{
  "/docs/browser/single-page-app-monitoring/get-started/spa-compatibility-requirements": [
    {
      "sections": [
        "Install Single Page App monitoring",
        "Tip",
        "Prerequisites",
        "Enable SPA monitoring",
        "Disable SPA monitoring"
      ],
      "title": "Install Single Page App monitoring",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Get started"
      ],
      "external_id": "04501b8d90b2c9b3bf3fa29f1662596a1379e2b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/get-started/install-single-page-app-monitoring/",
      "published_at": "2021-06-14T22:31:57Z",
      "updated_at": "2021-03-13T02:45:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In the New Relic UI, you can enable single-page app (SPA) monitoring. Tip To use SPA and browser monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Prerequisites In order to deploy SPA monitoring, you must: Make sure your app and Browser agent version meet New Relic's compatibility and requirements. Agree to the Terms of Service, which automatically appears during the setup process for the first app you select for your account. By agreeing to the Terms, you authorize New Relic to collect hash fragments from URLs. You only need to select the checkbox option once for your account. Enable SPA monitoring To deploy SPA monitoring for your app, you must already have a Pro subscription. Then, you must enable Pro + SPA monitoring, and deploy a new JavaScript snippet that includes SPA monitoring. Tip The bottom of the generated JavaScript snippet includes your Browser license key and application ID. This is useful, for example, when using the New Relic REST API (v2) or API Explorer. To enable SPA monitoring: Go to one.newrelic.com > Browser > (select an app) > Settings > Application settings, then select Pro + SPA. Agree to the Terms of Service. Select Save application settings. Deploy the new JavaScript snippet using the same method you used when you originally deployed Browser for your app: If you deploy Browser with the copy/paste method: Copy the entire JavaScript code snippet. Paste it as close to the top of the HEAD of your webpage as possible, but after any position-sensitive META tags (for example, X-UA-Compatible or charset information). If you deploy using an APM agent: If possible, restart your app and clear the server-side cache to ensure the APM agent picks up the change and deploys the new JavaScript snippet. Generate some traffic, then wait a few minutes for Browser to start receiving SPA monitoring data. To view SPA data: Go to one.newrelic.com > Browser > (select an app) > Page views. If SPA data does not start to appear in the Page views page after a few minutes, see Browser's troubleshooting procedures. Disable SPA monitoring To opt out of our SPA monitoring feature: Go to one.newrelic.com > Browser > (select an app) > Settings > Application settings. Select a different agent version/loader option. Select Save application settings.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.68697,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "sections": "Install <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "In the New Relic UI, you can enable <em>single</em>-<em>page</em> <em>app</em> (SPA) <em>monitoring</em>. Tip To use SPA and <em>browser</em> <em>monitoring</em>, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month"
      },
      "id": "6043f16664441f56fa378eec"
    },
    {
      "sections": [
        "Introduction to Single Page App monitoring",
        "Enable SPA monitoring",
        "Analyze throughput and performance data",
        "Browser SPA features",
        "For more help"
      ],
      "title": "Introduction to Single Page App monitoring",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Get started"
      ],
      "external_id": "6dedda52851e1ca1f180c8d88bdcb7038c4d1b5d",
      "image": "https://docs.newrelic.com/static/98d434a02c314f2bd2ce9828aa7b755d/c1b63/browser_SPA.png",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/get-started/introduction-single-page-app-monitoring/",
      "published_at": "2021-06-14T22:31:57Z",
      "updated_at": "2021-03-11T07:33:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Single page applications (SPAs) are web applications that load a single HTML page. The app dynamically updates without requiring a full page reload, in response to user interactions with the app, such as clicking a button or submitting a request. Browser's SPA monitoring provides deeper visibility and actionable insights into real users' experiences with single-page apps. SPA monitoring is also valuable for any app that uses AJAX requests to pull content dynamically and create a fluid user experience. In addition to monitoring route changes automatically, you can use Browser monitoring's SPA API to monitor virtually anything that executes inside the browser. This allows developers and their team to: Create faster, more responsive, highly interactive apps. Monitor the throughput and performance that real users are experiencing. Troubleshoot and resolve problems within the context of the page load. Query your data to assist with business decisions. Bring better apps to the marketplace more quickly. Enable SPA monitoring Before installing SPA monitoring, read SPA compatibility and requirements. Then, see Add apps to Single Page App monitoring. Analyze throughput and performance data Improving on traditional industry standards for measuring page load timing, we give you a complete picture of the activity, both synchronous and asynchronous, associated with page loads and route changes. one.newrelic.com > Browser > (select an app) > Page views: Use Browser monitoring's SPA monitoring to examine the throughput and performance of your SPA-architecture app. SPA data monitored by Browser monitoring can include: Performance data and throughput for page loads and route changes AJAX request data JavaScript activity, both synchronous and asynchronous Dynamic page updates, monitored using the SPA API With this data, you will gain a clear understanding of how your users experience your app's page loads and route changes, and be able to solve bottlenecks and troubleshoot errors. For more about how New Relic handles SPA data, see Understand SPA data collection. Browser SPA features Here is a summary of SPA monitoring features: Single-page app monitoring Take advantage of these features Robust views in Browser's UI When a user initiates a page load or route change, New Relic begins to monitor all subsequent JavaScript, and ends the timing once all AJAX events are complete. This provides a more accurate view of when a page is actually ready for a user compared to the traditional method of ending the timing when the window load event is fired. When SPA monitoring is enabled, the Page views page in Browser shows event-driven data about application usage levels (throughput) and user experience (performance), including: Charts with drill-down details about initial page load performance, route changes, and historical performance Sort, search, and filter options, including custom attributes Additional AJAX breakdown data for all initial page loads and route changes For an explanation of how SPA monitoring will impact your existing Browser account's data usage, see SPA and Browser data usage. Data analysis with data explorer The data explorer supports three SPA-specific event types: BrowserInteraction, AjaxRequest, and BrowserTiming. You can query these events in the query builder to analyze your app's performance and make business decisions. Customized data from API Use SPA API to obtain the specific data you need, such as custom naming, custom timing, finishline API, or other custom attributes. For more help Additional documentation resources include: SPA compatibility and requirements (see technical requirements for getting single-page app monitoring from New Relic) View SPA data in Browser monitoring (understand how Browser displays your data in the UI) Understand SPA data collection (learn how we collect and save your SPA data)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.38249,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "sections": "Introduction to <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": " features Here is a summary of SPA <em>monitoring</em> features: <em>Single</em>-<em>page</em> <em>app</em> <em>monitoring</em> Take advantage of these features Robust views in <em>Browser</em>&#x27;s UI When a user initiates a <em>page</em> load or route change, New Relic begins to <em>monitor</em> all subsequent JavaScript, and ends the timing once all AJAX events are complete"
      },
      "id": "604408d328ccbcf69e2c6064"
    },
    {
      "sections": [
        "Missing route changes with SPA agent",
        "Problem",
        "Solution",
        "Short term solutions",
        "Support",
        "Cause"
      ],
      "title": "Missing route changes with SPA agent",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Troubleshooting"
      ],
      "external_id": "9ca088a0459684464512ee51dfb7ffca22e26c14",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/troubleshooting/missing-route-changes-spa-agent/",
      "published_at": "2021-06-14T22:32:55Z",
      "updated_at": "2021-03-16T06:51:00Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You are using the Browser Pro + SPA agent, but you are not seeing all of the route change browser interactions you expect. We are aware that this can be frustrating. Our goal in summer 2020 is to reevaluate the SPA feature functionality, making it simpler and more reliable, starting with the methods we use to detect and capture route changes. Additionally, we plan to add new frameworks and use cases to our testing suite based on your feedback and examples. Likely this work will include new APIs as well as framework-specific plug-ins. Check our release notes for the latest updates. Solution Short term solutions To make sure all route changes are captured, you can use our SPA interaction() API. Using the interaction API will categorize the BrowserInteraction event (in the category attribute) as custom rather than a route change if no route change is in fact detected. If your framework is exposing events that represent router activity, you can use custom instrumentation in these events. Here is an example using our API with the Angular router: router.events.subscribe( (event: Event) => { if (event instanceof NavigationStart) { let i = newrelic.interaction() i.setName(event.url) i.save() } }); Copy In this example, the router object is an instance of the Angular router (from the @angular/router module). The setName call sets the name attribute of the BrowserInteraction event to the new URL, and the save call ensures that the interaction is captured. You will need to adapt this for the needs of your own application’s framework. If your framework does not provide routing events, then you can add this code in the event handler of the original interaction event such as click): myButton.addEventListener('click', function () { let i = newrelic.interaction() i.setName(‘new URL') i.save() }); Copy Recommendation: If you do not have access to router events nor the interaction event handler, implement this as soon as possible in code that you know is the result of a user interaction. An alternative to using the SPA API is to capture routes as PageAction events. PageAction events can be used to capture any custom data. We recommend this option as a fallback in case using the SPA interaction API does not work as expected, or to completely separate the custom instrumentation from built-in BrowserInteraction events. Both of these solutions can ensure these events are captured, either as a BrowserInteraction event or as a PageAction event. However, they will not address recording the correct duration and related AJAX calls. Support If this solution does not resolve your issue, please file a support ticket, and have the following information available: For situations where you are seeing most route changes, but none for a particular route change you expect, attempt to evaluate the difference in the implementation of the code for that particular route. Is there something non-standard or unique about that route that you could provide to our support team? Document the frameworks and any libraries that might be of interest. If this is a new problem, has anything changed in your environment that has led to these interactions suddenly not being tracked? Note the Browser agent version you are using. If you are more than a few releases behind, we will recommend that you update to the latest release, as we may have already resolved a similar issue. Be aware that due to the complexity of diagnosing these issues, the team will likely need access to an environment and code that demonstrates the problem for testing and research. Cause The Browser product attempts to be framework agnostic, as well as support coding best practices. However, there are often edge cases that will be missed that lead to you not collecting the route changes you expect. The implementation is based on instrumenting most common asynchronous browser APIs. There are cases when a web application uses some asynchronous API or uses custom or third-party code that we do not instrument, and this can result in inaccurate or missed route changes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.74672,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": ". <em>Page</em>Action events can be used to capture any custom data. We recommend this option as a fallback in case using the SPA interaction API does not work as expected, or to completely separate the custom instrumentation from built-in <em>Browser</em>Interaction events. Both of these solutions can ensure these events"
      },
      "id": "603e937628ccbcd4efeba750"
    }
  ],
  "/docs/browser/single-page-app-monitoring/troubleshooting/missing-route-changes-spa-agent": [
    {
      "sections": [
        "Install Single Page App monitoring",
        "Tip",
        "Prerequisites",
        "Enable SPA monitoring",
        "Disable SPA monitoring"
      ],
      "title": "Install Single Page App monitoring",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Get started"
      ],
      "external_id": "04501b8d90b2c9b3bf3fa29f1662596a1379e2b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/get-started/install-single-page-app-monitoring/",
      "published_at": "2021-06-14T22:31:57Z",
      "updated_at": "2021-03-13T02:45:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In the New Relic UI, you can enable single-page app (SPA) monitoring. Tip To use SPA and browser monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Prerequisites In order to deploy SPA monitoring, you must: Make sure your app and Browser agent version meet New Relic's compatibility and requirements. Agree to the Terms of Service, which automatically appears during the setup process for the first app you select for your account. By agreeing to the Terms, you authorize New Relic to collect hash fragments from URLs. You only need to select the checkbox option once for your account. Enable SPA monitoring To deploy SPA monitoring for your app, you must already have a Pro subscription. Then, you must enable Pro + SPA monitoring, and deploy a new JavaScript snippet that includes SPA monitoring. Tip The bottom of the generated JavaScript snippet includes your Browser license key and application ID. This is useful, for example, when using the New Relic REST API (v2) or API Explorer. To enable SPA monitoring: Go to one.newrelic.com > Browser > (select an app) > Settings > Application settings, then select Pro + SPA. Agree to the Terms of Service. Select Save application settings. Deploy the new JavaScript snippet using the same method you used when you originally deployed Browser for your app: If you deploy Browser with the copy/paste method: Copy the entire JavaScript code snippet. Paste it as close to the top of the HEAD of your webpage as possible, but after any position-sensitive META tags (for example, X-UA-Compatible or charset information). If you deploy using an APM agent: If possible, restart your app and clear the server-side cache to ensure the APM agent picks up the change and deploys the new JavaScript snippet. Generate some traffic, then wait a few minutes for Browser to start receiving SPA monitoring data. To view SPA data: Go to one.newrelic.com > Browser > (select an app) > Page views. If SPA data does not start to appear in the Page views page after a few minutes, see Browser's troubleshooting procedures. Disable SPA monitoring To opt out of our SPA monitoring feature: Go to one.newrelic.com > Browser > (select an app) > Settings > Application settings. Select a different agent version/loader option. Select Save application settings.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 180.02579,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "sections": "Install <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "In the New Relic UI, you can enable <em>single</em>-<em>page</em> <em>app</em> (SPA) <em>monitoring</em>. Tip To use SPA and <em>browser</em> <em>monitoring</em>, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month"
      },
      "id": "6043f16664441f56fa378eec"
    },
    {
      "sections": [
        "SPA compatibility and requirements",
        "Browser agent version",
        "Browser types",
        "Framework requirements",
        "Security when collecting hash fragments",
        "For more help"
      ],
      "title": "SPA compatibility and requirements",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Get started"
      ],
      "external_id": "17d916a952f7b86a1da190a9d7236072eff12361",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/get-started/spa-compatibility-requirements/",
      "published_at": "2021-06-14T22:31:57Z",
      "updated_at": "2021-05-05T17:26:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In order to set up Single Page Application (SPA) monitoring for Browser monitoring, make sure your app meets these SPA monitoring requirements. Browser agent version SPA monitoring requires an SPA-specific version of the Browser snippet, available for Browser agent version 885 or higher. To activate this snippet version for your application, enable your application for SPA monitoring. To check your version and integrate the updated snippet, follow the appropriate upgrade instructions. Browser types SPA monitoring requires the addEventListener Browser API and the Navigation Timing API. Both APIs are available in all modern browsers, including Google Chrome, Mozilla Firefox, Apple Safari, and Microsoft Internet Explorer (IE) versions 9 or higher. Framework requirements Because SPA instrumentation works by wrapping low-level browser APIs, it is framework-agnostic. SPA instrumentation is compatible with most SPA frameworks, such as Angular, Backbone, Ember, and React. It can also instrument requests made using JSONP. Below are known compatibility issues: If your application uses AngularJS and you want to use Browser's SPA monitoring capabilities, Zone.js versions 0.6.18-0.6.24 are not compatible with the SPA agent. The html2pdf.js library is not compatible with the SPA agent. Security when collecting hash fragments New Relic collects and saves hash fragments from route change URLs. If you use hashes to pass private or sensitive data, that data may be visible to your New Relic account users. Follow Browser's guidelines for security with data collection and reporting. For more help Additional documentation resources include: Browser settings (additional options to enable Browser features) Security for Browser monitoring (additional security considerations for Browser)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 177.70567,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Browser</em> agent version",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "In order to set up <em>Single</em> <em>Page</em> Application (SPA) <em>monitoring</em> for <em>Browser</em> <em>monitoring</em>, make sure your <em>app</em> meets these SPA <em>monitoring</em> requirements. <em>Browser</em> agent version SPA <em>monitoring</em> requires an SPA-specific version of the <em>Browser</em> snippet, available for <em>Browser</em> agent version 885 or higher"
      },
      "id": "6044095ee7b9d20d555799f3"
    },
    {
      "sections": [
        "Introduction to Single Page App monitoring",
        "Enable SPA monitoring",
        "Analyze throughput and performance data",
        "Browser SPA features",
        "For more help"
      ],
      "title": "Introduction to Single Page App monitoring",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Get started"
      ],
      "external_id": "6dedda52851e1ca1f180c8d88bdcb7038c4d1b5d",
      "image": "https://docs.newrelic.com/static/98d434a02c314f2bd2ce9828aa7b755d/c1b63/browser_SPA.png",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/get-started/introduction-single-page-app-monitoring/",
      "published_at": "2021-06-14T22:31:57Z",
      "updated_at": "2021-03-11T07:33:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Single page applications (SPAs) are web applications that load a single HTML page. The app dynamically updates without requiring a full page reload, in response to user interactions with the app, such as clicking a button or submitting a request. Browser's SPA monitoring provides deeper visibility and actionable insights into real users' experiences with single-page apps. SPA monitoring is also valuable for any app that uses AJAX requests to pull content dynamically and create a fluid user experience. In addition to monitoring route changes automatically, you can use Browser monitoring's SPA API to monitor virtually anything that executes inside the browser. This allows developers and their team to: Create faster, more responsive, highly interactive apps. Monitor the throughput and performance that real users are experiencing. Troubleshoot and resolve problems within the context of the page load. Query your data to assist with business decisions. Bring better apps to the marketplace more quickly. Enable SPA monitoring Before installing SPA monitoring, read SPA compatibility and requirements. Then, see Add apps to Single Page App monitoring. Analyze throughput and performance data Improving on traditional industry standards for measuring page load timing, we give you a complete picture of the activity, both synchronous and asynchronous, associated with page loads and route changes. one.newrelic.com > Browser > (select an app) > Page views: Use Browser monitoring's SPA monitoring to examine the throughput and performance of your SPA-architecture app. SPA data monitored by Browser monitoring can include: Performance data and throughput for page loads and route changes AJAX request data JavaScript activity, both synchronous and asynchronous Dynamic page updates, monitored using the SPA API With this data, you will gain a clear understanding of how your users experience your app's page loads and route changes, and be able to solve bottlenecks and troubleshoot errors. For more about how New Relic handles SPA data, see Understand SPA data collection. Browser SPA features Here is a summary of SPA monitoring features: Single-page app monitoring Take advantage of these features Robust views in Browser's UI When a user initiates a page load or route change, New Relic begins to monitor all subsequent JavaScript, and ends the timing once all AJAX events are complete. This provides a more accurate view of when a page is actually ready for a user compared to the traditional method of ending the timing when the window load event is fired. When SPA monitoring is enabled, the Page views page in Browser shows event-driven data about application usage levels (throughput) and user experience (performance), including: Charts with drill-down details about initial page load performance, route changes, and historical performance Sort, search, and filter options, including custom attributes Additional AJAX breakdown data for all initial page loads and route changes For an explanation of how SPA monitoring will impact your existing Browser account's data usage, see SPA and Browser data usage. Data analysis with data explorer The data explorer supports three SPA-specific event types: BrowserInteraction, AjaxRequest, and BrowserTiming. You can query these events in the query builder to analyze your app's performance and make business decisions. Customized data from API Use SPA API to obtain the specific data you need, such as custom naming, custom timing, finishline API, or other custom attributes. For more help Additional documentation resources include: SPA compatibility and requirements (see technical requirements for getting single-page app monitoring from New Relic) View SPA data in Browser monitoring (understand how Browser displays your data in the UI) Understand SPA data collection (learn how we collect and save your SPA data)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 160.70137,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "sections": "Introduction to <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": " features Here is a summary of SPA <em>monitoring</em> features: <em>Single</em>-<em>page</em> <em>app</em> <em>monitoring</em> Take advantage of these features Robust views in <em>Browser</em>&#x27;s UI When a user initiates a <em>page</em> load or route change, New Relic begins to <em>monitor</em> all subsequent JavaScript, and ends the timing once all AJAX events are complete"
      },
      "id": "604408d328ccbcf69e2c6064"
    }
  ],
  "/docs/browser/single-page-app-monitoring/use-spa-data/spa-data-collection": [
    {
      "sections": [
        "View SPA data in Browser UI",
        "Single-page app (SPA) data",
        "Filter SPA views",
        "Group SPA views",
        "SPA view details",
        "Initial page load performance details",
        "Route change performance details"
      ],
      "title": "View SPA data in Browser UI",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Use SPA data"
      ],
      "external_id": "0ab30db71f34da6376ff5e71734292b247754ca4",
      "image": "https://docs.newrelic.com/static/04bcea9186a93fc786a6db3469765824/c1b63/spa_overview.png",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/use-spa-data/view-spa-data-browser-ui/",
      "published_at": "2021-06-14T22:33:49Z",
      "updated_at": "2021-03-13T02:42:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have opted in to SPA (single-page app) monitoring, the Browser Page views page will include data on SPA route changes and initial page loads. one.newrelic.com > Browser > (select an app) > Page views: When you opt in to SPA monitoring, the Browser Page views page will display SPA data like route changes and associated asynchronous browser activity. Single-page app (SPA) data To view SPA data: Go to one.newrelic.com > Browser > (select an app) > Page views. Initial page loads and route changes are automatically grouped by Browser Interaction Name. You can adjust this with your allow list settings for segments. If you set custom route names with the SPA API, the custom route names will be displayed. You can change how the page loads and route changes are grouped by using the Group page by dropdown. By default, the list of page loads and route changes displays the most time consuming views at the top of the list. You can also sort by average response time, median response time, and throughput per minute by using the Sort by dropdown. To search for specific views by grouped URL, type in the search bar below the Sort by dropdown. For example, to find URLs that represent your checkout page, search for checkout. The charts on the initial Page view page display: The five views with the slowest average response times The five views with the highest throughput To change the range of time being examined, use the time picker near the top of the page. (If you choose a time range more than eight days in the past, some filtering and grouping functionality won't be available.) Filter SPA views one.newrelic.com > Browser > (select an app) > Page views > Filter: Use the Filter to filter for route changes, initial page loads, and other attributes like location and browser type. To view only initial page loads or only route changes, use the Filter dropdown. For example, to view only route changes, select Filter > Route change. The filter also gives you the ability to filter by other attributes of page loads and route changes, such as app name, geographical location of the browser, and browser type. For example, to see only page loads and route changes that occurred on browsers in the city of Portland, Oregon, select Filter > City > Portland. Group SPA views You can use the Group page by dropdown to group the list of page views by any attribute. For example, if you want to compare the average response times by browser type, select Group page by > userAgent. The combination of filtering and grouping lets you quickly find very specific data. For example, to compare how a specific URL is loading on different browsers: From the Filter dropdown, select targetURL, then select the URL you want to study. From the Group page by dropdown, select userAgent. SPA view details one.newrelic.com > Browser > (select an app) > Page views > (select a view): Select a view from the list to see assorted details and breakdowns. Select an individual page load or route change to see details. Selecting either will provide a breakdown of where time was spent for a browser interaction, and display that data over a time series matching the window selected in the time picker. Every route change view can theoretically also be an initial page load. (For example, when a route change URL is sent to someone else and they load it, that will now be considered an initial page load to New Relic.) This is why the SPA view details page has charts for both initial page loads and route changes. This allows you to compare how a view performs as an initial page load to how its performance as a route change. There are three chart display options, selectable with the icons to the right of the Avg initial page load time chart title. The default display is the color-coded stacked area chart. You can also switch to a Histogram display or a percentile line graph. Also on the details page is a Throughput chart that combines initial page loads and route changes. The chart displays the 5 pages with the highest throughput, which are listed beneath the chart, and consolidates all other pages into Other. Here are details on the specific performance data displayed for both page loads and route changes: Initial page load performance details For initial page loads, the performance details include the average back end time, front end time, and the window onload event: Back end time includes network, web app time, and request queuing. Front end time includes DOM processing, page rendering, and the time to complete all XHRs. A horizontal red line represents when the window load event is fired. This corresponds to the traditional page load timing measured by New Relic Browser without SPA monitoring enabled. With SPA monitoring it is common to have a window load event before the front end time is complete. (For more about how SPA page load timing differs from traditional page load timing, see Understand SPA data collection.) Route change performance details For route changes, the performance chart displays JS duration and waiting time. JS Duration is the sum of all JavaScript execution time during the interaction, which is synchronous by definition. The remaining time is called Waiting time and is derived by subtracting JS duration from the total duration. The Historical Performance and Breakdown details are similar for both page loads and route changes: Detail tab Comments Historical data The Historical Performance tab displays throughput (views per minute) and response time charted against the same time period yesterday and last week. Breakdowns The Breakdowns tab lists the various components individually timed as part of an interaction. By default, all XHRs are captured and timed. You can also use the SPA API to include additional elements for a route change or page load.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.20459,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View <em>SPA</em> <em>data</em> in <em>Browser</em> UI",
        "sections": "<em>Single</em>-<em>page</em> <em>app</em> (<em>SPA</em>) <em>data</em>",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "If you have opted in to <em>SPA</em> (<em>single</em>-<em>page</em> <em>app</em>) <em>monitoring</em>, the <em>Browser</em> <em>Page</em> views <em>page</em> will include <em>data</em> on <em>SPA</em> route changes and initial <em>page</em> loads. one.newrelic.com &gt; <em>Browser</em> &gt; (select an <em>app</em>) &gt; <em>Page</em> views: When you opt in to <em>SPA</em> <em>monitoring</em>, the <em>Browser</em> <em>Page</em> views <em>page</em> will display <em>SPA</em> <em>data</em> like"
      },
      "id": "60440de328ccbc26592c60be"
    },
    {
      "sections": [
        "Use SPA API"
      ],
      "title": "Use SPA API",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Use SPA data"
      ],
      "external_id": "85ba9b61e8ba08112a3a276d186fbe7af894251d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/use-spa-data/use-spa-api/",
      "published_at": "2021-06-14T22:32:54Z",
      "updated_at": "2021-03-11T07:35:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Browser's single-page application (SPA) monitoring includes an API to add custom monitoring of specific browser interactions. This is useful for monitoring interactions that New Relic does not record automatically because they do not result in route changes, such as a dynamically-updated widget. The SPA API also allows you to turn off default monitoring for interactions that you do not consider important enough to monitor. For more information about the SPA API, including specific API calls, see the Browser agent and SPA API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 227.82892,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Use</em> <em>SPA</em> API",
        "sections": "<em>Use</em> <em>SPA</em> API",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "<em>Browser</em>&#x27;s <em>single</em>-<em>page</em> application (<em>SPA</em>) <em>monitoring</em> includes an API to add custom <em>monitoring</em> of specific <em>browser</em> interactions. This is useful for <em>monitoring</em> interactions that New Relic does not record automatically because they do not result in route changes, such as a dynamically-updated widget"
      },
      "id": "60440de328ccbc04a23025de"
    },
    {
      "sections": [
        "SPA compatibility and requirements",
        "Browser agent version",
        "Browser types",
        "Framework requirements",
        "Security when collecting hash fragments",
        "For more help"
      ],
      "title": "SPA compatibility and requirements",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Get started"
      ],
      "external_id": "17d916a952f7b86a1da190a9d7236072eff12361",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/get-started/spa-compatibility-requirements/",
      "published_at": "2021-06-14T22:31:57Z",
      "updated_at": "2021-05-05T17:26:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In order to set up Single Page Application (SPA) monitoring for Browser monitoring, make sure your app meets these SPA monitoring requirements. Browser agent version SPA monitoring requires an SPA-specific version of the Browser snippet, available for Browser agent version 885 or higher. To activate this snippet version for your application, enable your application for SPA monitoring. To check your version and integrate the updated snippet, follow the appropriate upgrade instructions. Browser types SPA monitoring requires the addEventListener Browser API and the Navigation Timing API. Both APIs are available in all modern browsers, including Google Chrome, Mozilla Firefox, Apple Safari, and Microsoft Internet Explorer (IE) versions 9 or higher. Framework requirements Because SPA instrumentation works by wrapping low-level browser APIs, it is framework-agnostic. SPA instrumentation is compatible with most SPA frameworks, such as Angular, Backbone, Ember, and React. It can also instrument requests made using JSONP. Below are known compatibility issues: If your application uses AngularJS and you want to use Browser's SPA monitoring capabilities, Zone.js versions 0.6.18-0.6.24 are not compatible with the SPA agent. The html2pdf.js library is not compatible with the SPA agent. Security when collecting hash fragments New Relic collects and saves hash fragments from route change URLs. If you use hashes to pass private or sensitive data, that data may be visible to your New Relic account users. Follow Browser's guidelines for security with data collection and reporting. For more help Additional documentation resources include: Browser settings (additional options to enable Browser features) Security for Browser monitoring (additional security considerations for Browser)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 177.70567,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>SPA</em> compatibility and requirements",
        "sections": "<em>SPA</em> compatibility and requirements",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "In order to set up <em>Single</em> <em>Page</em> Application (<em>SPA</em>) <em>monitoring</em> for <em>Browser</em> <em>monitoring</em>, make sure your <em>app</em> meets these <em>SPA</em> <em>monitoring</em> requirements. <em>Browser</em> agent version <em>SPA</em> <em>monitoring</em> requires an <em>SPA</em>-specific version of the <em>Browser</em> snippet, available for <em>Browser</em> agent version 885 or higher"
      },
      "id": "6044095ee7b9d20d555799f3"
    }
  ],
  "/docs/browser/single-page-app-monitoring/use-spa-data/use-spa-api": [
    {
      "sections": [
        "SPA data collection",
        "Browser interactions",
        "Types of SPA data reporting",
        "Initial page loads",
        "Route changes",
        "Custom monitoring",
        "Difference from traditional page load timing",
        "Tip",
        "Timers",
        "Events and attributes"
      ],
      "title": "SPA data collection",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Use SPA data"
      ],
      "external_id": "d42d239aca2ea13a37fd926dca3672fcf83d73dd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/use-spa-data/spa-data-collection/",
      "published_at": "2021-06-14T22:33:49Z",
      "updated_at": "2021-03-11T04:55:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains how Browser collects and stores your asynchronous single page app (SPA) data. This will give you a better understanding of the SPA data you see in the Browser UI. This will also help you more easily add custom monitoring with the SPA API. Browser interactions At the heart of SPA monitoring is the concept of the browser interaction. New Relic defines a browser interaction as anything that occurs in the app user's browser; for example: A user interaction that leads to a page load or route change A scheduled, dynamic update to an app's widget A browser interaction includes not just the initial triggering event, but also the activity caused by that event, such as AJAX requests and both synchronous and asynchronous JavaScript. By tracking not just the cause but also the effects of a browser interaction, we help you understand how users experience your application's views and route changes. All apps are different and have different monitoring needs. That's why we include default monitoring as well as the ability to set up custom monitoring for any browser interactions you choose. Types of SPA data reporting Three major categories of single page app data can be reported to New Relic: Initial page loads Route changes Custom browser interactions created via the SPA API Each of these creates a BrowserInteraction event. If one or more AJAX requests are part of an interaction, then associated AjaxRequest events are also created. These events and their attributes can be queried in the query builder. Initial page loads An initial page load is a traditional URL change, stemming from a complete load or reload of a URL. This is indicated in the browser when a page load event fires (the window.onload event). Initial page loads appear along with route changes in the Browser UI. Route changes SPA users experience dynamic route changes in a similar way to page loads. Visitors to a site or app generally do not care how a new view was delivered; they simply know that when they perform an action, a new view appears. For this reason, we treat route changes in a similar way to page loads in the UI. In order to optimally monitor single page applications, we start monitoring many browser interactions that could theoretically lead to route changes. If these interactions do not lead to route changes, Browser initiates monitoring but then discards them. If these interactions do lead to a route change, Browser saves the interaction sequence as a BrowserInteraction event, including information about both synchronous and asynchronous activity. An interaction is considered a route change and saved as a BrowserInteraction event when one of the following occurs: The URL hash changes (usually using window.location.hash). A popstate event fires during a callback associated with an interaction. A pushState or replaceState API is called. Route changes appear along with initial page loads in the Browser UI. We receive and save hash fragments from route change URLs. If you use hashes to pass private or sensitive data, that data may be visible to your New Relic account users. For more information about data collection and reporting, see Security for Browser. Custom monitoring You can use the SPA API to set up custom monitoring of browser interactions that are not monitored by default. You can also use the API to disable default monitoring. Custom events are saved as BrowserInteraction events and have the following attributes: The category attribute will have the value Custom. The trigger attribute will have the value api. (This is the default value but can be changed with the API.) Difference from traditional page load timing To provide optimized data for single page app monitoring, we measure page load timing in a new way: by wrapping low level browser functions, both synchronous and asynchronous. This gives a fuller depiction of how long it takes to complete the changes required for a new view. This is different from the traditional method for page load timing. Traditional page load timing uses the firing of the window.onload event to determine when a page is loaded. This is not an optimal way to measure view change timing because web apps often have asynchronous code that runs for a significant amount of time after the window.onload event occurs. Tip Browser's standard, non-SPA Page views page displays different page load times than when SPA monitoring is enabled. Because SPA monitoring is measuring all asynchronous activity, the SPA load times will generally be longer than standard page load times. The traditional window.onload page load timing still appears on the SPA Page views page. When you select a specific page load event, Window onload appears as a red line in the page load time chart. You can also select Switch to standard page views to return to traditional load timing displays. Timers The agent monitors all asynchronous calls, including timers. Timers with durations shorter than one second are wrapped. Timers longer than one second are not wrapped because usually they are meant for non-web transactions, such as background work or polling that is unrelated to a user interaction. Events and attributes We save browser interactions that lead to route changes and page loads as BrowserInteraction events, and AJAX requests as AjaxRequest events. You can query these events in the query builder.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.99712,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>SPA</em> <em>data</em> collection",
        "sections": "<em>SPA</em> <em>data</em> collection",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "This document explains how <em>Browser</em> collects and stores your asynchronous <em>single</em> <em>page</em> <em>app</em> (<em>SPA</em>) <em>data</em>. This will give you a better understanding of the <em>SPA</em> <em>data</em> you see in the <em>Browser</em> UI. This will also help you more easily add custom <em>monitoring</em> with the <em>SPA</em> API. <em>Browser</em> interactions At the heart"
      },
      "id": "60440d9b196a672eb1960f6d"
    },
    {
      "sections": [
        "View SPA data in Browser UI",
        "Single-page app (SPA) data",
        "Filter SPA views",
        "Group SPA views",
        "SPA view details",
        "Initial page load performance details",
        "Route change performance details"
      ],
      "title": "View SPA data in Browser UI",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Use SPA data"
      ],
      "external_id": "0ab30db71f34da6376ff5e71734292b247754ca4",
      "image": "https://docs.newrelic.com/static/04bcea9186a93fc786a6db3469765824/c1b63/spa_overview.png",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/use-spa-data/view-spa-data-browser-ui/",
      "published_at": "2021-06-14T22:33:49Z",
      "updated_at": "2021-03-13T02:42:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have opted in to SPA (single-page app) monitoring, the Browser Page views page will include data on SPA route changes and initial page loads. one.newrelic.com > Browser > (select an app) > Page views: When you opt in to SPA monitoring, the Browser Page views page will display SPA data like route changes and associated asynchronous browser activity. Single-page app (SPA) data To view SPA data: Go to one.newrelic.com > Browser > (select an app) > Page views. Initial page loads and route changes are automatically grouped by Browser Interaction Name. You can adjust this with your allow list settings for segments. If you set custom route names with the SPA API, the custom route names will be displayed. You can change how the page loads and route changes are grouped by using the Group page by dropdown. By default, the list of page loads and route changes displays the most time consuming views at the top of the list. You can also sort by average response time, median response time, and throughput per minute by using the Sort by dropdown. To search for specific views by grouped URL, type in the search bar below the Sort by dropdown. For example, to find URLs that represent your checkout page, search for checkout. The charts on the initial Page view page display: The five views with the slowest average response times The five views with the highest throughput To change the range of time being examined, use the time picker near the top of the page. (If you choose a time range more than eight days in the past, some filtering and grouping functionality won't be available.) Filter SPA views one.newrelic.com > Browser > (select an app) > Page views > Filter: Use the Filter to filter for route changes, initial page loads, and other attributes like location and browser type. To view only initial page loads or only route changes, use the Filter dropdown. For example, to view only route changes, select Filter > Route change. The filter also gives you the ability to filter by other attributes of page loads and route changes, such as app name, geographical location of the browser, and browser type. For example, to see only page loads and route changes that occurred on browsers in the city of Portland, Oregon, select Filter > City > Portland. Group SPA views You can use the Group page by dropdown to group the list of page views by any attribute. For example, if you want to compare the average response times by browser type, select Group page by > userAgent. The combination of filtering and grouping lets you quickly find very specific data. For example, to compare how a specific URL is loading on different browsers: From the Filter dropdown, select targetURL, then select the URL you want to study. From the Group page by dropdown, select userAgent. SPA view details one.newrelic.com > Browser > (select an app) > Page views > (select a view): Select a view from the list to see assorted details and breakdowns. Select an individual page load or route change to see details. Selecting either will provide a breakdown of where time was spent for a browser interaction, and display that data over a time series matching the window selected in the time picker. Every route change view can theoretically also be an initial page load. (For example, when a route change URL is sent to someone else and they load it, that will now be considered an initial page load to New Relic.) This is why the SPA view details page has charts for both initial page loads and route changes. This allows you to compare how a view performs as an initial page load to how its performance as a route change. There are three chart display options, selectable with the icons to the right of the Avg initial page load time chart title. The default display is the color-coded stacked area chart. You can also switch to a Histogram display or a percentile line graph. Also on the details page is a Throughput chart that combines initial page loads and route changes. The chart displays the 5 pages with the highest throughput, which are listed beneath the chart, and consolidates all other pages into Other. Here are details on the specific performance data displayed for both page loads and route changes: Initial page load performance details For initial page loads, the performance details include the average back end time, front end time, and the window onload event: Back end time includes network, web app time, and request queuing. Front end time includes DOM processing, page rendering, and the time to complete all XHRs. A horizontal red line represents when the window load event is fired. This corresponds to the traditional page load timing measured by New Relic Browser without SPA monitoring enabled. With SPA monitoring it is common to have a window load event before the front end time is complete. (For more about how SPA page load timing differs from traditional page load timing, see Understand SPA data collection.) Route change performance details For route changes, the performance chart displays JS duration and waiting time. JS Duration is the sum of all JavaScript execution time during the interaction, which is synchronous by definition. The remaining time is called Waiting time and is derived by subtracting JS duration from the total duration. The Historical Performance and Breakdown details are similar for both page loads and route changes: Detail tab Comments Historical data The Historical Performance tab displays throughput (views per minute) and response time charted against the same time period yesterday and last week. Breakdowns The Breakdowns tab lists the various components individually timed as part of an interaction. By default, all XHRs are captured and timed. You can also use the SPA API to include additional elements for a route change or page load.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.20457,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View <em>SPA</em> <em>data</em> in <em>Browser</em> UI",
        "sections": "<em>Single</em>-<em>page</em> <em>app</em> (<em>SPA</em>) <em>data</em>",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "If you have opted in to <em>SPA</em> (<em>single</em>-<em>page</em> <em>app</em>) <em>monitoring</em>, the <em>Browser</em> <em>Page</em> views <em>page</em> will include <em>data</em> on <em>SPA</em> route changes and initial <em>page</em> loads. one.newrelic.com &gt; <em>Browser</em> &gt; (select an <em>app</em>) &gt; <em>Page</em> views: When you opt in to <em>SPA</em> <em>monitoring</em>, the <em>Browser</em> <em>Page</em> views <em>page</em> will display <em>SPA</em> <em>data</em> like"
      },
      "id": "60440de328ccbc26592c60be"
    },
    {
      "sections": [
        "SPA compatibility and requirements",
        "Browser agent version",
        "Browser types",
        "Framework requirements",
        "Security when collecting hash fragments",
        "For more help"
      ],
      "title": "SPA compatibility and requirements",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Get started"
      ],
      "external_id": "17d916a952f7b86a1da190a9d7236072eff12361",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/get-started/spa-compatibility-requirements/",
      "published_at": "2021-06-14T22:31:57Z",
      "updated_at": "2021-05-05T17:26:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In order to set up Single Page Application (SPA) monitoring for Browser monitoring, make sure your app meets these SPA monitoring requirements. Browser agent version SPA monitoring requires an SPA-specific version of the Browser snippet, available for Browser agent version 885 or higher. To activate this snippet version for your application, enable your application for SPA monitoring. To check your version and integrate the updated snippet, follow the appropriate upgrade instructions. Browser types SPA monitoring requires the addEventListener Browser API and the Navigation Timing API. Both APIs are available in all modern browsers, including Google Chrome, Mozilla Firefox, Apple Safari, and Microsoft Internet Explorer (IE) versions 9 or higher. Framework requirements Because SPA instrumentation works by wrapping low-level browser APIs, it is framework-agnostic. SPA instrumentation is compatible with most SPA frameworks, such as Angular, Backbone, Ember, and React. It can also instrument requests made using JSONP. Below are known compatibility issues: If your application uses AngularJS and you want to use Browser's SPA monitoring capabilities, Zone.js versions 0.6.18-0.6.24 are not compatible with the SPA agent. The html2pdf.js library is not compatible with the SPA agent. Security when collecting hash fragments New Relic collects and saves hash fragments from route change URLs. If you use hashes to pass private or sensitive data, that data may be visible to your New Relic account users. Follow Browser's guidelines for security with data collection and reporting. For more help Additional documentation resources include: Browser settings (additional options to enable Browser features) Security for Browser monitoring (additional security considerations for Browser)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 177.70566,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>SPA</em> compatibility and requirements",
        "sections": "<em>SPA</em> compatibility and requirements",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "In order to set up <em>Single</em> <em>Page</em> Application (<em>SPA</em>) <em>monitoring</em> for <em>Browser</em> <em>monitoring</em>, make sure your <em>app</em> meets these <em>SPA</em> <em>monitoring</em> requirements. <em>Browser</em> agent version <em>SPA</em> <em>monitoring</em> requires an <em>SPA</em>-specific version of the <em>Browser</em> snippet, available for <em>Browser</em> agent version 885 or higher"
      },
      "id": "6044095ee7b9d20d555799f3"
    }
  ],
  "/docs/browser/single-page-app-monitoring/use-spa-data/view-spa-data-browser-ui": [
    {
      "sections": [
        "SPA data collection",
        "Browser interactions",
        "Types of SPA data reporting",
        "Initial page loads",
        "Route changes",
        "Custom monitoring",
        "Difference from traditional page load timing",
        "Tip",
        "Timers",
        "Events and attributes"
      ],
      "title": "SPA data collection",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Use SPA data"
      ],
      "external_id": "d42d239aca2ea13a37fd926dca3672fcf83d73dd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/use-spa-data/spa-data-collection/",
      "published_at": "2021-06-14T22:33:49Z",
      "updated_at": "2021-03-11T04:55:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains how Browser collects and stores your asynchronous single page app (SPA) data. This will give you a better understanding of the SPA data you see in the Browser UI. This will also help you more easily add custom monitoring with the SPA API. Browser interactions At the heart of SPA monitoring is the concept of the browser interaction. New Relic defines a browser interaction as anything that occurs in the app user's browser; for example: A user interaction that leads to a page load or route change A scheduled, dynamic update to an app's widget A browser interaction includes not just the initial triggering event, but also the activity caused by that event, such as AJAX requests and both synchronous and asynchronous JavaScript. By tracking not just the cause but also the effects of a browser interaction, we help you understand how users experience your application's views and route changes. All apps are different and have different monitoring needs. That's why we include default monitoring as well as the ability to set up custom monitoring for any browser interactions you choose. Types of SPA data reporting Three major categories of single page app data can be reported to New Relic: Initial page loads Route changes Custom browser interactions created via the SPA API Each of these creates a BrowserInteraction event. If one or more AJAX requests are part of an interaction, then associated AjaxRequest events are also created. These events and their attributes can be queried in the query builder. Initial page loads An initial page load is a traditional URL change, stemming from a complete load or reload of a URL. This is indicated in the browser when a page load event fires (the window.onload event). Initial page loads appear along with route changes in the Browser UI. Route changes SPA users experience dynamic route changes in a similar way to page loads. Visitors to a site or app generally do not care how a new view was delivered; they simply know that when they perform an action, a new view appears. For this reason, we treat route changes in a similar way to page loads in the UI. In order to optimally monitor single page applications, we start monitoring many browser interactions that could theoretically lead to route changes. If these interactions do not lead to route changes, Browser initiates monitoring but then discards them. If these interactions do lead to a route change, Browser saves the interaction sequence as a BrowserInteraction event, including information about both synchronous and asynchronous activity. An interaction is considered a route change and saved as a BrowserInteraction event when one of the following occurs: The URL hash changes (usually using window.location.hash). A popstate event fires during a callback associated with an interaction. A pushState or replaceState API is called. Route changes appear along with initial page loads in the Browser UI. We receive and save hash fragments from route change URLs. If you use hashes to pass private or sensitive data, that data may be visible to your New Relic account users. For more information about data collection and reporting, see Security for Browser. Custom monitoring You can use the SPA API to set up custom monitoring of browser interactions that are not monitored by default. You can also use the API to disable default monitoring. Custom events are saved as BrowserInteraction events and have the following attributes: The category attribute will have the value Custom. The trigger attribute will have the value api. (This is the default value but can be changed with the API.) Difference from traditional page load timing To provide optimized data for single page app monitoring, we measure page load timing in a new way: by wrapping low level browser functions, both synchronous and asynchronous. This gives a fuller depiction of how long it takes to complete the changes required for a new view. This is different from the traditional method for page load timing. Traditional page load timing uses the firing of the window.onload event to determine when a page is loaded. This is not an optimal way to measure view change timing because web apps often have asynchronous code that runs for a significant amount of time after the window.onload event occurs. Tip Browser's standard, non-SPA Page views page displays different page load times than when SPA monitoring is enabled. Because SPA monitoring is measuring all asynchronous activity, the SPA load times will generally be longer than standard page load times. The traditional window.onload page load timing still appears on the SPA Page views page. When you select a specific page load event, Window onload appears as a red line in the page load time chart. You can also select Switch to standard page views to return to traditional load timing displays. Timers The agent monitors all asynchronous calls, including timers. Timers with durations shorter than one second are wrapped. Timers longer than one second are not wrapped because usually they are meant for non-web transactions, such as background work or polling that is unrelated to a user interaction. Events and attributes We save browser interactions that lead to route changes and page loads as BrowserInteraction events, and AJAX requests as AjaxRequest events. You can query these events in the query builder.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.99712,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>SPA</em> <em>data</em> collection",
        "sections": "<em>SPA</em> <em>data</em> collection",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "This document explains how <em>Browser</em> collects and stores your asynchronous <em>single</em> <em>page</em> <em>app</em> (<em>SPA</em>) <em>data</em>. This will give you a better understanding of the <em>SPA</em> <em>data</em> you see in the <em>Browser</em> UI. This will also help you more easily add custom <em>monitoring</em> with the <em>SPA</em> API. <em>Browser</em> interactions At the heart"
      },
      "id": "60440d9b196a672eb1960f6d"
    },
    {
      "sections": [
        "Use SPA API"
      ],
      "title": "Use SPA API",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Use SPA data"
      ],
      "external_id": "85ba9b61e8ba08112a3a276d186fbe7af894251d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/use-spa-data/use-spa-api/",
      "published_at": "2021-06-14T22:32:54Z",
      "updated_at": "2021-03-11T07:35:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Browser's single-page application (SPA) monitoring includes an API to add custom monitoring of specific browser interactions. This is useful for monitoring interactions that New Relic does not record automatically because they do not result in route changes, such as a dynamically-updated widget. The SPA API also allows you to turn off default monitoring for interactions that you do not consider important enough to monitor. For more information about the SPA API, including specific API calls, see the Browser agent and SPA API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 227.82892,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Use</em> <em>SPA</em> API",
        "sections": "<em>Use</em> <em>SPA</em> API",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "<em>Browser</em>&#x27;s <em>single</em>-<em>page</em> application (<em>SPA</em>) <em>monitoring</em> includes an API to add custom <em>monitoring</em> of specific <em>browser</em> interactions. This is useful for <em>monitoring</em> interactions that New Relic does not record automatically because they do not result in route changes, such as a dynamically-updated widget"
      },
      "id": "60440de328ccbc04a23025de"
    },
    {
      "sections": [
        "SPA compatibility and requirements",
        "Browser agent version",
        "Browser types",
        "Framework requirements",
        "Security when collecting hash fragments",
        "For more help"
      ],
      "title": "SPA compatibility and requirements",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Get started"
      ],
      "external_id": "17d916a952f7b86a1da190a9d7236072eff12361",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/get-started/spa-compatibility-requirements/",
      "published_at": "2021-06-14T22:31:57Z",
      "updated_at": "2021-05-05T17:26:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In order to set up Single Page Application (SPA) monitoring for Browser monitoring, make sure your app meets these SPA monitoring requirements. Browser agent version SPA monitoring requires an SPA-specific version of the Browser snippet, available for Browser agent version 885 or higher. To activate this snippet version for your application, enable your application for SPA monitoring. To check your version and integrate the updated snippet, follow the appropriate upgrade instructions. Browser types SPA monitoring requires the addEventListener Browser API and the Navigation Timing API. Both APIs are available in all modern browsers, including Google Chrome, Mozilla Firefox, Apple Safari, and Microsoft Internet Explorer (IE) versions 9 or higher. Framework requirements Because SPA instrumentation works by wrapping low-level browser APIs, it is framework-agnostic. SPA instrumentation is compatible with most SPA frameworks, such as Angular, Backbone, Ember, and React. It can also instrument requests made using JSONP. Below are known compatibility issues: If your application uses AngularJS and you want to use Browser's SPA monitoring capabilities, Zone.js versions 0.6.18-0.6.24 are not compatible with the SPA agent. The html2pdf.js library is not compatible with the SPA agent. Security when collecting hash fragments New Relic collects and saves hash fragments from route change URLs. If you use hashes to pass private or sensitive data, that data may be visible to your New Relic account users. Follow Browser's guidelines for security with data collection and reporting. For more help Additional documentation resources include: Browser settings (additional options to enable Browser features) Security for Browser monitoring (additional security considerations for Browser)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 177.70566,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>SPA</em> compatibility and requirements",
        "sections": "<em>SPA</em> compatibility and requirements",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "In order to set up <em>Single</em> <em>Page</em> Application (<em>SPA</em>) <em>monitoring</em> for <em>Browser</em> <em>monitoring</em>, make sure your <em>app</em> meets these <em>SPA</em> <em>monitoring</em> requirements. <em>Browser</em> agent version <em>SPA</em> <em>monitoring</em> requires an <em>SPA</em>-specific version of the <em>Browser</em> snippet, available for <em>Browser</em> agent version 885 or higher"
      },
      "id": "6044095ee7b9d20d555799f3"
    }
  ],
  "/docs/cloud-instance-optimizer-find-underused-virtual-machines": [
    {
      "sections": [
        "Azure VMs monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Inventory data",
        "Other system data",
        "Troubleshooting"
      ],
      "title": "Azure VMs monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "b77f3bb6f9dd73582e5789d2c2553a946de28e2b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-vms-monitoring-integration/",
      "published_at": "2021-06-15T13:20:52Z",
      "updated_at": "2021-05-21T18:18:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure monitoring provides an integration for Microsoft Azure Virtual Machines (VMs) that reports data from your Azure VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic's integration for Azure Virtual Machines reports data about your VMs service, like the VM ID, the VM size, the availability set, and the region name. You can monitor and alert on your Azure VMs data from New Relic, and you can create custom queries and chart dashboards. Requirements Requirements include: New Relic infrastructure agent installed with Infrastructure agent version 1.0.775 or higher. (Update the infrastructure agent.) New Relic Azure integrations activated Activate integration To enable this integration follow standard procedures to activate your Azure service in New Relic. Important You must install the infrastructure agent on each VM to see metrics from that host. Connecting your Azure subscription allows New Relic to access VM metadata. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Virtual Machines integration: Polling interval: 5 minutes Resolution: 1 data point per minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > Azure and look for the integration. You can query and explore your data using the AzureVirtualMachineSample event type. The provider value is AzureVirtualMachine. For more on how to find and use integration data, see Understand and use data. Inventory data Inventory data is information about your system's state and configuration. For details on how to find and use inventory data, see Understand and use data. The Azure Virtual Machines integration reports this inventory data: availabilitySet bootDiagnosticsEnabled image linuxConfiguration name networkInterfaces osDisk provisioningState regionName resourceGroupName (deprecates resourceGroup) vmId vmSize windowsConfiguration Other system data The Azure Virtual Machines integration also collects the following attributes about the service and its configuration: Region Availability zone Instance type Instance ID Troubleshooting If you use Host not reporting alert conditions, the importing of Azure metadata for your VMs will change the hosts registry and result in false alert notifications. To prevent false positives: For each Azure instance, disable its Host not reporting alert condition. Update the infrastructure agent for all instances that used this alert condition. Re-enable each Host not reporting alert condition.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.09393,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Find</em> and use data",
        "body": " <em>Machines</em> integration: Polling interval: 5 minutes Resolution: 1 data point per minute <em>Find</em> and use data To <em>find</em> your integration data, go to one.newrelic.com &gt; Infrastructure &gt; Azure and look for the integration. You can query and explore your data using the Azure<em>Virtual</em>MachineSample event type"
      },
      "id": "6044e56164441faf31378f07"
    },
    {
      "sections": [
        "Google Compute Engine monitoring integration",
        "Activate integration",
        "Important",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpVirtualMachineSample",
        "GcpVirtualMachineDiskSample",
        "Inventory data",
        "gcp/compute/virtual-machine",
        "gcp/compute/virtual-machine/disk",
        "Learn more"
      ],
      "title": "Google Compute Engine monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "749ce2f670e38c332eb8b591fb0fbf0098ba157f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-compute-engine-monitoring-integration/",
      "published_at": "2021-06-15T11:47:18Z",
      "updated_at": "2021-05-15T19:35:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "All New Relic Infrastructure accounts, regardless of subscription level, can use New Relic's Compute Engine integration to get a comprehensive, real-time view of their host's performance and status. New Relic Infrastructure's integration with Google Compute Engine reports metadata about instances (virtual machines) hosted on Google's infrastructure. You can monitor and alert on your GCP instances data from New Relic Infrastructure, and you can create custom queries and chart dashboards in New Relic Insights. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic Infrastructure. Important You must install the Infrastructure agent on each GCE host to see metrics from that host. Connecting your Google Cloud projects allows Infrastructure to access GCE metadata, such as region, type, and tags. Polling frequency New Relic Infrastructure integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling interval for the Google Compute Engine integration is 5 minutes. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data Metric data that New Relic receives from your GCP Compute Engine integration include: GcpVirtualMachineSample Name Description firewall.DroppedBytes Delta count of incoming bytes dropped by the firewall. firewall.DroppedPackets Delta count of incoming packets dropped by the firewall. instance.cpu.ReservedCores Total number of cores reserved on the host of the instance. GcpVirtualMachineDiskSample Name Description instance.disk.ThrottledReadBytes Delta count of bytes in throttled read operations. instance.disk.ThrottledReadOps Delta count of throttled read operations. instance.disk.ThrottledWriteBytes Delta count of bytes in throttled write operations. instance.disk.ThrottledWriteOps Delta count of throttled write operations. Inventory data Inventory data is information about the status or configuration of a service or host. You can examine inventory data in New Relic Infrastructure and in New Relic Insights. The Google Compute Engine integration reports configuration information and labels for virtual machines and disks through the properties listed below. Virtual machine tags are treated as labels that take the value true. gcp/compute/virtual-machine automaticRestart canIpForward cpuPlatform creationTimestamp deletionProtection description instanceId isPreemptible label.* machineType metadataFingerprint name networkInterfaces onHostMaintenance project status networkTags zone gcp/compute/virtual-machine/disk creationTimestamp description diskId encrypted instanceId instanceName label.* lastAttachTimestamp lastDetachTimestamp licenses name project replicaZones sizeGb sourceImage sourceImageId sourceSnapshot sourceSnapshotId status type users zone Learn more",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.48795,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "gcp&#x2F;compute&#x2F;<em>virtual</em>-<em>machine</em>",
        "tags": "Google <em>Cloud</em> Platform integrations",
        "body": " information and labels for <em>virtual</em> <em>machines</em> and disks through the properties listed below. <em>Virtual</em> machine tags are treated as labels that take the value true. gcp&#x2F;compute&#x2F;<em>virtual</em>-machine automaticRestart canIpForward cpuPlatform creationTimestamp deletionProtection description <em>instance</em>Id isPreemptible"
      },
      "id": "603e7d1f28ccbc483ceba771"
    },
    {
      "sections": [
        "Oracle Database monitoring integration",
        "Compatibility and requirements",
        "Oracle Database users and privileges",
        "Tip",
        "Install and activate",
        "Configure the integration",
        "Important",
        "Commands",
        "Arguments",
        "Labels",
        "Example configuration",
        "Example custom query configuration",
        "Find and use data",
        "Metric data",
        "Database metrics",
        "Tablespace metrics",
        "Inventory data",
        "Parameters",
        "Troubleshooting",
        "The Oracle library cannot be loaded",
        "ORACLE_HOME is not set correctly",
        "I get an ORA error",
        "Check the source code"
      ],
      "title": "Oracle Database monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "ec5ba9d06736a0cb168402e7af8a935068d748c9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/host-integrations/host-integrations-list/oracle-database-monitoring-integration/",
      "published_at": "2021-06-15T01:03:02Z",
      "updated_at": "2021-06-03T16:45:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Oracle Database integration collects key performance metrics on databases, tablespaces, and memory by default. You can customize your configuration to collect even more metrics, giving you detailed characterization of database performance. Read on to install the integration, and to see what data we collect. Compatibility and requirements Our integration is compatible with Oracle Database versions 11.2 and higher. Before installing the integration, make sure that you meet the following requirements: Linux distro compatible with infrastructure, except for RHEL/CentOS/OEL versions lower than 7. Install the infrastructure agent. Oracle Instant Client on the agent box. Oracle database with ORACLE_HOME configured to the correct directory for the root user. Oracle database user with both CONNECT and SELECT privileges on the required global views. Oracle database with a listener.ora file configured to monitor from a remote connection. By default, Oracle Database only listens to localhost. Oracle Database users and privileges In the Oracle database, execute the following statements to create a new user and assign user privileges. USERNAME and similar user-specific values must be replaced. If you use Oracle DB 12c or higher, use ALTER SESSION to access the database and manage users and user properties. Do not run this query if your Oracle DB version is lower than 12c. ALTER SESSION set \"_Oracle_SCRIPT\"=true; Copy Use CREATE USER to add a new user to the database. Replace USER_PASSWORD with the new user's password. CREATE USER USERNAME IDENTIFIED BY \"USER_PASSWORD\"; Copy Tip For assistance with user maintenance questions, consult the Oracle documentation or contact your system or database administrator. Grant CONNECT privileges to the user. GRANT CONNECT TO USERNAME; Copy Grant SELECT privileges to the user on the following global views: cdb_data_files cdb_pdbs cdb_users gv_$sysmetric gv_$pgastat gv_$instance gv_$filestat gv_$parameter sys.dba_data_files gv_$session gv_$sesstat gv_$statname gv_$rowcache gv_$sga gv_$sysstat v_$database gv_$librarycache gv_$sqlarea gv_$system_event dba_tablespaces gv_$session_wait gv_$rollstat v_$instance You can execute the following SQL statements together in one script or individually. GRANT SELECT ON cdb_data_files TO USERNAME; GRANT SELECT ON cdb_pdbs TO USERNAME; GRANT SELECT ON cdb_users TO USERNAME; GRANT SELECT ON gv_$sysmetric TO USERNAME; GRANT SELECT ON gv_$pgastat TO USERNAME; GRANT SELECT ON gv_$instance TO USERNAME; GRANT SELECT ON gv_$filestat TO USERNAME; GRANT SELECT ON gv_$parameter TO USERNAME; GRANT SELECT ON sys.dba_data_files TO USERNAME; GRANT SELECT ON DBA_TABLESPACES TO USERNAME; GRANT SELECT ON DBA_TABLESPACE_USAGE_METRICS TO USERNAME; GRANT SELECT ON gv_$session TO USERNAME; GRANT SELECT ON gv_$sesstat TO USERNAME; GRANT SELECT ON gv_$statname TO USERNAME; GRANT SELECT ON gv_$rowcache TO USERNAME; GRANT SELECT ON gv_$sga TO USERNAME; GRANT SELECT ON gv_$sysstat TO USERNAME; GRANT SELECT ON v_$database TO USERNAME; GRANT SELECT ON gv_$librarycache TO USERNAME; GRANT SELECT ON gv_$sqlarea TO USERNAME; GRANT SELECT ON gv_$system_event TO USERNAME; GRANT SELECT ON dba_tablespaces TO USERNAME; GRANT SELECT ON gv_$session_wait TO USERNAME; GRANT SELECT ON gv_$rollstat TO USERNAME; GRANT SELECT ON v_$instance TO USERNAME; Copy Install and activate To install the Oracle Database integration: Follow the instructions for installing an integration, using the file name nri-oracledb. Change directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy the sample configuration file: sudo cp oracledb-config.yml.sample oracledb-config.yml Copy Edit the oracledb-config.yml file as described in the configuration settings. Restart the infrastructure agent. Additional notes: Advanced: It's also possible to install the integration from a tarball file. This gives you full control over the installation and configuration process. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. Configure the integration An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. For an example configuration, see the example config file. Important With secrets management, you can configure on-host integrations with New Relic infrastructure's agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. For more information, see Secrets management. Commands The oracledb-config.yml file accepts the following commands: all_data: collects both inventory and metric data. Arguments The all_data command accepts the following arguments: service_name: Oracle Database service name of the instance (or cluster of instances) to monitor. This field is required. username: username of a user created with the required permissions. This field is required. password: password of a user created with the required permissions. This field is required. is_sys_dba: boolean value that indicates whether the authenticating user has SysDBA permissions. Default: false. oracle_home: path to where ORACLE_HOME is. This field is required. is_sys_oper: boolean value that indicates whether the authenticating user has SysOper permissions. Default: false. tablespaces: A JSON array of tablespaces to collect. If omitted, collects all tablespaces. Default: none (all tablespaces). Due to performance reasons, the integration will refuse to collect tablespace data for more than 200 tablespaces. If your database has more than 200 of tablespaces, you must restrict collection to a smaller number by using the tablespaces parameter. hostname: hostname of the instance to monitor. Default: 127.0.0.1. port: port number on which Oracle Database is running. Default: 1521. connection_string: a full connection string such as those found in tnsnames.ora. If this is specified, it takes priority over host, port, and service_name. extended_metrics: boolean value that indicates whether to collect extended metrics. Default: false. custom_metrics_query: a custom SQL query to run against the configured instance. Each row of the query is added as a new metric set on OracleCustomSample. Each non-null column in the row is added as an attribute on that metric set. custom_metrics_config: a path to a YAML file that contains a list of queries, along with custom sample names and metric type overrides. See example below for details. Labels The labels field controls the environment attribute. Default: production. Example configuration Example oracledb-config.yml file configuration: Example configuration integration_name: com.newrelic.oracledb instances: - name: oracledb command: all_data arguments: username: oracle_user password: oracle_password hostname: oracle-host.localnet oracle_home: <path to ORACLE_HOME> is_sys_dba: true service_name: ORCL custom_metrics_config: <path to custom queries yaml> # custom_metrics_query: >- # SELECT # 'physical_reads' AS \"metric_name\", # 'gauge' AS \"metric_type\", # SUM(PHYRDS) AS \"metric_value\", # INST_ID AS \"instanceID\" # FROM gv$filestat # GROUP BY INST_ID; labels: env: staging Copy Example custom query configuration --- queries: # Metric names are set to the column names in the query results - query: >- SELECT SUM(stat.gets) AS \"gets\", SUM(stat.waits) AS \"waits\", SUM(stat.waits)/SUM(stat.gets) AS \"ratio\", inst.inst_id FROM GV$ROLLSTAT stat, GV$INSTANCE inst WHERE stat.inst_id=inst.inst_id GROUP BY inst.inst_id # If not set explicitly here, metric type will default to # 'gauge' for numbers and 'attribute' for strings metric_types: gets: gauge # If unset, sample_name defaults to OracleCustomSample sample_name: MyCustomSample Copy For more about the general structure of on-host integration configuration, see Configuration. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > Third-party services and select one of the Oracle Database integration links. Oracle Database data is attached to the following event types: OracleDatabaseSample OracleTablespaceSample For more on how to find and use your data, see Understand integration data. Metric data The Oracle Database integration collects the following metric data attributes. Each metric name is prefixed with a category indicator and a period, such as disk. or memory.. Database metrics These attributes can be found by querying the OracleDatabaseSample event type. Metric Description db.activeParallelSessions Active parallel sessions. db.activeSerialSessions Active serial sessions. db.averageActiveSessions Average active sessions. Extended: yes. db.backgroundCheckpointsPerSecond Checkpoints per second. db.backgroundCpuUsagePerSecond Background CPU usage per second. db.backgroundTimePerSecond Background time per second. db.blockChangesPerSecond DB block changes per second. db.blockChangesPerTransaction DB block changes per transaction. db.blockChangesPerUserCall DB block changes per user call. db.blockGetsPerSecond DB block gets per second. db.blockGetsPerTransaction DB block gets per transaction. db.blockGetsPerUserCall DB block gets per user call. db.branchNodeSplitsPerSecond Branch node splits per second. db.branchNodeSplitsPerTransaction Branch node splits per transaction. db.consistentReadChangesPerSecond Consistent read changes per second. db.consistentReadChangesPerTransaction Consistent read changes per transaction. db.consistentReadGetsPerSecond Consistent read gets per second. db.consistentReadGetsPerTransaction Consistent read gets per transaction. db.cpuTimeRatio Database CPU time ratio. db.cpuUsagePerSecond CPU usage per second. Extended: yes. db.cpuUsagePerTransaction CPU usage per transaction. db.crBlocksCreatedPerSecond CR blocks created per second. db.crBlocksCreatedPerTransaction CR blocks created per transaction. db.crUndoRecordsAppliedPerSecond CR undo records applied per second. db.crUndoRecordsAppliedPerTransaction CR undo records applied per transaction. db.currentLogons Current logons count. db.currentOpenCursors Current open cursors count. db.cursorCacheHitsPerAttempts Cursor cache hit ratio. db.databaseCpuTimePerSecond Database time per second. db.dbwrCheckpointsPerSecond DBWR checkpoints per second. db.enqueueDeadlocksPerSecond Enqueue deadlocks per second. db.enqueueDeadlocksPerTransaction Enqueue deadlocks per transaction db.enqueueRequestsPerSecond Enqueue requests per second db.enqueueRequestsPerTransaction Enqueue requests per transaction. db.enqueueTimeoutsPerSecond Enqueue timeouts per second. db.enqueueTimeoutsPerTransaction Enqueue timeouts per transaction. db.enqueueWaitsPerSecond Enqueue waits per second. db.enqueueWaitsPerTransaction Enqueue waits per transaction. db.executionsPerSecond Executions per second. db.executionsPerTransaction Executions per transaction. Extended: yes. db.executionsPerUserCall Executions per user call. db.fullIndexScansPerSecond Full index scans per second. db.fullIndexScansPerTransaction Full index scans per transaction. db.GcCrBlockRecievedPerSecond GC CR block received per second. db.GcCrBlockRecievedPerTransaction GC CR block received per transaction. db.GcCurrentBlockReceivedPerSecond GC current block received per second. db.GcCurrentBlockReceivedPerTransactino GC current block received per transaction. db.globalCacheAverageCrGetTime Global cache average CR get time. db.globalCacheAverageCurrentGetTime Global cache average current get time. db.hardParseCountPerSecond Hard parse count per second. db.hardParseCountPerTransaction Hard parse count per transaction. db.hostCpuUsagePerSecond Host CPU usage per second. db.hostCpuUtilization Host CPU utilization (percentage). Extended: yes. db.leafNodeSplitsPerSecond Leaf node splits per second. db.leafNodeSplitsPerTransaction Leaf node splits per transaction. db.libraryCacheHitRatio Library cache hit ratio. db.libraryCacheMissRatio Library cache miss ratio. db.logicalReadsPerSecond Logical reads per second. db.logicalReadsPerTransaction Logical reads per transaction. db.logonsPerSecond Logons per second. db.logonsPerTransaction Logons per transaction. db.longTableScansPerSecond Long table scans per second. db.longTableScansPerTransaction Long table scans per transaction. db.openCursorsPerSecond Open cursors per second. db.openCursorsPerTransaction Open cursors per transaction. db.osLoad Current OS load. db.parseFailureCountPerSecond Parse failure count per second. db.parseFailureCountPerTransaction Parse failure count per transaction. db.pgaCacheHitPercentage PGA cache hit percentage. db.processLimitPercentage Process limit percentage. db.recursiveCallsPerSecond Recursive calls per second. db.recursiveCallsPerTransaction Recursive calls per transaction. db.redoWritesPerSecond Redo writes per second. db.redoWritesPerTransaction Redo writes per transaction. db.responseTimePerTransaction Response time per transaction. db.rowCacheHitRatio Row cache hit ratio. db.rowCacheMissRatio Row cache miss ratio. db.rowsPerSort Rows per sort. db.sessionCount Session count. Extended: yes. db.sessionLimitPercentage Session limit percentage. db.sharedPoolFreePercentage Shared pool free percentage. db.softParseRatio Soft parse ratio. db.sortsPerUserCall Total sorts per user call. db.sqlServiceResponseTime SQL service response time. db.streamsPoolUsagePercentage Streams pool usage percentage. db.tableScansPerUserCall Total table scans per user call. db.totalIndexScansPerSecond Total index scans per second. Extended: yes. db.totalIndexScansPerTransaction Total index scans per transaction. db.totalParseCountPerSecond Total parse count per second. db.totalParseCountPerTransaction Total parse count per transaction. db.totalTableScansPerSecond Total table scans per second. Extended: yes. db.totalTableScansPerTransaction Total table scans per transaction. db.TransactionsPerLogon Transactions per logon. db.userCallsPerSecond User calls per second. db.userCallsPerTransaction User calls per transaction. db.userCallsRatio User calls ratio. db.userCommitsPercentage User commits percentage. db.userCommitsPerSecond User commits per second. db.userLimitPercentage User limit percentage. db.userRollbacksPercentage User rollbacks per transaction. db.userRollbacksPerSecond User rollbacks per second. db.userRollbackUndoRecordsAppliedPerSecond User rollback undo records applied per second. db.userRollbackUndoRecordsAppliedPerTransaction User rollback undo records applied per transaction. db.waitTimeRatio Database wait time ratio. disk.blocksRead Number of block reads. Extended: yes. disk.blocksWritten Number of block writes. Extended: yes. disk.logicalReadsPerUserCall Logical reads per user call. disk.physicalLobsReadsPerSecond Physical reads direct lobs per second. disk.physicalLobsWritesPerSecond Physical writes direct lobs per second. disk.physicalReadBytesPerSecond Physical read total bytes per second. Extended: yes. disk.physicalReadIoRequestsPerSecond Physical read total I/O requests per second. Extended: yes. disk.physicalReadsPerSecond Physical reads direct per second. Extended: yes. disk.physicalWriteBytesPerSecond Physical write total bytes per second. disk.physicalWriteIoRequestsPerSecond Physical write I/O requests per second. disk.physicalWritesPerSecond Physical writes direct per second. Extended: yes. disk.physicalWriteTotalIoRequestsPerSecond Physical write total I/O requests per second. Extended: yes. disk.reads Total number of physical reads. Extended: yes. disk.readTime Amount of file read time. Extended: yes. disk.sortPerSecond Disk sort per second. disk.sortPerTransaction Disk sort per transaction. disk.tempSpaceUsed Temp space used. disk.writes Total number of physical writes. Extended: yes. disk.writeTime Amount of file write time. Extended: yes. lockedAccounts Number of accounts whose account_status is not OPEN. longRunningQueries Number of long running (> 60s) queries. memory.bufferCacheHitRatio Buffer cache hit ratio. Extended: yes. memory.globalCacheBlocksCorrupted Global cache blocks corrupted. memory.globalCacheBlocksLost Global cache blocks lost. memory.pgaAllocated Current amount of PGA memory allocated by the instance. memory.pgaFreeable Number of bytes of PGA memory in all processes that could be freed back to the operating system. memory.pgaInUse Indicates how much PGA memory is currently consumed by work areas. This number can be used to determine how much memory is consumed by other consumers of the PGA memory (for example, PL/SQL or Java). memory.pgaMaxSize Maximum size of a work area executed in automatic mode. Extended: yes. memory.redoAllocationHitRatio Redo allocation hit ratio. memory.redoGeneratedBytesPerSecond Redo generated bytes per second. memory.redoGeneratedBytesPerTransaction Redo generated bytes per transaction. memory.sortsRatio Memory sorts ratio. network.ioMegabytesPerSecond I/O megabytes per second. network.ioRequestsPerSecond I/O requests per second. Extended: yes. network.trafficBytePerSecond Network traffic volume per second. Extended: yes. query.physicalLobsReadsPerTransaction Physical reads direct lobs per transaction. query.physicalLobsWritesPerTransaction Physical writes direct lobs per transaction. query.physicalReadsPerTransaction Physical reads per transaction. query.physicalReadsPerTransaction Physical reads direct per transaction. query.physicalWritesPerTransaction Physical writes per transaction. query.physicalWritesPerTransaction Physical writes direct per transaction. query.transactionsPerSecond User transaction per second. Extended: yes. redoLog.logFileSwitch Number of redo log file switch events. redoLog.logFileSwitchArchivingNeeded Number of redo log file switch events that need archiving. redoLog.logFileSwitchCheckpointIncomplete Number of redo log file switch event checkpoints that are incomplete. redoLog.waits Number of redo log waits. rollbackSegments.gets Number of rollback segments gets. rollbackSegments.ratioWait Ratio of waits for rollback segments. rollbackSegments.waits Number of rollback segments waits. sga.bufferBusyWaits Number of SGA buffer busy waits. sga.fixedSizeInBytes SGA fixed size. sga.freeBufferWaits Number of SGA free buffer waits. sga.freeBufferInspected Number of SGA free buffer inspected. sga.hitRatio Hit ratio for the SGA. sga.logBufferAllocationRetriesRatio Retry ratio of allocations for the SGA log buffer. sga.logBufferRedoAllocationRetries Redo allocation ratio for the SGA log buffer. sga.logBufferRedoEntries Number of Redo entries in the SGA log buffer. sga.logBufferSpaceWaits Buffer space waits for the SGA log buffer. sga.redoBuffersInBytes SGA Redo buffers, in bytes. sga.sharedPoolDictCacheMissRatio Miss ratio for the SGA shared pool dictionary (dict) cache. sga.sharedPoolLibraryCacheHitRatio Hit ratio for the SGA shared pool library cache. sga.sharedPoolLibraryCacheReloadRatio Reload ratio for the SGA shared pool library cache. sga.sharedPoolLibraryCacheShareableMemoryPerStatementInBytes SGA cacheable memory per statement, in bytes. sga.sharedPoolLibraryCacheShareableMemoryPerUserInBytes SGA cacheable memory per user, in bytes. sga.ugaTotalMemoryInBytes Total memory in the User Global Area (UGA). sorts.diskInBytes Sorts disk usage, in bytes. sorts.memoryInBytes Sorts memory usage, in bytes. Tablespace metrics The Oracle Database integration collects the following tablespace metrics. These attributes can be found by querying the OracleTablespaceSample event type. Metric Description tablespace.isOffline Boolean for tablespace offline status. Extended: yes. tablespace.offlinePDBDatafiles The number of PDB datafiles that are offline. tablespace.offlineCDBDatafiles The number of CDB datafiles that are offline. tablespace.pdbDatafilesNonWrite The number of PDB datafiles in a non-writable state. tablespace.spaceConsumedInBytes Consumed amount of tablespace in bytes. tablespace.spaceReservedInBytes Total reserved tablespace in bytes. tablespace.spaceUsedPercentage Ratio of used to total tablespace. Extended: yes. Inventory data The Oracle Database integration captures the configuration parameters of the Oracle database. The data is available on the Inventory page, under the config/oracledb source. For more about inventory data, see Understand integration data. The integration captures data for the following Oracle Database configuration parameters: Parameters Metric Description DBFIPS_140 Enable use of crypographic libraries in FIPS mode, public. O7_DICTIONARY_ACCESSIBILITY Version 7 dictionary accessibility support. active_instance_count Number of active instances in the cluster database. adg_account_info_tracking ADG user account info tracked in standby (LOCAL) or in primary (GLOBAL). allow_global_dblinks LDAP lookup for DBLINKS. allow_group_access_to_sga Allow read access for SGA to users of Oracle owner group. approx_for_aggregation Replace exact_aggregation with approximate_aggregation. approx_for_count_distinct Replace count_distinct with approx_count_distinct. approx_for_percentile Replace percentile_* with approx_percentile. aq_tm_processes Number of AQ time managers to start. archive_lag_target Maximum number of seconds of redos the standby could lose. asm_diskstring Disk set locations for discovery. asm_preferred_read_failure_groups Preferred read failure groups. audit_file_dest Directory in which auditing files are to reside. audit_sys_operations Enable sys auditing. audit_syslog_level Syslog facility and level. audit_trail Enable system auditing. autotask_max_active_pdbs Setting for autotask maximum maintenance PDBs. awr_pdb_autoflush_enabled Enable/Disable AWR automatic PDB flushing. awr_pdb_max_parallel_slaves Maximum concurrent AWR PDB MMON slaves per instance. awr_snapshot_time_offset Setting for AWR snapshot time offset. background_core_dump Core size for background processes. background_dump_dest Detached process dump directory. backup_tape_io_slaves Backup tape I/O slaves. bitmap_merge_area_size Maximum memory allow for bitmap merge. blank_trimming Blank trimming semantics parameter. buffer_pool_keep Number of database blocks/latches in keep buffer pool. buffer_pool_recycle Number of database blocks/latches in recycle buffer pool. cdb_cluster If TRUE startup in CDB cluster mode. cdb_cluster_name CDB cluster name. cell_offload_compaction Cell packet compaction strategy. cell_offload_decryption Enable SQL processing offload of encrypted data to cells. cell_offload_parameters Additional cell offload parameters. cell_offload_plan_display Cell offload explain plan display. cell_offload_processing Enable SQL processing offload to cells. cell_offloadgroup_name Set the offload group name. circuits Max number of circuits. client_result_cache_lag Client result cache maximum lag in milliseconds. client_result_cache_size Client result cache max size in bytes. clonedb Clone database. clonedb_dir CloneDB Directory. cluster_database If TRUE startup in cluster database mode. cluster_database_instances Number of instances to use for sizing cluster DB SGA structures. cluster_interconnects Interconnects for RAC use. commit_logging Transaction commit log write behaviour. commit_point_strength Bias this node has toward not preparing in a two-phase commit. commit_wait Transaction commit log wait behaviour. commit_write Transaction commit log write behaviour. common_user_prefix Enforce restriction on a prefix of a common user, role, or profile . compatible Database will be completely compatible with this software version. connection_brokers Connection brokers specification. containers_parallel_degree Parallel degree for a CONTAINERS() query. control_file_record_keep_time Control file record keep time in days. control_files Control file names list. control_management_pack_access Declares which manageability packs are enabled. core_dump_dest Core dump directory. cpu_count Number of CPUs for this instance. create_bitmap_area_size Size of create bitmap buffer for bitmap index. create_stored_outlines Create stored outlines for DML statements. cursor_bind_capture_destination Allowed destination for captured bind variables. cursor_invalidation Default for DDL cursor invalidation semantics. cursor_sharing Cursor sharing mode. cursor_space_for_time Use more memory in order to get faster execution. data_guard_sync_latency Data guard sync latency. data_transfer_cache_size Size of data transfer cache. db_16k_cache_size Size of cache for 16K buffers. db_2k_cache_size Size of cache for 2K buffers. db_32k_cache_size Size of cache for 32K buffers. db_4k_cache_size Size of cache for 4K buffers. db_8k_cache_size Size of cache for 8K buffers. db_big_table_cache_percent_target Big table cache target size in percentage. db_block_buffers Number of database blocks cached in memory. db_block_checking Header checking and data and index block checking. db_block_checksum Store checksum in DB blocks and check during reads. db_block_size Size of database block in bytes. db_cache_advice Buffer cache sizing advisory. db_cache_size Size of default buffer pool for standard block size buffers. db_create_file_dest Default database location. db_create_online_log_dest_1 Online log/controlfile destination #1. db_create_online_log_dest_2 Online log/controlfile destination #2. db_create_online_log_dest_3 Online log/controlfile destination #3. db_create_online_log_dest_4 Online log/controlfile destination #4. db_create_online_log_dest_5 Online log/controlfile destination #5. db_domain Directory part of global database name stored with CREATE DATABASE. db_file_multiblock_read_count DB block to be read each I/O. db_file_name_convert Datafile name convert patterns and strings for standby/clone db. db_files Max allowable number of db files. db_flash_cache_file Flash cache file for default block size. db_flash_cache_size Flash cache size for db_flash_cache_file. db_flashback_retention_target Maximum flashback database log retention time in minutes.. db_index_compression_inheritance Options for table or tablespace level compression inheritance. db_keep_cache_size Size of KEEP buffer pool for standard block size buffers. db_lost_write_protect Enable lost write detection. db_name Database name specified in CREATE DATABASE. db_performance_profile Database performance category. db_recovery_file_dest Default database recovery file location. db_recovery_file_dest_size Database recovery files size limit. db_recycle_cache_size Size of RECYCLE buffer pool for standard block size buffers. db_securefile Permit securefile storage during lob creation. db_ultra_safe Sets defaults for other parameters that control protection levels. db_unique_name Database unique name. db_unrecoverable_scn_tracking Track nologging SCN in controlfile. db_writer_processes Number of background database writer processes to start. dbwr_io_slaves DBWR I/O slaves. ddl_lock_timeout Timeout to restrict the time that DDLS wait for DML lock. default_sharing Default sharing clause. deferred_segment_creation Defer segment creation to first insert. dg_broker_config_file1 Data guard broker configuration file #1. dg_broker_config_file2 Data guard broker configuration file #2. dg_broker_start Start data guard broker (DMON process). diagnostic_dest Diagnostic base directory. disable_pdb_feature Disable features. disk_asynch_io Use asynch I/O for random access devices. dispatchers Specifications of dispatchers. distributed_lock_timeout Number of seconds a distributed transaction waits for a lock. dml_locks DML locks - one for each table modified in a transaction. dnfs_batch_size Max number of dNFS asynch I/O requests queued per session. dst_upgrade_insert_conv Enables/Disables internal conversions during DST upgrade. enable_automatic_maintenance_pdb Enable/Disable automated maintenance for non-root PDB. enable_ddl_logging Enable ddl logging. enable_dnfs_dispatcher Enable DNFS dispatcher. enable_goldengate_replication Goldengate replication enabled. enable_pluggable_database Enable pluggable database. enabled_PDBs_on_standby List of enabled PDB patterns. encrypt_new_tablespaces Whether to encrypt newly created tablespaces. event Debug event control - default null string. exafusion_enabled Enable exafusion. external_keystore_credential_location External keystore credential location. fal_client FAL client. fal_server FAL server list. fast_start_io_target Upper bound on recovery reads. fast_start_mttr_target MTTR target in seconds. fast_start_parallel_rollback Max number of parallel recovery slaves that may be used. file_mapping Enable file mapping. fileio_network_adapters Network adapters for File I/O. filesystemio_options IO operations on filesystem files. fixed_date Fixed SYSDATE value. forward_listener Forward listener. gcs_server_processes Number of background gcs server processes to start. global_names Enforce that database links have same name as remote database. global_txn_processes Number of background global transaction processes to start. hash_area_size Size of in-memory hash work area. heat_map ILM Heatmap Tracking. hi_shared_memory_address SGA starting address (high order 32-bits on 64-bit platforms). hs_autoregister Enable automatic server DD updates in HS agent self-registration. ifile Include file in init.Ora. inmemory_adg_enabled Enable IMC support on ADG. inmemory_automatic_level Enable Automatic In-Memory management. inmemory_clause_default Default in-memory clause for new tables. inmemory_expressions_usage Controls which In-Memory Expressions are populated in-memory. inmemory_force Force tables to be in-memory or not. inmemory_max_populate_servers Maximum inmemory populate servers. inmemory_optimized_arithmetic Controls whether or not DSBs are stored in-memory. inmemory_prefer_xmem_memcompress Prefer to store tables with given memcompress levels in xmem. inmemory_prefer_xmem_priority Prefer to store tables with given priority levels in xmem. inmemory_query Specifies whether in-memory queries are allowed. inmemory_size Size in bytes of in-memory area. inmemory_trickle_repopulate_servers_percent Inmemory trickle repopulate servers percent. inmemory_virtual_columns Controls which user-defined virtual columns are stored in-memory. inmemory_xmem_size Size in bytes of in-memory xmem area. instance_abort_delay_time Time to delay an internal initiated abort (in seconds). instance_groups List of instance group names. instance_mode Indicates whether the instance read-only or read-write or read-mostly. instance_name Instance name supported by the instance. instance_number Instance number. instance_type Type of instance to be executed. instant_restore Instant repopulation of datafiles. java_jit_enabled Java VM JIT enabled. java_max_sessionspace_size Max allowed size in bytes of a Java sessionspace. java_pool_size Size in bytes of java pool. java_restrict Restrict Java VM Access. java_soft_sessionspace_limit Warning limit on size in bytes of a Java sessionspace. job_queue_processes Maximum number of job queue slave processes. large_pool_size Size in bytes of large pool. ldap_directory_access RDBMS's LDAP access option. ldap_directory_sysauth OID usage parameter. license_max_sessions Maximum number of non-system user sessions allowed. license_max_users Maximum number of named users that can be created in the database. license_sessions_warning Warning level for number of non-system user sessions. listener_networks Listener registration networks. local_listener Local listener. lock_name_space Lock name space used for generating lock names for standby/clone database. lock_sga Lock entire SGA in physical memory. log_archive_config Log archive config. log_archive_dest Archival destination text string. log_archive_dest_1 Archival destination #1 text string. log_archive_dest_10 Archival destination #10 text string. log_archive_dest_11 Archival destination #11 text string. log_archive_dest_12 Archival destination #12 text string. log_archive_dest_13 Archival destination #13 text string. log_archive_dest_14 Archival destination #14 text string. log_archive_dest_15 Archival destination #15 text string. log_archive_dest_16 Archival destination #16 text string. log_archive_dest_17 Archival destination #17 text string. log_archive_dest_18 Archival destination #18 text string. log_archive_dest_19 Archival destination #19 text string. log_archive_dest_2 Archival destination #2 text string. log_archive_dest_20 Archival destination #20 text string. log_archive_dest_21 Archival destination #21 text string. log_archive_dest_22 Archival destination #22 text string. log_archive_dest_23 Archival destination #23 text string. log_archive_dest_24 Archival destination #24 text string. log_archive_dest_25 Archival destination #25 text string. log_archive_dest_26 Archival destination #26 text string. log_archive_dest_27 Archival destination #27 text string. log_archive_dest_28 Archival destination #28 text string. log_archive_dest_29 Archival destination #29 text string. log_archive_dest_3 Archival destination #3 text string. log_archive_dest_30 Archival destination #30 text string. log_archive_dest_31 Archival destination #31 text string. log_archive_dest_4 Archival destination #4 text string. log_archive_dest_5 Archival destination #5 text string. log_archive_dest_6 Archival destination #6 text string. log_archive_dest_7 Archival destination #7 text string. log_archive_dest_8 Archival destination #8 text string. log_archive_dest_9 Archival destination #9 text string. log_archive_dest_state_1 Archival destination #1 state text string. log_archive_dest_state_10 Archival destination #10 state text string. log_archive_dest_state_11 Archival destination #11 state text string. log_archive_dest_state_12 Archival destination #12 state text string. log_archive_dest_state_13 Archival destination #13 state text string. log_archive_dest_state_14 Archival destination #14 state text string. log_archive_dest_state_15 Archival destination #15 state text string. log_archive_dest_state_16 Archival destination #16 state text string. log_archive_dest_state_17 Archival destination #17 state text string. log_archive_dest_state_18 Archival destination #18 state text string. log_archive_dest_state_19 Archival destination #19 state text string. log_archive_dest_state_2 Archival destination #2 state text string. log_archive_dest_state_20 Archival destination #20 state text string. log_archive_dest_state_21 Archival destination #21 state text string. log_archive_dest_state_22 Archival destination #22 state text string. log_archive_dest_state_23 Archival destination #23 state text string. log_archive_dest_state_24 Archival destination #24 state text string. log_archive_dest_state_25 Archival destination #25 state text string. log_archive_dest_state_26 Archival destination #26 state text string. log_archive_dest_state_27 Archival destination #27 state text string. log_archive_dest_state_28 Archival destination #28 state text string. log_archive_dest_state_29 Archival destination #29 state text string. log_archive_dest_state_3 Archival destination #3 state text string. log_archive_dest_state_30 Archival destination #30 state text string. log_archive_dest_state_31 Archival destination #31 state text string. log_archive_dest_state_4 Archival destination #4 state text string. log_archive_dest_state_5 Archival destination #5 state text string. log_archive_dest_state_6 Archival destination #6 state text string. log_archive_dest_state_7 Archival destination #7 state text string. log_archive_dest_state_8 Archival destination #8 state text string. log_archive_dest_state_9 Archival destination #9 state text string. log_archive_duplex_dest duplex Archival destination text string. log_archive_format Archival destination format. log_archive_max_processes Maximum number of active ARCH processes. log_archive_min_succeed_dest Minimum number of archive destinations that must succeed. log_archive_start Start archival process on SGA initialization. log_archive_trace Establish archive operation tracing level. log_buffer Redo circular buffer size. log_checkpoint_interval Number of redo blocks checkpoint threshold. log_checkpoint_timeout Maximum time interval between checkpoints in seconds. log_checkpoints_to_alert Log checkpoint begin/end to alert file. log_file_name_convert Logfile name convert patterns and strings for standby/clone db. long_module_action Use longer module and action. max_datapump_jobs_per_pdb Maximum number of concurrent data pump jobs per PDB. max_dispatchers Max number of dispatchers. max_dump_file_size Maximum size (in bytes) of dump file. max_idle_time Maximum session idle time in minutes. max_iops MAX I/O per second. max_mbps MAX MB per second. max_pdbs Max number of pdbs allowed in CDB or Application ROOT. max_shared_servers Max number of shared servers. max_string_size Controls maximum size of VARCHAR2, NVARCHAR2, and RAW types in SQL. memoptimize_pool_size Size of cache for imoltp buffers. memory_max_target Max size for Memory Target. memory_target Target size of Oracle SGA and PGA memory. multishard_query_data_consistency Consistency setting for multishard queries. multishard_query_partial_results Enable partial results for multishard queries. nls_calendar NLS calendar system name. nls_comp NLS comparison. nls_currency NLS local currency symbol. nls_date_format NLS Oracle date format. nls_date_language NLS date language name. nls_dual_currency Dual currency symbol. nls_iso_currency NLS ISO currency territory name. nls_language NLS language name. nls_length_semantics Create columns using byte or char semantics by default. nls_nchar_conv_excp NLS raise an exception instead of allowing implicit conversion. nls_numeric_characters NLS numeric characters. nls_sort NLS linguistic definition name. nls_territory NLS territory name. nls_time_format Time format. nls_time_tz_format Time with timezone format. nls_timestamp_format Time stamp format. nls_timestamp_tz_format Timestamp with timezone format. noncdb_compatible Non-CDB Compatible. object_cache_max_size_percent Percentage of maximum size over optimal of the user session's object cache. object_cache_optimal_size Optimal size of the user session's object cache in bytes. ofs_threads Number of OFS threads. olap_page_pool_size Size of the olap page pool in bytes. one_step_plugin_for_pdb_with_tde Facilitate one-step plugin for PDB with TDE encrypted data. open_cursors Max number of cursors per session. open_links Max number of open links per session. open_links_per_instance Max number of open links per instance. optimizer_adaptive_plans Controls all types of adaptive plans. optimizer_adaptive_reporting_only Use reporting-only mode for adaptive optimizations. optimizer_adaptive_statistics Controls all types of adaptive statistics. optimizer_capture_sql_plan_baselines Automatic capture of SQL plan baselines for repeatable statements. optimizer_dynamic_sampling Optimizer dynamic sampling. optimizer_features_enable Optimizer plan compatibility parameter. optimizer_ignore_hints Enables the embedded hints to be ignored. optimizer_ignore_parallel_hints Enables embedded parallel hints to be ignored. optimizer_index_caching Optimizer percent index caching. optimizer_index_cost_adj Optimizer index cost adjustment. optimizer_inmemory_aware Optimizer in-memory columnar awareness. optimizer_mode Optimizer mode. optimizer_secure_view_merging Optimizer secure view merging and predicate pushdown/movearound. optimizer_use_invisible_indexes Usage of invisible indexes (TRUE or FALSE). optimizer_use_pending_statistics Control whether to use optimizer pending statistics. optimizer_use_sql_plan_baselines Use of SQL plan baselines for captured sql statements. os_authent_prefix Prefix for auto-logon accounts. os_roles Retrieve roles from the operating system. outbound_dblink_protocols Outbound DBLINK Protocols allowed. parallel_adaptive_multi_user Enable adaptive setting of degree for multiple user streams. parallel_degree_limit Limit placed on degree of parallelism. parallel_degree_policy Policy used to compute the degree of parallelism (MANUAL, LIMITED, AUTO, or ADAPTIVE). parallel_execution_message_size Message buffer size for parallel execution. parallel_force_local Force single instance execution. parallel_instance_group Instance group to use for all parallel operations. parallel_max_servers Maximum parallel query servers per instance. parallel_min_degree Controls the minimum DOP computed by auto DOP. parallel_min_percent Minimum percent of threads required for parallel query. parallel_min_servers Minimum parallel query servers per instance. parallel_min_time_threshold Threshold above which a plan is a candidate for parallelization (in seconds). parallel_servers_target Instance target in terms of number of parallel servers. parallel_threads_per_cpu Number of parallel execution threads per CPU. pdb_file_name_convert PDB file name convert patterns and strings for create cdb/pdb. pdb_lockdown Pluggable database lockdown profile. pdb_os_credential Pluggable database OS credential to bind. pdb_template PDB template. permit_92_wrap_format Allow 9.2 or older wrap format in PL/SQL. pga_aggregate_limit Limit of aggregate PGA memory for the instance or PDB. pga_aggregate_target Target size for the aggregate PGA memory consumed by the instance. plscope_settings Plscope_settings controls the compile time collection, cross reference, and storage of PL/SQL source code identifier and SQL statement data. plsql_ccflags PL/SQL ccflags. plsql_code_type PL/SQL code-type. plsql_debug PL/SQL debug. plsql_optimize_level PL/SQL optimize level. plsql_v2_compatibility PL/SQL version 2.X compatibility flag. plsql_warnings PL/SQL compiler warnings settings. pre_page_sga Pre-page sga for process. private_temp_table_prefix Private temporary table prefix. processes User processes. processor_group_name Name of the processor group that this instance should run in. query_rewrite_enabled Allow rewrite of queries using materialized views if enabled. query_rewrite_integrity Perform rewrite using materialized views with desired integrity. rdbms_server_dn RDBMS's distinguished name. read_only_open_delayed If TRUE delay opening of read only files until first access. recovery_parallelism Number of server processes to use for parallel recovery. recyclebin Recyclebin processing. redo_transport_user Data guard transport user when using password file. remote_dependencies_mode Remote-procedure-call dependencies mode parameter. remote_listener Remote listener. remote_login_passwordfile Password file usage parameter. remote_os_authent Allow non-secure remote clients to use auto-logon accounts. remote_os_roles Allow non-secure remote clients to use os roles. remote_recovery_file_dest Default remote database recovery file location for refresh/relocate. replication_dependency_tracking Tracking dependency for replication parallel propagation. resource_limit Master switch for resource limit. resource_manage_goldengate Goldengate resource manager enabled. resource_manager_cpu_allocation Resource Manager CPU allocation. resource_manager_plan Resource mgr top plan. result_cache_max_result Maximum result size as percent of cache size. result_cache_max_size Maximum amount of memory to be used by the cache. result_cache_mode Result cache operator usage mode. result_cache_remote_expiration Maximum life time (min) for any result using a remote object. resumable_timeout Set resumable timeout. rollback_segments Undo segment list. sec_case_sensitive_logon Case sensitive password enabled for logon. sec_max_failed_login_attempts Maximum number of failed login attempts on a connection. sec_protocol_error_further_action TTC protocol error continue action. sec_protocol_error_trace_action TTC protocol error action. sec_return_server_release_banner Whether the server returns the complete version information. serial_reuse Reuse the frame segments. service_names Service names supported by the instance. session_cached_cursors Number of cursors to cache in a session. session_max_open_files Maximum number of open files allowed per session. sessions User and system sessions. sga_max_size Max total SGA size. sga_min_size Minimum, guaranteed size of PDB's SGA. sga_target Target size of SGA. shadow_core_dump Core size for shadow processes. shared_memory_address SGA starting address (low order 32-bits on 64-bit platforms). shared_pool_reserved_size Size in bytes of reserved area of shared pool. shared_pool_size Size in bytes of shared pool. shared_server_sessions Max number of shared server sessions. shared_servers Number of shared servers to start up. shrd_dupl_table_refresh_rate Duplicated table refresh rate (in seconds). skip_unusable_indexes Skip unusable indexes if set to TRUE. smtp_out_server Utl_smtp server and port configuration parameter. sort_area_retained_size Size of in-memory sort work area retained between fetch calls. sort_area_size Size of in-memory sort work area. spatial_vector_acceleration Enable spatial vector acceleration. spfile Server parameter file. sql92_security Require select privilege for searched update/delete. sql_trace Enable SQL trace. sqltune_category Category qualifier for applying hintsets. standby_db_preserve_states Preserve state cross standby role transition. standby_file_management If auto, files are created/dropped automatically on standby. standby_pdb_source_file_dblink Database link to standby source files. standby_pdb_source_file_directory Standby source file directory location. star_transformation_enabled Enable the use of star transformation. statistics_level Statistics level. streams_pool_size Size in bytes of the streams pool. tape_asynch_io Use asynch I/O requests for tape devices. target_pdbs Parameter is a hint to adjust certain attributes of the CDB. tde_configuration Per-PDB configuration for transparent tata encryption. temp_undo_enabled Is temporary undo enabled. thread Redo thread to mount. threaded_execution Threaded Execution Mode. timed_os_statistics Internal os statistic gathering interval in seconds. timed_statistics Maintain internal timing statistics. trace_enabled Enable in memory tracing. tracefile_identifier Trace file custom identifier. transactions Max. Number of concurrent active transactions. transactions_per_rollback_segment Number of active transactions per rollback segment. undo_management Instance runs in SMU mode if TRUE, else in RBU mode. undo_retention Undo retention in seconds. undo_tablespace Use/switch undo tablespace. unified_audit_sga_queue_size Size of unified audit SGA queue. unified_audit_systemlog Syslog facility and level for unified audit. uniform_log_timestamp_format Use uniform timestamp formats vs pre-12.2 formats. use_dedicated_broker Use dedicated connection broker. use_large_pages Use large pages if available (TRUE, FALSE, or ONLY). user_dump_dest User process dump directory. version Oracle Database version. xwallet_root Wallet root instance initialization parameter. workarea_size_policy Policy used to size SQL working areas (MANUAL``AUTO). Troubleshooting Troubleshooting tips: The Oracle library cannot be loaded If monitoring remotely, install the Oracle Instant Client and follow the instructions on how to add libclntsh.so to the shared library search path. If monitoring from the box with Oracle Database installed, install the Oracle Instant Client and add the path ORACLE_HOME/lib to the ldconfig search path. ORACLE_HOME is not set correctly This error will appear in the logs as [ERR] ORA-01284: Error while trying to retrieve text for error. To avoid this error make sure ORACLE_HOME is set correctly for the agent process. The agent runs as root, so its environment is not the same as the oracle user. To verify this setting, execute cat /proc/$(pgrep newrelic-infra)/environ to print out the environment variables for the infrastructure process, the output should include ORACLE_HOME if configured correctly. I get an ORA error To resolve errors of the type ORA, refer to Oracle's error list. Check the source code This integration is open source software. That means you can browse its source code and send improvements, or create your own fork and build it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 132.89796,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Find</em> and use data",
        "body": " one-step plugin for PDB with TDE encrypted data. open_cursors Max number of cursors per session. open_links Max number of open links per session. open_links_per_<em>instance</em> Max number of open links per <em>instance</em>. <em>optimizer</em>_adaptive_plans Controls all types of adaptive plans"
      },
      "id": "6044571428ccbc04a23101f8"
    }
  ],
  "/docs/correlate-load-balancer-application-metrics-workloads": [
    {
      "sections": [
        "Configure polling frequency and data collection for cloud integrations",
        "Tip",
        "Overview of settings",
        "Caution",
        "Change polling frequency",
        "Specify data to be fetched",
        "Data collection",
        "Filters",
        "Potential impact on alerts and charts"
      ],
      "title": "Configure polling frequency and data collection for cloud integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Infrastructure integrations",
        "Cloud integrations"
      ],
      "external_id": "b900b7545f9032201c212449be114e10176bf789",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/infrastructure-integrations/cloud-integrations/configure-polling-frequency-data-collection-cloud-integrations/",
      "published_at": "2021-06-15T13:00:43Z",
      "updated_at": "2021-06-15T13:00:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our cloud integrations get data from cloud provider APIs. In New Relic, you can change some of the data collection-related settings for your cloud integrations. Read on to see what changes you can make and the reasons for making them. Tip To use integrations and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Overview of settings New Relic cloud integrations get data from cloud providers' APIs. Data is generally collected from monitoring APIs such as AWS CloudWatch, Azure Monitor, and GCP Stackdriver, and inventory metadata is collected from the specific services' APIs. You can use the account status dashboard to see how your cloud integrations are handling data from a cloud service provider. If you want to report more or less data from your cloud integrations, or if you need to control the use of the cloud providers' APIs to prevent reaching rate and throttling limits in your cloud account, you can change the configuration settings to modify the amount of data they report. The two main controls are: Change polling frequency Change what data is reported Examples of business reasons for wanting to change your polling frequency include: Billing: If you need to manage your AWS CloudWatch bill, you may want to decrease the polling frequency. Before you do this, make sure that any alert conditions set for your cloud integrations are not affected by this reduction. New services: If you are deploying a new service or configuration and you want to collect data more often, you may want to increase the polling frequency temporarily. Caution Changing the configuration settings for your integrations may impact alert conditions and chart trends. Change polling frequency The polling frequency configuration determines how often New Relic reports data from your cloud provider for each service. By default, the polling frequency is set to the maximum frequency that is available for each service. To change the polling frequency for a cloud integration: Go to one.newrelic.com > Infrastructure. Select the tab that corresponds to your cloud service provider. Select Configure next to the integration. Use the dropdowns next to Data polling interval every to select how frequently you want New Relic to capture your cloud integration data. Specify data to be fetched You can specify which information you want captured for your cloud integration by enabling the collection of additional data and by applying multiple filters to each integration. To change this settings for your cloud integration: Go to one.newrelic.com > Infrastructure. Select the tab that corresponds to your cloud service provider. Select Configure next to the integration. Under Data collections and filters, turn the toggles you want On. For filters, select or enter the values that you want included in your reported data. Data collection For some cloud integrations, an additional number of calls to the cloud provider APIs are needed in order to collect data. For example, to fetch tags for AWS Elastic Map Reduce clusters, an additional call to the service API is required. To better control the amount of API calls that are sent to your cloud account for these integrations, you can specify when you need these types of data to be collected. Different data collection toggles are available, depending on the integration. Toggle Description Collect tags Some integrations require additional API calls to the cloud provider to report tags. Tag collection is enabled by default. Switch this to Off if you don't want the integration to collect your cloud resource tags and thus reduce the volume of API calls. Collect extended inventory Some integrations can collect extended inventory metadata about your cloud resources by making additional API calls to the cloud provider. The metadata included within the extended inventory for each cloud integration is described in the integration documentation. Extended inventory collection is disabled by default. Switch this to On if you want to monitor extended inventory. This will increase the volume of API calls. Collect shards data Available for AWS Kinesis Streams integration. By default, we don't report shard metrics. Switch this to On if you want to monitor shard metrics in addition to data stream metrics. Collect Lambda@Edge data Available for AWS CloudFront integration. By default, we don't report Lambda@Edge data. Switch this to On if you're using Lambda@Edge in AWS CloudFront and want to get Lambda execution location metadata. Collect node data Available for AWS Elasticsearch integration. By default, we don't report Elasticsearch node metrics. Switch this to On if you want to monitor node metrics in addition to cluster metrics. Collect NAT Gateway data and Collect VPN data Available for AWS VPC integration. By default, we don't report NAT Gateway nor VPN metrics. Switch these to On if you want to monitor NAT Gateway and VPN metrics and inventory, in addition to other VPC related entities inventory. Collect IP addresses Available for AWS EC2 integration. By default, we collect EC2 instance metadata that includes public and private IP addresses, and network interface details. Switch this to Off if you don't want New Relic to store and display these IP data. Filters When a filter is On, you specify the data that you want to be collected; for example, if the Limit to AWS region is On, the regions that you select will be the ones that data will be collected for. There are different filters available, depending on the integration: Filter Description Region Select the regions that include the resources that you want to monitor. Queue prefixes Available for AWS SQS integration. Enter each name or prefix for the queues that you want to monitor. Filter values are case-sensitive. Load balancer prefixes Available for AWS ALB integration. Enter each name or prefix for the application load balancers that you want to monitor. Filter values are case-sensitive. Stage name prefixes Available for AWS API Gateway integration. Enter each name or prefix for the stages that you want to monitor. Filter values are case-sensitive. Tag key Enter one tag key that is associated with the resources that you want to monitor. Filter values are case-sensitive, and you can use this filter in combination with tag value filter. Tag value Enter one tag value that is associated with the resources that you want to monitor. Filter values are case-sensitive, and you can use this filter in combination with tag key. Resource group Select the resource groups that are associated with the resources that you want to monitor. Potential impact on alerts and charts If you change an integration's configuration, it can impact alert conditions and charts. Here are some things to consider: If you change this setting... It may have this impact... Any configuration setting When you change the configuration settings, the data that New Relic displays in infrastructure charts, on the inventory page, and in the events feed changes as well. Any filters When you create alert conditions after you set filters, make sure that your alerts are not triggered by resources that you filtered out. Filter for regions If you filter for specific regions, it may lower the amount of data reported to New Relic, which could trigger an alert. If you create an alert condition for a specific region and then filter that region out, the region would no longer report data and would never trigger the alert. Polling frequency When you create an alert, make sure that you define the threshold for a time period that is longer than the polling frequency. Tags and extended inventory If you turn on tags and/or extended inventory, New Relic makes more API calls to the cloud provider, which could increase your cloud provider API usage bill.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 127.66095,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure polling frequency <em>and</em> data collection for cloud integrations",
        "sections": "Configure polling frequency <em>and</em> data collection for cloud integrations",
        "body": " the resources that you want to monitor. Queue prefixes Available for AWS SQS integration. Enter each name or prefix for the queues that you want to monitor. Filter values are case-sensitive. <em>Load</em> <em>balancer</em> prefixes Available for AWS ALB integration. Enter each name or prefix for the <em>application</em> <em>load</em>"
      },
      "id": "603e8eef64441fcc7e4e8853"
    },
    {
      "image": "https://docs.newrelic.com/static/775fe6d355fc6f5fd1793f286aa52c54/ae694/Dashboard.png",
      "url": "https://docs.newrelic.com/whats-new/2021/03/aws-cloudwatch/",
      "sections": [
        "Amazon CloudWatch Metric Streams",
        "More metrics, more often - fill gaps in your observability with Amazon CloudWatch Metric Streams and New Relic One"
      ],
      "published_at": "2021-06-15T04:15:20Z",
      "title": "Amazon CloudWatch Metric Streams",
      "updated_at": "2021-04-04T20:34:06Z",
      "type": "docs",
      "external_id": "004ba80238187bccbaa649145cc6dd58d7a90a42",
      "document_type": "nr1_announcement",
      "popularity": 1,
      "body": "More metrics, more often - fill gaps in your observability with Amazon CloudWatch Metric Streams and New Relic One More metrics more often means that you’ll receive Amazon CloudWatch data from all the AWS services you use as soon as they are available. Keep your applications running in the AWS Cloud humming. Less delay equals faster decisions. Correlate, analyze, visualize, and alert on the Amazon CloudWatch metrics for all of the AWS services your AWS cloud-based applications use. Two integration modes are available when you create a new AWS integration. Once you’ve completed setup, you can bring the data from AWS into dashboards right alongside the other New Relic One data available to you. The example below shows metrics from New Relic One’s Synthetic and Infrastructure Monitoring right next to the AWS Application Load Balancer and RDS database Metric Streams data. The Metric Streams data is stored in New Relic One’s Telemetry Data Platform as dimensional metrics of the summary type and can be queried using NRQL and used in Navigator and Lookout. This is the Navigator view grouped by AWS namespaces. Below is the Amazon CloudWatch Metric Streams status dashboard from Infrastructure -> AWS -> Account status dashboard Check out this short video walking through Amazon CloudWatch Metric Streams benefits. To get started: Navigate to Infrastructure Click AWS to set up your AWS integration today",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 127.101494,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Amazon CloudWatch <em>Metric</em> Streams",
        "sections": "More <em>metrics</em>, more often - fill gaps in your observability <em>with</em> Amazon CloudWatch <em>Metric</em> Streams <em>and</em> New Relic One",
        "body": " bring the data from AWS into dashboards right alongside the other New Relic One data available to you. The example below shows <em>metrics</em> from New Relic One’s Synthetic and Infrastructure Monitoring right next to the AWS <em>Application</em> <em>Load</em> <em>Balancer</em> and RDS database <em>Metric</em> Streams data. The <em>Metric</em> Streams"
      },
      "id": "606a22be196a6752ec47e824"
    },
    {
      "sections": [
        "AWS ELB (Classic) monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Child inventory data",
        "Tip"
      ],
      "title": "AWS ELB (Classic) monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "a2b3ad999c8ed420e698e813618feb7ca30ec75d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elb-classic-monitoring-integration/",
      "published_at": "2021-06-15T10:08:59Z",
      "updated_at": "2021-03-11T10:45:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an Amazon Elastic Classic Load Balancing (ELB) integration for reporting Classic ELB data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features New Relic's integration for Amazon Elastic Classic Load Balancing (ELB) reports ELB data, including HTTP code message counts, healthy and unhealthy host counts, latency times, and ELB configuration states. AWS integration data is also available for querying and chart creation in New Relic One. Amazon offers three types of load balancers: Classic Load Balancer, Application Load Balancer (ALB), and Network Load Balancer (NLB). New Relic also offers an ALB/NLB integration to monitor the last two types of load balancers. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS ELB integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the ELB integration links. You can query and explore your data using the LoadBalancerSample event type, with a provider value of Elb. Metric data The integration collects the following metrics. For additional details about these metrics, see Amazon's ELB Classic Load Balancer metrics documentation. Name Description backendConnectionErrors.Sum Rate of the number of connections per second that were not successfully established between the load balancer and the registered instances. The load balancer retries the connection when there are errors, so this count may exceed the request rate. This count also includes any connection errors related to health checks. healthyHostCount unHealthyHostCount The number of healthy or unhealthy instances registered with your load balancer. A newly registered instance is considered healthy after it passes the first health check. If cross-zone load balancing is enabled, the number of healthy instances for the LoadBalancerName dimension is calculated across all availability zones. Otherwise, it is calculated per availability zone. httpCodeBackend2XX httpCodeBackend3XX httpCodeBackend4XX httpCodeBackend5XX [ HTTP listener] The number of HTTP response codes generated per second by registered instances. This count does not include any response codes generated by the load balancer. httpCodeElb4XX [ HTTP listener] The number of HTTP 4XX client error codes generated by the load balancer per minute. Client errors are generated when a request is malformed or incomplete. httpCodeElb5XX [ HTTP listener] The number of HTTP 5XX server error codes generated by the load balancer per minute. This count does not include any response codes generated by the registered instances. The metric is reported if there are no healthy instances registered to the load balancer, or if the request rate exceeds the capacity of the instances (spillover) or the load balancer. latency.Average latency.Maximum [ HTTP listener] The total time elapsed, in seconds, from the time the load balancer sent the request to a registered instance until the instance started to send the response headers. [ TCP listener] The total time elapsed, in seconds, for the load balancer to successfully establish a connection to a registered instance. Available statistics: aws.elb.latency.p90 aws.elb.latency.p95 aws.elb.latency.p99 requestCount The number of requests completed or connections made per second during the specified interval (1 or 5 minutes). spilloverCount The total number of requests that were rejected per second, due to the surge queue being full. surgeQueueLength.Average, Maximum, Minimum The total number of requests that are pending routing. The load balancer queues a request if it is unable to establish a connection with a healthy instance in order to route the request. The maximum size of the queue is 1,024. Additional requests are rejected when the queue is full. For more information, see SpilloverCount. estimatedAlbActiveConnectionCount.Average, Maximum, Minimum The estimated number of concurrent TCP connections active from clients to the load balancer and from the load balancer to targets. estimatedAlbConsumedLcus.Average, Maximum, Minimum The estimated number of load balancer capacity units (LCU) used by an application load balancer. estimatedAlbNewConnectionCount.Average, Maximum, Minimum The estimated number of new TCP connections established from clients to the load balancer and from the load balancer to targets. estimatedProcessedBytes.Average, Maximum, Minimum The estimated number of bytes processed by an application load balancer. Inventory data The following configuration options are available with the New Relic Amazon ELB integration. Name Description availabilityZone Lists one or more availability zones from the same region as the load balancer. awsRegion The AWS region that the load balancer runs in. canonicalHostedZoneNameId The ID of the Amazon Route 53 hosted zone name associated with the load balancer. canonicalHostedZoneName The name of the Amazon Route 53 hosted zone that is associated with the load balancer. If you specify internal for the Elastic Load Balancing scheme, use DNSNameinstead. For an internal scheme, the load balancer doesn't have a CanonicalHostedZoneName value. createdTime Timestamp with the date and time the load balancer was created. dnsName The public DNS name of the load balancer. instances A JSON string representing the list of IDs of EC2 instances associated with the load balancer. listeners A JSON string representing the list of Listeners associated with the load balancer. loadBalancerName The name of the load balancer. scheme For load balancers attached to an Amazon VPC, this parameter can be used to specify the type of load balancer to use. For more information, see the AWS ElasticLoadBalancing documentation about LoadBalancer properties. securityGroups A JSON string representing the list of security groups assigned to your load balancer within your virtual private cloud (VPC). sourceSecurityGroup The security group that you can use as part of your inbound rules for your load balancer's back-end Amazon EC2 application instances. subnets A JSON string representing the list of subnet IDs in your virtual private cloud (VPC) to attach to your load balancer. Do not specify multiple subnets that are in the same Availability Zone. You can specify the AvailabilityZones or Subnets property, but not both. vpcId The ID of the VPC that the load balancer has been configured in. Child inventory data Tip Data indicated with an asterisk * is only fetched if extended inventory collection is on. Name Description accessLog/enabled * A boolean. If true, access logs are enabled for this load balancer. connectionDraining/enabled * A boolean. Use connection draining to ensure that a Classic Load Balancer does not send requests to unhealthy instances. For more information, see the AWS documentation to configure connection draining for your Classic Load Balancer. connectionDraining/timeout * The number of seconds the load balancer waits before forcibly closing connections to the de-registering instance. Valid values are 1 to 3600. connectionSettings/idleTimeout * For more information, see the AWS documentation to configure the idle connection timeout for your Classic Load Balancer. crossZoneLoadBalancing/enabled * A boolean. For more information, see the AWS documentation to configure cross-zone load balancing for your Classic Load Balancer. healthCheck/healthyThreshold The number of consecutive successful health checks that must occur before declaring an EC2 instance healthy. Valid values: 2 to 10. healthCheck/interval The amount of time in seconds between health checks of an individual instance. Valid values: 5 to 300. healthCheck/target Combination of three properties: The protocol to use to connect with the instance. Valid values: TCP, HTTP, HTTPS, and SSL. The port to use to connect with the instance, as a protocol:port pair. If the load balancer fails to connect with the instance at the specified port within the configured response timeout period, the instance is considered unhealthy. The destination for the HTTP or HTTPS request. healthCheck/timeout The amount of time in seconds to wait when receiving a response from the health check. Valid values: 2 to 60. healthCheck/unhealthyThreshold The number of consecutive failed health checks that must occur before declaring an EC2 instance unhealthy. Valid values: 2 to 10. policies/otherPolicies JSON string representing security policies associated with this load balancer.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 119.23729,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Metric</em> data",
        "body": "&#x27;s data, go to one.newrelic.com &gt; Infrastructure &gt; AWS and select one of the ELB integration links. You can query and explore your data using the <em>LoadBalancer</em>Sample event type, with a provider value of Elb. <em>Metric</em> data The integration collects the following <em>metrics</em>. For additional details about"
      },
      "id": "6044aa46e7b9d218d85799d0"
    }
  ],
  "/docs/create-integrations/infrastructure-integrations-sdk/get-started/compatibility-requirements-infrastructure-integrations-sdk": [
    {
      "sections": [
        "Introduction to Infrastructure Integrations SDK",
        "Important",
        "What is the Integrations SDK?",
        "What data can you report with an on-host integration?",
        "Create a custom integration"
      ],
      "title": "Introduction to Infrastructure Integrations SDK",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Get started"
      ],
      "external_id": "0662f6c3fbc151a0c836b54c104e81756b34827f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/get-started/introduction-infrastructure-integrations-sdk/",
      "published_at": "2021-06-14T22:22:04Z",
      "updated_at": "2021-03-16T07:28:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are several ways New Relic lets you create your own integration: General telemetry (metrics, traces) solutions: Use our Telemetry SDKs. Build a custom New Relic One application that uses your own JavaScript UI functionality. If you have New Relic Infrastructure, you can use our lightweight Flex integration tool (recommended) or use our Integrations SDK to build a complete Infrastructure on-host integration. Important New Relic is transitioning to rely on open source standards like Prometheus for future on-host integrations. Though the infrastructure SDK is the foundation of that transition, some of the tutorials and tools around this SDK might not be up-to-date with the latest developments. What is the Integrations SDK? Our Infrastructure Integrations SDK lets you build an on-host integration that reports custom data from your hosts or services. That data can then be found in New Relic Infrastructure and can be used to create custom queries and charts. What data can you report with an on-host integration? When you build an integration using the Integrations SDK, you assign the entities that report data. In New Relic terms, entity is a purposefully ambiguous term meaning something that reports data to New Relic (for example: a local host, a load balancer, or a database). A single integration can report data from multiple entities, which gives you the ability to report data from more than one service or host instance. There are three types of data an entity can generate: Metrics: Metric data is used for numerical measurement data. Examples: how many requests are in a queue, or the number of hits on a database per minute. Metric data from a custom integration can be queried and used to create dashboards. Inventory: Live system state and configuration information. This data will show up on the Infrastructure Inventory UI page. Events: Events are used to record important activities on a system. Examples: a service starting or a new table being created. Event data will be shown in the Infrastructure Events UI page. Create a custom integration To create an integration using the Integrations SDK, use these resources: See the Go language build tools and tutorial. The tutorial walks you through creating a Redis integration in Go. (Note: Go is not required; it's just the language for which we provide additional build tools. For more information, see Integrations SDK requirements.) See the integration file structure documentation, which describes the files required to create an integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.69455,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "sections": "Introduction to <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": " Relic <em>Infrastructure</em> and can be used to <em>create</em> custom queries and charts. What data can you report with an on-host integration? When you build an integration using the <em>Integrations</em> <em>SDK</em>, you assign the entities that report data. In New Relic terms, entity is a purposefully ambiguous term meaning"
      },
      "id": "603eb55be7b9d2dcb72a07e8"
    },
    {
      "sections": [
        "Go language integration tutorial and build tools",
        "Integrations tutorial",
        "Important",
        "Tip",
        "Go language integration building package"
      ],
      "title": "Go language integration tutorial and build tools",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Get started"
      ],
      "external_id": "068b7f6bc27cf0a360699121c3cf8c46c9398d6a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/get-started/go-language-integration-tutorial-build-tools/",
      "published_at": "2021-06-14T22:20:16Z",
      "updated_at": "2021-03-13T01:25:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Infrastructure Integrations SDK lets you build a custom on-host integration. This document explains the build tools and resources available for building an on-host integration with our Go language tools. Integrations tutorial Important The following tutorial is based on integrations using the SDK integration protocol v3. Find more information about the integration protocol v4 in the Github repository. The Go language integration-building tutorial on GitHub gives step-by-step procedures for building a Go language integration that reports Redis data. The tutorial shows how to build an integration using the Linux command line, but you can use the same techniques for a Windows integration with a standard Go install and PowerShell. The make command will not work with PowerShell, but you can use the Go commands inside it as a guide for building your integration. Tip You can create an on-host integration in any language, but Go is the language New Relic uses for its own integrations and build tools. To create an integration in another language, adhere to the integration file structures and JSON output requirements. Go language integration building package The tutorial relies on a New Relic Go language integration-building library package, which provides a set of useful Go functions and data structures. The package gives you tools that: Generate a \"scaffold\" integration structure with all the required fields. Read values from command-line arguments or environment variables. Generate and print JSON data to stdout. For information about file formats and JSON output specifications, see File requirements.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.15936,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Go language <em>integration</em> tutorial and build tools",
        "sections": "<em>Integrations</em> tutorial",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "The New Relic <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em> lets you build a custom on-host integration. This document explains the build tools and resources available for building an on-host integration with our Go language tools. <em>Integrations</em> tutorial Important The following tutorial is based on <em>integrations</em>"
      },
      "id": "6044091d28ccbcc5b22c6097"
    },
    {
      "sections": [
        "Not seeing attributes data",
        "Problem",
        "Solution"
      ],
      "title": "Not seeing attributes data",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Troubleshooting"
      ],
      "external_id": "25a763fd32bebfa1cb33b77caf260df9a4d9fe53",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/troubleshooting/not-seeing-attributes/",
      "published_at": "2021-06-14T20:50:43Z",
      "updated_at": "2021-03-16T08:30:13Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Your integration is reporting data, but a few inventory attributes are missing. Solution The following inventory key names are used internally by our platform. If customer-provided integrations send inventory items with the same key name, they will remain invisible to the user: pid installed_epoch epoch time size boot_id product_uuid installed_time",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.1959,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "Problem Your integration is reporting data, but a few inventory attributes are missing. Solution The following inventory key names are used internally by our platform. If customer-provided <em>integrations</em> send inventory items with the same key name, they will remain invisible to the user: pid installed_epoch epoch time size boot_id product_uuid installed_time"
      },
      "id": "60506c9564441f0e645321ab"
    }
  ],
  "/docs/create-integrations/infrastructure-integrations-sdk/get-started/go-language-integration-tutorial-build-tools": [
    {
      "sections": [
        "Introduction to Infrastructure Integrations SDK",
        "Important",
        "What is the Integrations SDK?",
        "What data can you report with an on-host integration?",
        "Create a custom integration"
      ],
      "title": "Introduction to Infrastructure Integrations SDK",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Get started"
      ],
      "external_id": "0662f6c3fbc151a0c836b54c104e81756b34827f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/get-started/introduction-infrastructure-integrations-sdk/",
      "published_at": "2021-06-14T22:22:04Z",
      "updated_at": "2021-03-16T07:28:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are several ways New Relic lets you create your own integration: General telemetry (metrics, traces) solutions: Use our Telemetry SDKs. Build a custom New Relic One application that uses your own JavaScript UI functionality. If you have New Relic Infrastructure, you can use our lightweight Flex integration tool (recommended) or use our Integrations SDK to build a complete Infrastructure on-host integration. Important New Relic is transitioning to rely on open source standards like Prometheus for future on-host integrations. Though the infrastructure SDK is the foundation of that transition, some of the tutorials and tools around this SDK might not be up-to-date with the latest developments. What is the Integrations SDK? Our Infrastructure Integrations SDK lets you build an on-host integration that reports custom data from your hosts or services. That data can then be found in New Relic Infrastructure and can be used to create custom queries and charts. What data can you report with an on-host integration? When you build an integration using the Integrations SDK, you assign the entities that report data. In New Relic terms, entity is a purposefully ambiguous term meaning something that reports data to New Relic (for example: a local host, a load balancer, or a database). A single integration can report data from multiple entities, which gives you the ability to report data from more than one service or host instance. There are three types of data an entity can generate: Metrics: Metric data is used for numerical measurement data. Examples: how many requests are in a queue, or the number of hits on a database per minute. Metric data from a custom integration can be queried and used to create dashboards. Inventory: Live system state and configuration information. This data will show up on the Infrastructure Inventory UI page. Events: Events are used to record important activities on a system. Examples: a service starting or a new table being created. Event data will be shown in the Infrastructure Events UI page. Create a custom integration To create an integration using the Integrations SDK, use these resources: See the Go language build tools and tutorial. The tutorial walks you through creating a Redis integration in Go. (Note: Go is not required; it's just the language for which we provide additional build tools. For more information, see Integrations SDK requirements.) See the integration file structure documentation, which describes the files required to create an integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.69455,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "sections": "Introduction to <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": " Relic <em>Infrastructure</em> and can be used to <em>create</em> custom queries and charts. What data can you report with an on-host integration? When you build an integration using the <em>Integrations</em> <em>SDK</em>, you assign the entities that report data. In New Relic terms, entity is a purposefully ambiguous term meaning"
      },
      "id": "603eb55be7b9d2dcb72a07e8"
    },
    {
      "sections": [
        "Compatibility and requirements for Infrastructure Integrations SDK",
        "Infrastructure version",
        "Operating systems",
        "Data and file specifications",
        "SDK version changes"
      ],
      "title": "Compatibility and requirements for Infrastructure Integrations SDK",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Get started"
      ],
      "external_id": "ea949057459c7c9648a9215928c1fd54c9d6a703",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/get-started/compatibility-requirements-infrastructure-integrations-sdk/",
      "published_at": "2021-06-14T22:22:04Z",
      "updated_at": "2021-03-13T02:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before using the New Relic Infrastructure integrations SDK to create a custom on-host integration, make sure your system meets these requirements. Infrastructure version To use the infrastructure Integrations SDK v4, you must have the Infrastructure agent version 1.13.0 or higher. To use SDK v3, you must have agent version 1.0.888 or higher. For Infrastructure agent version information and options for installation and updates, see the Infrastructure release notes. For notes on SDK versions and changes, see the change log. Operating systems Integrations built with the SDK can be compiled for either Linux or Windows operating systems. Data and file specifications Infrastructure on-host integrations can be created with any programming language, as long as they adhere to the data and file specifications. SDK version changes Infrastructure agent version Details 1.13.0 or higher Changes to integration protocol (v4), including support to dynamically register entities in NR1 and send dimensional metrics. New metric types. See SDK v4 release notes. 1.0.888 or higher Changes to JSON format, including support for multiple entities. The new JSON format is referred to as protocol 2 (described in JSON output documentation and also used in the definition file). Uses newer set of Go language build tools (referenced as GoSDK v3). 1.0.726 (for Linux); 1.0.775 (for Windows) Uses JSON protocol 1 (described in JSON output documentation and also used in the definition file). Uses older set of Go language build tools (referenced as GoSDK v2). If you've built an integration using the older Go language build tools and wish to update, see Upgrade from GoSDK v2 to v3 and Upgrade from v3 to v4. For updating the Infrastructure agent, see Update the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.16673,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "sections": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "Before using the New Relic <em>Infrastructure</em> <em>integrations</em> <em>SDK</em> to <em>create</em> a custom on-host integration, make sure your system meets these requirements. <em>Infrastructure</em> version To use the <em>infrastructure</em> <em>Integrations</em> <em>SDK</em> v4, you must have the <em>Infrastructure</em> agent version 1.13.0 or higher. To use <em>SDK</em> v3"
      },
      "id": "60440de564441fa14f378ecc"
    },
    {
      "sections": [
        "Not seeing attributes data",
        "Problem",
        "Solution"
      ],
      "title": "Not seeing attributes data",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Troubleshooting"
      ],
      "external_id": "25a763fd32bebfa1cb33b77caf260df9a4d9fe53",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/troubleshooting/not-seeing-attributes/",
      "published_at": "2021-06-14T20:50:43Z",
      "updated_at": "2021-03-16T08:30:13Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Your integration is reporting data, but a few inventory attributes are missing. Solution The following inventory key names are used internally by our platform. If customer-provided integrations send inventory items with the same key name, they will remain invisible to the user: pid installed_epoch epoch time size boot_id product_uuid installed_time",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.1959,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "Problem Your integration is reporting data, but a few inventory attributes are missing. Solution The following inventory key names are used internally by our platform. If customer-provided <em>integrations</em> send inventory items with the same key name, they will remain invisible to the user: pid installed_epoch epoch time size boot_id product_uuid installed_time"
      },
      "id": "60506c9564441f0e645321ab"
    }
  ],
  "/docs/create-integrations/infrastructure-integrations-sdk/get-started/introduction-infrastructure-integrations-sdk": [
    {
      "sections": [
        "Compatibility and requirements for Infrastructure Integrations SDK",
        "Infrastructure version",
        "Operating systems",
        "Data and file specifications",
        "SDK version changes"
      ],
      "title": "Compatibility and requirements for Infrastructure Integrations SDK",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Get started"
      ],
      "external_id": "ea949057459c7c9648a9215928c1fd54c9d6a703",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/get-started/compatibility-requirements-infrastructure-integrations-sdk/",
      "published_at": "2021-06-14T22:22:04Z",
      "updated_at": "2021-03-13T02:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before using the New Relic Infrastructure integrations SDK to create a custom on-host integration, make sure your system meets these requirements. Infrastructure version To use the infrastructure Integrations SDK v4, you must have the Infrastructure agent version 1.13.0 or higher. To use SDK v3, you must have agent version 1.0.888 or higher. For Infrastructure agent version information and options for installation and updates, see the Infrastructure release notes. For notes on SDK versions and changes, see the change log. Operating systems Integrations built with the SDK can be compiled for either Linux or Windows operating systems. Data and file specifications Infrastructure on-host integrations can be created with any programming language, as long as they adhere to the data and file specifications. SDK version changes Infrastructure agent version Details 1.13.0 or higher Changes to integration protocol (v4), including support to dynamically register entities in NR1 and send dimensional metrics. New metric types. See SDK v4 release notes. 1.0.888 or higher Changes to JSON format, including support for multiple entities. The new JSON format is referred to as protocol 2 (described in JSON output documentation and also used in the definition file). Uses newer set of Go language build tools (referenced as GoSDK v3). 1.0.726 (for Linux); 1.0.775 (for Windows) Uses JSON protocol 1 (described in JSON output documentation and also used in the definition file). Uses older set of Go language build tools (referenced as GoSDK v2). If you've built an integration using the older Go language build tools and wish to update, see Upgrade from GoSDK v2 to v3 and Upgrade from v3 to v4. For updating the Infrastructure agent, see Update the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.16673,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "sections": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "Before using the New Relic <em>Infrastructure</em> <em>integrations</em> <em>SDK</em> to <em>create</em> a custom on-host integration, make sure your system meets these requirements. <em>Infrastructure</em> version To use the <em>infrastructure</em> <em>Integrations</em> <em>SDK</em> v4, you must have the <em>Infrastructure</em> agent version 1.13.0 or higher. To use <em>SDK</em> v3"
      },
      "id": "60440de564441fa14f378ecc"
    },
    {
      "sections": [
        "Go language integration tutorial and build tools",
        "Integrations tutorial",
        "Important",
        "Tip",
        "Go language integration building package"
      ],
      "title": "Go language integration tutorial and build tools",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Get started"
      ],
      "external_id": "068b7f6bc27cf0a360699121c3cf8c46c9398d6a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/get-started/go-language-integration-tutorial-build-tools/",
      "published_at": "2021-06-14T22:20:16Z",
      "updated_at": "2021-03-13T01:25:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Infrastructure Integrations SDK lets you build a custom on-host integration. This document explains the build tools and resources available for building an on-host integration with our Go language tools. Integrations tutorial Important The following tutorial is based on integrations using the SDK integration protocol v3. Find more information about the integration protocol v4 in the Github repository. The Go language integration-building tutorial on GitHub gives step-by-step procedures for building a Go language integration that reports Redis data. The tutorial shows how to build an integration using the Linux command line, but you can use the same techniques for a Windows integration with a standard Go install and PowerShell. The make command will not work with PowerShell, but you can use the Go commands inside it as a guide for building your integration. Tip You can create an on-host integration in any language, but Go is the language New Relic uses for its own integrations and build tools. To create an integration in another language, adhere to the integration file structures and JSON output requirements. Go language integration building package The tutorial relies on a New Relic Go language integration-building library package, which provides a set of useful Go functions and data structures. The package gives you tools that: Generate a \"scaffold\" integration structure with all the required fields. Read values from command-line arguments or environment variables. Generate and print JSON data to stdout. For information about file formats and JSON output specifications, see File requirements.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.15936,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Go language <em>integration</em> tutorial and build tools",
        "sections": "<em>Integrations</em> tutorial",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "The New Relic <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em> lets you build a custom on-host integration. This document explains the build tools and resources available for building an on-host integration with our Go language tools. <em>Integrations</em> tutorial Important The following tutorial is based on <em>integrations</em>"
      },
      "id": "6044091d28ccbcc5b22c6097"
    },
    {
      "sections": [
        "Not seeing attributes data",
        "Problem",
        "Solution"
      ],
      "title": "Not seeing attributes data",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Troubleshooting"
      ],
      "external_id": "25a763fd32bebfa1cb33b77caf260df9a4d9fe53",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/troubleshooting/not-seeing-attributes/",
      "published_at": "2021-06-14T20:50:43Z",
      "updated_at": "2021-03-16T08:30:13Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Your integration is reporting data, but a few inventory attributes are missing. Solution The following inventory key names are used internally by our platform. If customer-provided integrations send inventory items with the same key name, they will remain invisible to the user: pid installed_epoch epoch time size boot_id product_uuid installed_time",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.1959,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "Problem Your integration is reporting data, but a few inventory attributes are missing. Solution The following inventory key names are used internally by our platform. If customer-provided <em>integrations</em> send inventory items with the same key name, they will remain invisible to the user: pid installed_epoch epoch time size boot_id product_uuid installed_time"
      },
      "id": "60506c9564441f0e645321ab"
    }
  ],
  "/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-configuration-overview": [
    {
      "sections": [
        "Compatibility and requirements for Infrastructure Integrations SDK",
        "Infrastructure version",
        "Operating systems",
        "Data and file specifications",
        "SDK version changes"
      ],
      "title": "Compatibility and requirements for Infrastructure Integrations SDK",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Get started"
      ],
      "external_id": "ea949057459c7c9648a9215928c1fd54c9d6a703",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/get-started/compatibility-requirements-infrastructure-integrations-sdk/",
      "published_at": "2021-06-14T22:22:04Z",
      "updated_at": "2021-03-13T02:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before using the New Relic Infrastructure integrations SDK to create a custom on-host integration, make sure your system meets these requirements. Infrastructure version To use the infrastructure Integrations SDK v4, you must have the Infrastructure agent version 1.13.0 or higher. To use SDK v3, you must have agent version 1.0.888 or higher. For Infrastructure agent version information and options for installation and updates, see the Infrastructure release notes. For notes on SDK versions and changes, see the change log. Operating systems Integrations built with the SDK can be compiled for either Linux or Windows operating systems. Data and file specifications Infrastructure on-host integrations can be created with any programming language, as long as they adhere to the data and file specifications. SDK version changes Infrastructure agent version Details 1.13.0 or higher Changes to integration protocol (v4), including support to dynamically register entities in NR1 and send dimensional metrics. New metric types. See SDK v4 release notes. 1.0.888 or higher Changes to JSON format, including support for multiple entities. The new JSON format is referred to as protocol 2 (described in JSON output documentation and also used in the definition file). Uses newer set of Go language build tools (referenced as GoSDK v3). 1.0.726 (for Linux); 1.0.775 (for Windows) Uses JSON protocol 1 (described in JSON output documentation and also used in the definition file). Uses older set of Go language build tools (referenced as GoSDK v2). If you've built an integration using the older Go language build tools and wish to update, see Upgrade from GoSDK v2 to v3 and Upgrade from v3 to v4. For updating the Infrastructure agent, see Update the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.227,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "sections": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "Before using the New Relic <em>Infrastructure</em> <em>integrations</em> <em>SDK</em> to <em>create</em> a custom on-host integration, make sure your system meets these requirements. <em>Infrastructure</em> version To use the <em>infrastructure</em> <em>Integrations</em> <em>SDK</em> v4, you must have the <em>Infrastructure</em> agent version 1.13.0 or higher. To use <em>SDK</em> v3"
      },
      "id": "60440de564441fa14f378ecc"
    },
    {
      "sections": [
        "On-host integration files",
        "Integration files"
      ],
      "title": "On-host integration files",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "bad9028bde5eb2b92ad7971e0ca42517530f3796",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-files/",
      "published_at": "2021-06-14T22:17:17Z",
      "updated_at": "2021-03-16T08:29:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Infrastructure Integrations SDK lets you create an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before you build an on-host integration, verify you meet the compatibility and requirements. An integration requires at least these files: An executable file, written in any language, that export JSON data in a format expected by the Infrastructure agent One or more configuration files For Go language build tools and a tutorial for creating these files, see Build resources.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.287,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> files",
        "sections": "On-host <em>integration</em> files",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "The New Relic <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em> lets you <em>create</em> an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before"
      },
      "id": "603ed7e264441ff57a4e883b"
    },
    {
      "sections": [
        "On-host integrations: Newer configuration format",
        "Configuration structure",
        "Tip",
        "Important",
        "List of configuration properties",
        "Select an integration to run",
        "name",
        "exec",
        "cli_args",
        "when",
        "Pass configuration to the integration executable",
        "env",
        "config",
        "config_template_path",
        "Configure how the agent executes your integrations",
        "integration_user",
        "interval",
        "inventory_source",
        "labels",
        "timeout",
        "working_dir",
        "Update older integration configuration"
      ],
      "title": "On-host integrations: Newer configuration format ",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "bc5bee12812cff6fabc728961e1b342b83f3e471",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-newer-configuration-format/",
      "published_at": "2021-06-14T22:22:47Z",
      "updated_at": "2021-03-16T07:30:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Infrastructure on-host integrations can use one of two types of configuration formats. In December 2019, Infrastructure agent version 1.8.0 began supporting a newer configuration format that makes use of a single configuration file (instead of two separate files), and provides other improvements. This document will explain how this newer format works. The older standard configuration format is supported by current Infrastructure agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration's configuration YAML must have an integrations top-level section containing a YAML array, where each entry represents an integration and its configuration. For each integration entry, only the name property is mandatory. The other properties are optional. Here's an example configuration featuring two integrations: our built-in Docker integration, which requires no configuration, and our MySQL integration: integrations: # New Relic integration that does not require any configuration - name: nri-docker # New Relic integration that gets its configuration from the environment - name: nri-mysql env: PORT: 3306 USERNAME: newrelic PASSWORD: 123456789 # to hide this field, read the secrets management documentation # Any free-form integration executed via a user-provided command - name: my-own-integration exec: python /opt/integrations/my-script.py --host=127.0.0.1 Copy You can have as many configuration YAML files as you want and can group your integration instances. Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Each configuration YAML file can also contain discovery and variables top-level sections. Important This configuration format does not require an agent restart. When saved, changes are detected and implemented immediately. This means that saving intermediate configuration changes may cause the integration to stop working. List of configuration properties This is a list of the general properties used to configure an integration. For more details about using these properties, including example values, see the documentation following the table. Config Description name Name of the integration. This is the only mandatory configuration property across all on-host integrations. If the exec field is not set it will also be the name of the integration executable. cli_args Optional list of command line arguments when name is used to provide the integration executable. Available since agent version 1.13.0. exec Full path to the integration executable, plus arguments. It may be a single-line string or a string array. If left unspecified, the exec field defaults to the name field. env YAML map containing the environment variables to be passed to the integration, where key is the environment variable name, and value is the variable value. config Configuration that is written as an external file and the path that is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. config_template_path Any external file whose path is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. Its usage allows applying discovery and secrets binding to any external configuration. integration_user Name of the user who runs the integration. interval Time between consecutive executions of the integration. It must be a number followed by a time unit (s, m or h), without spaces. inventory_source Allows overriding the category and term of the inventory source. labels Map with labels that decorate the data (metrics, events, inventory) reported by the integration. timeout A number followed by a time unit (ms, s, m or h). An integration that hasn't responded in this time period is killed and restarted. working_dir Working directory for the integration binary. when Integration is only executed if the clause evaluates to true. Conditions are defined below. The remainder of this document describes config properties grouped by their functionality: Select an integration to run Pass configuration to the integration command Configure how the agent executes integrations Select an integration to run There are two properties to select which integration will run: name and exec. The only mandatory property across all on-host integrations is name. The remaining properties specified in this document are optional. Example: integrations: - name: nri-docker - name: my-integration exec: /usr/local/bin/my-integration --metrics --inventory Copy name The mandatory name property can work in two ways: If the exec property is set: The name property only provides an identifier for the integration instance. This identifier is used in log messages and to provide a default inventory category/source in the form integration/<name> (for example, integration/nri-redis). This inventory path can be overridden with the inventory_source configuration option. If the exec property is not set: The agent looks for (and executes) an executable with the name value in any of the following folders: Linux: /var/db/newrelic-infra/newrelic-integrations/bin /var/db/newrelic-infra/newrelic-integrations /var/db/newrelic-infra/custom-integrations/bin /var/db/newrelic-infra/custom-integrations Windows C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations\\bin C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations If there is no executable with this name in the above folders the agent logs an error and the integration is not executed. Important In Windows, do not append the .exe extension to the name. The agent does this for you (for example, name: nri-mysql would look for nri-mysql.exe in the above folders). exec The exec optional property specifies the path, command, and command-line arguments of the integration to execute. When none of the path folders or arguments have spaces, it can be written in a single-line string: - name: my-integration exec: /usr/bin/python /opt/integrations/my-script.py --host=127.0.0.1 Copy If any of the path/arguments have spaces that are part of a single element, you can use a YAML array notation: - name: my-integration exec: - C:\\Program Files\\My Integration\\integration.exe - --host - 127.0.0.1 - --port - 8080 Copy The default working directory is the root directory of the agent configuration. It can be overridden with the working_dir property. cli_args The cli_args optional property specifies command line arguments that should be passed to the integration. It is useful when using name as it only provides the integration name identifier (not compatible with exec). - name: my-integration cli_args: [ -interval 10s ] Copy Usual YAML multi-line list format can be used as well: - name: my-integration cli_args: - -interval - 10s Copy when The when property allows to execute the integration only when all the evaluated conditions are successful. Available conditions are: env_exists: Environment variables exist and match value. file_exists: Given file path exists. feature: Provided feature-flag is enabled. Example: integrations: - name: ssh-integration when: file_exists: /var/run/sshd.pid Copy Pass configuration to the integration executable Often integration executables need to receive a configuration to work properly (for example, hostname and port of the monitored system, user credentials, etc.). The Infrastructure agent allows you to configure the integration commands in three ways (which you can combine): Command-line arguments, passed in the exec property. Environment variables, using the env property. Configuration files, whose path needs to be passed through environment variables or command-line arguments (see the config) property. Example: integrations: - name: my-integration exec: /opt/path/bin/script --host 127.0.0.1 --port 8081 - name: nri-mysql env: STATUS_URL: http://10.0.0.3/server-status?auto REMOTE_MONITORING: true Copy env The env property allows you to set environment variables that are passed to the executable. It is a key-value map with the required variables. Example: integrations: - name: nri-postgresql env: DATABASE: postgres PORT: 6432 COLLECTION_LIST: '[\"postgres\"]' COLLECT_DB_LOCK_METRICS: false VERBOSE: 1 Copy If you expect your integration to receive the configuration from the host's environment rather than specifying it explicitly in the configuration file, you need to set the required variables in the Infrastructure agent passthrough_environment global configuration property config This section describes various ways to pass configuration information to an integration. Pass configuration file directly Some integration commands may get their configuration from an external file. If your integration requires a configuration file, nothing prevents you from directly passing its path directly as a command-line argument or an environment variable. Here's an example using configuration of our Flex integration: integrations: - name: nri-flex env: CONFIG_FILE: /etc/nri-flex/configs/http-service.yaml - name: other-integration exec: /opt/integration/integration -f /opt/integration/config.properties Copy The above example assumes that the http-service.yaml and config.properties files exist. We can see that the nri-flex integration is expecting the http-service.yaml complete path via the CONFIG_FILE environment variable and the other-integration expects the complete config.properties path after the -f command-line flag. In the above example, it's necessary for the integration installer/configurator that the configuration files exist in the provided path and that the agent and integrations have read permissions on them. Pass configuration through config section If you prefer to keep your configuration file with the rest of the integration configuration, you can use the config section in the integration entry, which can contain a valid YAML object or just a multi-line string: integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv - name: other-integration exec: /opt/integration/integration -f ${config.path} config: | example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostname=localhost example.cfg.port=9025 Copy In the above examples, every time the nri-flex integration is executed, the agent creates a temporary file with the following contents: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy The above YAML is only a configuration example for the nri-flex integration. The agent ignores its contents; instead, it creates a temporary file and replaces the ${config.path} variable placeholder with its path. When the integration completes execution the temporary file is removed. Also, the agent creates another temporary file before executing the other-integration integration: example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostid=localhost example.cfg.port=9025 Copy It replaces the -f ${config.path} command-line placeholder with the temporary path of the written file. By convention, if you do not place the ${config.path} variable in any command-line argument or environment variable value, the agent passes the path of the configuration file via the CONFIG_PATH environment variable: # assuming that nri-example command is prepared to receive the configuration # file via the CONFIG_PATH environment variable integrations: - name: nri-example config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy Pass secrets and discovery through config section The main benefit for using a config section instead of hardcoding the full path of an external file is that you can insert ${variable} placeholders to apply our auto-discovery feature and secrets management. Here's an example followed by some explanations: variables: my_credentials: vault: http: url: http://my.vault.host/v1/newengine/data/secret headers: X-Vault-Token: my-vault-token discovery: docker: match: label.service: foo integrations: - name: foo-monitor exec: /opt/foo/bin/monitor --config=${config.path} config: | foo.host=${discovery.ip} foo.port=${discovery.port} foo.user=${my_credentials.user} foo.password=${my_credentials.password} Copy Tip (For more details about the variables and discovery sections, please visit the discovery and secrets management documentation). The above example relies on the following premises: There is a Vault service that allows retrieving a JSON object formed by the user and password fields. There may be a variable number of Docker containers labeled with service=foo, which are accessible from the agent host via a discoverable public IP and Port. The user has configured the foo-monitor integration to monitor all the service=foo labeled containers, which share a common user and password. Each instance of the foo-monitor integration requires executing the /opt/foo/bin/monitor executable, passing the text configuration inside the config section via the --config=<path> command-line argument. As example of workflow, imagine that the Vault invocation returns the following JSON: {\"user\":\"monitorer\",\"password\":\"5up3r53cr3t!\"} Copy At the moment of executing the foo-monitor integration, there are three running containers labeled with service=foo: ip: 10.0.0.3, port: 8080 ip: 10.0.0.3, port: 8081 ip: 10.0.0.3, port: 8082 The agent then creates the following three temporary files, using the contents of the config property as a template, but replacing the ${placeholders} by the acquired variables and discovered items (files' path is invented for the sake of simplicity): First match (/tmp/123_discovered): foo.host=10.0.0.3 foo.port=8080 foo.user=monitorer foo.password=5up3r53cr3t! Copy Second match (/tmp/456_discovered): foo.host=10.0.0.3 foo.port=8081 foo.user=monitorer foo.password=5up3r53cr3t! Copy Third match (/tmp/789_discovered) foo.host=10.0.0.3 foo.port=8082 foo.user=monitorer foo.password=5up3r53cr3t! Copy After the config variable placeholders have been replaced and the temporary files have been created, the /opt/foo/bin/monitor executable is executed three times (one per matched container), replacing the ${config.path} command-line placeholder with the temporary file corresponding to each discovered configuration: First match: /opt/foo/bin/monitor --config=/tmp/123_discovered Second match: /opt/foo/bin/monitor --config=/tmp/456_discovered Third match: /opt/foo/bin/monitor --config=/tmp/789_discovered To ensure security and to minimize the chance of leaking secrets to disk, the agent: Creates the files owned by the agent user, for example, root or nri-agent, depending on the user you have configured to run the agent. Sets read permissions only for the owner. Removes the created files when the integration instance finishes its execution. config_template_path If you want to use the secrets management and discovery in the configuration files that you're passing to the integration executable, but you prefer to keep them as an individual file, you can use the config_template_path: <path> option. It works exactly as in the config section: The agent applies secrets management and discovery to the file contents. The agent creates different temporary files that are passed to the integration via the ${config.path} placeholder (or the CONFIG_PATH environment variable). Example: discovery: docker: match: name: /^redis/ integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config_template_path: /etc/flex-configs/redis.yml Copy In the above example, the redis.yml external file can contain container discovery variable placeholders, like ${discovery.ip} or ${discovery.port}. Configure how the agent executes your integrations The properties of this section modify the way the Infrastructure agent executes and interacts with the integrations, or the way the agent decorates the integrations' data. integration_user The integration commands run as the same user as the agent (usually root or nri-agent). If due to permission restrictions an integration needs to run as another user, its name must be specified in the integration_user property. Example: integrations: - name: dbus-inventory exec: python my-dbus-script.py integration_user: dbus Copy interval The interval option sets the time between consecutive executions of an integration. The accepted format is an integer immediately followed by a time unit (s for seconds, m for minutes, h for hours). The default is 30s, and the minimum accepted value is 15s. Any value lower than 15s is automatically set to 15s. Example: integrations: - name: nri-nginx env: STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover interval: 20s Copy inventory_source Any inventory item must be catalogued under a category/source taxonomy. By default, each integration inventory is stored as integration/ + name value (for example, integration/nri-apache, integration/nri-mysql). The inventory_source property allows you to override the default taxonomy of inventory data. Example: integrations: - name: nri-nginx - name: nri-apache exec: - /var/db/newrelic-infra/newrelic-integrations/bin/nri-apache - --inventory inventory_source: config/apache Copy In the above example, the nri-nginx inventory, if any, would be visible in the New Relic UI under the integration/nri-nginx source. The nri-apache inventory would be visible under config/apache. labels labels is a key-value map that allows extra metadata to be provided for the integration. The agent uses those labels to decorate the metrics, events, and inventory that it receives from a given integration instance. Example: integrations: - name: nri-apache inventory_source: config/apache labels: env: production role: load_balancer Copy In the above example, the agent decorates all the metrics and events from the nri-apache instance with the following fields: label.env: production label.role: load_balancer Also, the following entries are added to the integration inventory: config/apache/labels/env: production config/apache/labels/role: load_balancer timeout If an integration has not returned any metric (or a heartbeat message as described below) before the time specified in the timeout value, the agent kills the integration process and restarts it after the corresponding interval. The accepted format is an integer number immediately followed (without spaces) by a time unit (ms for milliseconds, s for seconds, m for minutes, h for hours). If a zero (or negative) timeout value is provided, the integration can run forever without being killed by a timeout expiration. For long-running integrations (integrations that keep running, periodically returning metrics/events/inventory), each time the integration submits a metrics/events/inventory payload, the timeout deadline is restarted. That means that long-running integrations must return a valid JSON payload in an interval that is lower than timeout. Returning an empty JSON ({}) is interpreted as a heart-beat message that restarts the timeout, preventing the long-running integration from being killed, even if they don't have information to report. The default is 120s, and the minimum accepted value is 100ms. Any value lower than 100ms is automatically set to 100ms. Example: integrations: - name: nri-jmx arguments: JMX_HOST: jmx-host.localnet JMX_PORT: 7096 COLLECTION_FILES: \"/etc/newrelic-infra/integrations.d/jvm-metrics.yml\" timeout: 30s Copy working_dir working_dir sets the working directory of the command. If empty or unspecified, the agent runs the command in the Infrastructure agent's current directory. The default is the Infrastructure agent root directory. Example: integrations: - name: my-integration exec: /opt/integration/bin/integration working_dir: /opt/integration/scratch-zone Copy Update older integration configuration In December 2019, the Infrastructure agent version 1.8.0 began using a different configuration format. For details, see Config format differences. The main difference between these formats is that the older configuration format uses two separate configuration files (a INTEGRATION_NAME-definition.yml file and a INTEGRATION_NAME-config.yml file) and the newer version uses a single configuration file. Here are some of the features added by the newer configuration functionality: Flexible configuration via command-line arguments, environment variables, or external files. Ability to group different integrations in the same file. Hot reload: adding a new integration or changing its configuration does not require restarting the agent. Timeouts: if an integration doesn't respond before a user-specified time, the integration process is killed and restarted. Not all on-host integrations come with the newer configuration format, but you can update the configuration to the new format for all on-host integrations to take advantage of the new features. The following YAML shows an example Apache integration configuration using the older configuration format. Note that this configuration will still work with newer agents, but we recommend updating your integrations to take full advantage of features. integration_name: com.newrelic.apache instances: - name: apache-server-metrics command: metrics arguments: status_url: http://127.0.0.1/server-status?auto remote_monitoring: true labels: env: production role: load_balancer - name: apache-server-inventory command: inventory arguments: remote_monitoring: true labels: env: production role: load_balancer Copy To update an older integration configuration to the new format, you must perform two steps: Rename the instances top-level section to integrations. Remove the integration_name top-level section and add it to each integration entry. You are no longer required to keep a separate file for each integration type and you can group your legacy integration entries in the same file as other integrations. The new version of the Apache integration config: integrations: - name: apache-server-metrics integration_name: com.newrelic.apache command: metrics arguments: status_url: http://127.0.0.1/server-status?auto remote_monitoring: true labels: env: production role: load_balancer - name: apache-server-inventory integration_name: com.newrelic.apache command: inventory arguments: remote_monitoring: true labels: env: production role: load_balancer Copy Please note that because the older configuration format doesn't support hot reloading. You will need to restart the Infrastructure agent to remove the old integrations configuration (otherwise the old instances will coexist with the new ones).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.27914,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Newer configuration format ",
        "sections": "On-host <em>integrations</em>: Newer configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic <em>Infrastructure</em> on-host <em>integrations</em> can use one of two types of configuration formats. In December 2019, <em>Infrastructure</em> agent version 1.8.0 began supporting a newer configuration format that makes use of a single configuration file (instead of two separate files), and provides other"
      },
      "id": "603e923928ccbcb8dfeba751"
    }
  ],
  "/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-executable-file-json-specifications": [
    {
      "sections": [
        "Compatibility and requirements for Infrastructure Integrations SDK",
        "Infrastructure version",
        "Operating systems",
        "Data and file specifications",
        "SDK version changes"
      ],
      "title": "Compatibility and requirements for Infrastructure Integrations SDK",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Get started"
      ],
      "external_id": "ea949057459c7c9648a9215928c1fd54c9d6a703",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/get-started/compatibility-requirements-infrastructure-integrations-sdk/",
      "published_at": "2021-06-14T22:22:04Z",
      "updated_at": "2021-03-13T02:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before using the New Relic Infrastructure integrations SDK to create a custom on-host integration, make sure your system meets these requirements. Infrastructure version To use the infrastructure Integrations SDK v4, you must have the Infrastructure agent version 1.13.0 or higher. To use SDK v3, you must have agent version 1.0.888 or higher. For Infrastructure agent version information and options for installation and updates, see the Infrastructure release notes. For notes on SDK versions and changes, see the change log. Operating systems Integrations built with the SDK can be compiled for either Linux or Windows operating systems. Data and file specifications Infrastructure on-host integrations can be created with any programming language, as long as they adhere to the data and file specifications. SDK version changes Infrastructure agent version Details 1.13.0 or higher Changes to integration protocol (v4), including support to dynamically register entities in NR1 and send dimensional metrics. New metric types. See SDK v4 release notes. 1.0.888 or higher Changes to JSON format, including support for multiple entities. The new JSON format is referred to as protocol 2 (described in JSON output documentation and also used in the definition file). Uses newer set of Go language build tools (referenced as GoSDK v3). 1.0.726 (for Linux); 1.0.775 (for Windows) Uses JSON protocol 1 (described in JSON output documentation and also used in the definition file). Uses older set of Go language build tools (referenced as GoSDK v2). If you've built an integration using the older Go language build tools and wish to update, see Upgrade from GoSDK v2 to v3 and Upgrade from v3 to v4. For updating the Infrastructure agent, see Update the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.227,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "sections": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "Before using the New Relic <em>Infrastructure</em> <em>integrations</em> <em>SDK</em> to <em>create</em> a custom on-host integration, make sure your system meets these requirements. <em>Infrastructure</em> version To use the <em>infrastructure</em> <em>Integrations</em> <em>SDK</em> v4, you must have the <em>Infrastructure</em> agent version 1.13.0 or higher. To use <em>SDK</em> v3"
      },
      "id": "60440de564441fa14f378ecc"
    },
    {
      "sections": [
        "On-host integration files",
        "Integration files"
      ],
      "title": "On-host integration files",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "bad9028bde5eb2b92ad7971e0ca42517530f3796",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-files/",
      "published_at": "2021-06-14T22:17:17Z",
      "updated_at": "2021-03-16T08:29:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Infrastructure Integrations SDK lets you create an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before you build an on-host integration, verify you meet the compatibility and requirements. An integration requires at least these files: An executable file, written in any language, that export JSON data in a format expected by the Infrastructure agent One or more configuration files For Go language build tools and a tutorial for creating these files, see Build resources.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.287,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> files",
        "sections": "On-host <em>integration</em> files",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "The New Relic <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em> lets you <em>create</em> an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before"
      },
      "id": "603ed7e264441ff57a4e883b"
    },
    {
      "sections": [
        "On-host integrations: Newer configuration format",
        "Configuration structure",
        "Tip",
        "Important",
        "List of configuration properties",
        "Select an integration to run",
        "name",
        "exec",
        "cli_args",
        "when",
        "Pass configuration to the integration executable",
        "env",
        "config",
        "config_template_path",
        "Configure how the agent executes your integrations",
        "integration_user",
        "interval",
        "inventory_source",
        "labels",
        "timeout",
        "working_dir",
        "Update older integration configuration"
      ],
      "title": "On-host integrations: Newer configuration format ",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "bc5bee12812cff6fabc728961e1b342b83f3e471",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-newer-configuration-format/",
      "published_at": "2021-06-14T22:22:47Z",
      "updated_at": "2021-03-16T07:30:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Infrastructure on-host integrations can use one of two types of configuration formats. In December 2019, Infrastructure agent version 1.8.0 began supporting a newer configuration format that makes use of a single configuration file (instead of two separate files), and provides other improvements. This document will explain how this newer format works. The older standard configuration format is supported by current Infrastructure agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration's configuration YAML must have an integrations top-level section containing a YAML array, where each entry represents an integration and its configuration. For each integration entry, only the name property is mandatory. The other properties are optional. Here's an example configuration featuring two integrations: our built-in Docker integration, which requires no configuration, and our MySQL integration: integrations: # New Relic integration that does not require any configuration - name: nri-docker # New Relic integration that gets its configuration from the environment - name: nri-mysql env: PORT: 3306 USERNAME: newrelic PASSWORD: 123456789 # to hide this field, read the secrets management documentation # Any free-form integration executed via a user-provided command - name: my-own-integration exec: python /opt/integrations/my-script.py --host=127.0.0.1 Copy You can have as many configuration YAML files as you want and can group your integration instances. Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Each configuration YAML file can also contain discovery and variables top-level sections. Important This configuration format does not require an agent restart. When saved, changes are detected and implemented immediately. This means that saving intermediate configuration changes may cause the integration to stop working. List of configuration properties This is a list of the general properties used to configure an integration. For more details about using these properties, including example values, see the documentation following the table. Config Description name Name of the integration. This is the only mandatory configuration property across all on-host integrations. If the exec field is not set it will also be the name of the integration executable. cli_args Optional list of command line arguments when name is used to provide the integration executable. Available since agent version 1.13.0. exec Full path to the integration executable, plus arguments. It may be a single-line string or a string array. If left unspecified, the exec field defaults to the name field. env YAML map containing the environment variables to be passed to the integration, where key is the environment variable name, and value is the variable value. config Configuration that is written as an external file and the path that is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. config_template_path Any external file whose path is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. Its usage allows applying discovery and secrets binding to any external configuration. integration_user Name of the user who runs the integration. interval Time between consecutive executions of the integration. It must be a number followed by a time unit (s, m or h), without spaces. inventory_source Allows overriding the category and term of the inventory source. labels Map with labels that decorate the data (metrics, events, inventory) reported by the integration. timeout A number followed by a time unit (ms, s, m or h). An integration that hasn't responded in this time period is killed and restarted. working_dir Working directory for the integration binary. when Integration is only executed if the clause evaluates to true. Conditions are defined below. The remainder of this document describes config properties grouped by their functionality: Select an integration to run Pass configuration to the integration command Configure how the agent executes integrations Select an integration to run There are two properties to select which integration will run: name and exec. The only mandatory property across all on-host integrations is name. The remaining properties specified in this document are optional. Example: integrations: - name: nri-docker - name: my-integration exec: /usr/local/bin/my-integration --metrics --inventory Copy name The mandatory name property can work in two ways: If the exec property is set: The name property only provides an identifier for the integration instance. This identifier is used in log messages and to provide a default inventory category/source in the form integration/<name> (for example, integration/nri-redis). This inventory path can be overridden with the inventory_source configuration option. If the exec property is not set: The agent looks for (and executes) an executable with the name value in any of the following folders: Linux: /var/db/newrelic-infra/newrelic-integrations/bin /var/db/newrelic-infra/newrelic-integrations /var/db/newrelic-infra/custom-integrations/bin /var/db/newrelic-infra/custom-integrations Windows C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations\\bin C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations If there is no executable with this name in the above folders the agent logs an error and the integration is not executed. Important In Windows, do not append the .exe extension to the name. The agent does this for you (for example, name: nri-mysql would look for nri-mysql.exe in the above folders). exec The exec optional property specifies the path, command, and command-line arguments of the integration to execute. When none of the path folders or arguments have spaces, it can be written in a single-line string: - name: my-integration exec: /usr/bin/python /opt/integrations/my-script.py --host=127.0.0.1 Copy If any of the path/arguments have spaces that are part of a single element, you can use a YAML array notation: - name: my-integration exec: - C:\\Program Files\\My Integration\\integration.exe - --host - 127.0.0.1 - --port - 8080 Copy The default working directory is the root directory of the agent configuration. It can be overridden with the working_dir property. cli_args The cli_args optional property specifies command line arguments that should be passed to the integration. It is useful when using name as it only provides the integration name identifier (not compatible with exec). - name: my-integration cli_args: [ -interval 10s ] Copy Usual YAML multi-line list format can be used as well: - name: my-integration cli_args: - -interval - 10s Copy when The when property allows to execute the integration only when all the evaluated conditions are successful. Available conditions are: env_exists: Environment variables exist and match value. file_exists: Given file path exists. feature: Provided feature-flag is enabled. Example: integrations: - name: ssh-integration when: file_exists: /var/run/sshd.pid Copy Pass configuration to the integration executable Often integration executables need to receive a configuration to work properly (for example, hostname and port of the monitored system, user credentials, etc.). The Infrastructure agent allows you to configure the integration commands in three ways (which you can combine): Command-line arguments, passed in the exec property. Environment variables, using the env property. Configuration files, whose path needs to be passed through environment variables or command-line arguments (see the config) property. Example: integrations: - name: my-integration exec: /opt/path/bin/script --host 127.0.0.1 --port 8081 - name: nri-mysql env: STATUS_URL: http://10.0.0.3/server-status?auto REMOTE_MONITORING: true Copy env The env property allows you to set environment variables that are passed to the executable. It is a key-value map with the required variables. Example: integrations: - name: nri-postgresql env: DATABASE: postgres PORT: 6432 COLLECTION_LIST: '[\"postgres\"]' COLLECT_DB_LOCK_METRICS: false VERBOSE: 1 Copy If you expect your integration to receive the configuration from the host's environment rather than specifying it explicitly in the configuration file, you need to set the required variables in the Infrastructure agent passthrough_environment global configuration property config This section describes various ways to pass configuration information to an integration. Pass configuration file directly Some integration commands may get their configuration from an external file. If your integration requires a configuration file, nothing prevents you from directly passing its path directly as a command-line argument or an environment variable. Here's an example using configuration of our Flex integration: integrations: - name: nri-flex env: CONFIG_FILE: /etc/nri-flex/configs/http-service.yaml - name: other-integration exec: /opt/integration/integration -f /opt/integration/config.properties Copy The above example assumes that the http-service.yaml and config.properties files exist. We can see that the nri-flex integration is expecting the http-service.yaml complete path via the CONFIG_FILE environment variable and the other-integration expects the complete config.properties path after the -f command-line flag. In the above example, it's necessary for the integration installer/configurator that the configuration files exist in the provided path and that the agent and integrations have read permissions on them. Pass configuration through config section If you prefer to keep your configuration file with the rest of the integration configuration, you can use the config section in the integration entry, which can contain a valid YAML object or just a multi-line string: integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv - name: other-integration exec: /opt/integration/integration -f ${config.path} config: | example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostname=localhost example.cfg.port=9025 Copy In the above examples, every time the nri-flex integration is executed, the agent creates a temporary file with the following contents: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy The above YAML is only a configuration example for the nri-flex integration. The agent ignores its contents; instead, it creates a temporary file and replaces the ${config.path} variable placeholder with its path. When the integration completes execution the temporary file is removed. Also, the agent creates another temporary file before executing the other-integration integration: example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostid=localhost example.cfg.port=9025 Copy It replaces the -f ${config.path} command-line placeholder with the temporary path of the written file. By convention, if you do not place the ${config.path} variable in any command-line argument or environment variable value, the agent passes the path of the configuration file via the CONFIG_PATH environment variable: # assuming that nri-example command is prepared to receive the configuration # file via the CONFIG_PATH environment variable integrations: - name: nri-example config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy Pass secrets and discovery through config section The main benefit for using a config section instead of hardcoding the full path of an external file is that you can insert ${variable} placeholders to apply our auto-discovery feature and secrets management. Here's an example followed by some explanations: variables: my_credentials: vault: http: url: http://my.vault.host/v1/newengine/data/secret headers: X-Vault-Token: my-vault-token discovery: docker: match: label.service: foo integrations: - name: foo-monitor exec: /opt/foo/bin/monitor --config=${config.path} config: | foo.host=${discovery.ip} foo.port=${discovery.port} foo.user=${my_credentials.user} foo.password=${my_credentials.password} Copy Tip (For more details about the variables and discovery sections, please visit the discovery and secrets management documentation). The above example relies on the following premises: There is a Vault service that allows retrieving a JSON object formed by the user and password fields. There may be a variable number of Docker containers labeled with service=foo, which are accessible from the agent host via a discoverable public IP and Port. The user has configured the foo-monitor integration to monitor all the service=foo labeled containers, which share a common user and password. Each instance of the foo-monitor integration requires executing the /opt/foo/bin/monitor executable, passing the text configuration inside the config section via the --config=<path> command-line argument. As example of workflow, imagine that the Vault invocation returns the following JSON: {\"user\":\"monitorer\",\"password\":\"5up3r53cr3t!\"} Copy At the moment of executing the foo-monitor integration, there are three running containers labeled with service=foo: ip: 10.0.0.3, port: 8080 ip: 10.0.0.3, port: 8081 ip: 10.0.0.3, port: 8082 The agent then creates the following three temporary files, using the contents of the config property as a template, but replacing the ${placeholders} by the acquired variables and discovered items (files' path is invented for the sake of simplicity): First match (/tmp/123_discovered): foo.host=10.0.0.3 foo.port=8080 foo.user=monitorer foo.password=5up3r53cr3t! Copy Second match (/tmp/456_discovered): foo.host=10.0.0.3 foo.port=8081 foo.user=monitorer foo.password=5up3r53cr3t! Copy Third match (/tmp/789_discovered) foo.host=10.0.0.3 foo.port=8082 foo.user=monitorer foo.password=5up3r53cr3t! Copy After the config variable placeholders have been replaced and the temporary files have been created, the /opt/foo/bin/monitor executable is executed three times (one per matched container), replacing the ${config.path} command-line placeholder with the temporary file corresponding to each discovered configuration: First match: /opt/foo/bin/monitor --config=/tmp/123_discovered Second match: /opt/foo/bin/monitor --config=/tmp/456_discovered Third match: /opt/foo/bin/monitor --config=/tmp/789_discovered To ensure security and to minimize the chance of leaking secrets to disk, the agent: Creates the files owned by the agent user, for example, root or nri-agent, depending on the user you have configured to run the agent. Sets read permissions only for the owner. Removes the created files when the integration instance finishes its execution. config_template_path If you want to use the secrets management and discovery in the configuration files that you're passing to the integration executable, but you prefer to keep them as an individual file, you can use the config_template_path: <path> option. It works exactly as in the config section: The agent applies secrets management and discovery to the file contents. The agent creates different temporary files that are passed to the integration via the ${config.path} placeholder (or the CONFIG_PATH environment variable). Example: discovery: docker: match: name: /^redis/ integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config_template_path: /etc/flex-configs/redis.yml Copy In the above example, the redis.yml external file can contain container discovery variable placeholders, like ${discovery.ip} or ${discovery.port}. Configure how the agent executes your integrations The properties of this section modify the way the Infrastructure agent executes and interacts with the integrations, or the way the agent decorates the integrations' data. integration_user The integration commands run as the same user as the agent (usually root or nri-agent). If due to permission restrictions an integration needs to run as another user, its name must be specified in the integration_user property. Example: integrations: - name: dbus-inventory exec: python my-dbus-script.py integration_user: dbus Copy interval The interval option sets the time between consecutive executions of an integration. The accepted format is an integer immediately followed by a time unit (s for seconds, m for minutes, h for hours). The default is 30s, and the minimum accepted value is 15s. Any value lower than 15s is automatically set to 15s. Example: integrations: - name: nri-nginx env: STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover interval: 20s Copy inventory_source Any inventory item must be catalogued under a category/source taxonomy. By default, each integration inventory is stored as integration/ + name value (for example, integration/nri-apache, integration/nri-mysql). The inventory_source property allows you to override the default taxonomy of inventory data. Example: integrations: - name: nri-nginx - name: nri-apache exec: - /var/db/newrelic-infra/newrelic-integrations/bin/nri-apache - --inventory inventory_source: config/apache Copy In the above example, the nri-nginx inventory, if any, would be visible in the New Relic UI under the integration/nri-nginx source. The nri-apache inventory would be visible under config/apache. labels labels is a key-value map that allows extra metadata to be provided for the integration. The agent uses those labels to decorate the metrics, events, and inventory that it receives from a given integration instance. Example: integrations: - name: nri-apache inventory_source: config/apache labels: env: production role: load_balancer Copy In the above example, the agent decorates all the metrics and events from the nri-apache instance with the following fields: label.env: production label.role: load_balancer Also, the following entries are added to the integration inventory: config/apache/labels/env: production config/apache/labels/role: load_balancer timeout If an integration has not returned any metric (or a heartbeat message as described below) before the time specified in the timeout value, the agent kills the integration process and restarts it after the corresponding interval. The accepted format is an integer number immediately followed (without spaces) by a time unit (ms for milliseconds, s for seconds, m for minutes, h for hours). If a zero (or negative) timeout value is provided, the integration can run forever without being killed by a timeout expiration. For long-running integrations (integrations that keep running, periodically returning metrics/events/inventory), each time the integration submits a metrics/events/inventory payload, the timeout deadline is restarted. That means that long-running integrations must return a valid JSON payload in an interval that is lower than timeout. Returning an empty JSON ({}) is interpreted as a heart-beat message that restarts the timeout, preventing the long-running integration from being killed, even if they don't have information to report. The default is 120s, and the minimum accepted value is 100ms. Any value lower than 100ms is automatically set to 100ms. Example: integrations: - name: nri-jmx arguments: JMX_HOST: jmx-host.localnet JMX_PORT: 7096 COLLECTION_FILES: \"/etc/newrelic-infra/integrations.d/jvm-metrics.yml\" timeout: 30s Copy working_dir working_dir sets the working directory of the command. If empty or unspecified, the agent runs the command in the Infrastructure agent's current directory. The default is the Infrastructure agent root directory. Example: integrations: - name: my-integration exec: /opt/integration/bin/integration working_dir: /opt/integration/scratch-zone Copy Update older integration configuration In December 2019, the Infrastructure agent version 1.8.0 began using a different configuration format. For details, see Config format differences. The main difference between these formats is that the older configuration format uses two separate configuration files (a INTEGRATION_NAME-definition.yml file and a INTEGRATION_NAME-config.yml file) and the newer version uses a single configuration file. Here are some of the features added by the newer configuration functionality: Flexible configuration via command-line arguments, environment variables, or external files. Ability to group different integrations in the same file. Hot reload: adding a new integration or changing its configuration does not require restarting the agent. Timeouts: if an integration doesn't respond before a user-specified time, the integration process is killed and restarted. Not all on-host integrations come with the newer configuration format, but you can update the configuration to the new format for all on-host integrations to take advantage of the new features. The following YAML shows an example Apache integration configuration using the older configuration format. Note that this configuration will still work with newer agents, but we recommend updating your integrations to take full advantage of features. integration_name: com.newrelic.apache instances: - name: apache-server-metrics command: metrics arguments: status_url: http://127.0.0.1/server-status?auto remote_monitoring: true labels: env: production role: load_balancer - name: apache-server-inventory command: inventory arguments: remote_monitoring: true labels: env: production role: load_balancer Copy To update an older integration configuration to the new format, you must perform two steps: Rename the instances top-level section to integrations. Remove the integration_name top-level section and add it to each integration entry. You are no longer required to keep a separate file for each integration type and you can group your legacy integration entries in the same file as other integrations. The new version of the Apache integration config: integrations: - name: apache-server-metrics integration_name: com.newrelic.apache command: metrics arguments: status_url: http://127.0.0.1/server-status?auto remote_monitoring: true labels: env: production role: load_balancer - name: apache-server-inventory integration_name: com.newrelic.apache command: inventory arguments: remote_monitoring: true labels: env: production role: load_balancer Copy Please note that because the older configuration format doesn't support hot reloading. You will need to restart the Infrastructure agent to remove the old integrations configuration (otherwise the old instances will coexist with the new ones).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.27914,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Newer configuration format ",
        "sections": "On-host <em>integrations</em>: Newer configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic <em>Infrastructure</em> on-host <em>integrations</em> can use one of two types of configuration formats. In December 2019, <em>Infrastructure</em> agent version 1.8.0 began supporting a newer configuration format that makes use of a single configuration file (instead of two separate files), and provides other"
      },
      "id": "603e923928ccbcb8dfeba751"
    }
  ],
  "/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-files": [
    {
      "sections": [
        "Compatibility and requirements for Infrastructure Integrations SDK",
        "Infrastructure version",
        "Operating systems",
        "Data and file specifications",
        "SDK version changes"
      ],
      "title": "Compatibility and requirements for Infrastructure Integrations SDK",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Get started"
      ],
      "external_id": "ea949057459c7c9648a9215928c1fd54c9d6a703",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/get-started/compatibility-requirements-infrastructure-integrations-sdk/",
      "published_at": "2021-06-14T22:22:04Z",
      "updated_at": "2021-03-13T02:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before using the New Relic Infrastructure integrations SDK to create a custom on-host integration, make sure your system meets these requirements. Infrastructure version To use the infrastructure Integrations SDK v4, you must have the Infrastructure agent version 1.13.0 or higher. To use SDK v3, you must have agent version 1.0.888 or higher. For Infrastructure agent version information and options for installation and updates, see the Infrastructure release notes. For notes on SDK versions and changes, see the change log. Operating systems Integrations built with the SDK can be compiled for either Linux or Windows operating systems. Data and file specifications Infrastructure on-host integrations can be created with any programming language, as long as they adhere to the data and file specifications. SDK version changes Infrastructure agent version Details 1.13.0 or higher Changes to integration protocol (v4), including support to dynamically register entities in NR1 and send dimensional metrics. New metric types. See SDK v4 release notes. 1.0.888 or higher Changes to JSON format, including support for multiple entities. The new JSON format is referred to as protocol 2 (described in JSON output documentation and also used in the definition file). Uses newer set of Go language build tools (referenced as GoSDK v3). 1.0.726 (for Linux); 1.0.775 (for Windows) Uses JSON protocol 1 (described in JSON output documentation and also used in the definition file). Uses older set of Go language build tools (referenced as GoSDK v2). If you've built an integration using the older Go language build tools and wish to update, see Upgrade from GoSDK v2 to v3 and Upgrade from v3 to v4. For updating the Infrastructure agent, see Update the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.227,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "sections": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "Before using the New Relic <em>Infrastructure</em> <em>integrations</em> <em>SDK</em> to <em>create</em> a custom on-host integration, make sure your system meets these requirements. <em>Infrastructure</em> version To use the <em>infrastructure</em> <em>Integrations</em> <em>SDK</em> v4, you must have the <em>Infrastructure</em> agent version 1.13.0 or higher. To use <em>SDK</em> v3"
      },
      "id": "60440de564441fa14f378ecc"
    },
    {
      "sections": [
        "On-host integrations: Newer configuration format",
        "Configuration structure",
        "Tip",
        "Important",
        "List of configuration properties",
        "Select an integration to run",
        "name",
        "exec",
        "cli_args",
        "when",
        "Pass configuration to the integration executable",
        "env",
        "config",
        "config_template_path",
        "Configure how the agent executes your integrations",
        "integration_user",
        "interval",
        "inventory_source",
        "labels",
        "timeout",
        "working_dir",
        "Update older integration configuration"
      ],
      "title": "On-host integrations: Newer configuration format ",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "bc5bee12812cff6fabc728961e1b342b83f3e471",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-newer-configuration-format/",
      "published_at": "2021-06-14T22:22:47Z",
      "updated_at": "2021-03-16T07:30:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Infrastructure on-host integrations can use one of two types of configuration formats. In December 2019, Infrastructure agent version 1.8.0 began supporting a newer configuration format that makes use of a single configuration file (instead of two separate files), and provides other improvements. This document will explain how this newer format works. The older standard configuration format is supported by current Infrastructure agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration's configuration YAML must have an integrations top-level section containing a YAML array, where each entry represents an integration and its configuration. For each integration entry, only the name property is mandatory. The other properties are optional. Here's an example configuration featuring two integrations: our built-in Docker integration, which requires no configuration, and our MySQL integration: integrations: # New Relic integration that does not require any configuration - name: nri-docker # New Relic integration that gets its configuration from the environment - name: nri-mysql env: PORT: 3306 USERNAME: newrelic PASSWORD: 123456789 # to hide this field, read the secrets management documentation # Any free-form integration executed via a user-provided command - name: my-own-integration exec: python /opt/integrations/my-script.py --host=127.0.0.1 Copy You can have as many configuration YAML files as you want and can group your integration instances. Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Each configuration YAML file can also contain discovery and variables top-level sections. Important This configuration format does not require an agent restart. When saved, changes are detected and implemented immediately. This means that saving intermediate configuration changes may cause the integration to stop working. List of configuration properties This is a list of the general properties used to configure an integration. For more details about using these properties, including example values, see the documentation following the table. Config Description name Name of the integration. This is the only mandatory configuration property across all on-host integrations. If the exec field is not set it will also be the name of the integration executable. cli_args Optional list of command line arguments when name is used to provide the integration executable. Available since agent version 1.13.0. exec Full path to the integration executable, plus arguments. It may be a single-line string or a string array. If left unspecified, the exec field defaults to the name field. env YAML map containing the environment variables to be passed to the integration, where key is the environment variable name, and value is the variable value. config Configuration that is written as an external file and the path that is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. config_template_path Any external file whose path is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. Its usage allows applying discovery and secrets binding to any external configuration. integration_user Name of the user who runs the integration. interval Time between consecutive executions of the integration. It must be a number followed by a time unit (s, m or h), without spaces. inventory_source Allows overriding the category and term of the inventory source. labels Map with labels that decorate the data (metrics, events, inventory) reported by the integration. timeout A number followed by a time unit (ms, s, m or h). An integration that hasn't responded in this time period is killed and restarted. working_dir Working directory for the integration binary. when Integration is only executed if the clause evaluates to true. Conditions are defined below. The remainder of this document describes config properties grouped by their functionality: Select an integration to run Pass configuration to the integration command Configure how the agent executes integrations Select an integration to run There are two properties to select which integration will run: name and exec. The only mandatory property across all on-host integrations is name. The remaining properties specified in this document are optional. Example: integrations: - name: nri-docker - name: my-integration exec: /usr/local/bin/my-integration --metrics --inventory Copy name The mandatory name property can work in two ways: If the exec property is set: The name property only provides an identifier for the integration instance. This identifier is used in log messages and to provide a default inventory category/source in the form integration/<name> (for example, integration/nri-redis). This inventory path can be overridden with the inventory_source configuration option. If the exec property is not set: The agent looks for (and executes) an executable with the name value in any of the following folders: Linux: /var/db/newrelic-infra/newrelic-integrations/bin /var/db/newrelic-infra/newrelic-integrations /var/db/newrelic-infra/custom-integrations/bin /var/db/newrelic-infra/custom-integrations Windows C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations\\bin C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations If there is no executable with this name in the above folders the agent logs an error and the integration is not executed. Important In Windows, do not append the .exe extension to the name. The agent does this for you (for example, name: nri-mysql would look for nri-mysql.exe in the above folders). exec The exec optional property specifies the path, command, and command-line arguments of the integration to execute. When none of the path folders or arguments have spaces, it can be written in a single-line string: - name: my-integration exec: /usr/bin/python /opt/integrations/my-script.py --host=127.0.0.1 Copy If any of the path/arguments have spaces that are part of a single element, you can use a YAML array notation: - name: my-integration exec: - C:\\Program Files\\My Integration\\integration.exe - --host - 127.0.0.1 - --port - 8080 Copy The default working directory is the root directory of the agent configuration. It can be overridden with the working_dir property. cli_args The cli_args optional property specifies command line arguments that should be passed to the integration. It is useful when using name as it only provides the integration name identifier (not compatible with exec). - name: my-integration cli_args: [ -interval 10s ] Copy Usual YAML multi-line list format can be used as well: - name: my-integration cli_args: - -interval - 10s Copy when The when property allows to execute the integration only when all the evaluated conditions are successful. Available conditions are: env_exists: Environment variables exist and match value. file_exists: Given file path exists. feature: Provided feature-flag is enabled. Example: integrations: - name: ssh-integration when: file_exists: /var/run/sshd.pid Copy Pass configuration to the integration executable Often integration executables need to receive a configuration to work properly (for example, hostname and port of the monitored system, user credentials, etc.). The Infrastructure agent allows you to configure the integration commands in three ways (which you can combine): Command-line arguments, passed in the exec property. Environment variables, using the env property. Configuration files, whose path needs to be passed through environment variables or command-line arguments (see the config) property. Example: integrations: - name: my-integration exec: /opt/path/bin/script --host 127.0.0.1 --port 8081 - name: nri-mysql env: STATUS_URL: http://10.0.0.3/server-status?auto REMOTE_MONITORING: true Copy env The env property allows you to set environment variables that are passed to the executable. It is a key-value map with the required variables. Example: integrations: - name: nri-postgresql env: DATABASE: postgres PORT: 6432 COLLECTION_LIST: '[\"postgres\"]' COLLECT_DB_LOCK_METRICS: false VERBOSE: 1 Copy If you expect your integration to receive the configuration from the host's environment rather than specifying it explicitly in the configuration file, you need to set the required variables in the Infrastructure agent passthrough_environment global configuration property config This section describes various ways to pass configuration information to an integration. Pass configuration file directly Some integration commands may get their configuration from an external file. If your integration requires a configuration file, nothing prevents you from directly passing its path directly as a command-line argument or an environment variable. Here's an example using configuration of our Flex integration: integrations: - name: nri-flex env: CONFIG_FILE: /etc/nri-flex/configs/http-service.yaml - name: other-integration exec: /opt/integration/integration -f /opt/integration/config.properties Copy The above example assumes that the http-service.yaml and config.properties files exist. We can see that the nri-flex integration is expecting the http-service.yaml complete path via the CONFIG_FILE environment variable and the other-integration expects the complete config.properties path after the -f command-line flag. In the above example, it's necessary for the integration installer/configurator that the configuration files exist in the provided path and that the agent and integrations have read permissions on them. Pass configuration through config section If you prefer to keep your configuration file with the rest of the integration configuration, you can use the config section in the integration entry, which can contain a valid YAML object or just a multi-line string: integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv - name: other-integration exec: /opt/integration/integration -f ${config.path} config: | example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostname=localhost example.cfg.port=9025 Copy In the above examples, every time the nri-flex integration is executed, the agent creates a temporary file with the following contents: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy The above YAML is only a configuration example for the nri-flex integration. The agent ignores its contents; instead, it creates a temporary file and replaces the ${config.path} variable placeholder with its path. When the integration completes execution the temporary file is removed. Also, the agent creates another temporary file before executing the other-integration integration: example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostid=localhost example.cfg.port=9025 Copy It replaces the -f ${config.path} command-line placeholder with the temporary path of the written file. By convention, if you do not place the ${config.path} variable in any command-line argument or environment variable value, the agent passes the path of the configuration file via the CONFIG_PATH environment variable: # assuming that nri-example command is prepared to receive the configuration # file via the CONFIG_PATH environment variable integrations: - name: nri-example config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy Pass secrets and discovery through config section The main benefit for using a config section instead of hardcoding the full path of an external file is that you can insert ${variable} placeholders to apply our auto-discovery feature and secrets management. Here's an example followed by some explanations: variables: my_credentials: vault: http: url: http://my.vault.host/v1/newengine/data/secret headers: X-Vault-Token: my-vault-token discovery: docker: match: label.service: foo integrations: - name: foo-monitor exec: /opt/foo/bin/monitor --config=${config.path} config: | foo.host=${discovery.ip} foo.port=${discovery.port} foo.user=${my_credentials.user} foo.password=${my_credentials.password} Copy Tip (For more details about the variables and discovery sections, please visit the discovery and secrets management documentation). The above example relies on the following premises: There is a Vault service that allows retrieving a JSON object formed by the user and password fields. There may be a variable number of Docker containers labeled with service=foo, which are accessible from the agent host via a discoverable public IP and Port. The user has configured the foo-monitor integration to monitor all the service=foo labeled containers, which share a common user and password. Each instance of the foo-monitor integration requires executing the /opt/foo/bin/monitor executable, passing the text configuration inside the config section via the --config=<path> command-line argument. As example of workflow, imagine that the Vault invocation returns the following JSON: {\"user\":\"monitorer\",\"password\":\"5up3r53cr3t!\"} Copy At the moment of executing the foo-monitor integration, there are three running containers labeled with service=foo: ip: 10.0.0.3, port: 8080 ip: 10.0.0.3, port: 8081 ip: 10.0.0.3, port: 8082 The agent then creates the following three temporary files, using the contents of the config property as a template, but replacing the ${placeholders} by the acquired variables and discovered items (files' path is invented for the sake of simplicity): First match (/tmp/123_discovered): foo.host=10.0.0.3 foo.port=8080 foo.user=monitorer foo.password=5up3r53cr3t! Copy Second match (/tmp/456_discovered): foo.host=10.0.0.3 foo.port=8081 foo.user=monitorer foo.password=5up3r53cr3t! Copy Third match (/tmp/789_discovered) foo.host=10.0.0.3 foo.port=8082 foo.user=monitorer foo.password=5up3r53cr3t! Copy After the config variable placeholders have been replaced and the temporary files have been created, the /opt/foo/bin/monitor executable is executed three times (one per matched container), replacing the ${config.path} command-line placeholder with the temporary file corresponding to each discovered configuration: First match: /opt/foo/bin/monitor --config=/tmp/123_discovered Second match: /opt/foo/bin/monitor --config=/tmp/456_discovered Third match: /opt/foo/bin/monitor --config=/tmp/789_discovered To ensure security and to minimize the chance of leaking secrets to disk, the agent: Creates the files owned by the agent user, for example, root or nri-agent, depending on the user you have configured to run the agent. Sets read permissions only for the owner. Removes the created files when the integration instance finishes its execution. config_template_path If you want to use the secrets management and discovery in the configuration files that you're passing to the integration executable, but you prefer to keep them as an individual file, you can use the config_template_path: <path> option. It works exactly as in the config section: The agent applies secrets management and discovery to the file contents. The agent creates different temporary files that are passed to the integration via the ${config.path} placeholder (or the CONFIG_PATH environment variable). Example: discovery: docker: match: name: /^redis/ integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config_template_path: /etc/flex-configs/redis.yml Copy In the above example, the redis.yml external file can contain container discovery variable placeholders, like ${discovery.ip} or ${discovery.port}. Configure how the agent executes your integrations The properties of this section modify the way the Infrastructure agent executes and interacts with the integrations, or the way the agent decorates the integrations' data. integration_user The integration commands run as the same user as the agent (usually root or nri-agent). If due to permission restrictions an integration needs to run as another user, its name must be specified in the integration_user property. Example: integrations: - name: dbus-inventory exec: python my-dbus-script.py integration_user: dbus Copy interval The interval option sets the time between consecutive executions of an integration. The accepted format is an integer immediately followed by a time unit (s for seconds, m for minutes, h for hours). The default is 30s, and the minimum accepted value is 15s. Any value lower than 15s is automatically set to 15s. Example: integrations: - name: nri-nginx env: STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover interval: 20s Copy inventory_source Any inventory item must be catalogued under a category/source taxonomy. By default, each integration inventory is stored as integration/ + name value (for example, integration/nri-apache, integration/nri-mysql). The inventory_source property allows you to override the default taxonomy of inventory data. Example: integrations: - name: nri-nginx - name: nri-apache exec: - /var/db/newrelic-infra/newrelic-integrations/bin/nri-apache - --inventory inventory_source: config/apache Copy In the above example, the nri-nginx inventory, if any, would be visible in the New Relic UI under the integration/nri-nginx source. The nri-apache inventory would be visible under config/apache. labels labels is a key-value map that allows extra metadata to be provided for the integration. The agent uses those labels to decorate the metrics, events, and inventory that it receives from a given integration instance. Example: integrations: - name: nri-apache inventory_source: config/apache labels: env: production role: load_balancer Copy In the above example, the agent decorates all the metrics and events from the nri-apache instance with the following fields: label.env: production label.role: load_balancer Also, the following entries are added to the integration inventory: config/apache/labels/env: production config/apache/labels/role: load_balancer timeout If an integration has not returned any metric (or a heartbeat message as described below) before the time specified in the timeout value, the agent kills the integration process and restarts it after the corresponding interval. The accepted format is an integer number immediately followed (without spaces) by a time unit (ms for milliseconds, s for seconds, m for minutes, h for hours). If a zero (or negative) timeout value is provided, the integration can run forever without being killed by a timeout expiration. For long-running integrations (integrations that keep running, periodically returning metrics/events/inventory), each time the integration submits a metrics/events/inventory payload, the timeout deadline is restarted. That means that long-running integrations must return a valid JSON payload in an interval that is lower than timeout. Returning an empty JSON ({}) is interpreted as a heart-beat message that restarts the timeout, preventing the long-running integration from being killed, even if they don't have information to report. The default is 120s, and the minimum accepted value is 100ms. Any value lower than 100ms is automatically set to 100ms. Example: integrations: - name: nri-jmx arguments: JMX_HOST: jmx-host.localnet JMX_PORT: 7096 COLLECTION_FILES: \"/etc/newrelic-infra/integrations.d/jvm-metrics.yml\" timeout: 30s Copy working_dir working_dir sets the working directory of the command. If empty or unspecified, the agent runs the command in the Infrastructure agent's current directory. The default is the Infrastructure agent root directory. Example: integrations: - name: my-integration exec: /opt/integration/bin/integration working_dir: /opt/integration/scratch-zone Copy Update older integration configuration In December 2019, the Infrastructure agent version 1.8.0 began using a different configuration format. For details, see Config format differences. The main difference between these formats is that the older configuration format uses two separate configuration files (a INTEGRATION_NAME-definition.yml file and a INTEGRATION_NAME-config.yml file) and the newer version uses a single configuration file. Here are some of the features added by the newer configuration functionality: Flexible configuration via command-line arguments, environment variables, or external files. Ability to group different integrations in the same file. Hot reload: adding a new integration or changing its configuration does not require restarting the agent. Timeouts: if an integration doesn't respond before a user-specified time, the integration process is killed and restarted. Not all on-host integrations come with the newer configuration format, but you can update the configuration to the new format for all on-host integrations to take advantage of the new features. The following YAML shows an example Apache integration configuration using the older configuration format. Note that this configuration will still work with newer agents, but we recommend updating your integrations to take full advantage of features. integration_name: com.newrelic.apache instances: - name: apache-server-metrics command: metrics arguments: status_url: http://127.0.0.1/server-status?auto remote_monitoring: true labels: env: production role: load_balancer - name: apache-server-inventory command: inventory arguments: remote_monitoring: true labels: env: production role: load_balancer Copy To update an older integration configuration to the new format, you must perform two steps: Rename the instances top-level section to integrations. Remove the integration_name top-level section and add it to each integration entry. You are no longer required to keep a separate file for each integration type and you can group your legacy integration entries in the same file as other integrations. The new version of the Apache integration config: integrations: - name: apache-server-metrics integration_name: com.newrelic.apache command: metrics arguments: status_url: http://127.0.0.1/server-status?auto remote_monitoring: true labels: env: production role: load_balancer - name: apache-server-inventory integration_name: com.newrelic.apache command: inventory arguments: remote_monitoring: true labels: env: production role: load_balancer Copy Please note that because the older configuration format doesn't support hot reloading. You will need to restart the Infrastructure agent to remove the old integrations configuration (otherwise the old instances will coexist with the new ones).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.27914,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Newer configuration format ",
        "sections": "On-host <em>integrations</em>: Newer configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic <em>Infrastructure</em> on-host <em>integrations</em> can use one of two types of configuration formats. In December 2019, <em>Infrastructure</em> agent version 1.8.0 began supporting a newer configuration format that makes use of a single configuration file (instead of two separate files), and provides other"
      },
      "id": "603e923928ccbcb8dfeba751"
    },
    {
      "sections": [
        "On-host integrations: Standard configuration format",
        "Configuration file structure",
        "Definition file",
        "Definition file header",
        "Definition file commands",
        "Configuration file",
        "Tip",
        "Config file field definitions"
      ],
      "title": "On-host integrations: Standard configuration format",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "3b4c5ab77b2b8025ca8de375403f24bc75b3dca7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format/",
      "published_at": "2021-06-14T22:23:44Z",
      "updated_at": "2021-03-16T07:30:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Infrastructure on-host integrations can use one of two types of configuration formats. This document explains the older, standard configuration format. This format is used by most on-host integrations and is supported by newer Infrastructure agents (which also support a newer, improved configuration format). For an introduction to configuration, see Config overview. Configuration file structure An on-host integration that uses the standard configuration format requires two configuration files: A definition file A configuration file Definition file The definition file has a naming format like INTEGRATION_NAME-definition.yml. This file provides descriptive information about the integration, such as: the version of the JSON protocol it supports, a list of commands it can execute, and arguments that it accepts. It lives in this directory: Linux: /var/db/newrelic-infra/newrelic-integrations Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations Copy Here's an example of an NGINX integration definition file with two command sections on a Linux system: name: com.myorg.nginx protocol_version: 2 description: Collect metric and configuration data from NGINX os: linux commands: metrics: command: - myorg-nginx - --metrics interval: 15 inventory: command: - myorg-nginx - --inventory interval: 120 prefix: integration/myorg-nginx Copy A definition file can be broken down into two parts: The header The commands section Definition file header Here are explanations of a definition file's header elements: Definition header field Description name Required. A unique name name to identify the integration for logging, internal metrics, etc. When the agent loads the config file, New Relic uses the name to look up the integration in the agent's registry. protocol_version Required. The version number of the protocol. New Relic uses this to ensure compatibility between the integration and the agent. If the agent does not recognize an integration's version, it will filter out that integration and create a log message. The current version of the JSON protocol is 2. For more on protocol changes, see SDK changes. description Optional. Human-friendly explanation of what the integration does. os Optional. The operating system where the integration runs. New Relic uses this to filter integrations that you intend to run only on specific operating systems. Default: Run the integration regardless of the os value. To restrict the integration to a specific operating system, use either of these options: linux windows Definition file commands After the header is a list of commands. The commands section defines: One or more independent operating modes for the executable The runtime data required for it to be executed The commands section is a YAML map of command definitions, where each key is the unique alias name of the command in the integration's config file that specifies the executable to run. Definition commands Description command Required. The actual command line to be executed as a YAML array of command parts. These are assembled to run the actual command. For simple commands, the array might be only a single element. Additional command rules include: command arguments: The command and any command line arguments that are shared for all instances of the integration configuration. command execution: The command will be executed in the same directory as the definition file. command path: Any commands available on the host's $PATH can be used. Executables located in the same directory as the definition file, or in a subdirectory of it, can be executed using a relative path. For example: Linux: To run an executable called myorg-nginx in the same directory as the definition file, you could use myorg-nginx or ./myorg-nginx. Linux systems will execute myorg-nginx as if the user used ./myorg-nginx. Windows: To run an executable called myorg-nginx.exe in the same directory as the definition file, you could use \\myorg-nginx.exe or .\\myorg-nginx.exe. Windows systems writing myorg-nginx.exe will be executed as if indicating the current path: .\\myorg-nginx.exe. To use a command installed inside a directory on the host's $PATH, simply use the command name. Example: python. To run any other executable which is neither on the host's $PATH nor within the integration's directory, use an absolute path to the executable. Example: /opt/jdk/bin/java. If the given executable name exists within the integration's directory but also exists elsewhere on the system $PATH, the version in the integration's directory takes precedence. interval Optional. The number of seconds between two consecutive executions of the command, in particular between the end of the previous execution and the start of the next execution. Default for metric polling: 30 seconds. Minimum (floor): 15 seconds. Alerts: For metrics being used for alerts, use an interval of 30 seconds or less. prefix Optional. The categorization of the inventory in the form of category/short_integration_name. Example: integration/myorg-nginx. The prefix is not a platform-specific path. The forward slash is the correct separator between the category and short_integration_name. The prefix can have a maximum of two levels. Otherwise inventory will not be reported. Default value if not set: integration/integration_name. Configuration file The configuration file has a naming format like INTEGRATION_NAME-config.yml. This file specifies which executables to run and the parameters required to run them. It lives in this directory: Linux: /etc/newrelic-infra/integrations.d/ Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d Copy Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Here's an example of a config file with one instance defined. Explanations of these fields are explained below the example. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://127.0.0.1/status labels: environment: production role: load_balancer Copy Another example of a config file with two instances defined. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://one.url/status labels: environment: production role: load_balancer - name: nginx2.myorg.com-metrics command: metrics arguments: status_url: http://another.url/status labels: environment: production role: load_balancer Copy Config file field definitions Config file field Description integration_name Required. This is the header and is used to identify which executables to run. This name must exactly match the name specified in the integration's definition file. Recommendation: To ensure unique names, use reverse domain name notation. name Required. This is the name for the specific invocation (instance) of the integration. This is used to help identify any log messages generated by this integration and is also useful for troubleshooting. command Required. This is the command to be executed. This must exactly match one of the unique alias names specified in the integration's definition file. arguments Optional. A YAML object where: Keys: The argument name. Transformed to upper case when set as environment variable. Values: The argument values. Passed through as is. The arguments are made available to an integration as a set of environment variables. Arguments in the config file cannot be capitalised and should use underscores to separate words. labels Optional. A YAML object where: Keys: The label name. Values: The defined label value. integration_user Optional. String with the name the agent will use for executing the integration binary. Default: depends on the usermode. By default, integrations are executed with the same user that's running the integration agent, nri-agent for privileged and unprivileged mode and root user for root mode. When present, the Infrastructure agent will execute the integration binary as the specified user. For example, to run the integration binary as the root user when running the agent in a usermode different than root, just add integration_user: root to the configuration file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.27914,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Standard configuration format",
        "sections": "On-host <em>integrations</em>: Standard configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic <em>Infrastructure</em> on-host <em>integrations</em> can use one of two types of configuration formats. This document explains the older, standard configuration format. This format is used by most on-host <em>integrations</em> and is supported by newer <em>Infrastructure</em> agents (which also support a newer, improved"
      },
      "id": "603e923a196a67581ca83db3"
    }
  ],
  "/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-newer-configuration-format": [
    {
      "sections": [
        "Compatibility and requirements for Infrastructure Integrations SDK",
        "Infrastructure version",
        "Operating systems",
        "Data and file specifications",
        "SDK version changes"
      ],
      "title": "Compatibility and requirements for Infrastructure Integrations SDK",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Get started"
      ],
      "external_id": "ea949057459c7c9648a9215928c1fd54c9d6a703",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/get-started/compatibility-requirements-infrastructure-integrations-sdk/",
      "published_at": "2021-06-14T22:22:04Z",
      "updated_at": "2021-03-13T02:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before using the New Relic Infrastructure integrations SDK to create a custom on-host integration, make sure your system meets these requirements. Infrastructure version To use the infrastructure Integrations SDK v4, you must have the Infrastructure agent version 1.13.0 or higher. To use SDK v3, you must have agent version 1.0.888 or higher. For Infrastructure agent version information and options for installation and updates, see the Infrastructure release notes. For notes on SDK versions and changes, see the change log. Operating systems Integrations built with the SDK can be compiled for either Linux or Windows operating systems. Data and file specifications Infrastructure on-host integrations can be created with any programming language, as long as they adhere to the data and file specifications. SDK version changes Infrastructure agent version Details 1.13.0 or higher Changes to integration protocol (v4), including support to dynamically register entities in NR1 and send dimensional metrics. New metric types. See SDK v4 release notes. 1.0.888 or higher Changes to JSON format, including support for multiple entities. The new JSON format is referred to as protocol 2 (described in JSON output documentation and also used in the definition file). Uses newer set of Go language build tools (referenced as GoSDK v3). 1.0.726 (for Linux); 1.0.775 (for Windows) Uses JSON protocol 1 (described in JSON output documentation and also used in the definition file). Uses older set of Go language build tools (referenced as GoSDK v2). If you've built an integration using the older Go language build tools and wish to update, see Upgrade from GoSDK v2 to v3 and Upgrade from v3 to v4. For updating the Infrastructure agent, see Update the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.227,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "sections": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "Before using the New Relic <em>Infrastructure</em> <em>integrations</em> <em>SDK</em> to <em>create</em> a custom on-host integration, make sure your system meets these requirements. <em>Infrastructure</em> version To use the <em>infrastructure</em> <em>Integrations</em> <em>SDK</em> v4, you must have the <em>Infrastructure</em> agent version 1.13.0 or higher. To use <em>SDK</em> v3"
      },
      "id": "60440de564441fa14f378ecc"
    },
    {
      "sections": [
        "On-host integration files",
        "Integration files"
      ],
      "title": "On-host integration files",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "bad9028bde5eb2b92ad7971e0ca42517530f3796",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-files/",
      "published_at": "2021-06-14T22:17:17Z",
      "updated_at": "2021-03-16T08:29:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Infrastructure Integrations SDK lets you create an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before you build an on-host integration, verify you meet the compatibility and requirements. An integration requires at least these files: An executable file, written in any language, that export JSON data in a format expected by the Infrastructure agent One or more configuration files For Go language build tools and a tutorial for creating these files, see Build resources.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.287,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> files",
        "sections": "On-host <em>integration</em> files",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "The New Relic <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em> lets you <em>create</em> an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before"
      },
      "id": "603ed7e264441ff57a4e883b"
    },
    {
      "sections": [
        "On-host integrations: Standard configuration format",
        "Configuration file structure",
        "Definition file",
        "Definition file header",
        "Definition file commands",
        "Configuration file",
        "Tip",
        "Config file field definitions"
      ],
      "title": "On-host integrations: Standard configuration format",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "3b4c5ab77b2b8025ca8de375403f24bc75b3dca7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format/",
      "published_at": "2021-06-14T22:23:44Z",
      "updated_at": "2021-03-16T07:30:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Infrastructure on-host integrations can use one of two types of configuration formats. This document explains the older, standard configuration format. This format is used by most on-host integrations and is supported by newer Infrastructure agents (which also support a newer, improved configuration format). For an introduction to configuration, see Config overview. Configuration file structure An on-host integration that uses the standard configuration format requires two configuration files: A definition file A configuration file Definition file The definition file has a naming format like INTEGRATION_NAME-definition.yml. This file provides descriptive information about the integration, such as: the version of the JSON protocol it supports, a list of commands it can execute, and arguments that it accepts. It lives in this directory: Linux: /var/db/newrelic-infra/newrelic-integrations Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations Copy Here's an example of an NGINX integration definition file with two command sections on a Linux system: name: com.myorg.nginx protocol_version: 2 description: Collect metric and configuration data from NGINX os: linux commands: metrics: command: - myorg-nginx - --metrics interval: 15 inventory: command: - myorg-nginx - --inventory interval: 120 prefix: integration/myorg-nginx Copy A definition file can be broken down into two parts: The header The commands section Definition file header Here are explanations of a definition file's header elements: Definition header field Description name Required. A unique name name to identify the integration for logging, internal metrics, etc. When the agent loads the config file, New Relic uses the name to look up the integration in the agent's registry. protocol_version Required. The version number of the protocol. New Relic uses this to ensure compatibility between the integration and the agent. If the agent does not recognize an integration's version, it will filter out that integration and create a log message. The current version of the JSON protocol is 2. For more on protocol changes, see SDK changes. description Optional. Human-friendly explanation of what the integration does. os Optional. The operating system where the integration runs. New Relic uses this to filter integrations that you intend to run only on specific operating systems. Default: Run the integration regardless of the os value. To restrict the integration to a specific operating system, use either of these options: linux windows Definition file commands After the header is a list of commands. The commands section defines: One or more independent operating modes for the executable The runtime data required for it to be executed The commands section is a YAML map of command definitions, where each key is the unique alias name of the command in the integration's config file that specifies the executable to run. Definition commands Description command Required. The actual command line to be executed as a YAML array of command parts. These are assembled to run the actual command. For simple commands, the array might be only a single element. Additional command rules include: command arguments: The command and any command line arguments that are shared for all instances of the integration configuration. command execution: The command will be executed in the same directory as the definition file. command path: Any commands available on the host's $PATH can be used. Executables located in the same directory as the definition file, or in a subdirectory of it, can be executed using a relative path. For example: Linux: To run an executable called myorg-nginx in the same directory as the definition file, you could use myorg-nginx or ./myorg-nginx. Linux systems will execute myorg-nginx as if the user used ./myorg-nginx. Windows: To run an executable called myorg-nginx.exe in the same directory as the definition file, you could use \\myorg-nginx.exe or .\\myorg-nginx.exe. Windows systems writing myorg-nginx.exe will be executed as if indicating the current path: .\\myorg-nginx.exe. To use a command installed inside a directory on the host's $PATH, simply use the command name. Example: python. To run any other executable which is neither on the host's $PATH nor within the integration's directory, use an absolute path to the executable. Example: /opt/jdk/bin/java. If the given executable name exists within the integration's directory but also exists elsewhere on the system $PATH, the version in the integration's directory takes precedence. interval Optional. The number of seconds between two consecutive executions of the command, in particular between the end of the previous execution and the start of the next execution. Default for metric polling: 30 seconds. Minimum (floor): 15 seconds. Alerts: For metrics being used for alerts, use an interval of 30 seconds or less. prefix Optional. The categorization of the inventory in the form of category/short_integration_name. Example: integration/myorg-nginx. The prefix is not a platform-specific path. The forward slash is the correct separator between the category and short_integration_name. The prefix can have a maximum of two levels. Otherwise inventory will not be reported. Default value if not set: integration/integration_name. Configuration file The configuration file has a naming format like INTEGRATION_NAME-config.yml. This file specifies which executables to run and the parameters required to run them. It lives in this directory: Linux: /etc/newrelic-infra/integrations.d/ Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d Copy Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Here's an example of a config file with one instance defined. Explanations of these fields are explained below the example. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://127.0.0.1/status labels: environment: production role: load_balancer Copy Another example of a config file with two instances defined. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://one.url/status labels: environment: production role: load_balancer - name: nginx2.myorg.com-metrics command: metrics arguments: status_url: http://another.url/status labels: environment: production role: load_balancer Copy Config file field definitions Config file field Description integration_name Required. This is the header and is used to identify which executables to run. This name must exactly match the name specified in the integration's definition file. Recommendation: To ensure unique names, use reverse domain name notation. name Required. This is the name for the specific invocation (instance) of the integration. This is used to help identify any log messages generated by this integration and is also useful for troubleshooting. command Required. This is the command to be executed. This must exactly match one of the unique alias names specified in the integration's definition file. arguments Optional. A YAML object where: Keys: The argument name. Transformed to upper case when set as environment variable. Values: The argument values. Passed through as is. The arguments are made available to an integration as a set of environment variables. Arguments in the config file cannot be capitalised and should use underscores to separate words. labels Optional. A YAML object where: Keys: The label name. Values: The defined label value. integration_user Optional. String with the name the agent will use for executing the integration binary. Default: depends on the usermode. By default, integrations are executed with the same user that's running the integration agent, nri-agent for privileged and unprivileged mode and root user for root mode. When present, the Infrastructure agent will execute the integration binary as the specified user. For example, to run the integration binary as the root user when running the agent in a usermode different than root, just add integration_user: root to the configuration file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.27914,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Standard configuration format",
        "sections": "On-host <em>integrations</em>: Standard configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic <em>Infrastructure</em> on-host <em>integrations</em> can use one of two types of configuration formats. This document explains the older, standard configuration format. This format is used by most on-host <em>integrations</em> and is supported by newer <em>Infrastructure</em> agents (which also support a newer, improved"
      },
      "id": "603e923a196a67581ca83db3"
    }
  ],
  "/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format": [
    {
      "sections": [
        "Compatibility and requirements for Infrastructure Integrations SDK",
        "Infrastructure version",
        "Operating systems",
        "Data and file specifications",
        "SDK version changes"
      ],
      "title": "Compatibility and requirements for Infrastructure Integrations SDK",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Get started"
      ],
      "external_id": "ea949057459c7c9648a9215928c1fd54c9d6a703",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/get-started/compatibility-requirements-infrastructure-integrations-sdk/",
      "published_at": "2021-06-14T22:22:04Z",
      "updated_at": "2021-03-13T02:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before using the New Relic Infrastructure integrations SDK to create a custom on-host integration, make sure your system meets these requirements. Infrastructure version To use the infrastructure Integrations SDK v4, you must have the Infrastructure agent version 1.13.0 or higher. To use SDK v3, you must have agent version 1.0.888 or higher. For Infrastructure agent version information and options for installation and updates, see the Infrastructure release notes. For notes on SDK versions and changes, see the change log. Operating systems Integrations built with the SDK can be compiled for either Linux or Windows operating systems. Data and file specifications Infrastructure on-host integrations can be created with any programming language, as long as they adhere to the data and file specifications. SDK version changes Infrastructure agent version Details 1.13.0 or higher Changes to integration protocol (v4), including support to dynamically register entities in NR1 and send dimensional metrics. New metric types. See SDK v4 release notes. 1.0.888 or higher Changes to JSON format, including support for multiple entities. The new JSON format is referred to as protocol 2 (described in JSON output documentation and also used in the definition file). Uses newer set of Go language build tools (referenced as GoSDK v3). 1.0.726 (for Linux); 1.0.775 (for Windows) Uses JSON protocol 1 (described in JSON output documentation and also used in the definition file). Uses older set of Go language build tools (referenced as GoSDK v2). If you've built an integration using the older Go language build tools and wish to update, see Upgrade from GoSDK v2 to v3 and Upgrade from v3 to v4. For updating the Infrastructure agent, see Update the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.227,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "sections": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "Before using the New Relic <em>Infrastructure</em> <em>integrations</em> <em>SDK</em> to <em>create</em> a custom on-host integration, make sure your system meets these requirements. <em>Infrastructure</em> version To use the <em>infrastructure</em> <em>Integrations</em> <em>SDK</em> v4, you must have the <em>Infrastructure</em> agent version 1.13.0 or higher. To use <em>SDK</em> v3"
      },
      "id": "60440de564441fa14f378ecc"
    },
    {
      "sections": [
        "On-host integration files",
        "Integration files"
      ],
      "title": "On-host integration files",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "bad9028bde5eb2b92ad7971e0ca42517530f3796",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-files/",
      "published_at": "2021-06-14T22:17:17Z",
      "updated_at": "2021-03-16T08:29:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Infrastructure Integrations SDK lets you create an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before you build an on-host integration, verify you meet the compatibility and requirements. An integration requires at least these files: An executable file, written in any language, that export JSON data in a format expected by the Infrastructure agent One or more configuration files For Go language build tools and a tutorial for creating these files, see Build resources.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.287,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> files",
        "sections": "On-host <em>integration</em> files",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "The New Relic <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em> lets you <em>create</em> an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before"
      },
      "id": "603ed7e264441ff57a4e883b"
    },
    {
      "sections": [
        "On-host integrations: Newer configuration format",
        "Configuration structure",
        "Tip",
        "Important",
        "List of configuration properties",
        "Select an integration to run",
        "name",
        "exec",
        "cli_args",
        "when",
        "Pass configuration to the integration executable",
        "env",
        "config",
        "config_template_path",
        "Configure how the agent executes your integrations",
        "integration_user",
        "interval",
        "inventory_source",
        "labels",
        "timeout",
        "working_dir",
        "Update older integration configuration"
      ],
      "title": "On-host integrations: Newer configuration format ",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "bc5bee12812cff6fabc728961e1b342b83f3e471",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-newer-configuration-format/",
      "published_at": "2021-06-14T22:22:47Z",
      "updated_at": "2021-03-16T07:30:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Infrastructure on-host integrations can use one of two types of configuration formats. In December 2019, Infrastructure agent version 1.8.0 began supporting a newer configuration format that makes use of a single configuration file (instead of two separate files), and provides other improvements. This document will explain how this newer format works. The older standard configuration format is supported by current Infrastructure agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration's configuration YAML must have an integrations top-level section containing a YAML array, where each entry represents an integration and its configuration. For each integration entry, only the name property is mandatory. The other properties are optional. Here's an example configuration featuring two integrations: our built-in Docker integration, which requires no configuration, and our MySQL integration: integrations: # New Relic integration that does not require any configuration - name: nri-docker # New Relic integration that gets its configuration from the environment - name: nri-mysql env: PORT: 3306 USERNAME: newrelic PASSWORD: 123456789 # to hide this field, read the secrets management documentation # Any free-form integration executed via a user-provided command - name: my-own-integration exec: python /opt/integrations/my-script.py --host=127.0.0.1 Copy You can have as many configuration YAML files as you want and can group your integration instances. Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Each configuration YAML file can also contain discovery and variables top-level sections. Important This configuration format does not require an agent restart. When saved, changes are detected and implemented immediately. This means that saving intermediate configuration changes may cause the integration to stop working. List of configuration properties This is a list of the general properties used to configure an integration. For more details about using these properties, including example values, see the documentation following the table. Config Description name Name of the integration. This is the only mandatory configuration property across all on-host integrations. If the exec field is not set it will also be the name of the integration executable. cli_args Optional list of command line arguments when name is used to provide the integration executable. Available since agent version 1.13.0. exec Full path to the integration executable, plus arguments. It may be a single-line string or a string array. If left unspecified, the exec field defaults to the name field. env YAML map containing the environment variables to be passed to the integration, where key is the environment variable name, and value is the variable value. config Configuration that is written as an external file and the path that is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. config_template_path Any external file whose path is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. Its usage allows applying discovery and secrets binding to any external configuration. integration_user Name of the user who runs the integration. interval Time between consecutive executions of the integration. It must be a number followed by a time unit (s, m or h), without spaces. inventory_source Allows overriding the category and term of the inventory source. labels Map with labels that decorate the data (metrics, events, inventory) reported by the integration. timeout A number followed by a time unit (ms, s, m or h). An integration that hasn't responded in this time period is killed and restarted. working_dir Working directory for the integration binary. when Integration is only executed if the clause evaluates to true. Conditions are defined below. The remainder of this document describes config properties grouped by their functionality: Select an integration to run Pass configuration to the integration command Configure how the agent executes integrations Select an integration to run There are two properties to select which integration will run: name and exec. The only mandatory property across all on-host integrations is name. The remaining properties specified in this document are optional. Example: integrations: - name: nri-docker - name: my-integration exec: /usr/local/bin/my-integration --metrics --inventory Copy name The mandatory name property can work in two ways: If the exec property is set: The name property only provides an identifier for the integration instance. This identifier is used in log messages and to provide a default inventory category/source in the form integration/<name> (for example, integration/nri-redis). This inventory path can be overridden with the inventory_source configuration option. If the exec property is not set: The agent looks for (and executes) an executable with the name value in any of the following folders: Linux: /var/db/newrelic-infra/newrelic-integrations/bin /var/db/newrelic-infra/newrelic-integrations /var/db/newrelic-infra/custom-integrations/bin /var/db/newrelic-infra/custom-integrations Windows C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations\\bin C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations If there is no executable with this name in the above folders the agent logs an error and the integration is not executed. Important In Windows, do not append the .exe extension to the name. The agent does this for you (for example, name: nri-mysql would look for nri-mysql.exe in the above folders). exec The exec optional property specifies the path, command, and command-line arguments of the integration to execute. When none of the path folders or arguments have spaces, it can be written in a single-line string: - name: my-integration exec: /usr/bin/python /opt/integrations/my-script.py --host=127.0.0.1 Copy If any of the path/arguments have spaces that are part of a single element, you can use a YAML array notation: - name: my-integration exec: - C:\\Program Files\\My Integration\\integration.exe - --host - 127.0.0.1 - --port - 8080 Copy The default working directory is the root directory of the agent configuration. It can be overridden with the working_dir property. cli_args The cli_args optional property specifies command line arguments that should be passed to the integration. It is useful when using name as it only provides the integration name identifier (not compatible with exec). - name: my-integration cli_args: [ -interval 10s ] Copy Usual YAML multi-line list format can be used as well: - name: my-integration cli_args: - -interval - 10s Copy when The when property allows to execute the integration only when all the evaluated conditions are successful. Available conditions are: env_exists: Environment variables exist and match value. file_exists: Given file path exists. feature: Provided feature-flag is enabled. Example: integrations: - name: ssh-integration when: file_exists: /var/run/sshd.pid Copy Pass configuration to the integration executable Often integration executables need to receive a configuration to work properly (for example, hostname and port of the monitored system, user credentials, etc.). The Infrastructure agent allows you to configure the integration commands in three ways (which you can combine): Command-line arguments, passed in the exec property. Environment variables, using the env property. Configuration files, whose path needs to be passed through environment variables or command-line arguments (see the config) property. Example: integrations: - name: my-integration exec: /opt/path/bin/script --host 127.0.0.1 --port 8081 - name: nri-mysql env: STATUS_URL: http://10.0.0.3/server-status?auto REMOTE_MONITORING: true Copy env The env property allows you to set environment variables that are passed to the executable. It is a key-value map with the required variables. Example: integrations: - name: nri-postgresql env: DATABASE: postgres PORT: 6432 COLLECTION_LIST: '[\"postgres\"]' COLLECT_DB_LOCK_METRICS: false VERBOSE: 1 Copy If you expect your integration to receive the configuration from the host's environment rather than specifying it explicitly in the configuration file, you need to set the required variables in the Infrastructure agent passthrough_environment global configuration property config This section describes various ways to pass configuration information to an integration. Pass configuration file directly Some integration commands may get their configuration from an external file. If your integration requires a configuration file, nothing prevents you from directly passing its path directly as a command-line argument or an environment variable. Here's an example using configuration of our Flex integration: integrations: - name: nri-flex env: CONFIG_FILE: /etc/nri-flex/configs/http-service.yaml - name: other-integration exec: /opt/integration/integration -f /opt/integration/config.properties Copy The above example assumes that the http-service.yaml and config.properties files exist. We can see that the nri-flex integration is expecting the http-service.yaml complete path via the CONFIG_FILE environment variable and the other-integration expects the complete config.properties path after the -f command-line flag. In the above example, it's necessary for the integration installer/configurator that the configuration files exist in the provided path and that the agent and integrations have read permissions on them. Pass configuration through config section If you prefer to keep your configuration file with the rest of the integration configuration, you can use the config section in the integration entry, which can contain a valid YAML object or just a multi-line string: integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv - name: other-integration exec: /opt/integration/integration -f ${config.path} config: | example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostname=localhost example.cfg.port=9025 Copy In the above examples, every time the nri-flex integration is executed, the agent creates a temporary file with the following contents: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy The above YAML is only a configuration example for the nri-flex integration. The agent ignores its contents; instead, it creates a temporary file and replaces the ${config.path} variable placeholder with its path. When the integration completes execution the temporary file is removed. Also, the agent creates another temporary file before executing the other-integration integration: example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostid=localhost example.cfg.port=9025 Copy It replaces the -f ${config.path} command-line placeholder with the temporary path of the written file. By convention, if you do not place the ${config.path} variable in any command-line argument or environment variable value, the agent passes the path of the configuration file via the CONFIG_PATH environment variable: # assuming that nri-example command is prepared to receive the configuration # file via the CONFIG_PATH environment variable integrations: - name: nri-example config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy Pass secrets and discovery through config section The main benefit for using a config section instead of hardcoding the full path of an external file is that you can insert ${variable} placeholders to apply our auto-discovery feature and secrets management. Here's an example followed by some explanations: variables: my_credentials: vault: http: url: http://my.vault.host/v1/newengine/data/secret headers: X-Vault-Token: my-vault-token discovery: docker: match: label.service: foo integrations: - name: foo-monitor exec: /opt/foo/bin/monitor --config=${config.path} config: | foo.host=${discovery.ip} foo.port=${discovery.port} foo.user=${my_credentials.user} foo.password=${my_credentials.password} Copy Tip (For more details about the variables and discovery sections, please visit the discovery and secrets management documentation). The above example relies on the following premises: There is a Vault service that allows retrieving a JSON object formed by the user and password fields. There may be a variable number of Docker containers labeled with service=foo, which are accessible from the agent host via a discoverable public IP and Port. The user has configured the foo-monitor integration to monitor all the service=foo labeled containers, which share a common user and password. Each instance of the foo-monitor integration requires executing the /opt/foo/bin/monitor executable, passing the text configuration inside the config section via the --config=<path> command-line argument. As example of workflow, imagine that the Vault invocation returns the following JSON: {\"user\":\"monitorer\",\"password\":\"5up3r53cr3t!\"} Copy At the moment of executing the foo-monitor integration, there are three running containers labeled with service=foo: ip: 10.0.0.3, port: 8080 ip: 10.0.0.3, port: 8081 ip: 10.0.0.3, port: 8082 The agent then creates the following three temporary files, using the contents of the config property as a template, but replacing the ${placeholders} by the acquired variables and discovered items (files' path is invented for the sake of simplicity): First match (/tmp/123_discovered): foo.host=10.0.0.3 foo.port=8080 foo.user=monitorer foo.password=5up3r53cr3t! Copy Second match (/tmp/456_discovered): foo.host=10.0.0.3 foo.port=8081 foo.user=monitorer foo.password=5up3r53cr3t! Copy Third match (/tmp/789_discovered) foo.host=10.0.0.3 foo.port=8082 foo.user=monitorer foo.password=5up3r53cr3t! Copy After the config variable placeholders have been replaced and the temporary files have been created, the /opt/foo/bin/monitor executable is executed three times (one per matched container), replacing the ${config.path} command-line placeholder with the temporary file corresponding to each discovered configuration: First match: /opt/foo/bin/monitor --config=/tmp/123_discovered Second match: /opt/foo/bin/monitor --config=/tmp/456_discovered Third match: /opt/foo/bin/monitor --config=/tmp/789_discovered To ensure security and to minimize the chance of leaking secrets to disk, the agent: Creates the files owned by the agent user, for example, root or nri-agent, depending on the user you have configured to run the agent. Sets read permissions only for the owner. Removes the created files when the integration instance finishes its execution. config_template_path If you want to use the secrets management and discovery in the configuration files that you're passing to the integration executable, but you prefer to keep them as an individual file, you can use the config_template_path: <path> option. It works exactly as in the config section: The agent applies secrets management and discovery to the file contents. The agent creates different temporary files that are passed to the integration via the ${config.path} placeholder (or the CONFIG_PATH environment variable). Example: discovery: docker: match: name: /^redis/ integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config_template_path: /etc/flex-configs/redis.yml Copy In the above example, the redis.yml external file can contain container discovery variable placeholders, like ${discovery.ip} or ${discovery.port}. Configure how the agent executes your integrations The properties of this section modify the way the Infrastructure agent executes and interacts with the integrations, or the way the agent decorates the integrations' data. integration_user The integration commands run as the same user as the agent (usually root or nri-agent). If due to permission restrictions an integration needs to run as another user, its name must be specified in the integration_user property. Example: integrations: - name: dbus-inventory exec: python my-dbus-script.py integration_user: dbus Copy interval The interval option sets the time between consecutive executions of an integration. The accepted format is an integer immediately followed by a time unit (s for seconds, m for minutes, h for hours). The default is 30s, and the minimum accepted value is 15s. Any value lower than 15s is automatically set to 15s. Example: integrations: - name: nri-nginx env: STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover interval: 20s Copy inventory_source Any inventory item must be catalogued under a category/source taxonomy. By default, each integration inventory is stored as integration/ + name value (for example, integration/nri-apache, integration/nri-mysql). The inventory_source property allows you to override the default taxonomy of inventory data. Example: integrations: - name: nri-nginx - name: nri-apache exec: - /var/db/newrelic-infra/newrelic-integrations/bin/nri-apache - --inventory inventory_source: config/apache Copy In the above example, the nri-nginx inventory, if any, would be visible in the New Relic UI under the integration/nri-nginx source. The nri-apache inventory would be visible under config/apache. labels labels is a key-value map that allows extra metadata to be provided for the integration. The agent uses those labels to decorate the metrics, events, and inventory that it receives from a given integration instance. Example: integrations: - name: nri-apache inventory_source: config/apache labels: env: production role: load_balancer Copy In the above example, the agent decorates all the metrics and events from the nri-apache instance with the following fields: label.env: production label.role: load_balancer Also, the following entries are added to the integration inventory: config/apache/labels/env: production config/apache/labels/role: load_balancer timeout If an integration has not returned any metric (or a heartbeat message as described below) before the time specified in the timeout value, the agent kills the integration process and restarts it after the corresponding interval. The accepted format is an integer number immediately followed (without spaces) by a time unit (ms for milliseconds, s for seconds, m for minutes, h for hours). If a zero (or negative) timeout value is provided, the integration can run forever without being killed by a timeout expiration. For long-running integrations (integrations that keep running, periodically returning metrics/events/inventory), each time the integration submits a metrics/events/inventory payload, the timeout deadline is restarted. That means that long-running integrations must return a valid JSON payload in an interval that is lower than timeout. Returning an empty JSON ({}) is interpreted as a heart-beat message that restarts the timeout, preventing the long-running integration from being killed, even if they don't have information to report. The default is 120s, and the minimum accepted value is 100ms. Any value lower than 100ms is automatically set to 100ms. Example: integrations: - name: nri-jmx arguments: JMX_HOST: jmx-host.localnet JMX_PORT: 7096 COLLECTION_FILES: \"/etc/newrelic-infra/integrations.d/jvm-metrics.yml\" timeout: 30s Copy working_dir working_dir sets the working directory of the command. If empty or unspecified, the agent runs the command in the Infrastructure agent's current directory. The default is the Infrastructure agent root directory. Example: integrations: - name: my-integration exec: /opt/integration/bin/integration working_dir: /opt/integration/scratch-zone Copy Update older integration configuration In December 2019, the Infrastructure agent version 1.8.0 began using a different configuration format. For details, see Config format differences. The main difference between these formats is that the older configuration format uses two separate configuration files (a INTEGRATION_NAME-definition.yml file and a INTEGRATION_NAME-config.yml file) and the newer version uses a single configuration file. Here are some of the features added by the newer configuration functionality: Flexible configuration via command-line arguments, environment variables, or external files. Ability to group different integrations in the same file. Hot reload: adding a new integration or changing its configuration does not require restarting the agent. Timeouts: if an integration doesn't respond before a user-specified time, the integration process is killed and restarted. Not all on-host integrations come with the newer configuration format, but you can update the configuration to the new format for all on-host integrations to take advantage of the new features. The following YAML shows an example Apache integration configuration using the older configuration format. Note that this configuration will still work with newer agents, but we recommend updating your integrations to take full advantage of features. integration_name: com.newrelic.apache instances: - name: apache-server-metrics command: metrics arguments: status_url: http://127.0.0.1/server-status?auto remote_monitoring: true labels: env: production role: load_balancer - name: apache-server-inventory command: inventory arguments: remote_monitoring: true labels: env: production role: load_balancer Copy To update an older integration configuration to the new format, you must perform two steps: Rename the instances top-level section to integrations. Remove the integration_name top-level section and add it to each integration entry. You are no longer required to keep a separate file for each integration type and you can group your legacy integration entries in the same file as other integrations. The new version of the Apache integration config: integrations: - name: apache-server-metrics integration_name: com.newrelic.apache command: metrics arguments: status_url: http://127.0.0.1/server-status?auto remote_monitoring: true labels: env: production role: load_balancer - name: apache-server-inventory integration_name: com.newrelic.apache command: inventory arguments: remote_monitoring: true labels: env: production role: load_balancer Copy Please note that because the older configuration format doesn't support hot reloading. You will need to restart the Infrastructure agent to remove the old integrations configuration (otherwise the old instances will coexist with the new ones).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.27914,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Newer configuration format ",
        "sections": "On-host <em>integrations</em>: Newer configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic <em>Infrastructure</em> on-host <em>integrations</em> can use one of two types of configuration formats. In December 2019, <em>Infrastructure</em> agent version 1.8.0 began supporting a newer configuration format that makes use of a single configuration file (instead of two separate files), and provides other"
      },
      "id": "603e923928ccbcb8dfeba751"
    }
  ],
  "/docs/create-integrations/infrastructure-integrations-sdk/specifications/integration-logging-recommendations": [
    {
      "sections": [
        "Compatibility and requirements for Infrastructure Integrations SDK",
        "Infrastructure version",
        "Operating systems",
        "Data and file specifications",
        "SDK version changes"
      ],
      "title": "Compatibility and requirements for Infrastructure Integrations SDK",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Get started"
      ],
      "external_id": "ea949057459c7c9648a9215928c1fd54c9d6a703",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/get-started/compatibility-requirements-infrastructure-integrations-sdk/",
      "published_at": "2021-06-14T22:22:04Z",
      "updated_at": "2021-03-13T02:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before using the New Relic Infrastructure integrations SDK to create a custom on-host integration, make sure your system meets these requirements. Infrastructure version To use the infrastructure Integrations SDK v4, you must have the Infrastructure agent version 1.13.0 or higher. To use SDK v3, you must have agent version 1.0.888 or higher. For Infrastructure agent version information and options for installation and updates, see the Infrastructure release notes. For notes on SDK versions and changes, see the change log. Operating systems Integrations built with the SDK can be compiled for either Linux or Windows operating systems. Data and file specifications Infrastructure on-host integrations can be created with any programming language, as long as they adhere to the data and file specifications. SDK version changes Infrastructure agent version Details 1.13.0 or higher Changes to integration protocol (v4), including support to dynamically register entities in NR1 and send dimensional metrics. New metric types. See SDK v4 release notes. 1.0.888 or higher Changes to JSON format, including support for multiple entities. The new JSON format is referred to as protocol 2 (described in JSON output documentation and also used in the definition file). Uses newer set of Go language build tools (referenced as GoSDK v3). 1.0.726 (for Linux); 1.0.775 (for Windows) Uses JSON protocol 1 (described in JSON output documentation and also used in the definition file). Uses older set of Go language build tools (referenced as GoSDK v2). If you've built an integration using the older Go language build tools and wish to update, see Upgrade from GoSDK v2 to v3 and Upgrade from v3 to v4. For updating the Infrastructure agent, see Update the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.227,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "sections": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "Before using the New Relic <em>Infrastructure</em> <em>integrations</em> <em>SDK</em> to <em>create</em> a custom on-host integration, make sure your system meets these requirements. <em>Infrastructure</em> version To use the <em>infrastructure</em> <em>Integrations</em> <em>SDK</em> v4, you must have the <em>Infrastructure</em> agent version 1.13.0 or higher. To use <em>SDK</em> v3"
      },
      "id": "60440de564441fa14f378ecc"
    },
    {
      "sections": [
        "On-host integration files",
        "Integration files"
      ],
      "title": "On-host integration files",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "bad9028bde5eb2b92ad7971e0ca42517530f3796",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-files/",
      "published_at": "2021-06-14T22:17:17Z",
      "updated_at": "2021-03-16T08:29:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Infrastructure Integrations SDK lets you create an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before you build an on-host integration, verify you meet the compatibility and requirements. An integration requires at least these files: An executable file, written in any language, that export JSON data in a format expected by the Infrastructure agent One or more configuration files For Go language build tools and a tutorial for creating these files, see Build resources.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.287,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> files",
        "sections": "On-host <em>integration</em> files",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "The New Relic <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em> lets you <em>create</em> an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before"
      },
      "id": "603ed7e264441ff57a4e883b"
    },
    {
      "sections": [
        "On-host integrations: Newer configuration format",
        "Configuration structure",
        "Tip",
        "Important",
        "List of configuration properties",
        "Select an integration to run",
        "name",
        "exec",
        "cli_args",
        "when",
        "Pass configuration to the integration executable",
        "env",
        "config",
        "config_template_path",
        "Configure how the agent executes your integrations",
        "integration_user",
        "interval",
        "inventory_source",
        "labels",
        "timeout",
        "working_dir",
        "Update older integration configuration"
      ],
      "title": "On-host integrations: Newer configuration format ",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "bc5bee12812cff6fabc728961e1b342b83f3e471",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-newer-configuration-format/",
      "published_at": "2021-06-14T22:22:47Z",
      "updated_at": "2021-03-16T07:30:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Infrastructure on-host integrations can use one of two types of configuration formats. In December 2019, Infrastructure agent version 1.8.0 began supporting a newer configuration format that makes use of a single configuration file (instead of two separate files), and provides other improvements. This document will explain how this newer format works. The older standard configuration format is supported by current Infrastructure agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration's configuration YAML must have an integrations top-level section containing a YAML array, where each entry represents an integration and its configuration. For each integration entry, only the name property is mandatory. The other properties are optional. Here's an example configuration featuring two integrations: our built-in Docker integration, which requires no configuration, and our MySQL integration: integrations: # New Relic integration that does not require any configuration - name: nri-docker # New Relic integration that gets its configuration from the environment - name: nri-mysql env: PORT: 3306 USERNAME: newrelic PASSWORD: 123456789 # to hide this field, read the secrets management documentation # Any free-form integration executed via a user-provided command - name: my-own-integration exec: python /opt/integrations/my-script.py --host=127.0.0.1 Copy You can have as many configuration YAML files as you want and can group your integration instances. Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Each configuration YAML file can also contain discovery and variables top-level sections. Important This configuration format does not require an agent restart. When saved, changes are detected and implemented immediately. This means that saving intermediate configuration changes may cause the integration to stop working. List of configuration properties This is a list of the general properties used to configure an integration. For more details about using these properties, including example values, see the documentation following the table. Config Description name Name of the integration. This is the only mandatory configuration property across all on-host integrations. If the exec field is not set it will also be the name of the integration executable. cli_args Optional list of command line arguments when name is used to provide the integration executable. Available since agent version 1.13.0. exec Full path to the integration executable, plus arguments. It may be a single-line string or a string array. If left unspecified, the exec field defaults to the name field. env YAML map containing the environment variables to be passed to the integration, where key is the environment variable name, and value is the variable value. config Configuration that is written as an external file and the path that is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. config_template_path Any external file whose path is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. Its usage allows applying discovery and secrets binding to any external configuration. integration_user Name of the user who runs the integration. interval Time between consecutive executions of the integration. It must be a number followed by a time unit (s, m or h), without spaces. inventory_source Allows overriding the category and term of the inventory source. labels Map with labels that decorate the data (metrics, events, inventory) reported by the integration. timeout A number followed by a time unit (ms, s, m or h). An integration that hasn't responded in this time period is killed and restarted. working_dir Working directory for the integration binary. when Integration is only executed if the clause evaluates to true. Conditions are defined below. The remainder of this document describes config properties grouped by their functionality: Select an integration to run Pass configuration to the integration command Configure how the agent executes integrations Select an integration to run There are two properties to select which integration will run: name and exec. The only mandatory property across all on-host integrations is name. The remaining properties specified in this document are optional. Example: integrations: - name: nri-docker - name: my-integration exec: /usr/local/bin/my-integration --metrics --inventory Copy name The mandatory name property can work in two ways: If the exec property is set: The name property only provides an identifier for the integration instance. This identifier is used in log messages and to provide a default inventory category/source in the form integration/<name> (for example, integration/nri-redis). This inventory path can be overridden with the inventory_source configuration option. If the exec property is not set: The agent looks for (and executes) an executable with the name value in any of the following folders: Linux: /var/db/newrelic-infra/newrelic-integrations/bin /var/db/newrelic-infra/newrelic-integrations /var/db/newrelic-infra/custom-integrations/bin /var/db/newrelic-infra/custom-integrations Windows C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations\\bin C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations If there is no executable with this name in the above folders the agent logs an error and the integration is not executed. Important In Windows, do not append the .exe extension to the name. The agent does this for you (for example, name: nri-mysql would look for nri-mysql.exe in the above folders). exec The exec optional property specifies the path, command, and command-line arguments of the integration to execute. When none of the path folders or arguments have spaces, it can be written in a single-line string: - name: my-integration exec: /usr/bin/python /opt/integrations/my-script.py --host=127.0.0.1 Copy If any of the path/arguments have spaces that are part of a single element, you can use a YAML array notation: - name: my-integration exec: - C:\\Program Files\\My Integration\\integration.exe - --host - 127.0.0.1 - --port - 8080 Copy The default working directory is the root directory of the agent configuration. It can be overridden with the working_dir property. cli_args The cli_args optional property specifies command line arguments that should be passed to the integration. It is useful when using name as it only provides the integration name identifier (not compatible with exec). - name: my-integration cli_args: [ -interval 10s ] Copy Usual YAML multi-line list format can be used as well: - name: my-integration cli_args: - -interval - 10s Copy when The when property allows to execute the integration only when all the evaluated conditions are successful. Available conditions are: env_exists: Environment variables exist and match value. file_exists: Given file path exists. feature: Provided feature-flag is enabled. Example: integrations: - name: ssh-integration when: file_exists: /var/run/sshd.pid Copy Pass configuration to the integration executable Often integration executables need to receive a configuration to work properly (for example, hostname and port of the monitored system, user credentials, etc.). The Infrastructure agent allows you to configure the integration commands in three ways (which you can combine): Command-line arguments, passed in the exec property. Environment variables, using the env property. Configuration files, whose path needs to be passed through environment variables or command-line arguments (see the config) property. Example: integrations: - name: my-integration exec: /opt/path/bin/script --host 127.0.0.1 --port 8081 - name: nri-mysql env: STATUS_URL: http://10.0.0.3/server-status?auto REMOTE_MONITORING: true Copy env The env property allows you to set environment variables that are passed to the executable. It is a key-value map with the required variables. Example: integrations: - name: nri-postgresql env: DATABASE: postgres PORT: 6432 COLLECTION_LIST: '[\"postgres\"]' COLLECT_DB_LOCK_METRICS: false VERBOSE: 1 Copy If you expect your integration to receive the configuration from the host's environment rather than specifying it explicitly in the configuration file, you need to set the required variables in the Infrastructure agent passthrough_environment global configuration property config This section describes various ways to pass configuration information to an integration. Pass configuration file directly Some integration commands may get their configuration from an external file. If your integration requires a configuration file, nothing prevents you from directly passing its path directly as a command-line argument or an environment variable. Here's an example using configuration of our Flex integration: integrations: - name: nri-flex env: CONFIG_FILE: /etc/nri-flex/configs/http-service.yaml - name: other-integration exec: /opt/integration/integration -f /opt/integration/config.properties Copy The above example assumes that the http-service.yaml and config.properties files exist. We can see that the nri-flex integration is expecting the http-service.yaml complete path via the CONFIG_FILE environment variable and the other-integration expects the complete config.properties path after the -f command-line flag. In the above example, it's necessary for the integration installer/configurator that the configuration files exist in the provided path and that the agent and integrations have read permissions on them. Pass configuration through config section If you prefer to keep your configuration file with the rest of the integration configuration, you can use the config section in the integration entry, which can contain a valid YAML object or just a multi-line string: integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv - name: other-integration exec: /opt/integration/integration -f ${config.path} config: | example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostname=localhost example.cfg.port=9025 Copy In the above examples, every time the nri-flex integration is executed, the agent creates a temporary file with the following contents: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy The above YAML is only a configuration example for the nri-flex integration. The agent ignores its contents; instead, it creates a temporary file and replaces the ${config.path} variable placeholder with its path. When the integration completes execution the temporary file is removed. Also, the agent creates another temporary file before executing the other-integration integration: example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostid=localhost example.cfg.port=9025 Copy It replaces the -f ${config.path} command-line placeholder with the temporary path of the written file. By convention, if you do not place the ${config.path} variable in any command-line argument or environment variable value, the agent passes the path of the configuration file via the CONFIG_PATH environment variable: # assuming that nri-example command is prepared to receive the configuration # file via the CONFIG_PATH environment variable integrations: - name: nri-example config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy Pass secrets and discovery through config section The main benefit for using a config section instead of hardcoding the full path of an external file is that you can insert ${variable} placeholders to apply our auto-discovery feature and secrets management. Here's an example followed by some explanations: variables: my_credentials: vault: http: url: http://my.vault.host/v1/newengine/data/secret headers: X-Vault-Token: my-vault-token discovery: docker: match: label.service: foo integrations: - name: foo-monitor exec: /opt/foo/bin/monitor --config=${config.path} config: | foo.host=${discovery.ip} foo.port=${discovery.port} foo.user=${my_credentials.user} foo.password=${my_credentials.password} Copy Tip (For more details about the variables and discovery sections, please visit the discovery and secrets management documentation). The above example relies on the following premises: There is a Vault service that allows retrieving a JSON object formed by the user and password fields. There may be a variable number of Docker containers labeled with service=foo, which are accessible from the agent host via a discoverable public IP and Port. The user has configured the foo-monitor integration to monitor all the service=foo labeled containers, which share a common user and password. Each instance of the foo-monitor integration requires executing the /opt/foo/bin/monitor executable, passing the text configuration inside the config section via the --config=<path> command-line argument. As example of workflow, imagine that the Vault invocation returns the following JSON: {\"user\":\"monitorer\",\"password\":\"5up3r53cr3t!\"} Copy At the moment of executing the foo-monitor integration, there are three running containers labeled with service=foo: ip: 10.0.0.3, port: 8080 ip: 10.0.0.3, port: 8081 ip: 10.0.0.3, port: 8082 The agent then creates the following three temporary files, using the contents of the config property as a template, but replacing the ${placeholders} by the acquired variables and discovered items (files' path is invented for the sake of simplicity): First match (/tmp/123_discovered): foo.host=10.0.0.3 foo.port=8080 foo.user=monitorer foo.password=5up3r53cr3t! Copy Second match (/tmp/456_discovered): foo.host=10.0.0.3 foo.port=8081 foo.user=monitorer foo.password=5up3r53cr3t! Copy Third match (/tmp/789_discovered) foo.host=10.0.0.3 foo.port=8082 foo.user=monitorer foo.password=5up3r53cr3t! Copy After the config variable placeholders have been replaced and the temporary files have been created, the /opt/foo/bin/monitor executable is executed three times (one per matched container), replacing the ${config.path} command-line placeholder with the temporary file corresponding to each discovered configuration: First match: /opt/foo/bin/monitor --config=/tmp/123_discovered Second match: /opt/foo/bin/monitor --config=/tmp/456_discovered Third match: /opt/foo/bin/monitor --config=/tmp/789_discovered To ensure security and to minimize the chance of leaking secrets to disk, the agent: Creates the files owned by the agent user, for example, root or nri-agent, depending on the user you have configured to run the agent. Sets read permissions only for the owner. Removes the created files when the integration instance finishes its execution. config_template_path If you want to use the secrets management and discovery in the configuration files that you're passing to the integration executable, but you prefer to keep them as an individual file, you can use the config_template_path: <path> option. It works exactly as in the config section: The agent applies secrets management and discovery to the file contents. The agent creates different temporary files that are passed to the integration via the ${config.path} placeholder (or the CONFIG_PATH environment variable). Example: discovery: docker: match: name: /^redis/ integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config_template_path: /etc/flex-configs/redis.yml Copy In the above example, the redis.yml external file can contain container discovery variable placeholders, like ${discovery.ip} or ${discovery.port}. Configure how the agent executes your integrations The properties of this section modify the way the Infrastructure agent executes and interacts with the integrations, or the way the agent decorates the integrations' data. integration_user The integration commands run as the same user as the agent (usually root or nri-agent). If due to permission restrictions an integration needs to run as another user, its name must be specified in the integration_user property. Example: integrations: - name: dbus-inventory exec: python my-dbus-script.py integration_user: dbus Copy interval The interval option sets the time between consecutive executions of an integration. The accepted format is an integer immediately followed by a time unit (s for seconds, m for minutes, h for hours). The default is 30s, and the minimum accepted value is 15s. Any value lower than 15s is automatically set to 15s. Example: integrations: - name: nri-nginx env: STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover interval: 20s Copy inventory_source Any inventory item must be catalogued under a category/source taxonomy. By default, each integration inventory is stored as integration/ + name value (for example, integration/nri-apache, integration/nri-mysql). The inventory_source property allows you to override the default taxonomy of inventory data. Example: integrations: - name: nri-nginx - name: nri-apache exec: - /var/db/newrelic-infra/newrelic-integrations/bin/nri-apache - --inventory inventory_source: config/apache Copy In the above example, the nri-nginx inventory, if any, would be visible in the New Relic UI under the integration/nri-nginx source. The nri-apache inventory would be visible under config/apache. labels labels is a key-value map that allows extra metadata to be provided for the integration. The agent uses those labels to decorate the metrics, events, and inventory that it receives from a given integration instance. Example: integrations: - name: nri-apache inventory_source: config/apache labels: env: production role: load_balancer Copy In the above example, the agent decorates all the metrics and events from the nri-apache instance with the following fields: label.env: production label.role: load_balancer Also, the following entries are added to the integration inventory: config/apache/labels/env: production config/apache/labels/role: load_balancer timeout If an integration has not returned any metric (or a heartbeat message as described below) before the time specified in the timeout value, the agent kills the integration process and restarts it after the corresponding interval. The accepted format is an integer number immediately followed (without spaces) by a time unit (ms for milliseconds, s for seconds, m for minutes, h for hours). If a zero (or negative) timeout value is provided, the integration can run forever without being killed by a timeout expiration. For long-running integrations (integrations that keep running, periodically returning metrics/events/inventory), each time the integration submits a metrics/events/inventory payload, the timeout deadline is restarted. That means that long-running integrations must return a valid JSON payload in an interval that is lower than timeout. Returning an empty JSON ({}) is interpreted as a heart-beat message that restarts the timeout, preventing the long-running integration from being killed, even if they don't have information to report. The default is 120s, and the minimum accepted value is 100ms. Any value lower than 100ms is automatically set to 100ms. Example: integrations: - name: nri-jmx arguments: JMX_HOST: jmx-host.localnet JMX_PORT: 7096 COLLECTION_FILES: \"/etc/newrelic-infra/integrations.d/jvm-metrics.yml\" timeout: 30s Copy working_dir working_dir sets the working directory of the command. If empty or unspecified, the agent runs the command in the Infrastructure agent's current directory. The default is the Infrastructure agent root directory. Example: integrations: - name: my-integration exec: /opt/integration/bin/integration working_dir: /opt/integration/scratch-zone Copy Update older integration configuration In December 2019, the Infrastructure agent version 1.8.0 began using a different configuration format. For details, see Config format differences. The main difference between these formats is that the older configuration format uses two separate configuration files (a INTEGRATION_NAME-definition.yml file and a INTEGRATION_NAME-config.yml file) and the newer version uses a single configuration file. Here are some of the features added by the newer configuration functionality: Flexible configuration via command-line arguments, environment variables, or external files. Ability to group different integrations in the same file. Hot reload: adding a new integration or changing its configuration does not require restarting the agent. Timeouts: if an integration doesn't respond before a user-specified time, the integration process is killed and restarted. Not all on-host integrations come with the newer configuration format, but you can update the configuration to the new format for all on-host integrations to take advantage of the new features. The following YAML shows an example Apache integration configuration using the older configuration format. Note that this configuration will still work with newer agents, but we recommend updating your integrations to take full advantage of features. integration_name: com.newrelic.apache instances: - name: apache-server-metrics command: metrics arguments: status_url: http://127.0.0.1/server-status?auto remote_monitoring: true labels: env: production role: load_balancer - name: apache-server-inventory command: inventory arguments: remote_monitoring: true labels: env: production role: load_balancer Copy To update an older integration configuration to the new format, you must perform two steps: Rename the instances top-level section to integrations. Remove the integration_name top-level section and add it to each integration entry. You are no longer required to keep a separate file for each integration type and you can group your legacy integration entries in the same file as other integrations. The new version of the Apache integration config: integrations: - name: apache-server-metrics integration_name: com.newrelic.apache command: metrics arguments: status_url: http://127.0.0.1/server-status?auto remote_monitoring: true labels: env: production role: load_balancer - name: apache-server-inventory integration_name: com.newrelic.apache command: inventory arguments: remote_monitoring: true labels: env: production role: load_balancer Copy Please note that because the older configuration format doesn't support hot reloading. You will need to restart the Infrastructure agent to remove the old integrations configuration (otherwise the old instances will coexist with the new ones).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.27914,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Newer configuration format ",
        "sections": "On-host <em>integrations</em>: Newer configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic <em>Infrastructure</em> on-host <em>integrations</em> can use one of two types of configuration formats. In December 2019, <em>Infrastructure</em> agent version 1.8.0 began supporting a newer configuration format that makes use of a single configuration file (instead of two separate files), and provides other"
      },
      "id": "603e923928ccbcb8dfeba751"
    }
  ],
  "/docs/create-integrations/infrastructure-integrations-sdk/troubleshooting/not-seeing-attributes": [
    {
      "sections": [
        "Not seeing Infrastructure integration data",
        "Problem",
        "Solution",
        "Troubleshoot integration requirements",
        "Check the integration log file for error messages",
        "Check that the integration is loading correctly"
      ],
      "title": "Not seeing Infrastructure integration data",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Troubleshooting"
      ],
      "external_id": "6b918ff0c14a1df232f58fb6cba063d6ab85114e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/troubleshooting/not-seeing-infrastructure-integration-data/",
      "published_at": "2021-06-14T21:33:19Z",
      "updated_at": "2021-03-13T02:49:24Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You created a custom New Relic Infrastructure on-host integration using the Integrations SDK, but you're not seeing data in the Infrastructure UI. Solution To troubleshoot and resolve the problem: Verify that your integration meets New Relic Infrastructure's integration requirements. After ruling out common problems with integration requirements, follow the more in-depth troubleshooting procedures for error logs and integration loading. Troubleshoot integration requirements If you are not receiving data from your custom integration, verify that your integration follows these requirements. Integration requirements Comments Environment Make sure your environment meets the Integrations SDK requirements. Configuration file Use a validator such as yamllint to verify that the configuration file is a valid YAML file. Verify that the file is in the correct location. Definition file Use a validator such as yamllint to verify that the definition file is a valid YAML file. Verify that the header fields have the required format. Verify that the prefix for inventory set in the definition file is no more than two levels deep. Verify that the file is in the correct location. Metric sets Verify that the integration: Does not generate metric sets with more than 120 key-value pairs. Does not generate more than 1000 metric sets. JSON payload Verify that the integration does not generate a single JSON payload of more than 5 MB. Check the integration log file for error messages After ruling out common problems with integration requirements, follow these more in-depth troubleshooting procedures. Recommendation: Configure a log file in the Infrastructure agent configuration. This helps separate the types of errors so you can spot integration errors more easily. When there is an error loading or running your integration, the Infrastructure agent adds an error message to the log file. Errors are logged even if verbose mode is disabled. Check the log file for lines that include \"level=error\". If there are no error messages, check whether the Infrastructure agent is loading the integration correctly. Check that the integration is loading correctly To verify whether the Infrastructure agent is loading the integration correctly: Enable verbose mode in the Infrastructure agent configuration. Restart the Infrastructure agent. Verify that the first lines of the log file contain two messages: \"loaded plugin\" plugin=<your_integration_name> \"found plugin config file\" plugin-path=\"<your_integration_config_path>\" Copy Check for errors just before or after these lines that indicate a problem with loading. The agent schedules data to be sent based on the schedule set in the definition file. Look in the log file for the integration's JSON. JSON payload example nginx-server-metrics: {\\\"name\\\":\\\"com.newrelic.nginx\\\",\\\"protocol_version\\\":\\\"1\\\",\\\"integration_version\\\":\\\"0.5.0\\\",\\\"metrics\\\": [{\\\"event_type\\\":\\\"NginxSample\\\",\\\"net.connectionsAcceptedPerSecond\\\":0.10344827586206896,\\\"net.connectionsActive\\\":1, \\\"net.connectionsDroppedPerSecond\\\":0,\\\"net.connectionsReading\\\":0,\\\"net.connectionsWaiting\\\":0,\\\"net.connectionsWriting\\\":1, \\\"net.requestsPerSecond\\\":0.10344827586206896,\\\"software.edition\\\":\\\"open source\\\",\\\"software.version\\\":\\\"1.4.6 (Ubuntu)\\\"}],\\\"inventory\\\":{},\\\"events\\\":[]} Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.71805,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Not seeing <em>Infrastructure</em> <em>integration</em> data",
        "sections": "Not seeing <em>Infrastructure</em> <em>integration</em> data",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "Problem You created a custom New Relic <em>Infrastructure</em> on-host integration using the <em>Integrations</em> <em>SDK</em>, but you&#x27;re not seeing data in the <em>Infrastructure</em> UI. Solution To <em>troubleshoot</em> and resolve the problem: Verify that your integration meets New Relic <em>Infrastructure</em>&#x27;s integration requirements. After"
      },
      "id": "6043efdf28ccbc6d182c6081"
    },
    {
      "sections": [
        "Integration logging recommendations",
        "Logging requirements",
        "Recommendations and best practices",
        "For more help"
      ],
      "title": "Integration logging recommendations",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "5cd5cc6af7ef854ed9f5aabb3c8c6ddbc3e123fc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/integration-logging-recommendations/",
      "published_at": "2021-06-15T06:57:07Z",
      "updated_at": "2021-03-13T02:51:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Infrastructure provides an SDK for creating an on-host integration. This document explains requirements and best practices for generating integration logs. Logging requirements It's up to the integration creator to decide what kind of log messages to create, and what kind of information will be useful for debugging issues. There is only one requirement for how an integration must generate logs: The integration executable must write logs to standard error (stderr). The Infrastructure agent will capture lines written to standard error and merge them into the logging stream written by the Infrastructure agent itself. To avoid depending on third-party logging solutions, the Go integration building library provides a simple log package with the common log-levels. Recommendations and best practices Here are the recommended practices for generating integration logs: By default, an integration should be \"quiet.\" Aside from the data emitted to standard output, there should be very few logging or diagnostic messages generated. It's recommended you include a verbose logging mode similar to the verbose setting in the Infrastructure agent. Include a command line switch to enable and disable verbose logging (for example, -verbose). To debug your integration while the integration is running, include the verbose switch in the definition file as part of the command line to be run. This will send the verbose logs to the Infrastructure agent's own log file. For general debugging purposes, New Relic recommends you use a flag that writes the standard out JSON data in human-readable \"pretty-printed\" form (for example, --pretty). Note that output written in a \"pretty-printed\" form is only for your debugging purposes and is not compatible with the Infrastructure agent. Your integration should be created so that it can run on its own. If in doubt whether the integration is communicating with the Infrastructure agent, you can run the integration from the command line and see if it's producing the correct output or log messages you expect. For information about the Go language logging package, see Logging package. For more help For logging for all New Relic agents, see New Relic agent logs and troubleshooting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.05548,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Integration</em> logging recommendations",
        "sections": "<em>Integration</em> logging recommendations",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic <em>Infrastructure</em> provides an <em>SDK</em> for creating an on-host integration. This document explains requirements and best practices for generating integration logs. Logging requirements It&#x27;s up to the integration creator to decide what kind of log messages to <em>create</em>, and what kind of information"
      },
      "id": "6043f02664441fcb4e378efc"
    },
    {
      "sections": [
        "On-host integrations: Standard configuration format",
        "Configuration file structure",
        "Definition file",
        "Definition file header",
        "Definition file commands",
        "Configuration file",
        "Tip",
        "Config file field definitions"
      ],
      "title": "On-host integrations: Standard configuration format",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "3b4c5ab77b2b8025ca8de375403f24bc75b3dca7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format/",
      "published_at": "2021-06-14T22:23:44Z",
      "updated_at": "2021-03-16T07:30:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Infrastructure on-host integrations can use one of two types of configuration formats. This document explains the older, standard configuration format. This format is used by most on-host integrations and is supported by newer Infrastructure agents (which also support a newer, improved configuration format). For an introduction to configuration, see Config overview. Configuration file structure An on-host integration that uses the standard configuration format requires two configuration files: A definition file A configuration file Definition file The definition file has a naming format like INTEGRATION_NAME-definition.yml. This file provides descriptive information about the integration, such as: the version of the JSON protocol it supports, a list of commands it can execute, and arguments that it accepts. It lives in this directory: Linux: /var/db/newrelic-infra/newrelic-integrations Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations Copy Here's an example of an NGINX integration definition file with two command sections on a Linux system: name: com.myorg.nginx protocol_version: 2 description: Collect metric and configuration data from NGINX os: linux commands: metrics: command: - myorg-nginx - --metrics interval: 15 inventory: command: - myorg-nginx - --inventory interval: 120 prefix: integration/myorg-nginx Copy A definition file can be broken down into two parts: The header The commands section Definition file header Here are explanations of a definition file's header elements: Definition header field Description name Required. A unique name name to identify the integration for logging, internal metrics, etc. When the agent loads the config file, New Relic uses the name to look up the integration in the agent's registry. protocol_version Required. The version number of the protocol. New Relic uses this to ensure compatibility between the integration and the agent. If the agent does not recognize an integration's version, it will filter out that integration and create a log message. The current version of the JSON protocol is 2. For more on protocol changes, see SDK changes. description Optional. Human-friendly explanation of what the integration does. os Optional. The operating system where the integration runs. New Relic uses this to filter integrations that you intend to run only on specific operating systems. Default: Run the integration regardless of the os value. To restrict the integration to a specific operating system, use either of these options: linux windows Definition file commands After the header is a list of commands. The commands section defines: One or more independent operating modes for the executable The runtime data required for it to be executed The commands section is a YAML map of command definitions, where each key is the unique alias name of the command in the integration's config file that specifies the executable to run. Definition commands Description command Required. The actual command line to be executed as a YAML array of command parts. These are assembled to run the actual command. For simple commands, the array might be only a single element. Additional command rules include: command arguments: The command and any command line arguments that are shared for all instances of the integration configuration. command execution: The command will be executed in the same directory as the definition file. command path: Any commands available on the host's $PATH can be used. Executables located in the same directory as the definition file, or in a subdirectory of it, can be executed using a relative path. For example: Linux: To run an executable called myorg-nginx in the same directory as the definition file, you could use myorg-nginx or ./myorg-nginx. Linux systems will execute myorg-nginx as if the user used ./myorg-nginx. Windows: To run an executable called myorg-nginx.exe in the same directory as the definition file, you could use \\myorg-nginx.exe or .\\myorg-nginx.exe. Windows systems writing myorg-nginx.exe will be executed as if indicating the current path: .\\myorg-nginx.exe. To use a command installed inside a directory on the host's $PATH, simply use the command name. Example: python. To run any other executable which is neither on the host's $PATH nor within the integration's directory, use an absolute path to the executable. Example: /opt/jdk/bin/java. If the given executable name exists within the integration's directory but also exists elsewhere on the system $PATH, the version in the integration's directory takes precedence. interval Optional. The number of seconds between two consecutive executions of the command, in particular between the end of the previous execution and the start of the next execution. Default for metric polling: 30 seconds. Minimum (floor): 15 seconds. Alerts: For metrics being used for alerts, use an interval of 30 seconds or less. prefix Optional. The categorization of the inventory in the form of category/short_integration_name. Example: integration/myorg-nginx. The prefix is not a platform-specific path. The forward slash is the correct separator between the category and short_integration_name. The prefix can have a maximum of two levels. Otherwise inventory will not be reported. Default value if not set: integration/integration_name. Configuration file The configuration file has a naming format like INTEGRATION_NAME-config.yml. This file specifies which executables to run and the parameters required to run them. It lives in this directory: Linux: /etc/newrelic-infra/integrations.d/ Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d Copy Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Here's an example of a config file with one instance defined. Explanations of these fields are explained below the example. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://127.0.0.1/status labels: environment: production role: load_balancer Copy Another example of a config file with two instances defined. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://one.url/status labels: environment: production role: load_balancer - name: nginx2.myorg.com-metrics command: metrics arguments: status_url: http://another.url/status labels: environment: production role: load_balancer Copy Config file field definitions Config file field Description integration_name Required. This is the header and is used to identify which executables to run. This name must exactly match the name specified in the integration's definition file. Recommendation: To ensure unique names, use reverse domain name notation. name Required. This is the name for the specific invocation (instance) of the integration. This is used to help identify any log messages generated by this integration and is also useful for troubleshooting. command Required. This is the command to be executed. This must exactly match one of the unique alias names specified in the integration's definition file. arguments Optional. A YAML object where: Keys: The argument name. Transformed to upper case when set as environment variable. Values: The argument values. Passed through as is. The arguments are made available to an integration as a set of environment variables. Arguments in the config file cannot be capitalised and should use underscores to separate words. labels Optional. A YAML object where: Keys: The label name. Values: The defined label value. integration_user Optional. String with the name the agent will use for executing the integration binary. Default: depends on the usermode. By default, integrations are executed with the same user that's running the integration agent, nri-agent for privileged and unprivileged mode and root user for root mode. When present, the Infrastructure agent will execute the integration binary as the specified user. For example, to run the integration binary as the root user when running the agent in a usermode different than root, just add integration_user: root to the configuration file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.22975,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Standard configuration format",
        "sections": "On-host <em>integrations</em>: Standard configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic <em>Infrastructure</em> on-host <em>integrations</em> can use one of two types of configuration formats. This document explains the older, standard configuration format. This format is used by most on-host <em>integrations</em> and is supported by newer <em>Infrastructure</em> agents (which also support a newer, improved"
      },
      "id": "603e923a196a67581ca83db3"
    }
  ],
  "/docs/create-integrations/infrastructure-integrations-sdk/troubleshooting/not-seeing-infrastructure-integration-data": [
    {
      "sections": [
        "Not seeing attributes data",
        "Problem",
        "Solution"
      ],
      "title": "Not seeing attributes data",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Troubleshooting"
      ],
      "external_id": "25a763fd32bebfa1cb33b77caf260df9a4d9fe53",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/troubleshooting/not-seeing-attributes/",
      "published_at": "2021-06-14T20:50:43Z",
      "updated_at": "2021-03-16T08:30:13Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Your integration is reporting data, but a few inventory attributes are missing. Solution The following inventory key names are used internally by our platform. If customer-provided integrations send inventory items with the same key name, they will remain invisible to the user: pid installed_epoch epoch time size boot_id product_uuid installed_time",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.00227,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "Problem Your integration is reporting data, but a few inventory attributes are missing. Solution The following inventory key names are used internally by our platform. If customer-provided <em>integrations</em> send inventory items with the same key name, they will remain invisible to the user: pid installed_epoch epoch time size boot_id product_uuid installed_time"
      },
      "id": "60506c9564441f0e645321ab"
    },
    {
      "sections": [
        "Integration logging recommendations",
        "Logging requirements",
        "Recommendations and best practices",
        "For more help"
      ],
      "title": "Integration logging recommendations",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "5cd5cc6af7ef854ed9f5aabb3c8c6ddbc3e123fc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/integration-logging-recommendations/",
      "published_at": "2021-06-15T06:57:07Z",
      "updated_at": "2021-03-13T02:51:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Infrastructure provides an SDK for creating an on-host integration. This document explains requirements and best practices for generating integration logs. Logging requirements It's up to the integration creator to decide what kind of log messages to create, and what kind of information will be useful for debugging issues. There is only one requirement for how an integration must generate logs: The integration executable must write logs to standard error (stderr). The Infrastructure agent will capture lines written to standard error and merge them into the logging stream written by the Infrastructure agent itself. To avoid depending on third-party logging solutions, the Go integration building library provides a simple log package with the common log-levels. Recommendations and best practices Here are the recommended practices for generating integration logs: By default, an integration should be \"quiet.\" Aside from the data emitted to standard output, there should be very few logging or diagnostic messages generated. It's recommended you include a verbose logging mode similar to the verbose setting in the Infrastructure agent. Include a command line switch to enable and disable verbose logging (for example, -verbose). To debug your integration while the integration is running, include the verbose switch in the definition file as part of the command line to be run. This will send the verbose logs to the Infrastructure agent's own log file. For general debugging purposes, New Relic recommends you use a flag that writes the standard out JSON data in human-readable \"pretty-printed\" form (for example, --pretty). Note that output written in a \"pretty-printed\" form is only for your debugging purposes and is not compatible with the Infrastructure agent. Your integration should be created so that it can run on its own. If in doubt whether the integration is communicating with the Infrastructure agent, you can run the integration from the command line and see if it's producing the correct output or log messages you expect. For information about the Go language logging package, see Logging package. For more help For logging for all New Relic agents, see New Relic agent logs and troubleshooting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.05548,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Integration</em> logging recommendations",
        "sections": "<em>Integration</em> logging recommendations",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic <em>Infrastructure</em> provides an <em>SDK</em> for creating an on-host integration. This document explains requirements and best practices for generating integration logs. Logging requirements It&#x27;s up to the integration creator to decide what kind of log messages to <em>create</em>, and what kind of information"
      },
      "id": "6043f02664441fcb4e378efc"
    },
    {
      "sections": [
        "On-host integrations: Standard configuration format",
        "Configuration file structure",
        "Definition file",
        "Definition file header",
        "Definition file commands",
        "Configuration file",
        "Tip",
        "Config file field definitions"
      ],
      "title": "On-host integrations: Standard configuration format",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "3b4c5ab77b2b8025ca8de375403f24bc75b3dca7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format/",
      "published_at": "2021-06-14T22:23:44Z",
      "updated_at": "2021-03-16T07:30:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Infrastructure on-host integrations can use one of two types of configuration formats. This document explains the older, standard configuration format. This format is used by most on-host integrations and is supported by newer Infrastructure agents (which also support a newer, improved configuration format). For an introduction to configuration, see Config overview. Configuration file structure An on-host integration that uses the standard configuration format requires two configuration files: A definition file A configuration file Definition file The definition file has a naming format like INTEGRATION_NAME-definition.yml. This file provides descriptive information about the integration, such as: the version of the JSON protocol it supports, a list of commands it can execute, and arguments that it accepts. It lives in this directory: Linux: /var/db/newrelic-infra/newrelic-integrations Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations Copy Here's an example of an NGINX integration definition file with two command sections on a Linux system: name: com.myorg.nginx protocol_version: 2 description: Collect metric and configuration data from NGINX os: linux commands: metrics: command: - myorg-nginx - --metrics interval: 15 inventory: command: - myorg-nginx - --inventory interval: 120 prefix: integration/myorg-nginx Copy A definition file can be broken down into two parts: The header The commands section Definition file header Here are explanations of a definition file's header elements: Definition header field Description name Required. A unique name name to identify the integration for logging, internal metrics, etc. When the agent loads the config file, New Relic uses the name to look up the integration in the agent's registry. protocol_version Required. The version number of the protocol. New Relic uses this to ensure compatibility between the integration and the agent. If the agent does not recognize an integration's version, it will filter out that integration and create a log message. The current version of the JSON protocol is 2. For more on protocol changes, see SDK changes. description Optional. Human-friendly explanation of what the integration does. os Optional. The operating system where the integration runs. New Relic uses this to filter integrations that you intend to run only on specific operating systems. Default: Run the integration regardless of the os value. To restrict the integration to a specific operating system, use either of these options: linux windows Definition file commands After the header is a list of commands. The commands section defines: One or more independent operating modes for the executable The runtime data required for it to be executed The commands section is a YAML map of command definitions, where each key is the unique alias name of the command in the integration's config file that specifies the executable to run. Definition commands Description command Required. The actual command line to be executed as a YAML array of command parts. These are assembled to run the actual command. For simple commands, the array might be only a single element. Additional command rules include: command arguments: The command and any command line arguments that are shared for all instances of the integration configuration. command execution: The command will be executed in the same directory as the definition file. command path: Any commands available on the host's $PATH can be used. Executables located in the same directory as the definition file, or in a subdirectory of it, can be executed using a relative path. For example: Linux: To run an executable called myorg-nginx in the same directory as the definition file, you could use myorg-nginx or ./myorg-nginx. Linux systems will execute myorg-nginx as if the user used ./myorg-nginx. Windows: To run an executable called myorg-nginx.exe in the same directory as the definition file, you could use \\myorg-nginx.exe or .\\myorg-nginx.exe. Windows systems writing myorg-nginx.exe will be executed as if indicating the current path: .\\myorg-nginx.exe. To use a command installed inside a directory on the host's $PATH, simply use the command name. Example: python. To run any other executable which is neither on the host's $PATH nor within the integration's directory, use an absolute path to the executable. Example: /opt/jdk/bin/java. If the given executable name exists within the integration's directory but also exists elsewhere on the system $PATH, the version in the integration's directory takes precedence. interval Optional. The number of seconds between two consecutive executions of the command, in particular between the end of the previous execution and the start of the next execution. Default for metric polling: 30 seconds. Minimum (floor): 15 seconds. Alerts: For metrics being used for alerts, use an interval of 30 seconds or less. prefix Optional. The categorization of the inventory in the form of category/short_integration_name. Example: integration/myorg-nginx. The prefix is not a platform-specific path. The forward slash is the correct separator between the category and short_integration_name. The prefix can have a maximum of two levels. Otherwise inventory will not be reported. Default value if not set: integration/integration_name. Configuration file The configuration file has a naming format like INTEGRATION_NAME-config.yml. This file specifies which executables to run and the parameters required to run them. It lives in this directory: Linux: /etc/newrelic-infra/integrations.d/ Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d Copy Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Here's an example of a config file with one instance defined. Explanations of these fields are explained below the example. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://127.0.0.1/status labels: environment: production role: load_balancer Copy Another example of a config file with two instances defined. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://one.url/status labels: environment: production role: load_balancer - name: nginx2.myorg.com-metrics command: metrics arguments: status_url: http://another.url/status labels: environment: production role: load_balancer Copy Config file field definitions Config file field Description integration_name Required. This is the header and is used to identify which executables to run. This name must exactly match the name specified in the integration's definition file. Recommendation: To ensure unique names, use reverse domain name notation. name Required. This is the name for the specific invocation (instance) of the integration. This is used to help identify any log messages generated by this integration and is also useful for troubleshooting. command Required. This is the command to be executed. This must exactly match one of the unique alias names specified in the integration's definition file. arguments Optional. A YAML object where: Keys: The argument name. Transformed to upper case when set as environment variable. Values: The argument values. Passed through as is. The arguments are made available to an integration as a set of environment variables. Arguments in the config file cannot be capitalised and should use underscores to separate words. labels Optional. A YAML object where: Keys: The label name. Values: The defined label value. integration_user Optional. String with the name the agent will use for executing the integration binary. Default: depends on the usermode. By default, integrations are executed with the same user that's running the integration agent, nri-agent for privileged and unprivileged mode and root user for root mode. When present, the Infrastructure agent will execute the integration binary as the specified user. For example, to run the integration binary as the root user when running the agent in a usermode different than root, just add integration_user: root to the configuration file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.22975,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Standard configuration format",
        "sections": "On-host <em>integrations</em>: Standard configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic <em>Infrastructure</em> on-host <em>integrations</em> can use one of two types of configuration formats. This document explains the older, standard configuration format. This format is used by most on-host <em>integrations</em> and is supported by newer <em>Infrastructure</em> agents (which also support a newer, improved"
      },
      "id": "603e923a196a67581ca83db3"
    }
  ],
  "/docs/csp-v2-error-inline-javascript-not-allowed": [
    {
      "sections": [
        "Add or list Browser apps via API (v2)",
        "Important",
        "Add browser apps",
        "List all browser apps",
        "View specific browser apps"
      ],
      "title": "Add or list Browser apps via API (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Browser examples (v2)"
      ],
      "external_id": "53568984e3b360bac9255a33adad7e6b43fadf5d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/browser-examples-v2/add-or-list-browser-apps-api-v2/",
      "published_at": "2021-06-14T23:01:14Z",
      "updated_at": "2021-06-14T23:01:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are examples of how to use the New Relic REST API (v2) to add apps to browser monitoring or to get a list of your browser apps for a specific API key. This helps you manage deployment outside of New Relic One. These API calls are useful, for example, with larger organizations deploying multiple apps, or for integration partners who facilitate New Relic account creation and browser monitoring deployments. Important When you add a browser app via API (v2), you can only instrument basic page load timing. To use instrumentation supporting all SPA features, see Use Browser SPA agent. To add a fully instrumented app, go to one.newrelic.com, and click the Add more data button on the top right hand-side. Then, use the guided install to start monitoring your app. Add browser apps To add an app to New Relic One, replace ${APIKEY} with your New Relic API key, and replace ${STRING} with the app's name in the following command. To accomplish the same task from the API Explorer, use your API key and go to rpm.newrelic.com/api/explore > Browser Applications > POST Create. Use the following command: curl -X POST 'https://api.newrelic.com/v2/browser_applications.json' \\ -H \"X-Api-Key:${APIKEY}\" -i -H 'Content-Type: application/json' \\ -d \\ '{ \"browser_application\": { \"name\": ${STRING} } }' Copy The API returns an array of data where the element is a Browser application and the data associated with it: { \"browser_application\": { \"id\": \"integer\", \"name\": \"string\", \"browser_monitoring_key\": \"string\", \"loader_script\": \"string\" } Copy API (v2) output Description Browser app id (integer) This is the unique identification code for each app in New Relic One. App name (string) This is the app's name as it appears in the New Relic One. The browser_monitoring_key (string) This a unique key that is linked to (but is not the same as) the account license key. It is used to indicate the account in New Relic One where data will be reported. It cannot be used to determine your New Relic account's license key. Browser monitoring loader_script (string) The returned loader script is a JSON-encoded JavaScript snippet that is configured with the New Relic license key and application ID. The rest of the script is static and is approximately 10k in size. The loader script must be inserted into the user’s HTML pages correctly: It must appear in the page's <head> tag before the first script tag. If there are no script tags, put the JavaScript immediately before the </head> (end of head) tag. The entire loader script must be inserted in-line, not as a link to the .js file. List all browser apps To view a list of your apps in New Relic Browser, replace ${APIKEY} with your New Relic API key in the following command. To accomplish the same task from the API Explorer, use your API key and go to rpm.newrelic.com/api/explore > Browser Applications > GET List. Use the following command: curl -X GET 'https://api.newrelic.com/v2/browser_applications.json' \\ -H \"X-Api-Key:${APIKEY}\" -i Copy You can use the results to verify the account or name, and to get a copy of the loader script for the app, if needed. View specific browser apps View by name: To view a specific Browser app if you know its name, replace ${APIKEY} with your New Relic API key, and replace ${NAME} with your app's name in the following command: curl -X GET 'https://api.newrelic.com/v2/browser_applications.json' \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d \"filter[name]=${NAME}\" Copy View by Browser application ID: To view a specific Browser app if you know its ID, replace ${APIKEY} with your New Relic API key, and replace ${ID} with your Browser application ID in the following command: curl -X GET 'https://api.newrelic.com/v2/browser_applications.json' \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'filter[ids]=${ID}' Copy View multiple browser apps: To get information for multiple apps, separate the name or ID values with a comma in these commands; for example: -d 'filter[ids]=12345,23456' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 256.8751,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add or list Browser apps <em>via</em> API (<em>v2</em>)",
        "sections": "Add or list Browser apps <em>via</em> API (<em>v2</em>)",
        "tags": "REST API <em>v2</em>",
        "body": "&quot;: &quot;string&quot;, &quot;loader_<em>script</em>&quot;: &quot;string&quot; } Copy API (<em>v2</em>) output Description Browser app id (integer) This is the unique identification code for each app in New Relic One. App name (string) This is the app&#x27;s name as it appears in the New Relic One. The browser_monitoring_key (string) This a unique key"
      },
      "id": "603ed6a928ccbc422beba77b"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/release-notes/agent-release-notes/python-release-notes/python-agent-60401158/",
      "sections": [
        "Python agent v6.4.1.158",
        "Notes",
        "New Features",
        "Improvements",
        "Bug Fixes"
      ],
      "published_at": "2021-06-15T00:39:12Z",
      "title": "Python agent v6.4.1.158",
      "updated_at": "2021-06-09T12:48:41Z",
      "type": "docs",
      "external_id": "e80e9b29d88819e6d2375727e58f985ad9f6c5e3",
      "document_type": "release_notes",
      "popularity": 1,
      "body": "Notes This release of the Python agent adds support for Flask v2, improves logging for HTTP exceptions, and includes a bug fix. The agent can be installed using easy_install/pip/distribute via the Python Package Index or can be downloaded directly from the New Relic download site. New Features Add support for Flask v2 The agent will automatically instrument error handlers, nested blueprints, and async views. Improvements Improved logging for 410 status codes The agent now logs the content of a data collector response which specifies the reason for a disconnect for 410 status codes. Bug Fixes Non-PID specific memory metric being reported In agent version v6.2.0.156, memory metrics were modified to add the PID to each metric name. This release reintroduces non-PID specific memory metrics.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 219.8862,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Python agent <em>v6.4.1.158</em>",
        "sections": "Python agent <em>v6.4.1.158</em>",
        "body": " support for Flask <em>v2</em> The agent will automatically instrument <em>error</em> handlers, nested blueprints, and async views. Improvements Improved logging for 410 status codes The agent now logs the content of a data collector response which specifies the reason for a disconnect for 410 status codes. Bug Fixes"
      },
      "id": "60c0b8aa196a67bcdad09e47"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/release-notes/agent-release-notes/go-release-notes/go-agent-3-13-0/",
      "sections": [
        "Go agent v3.13.0",
        "3.13.0",
        "Fixed",
        "Changes",
        "Support Statement"
      ],
      "published_at": "2021-06-15T14:09:00Z",
      "title": "Go agent v3.13.0",
      "updated_at": "2021-06-06T05:07:05Z",
      "type": "docs",
      "external_id": "0bac0cdc23c901431e264e8855e99095a4b31645",
      "document_type": "release_notes",
      "popularity": 1,
      "body": "3.13.0 Fixed Replaced the NR AWS SDK V2 integration for the v3 agent with a new version that works. See the v3/integrations/nrawssdk-v2/example/main.go file for an example of how to use it. Issues #250 and #288 are fixed by this PR. #309 Fixes issue #221: grpc errors reported in code watched by UnaryServerInterceptor() or StreamServerInterceptor() now create error events which are reported to the UI with the error message string included. #317 Fixes documentation in GUIDE.md for txn.StartExternalSegment() to reflect the v3 usage. Thanks to @abeltay for calling this to our attention and submitting PR #320. Changes The v3/examples/server/main.go example now uses newrelic.ConfigFromEnvironment(), rather than explicitly pulling in the license key with newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")). The team is starting to use this as a general systems integration testing script, and this facilitates testing with different settings enabled. Support Statement New Relic recommends that you upgrade the agent regularly to ensure that you're getting the latest features and performance benefits. Additionally, older releases will no longer be supported when they reach end-of-life.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.91232,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Go agent <em>v3.13.0</em>",
        "sections": "Go agent <em>v3.13.0</em>",
        "body": "3.13.0 Fixed Replaced the NR AWS SDK <em>V2</em> integration for the <em>v</em>3 agent with a new version that works. See the <em>v</em>3&#x2F;integrations&#x2F;nrawssdk-<em>v2</em>&#x2F;example&#x2F;main.go file for an example of how to use it. Issues #250 and #288 are fixed by this PR. #309 Fixes issue #221: grpc errors reported in code watched"
      },
      "id": "60bc57f9e7b9d2444d574d6e"
    }
  ],
  "/docs/csp-v2-host-install-browser-agent": [
    {
      "sections": [
        "Add or list Browser apps via API (v2)",
        "Important",
        "Add browser apps",
        "List all browser apps",
        "View specific browser apps"
      ],
      "title": "Add or list Browser apps via API (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Browser examples (v2)"
      ],
      "external_id": "53568984e3b360bac9255a33adad7e6b43fadf5d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/browser-examples-v2/add-or-list-browser-apps-api-v2/",
      "published_at": "2021-06-14T23:01:14Z",
      "updated_at": "2021-06-14T23:01:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are examples of how to use the New Relic REST API (v2) to add apps to browser monitoring or to get a list of your browser apps for a specific API key. This helps you manage deployment outside of New Relic One. These API calls are useful, for example, with larger organizations deploying multiple apps, or for integration partners who facilitate New Relic account creation and browser monitoring deployments. Important When you add a browser app via API (v2), you can only instrument basic page load timing. To use instrumentation supporting all SPA features, see Use Browser SPA agent. To add a fully instrumented app, go to one.newrelic.com, and click the Add more data button on the top right hand-side. Then, use the guided install to start monitoring your app. Add browser apps To add an app to New Relic One, replace ${APIKEY} with your New Relic API key, and replace ${STRING} with the app's name in the following command. To accomplish the same task from the API Explorer, use your API key and go to rpm.newrelic.com/api/explore > Browser Applications > POST Create. Use the following command: curl -X POST 'https://api.newrelic.com/v2/browser_applications.json' \\ -H \"X-Api-Key:${APIKEY}\" -i -H 'Content-Type: application/json' \\ -d \\ '{ \"browser_application\": { \"name\": ${STRING} } }' Copy The API returns an array of data where the element is a Browser application and the data associated with it: { \"browser_application\": { \"id\": \"integer\", \"name\": \"string\", \"browser_monitoring_key\": \"string\", \"loader_script\": \"string\" } Copy API (v2) output Description Browser app id (integer) This is the unique identification code for each app in New Relic One. App name (string) This is the app's name as it appears in the New Relic One. The browser_monitoring_key (string) This a unique key that is linked to (but is not the same as) the account license key. It is used to indicate the account in New Relic One where data will be reported. It cannot be used to determine your New Relic account's license key. Browser monitoring loader_script (string) The returned loader script is a JSON-encoded JavaScript snippet that is configured with the New Relic license key and application ID. The rest of the script is static and is approximately 10k in size. The loader script must be inserted into the user’s HTML pages correctly: It must appear in the page's <head> tag before the first script tag. If there are no script tags, put the JavaScript immediately before the </head> (end of head) tag. The entire loader script must be inserted in-line, not as a link to the .js file. List all browser apps To view a list of your apps in New Relic Browser, replace ${APIKEY} with your New Relic API key in the following command. To accomplish the same task from the API Explorer, use your API key and go to rpm.newrelic.com/api/explore > Browser Applications > GET List. Use the following command: curl -X GET 'https://api.newrelic.com/v2/browser_applications.json' \\ -H \"X-Api-Key:${APIKEY}\" -i Copy You can use the results to verify the account or name, and to get a copy of the loader script for the app, if needed. View specific browser apps View by name: To view a specific Browser app if you know its name, replace ${APIKEY} with your New Relic API key, and replace ${NAME} with your app's name in the following command: curl -X GET 'https://api.newrelic.com/v2/browser_applications.json' \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d \"filter[name]=${NAME}\" Copy View by Browser application ID: To view a specific Browser app if you know its ID, replace ${APIKEY} with your New Relic API key, and replace ${ID} with your Browser application ID in the following command: curl -X GET 'https://api.newrelic.com/v2/browser_applications.json' \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'filter[ids]=${ID}' Copy View multiple browser apps: To get information for multiple apps, separate the name or ID values with a comma in these commands; for example: -d 'filter[ids]=12345,23456' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 534.6002,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add or list <em>Browser</em> apps <em>via</em> API (<em>v2</em>)",
        "sections": "Add or list <em>Browser</em> apps <em>via</em> API (<em>v2</em>)",
        "tags": "<em>Browser</em> examples (<em>v2</em>)",
        "body": " multiple apps, or for integration partners who facilitate New Relic account creation and <em>browser</em> monitoring deployments. Important When you add a <em>browser</em> app via API (<em>v2</em>), you can only instrument basic page load timing. To use instrumentation supporting all SPA features, see Use <em>Browser</em> SPA <em>agent</em>. To add"
      },
      "id": "603ed6a928ccbc422beba77b"
    },
    {
      "sections": [
        "Install the browser monitoring agent",
        "Tip",
        "Select a deployment option",
        "Important",
        "Enable an APM-monitored app",
        "Enable with copy/paste",
        "Instrument webpages using the APM agent",
        "Troubleshoot Browser agent installation"
      ],
      "title": "Install the browser monitoring agent",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Installation"
      ],
      "external_id": "bc45bbc86cd4d8b81367ad0904907ddc735717f3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/browser-monitoring/installation/install-browser-monitoring-agent/",
      "published_at": "2021-06-14T21:26:03Z",
      "updated_at": "2021-06-14T21:26:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Browser uses a JavaScript snippet (or \"agent\") to instrument your app's webpages. The JavaScript collects data for browser monitoring. To install the browser agent, you can choose from a number of deployment options. Tip To use Browser and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Select a deployment option No matter which option you use to deploy browser monitoring, the end result is to inject the browser agent's JavaScript snippet into your pages for browser monitoring. The method you select depends on your preferences and business needs. To view the procedure to install and enable the browser agent, click the link for the option you want to use. You can also use the Browser Application settings page to update settings. Important The following configuration options refer only to the browser monitoring agent. These are not the same as the New Relic user roles and editions. Browser deployment option Description Use the APM agent to inject the JavaScript You can use an APM agent to automatically inject the browser monitoring JavaScript snippet for you. This is the easiest way to install the agent for an app that already is being monitored by APM. (APM-monitored apps are listed on your APM Applications index.) Paste the JavaScript snippet into a webpage This allows you to control the exact placement of the JavaScript into your app's webpage(s) by copying and pasting the browser agent's JavaScript snippet. This is useful for: Standalone apps, static sites, and cached pages delivered by CDN APM apps that are not as closely coupled to the browser app as with a standard server-side app (for example, when your client-side app talks to a REST API back end) Enable single-page app (SPA) monitoring Enabling SPA requires a Pro + SPA browser agent subscription, and you may need to re-deploy the browser JavaScript agent. Use the REST API The REST API lets you manage deployment outside the browser UI. This is useful for large organizations deploying multiple apps. Use an APM agent API to manually instrument the JavaScript snippet For apps that are monitored by APM, you can use the APM agent's API to inject the JavaScript manually instead of automatically. Enable an APM-monitored app Use this procedure to automatically deploy the browser agent on an app that is monitored by APM: Go to one.newrelic.com, select Browser, and then select Add more data. In the Back-end, front-end, and mobile applications section, select the New Relic Browser tile. When prompted to select the account you want to add this instrumentation to, choose your account, and click Continue. From the Get started with New Relic Browser page, in the Choose a deployment method section, select Enable via New Relic APM. In the Choose your instrumentation section, select Lite, Pro, or Pro + SPA. In the Configure your instrumentation section, make the selections you want. In the Select your application section, type or use the search window to find an app's name. Click Enable. Important Node.js: To finish enabling the browser agent for a Node.js app, follow the additional procedure to insert the JavaScript header into the beginning of your HTML page's head tag. Generate some traffic for your app. Wait a few minutes for Browser to start collecting data, then select your app from the Browser applications index. Enable with copy/paste Use this procedure to insert browser's JavaScript snippet for browser monitoring into your app's webpages yourself. This option is useful for monitoring static sites (such as Jekyll) or cached pages delivered by CDN. Tip Near the bottom of the generated JavaScript is your browser license key and application ID. This is useful with the REST API and API Explorer. Go to one.newrelic.com, select Browser, and then select Add more data. In the Back-end, front-end, and mobile applications section, select the New Relic Browser tile. When prompted to select the account you want to add this instrumentation to, choose your account, and click Continue. From the Get started with New Relic Browser page, in the Choose a deployment method section, select Copy/Paste JavaScript Code. In the Choose your instrumentation section, select the type of agent: Lite, Pro, or Pro + SPA. In the Configure your instrumentation section, make the selections you want. In the Name your app section, name your app: If your app is monitored by APM, select Yes, then type or use the search window to find the app's name. If you have a standalone app for Browser (not monitored by APM), select No, then type the app's name. Click Enable. A new section, Instrument the agent, opens on the page with JavaScript code for your project. Copy the code snippet, then paste it inline into your pages as close to the top of the <head> element as possible, but after any position-sensitive <meta> tags (for example, X-UA-Compatible or charset information). For more information on the inline head placement, see JavaScript placement requirements. Generate some traffic for your app. Wait a few minutes for Browser to start collecting data, then select your app from the Browser applications index. If you use the copy/paste method, but don't finish the setup process, you can still view and copy the generated JavaScript snippet from your app's Browser Application settings page or by using the REST API (v2). Instrument webpages using the APM agent This information applies to apps that are also monitored by APM. New Relic's agents can instrument webpages with the required JavaScript for page load timing. If you use the APM agent to add the JavaScript snippet to your webpages, insert the instrumentation snippet as close to the top as possible. This allows you to take advantage of detailed information about browser's AJAX calls and JavaScript errors. For more information, see the instructions for your APM agent: C SDK Go Java .NET Node.js PHP Python Ruby Troubleshoot Browser agent installation When you enable browser Pro features for session traces, AJAX calls, or JavaScript errors, it may take approximately five minutes before information becomes available. If you have problems with your browser installation or if no data appears after five minutes, refer to the troubleshooting tips, and restart your agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 362.09857,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> <em>the</em> <em>browser</em> monitoring <em>agent</em>",
        "sections": "<em>Install</em> <em>the</em> <em>browser</em> monitoring <em>agent</em>",
        "tags": "<em>Installation</em>",
        "body": "&#x27;s <em>Browser</em> Application settings page or by using the REST API (<em>v2</em>). Instrument webpages using the APM <em>agent</em> This information applies to apps that are also monitored by APM. New Relic&#x27;s agents can instrument webpages with the required JavaScript for page load timing. If you use the APM <em>agent</em> to add"
      },
      "id": "604429e628ccbcb80b2c60d0"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/release-notes/agent-release-notes/python-release-notes/python-agent-60401158/",
      "sections": [
        "Python agent v6.4.1.158",
        "Notes",
        "New Features",
        "Improvements",
        "Bug Fixes"
      ],
      "published_at": "2021-06-15T00:39:12Z",
      "title": "Python agent v6.4.1.158",
      "updated_at": "2021-06-09T12:48:41Z",
      "type": "docs",
      "external_id": "e80e9b29d88819e6d2375727e58f985ad9f6c5e3",
      "document_type": "release_notes",
      "popularity": 1,
      "body": "Notes This release of the Python agent adds support for Flask v2, improves logging for HTTP exceptions, and includes a bug fix. The agent can be installed using easy_install/pip/distribute via the Python Package Index or can be downloaded directly from the New Relic download site. New Features Add support for Flask v2 The agent will automatically instrument error handlers, nested blueprints, and async views. Improvements Improved logging for 410 status codes The agent now logs the content of a data collector response which specifies the reason for a disconnect for 410 status codes. Bug Fixes Non-PID specific memory metric being reported In agent version v6.2.0.156, memory metrics were modified to add the PID to each metric name. This release reintroduces non-PID specific memory metrics.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 337.4115,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Python <em>agent</em> <em>v6.4.1.158</em>",
        "sections": "Python <em>agent</em> <em>v6.4.1.158</em>",
        "body": "Notes This release of the Python <em>agent</em> adds support for Flask <em>v2</em>, improves logging for HTTP exceptions, and includes a bug fix. The <em>agent</em> can be installed using easy_<em>install</em>&#x2F;pip&#x2F;distribute via the Python Package Index or can be downloaded directly from the New Relic download site. New Features Add"
      },
      "id": "60c0b8aa196a67bcdad09e47"
    }
  ],
  "/docs/csp-v2-monitor-salesforce": [
    {
      "sections": [
        "Add or list Browser apps via API (v2)",
        "Important",
        "Add browser apps",
        "List all browser apps",
        "View specific browser apps"
      ],
      "title": "Add or list Browser apps via API (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Browser examples (v2)"
      ],
      "external_id": "53568984e3b360bac9255a33adad7e6b43fadf5d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/browser-examples-v2/add-or-list-browser-apps-api-v2/",
      "published_at": "2021-06-14T23:01:14Z",
      "updated_at": "2021-06-14T23:01:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are examples of how to use the New Relic REST API (v2) to add apps to browser monitoring or to get a list of your browser apps for a specific API key. This helps you manage deployment outside of New Relic One. These API calls are useful, for example, with larger organizations deploying multiple apps, or for integration partners who facilitate New Relic account creation and browser monitoring deployments. Important When you add a browser app via API (v2), you can only instrument basic page load timing. To use instrumentation supporting all SPA features, see Use Browser SPA agent. To add a fully instrumented app, go to one.newrelic.com, and click the Add more data button on the top right hand-side. Then, use the guided install to start monitoring your app. Add browser apps To add an app to New Relic One, replace ${APIKEY} with your New Relic API key, and replace ${STRING} with the app's name in the following command. To accomplish the same task from the API Explorer, use your API key and go to rpm.newrelic.com/api/explore > Browser Applications > POST Create. Use the following command: curl -X POST 'https://api.newrelic.com/v2/browser_applications.json' \\ -H \"X-Api-Key:${APIKEY}\" -i -H 'Content-Type: application/json' \\ -d \\ '{ \"browser_application\": { \"name\": ${STRING} } }' Copy The API returns an array of data where the element is a Browser application and the data associated with it: { \"browser_application\": { \"id\": \"integer\", \"name\": \"string\", \"browser_monitoring_key\": \"string\", \"loader_script\": \"string\" } Copy API (v2) output Description Browser app id (integer) This is the unique identification code for each app in New Relic One. App name (string) This is the app's name as it appears in the New Relic One. The browser_monitoring_key (string) This a unique key that is linked to (but is not the same as) the account license key. It is used to indicate the account in New Relic One where data will be reported. It cannot be used to determine your New Relic account's license key. Browser monitoring loader_script (string) The returned loader script is a JSON-encoded JavaScript snippet that is configured with the New Relic license key and application ID. The rest of the script is static and is approximately 10k in size. The loader script must be inserted into the user’s HTML pages correctly: It must appear in the page's <head> tag before the first script tag. If there are no script tags, put the JavaScript immediately before the </head> (end of head) tag. The entire loader script must be inserted in-line, not as a link to the .js file. List all browser apps To view a list of your apps in New Relic Browser, replace ${APIKEY} with your New Relic API key in the following command. To accomplish the same task from the API Explorer, use your API key and go to rpm.newrelic.com/api/explore > Browser Applications > GET List. Use the following command: curl -X GET 'https://api.newrelic.com/v2/browser_applications.json' \\ -H \"X-Api-Key:${APIKEY}\" -i Copy You can use the results to verify the account or name, and to get a copy of the loader script for the app, if needed. View specific browser apps View by name: To view a specific Browser app if you know its name, replace ${APIKEY} with your New Relic API key, and replace ${NAME} with your app's name in the following command: curl -X GET 'https://api.newrelic.com/v2/browser_applications.json' \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d \"filter[name]=${NAME}\" Copy View by Browser application ID: To view a specific Browser app if you know its ID, replace ${APIKEY} with your New Relic API key, and replace ${ID} with your Browser application ID in the following command: curl -X GET 'https://api.newrelic.com/v2/browser_applications.json' \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'filter[ids]=${ID}' Copy View multiple browser apps: To get information for multiple apps, separate the name or ID values with a comma in these commands; for example: -d 'filter[ids]=12345,23456' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 438.45685,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add or list Browser apps <em>via</em> API (<em>v2</em>)",
        "sections": "Add or list Browser apps <em>via</em> API (<em>v2</em>)",
        "tags": "REST API <em>v2</em>",
        "body": "Here are examples of how to use the New Relic REST API (<em>v2</em>) to add apps to browser monitoring or to get a list of your browser apps for a specific API key. This helps you manage deployment outside of New Relic One. These API calls are useful, for example, with larger organizations deploying"
      },
      "id": "603ed6a928ccbc422beba77b"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/csp-v2-host-install-browser-agent/",
      "sections": [
        "CSP v2: Host and install the Browser agent",
        "Contents",
        "Requirements",
        "1. Whitelist New Relic Browser domains",
        "2. Copy Browser app's JS snippet",
        "3. Create .js file for page"
      ],
      "published_at": "2021-06-14T17:52:44Z",
      "title": "CSP v2: Host and install the Browser agent",
      "updated_at": "2021-05-16T11:10:54Z",
      "type": "docs",
      "external_id": "75530e0b53071dd92148ca07d572bc3a032e9c4e",
      "document_type": "page",
      "popularity": 1,
      "body": "If your organization has strict requirements about Content Security Policy (CSP) v2, you may need to host the New Relic Browser agent in order to properly install and run it. For example, if the New Relic domain hosting the Browser agent is being blocked by your website, you may see an error similar to this: Browser agent.js is unable to run because it violates the following Content Security Protocol directive: script-src = *.google.com other URLs Copy In this situation, you must copy and paste the agent's JavaScript code and self-host it as a .js file. This allows the page to reference the .js file during page load. Contents Requirements In order to host the Browser agent with your app, make sure you follow these requirements: CSP and Browser agent Requirements Application or platform Your app or platform where your site is hosted must meet New Relic Browser's standard compatibility requirements. Exception: CSP restrictions prevent you from linking an APM app for Browser monitoring. Subscription You must have a Pro+SPA Browser subscription for your app. Host location for domains The .js file for New Relic Browser must be hosted on a highly available or replicated location, such as a CDN or distributed network. This helps ensure performance is not affected. If you see error messages, add New Relic Browser domains to your CSP whitelist. If you want New Relic Browser to monitor Salesforce Lightning pages, follow the Salesforce procedures to add New Relic Browser domains to your CSP whitelist. By hosting the agent, you are responsible for any performance impact on the location where the agent is hosted. Browser agent version Your selected app must use the latest Browser agent version. 1. Whitelist New Relic Browser domains Follow your organization's standard procedures to request a CSP exception. Then add both of these New Relic Browser domains to your CSP whitelist: https://js-agent.newrelic.com: This is where the New Relic Browser agent is hosted. The Browser agent download requires three files to run. Two are downloaded after the initial agent is run to continue capturing performance data. https://bam.nr-data.net: This is the endpoint where the New Relic Browser agent receives data from your site. Here is example HTML to add to the head of your site: Content-Security-Policy: default-src 'self' https://js-agent.newrelic.com https://bam.nr-data.net Copy 2. Copy Browser app's JS snippet To create and host a .js file, you must first copy the Browser agent's JavaScript snippet from the hosting app. Go to one.newrelic.com and click Browser. From the list of Browser apps, select the app for which you want to self-host the Browser agent. Select Settings > Application settings > Copy/paste JavaScript code. Copy the Browser agent's JavaScript snippet. Save and exit the Browser app's Application settings page. Continue with the procedures to create a .js file for your page. 3. Create .js file for page After you copy the Browser agent's JavaScript snippet from the selected Browser app: Open a text editor and paste the Browser agent's JavaScript snippet. Delete the first line (<script type=\"text/javascript\">) and the last line of the JavaScript snippet (</script>). Save the text file as nr-spa-VERSION_NUMBER.min.js, where VERSION_NUMBER is the latest Browser agent version. Reference the .js file in the <head> of your webpage. After you install the Browser agent's JavaScript snippet, you can use the New Relic Browser UI to monitor website performance.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 296.19666,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>CSP</em> <em>v2</em>: Host and install the Browser agent",
        "sections": "<em>CSP</em> <em>v2</em>: Host and install the Browser agent",
        "body": "If your organization has strict requirements about Content Security Policy (<em>CSP</em>) <em>v2</em>, you may need to host the New Relic Browser agent in order to properly install and run it. For example, if the New Relic domain hosting the Browser agent is being blocked by your website, you may see an error"
      },
      "id": "6043d37364441f42cf378ee8"
    },
    {
      "sections": [
        "Introduction to New Relic's REST API Explorer",
        "Features",
        "Differences from API version 1",
        "Tip",
        "For more help"
      ],
      "title": "Introduction to New Relic's REST API Explorer",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "API Explorer v2"
      ],
      "external_id": "457d31007ab690d5e6f3679e150814c280b49441",
      "image": "https://docs.newrelic.com/static/c506cb08149178347d12b6cbb236c855/23592/API_explorer_main_page.png",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/api-explorer-v2/introduction-new-relics-rest-api-explorer/",
      "published_at": "2021-06-14T22:20:16Z",
      "updated_at": "2021-05-16T14:36:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers several APIs, including the New Relic REST API. This document introduces you to the REST API Explorer, which allows admin users and those with the API Key to: Browse the available REST API endpoints. Interact with the REST API within a user interface (the API Explorer). View a live source of documentation. Obtain curl commands for API actions. Share configured API calls with colleagues by copy and pasting API Explorer's URLs. This helps you to quickly search for solutions and test your API calls before adding them to your own software components. Features New Relic's API Explorer includes an interactive user interface for your selected account. The API Explorer UI lists the types of API calls (Applications, Users, etc.) and their available functions, such as GET metric data, PUT (update) applications, DELETE applications, etc. As you type values for Parameters, they automatically appear in the Request so that you can test and verify your syntax before sending the request. The UI indicates required fields, field descriptions, their type (integer, float, Boolean, etc.), and their location (path, query, etc.). For information on API keys, see REST API keys. rpm.newrelic.com/api/explore: The New Relic API Explorer makes it easy to test and send requests for any API endpoint. After you select your account and your choice of functions for the type of API call (applications, browsers, users, etc.), the UI provides an interactive form to view requirements and test your parameter values. Differences from API version 1 This API Explorer applies only to the New Relic REST API version 2, which focuses on data in and data out of New Relic. Version 2 replaces New Relic's deprecated REST API version 1. Be aware there are some differences between version 2 and 1: Names for data may be different. Some cURL commands for v2 are different than v1. Tip The New Relic agents use different APIs and are not accessible via the API Explorer. For more help",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 259.0883,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Differences from API <em>version</em> 1",
        "tags": "REST API <em>v2</em>",
        "body": ": Names for data may be different. Some cURL commands for <em>v2</em> are different than <em>v</em>1. Tip The New Relic agents use different APIs and are not accessible via the API Explorer. For more help"
      },
      "id": "6043ff97196a67c2f2960f65"
    }
  ],
  "/docs/distributed-tracing/concepts/distributed-tracing-planning-guide": [
    {
      "sections": [
        "Trace API general requirements and limits",
        "Endpoints",
        "Data formats",
        "Data limits",
        "Restricted attributes",
        "Request metadata (headers and query parameters)",
        "Important",
        "Response validation",
        "See HTTP status codes",
        "Exceeding span limits"
      ],
      "title": "Trace API general requirements and limits ",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "f77504082dae8374e0c7009a31abebbd4c0123f3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/trace-api-general-requirements-limits/",
      "published_at": "2021-06-14T18:07:42Z",
      "updated_at": "2021-06-09T00:57:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Information about Trace API data requirements, including: Data specifications and max limits Required metadata (headers, query parameters) Response validation details This document applies to the Trace API overall. For rules regarding specific data formats, see: New Relic-format trace data Zipkin-format trace data Endpoints All trace data is sent via a POST to a Trace API endpoint. We have a few endpoints, depending on your setup: Default Trace API endpoint: https://trace-api.newrelic.com/trace/v1 EU data centers: https://trace-api.eu.newrelic.com/trace/v1 (see other EU endpoints). Infinite Tracing: when you complete the Trace observer setup, you get a custom YOUR_TRACE_OBSERVER_URL value to use as an endpoint. If you're using an integration that uses the Trace API (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust the sampling of your tracing service to send us 100% of spans. For FedRAMP, see FedRAMP endpoints. Data formats Currently, the Trace API accepts two types of data formats: zipkin: For reporting Zipkin trace data. Zipkin data must be Zipkin JSON v2. newrelic: For reporting all other trace data. Data limits Data limits and rules: Condition Limit Max age of span timestamp values 20 minutes. timestamp must be within 20 minutes of current time at ingest, or within 20 minutes from the time the last span with the same trace.id was received by New Relic. Max payload size 1MB (10^6 bytes) (gzip compression supported) Max requests per minute 100K Max spans per minute per account family Dependent on agreement. Max limit: 2M. Max spans per trace 50K Max attributes per span 200 Max span attribute value length 4000 characters Allowed HTTP protocols HTTPS only Cross-account visibility of span details Potential data obfuscation To see an example of how span limits are enforced, see Exceeding limits. Restricted attributes The attributes in the table below are restricted in the newrelic-format JSON (in the attributes block) and in the zipkin-format JSON (in the tags block). Any values with these keys will be omitted: Restricted attribute Description entityGuid string Unique identifier for the entity that created this span. Generated from service.name, if available. guid string Used for backwards compatibility with data from APM agents. The attributes in the table below are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Restricted attribute description entity.guid string Unique identifier for the entity associated with this span. entity.name string Human-readable name of an entity, often used to identify an entity in the UI. entity.type string Used to differentiate between different types of entities, like hosts, applications, etc. Request metadata (headers and query parameters) The following table shows the required request metadata for all trace data formats. This metadata can be sent as HTTP headers on an ingest request or, in some cases, provided as query parameters, which may be required for tracing frameworks that don't allow header modification. Important Security note: We suggest using headers because query parameters are present in the URL and may be logged before being encrypted and received by New Relic. All data sent as query parameters must be URL-safe. Header Query param? Details Content-Type No Required. Must be application/json. Content-Length No Required. The length of the request body in octets (8-bit bytes) unless sent with chunked encoding. This header is generally set by default by the underlying HTTP client sending the data and in most cases should not require any additional effort by the end user. Api-Key Yes (case-sensitive) Required. The Trace API requires the Insights insert key. If this is provided as both a header and a query parameter, the values must match. Content-Encoding No Required if compressed payload. The value must be gzip. Data-Format Yes Required for zipkin. Optional for newrelic. If present, Data-Format-Version must also be present. Data-Format-Version Yes Required for zipkin. If present, Data-Format must also be present. There are only two possible pairings for these values: If Data-Format is zipkin, Data-Format-Version must be 2. If Data-Format is newrelic, Data-Format-Version must be 1. x-request-id No Optional - Reserved for future use. The value must be a valid UUID4. The value is expected to be unique for each request. Response validation A response for successfully sending trace data will include a requestId. For example: {\"requestId\":\"c1bb62fc-001a-b000-0000-016bb152e1bb\"} Copy There are two ways success/errors are signaled: HTTP status code (synchronous). Authentication and request errors will be signaled via HTTP status code. See HTTP status codes Code Meaning 202 Data accepted. This means that you've passed preliminary checks, but is not a guarantee that the data has been successfully parsed and indexed as part of a distributed trace. 400 The structure of the request was invalid. Errors with query parameters, etc. 403 Authentication error. May occur with an invalid license key or if you lack necessary entitlement to use the Trace API. 404 The request path is incorrect. 405 For any request method other than POST. 408 The request took too long to reach the endpoint. 411 The Content-Length header wasn’t included. 413 The payload was too big. 414 The request URI was too long. 415 The Content-Type or Content-Encoding was invalid. 429 The request rate quota has been exceeded. 431 The request headers are too long. 5xx There was a server error (please retry). NrIntegrationError events (asynchronous). Errors with the JSON payload or other semantic errors are asynchronously signaled via NrIntegrationError events that are stored in the account whose license key is associated with the request. For all errors of this type, the attribute newRelicFeature will be Distributed Tracing and requestId will be the requestId from the endpoint response. If you receive a 202 response and don't see an NrIntegrationError event, your data should be visible in New Relic One's global distributed tracing UI in about a minute. You should be able to find the trace using a standard trace search like: traceId = TRACE_ID_SENT Copy Exceeding span limits When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate limit messages with this NRQL: SELECT * FROM NrIntegrationError WHERE newRelicFeature = 'Distributed Tracing' AND category = 'RateLimit' AND rateLimitType = 'SpansPerMinute' Copy To get a notification when you exceed the limit, you can set up a NRQL alert. We calculate a rolling 10-minute average based on your span rate limit. This allows for temporary rate bursts, and lets us prioritize keeping and dropping complete traces instead of indiscriminately dropping spans on a per minute limit basis. In the example below of exceeding the rate, the rate limit is the default 100,000 spans per minute. New Relic allows a burst above 100K for a couple of minutes without downsampling, because the remaining minutes in the 10-minute window averaged under 100K spans/minute. For the previous 10 minutes (8:50 - 9:00) the service received 60,000 spans/minute. Minute Spans sent to API Total for past 10 minutes 8:59 60,000 600,000 9:00 40,000 580,000 9:01 50,000 570,000 9:02 250,000 760,000 9:03 220,000 920,000 9:04 125,000 985,000 9:05 70,000 995,000 9:06 50,000 985,000 9:07 40,000 965,000 9:08 40,000 945,000 9:09 40,000 925,000",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 211.2908,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Trace</em> API general requirements and limits ",
        "sections": "<em>Trace</em> API general requirements and limits",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>Tracing</em>: when you complete the <em>Trace</em> observer setup, you <em>get</em> a custom YOUR_<em>TRACE</em>_OBSERVER_URL value to use as an endpoint. If you&#x27;re using an integration that uses the <em>Trace</em> API (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust"
      },
      "id": "6071cf7628ccbcf8b851c158"
    },
    {
      "sections": [
        "How New Relic distributed tracing works",
        "Tip",
        "Trace sampling",
        "Head-based sampling (standard distributed tracing)",
        "Language agents: adaptive sampling",
        "Language agents: limits and sampling",
        "Trace rate limiting",
        "Lambda trace sampling",
        "Tail-based sampling (Infinite Tracing)",
        "Architecture",
        "Tail-based sampling algorithms",
        "No sampling",
        "Browser and Mobile trace reporting",
        "Trace API",
        "How trace data is structured",
        "How trace data is stored",
        "How trace context is passed between applications",
        "Important",
        "Scenario 1: Trace touching three agent types",
        "Scenario 2: Trace with W3C New Relic and middleware",
        "Scenario 3: Trace with any W3C-compliant agent and a New Relic agent."
      ],
      "title": "How New Relic distributed tracing works",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "4dbe0119017f78ad4db2a2b8a9ca2d287222753a",
      "image": "https://docs.newrelic.com/static/406c9f3af4012dab16df681c8feab256/c1b63/new-relic-distributed-tracing-trace-structure.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/how-new-relic-distributed-tracing-works/",
      "published_at": "2021-06-14T18:03:45Z",
      "updated_at": "2021-05-16T15:32:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some technical details about how New Relic distributed tracing works: How trace sampling works How we structure trace data How we store trace data How trace context is passed between applications Tip For instructions about setting up distributed tracing, see Overview: Enable distributed tracing. Trace sampling How your traces are sampled will depend on your setup and the New Relic tracing tool you're using. For example, you may be using a third-party telemetry service (like OpenTelemetry) to implement sampling of traces before your data gets to us or, if you're using Infinite Tracing, you'd probably send us all your trace data and use our sampling. We have a few sampling strategies available: Head-based sampling (standard distributed tracing) Tail-based sampling (Infinite Tracing) No sampling Head-based sampling (standard distributed tracing) With the exception of our Infinite Tracing feature, most of our tracing tools use a head-based sampling approach. This applies filters to individual spans before all spans in a trace arrive, which means decisions about whether to accept spans is made at the beginning (the \"head\") of the filtering process. We use this sampling strategy to capture a representative sample of activity while avoiding storage and performance issues. Here are some details about how head-based sampling is implemented in our standard distributed tracing tools: Language agents: adaptive sampling Our APM language agents use adaptive sampling to capture a representative sample of system activity. The following is an explanation of how adaptive sampling works. For the first service in a distributed trace, 10 requests are chosen to be sampled. The throughput to that service is used to adjust how frequently requests are sampled. This is explained in more detail below. The first service we monitor in a distributed trace is called the trace origin. The trace origin chooses requests at random to be traced. That decision propagates to the downstream services touched by that request. When the request has completed, all of the spans touched by that request that we've detected are made available in the UI as a complete trace (though agent limits may result in fragmented traces). APM agents have a limit on the number of transactions collected per minute (this can vary, depending on agent) and a limit on the number of spans collected per minute (1000 per agent instance). To adhere to these limits, the default number of traces at the trace origin is 10 traces per minute. An APM agent spreads out the collection of these 10 traces over a minute in order to get a representative sample over time. The exact sampling rate depends on the number of transactions in the previous minute. The rate responds to changes in transaction throughput, going up or down. For example, if the previous minute had 100 transactions, the agent would anticipate a similar number of transactions and select 1 out of every 10 transactions to be traced. Language agents: limits and sampling An APM language agent instance using head-based sampling has a limit of 1000 spans per minute. The agent attempts to keep all spans that are marked to be sampled as part of a distributed trace. In many distributed systems, the average microservice may generate 10 to 20 spans per request. In those cases, the agent span limit can accommodate all spans chosen, and that service will have full detail in a trace. However, some requests to services will generate many spans, and the agent span limit will be reached. As a result, some traces will not have full detail for that service. One solution to this would be to custom instrument an agent to report less activity and therefore report fewer spans. To read about how browser monitoring of trace data may vary from our language agents, see Browser traces. Trace rate limiting If the above sampling methods still result in too much trace data, we may limit incoming data by sampling traces after they're received. By making this decision at the trace level, it avoids fragmenting traces (accepting only part of a trace). This process works similarly to adaptive sampling. The total spans received in a minute are totaled. If too many spans are received, fewer spans may be accepted in the following minute, in order to achieve a floating-average throughput rate. Lambda trace sampling Our AWS Lambda monitoring uses its own sampling process. Tail-based sampling (Infinite Tracing) Our Infinite Tracing feature uses a tail-based sampling approach. \"Tail-based sampling\" means that trace-retention decisions are done at the tail end of processing after all the spans in a trace have arrived. With Infinite Tracing, you can send us 100% of your trace data from your application or third-party telemetry service, and Infinite Tracing will figure out which trace data is most important. And you can configure the sampling to ensure the traces important to you are retained. Architecture For Infinite Tracing, agents or integrations send 100% of all instrumented spans to a trace observer. The trace observer is a distributed tracing service residing in a cluster of services on AWS called New Relic Edge. Tip Only your spans go to the trace observer—all other data such as metrics, custom events, and transaction traces are sent the normal route to New Relic and are subject to local sampling. You configure a unique trace observer endpoint for the AWS region you want to send data to. You can request multiple endpoints, one per AWS region. The endpoint represents a trace observer for a particular workload. For example, all spans from a single trace (request) must go to that endpoint. Here are two architectural diagrams: one showing how data flows if you use APM agents and another if you use New Relic integrations like OpenTelemetry exporters: The trace observer holds traces open while spans for that trace arrive. Once the first span in a trace arrives, a session is kept open for 10 seconds. Each time a new span for that trace arrives, the expiration time is reset to 10 seconds. Traces that haven't seen a span arrive within the last 10 seconds will automatically expire. Tail-based sampling algorithms By default, each trace observer offers traces to three samplers: one looking for duration outliers, one looking for traces with errors, and one trying to randomly sample across all trace types. Each sampler keeps a target percentage of traces that match their criteria. Here are details about each sampler: Sampler Matching criteria Target percent Duration Traces with an outlier duration, using two algorithms: Gaussian (Assumes a normal distribution and a threshold at the 99th percentile) Eccentricity (Assumes no distribution and a threshold based on cluster) 100% Error Traces having at least one span with an error 100% Random All traces 1% (This is configurable. See Infinite Tracing: Random trace filter) If the matching criteria matches the trace, each sampler looks at the trace’s shape. A trace’s shape is the unique combination of the root span’s entity name and span name. This is a simple way to separate traces using the entry point of the request. Once the shape is determined, the sampler makes a decision to keep or reject the trace based on its target sampling percent. If it’s 100%, the trace is automatically kept. If it’s anything less, the probability the sampler keeps a given trace is determined by the target percent. For example, the default target percent is 1 for random traces, so 1% of those traces are kept. If you prefer, you can change the random filter percentage. Because the trace observer uses percentages of throughput, the number of traces selected will vary with that throughput. No sampling Some of our tools don't use sampling. Sampling details for these tools: Browser and Mobile trace reporting Browser monitoring distributed tracing and Mobile monitoring report all spans. Our APM language agents are often used in conjunction with browser and mobile monitoring, and our language agents use sampling. This means that there will likely be many more browser and mobile spans than back-end spans, which can result in browser and mobile app spans disconnected from back-end spans. For tips on querying for traces that contain front and back-end spans, see Find browser span data. Trace API If you don't have Infinite Tracing enabled, our Trace API does no sampling (unless the default data limits are exceeded). It's expected that you set up the Trace API to send us the traces you think are important. How trace data is structured Understanding the structure of a distributed trace can help you: Understand how traces are displayed in our UI Help you query trace data A distributed trace has a tree-like structure, with \"child\" spans that refer to one \"parent\" span. This diagram shows some important span relationships in a trace: This diagram shows how spans in a distributed trace relate to each other. This diagram shows several important concepts: Trace root. The first service or process in a trace is referred to as the root service or process. Process boundaries. A process represents the execution of a logical piece of code. Examples of a process include a backend service or Lambda function. Spans within a process are categorized as one of the following: Entry span: the first span in a process. Exit span: a span is a considered an exit span if it a) is the parent of an entry span, or b) has http. or db. attributes and therefore represents an external call. In-process span: a span that represents an internal method call or function and that is not an exit or entry span. Client spans. A client span represents a call to another entity or external dependency. Currently, there are two client span types: Datastore. If a client span has any attributes prefixed with db. (like db.statement), it's categorized as a datastore span. External. If a client span has any attributes prefixed with http. (like http.url) or has a child span in another process, it's categorized as an external span. This is a general category for any external calls that are not datastore queries. Trace duration. A trace's total duration is determined by the length of time from the start of the earliest span to the completion of the last span. You can query span relationship data with the NerdGraph GraphiQL explorer at api.newrelic.com/graphiql. How trace data is stored Understanding how we store trace data can help you query your trace data. We save trace data as: Span: A span represents operations that are part of a distributed trace. The operations that a span can represent include browser-side interactions, datastore queries, calls to other services, method-level timing, and Lambda functions. One example: in an HTTP service, a span is created at the start of an HTTP request and completed when the HTTP server returns a response. Span attributes contain important information about that operation (such as duration, host data, etc.), including trace-relationship details (such as traceId, guid). For span-related data, see span attributes. Transaction: If an entity in a trace is monitored by an agent, a request to that entity generates a single Transaction event. Transactions allow trace data to be tied to other New Relic features. For transaction-related data, see transaction attributes. Contextual metadata. We store metadata that shows calculations about a trace and the relationships between its spans. To query this data, use the NerdGraph GraphiQL explorer. How trace context is passed between applications We support the W3C Trace Context standard, which makes it easier to trace transactions across networks and services. When you enable distributed tracing, New Relic agents add HTTP headers to a service's outbound requests. HTTP headers act like passports on an international trip: They identify your software traces and carry important information as they travel through various networks, processes, and security systems. The headers also contain information that helps us link the spans together later: metadata like the trace ID, span ID, the New Relic account ID, and sampling information. This header information is passed along each span of a trace, unless the progress is stopped by something like middleware or agents that don't recognize the header format (see Figure 1). Figure 1 To address the problem of header propagation, we support the W3C Trace Context specification that requires two standardized headers. Our latest W3C New Relic agents send and receive these two required headers, and by default, they also send and receive the header of the prior New Relic agent: W3C (traceparent): The primary header that identifies the entire trace (trace ID) and the calling service (span id). W3C (tracestate): A required header that carries vendor-specific information and tracks where a trace has been. New Relic (newrelic): The original, proprietary header that is still sent to maintain backward compatibility with prior New Relic agents. This combination of three headers allows traces to be propagated across services instrumented with these types of agents: W3C New Relic agents Non-W3C New Relic agents W3C Trace Context-compatible agents Important If your requests only touch W3C Trace Context-compatible agents, you can opt to turn off the New Relic header. See the agent configuration documentation for details about turning off the newrelic header. The scenarios below show various types of successful header propagation. Scenario 1: Trace touching three agent types This shows the flow of headers when a request touches three different agent types: Scenario 2: Trace with W3C New Relic and middleware This shows the combination of headers sent by a W3C New Relic agent to some middleware. Scenario 3: Trace with any W3C-compliant agent and a New Relic agent. This shows the two required W3C headers from another vendor accepted by a W3C New Relic agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 200.09785,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "sections": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Here are some technical details about how New Relic <em>distributed</em> <em>tracing</em> works: How <em>trace</em> sampling works How we structure <em>trace</em> data How we store <em>trace</em> data How <em>trace</em> context is passed between applications Tip For instructions about setting up <em>distributed</em> <em>tracing</em>, see Overview: Enable <em>distributed</em>"
      },
      "id": "6072a66664441f14089d856c"
    },
    {
      "sections": [
        "Span attributes"
      ],
      "title": "Span attributes",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "725c10cb22b5d8f3b2a825c2dbf38b8640f93b13",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/span-attributes/",
      "published_at": "2021-06-14T18:09:35Z",
      "updated_at": "2021-06-02T17:14:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing creates Span data that can be queried in New Relic. Here are ways to learn more about Span data: To explore your span data, you can use the query builder. To see the default attributes attached to span data, use the data dictionary. For help with NRQL queries using these attributes, see these example queries.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.44902,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "<em>Distributed</em> <em>tracing</em> creates Span data that can be queried in New Relic. Here are ways to learn more about Span data: To explore your span data, you can use the query builder. To see the default attributes attached to span data, use the data dictionary. For help with NRQL queries using these attributes, see these example queries."
      },
      "id": "6072a767196a673e9964a7c3"
    }
  ],
  "/docs/distributed-tracing/concepts/how-new-relic-distributed-tracing-works": [
    {
      "sections": [
        "Distributed tracing: Planning guide",
        "Impact to APM features",
        "External services page has less detail",
        "Transaction trace UI displays service URLs, not transaction links",
        "Cross-application tracing will be disabled",
        "Impacts related to mobile monitoring",
        "Plan your rollout",
        "Enable distributed tracing"
      ],
      "title": "Distributed tracing: Planning guide",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "10263f2b6ec929f082153e28cbce07fe3a1f106a",
      "image": "https://docs.newrelic.com/static/7072dfa9e494767baabba420d78e7094/c1b63/distributed-trace-txn-trace-affects.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/distributed-tracing-planning-guide/",
      "published_at": "2021-06-14T18:03:44Z",
      "updated_at": "2021-05-28T11:44:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you are new to New Relic distributed tracing, we recommend you read the following before you enable distributed tracing. Impact to APM features Our distributed tracing improves on APM's previous cross application tracing feature. Here are some key benefits: See more cross-service activity details and more complete end-to-end traces. Filter and query traces, as well as make custom charts. See the complete trace even when calls cross account boundaries (for accounts with the same master account or in the same customer partnership). See Introduction to distributed tracing for other features. Enabling distributed tracing may affect some APM features you currently use. These changes affect only applications monitored by agents that have distributed tracing enabled—they don't apply on an account-level. We may provide backward compatibility with some or all of the affected features in future releases. For now, you should understand the following changes before enabling distributed tracing: External services page has less detail When distributed tracing is enabled for an application, external calls do not have internal transaction details at one.newrelic.com > APM > (select an app) > Monitor > External services > (select external service). To find that information, you would instead go to the Distributed tracing UI page, find the external call URLs, and see what their child spans are. Transaction trace UI displays service URLs, not transaction links When distributed tracing is enabled for an application, the transaction trace UI will no longer have the transaction name and link for the called service (see screenshot below). This will be replaced with the called service's URL. one.newrelic.com > APM > (select an app) > Monitor > Transactions > (select a transaction trace): This shows the transaction trace UI before distributed tracing is enabled, with a link to the associated transaction. With distributed tracing enabled, it will display the service's URL. If you wanted to get more detail about trace activity, you would go to the Distributed tracing UI page and examine that trace. Cross-application tracing will be disabled Enabling distributed tracing will disable the cross application tracing feature. Distributed tracing is an improved version of cross-application tracing and only one can be enabled at a time. Impacts related to mobile monitoring APM-related impacts include: When distributed tracing is enabled for an APM-monitored entity, legacy service maps will not show applications monitored by mobile. The App server drill-down feature of the legacy Mobile HTTP requests UI page is not available. Plan your rollout If you're enabling distributed tracing for a large, distributed system, here are some tips: If you are a current APM user, see Impact to APM features. Determine the requests that are the most important for your business, or the most likely to require analysis and troubleshooting, and enable distributed tracing for those services. Enable tracing for services at roughly the same time so you can more easily gauge how complete your end-to-end traces are. When you look at traces in the distributed tracing UI, you'll see spans in the trace for external calls to other services. Then, you can enable distributed tracing for any of those services you want. If a service is fairly standalone and not often used in context with other services, you may not want to enable distributed tracing for it. Here's a visual representation of such a phased roll-out: If you are using APM for a large, monolithic service, there may be many sub-process spans per trace and APM limits may result in fewer traces than expected. You can solve this by using APM agent instrumentation to disable the reporting of unimportant data. Distributed tracing works by propagating header information from service to service in a request path. Some services may communicate through a proxy or other intermediary service that does not automatically propagate the header. In that case, you will need to configure that proxy so that it allows the newrelic header value to be propagated from source to destination. Enable distributed tracing If you are aware of the impact to APM features and have thought about your rollout, you are ready to set up distributed tracing. See Overview: Enable distributed tracing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 232.24939,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Distributed</em> <em>tracing</em>: Planning guide",
        "sections": "<em>Distributed</em> <em>tracing</em>: Planning guide",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "): This shows the transaction <em>trace</em> UI before <em>distributed</em> <em>tracing</em> is enabled, with a link to the associated transaction. With <em>distributed</em> <em>tracing</em> enabled, it will display the service&#x27;s URL. If you wanted to <em>get</em> more detail about <em>trace</em> activity, you would go to the <em>Distributed</em> <em>tracing</em> UI page and examine"
      },
      "id": "6072a60564441f3a629d8535"
    },
    {
      "sections": [
        "Trace API general requirements and limits",
        "Endpoints",
        "Data formats",
        "Data limits",
        "Restricted attributes",
        "Request metadata (headers and query parameters)",
        "Important",
        "Response validation",
        "See HTTP status codes",
        "Exceeding span limits"
      ],
      "title": "Trace API general requirements and limits ",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "f77504082dae8374e0c7009a31abebbd4c0123f3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/trace-api-general-requirements-limits/",
      "published_at": "2021-06-14T18:07:42Z",
      "updated_at": "2021-06-09T00:57:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Information about Trace API data requirements, including: Data specifications and max limits Required metadata (headers, query parameters) Response validation details This document applies to the Trace API overall. For rules regarding specific data formats, see: New Relic-format trace data Zipkin-format trace data Endpoints All trace data is sent via a POST to a Trace API endpoint. We have a few endpoints, depending on your setup: Default Trace API endpoint: https://trace-api.newrelic.com/trace/v1 EU data centers: https://trace-api.eu.newrelic.com/trace/v1 (see other EU endpoints). Infinite Tracing: when you complete the Trace observer setup, you get a custom YOUR_TRACE_OBSERVER_URL value to use as an endpoint. If you're using an integration that uses the Trace API (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust the sampling of your tracing service to send us 100% of spans. For FedRAMP, see FedRAMP endpoints. Data formats Currently, the Trace API accepts two types of data formats: zipkin: For reporting Zipkin trace data. Zipkin data must be Zipkin JSON v2. newrelic: For reporting all other trace data. Data limits Data limits and rules: Condition Limit Max age of span timestamp values 20 minutes. timestamp must be within 20 minutes of current time at ingest, or within 20 minutes from the time the last span with the same trace.id was received by New Relic. Max payload size 1MB (10^6 bytes) (gzip compression supported) Max requests per minute 100K Max spans per minute per account family Dependent on agreement. Max limit: 2M. Max spans per trace 50K Max attributes per span 200 Max span attribute value length 4000 characters Allowed HTTP protocols HTTPS only Cross-account visibility of span details Potential data obfuscation To see an example of how span limits are enforced, see Exceeding limits. Restricted attributes The attributes in the table below are restricted in the newrelic-format JSON (in the attributes block) and in the zipkin-format JSON (in the tags block). Any values with these keys will be omitted: Restricted attribute Description entityGuid string Unique identifier for the entity that created this span. Generated from service.name, if available. guid string Used for backwards compatibility with data from APM agents. The attributes in the table below are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Restricted attribute description entity.guid string Unique identifier for the entity associated with this span. entity.name string Human-readable name of an entity, often used to identify an entity in the UI. entity.type string Used to differentiate between different types of entities, like hosts, applications, etc. Request metadata (headers and query parameters) The following table shows the required request metadata for all trace data formats. This metadata can be sent as HTTP headers on an ingest request or, in some cases, provided as query parameters, which may be required for tracing frameworks that don't allow header modification. Important Security note: We suggest using headers because query parameters are present in the URL and may be logged before being encrypted and received by New Relic. All data sent as query parameters must be URL-safe. Header Query param? Details Content-Type No Required. Must be application/json. Content-Length No Required. The length of the request body in octets (8-bit bytes) unless sent with chunked encoding. This header is generally set by default by the underlying HTTP client sending the data and in most cases should not require any additional effort by the end user. Api-Key Yes (case-sensitive) Required. The Trace API requires the Insights insert key. If this is provided as both a header and a query parameter, the values must match. Content-Encoding No Required if compressed payload. The value must be gzip. Data-Format Yes Required for zipkin. Optional for newrelic. If present, Data-Format-Version must also be present. Data-Format-Version Yes Required for zipkin. If present, Data-Format must also be present. There are only two possible pairings for these values: If Data-Format is zipkin, Data-Format-Version must be 2. If Data-Format is newrelic, Data-Format-Version must be 1. x-request-id No Optional - Reserved for future use. The value must be a valid UUID4. The value is expected to be unique for each request. Response validation A response for successfully sending trace data will include a requestId. For example: {\"requestId\":\"c1bb62fc-001a-b000-0000-016bb152e1bb\"} Copy There are two ways success/errors are signaled: HTTP status code (synchronous). Authentication and request errors will be signaled via HTTP status code. See HTTP status codes Code Meaning 202 Data accepted. This means that you've passed preliminary checks, but is not a guarantee that the data has been successfully parsed and indexed as part of a distributed trace. 400 The structure of the request was invalid. Errors with query parameters, etc. 403 Authentication error. May occur with an invalid license key or if you lack necessary entitlement to use the Trace API. 404 The request path is incorrect. 405 For any request method other than POST. 408 The request took too long to reach the endpoint. 411 The Content-Length header wasn’t included. 413 The payload was too big. 414 The request URI was too long. 415 The Content-Type or Content-Encoding was invalid. 429 The request rate quota has been exceeded. 431 The request headers are too long. 5xx There was a server error (please retry). NrIntegrationError events (asynchronous). Errors with the JSON payload or other semantic errors are asynchronously signaled via NrIntegrationError events that are stored in the account whose license key is associated with the request. For all errors of this type, the attribute newRelicFeature will be Distributed Tracing and requestId will be the requestId from the endpoint response. If you receive a 202 response and don't see an NrIntegrationError event, your data should be visible in New Relic One's global distributed tracing UI in about a minute. You should be able to find the trace using a standard trace search like: traceId = TRACE_ID_SENT Copy Exceeding span limits When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate limit messages with this NRQL: SELECT * FROM NrIntegrationError WHERE newRelicFeature = 'Distributed Tracing' AND category = 'RateLimit' AND rateLimitType = 'SpansPerMinute' Copy To get a notification when you exceed the limit, you can set up a NRQL alert. We calculate a rolling 10-minute average based on your span rate limit. This allows for temporary rate bursts, and lets us prioritize keeping and dropping complete traces instead of indiscriminately dropping spans on a per minute limit basis. In the example below of exceeding the rate, the rate limit is the default 100,000 spans per minute. New Relic allows a burst above 100K for a couple of minutes without downsampling, because the remaining minutes in the 10-minute window averaged under 100K spans/minute. For the previous 10 minutes (8:50 - 9:00) the service received 60,000 spans/minute. Minute Spans sent to API Total for past 10 minutes 8:59 60,000 600,000 9:00 40,000 580,000 9:01 50,000 570,000 9:02 250,000 760,000 9:03 220,000 920,000 9:04 125,000 985,000 9:05 70,000 995,000 9:06 50,000 985,000 9:07 40,000 965,000 9:08 40,000 945,000 9:09 40,000 925,000",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 211.29074,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Trace</em> API general requirements and limits ",
        "sections": "<em>Trace</em> API general requirements and limits",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>Tracing</em>: when you complete the <em>Trace</em> observer setup, you <em>get</em> a custom YOUR_<em>TRACE</em>_OBSERVER_URL value to use as an endpoint. If you&#x27;re using an integration that uses the <em>Trace</em> API (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust"
      },
      "id": "6071cf7628ccbcf8b851c158"
    },
    {
      "sections": [
        "Span attributes"
      ],
      "title": "Span attributes",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "725c10cb22b5d8f3b2a825c2dbf38b8640f93b13",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/span-attributes/",
      "published_at": "2021-06-14T18:09:35Z",
      "updated_at": "2021-06-02T17:14:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing creates Span data that can be queried in New Relic. Here are ways to learn more about Span data: To explore your span data, you can use the query builder. To see the default attributes attached to span data, use the data dictionary. For help with NRQL queries using these attributes, see these example queries.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.44899,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "<em>Distributed</em> <em>tracing</em> creates Span data that can be queried in New Relic. Here are ways to learn more about Span data: To explore your span data, you can use the query builder. To see the default attributes attached to span data, use the data dictionary. For help with NRQL queries using these attributes, see these example queries."
      },
      "id": "6072a767196a673e9964a7c3"
    }
  ],
  "/docs/distributed-tracing/concepts/introduction-distributed-tracing": [
    {
      "sections": [
        "Distributed tracing: Planning guide",
        "Impact to APM features",
        "External services page has less detail",
        "Transaction trace UI displays service URLs, not transaction links",
        "Cross-application tracing will be disabled",
        "Impacts related to mobile monitoring",
        "Plan your rollout",
        "Enable distributed tracing"
      ],
      "title": "Distributed tracing: Planning guide",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "10263f2b6ec929f082153e28cbce07fe3a1f106a",
      "image": "https://docs.newrelic.com/static/7072dfa9e494767baabba420d78e7094/c1b63/distributed-trace-txn-trace-affects.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/distributed-tracing-planning-guide/",
      "published_at": "2021-06-14T18:03:44Z",
      "updated_at": "2021-05-28T11:44:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you are new to New Relic distributed tracing, we recommend you read the following before you enable distributed tracing. Impact to APM features Our distributed tracing improves on APM's previous cross application tracing feature. Here are some key benefits: See more cross-service activity details and more complete end-to-end traces. Filter and query traces, as well as make custom charts. See the complete trace even when calls cross account boundaries (for accounts with the same master account or in the same customer partnership). See Introduction to distributed tracing for other features. Enabling distributed tracing may affect some APM features you currently use. These changes affect only applications monitored by agents that have distributed tracing enabled—they don't apply on an account-level. We may provide backward compatibility with some or all of the affected features in future releases. For now, you should understand the following changes before enabling distributed tracing: External services page has less detail When distributed tracing is enabled for an application, external calls do not have internal transaction details at one.newrelic.com > APM > (select an app) > Monitor > External services > (select external service). To find that information, you would instead go to the Distributed tracing UI page, find the external call URLs, and see what their child spans are. Transaction trace UI displays service URLs, not transaction links When distributed tracing is enabled for an application, the transaction trace UI will no longer have the transaction name and link for the called service (see screenshot below). This will be replaced with the called service's URL. one.newrelic.com > APM > (select an app) > Monitor > Transactions > (select a transaction trace): This shows the transaction trace UI before distributed tracing is enabled, with a link to the associated transaction. With distributed tracing enabled, it will display the service's URL. If you wanted to get more detail about trace activity, you would go to the Distributed tracing UI page and examine that trace. Cross-application tracing will be disabled Enabling distributed tracing will disable the cross application tracing feature. Distributed tracing is an improved version of cross-application tracing and only one can be enabled at a time. Impacts related to mobile monitoring APM-related impacts include: When distributed tracing is enabled for an APM-monitored entity, legacy service maps will not show applications monitored by mobile. The App server drill-down feature of the legacy Mobile HTTP requests UI page is not available. Plan your rollout If you're enabling distributed tracing for a large, distributed system, here are some tips: If you are a current APM user, see Impact to APM features. Determine the requests that are the most important for your business, or the most likely to require analysis and troubleshooting, and enable distributed tracing for those services. Enable tracing for services at roughly the same time so you can more easily gauge how complete your end-to-end traces are. When you look at traces in the distributed tracing UI, you'll see spans in the trace for external calls to other services. Then, you can enable distributed tracing for any of those services you want. If a service is fairly standalone and not often used in context with other services, you may not want to enable distributed tracing for it. Here's a visual representation of such a phased roll-out: If you are using APM for a large, monolithic service, there may be many sub-process spans per trace and APM limits may result in fewer traces than expected. You can solve this by using APM agent instrumentation to disable the reporting of unimportant data. Distributed tracing works by propagating header information from service to service in a request path. Some services may communicate through a proxy or other intermediary service that does not automatically propagate the header. In that case, you will need to configure that proxy so that it allows the newrelic header value to be propagated from source to destination. Enable distributed tracing If you are aware of the impact to APM features and have thought about your rollout, you are ready to set up distributed tracing. See Overview: Enable distributed tracing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 232.24939,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Distributed</em> <em>tracing</em>: Planning guide",
        "sections": "<em>Distributed</em> <em>tracing</em>: Planning guide",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "): This shows the transaction <em>trace</em> UI before <em>distributed</em> <em>tracing</em> is enabled, with a link to the associated transaction. With <em>distributed</em> <em>tracing</em> enabled, it will display the service&#x27;s URL. If you wanted to <em>get</em> more detail about <em>trace</em> activity, you would go to the <em>Distributed</em> <em>tracing</em> UI page and examine"
      },
      "id": "6072a60564441f3a629d8535"
    },
    {
      "sections": [
        "Trace API general requirements and limits",
        "Endpoints",
        "Data formats",
        "Data limits",
        "Restricted attributes",
        "Request metadata (headers and query parameters)",
        "Important",
        "Response validation",
        "See HTTP status codes",
        "Exceeding span limits"
      ],
      "title": "Trace API general requirements and limits ",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "f77504082dae8374e0c7009a31abebbd4c0123f3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/trace-api-general-requirements-limits/",
      "published_at": "2021-06-14T18:07:42Z",
      "updated_at": "2021-06-09T00:57:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Information about Trace API data requirements, including: Data specifications and max limits Required metadata (headers, query parameters) Response validation details This document applies to the Trace API overall. For rules regarding specific data formats, see: New Relic-format trace data Zipkin-format trace data Endpoints All trace data is sent via a POST to a Trace API endpoint. We have a few endpoints, depending on your setup: Default Trace API endpoint: https://trace-api.newrelic.com/trace/v1 EU data centers: https://trace-api.eu.newrelic.com/trace/v1 (see other EU endpoints). Infinite Tracing: when you complete the Trace observer setup, you get a custom YOUR_TRACE_OBSERVER_URL value to use as an endpoint. If you're using an integration that uses the Trace API (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust the sampling of your tracing service to send us 100% of spans. For FedRAMP, see FedRAMP endpoints. Data formats Currently, the Trace API accepts two types of data formats: zipkin: For reporting Zipkin trace data. Zipkin data must be Zipkin JSON v2. newrelic: For reporting all other trace data. Data limits Data limits and rules: Condition Limit Max age of span timestamp values 20 minutes. timestamp must be within 20 minutes of current time at ingest, or within 20 minutes from the time the last span with the same trace.id was received by New Relic. Max payload size 1MB (10^6 bytes) (gzip compression supported) Max requests per minute 100K Max spans per minute per account family Dependent on agreement. Max limit: 2M. Max spans per trace 50K Max attributes per span 200 Max span attribute value length 4000 characters Allowed HTTP protocols HTTPS only Cross-account visibility of span details Potential data obfuscation To see an example of how span limits are enforced, see Exceeding limits. Restricted attributes The attributes in the table below are restricted in the newrelic-format JSON (in the attributes block) and in the zipkin-format JSON (in the tags block). Any values with these keys will be omitted: Restricted attribute Description entityGuid string Unique identifier for the entity that created this span. Generated from service.name, if available. guid string Used for backwards compatibility with data from APM agents. The attributes in the table below are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Restricted attribute description entity.guid string Unique identifier for the entity associated with this span. entity.name string Human-readable name of an entity, often used to identify an entity in the UI. entity.type string Used to differentiate between different types of entities, like hosts, applications, etc. Request metadata (headers and query parameters) The following table shows the required request metadata for all trace data formats. This metadata can be sent as HTTP headers on an ingest request or, in some cases, provided as query parameters, which may be required for tracing frameworks that don't allow header modification. Important Security note: We suggest using headers because query parameters are present in the URL and may be logged before being encrypted and received by New Relic. All data sent as query parameters must be URL-safe. Header Query param? Details Content-Type No Required. Must be application/json. Content-Length No Required. The length of the request body in octets (8-bit bytes) unless sent with chunked encoding. This header is generally set by default by the underlying HTTP client sending the data and in most cases should not require any additional effort by the end user. Api-Key Yes (case-sensitive) Required. The Trace API requires the Insights insert key. If this is provided as both a header and a query parameter, the values must match. Content-Encoding No Required if compressed payload. The value must be gzip. Data-Format Yes Required for zipkin. Optional for newrelic. If present, Data-Format-Version must also be present. Data-Format-Version Yes Required for zipkin. If present, Data-Format must also be present. There are only two possible pairings for these values: If Data-Format is zipkin, Data-Format-Version must be 2. If Data-Format is newrelic, Data-Format-Version must be 1. x-request-id No Optional - Reserved for future use. The value must be a valid UUID4. The value is expected to be unique for each request. Response validation A response for successfully sending trace data will include a requestId. For example: {\"requestId\":\"c1bb62fc-001a-b000-0000-016bb152e1bb\"} Copy There are two ways success/errors are signaled: HTTP status code (synchronous). Authentication and request errors will be signaled via HTTP status code. See HTTP status codes Code Meaning 202 Data accepted. This means that you've passed preliminary checks, but is not a guarantee that the data has been successfully parsed and indexed as part of a distributed trace. 400 The structure of the request was invalid. Errors with query parameters, etc. 403 Authentication error. May occur with an invalid license key or if you lack necessary entitlement to use the Trace API. 404 The request path is incorrect. 405 For any request method other than POST. 408 The request took too long to reach the endpoint. 411 The Content-Length header wasn’t included. 413 The payload was too big. 414 The request URI was too long. 415 The Content-Type or Content-Encoding was invalid. 429 The request rate quota has been exceeded. 431 The request headers are too long. 5xx There was a server error (please retry). NrIntegrationError events (asynchronous). Errors with the JSON payload or other semantic errors are asynchronously signaled via NrIntegrationError events that are stored in the account whose license key is associated with the request. For all errors of this type, the attribute newRelicFeature will be Distributed Tracing and requestId will be the requestId from the endpoint response. If you receive a 202 response and don't see an NrIntegrationError event, your data should be visible in New Relic One's global distributed tracing UI in about a minute. You should be able to find the trace using a standard trace search like: traceId = TRACE_ID_SENT Copy Exceeding span limits When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate limit messages with this NRQL: SELECT * FROM NrIntegrationError WHERE newRelicFeature = 'Distributed Tracing' AND category = 'RateLimit' AND rateLimitType = 'SpansPerMinute' Copy To get a notification when you exceed the limit, you can set up a NRQL alert. We calculate a rolling 10-minute average based on your span rate limit. This allows for temporary rate bursts, and lets us prioritize keeping and dropping complete traces instead of indiscriminately dropping spans on a per minute limit basis. In the example below of exceeding the rate, the rate limit is the default 100,000 spans per minute. New Relic allows a burst above 100K for a couple of minutes without downsampling, because the remaining minutes in the 10-minute window averaged under 100K spans/minute. For the previous 10 minutes (8:50 - 9:00) the service received 60,000 spans/minute. Minute Spans sent to API Total for past 10 minutes 8:59 60,000 600,000 9:00 40,000 580,000 9:01 50,000 570,000 9:02 250,000 760,000 9:03 220,000 920,000 9:04 125,000 985,000 9:05 70,000 995,000 9:06 50,000 985,000 9:07 40,000 965,000 9:08 40,000 945,000 9:09 40,000 925,000",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 211.29074,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Trace</em> API general requirements and limits ",
        "sections": "<em>Trace</em> API general requirements and limits",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>Tracing</em>: when you complete the <em>Trace</em> observer setup, you <em>get</em> a custom YOUR_<em>TRACE</em>_OBSERVER_URL value to use as an endpoint. If you&#x27;re using an integration that uses the <em>Trace</em> API (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust"
      },
      "id": "6071cf7628ccbcf8b851c158"
    },
    {
      "sections": [
        "How New Relic distributed tracing works",
        "Tip",
        "Trace sampling",
        "Head-based sampling (standard distributed tracing)",
        "Language agents: adaptive sampling",
        "Language agents: limits and sampling",
        "Trace rate limiting",
        "Lambda trace sampling",
        "Tail-based sampling (Infinite Tracing)",
        "Architecture",
        "Tail-based sampling algorithms",
        "No sampling",
        "Browser and Mobile trace reporting",
        "Trace API",
        "How trace data is structured",
        "How trace data is stored",
        "How trace context is passed between applications",
        "Important",
        "Scenario 1: Trace touching three agent types",
        "Scenario 2: Trace with W3C New Relic and middleware",
        "Scenario 3: Trace with any W3C-compliant agent and a New Relic agent."
      ],
      "title": "How New Relic distributed tracing works",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "4dbe0119017f78ad4db2a2b8a9ca2d287222753a",
      "image": "https://docs.newrelic.com/static/406c9f3af4012dab16df681c8feab256/c1b63/new-relic-distributed-tracing-trace-structure.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/how-new-relic-distributed-tracing-works/",
      "published_at": "2021-06-14T18:03:45Z",
      "updated_at": "2021-05-16T15:32:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some technical details about how New Relic distributed tracing works: How trace sampling works How we structure trace data How we store trace data How trace context is passed between applications Tip For instructions about setting up distributed tracing, see Overview: Enable distributed tracing. Trace sampling How your traces are sampled will depend on your setup and the New Relic tracing tool you're using. For example, you may be using a third-party telemetry service (like OpenTelemetry) to implement sampling of traces before your data gets to us or, if you're using Infinite Tracing, you'd probably send us all your trace data and use our sampling. We have a few sampling strategies available: Head-based sampling (standard distributed tracing) Tail-based sampling (Infinite Tracing) No sampling Head-based sampling (standard distributed tracing) With the exception of our Infinite Tracing feature, most of our tracing tools use a head-based sampling approach. This applies filters to individual spans before all spans in a trace arrive, which means decisions about whether to accept spans is made at the beginning (the \"head\") of the filtering process. We use this sampling strategy to capture a representative sample of activity while avoiding storage and performance issues. Here are some details about how head-based sampling is implemented in our standard distributed tracing tools: Language agents: adaptive sampling Our APM language agents use adaptive sampling to capture a representative sample of system activity. The following is an explanation of how adaptive sampling works. For the first service in a distributed trace, 10 requests are chosen to be sampled. The throughput to that service is used to adjust how frequently requests are sampled. This is explained in more detail below. The first service we monitor in a distributed trace is called the trace origin. The trace origin chooses requests at random to be traced. That decision propagates to the downstream services touched by that request. When the request has completed, all of the spans touched by that request that we've detected are made available in the UI as a complete trace (though agent limits may result in fragmented traces). APM agents have a limit on the number of transactions collected per minute (this can vary, depending on agent) and a limit on the number of spans collected per minute (1000 per agent instance). To adhere to these limits, the default number of traces at the trace origin is 10 traces per minute. An APM agent spreads out the collection of these 10 traces over a minute in order to get a representative sample over time. The exact sampling rate depends on the number of transactions in the previous minute. The rate responds to changes in transaction throughput, going up or down. For example, if the previous minute had 100 transactions, the agent would anticipate a similar number of transactions and select 1 out of every 10 transactions to be traced. Language agents: limits and sampling An APM language agent instance using head-based sampling has a limit of 1000 spans per minute. The agent attempts to keep all spans that are marked to be sampled as part of a distributed trace. In many distributed systems, the average microservice may generate 10 to 20 spans per request. In those cases, the agent span limit can accommodate all spans chosen, and that service will have full detail in a trace. However, some requests to services will generate many spans, and the agent span limit will be reached. As a result, some traces will not have full detail for that service. One solution to this would be to custom instrument an agent to report less activity and therefore report fewer spans. To read about how browser monitoring of trace data may vary from our language agents, see Browser traces. Trace rate limiting If the above sampling methods still result in too much trace data, we may limit incoming data by sampling traces after they're received. By making this decision at the trace level, it avoids fragmenting traces (accepting only part of a trace). This process works similarly to adaptive sampling. The total spans received in a minute are totaled. If too many spans are received, fewer spans may be accepted in the following minute, in order to achieve a floating-average throughput rate. Lambda trace sampling Our AWS Lambda monitoring uses its own sampling process. Tail-based sampling (Infinite Tracing) Our Infinite Tracing feature uses a tail-based sampling approach. \"Tail-based sampling\" means that trace-retention decisions are done at the tail end of processing after all the spans in a trace have arrived. With Infinite Tracing, you can send us 100% of your trace data from your application or third-party telemetry service, and Infinite Tracing will figure out which trace data is most important. And you can configure the sampling to ensure the traces important to you are retained. Architecture For Infinite Tracing, agents or integrations send 100% of all instrumented spans to a trace observer. The trace observer is a distributed tracing service residing in a cluster of services on AWS called New Relic Edge. Tip Only your spans go to the trace observer—all other data such as metrics, custom events, and transaction traces are sent the normal route to New Relic and are subject to local sampling. You configure a unique trace observer endpoint for the AWS region you want to send data to. You can request multiple endpoints, one per AWS region. The endpoint represents a trace observer for a particular workload. For example, all spans from a single trace (request) must go to that endpoint. Here are two architectural diagrams: one showing how data flows if you use APM agents and another if you use New Relic integrations like OpenTelemetry exporters: The trace observer holds traces open while spans for that trace arrive. Once the first span in a trace arrives, a session is kept open for 10 seconds. Each time a new span for that trace arrives, the expiration time is reset to 10 seconds. Traces that haven't seen a span arrive within the last 10 seconds will automatically expire. Tail-based sampling algorithms By default, each trace observer offers traces to three samplers: one looking for duration outliers, one looking for traces with errors, and one trying to randomly sample across all trace types. Each sampler keeps a target percentage of traces that match their criteria. Here are details about each sampler: Sampler Matching criteria Target percent Duration Traces with an outlier duration, using two algorithms: Gaussian (Assumes a normal distribution and a threshold at the 99th percentile) Eccentricity (Assumes no distribution and a threshold based on cluster) 100% Error Traces having at least one span with an error 100% Random All traces 1% (This is configurable. See Infinite Tracing: Random trace filter) If the matching criteria matches the trace, each sampler looks at the trace’s shape. A trace’s shape is the unique combination of the root span’s entity name and span name. This is a simple way to separate traces using the entry point of the request. Once the shape is determined, the sampler makes a decision to keep or reject the trace based on its target sampling percent. If it’s 100%, the trace is automatically kept. If it’s anything less, the probability the sampler keeps a given trace is determined by the target percent. For example, the default target percent is 1 for random traces, so 1% of those traces are kept. If you prefer, you can change the random filter percentage. Because the trace observer uses percentages of throughput, the number of traces selected will vary with that throughput. No sampling Some of our tools don't use sampling. Sampling details for these tools: Browser and Mobile trace reporting Browser monitoring distributed tracing and Mobile monitoring report all spans. Our APM language agents are often used in conjunction with browser and mobile monitoring, and our language agents use sampling. This means that there will likely be many more browser and mobile spans than back-end spans, which can result in browser and mobile app spans disconnected from back-end spans. For tips on querying for traces that contain front and back-end spans, see Find browser span data. Trace API If you don't have Infinite Tracing enabled, our Trace API does no sampling (unless the default data limits are exceeded). It's expected that you set up the Trace API to send us the traces you think are important. How trace data is structured Understanding the structure of a distributed trace can help you: Understand how traces are displayed in our UI Help you query trace data A distributed trace has a tree-like structure, with \"child\" spans that refer to one \"parent\" span. This diagram shows some important span relationships in a trace: This diagram shows how spans in a distributed trace relate to each other. This diagram shows several important concepts: Trace root. The first service or process in a trace is referred to as the root service or process. Process boundaries. A process represents the execution of a logical piece of code. Examples of a process include a backend service or Lambda function. Spans within a process are categorized as one of the following: Entry span: the first span in a process. Exit span: a span is a considered an exit span if it a) is the parent of an entry span, or b) has http. or db. attributes and therefore represents an external call. In-process span: a span that represents an internal method call or function and that is not an exit or entry span. Client spans. A client span represents a call to another entity or external dependency. Currently, there are two client span types: Datastore. If a client span has any attributes prefixed with db. (like db.statement), it's categorized as a datastore span. External. If a client span has any attributes prefixed with http. (like http.url) or has a child span in another process, it's categorized as an external span. This is a general category for any external calls that are not datastore queries. Trace duration. A trace's total duration is determined by the length of time from the start of the earliest span to the completion of the last span. You can query span relationship data with the NerdGraph GraphiQL explorer at api.newrelic.com/graphiql. How trace data is stored Understanding how we store trace data can help you query your trace data. We save trace data as: Span: A span represents operations that are part of a distributed trace. The operations that a span can represent include browser-side interactions, datastore queries, calls to other services, method-level timing, and Lambda functions. One example: in an HTTP service, a span is created at the start of an HTTP request and completed when the HTTP server returns a response. Span attributes contain important information about that operation (such as duration, host data, etc.), including trace-relationship details (such as traceId, guid). For span-related data, see span attributes. Transaction: If an entity in a trace is monitored by an agent, a request to that entity generates a single Transaction event. Transactions allow trace data to be tied to other New Relic features. For transaction-related data, see transaction attributes. Contextual metadata. We store metadata that shows calculations about a trace and the relationships between its spans. To query this data, use the NerdGraph GraphiQL explorer. How trace context is passed between applications We support the W3C Trace Context standard, which makes it easier to trace transactions across networks and services. When you enable distributed tracing, New Relic agents add HTTP headers to a service's outbound requests. HTTP headers act like passports on an international trip: They identify your software traces and carry important information as they travel through various networks, processes, and security systems. The headers also contain information that helps us link the spans together later: metadata like the trace ID, span ID, the New Relic account ID, and sampling information. This header information is passed along each span of a trace, unless the progress is stopped by something like middleware or agents that don't recognize the header format (see Figure 1). Figure 1 To address the problem of header propagation, we support the W3C Trace Context specification that requires two standardized headers. Our latest W3C New Relic agents send and receive these two required headers, and by default, they also send and receive the header of the prior New Relic agent: W3C (traceparent): The primary header that identifies the entire trace (trace ID) and the calling service (span id). W3C (tracestate): A required header that carries vendor-specific information and tracks where a trace has been. New Relic (newrelic): The original, proprietary header that is still sent to maintain backward compatibility with prior New Relic agents. This combination of three headers allows traces to be propagated across services instrumented with these types of agents: W3C New Relic agents Non-W3C New Relic agents W3C Trace Context-compatible agents Important If your requests only touch W3C Trace Context-compatible agents, you can opt to turn off the New Relic header. See the agent configuration documentation for details about turning off the newrelic header. The scenarios below show various types of successful header propagation. Scenario 1: Trace touching three agent types This shows the flow of headers when a request touches three different agent types: Scenario 2: Trace with W3C New Relic and middleware This shows the combination of headers sent by a W3C New Relic agent to some middleware. Scenario 3: Trace with any W3C-compliant agent and a New Relic agent. This shows the two required W3C headers from another vendor accepted by a W3C New Relic agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 200.09784,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "sections": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Here are some technical details about how New Relic <em>distributed</em> <em>tracing</em> works: How <em>trace</em> sampling works How we structure <em>trace</em> data How we store <em>trace</em> data How <em>trace</em> context is passed between applications Tip For instructions about setting up <em>distributed</em> <em>tracing</em>, see Overview: Enable <em>distributed</em>"
      },
      "id": "6072a66664441f14089d856c"
    }
  ],
  "/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing": [
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-06-14T18:04:49Z",
      "updated_at": "2021-04-22T06:39:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any New Relic APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: New Relic APM: C New Relic APM: Golang New Relic APM: Java New Relic APM: .NET New Relic APM: Node.js New Relic APM: PHP New Relic APM: Python New Relic APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a New Relic APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever (i.e. -1). For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For best results, update to the latest Ruby agent version. Also install the additional Ruby agent gem for Infinite Tracing. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 6.11.0.365 or higher (includes W3C Trace Context) newrelic-infinite_tracing 6.11.0.375 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.94891,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language agents <em>and</em> <em>distributed</em> <em>tracing</em>",
        "sections": "<em>Configure</em> standard <em>distributed</em> <em>tracing</em> for your older agents",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " you&#x27;re done, return here with your <em>trace</em> observer information and continue with the next step to <em>configure</em> the agent. Step 3: <em>Configure</em> the agent for Infinite <em>Tracing</em> Infinite <em>Tracing</em> configuration settings include the standard <em>distributed</em> <em>tracing</em> plus information about the <em>trace</em> observer. Find"
      },
      "id": "6072a66564441fb28e9d8595"
    },
    {
      "sections": [
        "Overview: Set up distributed tracing",
        "New Relic integrations",
        "New Relic integrations for third-party telemetry tools",
        "Set up your own solution with our Trace API",
        "Tip"
      ],
      "title": "Overview: Set up distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "cd81f363a9ee07640029b514cafe1f84ac04ef99",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/overview-enable-distributed-tracing/",
      "published_at": "2021-06-14T18:04:49Z",
      "updated_at": "2021-04-11T07:33:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer a variety of ways to capture distributed tracing data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic Trace API New Relic integrations We offer a range of agents to capture trace data from your applications: Product Description Language agents See telemetry data from applications instrumented with our language-specific agents: C, Go, Java, .NET, Node.js, PHP, Python, and Ruby. Monitoring for AWS Lambda See Lambda function activity, and examine the functions in your traces. Browser See users' browser-side traces. Mobile See users' mobile traces. New Relic integrations for third-party telemetry tools If you are collecting data with these telemetry tools, you can send your data to New Relic: OpenTelemetry Istio Kamon OpenCensus AWS X-Ray Set up your own solution with our Trace API Send data from your telemetry tool directly to New Relic without using an integration that exports the data. Tip Note that this may require more manual configuration than using an integration. Data format Description Trace API: New Relic format Convert your trace data to the New Relic format and send it to New Relic for viewing. Trace API: Data in Zipkin format Send your Zipkin trace data to New Relic for viewing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 231.97508,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "sections": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "We offer a variety of ways to capture <em>distributed</em> <em>tracing</em> data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic <em>Trace</em> API New Relic integrations We offer a range of agents to capture <em>trace</em>"
      },
      "id": "6072a666196a67a2bf64a758"
    },
    {
      "sections": [
        "Trace API general requirements and limits",
        "Endpoints",
        "Data formats",
        "Data limits",
        "Restricted attributes",
        "Request metadata (headers and query parameters)",
        "Important",
        "Response validation",
        "See HTTP status codes",
        "Exceeding span limits"
      ],
      "title": "Trace API general requirements and limits ",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "f77504082dae8374e0c7009a31abebbd4c0123f3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/trace-api-general-requirements-limits/",
      "published_at": "2021-06-14T18:07:42Z",
      "updated_at": "2021-06-09T00:57:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Information about Trace API data requirements, including: Data specifications and max limits Required metadata (headers, query parameters) Response validation details This document applies to the Trace API overall. For rules regarding specific data formats, see: New Relic-format trace data Zipkin-format trace data Endpoints All trace data is sent via a POST to a Trace API endpoint. We have a few endpoints, depending on your setup: Default Trace API endpoint: https://trace-api.newrelic.com/trace/v1 EU data centers: https://trace-api.eu.newrelic.com/trace/v1 (see other EU endpoints). Infinite Tracing: when you complete the Trace observer setup, you get a custom YOUR_TRACE_OBSERVER_URL value to use as an endpoint. If you're using an integration that uses the Trace API (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust the sampling of your tracing service to send us 100% of spans. For FedRAMP, see FedRAMP endpoints. Data formats Currently, the Trace API accepts two types of data formats: zipkin: For reporting Zipkin trace data. Zipkin data must be Zipkin JSON v2. newrelic: For reporting all other trace data. Data limits Data limits and rules: Condition Limit Max age of span timestamp values 20 minutes. timestamp must be within 20 minutes of current time at ingest, or within 20 minutes from the time the last span with the same trace.id was received by New Relic. Max payload size 1MB (10^6 bytes) (gzip compression supported) Max requests per minute 100K Max spans per minute per account family Dependent on agreement. Max limit: 2M. Max spans per trace 50K Max attributes per span 200 Max span attribute value length 4000 characters Allowed HTTP protocols HTTPS only Cross-account visibility of span details Potential data obfuscation To see an example of how span limits are enforced, see Exceeding limits. Restricted attributes The attributes in the table below are restricted in the newrelic-format JSON (in the attributes block) and in the zipkin-format JSON (in the tags block). Any values with these keys will be omitted: Restricted attribute Description entityGuid string Unique identifier for the entity that created this span. Generated from service.name, if available. guid string Used for backwards compatibility with data from APM agents. The attributes in the table below are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Restricted attribute description entity.guid string Unique identifier for the entity associated with this span. entity.name string Human-readable name of an entity, often used to identify an entity in the UI. entity.type string Used to differentiate between different types of entities, like hosts, applications, etc. Request metadata (headers and query parameters) The following table shows the required request metadata for all trace data formats. This metadata can be sent as HTTP headers on an ingest request or, in some cases, provided as query parameters, which may be required for tracing frameworks that don't allow header modification. Important Security note: We suggest using headers because query parameters are present in the URL and may be logged before being encrypted and received by New Relic. All data sent as query parameters must be URL-safe. Header Query param? Details Content-Type No Required. Must be application/json. Content-Length No Required. The length of the request body in octets (8-bit bytes) unless sent with chunked encoding. This header is generally set by default by the underlying HTTP client sending the data and in most cases should not require any additional effort by the end user. Api-Key Yes (case-sensitive) Required. The Trace API requires the Insights insert key. If this is provided as both a header and a query parameter, the values must match. Content-Encoding No Required if compressed payload. The value must be gzip. Data-Format Yes Required for zipkin. Optional for newrelic. If present, Data-Format-Version must also be present. Data-Format-Version Yes Required for zipkin. If present, Data-Format must also be present. There are only two possible pairings for these values: If Data-Format is zipkin, Data-Format-Version must be 2. If Data-Format is newrelic, Data-Format-Version must be 1. x-request-id No Optional - Reserved for future use. The value must be a valid UUID4. The value is expected to be unique for each request. Response validation A response for successfully sending trace data will include a requestId. For example: {\"requestId\":\"c1bb62fc-001a-b000-0000-016bb152e1bb\"} Copy There are two ways success/errors are signaled: HTTP status code (synchronous). Authentication and request errors will be signaled via HTTP status code. See HTTP status codes Code Meaning 202 Data accepted. This means that you've passed preliminary checks, but is not a guarantee that the data has been successfully parsed and indexed as part of a distributed trace. 400 The structure of the request was invalid. Errors with query parameters, etc. 403 Authentication error. May occur with an invalid license key or if you lack necessary entitlement to use the Trace API. 404 The request path is incorrect. 405 For any request method other than POST. 408 The request took too long to reach the endpoint. 411 The Content-Length header wasn’t included. 413 The payload was too big. 414 The request URI was too long. 415 The Content-Type or Content-Encoding was invalid. 429 The request rate quota has been exceeded. 431 The request headers are too long. 5xx There was a server error (please retry). NrIntegrationError events (asynchronous). Errors with the JSON payload or other semantic errors are asynchronously signaled via NrIntegrationError events that are stored in the account whose license key is associated with the request. For all errors of this type, the attribute newRelicFeature will be Distributed Tracing and requestId will be the requestId from the endpoint response. If you receive a 202 response and don't see an NrIntegrationError event, your data should be visible in New Relic One's global distributed tracing UI in about a minute. You should be able to find the trace using a standard trace search like: traceId = TRACE_ID_SENT Copy Exceeding span limits When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate limit messages with this NRQL: SELECT * FROM NrIntegrationError WHERE newRelicFeature = 'Distributed Tracing' AND category = 'RateLimit' AND rateLimitType = 'SpansPerMinute' Copy To get a notification when you exceed the limit, you can set up a NRQL alert. We calculate a rolling 10-minute average based on your span rate limit. This allows for temporary rate bursts, and lets us prioritize keeping and dropping complete traces instead of indiscriminately dropping spans on a per minute limit basis. In the example below of exceeding the rate, the rate limit is the default 100,000 spans per minute. New Relic allows a burst above 100K for a couple of minutes without downsampling, because the remaining minutes in the 10-minute window averaged under 100K spans/minute. For the previous 10 minutes (8:50 - 9:00) the service received 60,000 spans/minute. Minute Spans sent to API Total for past 10 minutes 8:59 60,000 600,000 9:00 40,000 580,000 9:01 50,000 570,000 9:02 250,000 760,000 9:03 220,000 920,000 9:04 125,000 985,000 9:05 70,000 995,000 9:06 50,000 985,000 9:07 40,000 965,000 9:08 40,000 945,000 9:09 40,000 925,000",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 206.80322,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Trace</em> API general requirements <em>and</em> limits ",
        "sections": "<em>Trace</em> API general requirements <em>and</em> limits",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>Tracing</em>: when you complete the <em>Trace</em> observer setup, you get a custom YOUR_<em>TRACE</em>_OBSERVER_URL value to use as an endpoint. If you&#x27;re using an integration that uses the <em>Trace</em> API (for example, these integrations), you must <em>configure</em> that integration with that endpoint. You will also want to adjust"
      },
      "id": "6071cf7628ccbcf8b851c158"
    }
  ],
  "/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing": [
    {
      "sections": [
        "Enable distributed tracing for our telemetry tool integrations",
        "Sampling considerations",
        "Set up integrations"
      ],
      "title": "Enable distributed tracing for our telemetry tool integrations",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "ca05c9c79d80af7bc4f16230459e9811a23a94b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing/",
      "published_at": "2021-06-14T18:03:44Z",
      "updated_at": "2021-04-15T22:20:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the telemetry tools Istio, Kamon, OpenCensus, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because distributed systems can generate a lot of trace data, telemetry tools rely on data sampling (filtering). When you install a telemetry integration that reports trace data, you'll have an option to enable Infinite Tracing. Choosing Infinite Tracing has implications for how you configure sampling in your telemetry tool: Standard installation without Infinite Tracing: A standard installation assumes you want your telemetry tool to sample trace data before it's sent to us. (If your trace data exceeds our Trace API limits, we may also do additional sampling.) Install with Infinite Tracing: If you choose Infinite Tracing (read requirements), we assume your telemetry tool's sampling is set to 100%, so that all of that tool's trace data is sent to us. The trace observer selects the most important and actionable traces using tail-based sampling, and then that data is ingested via our Trace API. Set up integrations To set up your telemetry tool for sending distributed traces to New Relic, follow the instructions for your tool: OpenTelemetry Istio Kamon OpenCensus AWS X-Ray",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 233.9693,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Enable</em> <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "sections": "<em>Enable</em> <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " you install a telemetry integration that reports <em>trace</em> data, you&#x27;ll have an option to <em>enable</em> Infinite <em>Tracing</em>. Choosing Infinite <em>Tracing</em> has implications for how you <em>configure</em> sampling in your telemetry tool: Standard installation without Infinite <em>Tracing</em>: A standard installation assumes you want"
      },
      "id": "6072a66664441f271c9d8557"
    },
    {
      "sections": [
        "Overview: Set up distributed tracing",
        "New Relic integrations",
        "New Relic integrations for third-party telemetry tools",
        "Set up your own solution with our Trace API",
        "Tip"
      ],
      "title": "Overview: Set up distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "cd81f363a9ee07640029b514cafe1f84ac04ef99",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/overview-enable-distributed-tracing/",
      "published_at": "2021-06-14T18:04:49Z",
      "updated_at": "2021-04-11T07:33:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer a variety of ways to capture distributed tracing data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic Trace API New Relic integrations We offer a range of agents to capture trace data from your applications: Product Description Language agents See telemetry data from applications instrumented with our language-specific agents: C, Go, Java, .NET, Node.js, PHP, Python, and Ruby. Monitoring for AWS Lambda See Lambda function activity, and examine the functions in your traces. Browser See users' browser-side traces. Mobile See users' mobile traces. New Relic integrations for third-party telemetry tools If you are collecting data with these telemetry tools, you can send your data to New Relic: OpenTelemetry Istio Kamon OpenCensus AWS X-Ray Set up your own solution with our Trace API Send data from your telemetry tool directly to New Relic without using an integration that exports the data. Tip Note that this may require more manual configuration than using an integration. Data format Description Trace API: New Relic format Convert your trace data to the New Relic format and send it to New Relic for viewing. Trace API: Data in Zipkin format Send your Zipkin trace data to New Relic for viewing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 231.97507,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "sections": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "We offer a variety of ways to capture <em>distributed</em> <em>tracing</em> data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic <em>Trace</em> API New Relic integrations We offer a range of agents to capture <em>trace</em>"
      },
      "id": "6072a666196a67a2bf64a758"
    },
    {
      "sections": [
        "Trace API general requirements and limits",
        "Endpoints",
        "Data formats",
        "Data limits",
        "Restricted attributes",
        "Request metadata (headers and query parameters)",
        "Important",
        "Response validation",
        "See HTTP status codes",
        "Exceeding span limits"
      ],
      "title": "Trace API general requirements and limits ",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "f77504082dae8374e0c7009a31abebbd4c0123f3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/trace-api-general-requirements-limits/",
      "published_at": "2021-06-14T18:07:42Z",
      "updated_at": "2021-06-09T00:57:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Information about Trace API data requirements, including: Data specifications and max limits Required metadata (headers, query parameters) Response validation details This document applies to the Trace API overall. For rules regarding specific data formats, see: New Relic-format trace data Zipkin-format trace data Endpoints All trace data is sent via a POST to a Trace API endpoint. We have a few endpoints, depending on your setup: Default Trace API endpoint: https://trace-api.newrelic.com/trace/v1 EU data centers: https://trace-api.eu.newrelic.com/trace/v1 (see other EU endpoints). Infinite Tracing: when you complete the Trace observer setup, you get a custom YOUR_TRACE_OBSERVER_URL value to use as an endpoint. If you're using an integration that uses the Trace API (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust the sampling of your tracing service to send us 100% of spans. For FedRAMP, see FedRAMP endpoints. Data formats Currently, the Trace API accepts two types of data formats: zipkin: For reporting Zipkin trace data. Zipkin data must be Zipkin JSON v2. newrelic: For reporting all other trace data. Data limits Data limits and rules: Condition Limit Max age of span timestamp values 20 minutes. timestamp must be within 20 minutes of current time at ingest, or within 20 minutes from the time the last span with the same trace.id was received by New Relic. Max payload size 1MB (10^6 bytes) (gzip compression supported) Max requests per minute 100K Max spans per minute per account family Dependent on agreement. Max limit: 2M. Max spans per trace 50K Max attributes per span 200 Max span attribute value length 4000 characters Allowed HTTP protocols HTTPS only Cross-account visibility of span details Potential data obfuscation To see an example of how span limits are enforced, see Exceeding limits. Restricted attributes The attributes in the table below are restricted in the newrelic-format JSON (in the attributes block) and in the zipkin-format JSON (in the tags block). Any values with these keys will be omitted: Restricted attribute Description entityGuid string Unique identifier for the entity that created this span. Generated from service.name, if available. guid string Used for backwards compatibility with data from APM agents. The attributes in the table below are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Restricted attribute description entity.guid string Unique identifier for the entity associated with this span. entity.name string Human-readable name of an entity, often used to identify an entity in the UI. entity.type string Used to differentiate between different types of entities, like hosts, applications, etc. Request metadata (headers and query parameters) The following table shows the required request metadata for all trace data formats. This metadata can be sent as HTTP headers on an ingest request or, in some cases, provided as query parameters, which may be required for tracing frameworks that don't allow header modification. Important Security note: We suggest using headers because query parameters are present in the URL and may be logged before being encrypted and received by New Relic. All data sent as query parameters must be URL-safe. Header Query param? Details Content-Type No Required. Must be application/json. Content-Length No Required. The length of the request body in octets (8-bit bytes) unless sent with chunked encoding. This header is generally set by default by the underlying HTTP client sending the data and in most cases should not require any additional effort by the end user. Api-Key Yes (case-sensitive) Required. The Trace API requires the Insights insert key. If this is provided as both a header and a query parameter, the values must match. Content-Encoding No Required if compressed payload. The value must be gzip. Data-Format Yes Required for zipkin. Optional for newrelic. If present, Data-Format-Version must also be present. Data-Format-Version Yes Required for zipkin. If present, Data-Format must also be present. There are only two possible pairings for these values: If Data-Format is zipkin, Data-Format-Version must be 2. If Data-Format is newrelic, Data-Format-Version must be 1. x-request-id No Optional - Reserved for future use. The value must be a valid UUID4. The value is expected to be unique for each request. Response validation A response for successfully sending trace data will include a requestId. For example: {\"requestId\":\"c1bb62fc-001a-b000-0000-016bb152e1bb\"} Copy There are two ways success/errors are signaled: HTTP status code (synchronous). Authentication and request errors will be signaled via HTTP status code. See HTTP status codes Code Meaning 202 Data accepted. This means that you've passed preliminary checks, but is not a guarantee that the data has been successfully parsed and indexed as part of a distributed trace. 400 The structure of the request was invalid. Errors with query parameters, etc. 403 Authentication error. May occur with an invalid license key or if you lack necessary entitlement to use the Trace API. 404 The request path is incorrect. 405 For any request method other than POST. 408 The request took too long to reach the endpoint. 411 The Content-Length header wasn’t included. 413 The payload was too big. 414 The request URI was too long. 415 The Content-Type or Content-Encoding was invalid. 429 The request rate quota has been exceeded. 431 The request headers are too long. 5xx There was a server error (please retry). NrIntegrationError events (asynchronous). Errors with the JSON payload or other semantic errors are asynchronously signaled via NrIntegrationError events that are stored in the account whose license key is associated with the request. For all errors of this type, the attribute newRelicFeature will be Distributed Tracing and requestId will be the requestId from the endpoint response. If you receive a 202 response and don't see an NrIntegrationError event, your data should be visible in New Relic One's global distributed tracing UI in about a minute. You should be able to find the trace using a standard trace search like: traceId = TRACE_ID_SENT Copy Exceeding span limits When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate limit messages with this NRQL: SELECT * FROM NrIntegrationError WHERE newRelicFeature = 'Distributed Tracing' AND category = 'RateLimit' AND rateLimitType = 'SpansPerMinute' Copy To get a notification when you exceed the limit, you can set up a NRQL alert. We calculate a rolling 10-minute average based on your span rate limit. This allows for temporary rate bursts, and lets us prioritize keeping and dropping complete traces instead of indiscriminately dropping spans on a per minute limit basis. In the example below of exceeding the rate, the rate limit is the default 100,000 spans per minute. New Relic allows a burst above 100K for a couple of minutes without downsampling, because the remaining minutes in the 10-minute window averaged under 100K spans/minute. For the previous 10 minutes (8:50 - 9:00) the service received 60,000 spans/minute. Minute Spans sent to API Total for past 10 minutes 8:59 60,000 600,000 9:00 40,000 580,000 9:01 50,000 570,000 9:02 250,000 760,000 9:03 220,000 920,000 9:04 125,000 985,000 9:05 70,000 995,000 9:06 50,000 985,000 9:07 40,000 965,000 9:08 40,000 945,000 9:09 40,000 925,000",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 206.80316,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Trace</em> API general requirements <em>and</em> limits ",
        "sections": "<em>Trace</em> API general requirements <em>and</em> limits",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>Tracing</em>: when you complete the <em>Trace</em> observer setup, you get a custom YOUR_<em>TRACE</em>_OBSERVER_URL value to use as an endpoint. If you&#x27;re using an integration that uses the <em>Trace</em> API (for example, these integrations), you must <em>configure</em> that integration with that endpoint. You will also want to adjust"
      },
      "id": "6071cf7628ccbcf8b851c158"
    }
  ],
  "/docs/distributed-tracing/enable-configure/overview-enable-distributed-tracing": [
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-06-14T18:04:49Z",
      "updated_at": "2021-04-22T06:39:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any New Relic APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: New Relic APM: C New Relic APM: Golang New Relic APM: Java New Relic APM: .NET New Relic APM: Node.js New Relic APM: PHP New Relic APM: Python New Relic APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a New Relic APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever (i.e. -1). For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For best results, update to the latest Ruby agent version. Also install the additional Ruby agent gem for Infinite Tracing. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 6.11.0.365 or higher (includes W3C Trace Context) newrelic-infinite_tracing 6.11.0.375 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.94891,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language agents <em>and</em> <em>distributed</em> <em>tracing</em>",
        "sections": "<em>Configure</em> standard <em>distributed</em> <em>tracing</em> for your older agents",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " you&#x27;re done, return here with your <em>trace</em> observer information and continue with the next step to <em>configure</em> the agent. Step 3: <em>Configure</em> the agent for Infinite <em>Tracing</em> Infinite <em>Tracing</em> configuration settings include the standard <em>distributed</em> <em>tracing</em> plus information about the <em>trace</em> observer. Find"
      },
      "id": "6072a66564441fb28e9d8595"
    },
    {
      "sections": [
        "Enable distributed tracing for our telemetry tool integrations",
        "Sampling considerations",
        "Set up integrations"
      ],
      "title": "Enable distributed tracing for our telemetry tool integrations",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "ca05c9c79d80af7bc4f16230459e9811a23a94b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing/",
      "published_at": "2021-06-14T18:03:44Z",
      "updated_at": "2021-04-15T22:20:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the telemetry tools Istio, Kamon, OpenCensus, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because distributed systems can generate a lot of trace data, telemetry tools rely on data sampling (filtering). When you install a telemetry integration that reports trace data, you'll have an option to enable Infinite Tracing. Choosing Infinite Tracing has implications for how you configure sampling in your telemetry tool: Standard installation without Infinite Tracing: A standard installation assumes you want your telemetry tool to sample trace data before it's sent to us. (If your trace data exceeds our Trace API limits, we may also do additional sampling.) Install with Infinite Tracing: If you choose Infinite Tracing (read requirements), we assume your telemetry tool's sampling is set to 100%, so that all of that tool's trace data is sent to us. The trace observer selects the most important and actionable traces using tail-based sampling, and then that data is ingested via our Trace API. Set up integrations To set up your telemetry tool for sending distributed traces to New Relic, follow the instructions for your tool: OpenTelemetry Istio Kamon OpenCensus AWS X-Ray",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 233.9693,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Enable</em> <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "sections": "<em>Enable</em> <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " you install a telemetry integration that reports <em>trace</em> data, you&#x27;ll have an option to <em>enable</em> Infinite <em>Tracing</em>. Choosing Infinite <em>Tracing</em> has implications for how you <em>configure</em> sampling in your telemetry tool: Standard installation without Infinite <em>Tracing</em>: A standard installation assumes you want"
      },
      "id": "6072a66664441f271c9d8557"
    },
    {
      "sections": [
        "Trace API general requirements and limits",
        "Endpoints",
        "Data formats",
        "Data limits",
        "Restricted attributes",
        "Request metadata (headers and query parameters)",
        "Important",
        "Response validation",
        "See HTTP status codes",
        "Exceeding span limits"
      ],
      "title": "Trace API general requirements and limits ",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "f77504082dae8374e0c7009a31abebbd4c0123f3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/trace-api-general-requirements-limits/",
      "published_at": "2021-06-14T18:07:42Z",
      "updated_at": "2021-06-09T00:57:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Information about Trace API data requirements, including: Data specifications and max limits Required metadata (headers, query parameters) Response validation details This document applies to the Trace API overall. For rules regarding specific data formats, see: New Relic-format trace data Zipkin-format trace data Endpoints All trace data is sent via a POST to a Trace API endpoint. We have a few endpoints, depending on your setup: Default Trace API endpoint: https://trace-api.newrelic.com/trace/v1 EU data centers: https://trace-api.eu.newrelic.com/trace/v1 (see other EU endpoints). Infinite Tracing: when you complete the Trace observer setup, you get a custom YOUR_TRACE_OBSERVER_URL value to use as an endpoint. If you're using an integration that uses the Trace API (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust the sampling of your tracing service to send us 100% of spans. For FedRAMP, see FedRAMP endpoints. Data formats Currently, the Trace API accepts two types of data formats: zipkin: For reporting Zipkin trace data. Zipkin data must be Zipkin JSON v2. newrelic: For reporting all other trace data. Data limits Data limits and rules: Condition Limit Max age of span timestamp values 20 minutes. timestamp must be within 20 minutes of current time at ingest, or within 20 minutes from the time the last span with the same trace.id was received by New Relic. Max payload size 1MB (10^6 bytes) (gzip compression supported) Max requests per minute 100K Max spans per minute per account family Dependent on agreement. Max limit: 2M. Max spans per trace 50K Max attributes per span 200 Max span attribute value length 4000 characters Allowed HTTP protocols HTTPS only Cross-account visibility of span details Potential data obfuscation To see an example of how span limits are enforced, see Exceeding limits. Restricted attributes The attributes in the table below are restricted in the newrelic-format JSON (in the attributes block) and in the zipkin-format JSON (in the tags block). Any values with these keys will be omitted: Restricted attribute Description entityGuid string Unique identifier for the entity that created this span. Generated from service.name, if available. guid string Used for backwards compatibility with data from APM agents. The attributes in the table below are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Restricted attribute description entity.guid string Unique identifier for the entity associated with this span. entity.name string Human-readable name of an entity, often used to identify an entity in the UI. entity.type string Used to differentiate between different types of entities, like hosts, applications, etc. Request metadata (headers and query parameters) The following table shows the required request metadata for all trace data formats. This metadata can be sent as HTTP headers on an ingest request or, in some cases, provided as query parameters, which may be required for tracing frameworks that don't allow header modification. Important Security note: We suggest using headers because query parameters are present in the URL and may be logged before being encrypted and received by New Relic. All data sent as query parameters must be URL-safe. Header Query param? Details Content-Type No Required. Must be application/json. Content-Length No Required. The length of the request body in octets (8-bit bytes) unless sent with chunked encoding. This header is generally set by default by the underlying HTTP client sending the data and in most cases should not require any additional effort by the end user. Api-Key Yes (case-sensitive) Required. The Trace API requires the Insights insert key. If this is provided as both a header and a query parameter, the values must match. Content-Encoding No Required if compressed payload. The value must be gzip. Data-Format Yes Required for zipkin. Optional for newrelic. If present, Data-Format-Version must also be present. Data-Format-Version Yes Required for zipkin. If present, Data-Format must also be present. There are only two possible pairings for these values: If Data-Format is zipkin, Data-Format-Version must be 2. If Data-Format is newrelic, Data-Format-Version must be 1. x-request-id No Optional - Reserved for future use. The value must be a valid UUID4. The value is expected to be unique for each request. Response validation A response for successfully sending trace data will include a requestId. For example: {\"requestId\":\"c1bb62fc-001a-b000-0000-016bb152e1bb\"} Copy There are two ways success/errors are signaled: HTTP status code (synchronous). Authentication and request errors will be signaled via HTTP status code. See HTTP status codes Code Meaning 202 Data accepted. This means that you've passed preliminary checks, but is not a guarantee that the data has been successfully parsed and indexed as part of a distributed trace. 400 The structure of the request was invalid. Errors with query parameters, etc. 403 Authentication error. May occur with an invalid license key or if you lack necessary entitlement to use the Trace API. 404 The request path is incorrect. 405 For any request method other than POST. 408 The request took too long to reach the endpoint. 411 The Content-Length header wasn’t included. 413 The payload was too big. 414 The request URI was too long. 415 The Content-Type or Content-Encoding was invalid. 429 The request rate quota has been exceeded. 431 The request headers are too long. 5xx There was a server error (please retry). NrIntegrationError events (asynchronous). Errors with the JSON payload or other semantic errors are asynchronously signaled via NrIntegrationError events that are stored in the account whose license key is associated with the request. For all errors of this type, the attribute newRelicFeature will be Distributed Tracing and requestId will be the requestId from the endpoint response. If you receive a 202 response and don't see an NrIntegrationError event, your data should be visible in New Relic One's global distributed tracing UI in about a minute. You should be able to find the trace using a standard trace search like: traceId = TRACE_ID_SENT Copy Exceeding span limits When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate limit messages with this NRQL: SELECT * FROM NrIntegrationError WHERE newRelicFeature = 'Distributed Tracing' AND category = 'RateLimit' AND rateLimitType = 'SpansPerMinute' Copy To get a notification when you exceed the limit, you can set up a NRQL alert. We calculate a rolling 10-minute average based on your span rate limit. This allows for temporary rate bursts, and lets us prioritize keeping and dropping complete traces instead of indiscriminately dropping spans on a per minute limit basis. In the example below of exceeding the rate, the rate limit is the default 100,000 spans per minute. New Relic allows a burst above 100K for a couple of minutes without downsampling, because the remaining minutes in the 10-minute window averaged under 100K spans/minute. For the previous 10 minutes (8:50 - 9:00) the service received 60,000 spans/minute. Minute Spans sent to API Total for past 10 minutes 8:59 60,000 600,000 9:00 40,000 580,000 9:01 50,000 570,000 9:02 250,000 760,000 9:03 220,000 920,000 9:04 125,000 985,000 9:05 70,000 995,000 9:06 50,000 985,000 9:07 40,000 965,000 9:08 40,000 945,000 9:09 40,000 925,000",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 206.80316,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Trace</em> API general requirements <em>and</em> limits ",
        "sections": "<em>Trace</em> API general requirements <em>and</em> limits",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>Tracing</em>: when you complete the <em>Trace</em> observer setup, you get a custom YOUR_<em>TRACE</em>_OBSERVER_URL value to use as an endpoint. If you&#x27;re using an integration that uses the <em>Trace</em> API (for example, these integrations), you must <em>configure</em> that integration with that endpoint. You will also want to adjust"
      },
      "id": "6071cf7628ccbcf8b851c158"
    }
  ],
  "/docs/distributed-tracing/enable-configure/quick-start": [
    {
      "image": "https://developer.newrelic.com/static/c1fd6182602c7dbc74bf14b13dc1a4c0/0086b/dev-terms-and-conditions.png",
      "url": "https://developer.newrelic.com/build-apps/ab-test/install-nr1/",
      "sections": [
        "Install and configure the New Relic One CLI",
        "Course",
        "Install and configure the CLI",
        "Tip"
      ],
      "published_at": "2021-06-16T01:57:45Z",
      "title": "Install and configure the New Relic One CLI",
      "updated_at": "2021-05-21T01:46:56Z",
      "type": "developer",
      "external_id": "a09ffc1a2296796669ad9d026d6c16937b23a3d4",
      "document_type": "page",
      "popularity": 1,
      "info": "Install and configure the New Relic One CLI",
      "body": "Course This lesson is part of a course that teaches you how to build a New Relic One application from the ground up. If you haven't already, check out the course introduction. Each lesson in the course builds upon the last, so make sure you've completed the last lesson, Spin up your demo services, before starting this one. One of the primary elements of the New Relic One SDK is the command line interface (CLI). To create a Nerdpack , you'll need to install the SDK, configure the CLI to work with your New Relic account, and then utilize its create command. Install and configure the CLI Step 1 of 5 Go to the Build on New Relic quick start. Step 2 of 5 Get your API key: Once you install the CLI, you'll use this key to create a user profile that's associated with your account. The CLI uses this profile to manage entities within your account. Step 3 of 5 Read and accept the New Relic developer terms and conditions: Even if you install the CLI, you won't be able to use it without first accepting these terms and conditions. Step 4 of 5 Choose your operating system and click Download installer: Once you've installed the SDK, you'll have access to the nr1 CLI. Verify this by checking your SDK version: bash Copy $ nr1 --version If you already had the CLI, update it: bash Copy $ nr1 update Tip It’s important to distinguish between the newrelic CLI and the nr1 CLI. newrelic is for managing entities in your New Relic account. nr1 is for managing New Relic One applications. Step 5 of 5 Copy the command to save your credentials: This command has a profile name, your region, and your API key baked in. Run the command in your terminal: bash Copy $ nr1 profiles:add --name <profile name> --api-key <User key> --region <region> Profiles let you select which New Relic account you want to run commands against. If you have multiple accounts, you can view them with profiles:list: bash Copy $ nr1 profiles:list Notice that one profile is your default profile. This is the account your commands will run against, unless you specify another. To specify a profile for a particular command, use the --profile option: bash Copy $ nr1 create --profile <your profile> If this is your first time using the CLI, then the profile you just added is your default profile. If you have other profiles, you need to set your default to the one you'd like to use for this course: bash Copy $ nr1 profiles:default Tip If you forget these commands, you can look them up in the profiles help menu: bash Copy $ nr1 profiles --help Now, you can exit the Build on New Relic quick start. You’re ready to build an application with the New Relic One CLI! Course This lesson is part of a course that teaches you how to build a New Relic One application from the ground up. Continue on to the next lesson: Create a Nerdpack.",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 371.6855,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " of 5 Go to the Build on New Relic <em>quick</em> <em>start</em>. Step 2 of 5 Get your API key: Once you install the CLI, you&#x27;ll use this key to create a user profile that&#x27;s associated with your account. The CLI uses this profile to manage entities within your account. Step 3 of 5 Read and accept the New Relic"
      },
      "id": "6091faf1196a6714b4d52a39"
    },
    {
      "sections": [
        "Set up your development environment",
        "Before you begin",
        "A note on support",
        "Tip",
        "Prepare to build or modify apps",
        "Start building",
        "Contribute to developer.newrelic.com"
      ],
      "title": "Set up your development environment",
      "type": "developer",
      "tags": [
        "developer account",
        "API key",
        "New Relic One CLI"
      ],
      "external_id": "c45638a9cd548d1ffffc9f1c7708f115a92ae04a",
      "image": "",
      "url": "https://developer.newrelic.com/build-apps/set-up-dev-env/",
      "published_at": "2021-06-16T01:46:03Z",
      "updated_at": "2021-05-05T01:51:53Z",
      "document_type": "page",
      "popularity": 1,
      "info": "Prepare to build apps and contribute to this site",
      "body": "If you've decided to build a custom app or modify one of our open source apps, you need a few essential tools: The New Relic One command line interface (CLI) An API key, which you get when you download the CLI Depending on what you want to do with your app, you might have some additional setup and configuration. This guide covers: Downloading the New Relic One CLI to build or modify apps Contribute content to this website Before you begin Before you begin, we recommend first reading about permissions. To start building, you must have: A github account account - While not strictly necessary for building apps, a GitHub account enables you to download and customize our open source apps, and contribute an open source project. A New Relic developer account - if you don't already have one, you can get a free trial account for developing New Relic applications. npm - If you've installed Node.js, then you already have npm, which is used to share, reuse, and update JavaScript code, and is necessary for working with React components that are the framework for New Relic apps and this website. A note on support Building a New Relic One application is the same as building any JavaScript/React application. We offer support to help with our building tools (our CLI and SDK library). However, we don't offer support for basic JavaScript or React coding questions or issues. For common questions and answers about building, see the Explorers Hub page on building on New Relic One. Tip Use the New Relic One VSCode extension or the New Relic VSCode extension pack to build your apps. Prepare to build or modify apps Step 1 of 1 Download the CLI and API key. On the Build New Relic One applications page, complete the Quick start steps. These six Quick start steps get you an API key for use with developing apps, and the New Relic One CLI, for building and deploying apps. At the end of the Quick start, you have a project consisting of the following: A Nerdpack - The package containing all the files required by your application. It contains two types of files that you customize to build your app: Nerdlets, and the launcher. One or more Nerdlet files - A specific UI view or window. A Nerdlet is a React JavaScript package that includes an index.js file, a stylesheet, and a JSON-format config file. It can contain any JS functionality (charts, interactive fields, tooltips, etc.). A launcher file: This is the basis for the launcher, which is used to open your application from New Relic One after you publish your app. Start building Step 1 of 1 If you're ready to code, cd to your Nerdpack and get started. If you want to learn more about building applications, try these step-by-step guides: Build a \"Hello, World!\" application shows how to create a little application, publish it to New Relic One, and share it with others by subscribing accounts to it. Map pageviews by region takes you through the steps to create one of our popular open source apps. You learn to add a custom query to an app and view it in a table, then add that data to a map. Contribute to developer.newrelic.com This site is open source, and we want your input. Create a pull request if you see a mistake you know how to fix. Drop us a GitHub issue if you see some content gaps you want us to work on. Or write up a whole new guide if you have one you'd like to share. Read on to learn how. Step 1 of 3 Fork the developer-website GithHub repo. Forking the repo enables you to work on your own copy of the developer.newrelic.com files, and build the site locally. It also enables us to more easily manage incomimg pull requests. On the developer-website page in GitHub, select the Fork button on the top right of the page, choose the account you want to fork to, and wait a few seconds while the fork is created. Sync regularly to keep your fork up to date with changes and additions to the main branch upstream. Step 2 of 3 Make a feature or documentation request. On any page, select the GitHub button at the top of the page, and then select the kind of change you want, and fill out the GitHub form. Step 3 of 3 Contribute a new guide. Check out our contributors guidelines, which will walk you through the process.",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 361.16174,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Start</em> building",
        "body": " Relic One VSCode extension or the New Relic VSCode extension pack to build your apps. Prepare to build or modify apps Step 1 of 1 Download the CLI and API key. On the Build New Relic One applications page, complete the <em>Quick</em> <em>start</em> steps. These six <em>Quick</em> <em>start</em> steps get you an API key for use"
      },
      "id": "6091fa3ae7b9d2e0595068b1"
    },
    {
      "sections": [
        "New Relic One CLI reference",
        "Installing the New Relic One CLI",
        "Tip",
        "New Relic One CLI Commands",
        "Get started",
        "Configure your CLI preferences",
        "Set up your Nerdpacks",
        "Manage your Nerdpack subscriptions",
        "Install and manage plugins",
        "Manage catalog information"
      ],
      "title": "New Relic One CLI reference",
      "type": "developer",
      "tags": [
        "New Relic One app",
        "nerdpack commands"
      ],
      "external_id": "858339a44ead21c83257778ce60b4c352cd30d3b",
      "image": "https://developer.newrelic.com/static/2c6d337608b38a3312b4fc740afe6167/7272b/developercenter.png",
      "url": "https://developer.newrelic.com/explore-docs/nr1-cli/",
      "published_at": "2021-06-16T01:44:52Z",
      "updated_at": "2021-05-05T01:53:28Z",
      "document_type": "page",
      "popularity": 1,
      "info": "An overview of the CLI to help you build, deploy, and manage New Relic apps.",
      "body": "To build a New Relic One app, you must install the New Relic One CLI. The CLI helps you build, publish, and manage your New Relic app. We provide a variety of tools for building apps, including the New Relic One CLI (command line interface). This page explains how to use CLI commands to: Generate Nerdpack/Nerdlet templates Locally serve Nerdpacks (when developing) Publish and deploy Subscribe to Nerdpacks Add screenshots and metadata to the catalog Installing the New Relic One CLI In New Relic, click Apps and then in the New Relic One catalog area, click the Build your own application launcher and follow the quick start instructions. The quick start automatically generates an API key for the account you select, and gives you the pre-populated commands to create a profile, generate your first \"Hello World\" app, and serve it locally. Tip Use the NR1 VS Code extension to build your apps. New Relic One CLI Commands This table provides descriptions for the New Relic One commands. For more context, including usage and option details, click any individual command or the command category. For details on user permissions, see Permissions. For more on how to serve and publish your application, see our guide on Deploying your New Relic One app. Get started nr1 help Shows all nr1 commands or details about each command. nr1 update Updates to the latest version of the CLI. nr1 create Creates a new component from a template (Nerdpack, Nerdlet, launcher, or catalog). nr1 profiles Manages the profiles you use to run CLI commands. nr1 autocomplete Displays autocomplete installation instructions. nr1 nrql Fetches data using NRQL (New Relic query language). Configure your CLI preferences nr1 config:set Sets a specific configuration value. nr1 config:get Shows a specific configuration. nr1 config:list Lists your configuration choices. nr1 config:delete Removes the value of a specific configuration. Set up your Nerdpacks nr1 nerdpack:build Assembles your Nerdpack into bundles. nr1 nerdpack:clone Clones an open source Nerdpack from our GitHub repository. nr1 nerdpack:serve Serves your Nerdpack for testing and development purposes. nr1 nerdpack:uuid Shows or regenerates the UUID of a Nerdpack. nr1 nerdpack:publish Publishes your Nerdpack to New Relic. nr1 nerdpack:deploy Deploys a Nerdpack version to a specific channel. nr1 nerdpack:undeploy Undeploys a Nerdpack version from a specific channel. nr1 nerdpack:clean Cleans your developtment folders. nr1 nerdpack:validate Validates the contents of your Nerdpack. nr1 nerdpack:info Shows the state of your Nerdpack in the New Relic's registry. Manage your Nerdpack subscriptions nr1 subscription:set Subscribes your account to a Nerdpack and channel. nr1 subscription:list Lists all the Nerdpacks your account is subscribed to. nr1 subscription:unset Unsubscribes your account from a Nerdpack. Install and manage plugins nr1 plugins:install Installs a plugin into the CLI. nr1 plugins:link Links a plugin into the CLI for development. nr1 plugins:update Updates your installed plugins. nr1 plugins:uninstall Removes a plugin from the CLI. Manage catalog information nr1 catalog:info Shows the Nerdpack info stored in the catalog. nr1 catalog:submit Gathers and submits the catalog info on the current folder.",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 342.9526,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Get <em>started</em>",
        "body": " launcher and follow the <em>quick</em> <em>start</em> instructions. The <em>quick</em> <em>start</em> automatically generates an API key for the account you select, and gives you the pre-populated commands to create a profile, generate your first &quot;Hello World&quot; app, and serve it locally. Tip Use the NR1 VS Code extension to build your apps"
      },
      "id": "6091fa9864441feb412f36d4"
    }
  ],
  "/docs/distributed-tracing/index": [
    {
      "sections": [
        "View your OpenTelemetry data in New Relic",
        "Explorer: Get the big picture along with the details",
        "Summary page",
        "Distributed Tracing",
        "Tip",
        "Transactions",
        "Databases",
        "Externals",
        "Errors",
        "Metrics Explorer",
        "Data explorer and query builder"
      ],
      "title": "View your OpenTelemetry data in New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Open source telemetry integrations",
        "OpenTelemetry"
      ],
      "external_id": "a5213cb2206f4c161dd97c015a7c6679b08e867b",
      "image": "https://docs.newrelic.com/static/2f8a3baa6793edf958ecb9db5346efa7/c1b63/explorer_otel_services.png",
      "url": "https://docs.newrelic.com/docs/integrations/open-source-telemetry-integrations/opentelemetry/view-your-opentelemetry-data-new-relic/",
      "published_at": "2021-06-15T13:27:17Z",
      "updated_at": "2021-06-15T13:27:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you import OpenTelemetry data into New Relic, you can use a variety of tools to analyze it. Take a look at these UI options: Explorer Data explorer and query builder Explorer: Get the big picture along with the details The New Relic explorer is a good place to get overview information about your applications, as well as detailed information, such as distributed tracing. To get started with the explorer: Go to one.newrelic.com and click Explorer. In the left sidebar, click Services - OpenTelemetry: Click the service you want to know more about, and if you need help understanding the data, see the explanations below. Summary page The opening page of the explorer is the Summary page listing various golden signals about your entity. Golden signals are key monitoring details such as response time, throughput, and error rate. By using this information, you can quickly decide if you need to dig deeper. Distributed Tracing When you access distributed tracing through the explorer, you are looking at traces that include that service. Once you’re in that service, you can filter spans to find the ones you want. For example, to query service.name or trace.id, you can use the following: service.name = YOUR_SERVICE_NAME trace.id = YOUR_TRACE_ID For more ways to filter and analyze your spans, see our distributed tracing UI page. Tip If you prefer to search traces across all New Relic accounts in your organization, you can go outside explorer: one.newrelic.com > Apps > Favorites > Distributed tracing. Transactions Use Transactions to identify slow or error transactions that might be causing a spike in the response time of your application. From the transaction summary page, you can get a list of transactions by selecting See transactions table. Databases The Databases page shows an application's database and cache data. The page shows individual database transactions as a sortable table, and shows operations, throughput, and response time as charts. Externals Externals captures calls to out-of-process services such as web services, resources in the cloud, and other network entities. Errors On this page, you can see total errors, as well as charts showing error count and error rate. Metrics Explorer For selected OpenTelemetry languages, you can see information about your metrics in this section. Also, if you are using the Prometheus exporter with OpenTelemetry, you can view your metric data here. Data explorer and query builder Explore your metrics and traces using the data explorer, or write your own queries in query builder using NRQL. For more on how to query your data once it's in New Relic, see Query your data and Introduction to NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 998.8745,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Distributed</em> <em>Tracing</em>",
        "body": " to dig deeper. <em>Distributed</em> <em>Tracing</em> When you access <em>distributed</em> <em>tracing</em> through the explorer, you are looking at traces that include that service. Once you’re in that service, you can filter spans to find the ones you want. For example, to query service.name or <em>trace</em>.id, you can use the following"
      },
      "id": "6044e5dfe7b9d283d3579a04"
    },
    {
      "sections": [
        "Introduction to distributed tracing",
        "Why it matters",
        "Instrumentation: The key to distributed tracing",
        "What you can see in the New Relic UI",
        "Next steps"
      ],
      "title": "Introduction to distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "ac173988a6503674b4411c9c2efe6713912c37f2",
      "image": "https://docs.newrelic.com/static/8a63e4d34a1272fa33ad7b3564db6bf8/b5bda/span-diagram.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/introduction-distributed-tracing/",
      "published_at": "2021-06-14T18:03:44Z",
      "updated_at": "2021-04-11T07:38:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing tracks and observes service requests as they flow through distributed systems. With distributed tracing data, you can quickly pinpoint failures or performance issues and fix them. Distributed tracing systems collect data as the requests go from one service to another, recording each segment of the journey as a span. These spans contain important details about each segment of the request and are combined into one trace. The completed trace gives you a picture of the entire request. Here is an example of three spans captured from an HTTP request. These spans are sent to New Relic where they are combined into one distributed trace. Why it matters A request might pass through various microservices to reach completion. The microservices or functions could be located in multiple containers, serverless environments, virtual machines, different cloud providers, on-premises, or any combination of these. For example, let's say that you're in a situation where a slow-running request affects the experience of a set of customers: The request is distributed across multiple microservices and serverless functions. Several different teams own and monitor the various services that are involved in the request. None of the teams have reported any performance issues with their microservices. Without a way to view the performance of the entire request across the different services, it’s nearly impossible to pinpoint where and why the high latency is occurring and which team should address the issue. Instrumentation: The key to distributed tracing Distributed tracing starts with the instrumentation of your services to enable data collection and correlation across the entire distributed system. Instrumention means either manually adding code to services or installing agents that automatically track trace data. Many of our New Relic solutions automatically instrument your services for a large number of programming languages and frameworks. You can also use open source tools and open instrumentation standards to instrument your environment. OpenTelemetry, part of the Cloud Native Computing Foundation (CNCF), is becoming the one standard for open source instrumentation and telemetry collection. What you can see in the New Relic UI After the data is collected, you can visualize it to see service dependencies, performance, and any anomalous events such as errors or unusual latency. Here are some examples of what you can do with your data: What you can do Description Detect anomalous spans Spans that are slow in comparison to typical behavior are marked as anomalous, with charts comparing them to typical performance. See your errors and logs Frontend and backend errors appear right in the context of your traces. Everything you need to troubleshoot is in one place. Filter results You can filter charts using many data points, so you can analyze trace data in different ways. Customize queries and dashboards You can create custom queries of your trace data and create custom data dashboards. See data across accounts See a global view of traces from across all your accounts and applications in New Relic One. Query traces programmatically Query distributed trace data by using GraphQL in our NerdGraph API explorer. Next steps Here are some tasks to consider: To instrument your services, check out our Quick start. To learn more about what's happening under the hood, see How distributed tracing works.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>distributed</em> <em>tracing</em>",
        "sections": "Introduction to <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Distributed</em> <em>tracing</em>",
        "body": " and create custom data dashboards. See data across accounts See a global view of traces from across all your accounts and applications in New Relic One. Query traces programmatically Query <em>distributed</em> <em>trace</em> data by using GraphQL in our NerdGraph API explorer. Next steps Here are some tasks to consider: To instrument your services, check out our Quick start. To learn more about what&#x27;s happening under the hood, see How <em>distributed</em> <em>tracing</em> works."
      },
      "id": "6072a767e7b9d231f1a5c64c"
    },
    {
      "image": "https://docs.newrelic.com/static/f487e8c287d614c494f56bd35fd38bb5/c1b63/arrow-step-diagram-trans.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/quick-start/",
      "sections": [
        "Quick start"
      ],
      "published_at": "2021-06-14T18:04:48Z",
      "title": "Quick start",
      "updated_at": "2021-04-11T07:32:21Z",
      "type": "docs",
      "external_id": "f9f4aa287602eee82a0eb7d15775d033ada26d63",
      "document_type": "page",
      "popularity": 1,
      "body": "To set up distributed tracing, you'll complete these three general steps: Identify services: Identify and write down the endpoints, services, languages, and systems that are used to complete this request (you'll need this information in the next step). If you have an environment diagram like the following, you could use it to create a list of services handling requests: Instrument services: Instrument each service you identify so it can send your trace data. Some tools, such as New Relic APM agents, instrument services automatically, while other tools require you to insert some code in the services. Click the icon below for instrumentation steps: New Relic APM: C New Relic APM: Golang New Relic APM: Java New Relic APM: .NET New Relic APM: Node.js New Relic APM: PHP New Relic APM: Python New Relic APM: Ruby New Relic Browser New Relic Mobile AWS Lambda Functions Istio Kamon OpenTelemetry X-Ray Zipkin format: custom integration New Relic format: custom integration View traces: After you instrument the services, generate some traffic in your application, and then go to the New Relic UI to see your trace data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": "To set up <em>distributed</em> <em>tracing</em>, you&#x27;ll complete these three general steps: Identify services: Identify and write down the endpoints, services, languages, and systems that are used to complete this request (you&#x27;ll need this information in the next step). If you have an environment diagram like"
      },
      "id": "6072a60564441f2f6f9d8541"
    }
  ],
  "/docs/distributed-tracing/infinite-tracing/infinite-tracing-configure-proxy-support": [
    {
      "sections": [
        "Trace API general requirements and limits",
        "Endpoints",
        "Data formats",
        "Data limits",
        "Restricted attributes",
        "Request metadata (headers and query parameters)",
        "Important",
        "Response validation",
        "See HTTP status codes",
        "Exceeding span limits"
      ],
      "title": "Trace API general requirements and limits ",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "f77504082dae8374e0c7009a31abebbd4c0123f3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/trace-api-general-requirements-limits/",
      "published_at": "2021-06-14T18:07:42Z",
      "updated_at": "2021-06-09T00:57:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Information about Trace API data requirements, including: Data specifications and max limits Required metadata (headers, query parameters) Response validation details This document applies to the Trace API overall. For rules regarding specific data formats, see: New Relic-format trace data Zipkin-format trace data Endpoints All trace data is sent via a POST to a Trace API endpoint. We have a few endpoints, depending on your setup: Default Trace API endpoint: https://trace-api.newrelic.com/trace/v1 EU data centers: https://trace-api.eu.newrelic.com/trace/v1 (see other EU endpoints). Infinite Tracing: when you complete the Trace observer setup, you get a custom YOUR_TRACE_OBSERVER_URL value to use as an endpoint. If you're using an integration that uses the Trace API (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust the sampling of your tracing service to send us 100% of spans. For FedRAMP, see FedRAMP endpoints. Data formats Currently, the Trace API accepts two types of data formats: zipkin: For reporting Zipkin trace data. Zipkin data must be Zipkin JSON v2. newrelic: For reporting all other trace data. Data limits Data limits and rules: Condition Limit Max age of span timestamp values 20 minutes. timestamp must be within 20 minutes of current time at ingest, or within 20 minutes from the time the last span with the same trace.id was received by New Relic. Max payload size 1MB (10^6 bytes) (gzip compression supported) Max requests per minute 100K Max spans per minute per account family Dependent on agreement. Max limit: 2M. Max spans per trace 50K Max attributes per span 200 Max span attribute value length 4000 characters Allowed HTTP protocols HTTPS only Cross-account visibility of span details Potential data obfuscation To see an example of how span limits are enforced, see Exceeding limits. Restricted attributes The attributes in the table below are restricted in the newrelic-format JSON (in the attributes block) and in the zipkin-format JSON (in the tags block). Any values with these keys will be omitted: Restricted attribute Description entityGuid string Unique identifier for the entity that created this span. Generated from service.name, if available. guid string Used for backwards compatibility with data from APM agents. The attributes in the table below are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Restricted attribute description entity.guid string Unique identifier for the entity associated with this span. entity.name string Human-readable name of an entity, often used to identify an entity in the UI. entity.type string Used to differentiate between different types of entities, like hosts, applications, etc. Request metadata (headers and query parameters) The following table shows the required request metadata for all trace data formats. This metadata can be sent as HTTP headers on an ingest request or, in some cases, provided as query parameters, which may be required for tracing frameworks that don't allow header modification. Important Security note: We suggest using headers because query parameters are present in the URL and may be logged before being encrypted and received by New Relic. All data sent as query parameters must be URL-safe. Header Query param? Details Content-Type No Required. Must be application/json. Content-Length No Required. The length of the request body in octets (8-bit bytes) unless sent with chunked encoding. This header is generally set by default by the underlying HTTP client sending the data and in most cases should not require any additional effort by the end user. Api-Key Yes (case-sensitive) Required. The Trace API requires the Insights insert key. If this is provided as both a header and a query parameter, the values must match. Content-Encoding No Required if compressed payload. The value must be gzip. Data-Format Yes Required for zipkin. Optional for newrelic. If present, Data-Format-Version must also be present. Data-Format-Version Yes Required for zipkin. If present, Data-Format must also be present. There are only two possible pairings for these values: If Data-Format is zipkin, Data-Format-Version must be 2. If Data-Format is newrelic, Data-Format-Version must be 1. x-request-id No Optional - Reserved for future use. The value must be a valid UUID4. The value is expected to be unique for each request. Response validation A response for successfully sending trace data will include a requestId. For example: {\"requestId\":\"c1bb62fc-001a-b000-0000-016bb152e1bb\"} Copy There are two ways success/errors are signaled: HTTP status code (synchronous). Authentication and request errors will be signaled via HTTP status code. See HTTP status codes Code Meaning 202 Data accepted. This means that you've passed preliminary checks, but is not a guarantee that the data has been successfully parsed and indexed as part of a distributed trace. 400 The structure of the request was invalid. Errors with query parameters, etc. 403 Authentication error. May occur with an invalid license key or if you lack necessary entitlement to use the Trace API. 404 The request path is incorrect. 405 For any request method other than POST. 408 The request took too long to reach the endpoint. 411 The Content-Length header wasn’t included. 413 The payload was too big. 414 The request URI was too long. 415 The Content-Type or Content-Encoding was invalid. 429 The request rate quota has been exceeded. 431 The request headers are too long. 5xx There was a server error (please retry). NrIntegrationError events (asynchronous). Errors with the JSON payload or other semantic errors are asynchronously signaled via NrIntegrationError events that are stored in the account whose license key is associated with the request. For all errors of this type, the attribute newRelicFeature will be Distributed Tracing and requestId will be the requestId from the endpoint response. If you receive a 202 response and don't see an NrIntegrationError event, your data should be visible in New Relic One's global distributed tracing UI in about a minute. You should be able to find the trace using a standard trace search like: traceId = TRACE_ID_SENT Copy Exceeding span limits When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate limit messages with this NRQL: SELECT * FROM NrIntegrationError WHERE newRelicFeature = 'Distributed Tracing' AND category = 'RateLimit' AND rateLimitType = 'SpansPerMinute' Copy To get a notification when you exceed the limit, you can set up a NRQL alert. We calculate a rolling 10-minute average based on your span rate limit. This allows for temporary rate bursts, and lets us prioritize keeping and dropping complete traces instead of indiscriminately dropping spans on a per minute limit basis. In the example below of exceeding the rate, the rate limit is the default 100,000 spans per minute. New Relic allows a burst above 100K for a couple of minutes without downsampling, because the remaining minutes in the 10-minute window averaged under 100K spans/minute. For the previous 10 minutes (8:50 - 9:00) the service received 60,000 spans/minute. Minute Spans sent to API Total for past 10 minutes 8:59 60,000 600,000 9:00 40,000 580,000 9:01 50,000 570,000 9:02 250,000 760,000 9:03 220,000 920,000 9:04 125,000 985,000 9:05 70,000 995,000 9:06 50,000 985,000 9:07 40,000 965,000 9:08 40,000 945,000 9:09 40,000 925,000",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 262.45343,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Trace</em> API general requirements and limits ",
        "sections": "<em>Trace</em> API general requirements and limits",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " be visible in New Relic One&#x27;s global <em>distributed</em> <em>tracing</em> UI in about a minute. You should be able to find the <em>trace</em> using a standard <em>trace</em> search like: <em>trace</em>Id = <em>TRACE</em>_ID_SENT Copy Exceeding span limits When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate"
      },
      "id": "6071cf7628ccbcf8b851c158"
    },
    {
      "sections": [
        "Infinite Tracing: trace configuration conflicts",
        "Problem"
      ],
      "title": "Infinite Tracing: trace configuration conflicts",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Troubleshooting"
      ],
      "external_id": "b5f9f72d5adf410a972ef089484d53ffa355aa65",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/troubleshooting/infinite-tracing-trace-configuration-conflicts/",
      "published_at": "2021-06-14T19:08:49Z",
      "updated_at": "2021-04-11T07:38:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Traces with configuration conflicts are caused when you've enabled Infinite Tracing for one or more services in a trace, but other services in that trace have our standard (non-Infinite Tracing) distributed tracing solutions enabled. You can solve this problem by enabling Infinite Tracing for all services in a trace. A tracing configuration conflict can cause issues like: Fragmented traces and orphaned spans. Incomplete Infinite Tracing metrics due to not taking standard trace sampling into account. Discrepancies for metrics like span count, service count, durations, and error count. Confusing search results. For example, for standard tracing spans that send headers to Infinite Tracing-instrumented services, those spans may show in the trace list but not in the trace waterfall view. Missing traces for monitored browser apps and mobile apps. Because Infinite Tracing isn’t yet available for browser or mobile monitoring, spans from these services won’t show up in the trace waterfall when they make requests to Infinite Tracing-enabled services. For traces with a configuration conflict, we’ll display only the Infinite Tracing data in the UI because that data is of higher quality. (All tracing data is queryable via NRQL.)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 260.83084,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infinite</em> <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "sections": "<em>Infinite</em> <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Problem Traces with configuration conflicts are caused when you&#x27;ve enabled <em>Infinite</em> <em>Tracing</em> for one or more services in a <em>trace</em>, but other services in that <em>trace</em> have our standard (non-<em>Infinite</em> <em>Tracing</em>) <em>distributed</em> <em>tracing</em> solutions enabled. You can solve this problem by enabling <em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6072a76664441fe9c09d859a"
    },
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "Tip",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2021-06-14T18:06:43Z",
      "updated_at": "2021-05-05T19:20:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to our Infinite Tracing feature. For an overview of all distributed tracing options, see Enable distributed tracing. Tip To use Infinite Tracing and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing plan: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. To start setting up Infinite Tracing, and to see specific requirements, see the docs for these tools: Our language agents Our integrations for third-party telemetry tools Our Trace API Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 259.42432,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "sections": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " standard <em>distributed</em> <em>tracing</em> options, <em>Infinite</em> <em>Tracing</em> can process more <em>trace</em> data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard <em>tracing</em> feature uses. Resources for learning more about <em>Infinite</em> <em>Tracing</em>: <em>Infinite</em>"
      },
      "id": "6072a6a4196a67faa964a788"
    }
  ],
  "/docs/distributed-tracing/infinite-tracing/infinite-tracing-configure-random-trace-filter": [
    {
      "sections": [
        "Trace API general requirements and limits",
        "Endpoints",
        "Data formats",
        "Data limits",
        "Restricted attributes",
        "Request metadata (headers and query parameters)",
        "Important",
        "Response validation",
        "See HTTP status codes",
        "Exceeding span limits"
      ],
      "title": "Trace API general requirements and limits ",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "f77504082dae8374e0c7009a31abebbd4c0123f3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/trace-api-general-requirements-limits/",
      "published_at": "2021-06-14T18:07:42Z",
      "updated_at": "2021-06-09T00:57:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Information about Trace API data requirements, including: Data specifications and max limits Required metadata (headers, query parameters) Response validation details This document applies to the Trace API overall. For rules regarding specific data formats, see: New Relic-format trace data Zipkin-format trace data Endpoints All trace data is sent via a POST to a Trace API endpoint. We have a few endpoints, depending on your setup: Default Trace API endpoint: https://trace-api.newrelic.com/trace/v1 EU data centers: https://trace-api.eu.newrelic.com/trace/v1 (see other EU endpoints). Infinite Tracing: when you complete the Trace observer setup, you get a custom YOUR_TRACE_OBSERVER_URL value to use as an endpoint. If you're using an integration that uses the Trace API (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust the sampling of your tracing service to send us 100% of spans. For FedRAMP, see FedRAMP endpoints. Data formats Currently, the Trace API accepts two types of data formats: zipkin: For reporting Zipkin trace data. Zipkin data must be Zipkin JSON v2. newrelic: For reporting all other trace data. Data limits Data limits and rules: Condition Limit Max age of span timestamp values 20 minutes. timestamp must be within 20 minutes of current time at ingest, or within 20 minutes from the time the last span with the same trace.id was received by New Relic. Max payload size 1MB (10^6 bytes) (gzip compression supported) Max requests per minute 100K Max spans per minute per account family Dependent on agreement. Max limit: 2M. Max spans per trace 50K Max attributes per span 200 Max span attribute value length 4000 characters Allowed HTTP protocols HTTPS only Cross-account visibility of span details Potential data obfuscation To see an example of how span limits are enforced, see Exceeding limits. Restricted attributes The attributes in the table below are restricted in the newrelic-format JSON (in the attributes block) and in the zipkin-format JSON (in the tags block). Any values with these keys will be omitted: Restricted attribute Description entityGuid string Unique identifier for the entity that created this span. Generated from service.name, if available. guid string Used for backwards compatibility with data from APM agents. The attributes in the table below are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Restricted attribute description entity.guid string Unique identifier for the entity associated with this span. entity.name string Human-readable name of an entity, often used to identify an entity in the UI. entity.type string Used to differentiate between different types of entities, like hosts, applications, etc. Request metadata (headers and query parameters) The following table shows the required request metadata for all trace data formats. This metadata can be sent as HTTP headers on an ingest request or, in some cases, provided as query parameters, which may be required for tracing frameworks that don't allow header modification. Important Security note: We suggest using headers because query parameters are present in the URL and may be logged before being encrypted and received by New Relic. All data sent as query parameters must be URL-safe. Header Query param? Details Content-Type No Required. Must be application/json. Content-Length No Required. The length of the request body in octets (8-bit bytes) unless sent with chunked encoding. This header is generally set by default by the underlying HTTP client sending the data and in most cases should not require any additional effort by the end user. Api-Key Yes (case-sensitive) Required. The Trace API requires the Insights insert key. If this is provided as both a header and a query parameter, the values must match. Content-Encoding No Required if compressed payload. The value must be gzip. Data-Format Yes Required for zipkin. Optional for newrelic. If present, Data-Format-Version must also be present. Data-Format-Version Yes Required for zipkin. If present, Data-Format must also be present. There are only two possible pairings for these values: If Data-Format is zipkin, Data-Format-Version must be 2. If Data-Format is newrelic, Data-Format-Version must be 1. x-request-id No Optional - Reserved for future use. The value must be a valid UUID4. The value is expected to be unique for each request. Response validation A response for successfully sending trace data will include a requestId. For example: {\"requestId\":\"c1bb62fc-001a-b000-0000-016bb152e1bb\"} Copy There are two ways success/errors are signaled: HTTP status code (synchronous). Authentication and request errors will be signaled via HTTP status code. See HTTP status codes Code Meaning 202 Data accepted. This means that you've passed preliminary checks, but is not a guarantee that the data has been successfully parsed and indexed as part of a distributed trace. 400 The structure of the request was invalid. Errors with query parameters, etc. 403 Authentication error. May occur with an invalid license key or if you lack necessary entitlement to use the Trace API. 404 The request path is incorrect. 405 For any request method other than POST. 408 The request took too long to reach the endpoint. 411 The Content-Length header wasn’t included. 413 The payload was too big. 414 The request URI was too long. 415 The Content-Type or Content-Encoding was invalid. 429 The request rate quota has been exceeded. 431 The request headers are too long. 5xx There was a server error (please retry). NrIntegrationError events (asynchronous). Errors with the JSON payload or other semantic errors are asynchronously signaled via NrIntegrationError events that are stored in the account whose license key is associated with the request. For all errors of this type, the attribute newRelicFeature will be Distributed Tracing and requestId will be the requestId from the endpoint response. If you receive a 202 response and don't see an NrIntegrationError event, your data should be visible in New Relic One's global distributed tracing UI in about a minute. You should be able to find the trace using a standard trace search like: traceId = TRACE_ID_SENT Copy Exceeding span limits When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate limit messages with this NRQL: SELECT * FROM NrIntegrationError WHERE newRelicFeature = 'Distributed Tracing' AND category = 'RateLimit' AND rateLimitType = 'SpansPerMinute' Copy To get a notification when you exceed the limit, you can set up a NRQL alert. We calculate a rolling 10-minute average based on your span rate limit. This allows for temporary rate bursts, and lets us prioritize keeping and dropping complete traces instead of indiscriminately dropping spans on a per minute limit basis. In the example below of exceeding the rate, the rate limit is the default 100,000 spans per minute. New Relic allows a burst above 100K for a couple of minutes without downsampling, because the remaining minutes in the 10-minute window averaged under 100K spans/minute. For the previous 10 minutes (8:50 - 9:00) the service received 60,000 spans/minute. Minute Spans sent to API Total for past 10 minutes 8:59 60,000 600,000 9:00 40,000 580,000 9:01 50,000 570,000 9:02 250,000 760,000 9:03 220,000 920,000 9:04 125,000 985,000 9:05 70,000 995,000 9:06 50,000 985,000 9:07 40,000 965,000 9:08 40,000 945,000 9:09 40,000 925,000",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 262.45343,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Trace</em> API general requirements and limits ",
        "sections": "<em>Trace</em> API general requirements and limits",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " be visible in New Relic One&#x27;s global <em>distributed</em> <em>tracing</em> UI in about a minute. You should be able to find the <em>trace</em> using a standard <em>trace</em> search like: <em>trace</em>Id = <em>TRACE</em>_ID_SENT Copy Exceeding span limits When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate"
      },
      "id": "6071cf7628ccbcf8b851c158"
    },
    {
      "sections": [
        "Infinite Tracing: trace configuration conflicts",
        "Problem"
      ],
      "title": "Infinite Tracing: trace configuration conflicts",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Troubleshooting"
      ],
      "external_id": "b5f9f72d5adf410a972ef089484d53ffa355aa65",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/troubleshooting/infinite-tracing-trace-configuration-conflicts/",
      "published_at": "2021-06-14T19:08:49Z",
      "updated_at": "2021-04-11T07:38:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Traces with configuration conflicts are caused when you've enabled Infinite Tracing for one or more services in a trace, but other services in that trace have our standard (non-Infinite Tracing) distributed tracing solutions enabled. You can solve this problem by enabling Infinite Tracing for all services in a trace. A tracing configuration conflict can cause issues like: Fragmented traces and orphaned spans. Incomplete Infinite Tracing metrics due to not taking standard trace sampling into account. Discrepancies for metrics like span count, service count, durations, and error count. Confusing search results. For example, for standard tracing spans that send headers to Infinite Tracing-instrumented services, those spans may show in the trace list but not in the trace waterfall view. Missing traces for monitored browser apps and mobile apps. Because Infinite Tracing isn’t yet available for browser or mobile monitoring, spans from these services won’t show up in the trace waterfall when they make requests to Infinite Tracing-enabled services. For traces with a configuration conflict, we’ll display only the Infinite Tracing data in the UI because that data is of higher quality. (All tracing data is queryable via NRQL.)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 260.83084,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infinite</em> <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "sections": "<em>Infinite</em> <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Problem Traces with configuration conflicts are caused when you&#x27;ve enabled <em>Infinite</em> <em>Tracing</em> for one or more services in a <em>trace</em>, but other services in that <em>trace</em> have our standard (non-<em>Infinite</em> <em>Tracing</em>) <em>distributed</em> <em>tracing</em> solutions enabled. You can solve this problem by enabling <em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6072a76664441fe9c09d859a"
    },
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "Tip",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2021-06-14T18:06:43Z",
      "updated_at": "2021-05-05T19:20:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to our Infinite Tracing feature. For an overview of all distributed tracing options, see Enable distributed tracing. Tip To use Infinite Tracing and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing plan: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. To start setting up Infinite Tracing, and to see specific requirements, see the docs for these tools: Our language agents Our integrations for third-party telemetry tools Our Trace API Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 259.42432,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "sections": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " standard <em>distributed</em> <em>tracing</em> options, <em>Infinite</em> <em>Tracing</em> can process more <em>trace</em> data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard <em>tracing</em> feature uses. Resources for learning more about <em>Infinite</em> <em>Tracing</em>: <em>Infinite</em>"
      },
      "id": "6072a6a4196a67faa964a788"
    }
  ],
  "/docs/distributed-tracing/infinite-tracing/infinite-tracing-configure-span-attribute-trace-filter": [
    {
      "sections": [
        "Trace API general requirements and limits",
        "Endpoints",
        "Data formats",
        "Data limits",
        "Restricted attributes",
        "Request metadata (headers and query parameters)",
        "Important",
        "Response validation",
        "See HTTP status codes",
        "Exceeding span limits"
      ],
      "title": "Trace API general requirements and limits ",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "f77504082dae8374e0c7009a31abebbd4c0123f3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/trace-api-general-requirements-limits/",
      "published_at": "2021-06-14T18:07:42Z",
      "updated_at": "2021-06-09T00:57:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Information about Trace API data requirements, including: Data specifications and max limits Required metadata (headers, query parameters) Response validation details This document applies to the Trace API overall. For rules regarding specific data formats, see: New Relic-format trace data Zipkin-format trace data Endpoints All trace data is sent via a POST to a Trace API endpoint. We have a few endpoints, depending on your setup: Default Trace API endpoint: https://trace-api.newrelic.com/trace/v1 EU data centers: https://trace-api.eu.newrelic.com/trace/v1 (see other EU endpoints). Infinite Tracing: when you complete the Trace observer setup, you get a custom YOUR_TRACE_OBSERVER_URL value to use as an endpoint. If you're using an integration that uses the Trace API (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust the sampling of your tracing service to send us 100% of spans. For FedRAMP, see FedRAMP endpoints. Data formats Currently, the Trace API accepts two types of data formats: zipkin: For reporting Zipkin trace data. Zipkin data must be Zipkin JSON v2. newrelic: For reporting all other trace data. Data limits Data limits and rules: Condition Limit Max age of span timestamp values 20 minutes. timestamp must be within 20 minutes of current time at ingest, or within 20 minutes from the time the last span with the same trace.id was received by New Relic. Max payload size 1MB (10^6 bytes) (gzip compression supported) Max requests per minute 100K Max spans per minute per account family Dependent on agreement. Max limit: 2M. Max spans per trace 50K Max attributes per span 200 Max span attribute value length 4000 characters Allowed HTTP protocols HTTPS only Cross-account visibility of span details Potential data obfuscation To see an example of how span limits are enforced, see Exceeding limits. Restricted attributes The attributes in the table below are restricted in the newrelic-format JSON (in the attributes block) and in the zipkin-format JSON (in the tags block). Any values with these keys will be omitted: Restricted attribute Description entityGuid string Unique identifier for the entity that created this span. Generated from service.name, if available. guid string Used for backwards compatibility with data from APM agents. The attributes in the table below are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Restricted attribute description entity.guid string Unique identifier for the entity associated with this span. entity.name string Human-readable name of an entity, often used to identify an entity in the UI. entity.type string Used to differentiate between different types of entities, like hosts, applications, etc. Request metadata (headers and query parameters) The following table shows the required request metadata for all trace data formats. This metadata can be sent as HTTP headers on an ingest request or, in some cases, provided as query parameters, which may be required for tracing frameworks that don't allow header modification. Important Security note: We suggest using headers because query parameters are present in the URL and may be logged before being encrypted and received by New Relic. All data sent as query parameters must be URL-safe. Header Query param? Details Content-Type No Required. Must be application/json. Content-Length No Required. The length of the request body in octets (8-bit bytes) unless sent with chunked encoding. This header is generally set by default by the underlying HTTP client sending the data and in most cases should not require any additional effort by the end user. Api-Key Yes (case-sensitive) Required. The Trace API requires the Insights insert key. If this is provided as both a header and a query parameter, the values must match. Content-Encoding No Required if compressed payload. The value must be gzip. Data-Format Yes Required for zipkin. Optional for newrelic. If present, Data-Format-Version must also be present. Data-Format-Version Yes Required for zipkin. If present, Data-Format must also be present. There are only two possible pairings for these values: If Data-Format is zipkin, Data-Format-Version must be 2. If Data-Format is newrelic, Data-Format-Version must be 1. x-request-id No Optional - Reserved for future use. The value must be a valid UUID4. The value is expected to be unique for each request. Response validation A response for successfully sending trace data will include a requestId. For example: {\"requestId\":\"c1bb62fc-001a-b000-0000-016bb152e1bb\"} Copy There are two ways success/errors are signaled: HTTP status code (synchronous). Authentication and request errors will be signaled via HTTP status code. See HTTP status codes Code Meaning 202 Data accepted. This means that you've passed preliminary checks, but is not a guarantee that the data has been successfully parsed and indexed as part of a distributed trace. 400 The structure of the request was invalid. Errors with query parameters, etc. 403 Authentication error. May occur with an invalid license key or if you lack necessary entitlement to use the Trace API. 404 The request path is incorrect. 405 For any request method other than POST. 408 The request took too long to reach the endpoint. 411 The Content-Length header wasn’t included. 413 The payload was too big. 414 The request URI was too long. 415 The Content-Type or Content-Encoding was invalid. 429 The request rate quota has been exceeded. 431 The request headers are too long. 5xx There was a server error (please retry). NrIntegrationError events (asynchronous). Errors with the JSON payload or other semantic errors are asynchronously signaled via NrIntegrationError events that are stored in the account whose license key is associated with the request. For all errors of this type, the attribute newRelicFeature will be Distributed Tracing and requestId will be the requestId from the endpoint response. If you receive a 202 response and don't see an NrIntegrationError event, your data should be visible in New Relic One's global distributed tracing UI in about a minute. You should be able to find the trace using a standard trace search like: traceId = TRACE_ID_SENT Copy Exceeding span limits When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate limit messages with this NRQL: SELECT * FROM NrIntegrationError WHERE newRelicFeature = 'Distributed Tracing' AND category = 'RateLimit' AND rateLimitType = 'SpansPerMinute' Copy To get a notification when you exceed the limit, you can set up a NRQL alert. We calculate a rolling 10-minute average based on your span rate limit. This allows for temporary rate bursts, and lets us prioritize keeping and dropping complete traces instead of indiscriminately dropping spans on a per minute limit basis. In the example below of exceeding the rate, the rate limit is the default 100,000 spans per minute. New Relic allows a burst above 100K for a couple of minutes without downsampling, because the remaining minutes in the 10-minute window averaged under 100K spans/minute. For the previous 10 minutes (8:50 - 9:00) the service received 60,000 spans/minute. Minute Spans sent to API Total for past 10 minutes 8:59 60,000 600,000 9:00 40,000 580,000 9:01 50,000 570,000 9:02 250,000 760,000 9:03 220,000 920,000 9:04 125,000 985,000 9:05 70,000 995,000 9:06 50,000 985,000 9:07 40,000 965,000 9:08 40,000 945,000 9:09 40,000 925,000",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 262.45337,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Trace</em> API general requirements and limits ",
        "sections": "<em>Trace</em> API general requirements and limits",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " be visible in New Relic One&#x27;s global <em>distributed</em> <em>tracing</em> UI in about a minute. You should be able to find the <em>trace</em> using a standard <em>trace</em> search like: <em>trace</em>Id = <em>TRACE</em>_ID_SENT Copy Exceeding span limits When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate"
      },
      "id": "6071cf7628ccbcf8b851c158"
    },
    {
      "sections": [
        "Infinite Tracing: trace configuration conflicts",
        "Problem"
      ],
      "title": "Infinite Tracing: trace configuration conflicts",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Troubleshooting"
      ],
      "external_id": "b5f9f72d5adf410a972ef089484d53ffa355aa65",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/troubleshooting/infinite-tracing-trace-configuration-conflicts/",
      "published_at": "2021-06-14T19:08:49Z",
      "updated_at": "2021-04-11T07:38:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Traces with configuration conflicts are caused when you've enabled Infinite Tracing for one or more services in a trace, but other services in that trace have our standard (non-Infinite Tracing) distributed tracing solutions enabled. You can solve this problem by enabling Infinite Tracing for all services in a trace. A tracing configuration conflict can cause issues like: Fragmented traces and orphaned spans. Incomplete Infinite Tracing metrics due to not taking standard trace sampling into account. Discrepancies for metrics like span count, service count, durations, and error count. Confusing search results. For example, for standard tracing spans that send headers to Infinite Tracing-instrumented services, those spans may show in the trace list but not in the trace waterfall view. Missing traces for monitored browser apps and mobile apps. Because Infinite Tracing isn’t yet available for browser or mobile monitoring, spans from these services won’t show up in the trace waterfall when they make requests to Infinite Tracing-enabled services. For traces with a configuration conflict, we’ll display only the Infinite Tracing data in the UI because that data is of higher quality. (All tracing data is queryable via NRQL.)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 260.83084,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infinite</em> <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "sections": "<em>Infinite</em> <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Problem Traces with configuration conflicts are caused when you&#x27;ve enabled <em>Infinite</em> <em>Tracing</em> for one or more services in a <em>trace</em>, but other services in that <em>trace</em> have our standard (non-<em>Infinite</em> <em>Tracing</em>) <em>distributed</em> <em>tracing</em> solutions enabled. You can solve this problem by enabling <em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6072a76664441fe9c09d859a"
    },
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "Tip",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2021-06-14T18:06:43Z",
      "updated_at": "2021-05-05T19:20:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to our Infinite Tracing feature. For an overview of all distributed tracing options, see Enable distributed tracing. Tip To use Infinite Tracing and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing plan: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. To start setting up Infinite Tracing, and to see specific requirements, see the docs for these tools: Our language agents Our integrations for third-party telemetry tools Our Trace API Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 259.42432,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "sections": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " standard <em>distributed</em> <em>tracing</em> options, <em>Infinite</em> <em>Tracing</em> can process more <em>trace</em> data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard <em>tracing</em> feature uses. Resources for learning more about <em>Infinite</em> <em>Tracing</em>: <em>Infinite</em>"
      },
      "id": "6072a6a4196a67faa964a788"
    }
  ],
  "/docs/distributed-tracing/infinite-tracing/infinite-tracing-configure-trace-observer-monitoring": [
    {
      "sections": [
        "Trace API general requirements and limits",
        "Endpoints",
        "Data formats",
        "Data limits",
        "Restricted attributes",
        "Request metadata (headers and query parameters)",
        "Important",
        "Response validation",
        "See HTTP status codes",
        "Exceeding span limits"
      ],
      "title": "Trace API general requirements and limits ",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "f77504082dae8374e0c7009a31abebbd4c0123f3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/trace-api-general-requirements-limits/",
      "published_at": "2021-06-14T18:07:42Z",
      "updated_at": "2021-06-09T00:57:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Information about Trace API data requirements, including: Data specifications and max limits Required metadata (headers, query parameters) Response validation details This document applies to the Trace API overall. For rules regarding specific data formats, see: New Relic-format trace data Zipkin-format trace data Endpoints All trace data is sent via a POST to a Trace API endpoint. We have a few endpoints, depending on your setup: Default Trace API endpoint: https://trace-api.newrelic.com/trace/v1 EU data centers: https://trace-api.eu.newrelic.com/trace/v1 (see other EU endpoints). Infinite Tracing: when you complete the Trace observer setup, you get a custom YOUR_TRACE_OBSERVER_URL value to use as an endpoint. If you're using an integration that uses the Trace API (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust the sampling of your tracing service to send us 100% of spans. For FedRAMP, see FedRAMP endpoints. Data formats Currently, the Trace API accepts two types of data formats: zipkin: For reporting Zipkin trace data. Zipkin data must be Zipkin JSON v2. newrelic: For reporting all other trace data. Data limits Data limits and rules: Condition Limit Max age of span timestamp values 20 minutes. timestamp must be within 20 minutes of current time at ingest, or within 20 minutes from the time the last span with the same trace.id was received by New Relic. Max payload size 1MB (10^6 bytes) (gzip compression supported) Max requests per minute 100K Max spans per minute per account family Dependent on agreement. Max limit: 2M. Max spans per trace 50K Max attributes per span 200 Max span attribute value length 4000 characters Allowed HTTP protocols HTTPS only Cross-account visibility of span details Potential data obfuscation To see an example of how span limits are enforced, see Exceeding limits. Restricted attributes The attributes in the table below are restricted in the newrelic-format JSON (in the attributes block) and in the zipkin-format JSON (in the tags block). Any values with these keys will be omitted: Restricted attribute Description entityGuid string Unique identifier for the entity that created this span. Generated from service.name, if available. guid string Used for backwards compatibility with data from APM agents. The attributes in the table below are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Restricted attribute description entity.guid string Unique identifier for the entity associated with this span. entity.name string Human-readable name of an entity, often used to identify an entity in the UI. entity.type string Used to differentiate between different types of entities, like hosts, applications, etc. Request metadata (headers and query parameters) The following table shows the required request metadata for all trace data formats. This metadata can be sent as HTTP headers on an ingest request or, in some cases, provided as query parameters, which may be required for tracing frameworks that don't allow header modification. Important Security note: We suggest using headers because query parameters are present in the URL and may be logged before being encrypted and received by New Relic. All data sent as query parameters must be URL-safe. Header Query param? Details Content-Type No Required. Must be application/json. Content-Length No Required. The length of the request body in octets (8-bit bytes) unless sent with chunked encoding. This header is generally set by default by the underlying HTTP client sending the data and in most cases should not require any additional effort by the end user. Api-Key Yes (case-sensitive) Required. The Trace API requires the Insights insert key. If this is provided as both a header and a query parameter, the values must match. Content-Encoding No Required if compressed payload. The value must be gzip. Data-Format Yes Required for zipkin. Optional for newrelic. If present, Data-Format-Version must also be present. Data-Format-Version Yes Required for zipkin. If present, Data-Format must also be present. There are only two possible pairings for these values: If Data-Format is zipkin, Data-Format-Version must be 2. If Data-Format is newrelic, Data-Format-Version must be 1. x-request-id No Optional - Reserved for future use. The value must be a valid UUID4. The value is expected to be unique for each request. Response validation A response for successfully sending trace data will include a requestId. For example: {\"requestId\":\"c1bb62fc-001a-b000-0000-016bb152e1bb\"} Copy There are two ways success/errors are signaled: HTTP status code (synchronous). Authentication and request errors will be signaled via HTTP status code. See HTTP status codes Code Meaning 202 Data accepted. This means that you've passed preliminary checks, but is not a guarantee that the data has been successfully parsed and indexed as part of a distributed trace. 400 The structure of the request was invalid. Errors with query parameters, etc. 403 Authentication error. May occur with an invalid license key or if you lack necessary entitlement to use the Trace API. 404 The request path is incorrect. 405 For any request method other than POST. 408 The request took too long to reach the endpoint. 411 The Content-Length header wasn’t included. 413 The payload was too big. 414 The request URI was too long. 415 The Content-Type or Content-Encoding was invalid. 429 The request rate quota has been exceeded. 431 The request headers are too long. 5xx There was a server error (please retry). NrIntegrationError events (asynchronous). Errors with the JSON payload or other semantic errors are asynchronously signaled via NrIntegrationError events that are stored in the account whose license key is associated with the request. For all errors of this type, the attribute newRelicFeature will be Distributed Tracing and requestId will be the requestId from the endpoint response. If you receive a 202 response and don't see an NrIntegrationError event, your data should be visible in New Relic One's global distributed tracing UI in about a minute. You should be able to find the trace using a standard trace search like: traceId = TRACE_ID_SENT Copy Exceeding span limits When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate limit messages with this NRQL: SELECT * FROM NrIntegrationError WHERE newRelicFeature = 'Distributed Tracing' AND category = 'RateLimit' AND rateLimitType = 'SpansPerMinute' Copy To get a notification when you exceed the limit, you can set up a NRQL alert. We calculate a rolling 10-minute average based on your span rate limit. This allows for temporary rate bursts, and lets us prioritize keeping and dropping complete traces instead of indiscriminately dropping spans on a per minute limit basis. In the example below of exceeding the rate, the rate limit is the default 100,000 spans per minute. New Relic allows a burst above 100K for a couple of minutes without downsampling, because the remaining minutes in the 10-minute window averaged under 100K spans/minute. For the previous 10 minutes (8:50 - 9:00) the service received 60,000 spans/minute. Minute Spans sent to API Total for past 10 minutes 8:59 60,000 600,000 9:00 40,000 580,000 9:01 50,000 570,000 9:02 250,000 760,000 9:03 220,000 920,000 9:04 125,000 985,000 9:05 70,000 995,000 9:06 50,000 985,000 9:07 40,000 965,000 9:08 40,000 945,000 9:09 40,000 925,000",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 262.45337,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Trace</em> API general requirements and limits ",
        "sections": "<em>Trace</em> API general requirements and limits",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " be visible in New Relic One&#x27;s global <em>distributed</em> <em>tracing</em> UI in about a minute. You should be able to find the <em>trace</em> using a standard <em>trace</em> search like: <em>trace</em>Id = <em>TRACE</em>_ID_SENT Copy Exceeding span limits When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate"
      },
      "id": "6071cf7628ccbcf8b851c158"
    },
    {
      "sections": [
        "Infinite Tracing: trace configuration conflicts",
        "Problem"
      ],
      "title": "Infinite Tracing: trace configuration conflicts",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Troubleshooting"
      ],
      "external_id": "b5f9f72d5adf410a972ef089484d53ffa355aa65",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/troubleshooting/infinite-tracing-trace-configuration-conflicts/",
      "published_at": "2021-06-14T19:08:49Z",
      "updated_at": "2021-04-11T07:38:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Traces with configuration conflicts are caused when you've enabled Infinite Tracing for one or more services in a trace, but other services in that trace have our standard (non-Infinite Tracing) distributed tracing solutions enabled. You can solve this problem by enabling Infinite Tracing for all services in a trace. A tracing configuration conflict can cause issues like: Fragmented traces and orphaned spans. Incomplete Infinite Tracing metrics due to not taking standard trace sampling into account. Discrepancies for metrics like span count, service count, durations, and error count. Confusing search results. For example, for standard tracing spans that send headers to Infinite Tracing-instrumented services, those spans may show in the trace list but not in the trace waterfall view. Missing traces for monitored browser apps and mobile apps. Because Infinite Tracing isn’t yet available for browser or mobile monitoring, spans from these services won’t show up in the trace waterfall when they make requests to Infinite Tracing-enabled services. For traces with a configuration conflict, we’ll display only the Infinite Tracing data in the UI because that data is of higher quality. (All tracing data is queryable via NRQL.)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 260.83084,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infinite</em> <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "sections": "<em>Infinite</em> <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Problem Traces with configuration conflicts are caused when you&#x27;ve enabled <em>Infinite</em> <em>Tracing</em> for one or more services in a <em>trace</em>, but other services in that <em>trace</em> have our standard (non-<em>Infinite</em> <em>Tracing</em>) <em>distributed</em> <em>tracing</em> solutions enabled. You can solve this problem by enabling <em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6072a76664441fe9c09d859a"
    },
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "Tip",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2021-06-14T18:06:43Z",
      "updated_at": "2021-05-05T19:20:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to our Infinite Tracing feature. For an overview of all distributed tracing options, see Enable distributed tracing. Tip To use Infinite Tracing and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing plan: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. To start setting up Infinite Tracing, and to see specific requirements, see the docs for these tools: Our language agents Our integrations for third-party telemetry tools Our Trace API Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 259.42432,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "sections": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " standard <em>distributed</em> <em>tracing</em> options, <em>Infinite</em> <em>Tracing</em> can process more <em>trace</em> data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard <em>tracing</em> feature uses. Resources for learning more about <em>Infinite</em> <em>Tracing</em>: <em>Infinite</em>"
      },
      "id": "6072a6a4196a67faa964a788"
    }
  ],
  "/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing": [
    {
      "sections": [
        "Trace API general requirements and limits",
        "Endpoints",
        "Data formats",
        "Data limits",
        "Restricted attributes",
        "Request metadata (headers and query parameters)",
        "Important",
        "Response validation",
        "See HTTP status codes",
        "Exceeding span limits"
      ],
      "title": "Trace API general requirements and limits ",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "f77504082dae8374e0c7009a31abebbd4c0123f3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/trace-api-general-requirements-limits/",
      "published_at": "2021-06-14T18:07:42Z",
      "updated_at": "2021-06-09T00:57:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Information about Trace API data requirements, including: Data specifications and max limits Required metadata (headers, query parameters) Response validation details This document applies to the Trace API overall. For rules regarding specific data formats, see: New Relic-format trace data Zipkin-format trace data Endpoints All trace data is sent via a POST to a Trace API endpoint. We have a few endpoints, depending on your setup: Default Trace API endpoint: https://trace-api.newrelic.com/trace/v1 EU data centers: https://trace-api.eu.newrelic.com/trace/v1 (see other EU endpoints). Infinite Tracing: when you complete the Trace observer setup, you get a custom YOUR_TRACE_OBSERVER_URL value to use as an endpoint. If you're using an integration that uses the Trace API (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust the sampling of your tracing service to send us 100% of spans. For FedRAMP, see FedRAMP endpoints. Data formats Currently, the Trace API accepts two types of data formats: zipkin: For reporting Zipkin trace data. Zipkin data must be Zipkin JSON v2. newrelic: For reporting all other trace data. Data limits Data limits and rules: Condition Limit Max age of span timestamp values 20 minutes. timestamp must be within 20 minutes of current time at ingest, or within 20 minutes from the time the last span with the same trace.id was received by New Relic. Max payload size 1MB (10^6 bytes) (gzip compression supported) Max requests per minute 100K Max spans per minute per account family Dependent on agreement. Max limit: 2M. Max spans per trace 50K Max attributes per span 200 Max span attribute value length 4000 characters Allowed HTTP protocols HTTPS only Cross-account visibility of span details Potential data obfuscation To see an example of how span limits are enforced, see Exceeding limits. Restricted attributes The attributes in the table below are restricted in the newrelic-format JSON (in the attributes block) and in the zipkin-format JSON (in the tags block). Any values with these keys will be omitted: Restricted attribute Description entityGuid string Unique identifier for the entity that created this span. Generated from service.name, if available. guid string Used for backwards compatibility with data from APM agents. The attributes in the table below are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Restricted attribute description entity.guid string Unique identifier for the entity associated with this span. entity.name string Human-readable name of an entity, often used to identify an entity in the UI. entity.type string Used to differentiate between different types of entities, like hosts, applications, etc. Request metadata (headers and query parameters) The following table shows the required request metadata for all trace data formats. This metadata can be sent as HTTP headers on an ingest request or, in some cases, provided as query parameters, which may be required for tracing frameworks that don't allow header modification. Important Security note: We suggest using headers because query parameters are present in the URL and may be logged before being encrypted and received by New Relic. All data sent as query parameters must be URL-safe. Header Query param? Details Content-Type No Required. Must be application/json. Content-Length No Required. The length of the request body in octets (8-bit bytes) unless sent with chunked encoding. This header is generally set by default by the underlying HTTP client sending the data and in most cases should not require any additional effort by the end user. Api-Key Yes (case-sensitive) Required. The Trace API requires the Insights insert key. If this is provided as both a header and a query parameter, the values must match. Content-Encoding No Required if compressed payload. The value must be gzip. Data-Format Yes Required for zipkin. Optional for newrelic. If present, Data-Format-Version must also be present. Data-Format-Version Yes Required for zipkin. If present, Data-Format must also be present. There are only two possible pairings for these values: If Data-Format is zipkin, Data-Format-Version must be 2. If Data-Format is newrelic, Data-Format-Version must be 1. x-request-id No Optional - Reserved for future use. The value must be a valid UUID4. The value is expected to be unique for each request. Response validation A response for successfully sending trace data will include a requestId. For example: {\"requestId\":\"c1bb62fc-001a-b000-0000-016bb152e1bb\"} Copy There are two ways success/errors are signaled: HTTP status code (synchronous). Authentication and request errors will be signaled via HTTP status code. See HTTP status codes Code Meaning 202 Data accepted. This means that you've passed preliminary checks, but is not a guarantee that the data has been successfully parsed and indexed as part of a distributed trace. 400 The structure of the request was invalid. Errors with query parameters, etc. 403 Authentication error. May occur with an invalid license key or if you lack necessary entitlement to use the Trace API. 404 The request path is incorrect. 405 For any request method other than POST. 408 The request took too long to reach the endpoint. 411 The Content-Length header wasn’t included. 413 The payload was too big. 414 The request URI was too long. 415 The Content-Type or Content-Encoding was invalid. 429 The request rate quota has been exceeded. 431 The request headers are too long. 5xx There was a server error (please retry). NrIntegrationError events (asynchronous). Errors with the JSON payload or other semantic errors are asynchronously signaled via NrIntegrationError events that are stored in the account whose license key is associated with the request. For all errors of this type, the attribute newRelicFeature will be Distributed Tracing and requestId will be the requestId from the endpoint response. If you receive a 202 response and don't see an NrIntegrationError event, your data should be visible in New Relic One's global distributed tracing UI in about a minute. You should be able to find the trace using a standard trace search like: traceId = TRACE_ID_SENT Copy Exceeding span limits When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate limit messages with this NRQL: SELECT * FROM NrIntegrationError WHERE newRelicFeature = 'Distributed Tracing' AND category = 'RateLimit' AND rateLimitType = 'SpansPerMinute' Copy To get a notification when you exceed the limit, you can set up a NRQL alert. We calculate a rolling 10-minute average based on your span rate limit. This allows for temporary rate bursts, and lets us prioritize keeping and dropping complete traces instead of indiscriminately dropping spans on a per minute limit basis. In the example below of exceeding the rate, the rate limit is the default 100,000 spans per minute. New Relic allows a burst above 100K for a couple of minutes without downsampling, because the remaining minutes in the 10-minute window averaged under 100K spans/minute. For the previous 10 minutes (8:50 - 9:00) the service received 60,000 spans/minute. Minute Spans sent to API Total for past 10 minutes 8:59 60,000 600,000 9:00 40,000 580,000 9:01 50,000 570,000 9:02 250,000 760,000 9:03 220,000 920,000 9:04 125,000 985,000 9:05 70,000 995,000 9:06 50,000 985,000 9:07 40,000 965,000 9:08 40,000 945,000 9:09 40,000 925,000",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 262.45337,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Trace</em> API general requirements and limits ",
        "sections": "<em>Trace</em> API general requirements and limits",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " be visible in New Relic One&#x27;s global <em>distributed</em> <em>tracing</em> UI in about a minute. You should be able to find the <em>trace</em> using a standard <em>trace</em> search like: <em>trace</em>Id = <em>TRACE</em>_ID_SENT Copy Exceeding span limits When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate"
      },
      "id": "6071cf7628ccbcf8b851c158"
    },
    {
      "sections": [
        "Infinite Tracing: trace configuration conflicts",
        "Problem"
      ],
      "title": "Infinite Tracing: trace configuration conflicts",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Troubleshooting"
      ],
      "external_id": "b5f9f72d5adf410a972ef089484d53ffa355aa65",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/troubleshooting/infinite-tracing-trace-configuration-conflicts/",
      "published_at": "2021-06-14T19:08:49Z",
      "updated_at": "2021-04-11T07:38:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Traces with configuration conflicts are caused when you've enabled Infinite Tracing for one or more services in a trace, but other services in that trace have our standard (non-Infinite Tracing) distributed tracing solutions enabled. You can solve this problem by enabling Infinite Tracing for all services in a trace. A tracing configuration conflict can cause issues like: Fragmented traces and orphaned spans. Incomplete Infinite Tracing metrics due to not taking standard trace sampling into account. Discrepancies for metrics like span count, service count, durations, and error count. Confusing search results. For example, for standard tracing spans that send headers to Infinite Tracing-instrumented services, those spans may show in the trace list but not in the trace waterfall view. Missing traces for monitored browser apps and mobile apps. Because Infinite Tracing isn’t yet available for browser or mobile monitoring, spans from these services won’t show up in the trace waterfall when they make requests to Infinite Tracing-enabled services. For traces with a configuration conflict, we’ll display only the Infinite Tracing data in the UI because that data is of higher quality. (All tracing data is queryable via NRQL.)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 260.83084,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infinite</em> <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "sections": "<em>Infinite</em> <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Problem Traces with configuration conflicts are caused when you&#x27;ve enabled <em>Infinite</em> <em>Tracing</em> for one or more services in a <em>trace</em>, but other services in that <em>trace</em> have our standard (non-<em>Infinite</em> <em>Tracing</em>) <em>distributed</em> <em>tracing</em> solutions enabled. You can solve this problem by enabling <em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6072a76664441fe9c09d859a"
    },
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-06-14T18:04:49Z",
      "updated_at": "2021-04-22T06:39:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any New Relic APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: New Relic APM: C New Relic APM: Golang New Relic APM: Java New Relic APM: .NET New Relic APM: Node.js New Relic APM: PHP New Relic APM: Python New Relic APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a New Relic APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever (i.e. -1). For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For best results, update to the latest Ruby agent version. Also install the additional Ruby agent gem for Infinite Tracing. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 6.11.0.365 or higher (includes W3C Trace Context) newrelic-infinite_tracing 6.11.0.375 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 254.85458,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language agents and <em>distributed</em> <em>tracing</em>",
        "sections": "Language agents and <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>tracing</em> UI Query <em>distributed</em> <em>trace</em> data Set up <em>Infinite</em> <em>Tracing</em> (advanced option) Standard <em>distributed</em> <em>tracing</em> for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up <em>Infinite</em> <em>Tracing</em>. This alternative"
      },
      "id": "6072a66564441fb28e9d8595"
    }
  ],
  "/docs/distributed-tracing/infinite-tracing/set-trace-observer": [
    {
      "sections": [
        "Trace API general requirements and limits",
        "Endpoints",
        "Data formats",
        "Data limits",
        "Restricted attributes",
        "Request metadata (headers and query parameters)",
        "Important",
        "Response validation",
        "See HTTP status codes",
        "Exceeding span limits"
      ],
      "title": "Trace API general requirements and limits ",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "f77504082dae8374e0c7009a31abebbd4c0123f3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/trace-api-general-requirements-limits/",
      "published_at": "2021-06-14T18:07:42Z",
      "updated_at": "2021-06-09T00:57:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Information about Trace API data requirements, including: Data specifications and max limits Required metadata (headers, query parameters) Response validation details This document applies to the Trace API overall. For rules regarding specific data formats, see: New Relic-format trace data Zipkin-format trace data Endpoints All trace data is sent via a POST to a Trace API endpoint. We have a few endpoints, depending on your setup: Default Trace API endpoint: https://trace-api.newrelic.com/trace/v1 EU data centers: https://trace-api.eu.newrelic.com/trace/v1 (see other EU endpoints). Infinite Tracing: when you complete the Trace observer setup, you get a custom YOUR_TRACE_OBSERVER_URL value to use as an endpoint. If you're using an integration that uses the Trace API (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust the sampling of your tracing service to send us 100% of spans. For FedRAMP, see FedRAMP endpoints. Data formats Currently, the Trace API accepts two types of data formats: zipkin: For reporting Zipkin trace data. Zipkin data must be Zipkin JSON v2. newrelic: For reporting all other trace data. Data limits Data limits and rules: Condition Limit Max age of span timestamp values 20 minutes. timestamp must be within 20 minutes of current time at ingest, or within 20 minutes from the time the last span with the same trace.id was received by New Relic. Max payload size 1MB (10^6 bytes) (gzip compression supported) Max requests per minute 100K Max spans per minute per account family Dependent on agreement. Max limit: 2M. Max spans per trace 50K Max attributes per span 200 Max span attribute value length 4000 characters Allowed HTTP protocols HTTPS only Cross-account visibility of span details Potential data obfuscation To see an example of how span limits are enforced, see Exceeding limits. Restricted attributes The attributes in the table below are restricted in the newrelic-format JSON (in the attributes block) and in the zipkin-format JSON (in the tags block). Any values with these keys will be omitted: Restricted attribute Description entityGuid string Unique identifier for the entity that created this span. Generated from service.name, if available. guid string Used for backwards compatibility with data from APM agents. The attributes in the table below are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Restricted attribute description entity.guid string Unique identifier for the entity associated with this span. entity.name string Human-readable name of an entity, often used to identify an entity in the UI. entity.type string Used to differentiate between different types of entities, like hosts, applications, etc. Request metadata (headers and query parameters) The following table shows the required request metadata for all trace data formats. This metadata can be sent as HTTP headers on an ingest request or, in some cases, provided as query parameters, which may be required for tracing frameworks that don't allow header modification. Important Security note: We suggest using headers because query parameters are present in the URL and may be logged before being encrypted and received by New Relic. All data sent as query parameters must be URL-safe. Header Query param? Details Content-Type No Required. Must be application/json. Content-Length No Required. The length of the request body in octets (8-bit bytes) unless sent with chunked encoding. This header is generally set by default by the underlying HTTP client sending the data and in most cases should not require any additional effort by the end user. Api-Key Yes (case-sensitive) Required. The Trace API requires the Insights insert key. If this is provided as both a header and a query parameter, the values must match. Content-Encoding No Required if compressed payload. The value must be gzip. Data-Format Yes Required for zipkin. Optional for newrelic. If present, Data-Format-Version must also be present. Data-Format-Version Yes Required for zipkin. If present, Data-Format must also be present. There are only two possible pairings for these values: If Data-Format is zipkin, Data-Format-Version must be 2. If Data-Format is newrelic, Data-Format-Version must be 1. x-request-id No Optional - Reserved for future use. The value must be a valid UUID4. The value is expected to be unique for each request. Response validation A response for successfully sending trace data will include a requestId. For example: {\"requestId\":\"c1bb62fc-001a-b000-0000-016bb152e1bb\"} Copy There are two ways success/errors are signaled: HTTP status code (synchronous). Authentication and request errors will be signaled via HTTP status code. See HTTP status codes Code Meaning 202 Data accepted. This means that you've passed preliminary checks, but is not a guarantee that the data has been successfully parsed and indexed as part of a distributed trace. 400 The structure of the request was invalid. Errors with query parameters, etc. 403 Authentication error. May occur with an invalid license key or if you lack necessary entitlement to use the Trace API. 404 The request path is incorrect. 405 For any request method other than POST. 408 The request took too long to reach the endpoint. 411 The Content-Length header wasn’t included. 413 The payload was too big. 414 The request URI was too long. 415 The Content-Type or Content-Encoding was invalid. 429 The request rate quota has been exceeded. 431 The request headers are too long. 5xx There was a server error (please retry). NrIntegrationError events (asynchronous). Errors with the JSON payload or other semantic errors are asynchronously signaled via NrIntegrationError events that are stored in the account whose license key is associated with the request. For all errors of this type, the attribute newRelicFeature will be Distributed Tracing and requestId will be the requestId from the endpoint response. If you receive a 202 response and don't see an NrIntegrationError event, your data should be visible in New Relic One's global distributed tracing UI in about a minute. You should be able to find the trace using a standard trace search like: traceId = TRACE_ID_SENT Copy Exceeding span limits When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate limit messages with this NRQL: SELECT * FROM NrIntegrationError WHERE newRelicFeature = 'Distributed Tracing' AND category = 'RateLimit' AND rateLimitType = 'SpansPerMinute' Copy To get a notification when you exceed the limit, you can set up a NRQL alert. We calculate a rolling 10-minute average based on your span rate limit. This allows for temporary rate bursts, and lets us prioritize keeping and dropping complete traces instead of indiscriminately dropping spans on a per minute limit basis. In the example below of exceeding the rate, the rate limit is the default 100,000 spans per minute. New Relic allows a burst above 100K for a couple of minutes without downsampling, because the remaining minutes in the 10-minute window averaged under 100K spans/minute. For the previous 10 minutes (8:50 - 9:00) the service received 60,000 spans/minute. Minute Spans sent to API Total for past 10 minutes 8:59 60,000 600,000 9:00 40,000 580,000 9:01 50,000 570,000 9:02 250,000 760,000 9:03 220,000 920,000 9:04 125,000 985,000 9:05 70,000 995,000 9:06 50,000 985,000 9:07 40,000 965,000 9:08 40,000 945,000 9:09 40,000 925,000",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 262.45328,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Trace</em> API general requirements and limits ",
        "sections": "<em>Trace</em> API general requirements and limits",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " be visible in New Relic One&#x27;s global <em>distributed</em> <em>tracing</em> UI in about a minute. You should be able to find the <em>trace</em> using a standard <em>trace</em> search like: <em>trace</em>Id = <em>TRACE</em>_ID_SENT Copy Exceeding span limits When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate"
      },
      "id": "6071cf7628ccbcf8b851c158"
    },
    {
      "sections": [
        "Infinite Tracing: trace configuration conflicts",
        "Problem"
      ],
      "title": "Infinite Tracing: trace configuration conflicts",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Troubleshooting"
      ],
      "external_id": "b5f9f72d5adf410a972ef089484d53ffa355aa65",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/troubleshooting/infinite-tracing-trace-configuration-conflicts/",
      "published_at": "2021-06-14T19:08:49Z",
      "updated_at": "2021-04-11T07:38:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Traces with configuration conflicts are caused when you've enabled Infinite Tracing for one or more services in a trace, but other services in that trace have our standard (non-Infinite Tracing) distributed tracing solutions enabled. You can solve this problem by enabling Infinite Tracing for all services in a trace. A tracing configuration conflict can cause issues like: Fragmented traces and orphaned spans. Incomplete Infinite Tracing metrics due to not taking standard trace sampling into account. Discrepancies for metrics like span count, service count, durations, and error count. Confusing search results. For example, for standard tracing spans that send headers to Infinite Tracing-instrumented services, those spans may show in the trace list but not in the trace waterfall view. Missing traces for monitored browser apps and mobile apps. Because Infinite Tracing isn’t yet available for browser or mobile monitoring, spans from these services won’t show up in the trace waterfall when they make requests to Infinite Tracing-enabled services. For traces with a configuration conflict, we’ll display only the Infinite Tracing data in the UI because that data is of higher quality. (All tracing data is queryable via NRQL.)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 260.83084,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infinite</em> <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "sections": "<em>Infinite</em> <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Problem Traces with configuration conflicts are caused when you&#x27;ve enabled <em>Infinite</em> <em>Tracing</em> for one or more services in a <em>trace</em>, but other services in that <em>trace</em> have our standard (non-<em>Infinite</em> <em>Tracing</em>) <em>distributed</em> <em>tracing</em> solutions enabled. You can solve this problem by enabling <em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6072a76664441fe9c09d859a"
    },
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "Tip",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2021-06-14T18:06:43Z",
      "updated_at": "2021-05-05T19:20:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to our Infinite Tracing feature. For an overview of all distributed tracing options, see Enable distributed tracing. Tip To use Infinite Tracing and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing plan: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. To start setting up Infinite Tracing, and to see specific requirements, see the docs for these tools: Our language agents Our integrations for third-party telemetry tools Our Trace API Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 259.42432,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "sections": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " standard <em>distributed</em> <em>tracing</em> options, <em>Infinite</em> <em>Tracing</em> can process more <em>trace</em> data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard <em>tracing</em> feature uses. Resources for learning more about <em>Infinite</em> <em>Tracing</em>: <em>Infinite</em>"
      },
      "id": "6072a6a4196a67faa964a788"
    }
  ],
  "/docs/distributed-tracing/other-requirements/infinite-tracing-configuring-ssl-java-7-8": [
    {
      "sections": [
        "Trace API general requirements and limits",
        "Endpoints",
        "Data formats",
        "Data limits",
        "Restricted attributes",
        "Request metadata (headers and query parameters)",
        "Important",
        "Response validation",
        "See HTTP status codes",
        "Exceeding span limits"
      ],
      "title": "Trace API general requirements and limits ",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "f77504082dae8374e0c7009a31abebbd4c0123f3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/trace-api-general-requirements-limits/",
      "published_at": "2021-06-14T18:07:42Z",
      "updated_at": "2021-06-09T00:57:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Information about Trace API data requirements, including: Data specifications and max limits Required metadata (headers, query parameters) Response validation details This document applies to the Trace API overall. For rules regarding specific data formats, see: New Relic-format trace data Zipkin-format trace data Endpoints All trace data is sent via a POST to a Trace API endpoint. We have a few endpoints, depending on your setup: Default Trace API endpoint: https://trace-api.newrelic.com/trace/v1 EU data centers: https://trace-api.eu.newrelic.com/trace/v1 (see other EU endpoints). Infinite Tracing: when you complete the Trace observer setup, you get a custom YOUR_TRACE_OBSERVER_URL value to use as an endpoint. If you're using an integration that uses the Trace API (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust the sampling of your tracing service to send us 100% of spans. For FedRAMP, see FedRAMP endpoints. Data formats Currently, the Trace API accepts two types of data formats: zipkin: For reporting Zipkin trace data. Zipkin data must be Zipkin JSON v2. newrelic: For reporting all other trace data. Data limits Data limits and rules: Condition Limit Max age of span timestamp values 20 minutes. timestamp must be within 20 minutes of current time at ingest, or within 20 minutes from the time the last span with the same trace.id was received by New Relic. Max payload size 1MB (10^6 bytes) (gzip compression supported) Max requests per minute 100K Max spans per minute per account family Dependent on agreement. Max limit: 2M. Max spans per trace 50K Max attributes per span 200 Max span attribute value length 4000 characters Allowed HTTP protocols HTTPS only Cross-account visibility of span details Potential data obfuscation To see an example of how span limits are enforced, see Exceeding limits. Restricted attributes The attributes in the table below are restricted in the newrelic-format JSON (in the attributes block) and in the zipkin-format JSON (in the tags block). Any values with these keys will be omitted: Restricted attribute Description entityGuid string Unique identifier for the entity that created this span. Generated from service.name, if available. guid string Used for backwards compatibility with data from APM agents. The attributes in the table below are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Restricted attribute description entity.guid string Unique identifier for the entity associated with this span. entity.name string Human-readable name of an entity, often used to identify an entity in the UI. entity.type string Used to differentiate between different types of entities, like hosts, applications, etc. Request metadata (headers and query parameters) The following table shows the required request metadata for all trace data formats. This metadata can be sent as HTTP headers on an ingest request or, in some cases, provided as query parameters, which may be required for tracing frameworks that don't allow header modification. Important Security note: We suggest using headers because query parameters are present in the URL and may be logged before being encrypted and received by New Relic. All data sent as query parameters must be URL-safe. Header Query param? Details Content-Type No Required. Must be application/json. Content-Length No Required. The length of the request body in octets (8-bit bytes) unless sent with chunked encoding. This header is generally set by default by the underlying HTTP client sending the data and in most cases should not require any additional effort by the end user. Api-Key Yes (case-sensitive) Required. The Trace API requires the Insights insert key. If this is provided as both a header and a query parameter, the values must match. Content-Encoding No Required if compressed payload. The value must be gzip. Data-Format Yes Required for zipkin. Optional for newrelic. If present, Data-Format-Version must also be present. Data-Format-Version Yes Required for zipkin. If present, Data-Format must also be present. There are only two possible pairings for these values: If Data-Format is zipkin, Data-Format-Version must be 2. If Data-Format is newrelic, Data-Format-Version must be 1. x-request-id No Optional - Reserved for future use. The value must be a valid UUID4. The value is expected to be unique for each request. Response validation A response for successfully sending trace data will include a requestId. For example: {\"requestId\":\"c1bb62fc-001a-b000-0000-016bb152e1bb\"} Copy There are two ways success/errors are signaled: HTTP status code (synchronous). Authentication and request errors will be signaled via HTTP status code. See HTTP status codes Code Meaning 202 Data accepted. This means that you've passed preliminary checks, but is not a guarantee that the data has been successfully parsed and indexed as part of a distributed trace. 400 The structure of the request was invalid. Errors with query parameters, etc. 403 Authentication error. May occur with an invalid license key or if you lack necessary entitlement to use the Trace API. 404 The request path is incorrect. 405 For any request method other than POST. 408 The request took too long to reach the endpoint. 411 The Content-Length header wasn’t included. 413 The payload was too big. 414 The request URI was too long. 415 The Content-Type or Content-Encoding was invalid. 429 The request rate quota has been exceeded. 431 The request headers are too long. 5xx There was a server error (please retry). NrIntegrationError events (asynchronous). Errors with the JSON payload or other semantic errors are asynchronously signaled via NrIntegrationError events that are stored in the account whose license key is associated with the request. For all errors of this type, the attribute newRelicFeature will be Distributed Tracing and requestId will be the requestId from the endpoint response. If you receive a 202 response and don't see an NrIntegrationError event, your data should be visible in New Relic One's global distributed tracing UI in about a minute. You should be able to find the trace using a standard trace search like: traceId = TRACE_ID_SENT Copy Exceeding span limits When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate limit messages with this NRQL: SELECT * FROM NrIntegrationError WHERE newRelicFeature = 'Distributed Tracing' AND category = 'RateLimit' AND rateLimitType = 'SpansPerMinute' Copy To get a notification when you exceed the limit, you can set up a NRQL alert. We calculate a rolling 10-minute average based on your span rate limit. This allows for temporary rate bursts, and lets us prioritize keeping and dropping complete traces instead of indiscriminately dropping spans on a per minute limit basis. In the example below of exceeding the rate, the rate limit is the default 100,000 spans per minute. New Relic allows a burst above 100K for a couple of minutes without downsampling, because the remaining minutes in the 10-minute window averaged under 100K spans/minute. For the previous 10 minutes (8:50 - 9:00) the service received 60,000 spans/minute. Minute Spans sent to API Total for past 10 minutes 8:59 60,000 600,000 9:00 40,000 580,000 9:01 50,000 570,000 9:02 250,000 760,000 9:03 220,000 920,000 9:04 125,000 985,000 9:05 70,000 995,000 9:06 50,000 985,000 9:07 40,000 965,000 9:08 40,000 945,000 9:09 40,000 925,000",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 262.45328,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Trace</em> API general requirements and limits ",
        "sections": "<em>Trace</em> API general requirements and limits",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " be visible in New Relic One&#x27;s global <em>distributed</em> <em>tracing</em> UI in about a minute. You should be able to find the <em>trace</em> using a standard <em>trace</em> search like: <em>trace</em>Id = <em>TRACE</em>_ID_SENT Copy Exceeding span limits When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate"
      },
      "id": "6071cf7628ccbcf8b851c158"
    },
    {
      "sections": [
        "Infinite Tracing: trace configuration conflicts",
        "Problem"
      ],
      "title": "Infinite Tracing: trace configuration conflicts",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Troubleshooting"
      ],
      "external_id": "b5f9f72d5adf410a972ef089484d53ffa355aa65",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/troubleshooting/infinite-tracing-trace-configuration-conflicts/",
      "published_at": "2021-06-14T19:08:49Z",
      "updated_at": "2021-04-11T07:38:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Traces with configuration conflicts are caused when you've enabled Infinite Tracing for one or more services in a trace, but other services in that trace have our standard (non-Infinite Tracing) distributed tracing solutions enabled. You can solve this problem by enabling Infinite Tracing for all services in a trace. A tracing configuration conflict can cause issues like: Fragmented traces and orphaned spans. Incomplete Infinite Tracing metrics due to not taking standard trace sampling into account. Discrepancies for metrics like span count, service count, durations, and error count. Confusing search results. For example, for standard tracing spans that send headers to Infinite Tracing-instrumented services, those spans may show in the trace list but not in the trace waterfall view. Missing traces for monitored browser apps and mobile apps. Because Infinite Tracing isn’t yet available for browser or mobile monitoring, spans from these services won’t show up in the trace waterfall when they make requests to Infinite Tracing-enabled services. For traces with a configuration conflict, we’ll display only the Infinite Tracing data in the UI because that data is of higher quality. (All tracing data is queryable via NRQL.)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 260.83084,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infinite</em> <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "sections": "<em>Infinite</em> <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Problem Traces with configuration conflicts are caused when you&#x27;ve enabled <em>Infinite</em> <em>Tracing</em> for one or more services in a <em>trace</em>, but other services in that <em>trace</em> have our standard (non-<em>Infinite</em> <em>Tracing</em>) <em>distributed</em> <em>tracing</em> solutions enabled. You can solve this problem by enabling <em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6072a76664441fe9c09d859a"
    },
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "Tip",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2021-06-14T18:06:43Z",
      "updated_at": "2021-05-05T19:20:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to our Infinite Tracing feature. For an overview of all distributed tracing options, see Enable distributed tracing. Tip To use Infinite Tracing and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing plan: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. To start setting up Infinite Tracing, and to see specific requirements, see the docs for these tools: Our language agents Our integrations for third-party telemetry tools Our Trace API Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 259.42432,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "sections": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " standard <em>distributed</em> <em>tracing</em> options, <em>Infinite</em> <em>Tracing</em> can process more <em>trace</em> data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard <em>tracing</em> feature uses. Resources for learning more about <em>Infinite</em> <em>Tracing</em>: <em>Infinite</em>"
      },
      "id": "6072a6a4196a67faa964a788"
    }
  ],
  "/docs/distributed-tracing/trace-api/introduction-trace-api": [
    {
      "sections": [
        "Trace API general requirements and limits",
        "Endpoints",
        "Data formats",
        "Data limits",
        "Restricted attributes",
        "Request metadata (headers and query parameters)",
        "Important",
        "Response validation",
        "See HTTP status codes",
        "Exceeding span limits"
      ],
      "title": "Trace API general requirements and limits ",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "f77504082dae8374e0c7009a31abebbd4c0123f3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/trace-api-general-requirements-limits/",
      "published_at": "2021-06-14T18:07:42Z",
      "updated_at": "2021-06-09T00:57:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Information about Trace API data requirements, including: Data specifications and max limits Required metadata (headers, query parameters) Response validation details This document applies to the Trace API overall. For rules regarding specific data formats, see: New Relic-format trace data Zipkin-format trace data Endpoints All trace data is sent via a POST to a Trace API endpoint. We have a few endpoints, depending on your setup: Default Trace API endpoint: https://trace-api.newrelic.com/trace/v1 EU data centers: https://trace-api.eu.newrelic.com/trace/v1 (see other EU endpoints). Infinite Tracing: when you complete the Trace observer setup, you get a custom YOUR_TRACE_OBSERVER_URL value to use as an endpoint. If you're using an integration that uses the Trace API (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust the sampling of your tracing service to send us 100% of spans. For FedRAMP, see FedRAMP endpoints. Data formats Currently, the Trace API accepts two types of data formats: zipkin: For reporting Zipkin trace data. Zipkin data must be Zipkin JSON v2. newrelic: For reporting all other trace data. Data limits Data limits and rules: Condition Limit Max age of span timestamp values 20 minutes. timestamp must be within 20 minutes of current time at ingest, or within 20 minutes from the time the last span with the same trace.id was received by New Relic. Max payload size 1MB (10^6 bytes) (gzip compression supported) Max requests per minute 100K Max spans per minute per account family Dependent on agreement. Max limit: 2M. Max spans per trace 50K Max attributes per span 200 Max span attribute value length 4000 characters Allowed HTTP protocols HTTPS only Cross-account visibility of span details Potential data obfuscation To see an example of how span limits are enforced, see Exceeding limits. Restricted attributes The attributes in the table below are restricted in the newrelic-format JSON (in the attributes block) and in the zipkin-format JSON (in the tags block). Any values with these keys will be omitted: Restricted attribute Description entityGuid string Unique identifier for the entity that created this span. Generated from service.name, if available. guid string Used for backwards compatibility with data from APM agents. The attributes in the table below are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Restricted attribute description entity.guid string Unique identifier for the entity associated with this span. entity.name string Human-readable name of an entity, often used to identify an entity in the UI. entity.type string Used to differentiate between different types of entities, like hosts, applications, etc. Request metadata (headers and query parameters) The following table shows the required request metadata for all trace data formats. This metadata can be sent as HTTP headers on an ingest request or, in some cases, provided as query parameters, which may be required for tracing frameworks that don't allow header modification. Important Security note: We suggest using headers because query parameters are present in the URL and may be logged before being encrypted and received by New Relic. All data sent as query parameters must be URL-safe. Header Query param? Details Content-Type No Required. Must be application/json. Content-Length No Required. The length of the request body in octets (8-bit bytes) unless sent with chunked encoding. This header is generally set by default by the underlying HTTP client sending the data and in most cases should not require any additional effort by the end user. Api-Key Yes (case-sensitive) Required. The Trace API requires the Insights insert key. If this is provided as both a header and a query parameter, the values must match. Content-Encoding No Required if compressed payload. The value must be gzip. Data-Format Yes Required for zipkin. Optional for newrelic. If present, Data-Format-Version must also be present. Data-Format-Version Yes Required for zipkin. If present, Data-Format must also be present. There are only two possible pairings for these values: If Data-Format is zipkin, Data-Format-Version must be 2. If Data-Format is newrelic, Data-Format-Version must be 1. x-request-id No Optional - Reserved for future use. The value must be a valid UUID4. The value is expected to be unique for each request. Response validation A response for successfully sending trace data will include a requestId. For example: {\"requestId\":\"c1bb62fc-001a-b000-0000-016bb152e1bb\"} Copy There are two ways success/errors are signaled: HTTP status code (synchronous). Authentication and request errors will be signaled via HTTP status code. See HTTP status codes Code Meaning 202 Data accepted. This means that you've passed preliminary checks, but is not a guarantee that the data has been successfully parsed and indexed as part of a distributed trace. 400 The structure of the request was invalid. Errors with query parameters, etc. 403 Authentication error. May occur with an invalid license key or if you lack necessary entitlement to use the Trace API. 404 The request path is incorrect. 405 For any request method other than POST. 408 The request took too long to reach the endpoint. 411 The Content-Length header wasn’t included. 413 The payload was too big. 414 The request URI was too long. 415 The Content-Type or Content-Encoding was invalid. 429 The request rate quota has been exceeded. 431 The request headers are too long. 5xx There was a server error (please retry). NrIntegrationError events (asynchronous). Errors with the JSON payload or other semantic errors are asynchronously signaled via NrIntegrationError events that are stored in the account whose license key is associated with the request. For all errors of this type, the attribute newRelicFeature will be Distributed Tracing and requestId will be the requestId from the endpoint response. If you receive a 202 response and don't see an NrIntegrationError event, your data should be visible in New Relic One's global distributed tracing UI in about a minute. You should be able to find the trace using a standard trace search like: traceId = TRACE_ID_SENT Copy Exceeding span limits When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate limit messages with this NRQL: SELECT * FROM NrIntegrationError WHERE newRelicFeature = 'Distributed Tracing' AND category = 'RateLimit' AND rateLimitType = 'SpansPerMinute' Copy To get a notification when you exceed the limit, you can set up a NRQL alert. We calculate a rolling 10-minute average based on your span rate limit. This allows for temporary rate bursts, and lets us prioritize keeping and dropping complete traces instead of indiscriminately dropping spans on a per minute limit basis. In the example below of exceeding the rate, the rate limit is the default 100,000 spans per minute. New Relic allows a burst above 100K for a couple of minutes without downsampling, because the remaining minutes in the 10-minute window averaged under 100K spans/minute. For the previous 10 minutes (8:50 - 9:00) the service received 60,000 spans/minute. Minute Spans sent to API Total for past 10 minutes 8:59 60,000 600,000 9:00 40,000 580,000 9:01 50,000 570,000 9:02 250,000 760,000 9:03 220,000 920,000 9:04 125,000 985,000 9:05 70,000 995,000 9:06 50,000 985,000 9:07 40,000 965,000 9:08 40,000 945,000 9:09 40,000 925,000",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 289.51443,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Trace</em> <em>API</em> general requirements and limits ",
        "sections": "<em>Trace</em> <em>API</em> general requirements and limits",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>Tracing</em>: when you complete the <em>Trace</em> observer setup, you get a custom YOUR_<em>TRACE</em>_OBSERVER_URL value to use as an endpoint. If you&#x27;re using an integration that uses the <em>Trace</em> <em>API</em> (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust"
      },
      "id": "6071cf7628ccbcf8b851c158"
    },
    {
      "sections": [
        "Report Zipkin-format traces via Trace API",
        "Zipkin version requirements",
        "Overview of using the Trace API",
        "Send sample Zipkin trace payload",
        "Send Zipkin-format payload",
        "Send data from existing Zipkin instrumentation",
        "Transformation of Zipkin data",
        "Add other tags/attributes"
      ],
      "title": "Report Zipkin-format traces via Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "dba8334d1f068236c741ff04c13ecc2be2c184fc",
      "image": "https://docs.newrelic.com/static/96e69137f0dd86b313ec72d5f0c1ad83/119c7/Screen-Shot-2020-08-13-at-1.26.17-PM.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/report-zipkin-format-traces-trace-api/",
      "published_at": "2021-06-14T18:07:42Z",
      "updated_at": "2021-04-10T16:18:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you want to create your own tracing implementation, you can use our Trace API. This doc explains how to send Zipkin-format trace data to our Trace API. (For our general data format, see New Relic format.) Zipkin version requirements The Trace API supports data from Zipkin JSON v2 (or higher) without any modification. For details on this version, see Zipkin v2 release details and the Zipkin v2 schema. Overview of using the Trace API Using our Trace API is as simple as: Sending trace data in the expected format (in this case, zipkin format). Sending that data to the appropriate endpoint Our send-data instructions have options for enabling Infinite Tracing. To learn more about this, see Intro to Infinite Tracing and Sampling considerations. To get started using the Trace API, choose an option: Send a sample trace: This shows a curl example of sending a trace to New Relic. This is useful for understanding how the Trace API works, and to verify you're seeing data in New Relic. Report data from existing Zipkin instrumentation: if you have an existing Zipkin implementation, you can simply change the endpoint of where your data gets sent. Send sample Zipkin trace payload This section describes how to send a simple Zipkin-format trace to our Trace API via curl request. You might choose to do this in order to learn how our API works and to verify that data is showing up in New Relic before doing in-depth instrumentation. To get started sending a sample payload: (Optional, to enable Infinite Tracing) First, you must set up a trace observer. That procedure includes instructions for sending a sample trace using our general new-relic format. When you get to that step, return here to instead learn how to send a Zipkin-format trace. Send a Zipkin-format payload following the instructions below. Send Zipkin-format payload To send a sample Zipkin-format trace: Get an Insights insert key: Go to the API keys UI and select Insights insert keys. If you don't already have a key, create a new one by selecting Insert keys +. You'll be executing a curl request, below. Notes on this: Replace the insert key placeholder with your insert key. If you're using Infinite Tracing, use the YOUR_TRACE_OBSERVER_URL value in place of the standard endpoint. If you want to send more than one post, change the trace ID to a different value. Sending the same payload or span id multiple times for the same traceId may result in fragmented traces in the UI. curl -i -H 'Content-Type: application/json' \\ -H 'Api-Key: $NEW_RELIC_INSERT_KEY' \\ -H 'Data-Format: zipkin' \\ -H 'Data-Format-Version: 2' \\ -X POST \\ -d '[ { \"traceId\": \"test-zipkin-trace-id-1\", \"id\": \"3e0f5885710776cd\", \"kind\": \"CLIENT\", \"name\": \"post\", \"duration\": 508068, \"localEndpoint\": { \"serviceName\": \"service-1\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { } }, { \"traceId\": \"test-zipkin-trace-id-1\", \"parentId\": \"3e0f5885710776cd\", \"id\": \"asdf9asdn123lkasdf\", \"kind\": \"CLIENT\", \"name\": \"service 2 span\", \"duration\": 2019, \"localEndpoint\": { \"serviceName\": \"service-2\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"error.message\": \"Invalid credentials\" } } ]' 'https://trace-api.newrelic.com/trace/v1' Copy Within a minute, the trace should be available in the our distributed tracing UI. To find it, run a query for the trace.id. In this example, it was test-zipkin-trace-id-1. Note that you search by the transformed attribute of trace.id (not traceId). To learn more: Learn where Trace API data shows up in the UI. Send data from an existing Zipkin instrumentation. Learn how to decorate spans by adding tags. This helps you customize how traces are displayed in our UI for a richer, more helpful experience. Learn about general endpoint information (data limits, required metadata, and response validation). Learn about how Zipkin data is transformed and stored in our format. If you don't see your trace data, see Troubleshooting. Send data from existing Zipkin instrumentation Preliminary notes: If you want to enable Infinite Tracing, you first must set up a trace observer. It can be helpful to first send a sample payload to verify things are working properly. To report data from an existing Zipkin instrumentation, you'll point the Zipkin tracer at the appropriate Trace API endpoint with some required request metadata. You can send the required metadata as headers or query parameters (some Zipkin tracer versions don't allow specifying HTTP headers). Here's an example of what it might look like to create a Zipkin OkHttpSender in Java configured for the Trace API: OkHttpSender.create(\"https://trace-api.newrelic.com/trace/v1?Api-Key=NEW_RELIC_INSERT_API_KEY&Data-Format=zipkin&Data-Format-Version=2\"); Copy Note that if you were using Infinite Tracing, or had an EU-region New Relic account, the endpoint would be different. For an explanation of Api-Key and the other metadata, see Request metadata. Transformation of Zipkin data To create a consistent search/query experience, some Zipkin data will be transformed to match New Relic attribute naming. For more on how we store and structure trace data, see How distributed tracing works. Zipkin tag Stored in New Relic as... Details traceId trace.id Unique identifier for a trace. id id Unique identifier for a span. parentId parent.id Identifier of the upstream span that called the service. kind kind Either Client or Server. name name Name of span. duration duration.ms Zipkin v2 spans must have durations specified in microseconds, and will be converted to milliseconds. localEndpoint: serviceName service.name We use the Zipkin v2 service name to identify the entity that created this span. localEndpoint: port localEndpoint.port All values in the localEndpoint object will be flattened to a span attribute called localEndpoint.key tags reported as attributes Key:value pairs in the tags object in Zipkin v2 will be written as span attributes. annotations not supported We do not currently support annotations in the Trace API. Spans will not be rejected if they contain annotations, but the annotations data will not be written. Add other tags/attributes You can add any tags you want to the tags block, with the exception of the restricted tags. For example, you might want to add attributes like customer.id or user.id to help you analyze your trace data. Tags will be converted to New Relic attributes. To learn how to control how spans appear in New Relic (for example, adding errors or setting a span as a datastore span), see Decorate spans.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.25296,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report Zipkin-format <em>traces</em> via <em>Trace</em> <em>API</em>",
        "sections": "Report Zipkin-format <em>traces</em> via <em>Trace</em> <em>API</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": ", &quot;localEndpoint&quot;: { &quot;serviceName&quot;: &quot;service-2&quot;, &quot;ipv4&quot;: &quot;127.0.0.1&quot;, &quot;port&quot;: 8080 }, &quot;tags&quot;: { &quot;error.message&quot;: &quot;Invalid credentials&quot; } } ]&#x27; &#x27;https:&#x2F;&#x2F;<em>trace</em>-<em>api</em>.newrelic.com&#x2F;<em>trace</em>&#x2F;v1&#x27; Copy Within a minute, the <em>trace</em> should be available in the our <em>distributed</em> <em>tracing</em> UI. To find it, run a query"
      },
      "id": "6071cfc864441fa88f9d8530"
    },
    {
      "sections": [
        "Trace API: Decorate spans with attributes",
        "Why decorate your spans?",
        "How to decorate your spans with attributes",
        "JSON examples",
        "New Relic-format attribute examples",
        "Zipkin-format attribute examples"
      ],
      "title": "Trace API: Decorate spans with attributes",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "1e5d907a844f32e60b4cb7db4d7d1728a22adcde",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/trace-api-decorate-spans-attributes/",
      "published_at": "2021-06-14T18:07:42Z",
      "updated_at": "2021-04-10T16:18:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document will explain how to add attributes to trace data sent to the Trace API so that spans display specific properties in the UI. Why decorate your spans? When you send data to our Trace API, you can add custom attributes to spans. For example, you might decide to add attributes like customer.id or user.id in order to help you analyze your trace data. Some expected attribute values cause our distributed tracing UI to display some specific trace properties and details. For example, if a span has an attribute with an error. prefix, the UI displays that span with an error. For another example, a span with an attribute that has a db. prefix will be displayed as a datastore span in the UI, and will have its datastore query highlighted. Decorating your spans to show specific properties in our UI can help you: Better understand the structure of your trace data. More easily troubleshoot problems. How to decorate your spans with attributes This table explains how to get spans sent to the Trace API to show up with specific properties in the UI. For property descriptions, see span properties. Desired span property UI indicator How to add property Errors Use an attribute with an error. prefix. For example: error.message. External Use an attribute with an http. prefix. For example: http.method. A span will also appear as an external if it has a child that comes from a different entity. Datastore Use an attribute with an db. prefix. For example: db.statement. Service This cannot be done with an attribute. A span is classified as a service span if it's the root span, or if its parent is from a different entity. If a span has several properties, service span classification takes precedence in the UI. In-process This cannot be done with an attribute. A span is classified as in-process if it hasn't been classified as a service span, datastore span, or external span. For more on how these span properties are determined and stored, see Trace structure. Tips for adding attributes: You can add any attribute to a span. For example: you might add an attribute like customer.id so that you could search traces globally for traces containing a specific customer. A span can be in multiple categories. For example, external is a more general category than is datastore, so if a span is classified as both external and datastore, it will be indicated as a datastore span in the UI. JSON examples Here are JSON examples showing how to use attributes to set span properties: New Relic-format attribute examples New Relic-format JSON with multiple types of attributes added. The significance of the custom attributes is described in customAttribute. [ { \"common\": { \"attributes\": { \"hostname\": \"cattle456.example.com\", \"environment\": \"staging\" } }, \"spans\": [ { \"id\": \"1-abcdefg\", \"trace.id\": \"abc123-xyz789\", \"attributes\": { \"service.name\": \"Order Service\", \"duration.ms\": 3.5, \"error.name\": \"StackOverflowException\", \"name\": \"/placeOrder [POST]\", \"customer.id\": \"datanerd@newrelic.com\", \"description\": \"This span is the root of the whole trace. It has no parent.id. Custom attributes like 'customer.id' can have any name. Using these kinds of attributes will allow you to do a global search across all traces for desired traces.\" } }, { \"id\": \"2-abcdefg\", \"trace.id\": \"abc123-xyz789\", \"attributes\": { \"service.name\": \"Order Service\", \"duration.ms\": 1, \"parent.id\": \"1-abcdefg\", \"db.query\": \"foo selection\", \"db.statement\": \"SELECT FOO FROM BAR\", \"name\": \"DB Span\", \"description\": \"This is a datastore span. The presence of one or more attributes prefixed with db. makes this display as a datastore span in the UI.\" } }, { \"id\": \"3-abcdefg\", \"trace.id\": \"abc123-xyz789\", \"attributes\": { \"service.name\": \"Order Service\", \"parent.id\": \"1-abcdefg\", \"duration.ms\": 1.5, \"http.method\": \"POST\", \"name\": \"HTTP Span\", \"description\": \"An external (HTTP) span. Spans with one or more attributes prefixed with http. are treated as external spans.\" } }, { \"id\": \"4-abcdefg\", \"trace.id\": \"abc123-xyz789\", \"attributes\": { \"service.name\": \"Order Service\", \"duration.ms\": 1.2, \"error.text\": \"404 file not found\", \"parent.id\": \"1-abcdefg\", \"http.method\": \"GET\", \"http.statusCode\": 404, \"name\": \"Error Http Span\", \"description\": \"Spans with error. prefixed attributes are displayed in red text in the UI. Errors can coexist with other span categories.\" } }, { \"id\": \"5-abcdefg\", \"trace.id\": \"abc123-xyz789\", \"attributes\": { \"service.name\": \"Order Service\", \"error.message\": \"404 file not found\", \"duration.ms\": 1.2, \"parent.id\": \"1-abcdefg\", \"http.method\": \"GET\", \"http.statusCode\": 404, \"db.query\": \"SELECT FOO FROM BAR\", \"name\": \"Error Http DB Span\", \"description\": \"Spans can have multiple properties. Relevant attributes are highlighted when you select a span to view its details.\" } }, { \"id\": \"6-abcdefg\", \"trace.id\": \"abc123-xyz789\", \"attributes\": { \"service.name\": \"Order Service\", \"duration.ms\": 1.6, \"parent.id\": \"1-abcdefg\", \"http.method\": \"GET\", \"db.query\": \"SELECT FOO FROM BAR\", \"name\": \"Http DB Span\", \"description\": \"External (HTTP) is a more general category than is datastore, so a span with both http.- and db.-prefixed attributes is displayed as a datastore span in the UI.\" } }, { \"id\": \"7-abcdefg\", \"trace.id\": \"abc123-xyz789\", \"attributes\": { \"service.name\": \"Order Service\", \"duration.ms\": 2.0, \"parent.id\": \"1-abcdefg\", \"description\": \"Spans with no explicit types that belong to the same entity as its parent and children are considered in-process spans.\", \"name\": \"In-process span 1\" } }, { \"id\": \"8-abcdefg\", \"trace.id\": \"abc123-xyz789\", \"attributes\": { \"service.name\": \"Order Service\", \"duration.ms\": 1.7, \"parent.id\": \"7-abcdefg\", \"name\": \"In-process span 2\", \"description\": \"In-process spans can represent a breakdown of work being done within a process.\" } }, { \"id\": \"9-abcdefg\", \"trace.id\": \"abc123-xyz789\", \"attributes\": { \"service.name\": \"Order Service\", \"duration.ms\": 1.0, \"parent.id\": \"8-abcdefg\", \"name\": \"In-process span 3\", \"description\": \"The number and granularity of in-process spans vary depending on instrumentation and frameworks being used.\" } }, { \"id\": \"10-abcdefg\", \"trace.id\": \"abc123-xyz789\", \"attributes\": { \"service.name\": \"Order Service\", \"duration.ms\": 2.2, \"parent.id\": \"1-abcdefg\", \"name\": \"In-process span\" } }, { \"id\": \"11-abcdefg\", \"trace.id\": \"abc123-xyz789\", \"attributes\": { \"service.name\": \"Order Service\", \"duration.ms\": 2.2, \"parent.id\": \"10-abcdefg\", \"name\": \"External determined by entity change\", \"description\": \"A span that’s a parent to a span from another entity is displayed as an external span in the UI.\" } }, { \"id\": \"12-abcdefg\", \"trace.id\": \"abc123-xyz789\", \"attributes\": { \"service.name\": \"Order Notification Service\", \"duration.ms\": 1.8, \"parent.id\": \"11-abcdefg\", \"name\": \"Entry span determined by entity change\", \"description\": \"The attribute 'service.name' is used to detect process boundaries in the UI. For compatibility with data from Lambda monitoring and APM agents, the attribute 'entity.name' can be used to search across all traces.\" } } ] } ] Copy Zipkin-format attribute examples Zipkin-format JSON with multiple attribute types added. The significance of the attributes (key-value pairs) is described in customAttribute. [ { \"traceId\": \"zipkinSampleTrace\", \"id\": \"1\", \"kind\": \"SERVER\", \"name\": \"Error Span\", \"duration\": 35000, \"localEndpoint\": { \"serviceName\": \"sampleApp\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"customAttribute\": \"This span is the root of the whole trace. It has no parent.id\" } }, { \"traceId\": \"zipkinSampleTrace\", \"id\": \"2\", \"parentId\": \"1\", \"kind\": \"SERVER\", \"name\": \"post\", \"duration\": 10000, \"localEndpoint\": { \"serviceName\": \"sampleApp\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"customAttribute\": \"This is a datastore span. The presence of one or more attributes prefixed with db. makes this display as a datastore span in the UI.\" } }, { \"traceId\": \"zipkinSampleTrace\", \"id\": \"2\", \"parentId\": \"1\", \"kind\": \"CLIENT\", \"name\": \"DB Span\", \"duration\": 12000, \"localEndpoint\": { \"serviceName\": \"sampleApp\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"db.query\": \"foo selection\", \"db.statement\": \"SELECT FOO FROM BAR\", \"customAttribute\": \"This is a datastore span. The presence of one or more attributes prefixed with db. makes this display as a datastore span in the UI.\" } }, { \"traceId\": \"zipkinSampleTrace\", \"id\": \"3\", \"parentId\": \"1\", \"kind\": \"CLIENT\", \"name\": \"HTTP Span\", \"duration\": 15000, \"localEndpoint\": { \"serviceName\": \"sampleApp\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"http.method\": \"POST\", \"customAttribute\": \"AAn external (HTTP) span. Spans with one or more attributes prefixed with http. are treated as external spans.\" } }, { \"traceId\": \"zipkinSampleTrace\", \"id\": \"4\", \"parentId\": \"1\", \"kind\": \"CLIENT\", \"name\": \"Error Span\", \"duration\": 12000, \"localEndpoint\": { \"serviceName\": \"sampleApp\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"error.message\": \"404 file not found\", \"http.method\": \"GET\", \"http.statusCode\": 404, \"customAttribute\": \"Spans with error. prefixed attributes are displayed in red text in the UI. Errors can coexist with other span categories.\" } }, { \"traceId\": \"zipkinSampleTrace\", \"id\": \"5\", \"parentId\": \"1\", \"kind\": \"CLIENT\", \"name\": \"HTTP Error DB Span\", \"duration\": 12000, \"localEndpoint\": { \"serviceName\": \"sampleApp\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"error.message\": \"404 file not found\", \"http.method\": \"GET\", \"http.statusCode\": 404, \"db.query\": \"SELECT FOO FROM BAR\", \"customAttribute\": \"Spans can have multiple properties. Relevant attributes are highlighted when you select a span to view its details.\" } }, { \"traceId\": \"zipkinSampleTrace\", \"id\": \"6\", \"parentId\": \"1\", \"kind\": \"CLIENT\", \"name\": \"HTTP DB Span\", \"duration\": 12000, \"localEndpoint\": { \"serviceName\": \"sampleApp\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"http.method\": \"GET\", \"db.query\": \"SELECT FOO FROM BAR\", \"customAttribute\": \"External (HTTP) is a more general category than is datastore, so a span with both http.- and db.-prefixed attributes is displayed as a datastore span in the UI.\" } }, { \"traceId\": \"zipkinSampleTrace\", \"id\": \"7\", \"parentId\": \"1\", \"kind\": \"SERVER\", \"name\": \"In process span 1\", \"duration\": 12000, \"localEndpoint\": { \"serviceName\": \"sampleApp\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"customAttribute\": \"Spans with no explicit types that belong to the same entity as its parent and children are considered in-process spans.\" } }, { \"traceId\": \"zipkinSampleTrace\", \"id\": \"8\", \"parentId\": \"7\", \"kind\": \"SERVER\", \"name\": \"In process span 2\", \"duration\": 12000, \"localEndpoint\": { \"serviceName\": \"sampleApp\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"customAttribute\": \"In-process spans can represent a breakdown of work being done within a process.\" } }, { \"traceId\": \"zipkinSampleTrace\", \"id\": \"9\", \"parentId\": \"8\", \"kind\": \"SERVER\", \"name\": \"In process span 2\", \"duration\": 12000, \"localEndpoint\": { \"serviceName\": \"sampleApp\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"customAttribute\": \"The number and granularity of in-process spans vary depending on instrumentation and frameworks being used.\" } }, { \"traceId\": \"zipkinSampleTrace\", \"id\": \"10\", \"parentId\": \"1\", \"kind\": \"CLIENT\", \"name\": \"In process remote parent\", \"duration\": 12000, \"localEndpoint\": { \"serviceName\": \"sampleApp\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"name\": \"in process remote parent\" } }, { \"traceId\": \"zipkinSampleTrace\", \"id\": \"10\", \"parentId\": \"1\", \"kind\": \"CLIENT\", \"name\": \"In process remote parent\", \"duration\": 12000, \"localEndpoint\": { \"serviceName\": \"sampleApp\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"customAttribute\": \"A span that is a parent to a span from another entity will be displayed as an external span.\" } }, { \"traceId\": \"zipkinSampleTrace\", \"id\": \"11\", \"parentId\": \"10\", \"kind\": \"SERVER\", \"name\": \"Downstream entry span\", \"duration\": 12000, \"localEndpoint\": { \"serviceName\": \"downstreamSampleApp\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"customAttribute\": \"The attribute 'service.name' is used to detect process boundaries in the UI. For compatibility with data from Lambda monitoring and APM agents, the attribute 'entity.name' can be used to search across all traces.\" } } ] Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.25296,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Trace</em> <em>API</em>: Decorate spans with attributes",
        "sections": "<em>Trace</em> <em>API</em>: Decorate spans with attributes",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " customer.id or user.id in order to help you analyze your <em>trace</em> data. Some expected attribute values cause our <em>distributed</em> <em>tracing</em> UI to display some specific <em>trace</em> properties and details. For example, if a span has an attribute with an error. prefix, the UI displays that span with an error. For another"
      },
      "id": "6071cfc8196a678ed764a7b2"
    }
  ],
  "/docs/distributed-tracing/trace-api/report-new-relic-format-traces-trace-api": [
    {
      "sections": [
        "Trace API general requirements and limits",
        "Endpoints",
        "Data formats",
        "Data limits",
        "Restricted attributes",
        "Request metadata (headers and query parameters)",
        "Important",
        "Response validation",
        "See HTTP status codes",
        "Exceeding span limits"
      ],
      "title": "Trace API general requirements and limits ",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "f77504082dae8374e0c7009a31abebbd4c0123f3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/trace-api-general-requirements-limits/",
      "published_at": "2021-06-14T18:07:42Z",
      "updated_at": "2021-06-09T00:57:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Information about Trace API data requirements, including: Data specifications and max limits Required metadata (headers, query parameters) Response validation details This document applies to the Trace API overall. For rules regarding specific data formats, see: New Relic-format trace data Zipkin-format trace data Endpoints All trace data is sent via a POST to a Trace API endpoint. We have a few endpoints, depending on your setup: Default Trace API endpoint: https://trace-api.newrelic.com/trace/v1 EU data centers: https://trace-api.eu.newrelic.com/trace/v1 (see other EU endpoints). Infinite Tracing: when you complete the Trace observer setup, you get a custom YOUR_TRACE_OBSERVER_URL value to use as an endpoint. If you're using an integration that uses the Trace API (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust the sampling of your tracing service to send us 100% of spans. For FedRAMP, see FedRAMP endpoints. Data formats Currently, the Trace API accepts two types of data formats: zipkin: For reporting Zipkin trace data. Zipkin data must be Zipkin JSON v2. newrelic: For reporting all other trace data. Data limits Data limits and rules: Condition Limit Max age of span timestamp values 20 minutes. timestamp must be within 20 minutes of current time at ingest, or within 20 minutes from the time the last span with the same trace.id was received by New Relic. Max payload size 1MB (10^6 bytes) (gzip compression supported) Max requests per minute 100K Max spans per minute per account family Dependent on agreement. Max limit: 2M. Max spans per trace 50K Max attributes per span 200 Max span attribute value length 4000 characters Allowed HTTP protocols HTTPS only Cross-account visibility of span details Potential data obfuscation To see an example of how span limits are enforced, see Exceeding limits. Restricted attributes The attributes in the table below are restricted in the newrelic-format JSON (in the attributes block) and in the zipkin-format JSON (in the tags block). Any values with these keys will be omitted: Restricted attribute Description entityGuid string Unique identifier for the entity that created this span. Generated from service.name, if available. guid string Used for backwards compatibility with data from APM agents. The attributes in the table below are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Restricted attribute description entity.guid string Unique identifier for the entity associated with this span. entity.name string Human-readable name of an entity, often used to identify an entity in the UI. entity.type string Used to differentiate between different types of entities, like hosts, applications, etc. Request metadata (headers and query parameters) The following table shows the required request metadata for all trace data formats. This metadata can be sent as HTTP headers on an ingest request or, in some cases, provided as query parameters, which may be required for tracing frameworks that don't allow header modification. Important Security note: We suggest using headers because query parameters are present in the URL and may be logged before being encrypted and received by New Relic. All data sent as query parameters must be URL-safe. Header Query param? Details Content-Type No Required. Must be application/json. Content-Length No Required. The length of the request body in octets (8-bit bytes) unless sent with chunked encoding. This header is generally set by default by the underlying HTTP client sending the data and in most cases should not require any additional effort by the end user. Api-Key Yes (case-sensitive) Required. The Trace API requires the Insights insert key. If this is provided as both a header and a query parameter, the values must match. Content-Encoding No Required if compressed payload. The value must be gzip. Data-Format Yes Required for zipkin. Optional for newrelic. If present, Data-Format-Version must also be present. Data-Format-Version Yes Required for zipkin. If present, Data-Format must also be present. There are only two possible pairings for these values: If Data-Format is zipkin, Data-Format-Version must be 2. If Data-Format is newrelic, Data-Format-Version must be 1. x-request-id No Optional - Reserved for future use. The value must be a valid UUID4. The value is expected to be unique for each request. Response validation A response for successfully sending trace data will include a requestId. For example: {\"requestId\":\"c1bb62fc-001a-b000-0000-016bb152e1bb\"} Copy There are two ways success/errors are signaled: HTTP status code (synchronous). Authentication and request errors will be signaled via HTTP status code. See HTTP status codes Code Meaning 202 Data accepted. This means that you've passed preliminary checks, but is not a guarantee that the data has been successfully parsed and indexed as part of a distributed trace. 400 The structure of the request was invalid. Errors with query parameters, etc. 403 Authentication error. May occur with an invalid license key or if you lack necessary entitlement to use the Trace API. 404 The request path is incorrect. 405 For any request method other than POST. 408 The request took too long to reach the endpoint. 411 The Content-Length header wasn’t included. 413 The payload was too big. 414 The request URI was too long. 415 The Content-Type or Content-Encoding was invalid. 429 The request rate quota has been exceeded. 431 The request headers are too long. 5xx There was a server error (please retry). NrIntegrationError events (asynchronous). Errors with the JSON payload or other semantic errors are asynchronously signaled via NrIntegrationError events that are stored in the account whose license key is associated with the request. For all errors of this type, the attribute newRelicFeature will be Distributed Tracing and requestId will be the requestId from the endpoint response. If you receive a 202 response and don't see an NrIntegrationError event, your data should be visible in New Relic One's global distributed tracing UI in about a minute. You should be able to find the trace using a standard trace search like: traceId = TRACE_ID_SENT Copy Exceeding span limits When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate limit messages with this NRQL: SELECT * FROM NrIntegrationError WHERE newRelicFeature = 'Distributed Tracing' AND category = 'RateLimit' AND rateLimitType = 'SpansPerMinute' Copy To get a notification when you exceed the limit, you can set up a NRQL alert. We calculate a rolling 10-minute average based on your span rate limit. This allows for temporary rate bursts, and lets us prioritize keeping and dropping complete traces instead of indiscriminately dropping spans on a per minute limit basis. In the example below of exceeding the rate, the rate limit is the default 100,000 spans per minute. New Relic allows a burst above 100K for a couple of minutes without downsampling, because the remaining minutes in the 10-minute window averaged under 100K spans/minute. For the previous 10 minutes (8:50 - 9:00) the service received 60,000 spans/minute. Minute Spans sent to API Total for past 10 minutes 8:59 60,000 600,000 9:00 40,000 580,000 9:01 50,000 570,000 9:02 250,000 760,000 9:03 220,000 920,000 9:04 125,000 985,000 9:05 70,000 995,000 9:06 50,000 985,000 9:07 40,000 965,000 9:08 40,000 945,000 9:09 40,000 925,000",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 289.51443,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Trace</em> <em>API</em> general requirements and limits ",
        "sections": "<em>Trace</em> <em>API</em> general requirements and limits",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>Tracing</em>: when you complete the <em>Trace</em> observer setup, you get a custom YOUR_<em>TRACE</em>_OBSERVER_URL value to use as an endpoint. If you&#x27;re using an integration that uses the <em>Trace</em> <em>API</em> (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust"
      },
      "id": "6071cf7628ccbcf8b851c158"
    },
    {
      "sections": [
        "Introduction to the Trace API",
        "Tip",
        "What is the Trace API?",
        "Requirements",
        "Sampling considerations",
        "Start reporting data",
        "Find data",
        "Next steps"
      ],
      "title": "Introduction to the Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "119447fbb33c4469c81877ffaa273bd7b1956e9f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/introduction-trace-api/",
      "published_at": "2021-06-14T18:06:42Z",
      "updated_at": "2021-04-10T16:16:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Trace API is used to send distributed tracing data to New Relic: either in our own generic format or the Zipkin data format. This API is also how trace data from some of our integrations and exporters is reported to New Relic. To skip some introductory content and get started quickly, go to Start reporting data. Tip To use APIs and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. What is the Trace API? The Trace API is one way that New Relic collects distributed tracing data. We have some tracing tools that report data via this API (Infinite Tracing, our open source integrations, and our Telemetry SDKs), or you can use the API directly to create your own tracing implementation. Reasons to use the Trace API: You have your own custom distributed tracing tool and want to see that data in New Relic without changing your instrumentation. You have a tool that emits tracing data but that requires a backend for trace storage. You want to report distributed tracing data to New Relic without the use of our installed solutions. You use Zipkin and want to see that trace data in New Relic without changing your instrumentation. Want to understand how trace data relates to other New Relic data? Read about our data types. Requirements For details about what data you can send and how it is handled, see Rules and limits. Sampling considerations When using the Trace API, you have the option to enable Infinite Tracing. Whether you use Infinite Tracing has implications for how you configure sampling: Use your own sampling (no Infinite Tracing): If you don't use Infinite Tracing, it's assumed you want to use your own sampling implementation to sample traces before they're sent to us. (If your trace data exceeds our data limits, we do enact sampling.) Use Infinite Tracing: If you want to use Infinite Tracing, a typical approach is to send us 100% of your trace data and rely on Infinite Tracing sampling. (When you go through the Start reporting data instructions, below, you'll have an option for enabling Infinite Tracing.) Start reporting data The Trace API accepts trace data in these two JSON formats: zipkin: the Zipkin JSON v2 trace data format (learn what Zipkin is). Get started sending Zipkin data. newrelic: our general format. If you don't have Zipkin-format data, use this. Get started sending New Relic-format data. Having problems getting data to report? See Troubleshooting. Find data You can find data sent via the Trace API, or from integrations that use this API, in these locations: In our distributed tracing UI. By querying: For details about how to query and create custom charts, see Query distributed tracing data. Next steps Here are some additional steps to consider: Learn more about how distributed tracing works and the data structure. Decorate span data with custom attributes. Use our GraphQL-based NerdGraph API to programmatically query your trace data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.44983,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Trace</em> <em>API</em>",
        "sections": "Introduction to the <em>Trace</em> <em>API</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Our <em>Trace</em> <em>API</em> is used to send <em>distributed</em> <em>tracing</em> data to New Relic: either in our own generic format or the Zipkin data format. This <em>API</em> is also how <em>trace</em> data from some of our integrations and exporters is reported to New Relic. To skip some introductory content and get started quickly, go"
      },
      "id": "6071cf7728ccbcf4bc51c16a"
    },
    {
      "sections": [
        "Report Zipkin-format traces via Trace API",
        "Zipkin version requirements",
        "Overview of using the Trace API",
        "Send sample Zipkin trace payload",
        "Send Zipkin-format payload",
        "Send data from existing Zipkin instrumentation",
        "Transformation of Zipkin data",
        "Add other tags/attributes"
      ],
      "title": "Report Zipkin-format traces via Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "dba8334d1f068236c741ff04c13ecc2be2c184fc",
      "image": "https://docs.newrelic.com/static/96e69137f0dd86b313ec72d5f0c1ad83/119c7/Screen-Shot-2020-08-13-at-1.26.17-PM.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/report-zipkin-format-traces-trace-api/",
      "published_at": "2021-06-14T18:07:42Z",
      "updated_at": "2021-04-10T16:18:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you want to create your own tracing implementation, you can use our Trace API. This doc explains how to send Zipkin-format trace data to our Trace API. (For our general data format, see New Relic format.) Zipkin version requirements The Trace API supports data from Zipkin JSON v2 (or higher) without any modification. For details on this version, see Zipkin v2 release details and the Zipkin v2 schema. Overview of using the Trace API Using our Trace API is as simple as: Sending trace data in the expected format (in this case, zipkin format). Sending that data to the appropriate endpoint Our send-data instructions have options for enabling Infinite Tracing. To learn more about this, see Intro to Infinite Tracing and Sampling considerations. To get started using the Trace API, choose an option: Send a sample trace: This shows a curl example of sending a trace to New Relic. This is useful for understanding how the Trace API works, and to verify you're seeing data in New Relic. Report data from existing Zipkin instrumentation: if you have an existing Zipkin implementation, you can simply change the endpoint of where your data gets sent. Send sample Zipkin trace payload This section describes how to send a simple Zipkin-format trace to our Trace API via curl request. You might choose to do this in order to learn how our API works and to verify that data is showing up in New Relic before doing in-depth instrumentation. To get started sending a sample payload: (Optional, to enable Infinite Tracing) First, you must set up a trace observer. That procedure includes instructions for sending a sample trace using our general new-relic format. When you get to that step, return here to instead learn how to send a Zipkin-format trace. Send a Zipkin-format payload following the instructions below. Send Zipkin-format payload To send a sample Zipkin-format trace: Get an Insights insert key: Go to the API keys UI and select Insights insert keys. If you don't already have a key, create a new one by selecting Insert keys +. You'll be executing a curl request, below. Notes on this: Replace the insert key placeholder with your insert key. If you're using Infinite Tracing, use the YOUR_TRACE_OBSERVER_URL value in place of the standard endpoint. If you want to send more than one post, change the trace ID to a different value. Sending the same payload or span id multiple times for the same traceId may result in fragmented traces in the UI. curl -i -H 'Content-Type: application/json' \\ -H 'Api-Key: $NEW_RELIC_INSERT_KEY' \\ -H 'Data-Format: zipkin' \\ -H 'Data-Format-Version: 2' \\ -X POST \\ -d '[ { \"traceId\": \"test-zipkin-trace-id-1\", \"id\": \"3e0f5885710776cd\", \"kind\": \"CLIENT\", \"name\": \"post\", \"duration\": 508068, \"localEndpoint\": { \"serviceName\": \"service-1\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { } }, { \"traceId\": \"test-zipkin-trace-id-1\", \"parentId\": \"3e0f5885710776cd\", \"id\": \"asdf9asdn123lkasdf\", \"kind\": \"CLIENT\", \"name\": \"service 2 span\", \"duration\": 2019, \"localEndpoint\": { \"serviceName\": \"service-2\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"error.message\": \"Invalid credentials\" } } ]' 'https://trace-api.newrelic.com/trace/v1' Copy Within a minute, the trace should be available in the our distributed tracing UI. To find it, run a query for the trace.id. In this example, it was test-zipkin-trace-id-1. Note that you search by the transformed attribute of trace.id (not traceId). To learn more: Learn where Trace API data shows up in the UI. Send data from an existing Zipkin instrumentation. Learn how to decorate spans by adding tags. This helps you customize how traces are displayed in our UI for a richer, more helpful experience. Learn about general endpoint information (data limits, required metadata, and response validation). Learn about how Zipkin data is transformed and stored in our format. If you don't see your trace data, see Troubleshooting. Send data from existing Zipkin instrumentation Preliminary notes: If you want to enable Infinite Tracing, you first must set up a trace observer. It can be helpful to first send a sample payload to verify things are working properly. To report data from an existing Zipkin instrumentation, you'll point the Zipkin tracer at the appropriate Trace API endpoint with some required request metadata. You can send the required metadata as headers or query parameters (some Zipkin tracer versions don't allow specifying HTTP headers). Here's an example of what it might look like to create a Zipkin OkHttpSender in Java configured for the Trace API: OkHttpSender.create(\"https://trace-api.newrelic.com/trace/v1?Api-Key=NEW_RELIC_INSERT_API_KEY&Data-Format=zipkin&Data-Format-Version=2\"); Copy Note that if you were using Infinite Tracing, or had an EU-region New Relic account, the endpoint would be different. For an explanation of Api-Key and the other metadata, see Request metadata. Transformation of Zipkin data To create a consistent search/query experience, some Zipkin data will be transformed to match New Relic attribute naming. For more on how we store and structure trace data, see How distributed tracing works. Zipkin tag Stored in New Relic as... Details traceId trace.id Unique identifier for a trace. id id Unique identifier for a span. parentId parent.id Identifier of the upstream span that called the service. kind kind Either Client or Server. name name Name of span. duration duration.ms Zipkin v2 spans must have durations specified in microseconds, and will be converted to milliseconds. localEndpoint: serviceName service.name We use the Zipkin v2 service name to identify the entity that created this span. localEndpoint: port localEndpoint.port All values in the localEndpoint object will be flattened to a span attribute called localEndpoint.key tags reported as attributes Key:value pairs in the tags object in Zipkin v2 will be written as span attributes. annotations not supported We do not currently support annotations in the Trace API. Spans will not be rejected if they contain annotations, but the annotations data will not be written. Add other tags/attributes You can add any tags you want to the tags block, with the exception of the restricted tags. For example, you might want to add attributes like customer.id or user.id to help you analyze your trace data. Tags will be converted to New Relic attributes. To learn how to control how spans appear in New Relic (for example, adding errors or setting a span as a datastore span), see Decorate spans.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.25296,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report Zipkin-format <em>traces</em> via <em>Trace</em> <em>API</em>",
        "sections": "Report Zipkin-format <em>traces</em> via <em>Trace</em> <em>API</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": ", &quot;localEndpoint&quot;: { &quot;serviceName&quot;: &quot;service-2&quot;, &quot;ipv4&quot;: &quot;127.0.0.1&quot;, &quot;port&quot;: 8080 }, &quot;tags&quot;: { &quot;error.message&quot;: &quot;Invalid credentials&quot; } } ]&#x27; &#x27;https:&#x2F;&#x2F;<em>trace</em>-<em>api</em>.newrelic.com&#x2F;<em>trace</em>&#x2F;v1&#x27; Copy Within a minute, the <em>trace</em> should be available in the our <em>distributed</em> <em>tracing</em> UI. To find it, run a query"
      },
      "id": "6071cfc864441fa88f9d8530"
    }
  ],
  "/docs/distributed-tracing/trace-api/report-zipkin-format-traces-trace-api": [
    {
      "sections": [
        "Trace API general requirements and limits",
        "Endpoints",
        "Data formats",
        "Data limits",
        "Restricted attributes",
        "Request metadata (headers and query parameters)",
        "Important",
        "Response validation",
        "See HTTP status codes",
        "Exceeding span limits"
      ],
      "title": "Trace API general requirements and limits ",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "f77504082dae8374e0c7009a31abebbd4c0123f3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/trace-api-general-requirements-limits/",
      "published_at": "2021-06-14T18:07:42Z",
      "updated_at": "2021-06-09T00:57:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Information about Trace API data requirements, including: Data specifications and max limits Required metadata (headers, query parameters) Response validation details This document applies to the Trace API overall. For rules regarding specific data formats, see: New Relic-format trace data Zipkin-format trace data Endpoints All trace data is sent via a POST to a Trace API endpoint. We have a few endpoints, depending on your setup: Default Trace API endpoint: https://trace-api.newrelic.com/trace/v1 EU data centers: https://trace-api.eu.newrelic.com/trace/v1 (see other EU endpoints). Infinite Tracing: when you complete the Trace observer setup, you get a custom YOUR_TRACE_OBSERVER_URL value to use as an endpoint. If you're using an integration that uses the Trace API (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust the sampling of your tracing service to send us 100% of spans. For FedRAMP, see FedRAMP endpoints. Data formats Currently, the Trace API accepts two types of data formats: zipkin: For reporting Zipkin trace data. Zipkin data must be Zipkin JSON v2. newrelic: For reporting all other trace data. Data limits Data limits and rules: Condition Limit Max age of span timestamp values 20 minutes. timestamp must be within 20 minutes of current time at ingest, or within 20 minutes from the time the last span with the same trace.id was received by New Relic. Max payload size 1MB (10^6 bytes) (gzip compression supported) Max requests per minute 100K Max spans per minute per account family Dependent on agreement. Max limit: 2M. Max spans per trace 50K Max attributes per span 200 Max span attribute value length 4000 characters Allowed HTTP protocols HTTPS only Cross-account visibility of span details Potential data obfuscation To see an example of how span limits are enforced, see Exceeding limits. Restricted attributes The attributes in the table below are restricted in the newrelic-format JSON (in the attributes block) and in the zipkin-format JSON (in the tags block). Any values with these keys will be omitted: Restricted attribute Description entityGuid string Unique identifier for the entity that created this span. Generated from service.name, if available. guid string Used for backwards compatibility with data from APM agents. The attributes in the table below are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Restricted attribute description entity.guid string Unique identifier for the entity associated with this span. entity.name string Human-readable name of an entity, often used to identify an entity in the UI. entity.type string Used to differentiate between different types of entities, like hosts, applications, etc. Request metadata (headers and query parameters) The following table shows the required request metadata for all trace data formats. This metadata can be sent as HTTP headers on an ingest request or, in some cases, provided as query parameters, which may be required for tracing frameworks that don't allow header modification. Important Security note: We suggest using headers because query parameters are present in the URL and may be logged before being encrypted and received by New Relic. All data sent as query parameters must be URL-safe. Header Query param? Details Content-Type No Required. Must be application/json. Content-Length No Required. The length of the request body in octets (8-bit bytes) unless sent with chunked encoding. This header is generally set by default by the underlying HTTP client sending the data and in most cases should not require any additional effort by the end user. Api-Key Yes (case-sensitive) Required. The Trace API requires the Insights insert key. If this is provided as both a header and a query parameter, the values must match. Content-Encoding No Required if compressed payload. The value must be gzip. Data-Format Yes Required for zipkin. Optional for newrelic. If present, Data-Format-Version must also be present. Data-Format-Version Yes Required for zipkin. If present, Data-Format must also be present. There are only two possible pairings for these values: If Data-Format is zipkin, Data-Format-Version must be 2. If Data-Format is newrelic, Data-Format-Version must be 1. x-request-id No Optional - Reserved for future use. The value must be a valid UUID4. The value is expected to be unique for each request. Response validation A response for successfully sending trace data will include a requestId. For example: {\"requestId\":\"c1bb62fc-001a-b000-0000-016bb152e1bb\"} Copy There are two ways success/errors are signaled: HTTP status code (synchronous). Authentication and request errors will be signaled via HTTP status code. See HTTP status codes Code Meaning 202 Data accepted. This means that you've passed preliminary checks, but is not a guarantee that the data has been successfully parsed and indexed as part of a distributed trace. 400 The structure of the request was invalid. Errors with query parameters, etc. 403 Authentication error. May occur with an invalid license key or if you lack necessary entitlement to use the Trace API. 404 The request path is incorrect. 405 For any request method other than POST. 408 The request took too long to reach the endpoint. 411 The Content-Length header wasn’t included. 413 The payload was too big. 414 The request URI was too long. 415 The Content-Type or Content-Encoding was invalid. 429 The request rate quota has been exceeded. 431 The request headers are too long. 5xx There was a server error (please retry). NrIntegrationError events (asynchronous). Errors with the JSON payload or other semantic errors are asynchronously signaled via NrIntegrationError events that are stored in the account whose license key is associated with the request. For all errors of this type, the attribute newRelicFeature will be Distributed Tracing and requestId will be the requestId from the endpoint response. If you receive a 202 response and don't see an NrIntegrationError event, your data should be visible in New Relic One's global distributed tracing UI in about a minute. You should be able to find the trace using a standard trace search like: traceId = TRACE_ID_SENT Copy Exceeding span limits When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate limit messages with this NRQL: SELECT * FROM NrIntegrationError WHERE newRelicFeature = 'Distributed Tracing' AND category = 'RateLimit' AND rateLimitType = 'SpansPerMinute' Copy To get a notification when you exceed the limit, you can set up a NRQL alert. We calculate a rolling 10-minute average based on your span rate limit. This allows for temporary rate bursts, and lets us prioritize keeping and dropping complete traces instead of indiscriminately dropping spans on a per minute limit basis. In the example below of exceeding the rate, the rate limit is the default 100,000 spans per minute. New Relic allows a burst above 100K for a couple of minutes without downsampling, because the remaining minutes in the 10-minute window averaged under 100K spans/minute. For the previous 10 minutes (8:50 - 9:00) the service received 60,000 spans/minute. Minute Spans sent to API Total for past 10 minutes 8:59 60,000 600,000 9:00 40,000 580,000 9:01 50,000 570,000 9:02 250,000 760,000 9:03 220,000 920,000 9:04 125,000 985,000 9:05 70,000 995,000 9:06 50,000 985,000 9:07 40,000 965,000 9:08 40,000 945,000 9:09 40,000 925,000",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 289.51434,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Trace</em> <em>API</em> general requirements and limits ",
        "sections": "<em>Trace</em> <em>API</em> general requirements and limits",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>Tracing</em>: when you complete the <em>Trace</em> observer setup, you get a custom YOUR_<em>TRACE</em>_OBSERVER_URL value to use as an endpoint. If you&#x27;re using an integration that uses the <em>Trace</em> <em>API</em> (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust"
      },
      "id": "6071cf7628ccbcf8b851c158"
    },
    {
      "sections": [
        "Introduction to the Trace API",
        "Tip",
        "What is the Trace API?",
        "Requirements",
        "Sampling considerations",
        "Start reporting data",
        "Find data",
        "Next steps"
      ],
      "title": "Introduction to the Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "119447fbb33c4469c81877ffaa273bd7b1956e9f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/introduction-trace-api/",
      "published_at": "2021-06-14T18:06:42Z",
      "updated_at": "2021-04-10T16:16:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Trace API is used to send distributed tracing data to New Relic: either in our own generic format or the Zipkin data format. This API is also how trace data from some of our integrations and exporters is reported to New Relic. To skip some introductory content and get started quickly, go to Start reporting data. Tip To use APIs and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. What is the Trace API? The Trace API is one way that New Relic collects distributed tracing data. We have some tracing tools that report data via this API (Infinite Tracing, our open source integrations, and our Telemetry SDKs), or you can use the API directly to create your own tracing implementation. Reasons to use the Trace API: You have your own custom distributed tracing tool and want to see that data in New Relic without changing your instrumentation. You have a tool that emits tracing data but that requires a backend for trace storage. You want to report distributed tracing data to New Relic without the use of our installed solutions. You use Zipkin and want to see that trace data in New Relic without changing your instrumentation. Want to understand how trace data relates to other New Relic data? Read about our data types. Requirements For details about what data you can send and how it is handled, see Rules and limits. Sampling considerations When using the Trace API, you have the option to enable Infinite Tracing. Whether you use Infinite Tracing has implications for how you configure sampling: Use your own sampling (no Infinite Tracing): If you don't use Infinite Tracing, it's assumed you want to use your own sampling implementation to sample traces before they're sent to us. (If your trace data exceeds our data limits, we do enact sampling.) Use Infinite Tracing: If you want to use Infinite Tracing, a typical approach is to send us 100% of your trace data and rely on Infinite Tracing sampling. (When you go through the Start reporting data instructions, below, you'll have an option for enabling Infinite Tracing.) Start reporting data The Trace API accepts trace data in these two JSON formats: zipkin: the Zipkin JSON v2 trace data format (learn what Zipkin is). Get started sending Zipkin data. newrelic: our general format. If you don't have Zipkin-format data, use this. Get started sending New Relic-format data. Having problems getting data to report? See Troubleshooting. Find data You can find data sent via the Trace API, or from integrations that use this API, in these locations: In our distributed tracing UI. By querying: For details about how to query and create custom charts, see Query distributed tracing data. Next steps Here are some additional steps to consider: Learn more about how distributed tracing works and the data structure. Decorate span data with custom attributes. Use our GraphQL-based NerdGraph API to programmatically query your trace data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.44983,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Trace</em> <em>API</em>",
        "sections": "Introduction to the <em>Trace</em> <em>API</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Our <em>Trace</em> <em>API</em> is used to send <em>distributed</em> <em>tracing</em> data to New Relic: either in our own generic format or the Zipkin data format. This <em>API</em> is also how <em>trace</em> data from some of our integrations and exporters is reported to New Relic. To skip some introductory content and get started quickly, go"
      },
      "id": "6071cf7728ccbcf4bc51c16a"
    },
    {
      "sections": [
        "Trace API: Decorate spans with attributes",
        "Why decorate your spans?",
        "How to decorate your spans with attributes",
        "JSON examples",
        "New Relic-format attribute examples",
        "Zipkin-format attribute examples"
      ],
      "title": "Trace API: Decorate spans with attributes",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "1e5d907a844f32e60b4cb7db4d7d1728a22adcde",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/trace-api-decorate-spans-attributes/",
      "published_at": "2021-06-14T18:07:42Z",
      "updated_at": "2021-04-10T16:18:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document will explain how to add attributes to trace data sent to the Trace API so that spans display specific properties in the UI. Why decorate your spans? When you send data to our Trace API, you can add custom attributes to spans. For example, you might decide to add attributes like customer.id or user.id in order to help you analyze your trace data. Some expected attribute values cause our distributed tracing UI to display some specific trace properties and details. For example, if a span has an attribute with an error. prefix, the UI displays that span with an error. For another example, a span with an attribute that has a db. prefix will be displayed as a datastore span in the UI, and will have its datastore query highlighted. Decorating your spans to show specific properties in our UI can help you: Better understand the structure of your trace data. More easily troubleshoot problems. How to decorate your spans with attributes This table explains how to get spans sent to the Trace API to show up with specific properties in the UI. For property descriptions, see span properties. Desired span property UI indicator How to add property Errors Use an attribute with an error. prefix. For example: error.message. External Use an attribute with an http. prefix. For example: http.method. A span will also appear as an external if it has a child that comes from a different entity. Datastore Use an attribute with an db. prefix. For example: db.statement. Service This cannot be done with an attribute. A span is classified as a service span if it's the root span, or if its parent is from a different entity. If a span has several properties, service span classification takes precedence in the UI. In-process This cannot be done with an attribute. A span is classified as in-process if it hasn't been classified as a service span, datastore span, or external span. For more on how these span properties are determined and stored, see Trace structure. Tips for adding attributes: You can add any attribute to a span. For example: you might add an attribute like customer.id so that you could search traces globally for traces containing a specific customer. A span can be in multiple categories. For example, external is a more general category than is datastore, so if a span is classified as both external and datastore, it will be indicated as a datastore span in the UI. JSON examples Here are JSON examples showing how to use attributes to set span properties: New Relic-format attribute examples New Relic-format JSON with multiple types of attributes added. The significance of the custom attributes is described in customAttribute. [ { \"common\": { \"attributes\": { \"hostname\": \"cattle456.example.com\", \"environment\": \"staging\" } }, \"spans\": [ { \"id\": \"1-abcdefg\", \"trace.id\": \"abc123-xyz789\", \"attributes\": { \"service.name\": \"Order Service\", \"duration.ms\": 3.5, \"error.name\": \"StackOverflowException\", \"name\": \"/placeOrder [POST]\", \"customer.id\": \"datanerd@newrelic.com\", \"description\": \"This span is the root of the whole trace. It has no parent.id. Custom attributes like 'customer.id' can have any name. Using these kinds of attributes will allow you to do a global search across all traces for desired traces.\" } }, { \"id\": \"2-abcdefg\", \"trace.id\": \"abc123-xyz789\", \"attributes\": { \"service.name\": \"Order Service\", \"duration.ms\": 1, \"parent.id\": \"1-abcdefg\", \"db.query\": \"foo selection\", \"db.statement\": \"SELECT FOO FROM BAR\", \"name\": \"DB Span\", \"description\": \"This is a datastore span. The presence of one or more attributes prefixed with db. makes this display as a datastore span in the UI.\" } }, { \"id\": \"3-abcdefg\", \"trace.id\": \"abc123-xyz789\", \"attributes\": { \"service.name\": \"Order Service\", \"parent.id\": \"1-abcdefg\", \"duration.ms\": 1.5, \"http.method\": \"POST\", \"name\": \"HTTP Span\", \"description\": \"An external (HTTP) span. Spans with one or more attributes prefixed with http. are treated as external spans.\" } }, { \"id\": \"4-abcdefg\", \"trace.id\": \"abc123-xyz789\", \"attributes\": { \"service.name\": \"Order Service\", \"duration.ms\": 1.2, \"error.text\": \"404 file not found\", \"parent.id\": \"1-abcdefg\", \"http.method\": \"GET\", \"http.statusCode\": 404, \"name\": \"Error Http Span\", \"description\": \"Spans with error. prefixed attributes are displayed in red text in the UI. Errors can coexist with other span categories.\" } }, { \"id\": \"5-abcdefg\", \"trace.id\": \"abc123-xyz789\", \"attributes\": { \"service.name\": \"Order Service\", \"error.message\": \"404 file not found\", \"duration.ms\": 1.2, \"parent.id\": \"1-abcdefg\", \"http.method\": \"GET\", \"http.statusCode\": 404, \"db.query\": \"SELECT FOO FROM BAR\", \"name\": \"Error Http DB Span\", \"description\": \"Spans can have multiple properties. Relevant attributes are highlighted when you select a span to view its details.\" } }, { \"id\": \"6-abcdefg\", \"trace.id\": \"abc123-xyz789\", \"attributes\": { \"service.name\": \"Order Service\", \"duration.ms\": 1.6, \"parent.id\": \"1-abcdefg\", \"http.method\": \"GET\", \"db.query\": \"SELECT FOO FROM BAR\", \"name\": \"Http DB Span\", \"description\": \"External (HTTP) is a more general category than is datastore, so a span with both http.- and db.-prefixed attributes is displayed as a datastore span in the UI.\" } }, { \"id\": \"7-abcdefg\", \"trace.id\": \"abc123-xyz789\", \"attributes\": { \"service.name\": \"Order Service\", \"duration.ms\": 2.0, \"parent.id\": \"1-abcdefg\", \"description\": \"Spans with no explicit types that belong to the same entity as its parent and children are considered in-process spans.\", \"name\": \"In-process span 1\" } }, { \"id\": \"8-abcdefg\", \"trace.id\": \"abc123-xyz789\", \"attributes\": { \"service.name\": \"Order Service\", \"duration.ms\": 1.7, \"parent.id\": \"7-abcdefg\", \"name\": \"In-process span 2\", \"description\": \"In-process spans can represent a breakdown of work being done within a process.\" } }, { \"id\": \"9-abcdefg\", \"trace.id\": \"abc123-xyz789\", \"attributes\": { \"service.name\": \"Order Service\", \"duration.ms\": 1.0, \"parent.id\": \"8-abcdefg\", \"name\": \"In-process span 3\", \"description\": \"The number and granularity of in-process spans vary depending on instrumentation and frameworks being used.\" } }, { \"id\": \"10-abcdefg\", \"trace.id\": \"abc123-xyz789\", \"attributes\": { \"service.name\": \"Order Service\", \"duration.ms\": 2.2, \"parent.id\": \"1-abcdefg\", \"name\": \"In-process span\" } }, { \"id\": \"11-abcdefg\", \"trace.id\": \"abc123-xyz789\", \"attributes\": { \"service.name\": \"Order Service\", \"duration.ms\": 2.2, \"parent.id\": \"10-abcdefg\", \"name\": \"External determined by entity change\", \"description\": \"A span that’s a parent to a span from another entity is displayed as an external span in the UI.\" } }, { \"id\": \"12-abcdefg\", \"trace.id\": \"abc123-xyz789\", \"attributes\": { \"service.name\": \"Order Notification Service\", \"duration.ms\": 1.8, \"parent.id\": \"11-abcdefg\", \"name\": \"Entry span determined by entity change\", \"description\": \"The attribute 'service.name' is used to detect process boundaries in the UI. For compatibility with data from Lambda monitoring and APM agents, the attribute 'entity.name' can be used to search across all traces.\" } } ] } ] Copy Zipkin-format attribute examples Zipkin-format JSON with multiple attribute types added. The significance of the attributes (key-value pairs) is described in customAttribute. [ { \"traceId\": \"zipkinSampleTrace\", \"id\": \"1\", \"kind\": \"SERVER\", \"name\": \"Error Span\", \"duration\": 35000, \"localEndpoint\": { \"serviceName\": \"sampleApp\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"customAttribute\": \"This span is the root of the whole trace. It has no parent.id\" } }, { \"traceId\": \"zipkinSampleTrace\", \"id\": \"2\", \"parentId\": \"1\", \"kind\": \"SERVER\", \"name\": \"post\", \"duration\": 10000, \"localEndpoint\": { \"serviceName\": \"sampleApp\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"customAttribute\": \"This is a datastore span. The presence of one or more attributes prefixed with db. makes this display as a datastore span in the UI.\" } }, { \"traceId\": \"zipkinSampleTrace\", \"id\": \"2\", \"parentId\": \"1\", \"kind\": \"CLIENT\", \"name\": \"DB Span\", \"duration\": 12000, \"localEndpoint\": { \"serviceName\": \"sampleApp\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"db.query\": \"foo selection\", \"db.statement\": \"SELECT FOO FROM BAR\", \"customAttribute\": \"This is a datastore span. The presence of one or more attributes prefixed with db. makes this display as a datastore span in the UI.\" } }, { \"traceId\": \"zipkinSampleTrace\", \"id\": \"3\", \"parentId\": \"1\", \"kind\": \"CLIENT\", \"name\": \"HTTP Span\", \"duration\": 15000, \"localEndpoint\": { \"serviceName\": \"sampleApp\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"http.method\": \"POST\", \"customAttribute\": \"AAn external (HTTP) span. Spans with one or more attributes prefixed with http. are treated as external spans.\" } }, { \"traceId\": \"zipkinSampleTrace\", \"id\": \"4\", \"parentId\": \"1\", \"kind\": \"CLIENT\", \"name\": \"Error Span\", \"duration\": 12000, \"localEndpoint\": { \"serviceName\": \"sampleApp\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"error.message\": \"404 file not found\", \"http.method\": \"GET\", \"http.statusCode\": 404, \"customAttribute\": \"Spans with error. prefixed attributes are displayed in red text in the UI. Errors can coexist with other span categories.\" } }, { \"traceId\": \"zipkinSampleTrace\", \"id\": \"5\", \"parentId\": \"1\", \"kind\": \"CLIENT\", \"name\": \"HTTP Error DB Span\", \"duration\": 12000, \"localEndpoint\": { \"serviceName\": \"sampleApp\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"error.message\": \"404 file not found\", \"http.method\": \"GET\", \"http.statusCode\": 404, \"db.query\": \"SELECT FOO FROM BAR\", \"customAttribute\": \"Spans can have multiple properties. Relevant attributes are highlighted when you select a span to view its details.\" } }, { \"traceId\": \"zipkinSampleTrace\", \"id\": \"6\", \"parentId\": \"1\", \"kind\": \"CLIENT\", \"name\": \"HTTP DB Span\", \"duration\": 12000, \"localEndpoint\": { \"serviceName\": \"sampleApp\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"http.method\": \"GET\", \"db.query\": \"SELECT FOO FROM BAR\", \"customAttribute\": \"External (HTTP) is a more general category than is datastore, so a span with both http.- and db.-prefixed attributes is displayed as a datastore span in the UI.\" } }, { \"traceId\": \"zipkinSampleTrace\", \"id\": \"7\", \"parentId\": \"1\", \"kind\": \"SERVER\", \"name\": \"In process span 1\", \"duration\": 12000, \"localEndpoint\": { \"serviceName\": \"sampleApp\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"customAttribute\": \"Spans with no explicit types that belong to the same entity as its parent and children are considered in-process spans.\" } }, { \"traceId\": \"zipkinSampleTrace\", \"id\": \"8\", \"parentId\": \"7\", \"kind\": \"SERVER\", \"name\": \"In process span 2\", \"duration\": 12000, \"localEndpoint\": { \"serviceName\": \"sampleApp\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"customAttribute\": \"In-process spans can represent a breakdown of work being done within a process.\" } }, { \"traceId\": \"zipkinSampleTrace\", \"id\": \"9\", \"parentId\": \"8\", \"kind\": \"SERVER\", \"name\": \"In process span 2\", \"duration\": 12000, \"localEndpoint\": { \"serviceName\": \"sampleApp\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"customAttribute\": \"The number and granularity of in-process spans vary depending on instrumentation and frameworks being used.\" } }, { \"traceId\": \"zipkinSampleTrace\", \"id\": \"10\", \"parentId\": \"1\", \"kind\": \"CLIENT\", \"name\": \"In process remote parent\", \"duration\": 12000, \"localEndpoint\": { \"serviceName\": \"sampleApp\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"name\": \"in process remote parent\" } }, { \"traceId\": \"zipkinSampleTrace\", \"id\": \"10\", \"parentId\": \"1\", \"kind\": \"CLIENT\", \"name\": \"In process remote parent\", \"duration\": 12000, \"localEndpoint\": { \"serviceName\": \"sampleApp\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"customAttribute\": \"A span that is a parent to a span from another entity will be displayed as an external span.\" } }, { \"traceId\": \"zipkinSampleTrace\", \"id\": \"11\", \"parentId\": \"10\", \"kind\": \"SERVER\", \"name\": \"Downstream entry span\", \"duration\": 12000, \"localEndpoint\": { \"serviceName\": \"downstreamSampleApp\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"customAttribute\": \"The attribute 'service.name' is used to detect process boundaries in the UI. For compatibility with data from Lambda monitoring and APM agents, the attribute 'entity.name' can be used to search across all traces.\" } } ] Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.25296,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Trace</em> <em>API</em>: Decorate spans with attributes",
        "sections": "<em>Trace</em> <em>API</em>: Decorate spans with attributes",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " customer.id or user.id in order to help you analyze your <em>trace</em> data. Some expected attribute values cause our <em>distributed</em> <em>tracing</em> UI to display some specific <em>trace</em> properties and details. For example, if a span has an attribute with an error. prefix, the UI displays that span with an error. For another"
      },
      "id": "6071cfc8196a678ed764a7b2"
    }
  ],
  "/docs/distributed-tracing/trace-api/trace-api-decorate-spans-attributes": [
    {
      "sections": [
        "Trace API general requirements and limits",
        "Endpoints",
        "Data formats",
        "Data limits",
        "Restricted attributes",
        "Request metadata (headers and query parameters)",
        "Important",
        "Response validation",
        "See HTTP status codes",
        "Exceeding span limits"
      ],
      "title": "Trace API general requirements and limits ",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "f77504082dae8374e0c7009a31abebbd4c0123f3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/trace-api-general-requirements-limits/",
      "published_at": "2021-06-14T18:07:42Z",
      "updated_at": "2021-06-09T00:57:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Information about Trace API data requirements, including: Data specifications and max limits Required metadata (headers, query parameters) Response validation details This document applies to the Trace API overall. For rules regarding specific data formats, see: New Relic-format trace data Zipkin-format trace data Endpoints All trace data is sent via a POST to a Trace API endpoint. We have a few endpoints, depending on your setup: Default Trace API endpoint: https://trace-api.newrelic.com/trace/v1 EU data centers: https://trace-api.eu.newrelic.com/trace/v1 (see other EU endpoints). Infinite Tracing: when you complete the Trace observer setup, you get a custom YOUR_TRACE_OBSERVER_URL value to use as an endpoint. If you're using an integration that uses the Trace API (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust the sampling of your tracing service to send us 100% of spans. For FedRAMP, see FedRAMP endpoints. Data formats Currently, the Trace API accepts two types of data formats: zipkin: For reporting Zipkin trace data. Zipkin data must be Zipkin JSON v2. newrelic: For reporting all other trace data. Data limits Data limits and rules: Condition Limit Max age of span timestamp values 20 minutes. timestamp must be within 20 minutes of current time at ingest, or within 20 minutes from the time the last span with the same trace.id was received by New Relic. Max payload size 1MB (10^6 bytes) (gzip compression supported) Max requests per minute 100K Max spans per minute per account family Dependent on agreement. Max limit: 2M. Max spans per trace 50K Max attributes per span 200 Max span attribute value length 4000 characters Allowed HTTP protocols HTTPS only Cross-account visibility of span details Potential data obfuscation To see an example of how span limits are enforced, see Exceeding limits. Restricted attributes The attributes in the table below are restricted in the newrelic-format JSON (in the attributes block) and in the zipkin-format JSON (in the tags block). Any values with these keys will be omitted: Restricted attribute Description entityGuid string Unique identifier for the entity that created this span. Generated from service.name, if available. guid string Used for backwards compatibility with data from APM agents. The attributes in the table below are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Restricted attribute description entity.guid string Unique identifier for the entity associated with this span. entity.name string Human-readable name of an entity, often used to identify an entity in the UI. entity.type string Used to differentiate between different types of entities, like hosts, applications, etc. Request metadata (headers and query parameters) The following table shows the required request metadata for all trace data formats. This metadata can be sent as HTTP headers on an ingest request or, in some cases, provided as query parameters, which may be required for tracing frameworks that don't allow header modification. Important Security note: We suggest using headers because query parameters are present in the URL and may be logged before being encrypted and received by New Relic. All data sent as query parameters must be URL-safe. Header Query param? Details Content-Type No Required. Must be application/json. Content-Length No Required. The length of the request body in octets (8-bit bytes) unless sent with chunked encoding. This header is generally set by default by the underlying HTTP client sending the data and in most cases should not require any additional effort by the end user. Api-Key Yes (case-sensitive) Required. The Trace API requires the Insights insert key. If this is provided as both a header and a query parameter, the values must match. Content-Encoding No Required if compressed payload. The value must be gzip. Data-Format Yes Required for zipkin. Optional for newrelic. If present, Data-Format-Version must also be present. Data-Format-Version Yes Required for zipkin. If present, Data-Format must also be present. There are only two possible pairings for these values: If Data-Format is zipkin, Data-Format-Version must be 2. If Data-Format is newrelic, Data-Format-Version must be 1. x-request-id No Optional - Reserved for future use. The value must be a valid UUID4. The value is expected to be unique for each request. Response validation A response for successfully sending trace data will include a requestId. For example: {\"requestId\":\"c1bb62fc-001a-b000-0000-016bb152e1bb\"} Copy There are two ways success/errors are signaled: HTTP status code (synchronous). Authentication and request errors will be signaled via HTTP status code. See HTTP status codes Code Meaning 202 Data accepted. This means that you've passed preliminary checks, but is not a guarantee that the data has been successfully parsed and indexed as part of a distributed trace. 400 The structure of the request was invalid. Errors with query parameters, etc. 403 Authentication error. May occur with an invalid license key or if you lack necessary entitlement to use the Trace API. 404 The request path is incorrect. 405 For any request method other than POST. 408 The request took too long to reach the endpoint. 411 The Content-Length header wasn’t included. 413 The payload was too big. 414 The request URI was too long. 415 The Content-Type or Content-Encoding was invalid. 429 The request rate quota has been exceeded. 431 The request headers are too long. 5xx There was a server error (please retry). NrIntegrationError events (asynchronous). Errors with the JSON payload or other semantic errors are asynchronously signaled via NrIntegrationError events that are stored in the account whose license key is associated with the request. For all errors of this type, the attribute newRelicFeature will be Distributed Tracing and requestId will be the requestId from the endpoint response. If you receive a 202 response and don't see an NrIntegrationError event, your data should be visible in New Relic One's global distributed tracing UI in about a minute. You should be able to find the trace using a standard trace search like: traceId = TRACE_ID_SENT Copy Exceeding span limits When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate limit messages with this NRQL: SELECT * FROM NrIntegrationError WHERE newRelicFeature = 'Distributed Tracing' AND category = 'RateLimit' AND rateLimitType = 'SpansPerMinute' Copy To get a notification when you exceed the limit, you can set up a NRQL alert. We calculate a rolling 10-minute average based on your span rate limit. This allows for temporary rate bursts, and lets us prioritize keeping and dropping complete traces instead of indiscriminately dropping spans on a per minute limit basis. In the example below of exceeding the rate, the rate limit is the default 100,000 spans per minute. New Relic allows a burst above 100K for a couple of minutes without downsampling, because the remaining minutes in the 10-minute window averaged under 100K spans/minute. For the previous 10 minutes (8:50 - 9:00) the service received 60,000 spans/minute. Minute Spans sent to API Total for past 10 minutes 8:59 60,000 600,000 9:00 40,000 580,000 9:01 50,000 570,000 9:02 250,000 760,000 9:03 220,000 920,000 9:04 125,000 985,000 9:05 70,000 995,000 9:06 50,000 985,000 9:07 40,000 965,000 9:08 40,000 945,000 9:09 40,000 925,000",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 289.51434,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Trace</em> <em>API</em> general requirements and limits ",
        "sections": "<em>Trace</em> <em>API</em> general requirements and limits",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>Tracing</em>: when you complete the <em>Trace</em> observer setup, you get a custom YOUR_<em>TRACE</em>_OBSERVER_URL value to use as an endpoint. If you&#x27;re using an integration that uses the <em>Trace</em> <em>API</em> (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust"
      },
      "id": "6071cf7628ccbcf8b851c158"
    },
    {
      "sections": [
        "Introduction to the Trace API",
        "Tip",
        "What is the Trace API?",
        "Requirements",
        "Sampling considerations",
        "Start reporting data",
        "Find data",
        "Next steps"
      ],
      "title": "Introduction to the Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "119447fbb33c4469c81877ffaa273bd7b1956e9f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/introduction-trace-api/",
      "published_at": "2021-06-14T18:06:42Z",
      "updated_at": "2021-04-10T16:16:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Trace API is used to send distributed tracing data to New Relic: either in our own generic format or the Zipkin data format. This API is also how trace data from some of our integrations and exporters is reported to New Relic. To skip some introductory content and get started quickly, go to Start reporting data. Tip To use APIs and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. What is the Trace API? The Trace API is one way that New Relic collects distributed tracing data. We have some tracing tools that report data via this API (Infinite Tracing, our open source integrations, and our Telemetry SDKs), or you can use the API directly to create your own tracing implementation. Reasons to use the Trace API: You have your own custom distributed tracing tool and want to see that data in New Relic without changing your instrumentation. You have a tool that emits tracing data but that requires a backend for trace storage. You want to report distributed tracing data to New Relic without the use of our installed solutions. You use Zipkin and want to see that trace data in New Relic without changing your instrumentation. Want to understand how trace data relates to other New Relic data? Read about our data types. Requirements For details about what data you can send and how it is handled, see Rules and limits. Sampling considerations When using the Trace API, you have the option to enable Infinite Tracing. Whether you use Infinite Tracing has implications for how you configure sampling: Use your own sampling (no Infinite Tracing): If you don't use Infinite Tracing, it's assumed you want to use your own sampling implementation to sample traces before they're sent to us. (If your trace data exceeds our data limits, we do enact sampling.) Use Infinite Tracing: If you want to use Infinite Tracing, a typical approach is to send us 100% of your trace data and rely on Infinite Tracing sampling. (When you go through the Start reporting data instructions, below, you'll have an option for enabling Infinite Tracing.) Start reporting data The Trace API accepts trace data in these two JSON formats: zipkin: the Zipkin JSON v2 trace data format (learn what Zipkin is). Get started sending Zipkin data. newrelic: our general format. If you don't have Zipkin-format data, use this. Get started sending New Relic-format data. Having problems getting data to report? See Troubleshooting. Find data You can find data sent via the Trace API, or from integrations that use this API, in these locations: In our distributed tracing UI. By querying: For details about how to query and create custom charts, see Query distributed tracing data. Next steps Here are some additional steps to consider: Learn more about how distributed tracing works and the data structure. Decorate span data with custom attributes. Use our GraphQL-based NerdGraph API to programmatically query your trace data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.44983,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Trace</em> <em>API</em>",
        "sections": "Introduction to the <em>Trace</em> <em>API</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Our <em>Trace</em> <em>API</em> is used to send <em>distributed</em> <em>tracing</em> data to New Relic: either in our own generic format or the Zipkin data format. This <em>API</em> is also how <em>trace</em> data from some of our integrations and exporters is reported to New Relic. To skip some introductory content and get started quickly, go"
      },
      "id": "6071cf7728ccbcf4bc51c16a"
    },
    {
      "sections": [
        "Report Zipkin-format traces via Trace API",
        "Zipkin version requirements",
        "Overview of using the Trace API",
        "Send sample Zipkin trace payload",
        "Send Zipkin-format payload",
        "Send data from existing Zipkin instrumentation",
        "Transformation of Zipkin data",
        "Add other tags/attributes"
      ],
      "title": "Report Zipkin-format traces via Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "dba8334d1f068236c741ff04c13ecc2be2c184fc",
      "image": "https://docs.newrelic.com/static/96e69137f0dd86b313ec72d5f0c1ad83/119c7/Screen-Shot-2020-08-13-at-1.26.17-PM.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/report-zipkin-format-traces-trace-api/",
      "published_at": "2021-06-14T18:07:42Z",
      "updated_at": "2021-04-10T16:18:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you want to create your own tracing implementation, you can use our Trace API. This doc explains how to send Zipkin-format trace data to our Trace API. (For our general data format, see New Relic format.) Zipkin version requirements The Trace API supports data from Zipkin JSON v2 (or higher) without any modification. For details on this version, see Zipkin v2 release details and the Zipkin v2 schema. Overview of using the Trace API Using our Trace API is as simple as: Sending trace data in the expected format (in this case, zipkin format). Sending that data to the appropriate endpoint Our send-data instructions have options for enabling Infinite Tracing. To learn more about this, see Intro to Infinite Tracing and Sampling considerations. To get started using the Trace API, choose an option: Send a sample trace: This shows a curl example of sending a trace to New Relic. This is useful for understanding how the Trace API works, and to verify you're seeing data in New Relic. Report data from existing Zipkin instrumentation: if you have an existing Zipkin implementation, you can simply change the endpoint of where your data gets sent. Send sample Zipkin trace payload This section describes how to send a simple Zipkin-format trace to our Trace API via curl request. You might choose to do this in order to learn how our API works and to verify that data is showing up in New Relic before doing in-depth instrumentation. To get started sending a sample payload: (Optional, to enable Infinite Tracing) First, you must set up a trace observer. That procedure includes instructions for sending a sample trace using our general new-relic format. When you get to that step, return here to instead learn how to send a Zipkin-format trace. Send a Zipkin-format payload following the instructions below. Send Zipkin-format payload To send a sample Zipkin-format trace: Get an Insights insert key: Go to the API keys UI and select Insights insert keys. If you don't already have a key, create a new one by selecting Insert keys +. You'll be executing a curl request, below. Notes on this: Replace the insert key placeholder with your insert key. If you're using Infinite Tracing, use the YOUR_TRACE_OBSERVER_URL value in place of the standard endpoint. If you want to send more than one post, change the trace ID to a different value. Sending the same payload or span id multiple times for the same traceId may result in fragmented traces in the UI. curl -i -H 'Content-Type: application/json' \\ -H 'Api-Key: $NEW_RELIC_INSERT_KEY' \\ -H 'Data-Format: zipkin' \\ -H 'Data-Format-Version: 2' \\ -X POST \\ -d '[ { \"traceId\": \"test-zipkin-trace-id-1\", \"id\": \"3e0f5885710776cd\", \"kind\": \"CLIENT\", \"name\": \"post\", \"duration\": 508068, \"localEndpoint\": { \"serviceName\": \"service-1\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { } }, { \"traceId\": \"test-zipkin-trace-id-1\", \"parentId\": \"3e0f5885710776cd\", \"id\": \"asdf9asdn123lkasdf\", \"kind\": \"CLIENT\", \"name\": \"service 2 span\", \"duration\": 2019, \"localEndpoint\": { \"serviceName\": \"service-2\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"error.message\": \"Invalid credentials\" } } ]' 'https://trace-api.newrelic.com/trace/v1' Copy Within a minute, the trace should be available in the our distributed tracing UI. To find it, run a query for the trace.id. In this example, it was test-zipkin-trace-id-1. Note that you search by the transformed attribute of trace.id (not traceId). To learn more: Learn where Trace API data shows up in the UI. Send data from an existing Zipkin instrumentation. Learn how to decorate spans by adding tags. This helps you customize how traces are displayed in our UI for a richer, more helpful experience. Learn about general endpoint information (data limits, required metadata, and response validation). Learn about how Zipkin data is transformed and stored in our format. If you don't see your trace data, see Troubleshooting. Send data from existing Zipkin instrumentation Preliminary notes: If you want to enable Infinite Tracing, you first must set up a trace observer. It can be helpful to first send a sample payload to verify things are working properly. To report data from an existing Zipkin instrumentation, you'll point the Zipkin tracer at the appropriate Trace API endpoint with some required request metadata. You can send the required metadata as headers or query parameters (some Zipkin tracer versions don't allow specifying HTTP headers). Here's an example of what it might look like to create a Zipkin OkHttpSender in Java configured for the Trace API: OkHttpSender.create(\"https://trace-api.newrelic.com/trace/v1?Api-Key=NEW_RELIC_INSERT_API_KEY&Data-Format=zipkin&Data-Format-Version=2\"); Copy Note that if you were using Infinite Tracing, or had an EU-region New Relic account, the endpoint would be different. For an explanation of Api-Key and the other metadata, see Request metadata. Transformation of Zipkin data To create a consistent search/query experience, some Zipkin data will be transformed to match New Relic attribute naming. For more on how we store and structure trace data, see How distributed tracing works. Zipkin tag Stored in New Relic as... Details traceId trace.id Unique identifier for a trace. id id Unique identifier for a span. parentId parent.id Identifier of the upstream span that called the service. kind kind Either Client or Server. name name Name of span. duration duration.ms Zipkin v2 spans must have durations specified in microseconds, and will be converted to milliseconds. localEndpoint: serviceName service.name We use the Zipkin v2 service name to identify the entity that created this span. localEndpoint: port localEndpoint.port All values in the localEndpoint object will be flattened to a span attribute called localEndpoint.key tags reported as attributes Key:value pairs in the tags object in Zipkin v2 will be written as span attributes. annotations not supported We do not currently support annotations in the Trace API. Spans will not be rejected if they contain annotations, but the annotations data will not be written. Add other tags/attributes You can add any tags you want to the tags block, with the exception of the restricted tags. For example, you might want to add attributes like customer.id or user.id to help you analyze your trace data. Tags will be converted to New Relic attributes. To learn how to control how spans appear in New Relic (for example, adding errors or setting a span as a datastore span), see Decorate spans.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.25296,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report Zipkin-format <em>traces</em> via <em>Trace</em> <em>API</em>",
        "sections": "Report Zipkin-format <em>traces</em> via <em>Trace</em> <em>API</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": ", &quot;localEndpoint&quot;: { &quot;serviceName&quot;: &quot;service-2&quot;, &quot;ipv4&quot;: &quot;127.0.0.1&quot;, &quot;port&quot;: 8080 }, &quot;tags&quot;: { &quot;error.message&quot;: &quot;Invalid credentials&quot; } } ]&#x27; &#x27;https:&#x2F;&#x2F;<em>trace</em>-<em>api</em>.newrelic.com&#x2F;<em>trace</em>&#x2F;v1&#x27; Copy Within a minute, the <em>trace</em> should be available in the our <em>distributed</em> <em>tracing</em> UI. To find it, run a query"
      },
      "id": "6071cfc864441fa88f9d8530"
    }
  ],
  "/docs/distributed-tracing/trace-api/trace-api-general-requirements-limits": [
    {
      "sections": [
        "Introduction to the Trace API",
        "Tip",
        "What is the Trace API?",
        "Requirements",
        "Sampling considerations",
        "Start reporting data",
        "Find data",
        "Next steps"
      ],
      "title": "Introduction to the Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "119447fbb33c4469c81877ffaa273bd7b1956e9f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/introduction-trace-api/",
      "published_at": "2021-06-14T18:06:42Z",
      "updated_at": "2021-04-10T16:16:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Trace API is used to send distributed tracing data to New Relic: either in our own generic format or the Zipkin data format. This API is also how trace data from some of our integrations and exporters is reported to New Relic. To skip some introductory content and get started quickly, go to Start reporting data. Tip To use APIs and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. What is the Trace API? The Trace API is one way that New Relic collects distributed tracing data. We have some tracing tools that report data via this API (Infinite Tracing, our open source integrations, and our Telemetry SDKs), or you can use the API directly to create your own tracing implementation. Reasons to use the Trace API: You have your own custom distributed tracing tool and want to see that data in New Relic without changing your instrumentation. You have a tool that emits tracing data but that requires a backend for trace storage. You want to report distributed tracing data to New Relic without the use of our installed solutions. You use Zipkin and want to see that trace data in New Relic without changing your instrumentation. Want to understand how trace data relates to other New Relic data? Read about our data types. Requirements For details about what data you can send and how it is handled, see Rules and limits. Sampling considerations When using the Trace API, you have the option to enable Infinite Tracing. Whether you use Infinite Tracing has implications for how you configure sampling: Use your own sampling (no Infinite Tracing): If you don't use Infinite Tracing, it's assumed you want to use your own sampling implementation to sample traces before they're sent to us. (If your trace data exceeds our data limits, we do enact sampling.) Use Infinite Tracing: If you want to use Infinite Tracing, a typical approach is to send us 100% of your trace data and rely on Infinite Tracing sampling. (When you go through the Start reporting data instructions, below, you'll have an option for enabling Infinite Tracing.) Start reporting data The Trace API accepts trace data in these two JSON formats: zipkin: the Zipkin JSON v2 trace data format (learn what Zipkin is). Get started sending Zipkin data. newrelic: our general format. If you don't have Zipkin-format data, use this. Get started sending New Relic-format data. Having problems getting data to report? See Troubleshooting. Find data You can find data sent via the Trace API, or from integrations that use this API, in these locations: In our distributed tracing UI. By querying: For details about how to query and create custom charts, see Query distributed tracing data. Next steps Here are some additional steps to consider: Learn more about how distributed tracing works and the data structure. Decorate span data with custom attributes. Use our GraphQL-based NerdGraph API to programmatically query your trace data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.44983,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Trace</em> <em>API</em>",
        "sections": "Introduction to the <em>Trace</em> <em>API</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Our <em>Trace</em> <em>API</em> is used to send <em>distributed</em> <em>tracing</em> data to New Relic: either in our own generic format or the Zipkin data format. This <em>API</em> is also how <em>trace</em> data from some of our integrations and exporters is reported to New Relic. To skip some introductory content and get started quickly, go"
      },
      "id": "6071cf7728ccbcf4bc51c16a"
    },
    {
      "sections": [
        "Report Zipkin-format traces via Trace API",
        "Zipkin version requirements",
        "Overview of using the Trace API",
        "Send sample Zipkin trace payload",
        "Send Zipkin-format payload",
        "Send data from existing Zipkin instrumentation",
        "Transformation of Zipkin data",
        "Add other tags/attributes"
      ],
      "title": "Report Zipkin-format traces via Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "dba8334d1f068236c741ff04c13ecc2be2c184fc",
      "image": "https://docs.newrelic.com/static/96e69137f0dd86b313ec72d5f0c1ad83/119c7/Screen-Shot-2020-08-13-at-1.26.17-PM.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/report-zipkin-format-traces-trace-api/",
      "published_at": "2021-06-14T18:07:42Z",
      "updated_at": "2021-04-10T16:18:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you want to create your own tracing implementation, you can use our Trace API. This doc explains how to send Zipkin-format trace data to our Trace API. (For our general data format, see New Relic format.) Zipkin version requirements The Trace API supports data from Zipkin JSON v2 (or higher) without any modification. For details on this version, see Zipkin v2 release details and the Zipkin v2 schema. Overview of using the Trace API Using our Trace API is as simple as: Sending trace data in the expected format (in this case, zipkin format). Sending that data to the appropriate endpoint Our send-data instructions have options for enabling Infinite Tracing. To learn more about this, see Intro to Infinite Tracing and Sampling considerations. To get started using the Trace API, choose an option: Send a sample trace: This shows a curl example of sending a trace to New Relic. This is useful for understanding how the Trace API works, and to verify you're seeing data in New Relic. Report data from existing Zipkin instrumentation: if you have an existing Zipkin implementation, you can simply change the endpoint of where your data gets sent. Send sample Zipkin trace payload This section describes how to send a simple Zipkin-format trace to our Trace API via curl request. You might choose to do this in order to learn how our API works and to verify that data is showing up in New Relic before doing in-depth instrumentation. To get started sending a sample payload: (Optional, to enable Infinite Tracing) First, you must set up a trace observer. That procedure includes instructions for sending a sample trace using our general new-relic format. When you get to that step, return here to instead learn how to send a Zipkin-format trace. Send a Zipkin-format payload following the instructions below. Send Zipkin-format payload To send a sample Zipkin-format trace: Get an Insights insert key: Go to the API keys UI and select Insights insert keys. If you don't already have a key, create a new one by selecting Insert keys +. You'll be executing a curl request, below. Notes on this: Replace the insert key placeholder with your insert key. If you're using Infinite Tracing, use the YOUR_TRACE_OBSERVER_URL value in place of the standard endpoint. If you want to send more than one post, change the trace ID to a different value. Sending the same payload or span id multiple times for the same traceId may result in fragmented traces in the UI. curl -i -H 'Content-Type: application/json' \\ -H 'Api-Key: $NEW_RELIC_INSERT_KEY' \\ -H 'Data-Format: zipkin' \\ -H 'Data-Format-Version: 2' \\ -X POST \\ -d '[ { \"traceId\": \"test-zipkin-trace-id-1\", \"id\": \"3e0f5885710776cd\", \"kind\": \"CLIENT\", \"name\": \"post\", \"duration\": 508068, \"localEndpoint\": { \"serviceName\": \"service-1\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { } }, { \"traceId\": \"test-zipkin-trace-id-1\", \"parentId\": \"3e0f5885710776cd\", \"id\": \"asdf9asdn123lkasdf\", \"kind\": \"CLIENT\", \"name\": \"service 2 span\", \"duration\": 2019, \"localEndpoint\": { \"serviceName\": \"service-2\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"error.message\": \"Invalid credentials\" } } ]' 'https://trace-api.newrelic.com/trace/v1' Copy Within a minute, the trace should be available in the our distributed tracing UI. To find it, run a query for the trace.id. In this example, it was test-zipkin-trace-id-1. Note that you search by the transformed attribute of trace.id (not traceId). To learn more: Learn where Trace API data shows up in the UI. Send data from an existing Zipkin instrumentation. Learn how to decorate spans by adding tags. This helps you customize how traces are displayed in our UI for a richer, more helpful experience. Learn about general endpoint information (data limits, required metadata, and response validation). Learn about how Zipkin data is transformed and stored in our format. If you don't see your trace data, see Troubleshooting. Send data from existing Zipkin instrumentation Preliminary notes: If you want to enable Infinite Tracing, you first must set up a trace observer. It can be helpful to first send a sample payload to verify things are working properly. To report data from an existing Zipkin instrumentation, you'll point the Zipkin tracer at the appropriate Trace API endpoint with some required request metadata. You can send the required metadata as headers or query parameters (some Zipkin tracer versions don't allow specifying HTTP headers). Here's an example of what it might look like to create a Zipkin OkHttpSender in Java configured for the Trace API: OkHttpSender.create(\"https://trace-api.newrelic.com/trace/v1?Api-Key=NEW_RELIC_INSERT_API_KEY&Data-Format=zipkin&Data-Format-Version=2\"); Copy Note that if you were using Infinite Tracing, or had an EU-region New Relic account, the endpoint would be different. For an explanation of Api-Key and the other metadata, see Request metadata. Transformation of Zipkin data To create a consistent search/query experience, some Zipkin data will be transformed to match New Relic attribute naming. For more on how we store and structure trace data, see How distributed tracing works. Zipkin tag Stored in New Relic as... Details traceId trace.id Unique identifier for a trace. id id Unique identifier for a span. parentId parent.id Identifier of the upstream span that called the service. kind kind Either Client or Server. name name Name of span. duration duration.ms Zipkin v2 spans must have durations specified in microseconds, and will be converted to milliseconds. localEndpoint: serviceName service.name We use the Zipkin v2 service name to identify the entity that created this span. localEndpoint: port localEndpoint.port All values in the localEndpoint object will be flattened to a span attribute called localEndpoint.key tags reported as attributes Key:value pairs in the tags object in Zipkin v2 will be written as span attributes. annotations not supported We do not currently support annotations in the Trace API. Spans will not be rejected if they contain annotations, but the annotations data will not be written. Add other tags/attributes You can add any tags you want to the tags block, with the exception of the restricted tags. For example, you might want to add attributes like customer.id or user.id to help you analyze your trace data. Tags will be converted to New Relic attributes. To learn how to control how spans appear in New Relic (for example, adding errors or setting a span as a datastore span), see Decorate spans.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.25294,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report Zipkin-format <em>traces</em> via <em>Trace</em> <em>API</em>",
        "sections": "Report Zipkin-format <em>traces</em> via <em>Trace</em> <em>API</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": ", &quot;localEndpoint&quot;: { &quot;serviceName&quot;: &quot;service-2&quot;, &quot;ipv4&quot;: &quot;127.0.0.1&quot;, &quot;port&quot;: 8080 }, &quot;tags&quot;: { &quot;error.message&quot;: &quot;Invalid credentials&quot; } } ]&#x27; &#x27;https:&#x2F;&#x2F;<em>trace</em>-<em>api</em>.newrelic.com&#x2F;<em>trace</em>&#x2F;v1&#x27; Copy Within a minute, the <em>trace</em> should be available in the our <em>distributed</em> <em>tracing</em> UI. To find it, run a query"
      },
      "id": "6071cfc864441fa88f9d8530"
    },
    {
      "sections": [
        "Trace API: Decorate spans with attributes",
        "Why decorate your spans?",
        "How to decorate your spans with attributes",
        "JSON examples",
        "New Relic-format attribute examples",
        "Zipkin-format attribute examples"
      ],
      "title": "Trace API: Decorate spans with attributes",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "1e5d907a844f32e60b4cb7db4d7d1728a22adcde",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/trace-api-decorate-spans-attributes/",
      "published_at": "2021-06-14T18:07:42Z",
      "updated_at": "2021-04-10T16:18:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document will explain how to add attributes to trace data sent to the Trace API so that spans display specific properties in the UI. Why decorate your spans? When you send data to our Trace API, you can add custom attributes to spans. For example, you might decide to add attributes like customer.id or user.id in order to help you analyze your trace data. Some expected attribute values cause our distributed tracing UI to display some specific trace properties and details. For example, if a span has an attribute with an error. prefix, the UI displays that span with an error. For another example, a span with an attribute that has a db. prefix will be displayed as a datastore span in the UI, and will have its datastore query highlighted. Decorating your spans to show specific properties in our UI can help you: Better understand the structure of your trace data. More easily troubleshoot problems. How to decorate your spans with attributes This table explains how to get spans sent to the Trace API to show up with specific properties in the UI. For property descriptions, see span properties. Desired span property UI indicator How to add property Errors Use an attribute with an error. prefix. For example: error.message. External Use an attribute with an http. prefix. For example: http.method. A span will also appear as an external if it has a child that comes from a different entity. Datastore Use an attribute with an db. prefix. For example: db.statement. Service This cannot be done with an attribute. A span is classified as a service span if it's the root span, or if its parent is from a different entity. If a span has several properties, service span classification takes precedence in the UI. In-process This cannot be done with an attribute. A span is classified as in-process if it hasn't been classified as a service span, datastore span, or external span. For more on how these span properties are determined and stored, see Trace structure. Tips for adding attributes: You can add any attribute to a span. For example: you might add an attribute like customer.id so that you could search traces globally for traces containing a specific customer. A span can be in multiple categories. For example, external is a more general category than is datastore, so if a span is classified as both external and datastore, it will be indicated as a datastore span in the UI. JSON examples Here are JSON examples showing how to use attributes to set span properties: New Relic-format attribute examples New Relic-format JSON with multiple types of attributes added. The significance of the custom attributes is described in customAttribute. [ { \"common\": { \"attributes\": { \"hostname\": \"cattle456.example.com\", \"environment\": \"staging\" } }, \"spans\": [ { \"id\": \"1-abcdefg\", \"trace.id\": \"abc123-xyz789\", \"attributes\": { \"service.name\": \"Order Service\", \"duration.ms\": 3.5, \"error.name\": \"StackOverflowException\", \"name\": \"/placeOrder [POST]\", \"customer.id\": \"datanerd@newrelic.com\", \"description\": \"This span is the root of the whole trace. It has no parent.id. Custom attributes like 'customer.id' can have any name. Using these kinds of attributes will allow you to do a global search across all traces for desired traces.\" } }, { \"id\": \"2-abcdefg\", \"trace.id\": \"abc123-xyz789\", \"attributes\": { \"service.name\": \"Order Service\", \"duration.ms\": 1, \"parent.id\": \"1-abcdefg\", \"db.query\": \"foo selection\", \"db.statement\": \"SELECT FOO FROM BAR\", \"name\": \"DB Span\", \"description\": \"This is a datastore span. The presence of one or more attributes prefixed with db. makes this display as a datastore span in the UI.\" } }, { \"id\": \"3-abcdefg\", \"trace.id\": \"abc123-xyz789\", \"attributes\": { \"service.name\": \"Order Service\", \"parent.id\": \"1-abcdefg\", \"duration.ms\": 1.5, \"http.method\": \"POST\", \"name\": \"HTTP Span\", \"description\": \"An external (HTTP) span. Spans with one or more attributes prefixed with http. are treated as external spans.\" } }, { \"id\": \"4-abcdefg\", \"trace.id\": \"abc123-xyz789\", \"attributes\": { \"service.name\": \"Order Service\", \"duration.ms\": 1.2, \"error.text\": \"404 file not found\", \"parent.id\": \"1-abcdefg\", \"http.method\": \"GET\", \"http.statusCode\": 404, \"name\": \"Error Http Span\", \"description\": \"Spans with error. prefixed attributes are displayed in red text in the UI. Errors can coexist with other span categories.\" } }, { \"id\": \"5-abcdefg\", \"trace.id\": \"abc123-xyz789\", \"attributes\": { \"service.name\": \"Order Service\", \"error.message\": \"404 file not found\", \"duration.ms\": 1.2, \"parent.id\": \"1-abcdefg\", \"http.method\": \"GET\", \"http.statusCode\": 404, \"db.query\": \"SELECT FOO FROM BAR\", \"name\": \"Error Http DB Span\", \"description\": \"Spans can have multiple properties. Relevant attributes are highlighted when you select a span to view its details.\" } }, { \"id\": \"6-abcdefg\", \"trace.id\": \"abc123-xyz789\", \"attributes\": { \"service.name\": \"Order Service\", \"duration.ms\": 1.6, \"parent.id\": \"1-abcdefg\", \"http.method\": \"GET\", \"db.query\": \"SELECT FOO FROM BAR\", \"name\": \"Http DB Span\", \"description\": \"External (HTTP) is a more general category than is datastore, so a span with both http.- and db.-prefixed attributes is displayed as a datastore span in the UI.\" } }, { \"id\": \"7-abcdefg\", \"trace.id\": \"abc123-xyz789\", \"attributes\": { \"service.name\": \"Order Service\", \"duration.ms\": 2.0, \"parent.id\": \"1-abcdefg\", \"description\": \"Spans with no explicit types that belong to the same entity as its parent and children are considered in-process spans.\", \"name\": \"In-process span 1\" } }, { \"id\": \"8-abcdefg\", \"trace.id\": \"abc123-xyz789\", \"attributes\": { \"service.name\": \"Order Service\", \"duration.ms\": 1.7, \"parent.id\": \"7-abcdefg\", \"name\": \"In-process span 2\", \"description\": \"In-process spans can represent a breakdown of work being done within a process.\" } }, { \"id\": \"9-abcdefg\", \"trace.id\": \"abc123-xyz789\", \"attributes\": { \"service.name\": \"Order Service\", \"duration.ms\": 1.0, \"parent.id\": \"8-abcdefg\", \"name\": \"In-process span 3\", \"description\": \"The number and granularity of in-process spans vary depending on instrumentation and frameworks being used.\" } }, { \"id\": \"10-abcdefg\", \"trace.id\": \"abc123-xyz789\", \"attributes\": { \"service.name\": \"Order Service\", \"duration.ms\": 2.2, \"parent.id\": \"1-abcdefg\", \"name\": \"In-process span\" } }, { \"id\": \"11-abcdefg\", \"trace.id\": \"abc123-xyz789\", \"attributes\": { \"service.name\": \"Order Service\", \"duration.ms\": 2.2, \"parent.id\": \"10-abcdefg\", \"name\": \"External determined by entity change\", \"description\": \"A span that’s a parent to a span from another entity is displayed as an external span in the UI.\" } }, { \"id\": \"12-abcdefg\", \"trace.id\": \"abc123-xyz789\", \"attributes\": { \"service.name\": \"Order Notification Service\", \"duration.ms\": 1.8, \"parent.id\": \"11-abcdefg\", \"name\": \"Entry span determined by entity change\", \"description\": \"The attribute 'service.name' is used to detect process boundaries in the UI. For compatibility with data from Lambda monitoring and APM agents, the attribute 'entity.name' can be used to search across all traces.\" } } ] } ] Copy Zipkin-format attribute examples Zipkin-format JSON with multiple attribute types added. The significance of the attributes (key-value pairs) is described in customAttribute. [ { \"traceId\": \"zipkinSampleTrace\", \"id\": \"1\", \"kind\": \"SERVER\", \"name\": \"Error Span\", \"duration\": 35000, \"localEndpoint\": { \"serviceName\": \"sampleApp\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"customAttribute\": \"This span is the root of the whole trace. It has no parent.id\" } }, { \"traceId\": \"zipkinSampleTrace\", \"id\": \"2\", \"parentId\": \"1\", \"kind\": \"SERVER\", \"name\": \"post\", \"duration\": 10000, \"localEndpoint\": { \"serviceName\": \"sampleApp\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"customAttribute\": \"This is a datastore span. The presence of one or more attributes prefixed with db. makes this display as a datastore span in the UI.\" } }, { \"traceId\": \"zipkinSampleTrace\", \"id\": \"2\", \"parentId\": \"1\", \"kind\": \"CLIENT\", \"name\": \"DB Span\", \"duration\": 12000, \"localEndpoint\": { \"serviceName\": \"sampleApp\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"db.query\": \"foo selection\", \"db.statement\": \"SELECT FOO FROM BAR\", \"customAttribute\": \"This is a datastore span. The presence of one or more attributes prefixed with db. makes this display as a datastore span in the UI.\" } }, { \"traceId\": \"zipkinSampleTrace\", \"id\": \"3\", \"parentId\": \"1\", \"kind\": \"CLIENT\", \"name\": \"HTTP Span\", \"duration\": 15000, \"localEndpoint\": { \"serviceName\": \"sampleApp\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"http.method\": \"POST\", \"customAttribute\": \"AAn external (HTTP) span. Spans with one or more attributes prefixed with http. are treated as external spans.\" } }, { \"traceId\": \"zipkinSampleTrace\", \"id\": \"4\", \"parentId\": \"1\", \"kind\": \"CLIENT\", \"name\": \"Error Span\", \"duration\": 12000, \"localEndpoint\": { \"serviceName\": \"sampleApp\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"error.message\": \"404 file not found\", \"http.method\": \"GET\", \"http.statusCode\": 404, \"customAttribute\": \"Spans with error. prefixed attributes are displayed in red text in the UI. Errors can coexist with other span categories.\" } }, { \"traceId\": \"zipkinSampleTrace\", \"id\": \"5\", \"parentId\": \"1\", \"kind\": \"CLIENT\", \"name\": \"HTTP Error DB Span\", \"duration\": 12000, \"localEndpoint\": { \"serviceName\": \"sampleApp\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"error.message\": \"404 file not found\", \"http.method\": \"GET\", \"http.statusCode\": 404, \"db.query\": \"SELECT FOO FROM BAR\", \"customAttribute\": \"Spans can have multiple properties. Relevant attributes are highlighted when you select a span to view its details.\" } }, { \"traceId\": \"zipkinSampleTrace\", \"id\": \"6\", \"parentId\": \"1\", \"kind\": \"CLIENT\", \"name\": \"HTTP DB Span\", \"duration\": 12000, \"localEndpoint\": { \"serviceName\": \"sampleApp\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"http.method\": \"GET\", \"db.query\": \"SELECT FOO FROM BAR\", \"customAttribute\": \"External (HTTP) is a more general category than is datastore, so a span with both http.- and db.-prefixed attributes is displayed as a datastore span in the UI.\" } }, { \"traceId\": \"zipkinSampleTrace\", \"id\": \"7\", \"parentId\": \"1\", \"kind\": \"SERVER\", \"name\": \"In process span 1\", \"duration\": 12000, \"localEndpoint\": { \"serviceName\": \"sampleApp\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"customAttribute\": \"Spans with no explicit types that belong to the same entity as its parent and children are considered in-process spans.\" } }, { \"traceId\": \"zipkinSampleTrace\", \"id\": \"8\", \"parentId\": \"7\", \"kind\": \"SERVER\", \"name\": \"In process span 2\", \"duration\": 12000, \"localEndpoint\": { \"serviceName\": \"sampleApp\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"customAttribute\": \"In-process spans can represent a breakdown of work being done within a process.\" } }, { \"traceId\": \"zipkinSampleTrace\", \"id\": \"9\", \"parentId\": \"8\", \"kind\": \"SERVER\", \"name\": \"In process span 2\", \"duration\": 12000, \"localEndpoint\": { \"serviceName\": \"sampleApp\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"customAttribute\": \"The number and granularity of in-process spans vary depending on instrumentation and frameworks being used.\" } }, { \"traceId\": \"zipkinSampleTrace\", \"id\": \"10\", \"parentId\": \"1\", \"kind\": \"CLIENT\", \"name\": \"In process remote parent\", \"duration\": 12000, \"localEndpoint\": { \"serviceName\": \"sampleApp\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"name\": \"in process remote parent\" } }, { \"traceId\": \"zipkinSampleTrace\", \"id\": \"10\", \"parentId\": \"1\", \"kind\": \"CLIENT\", \"name\": \"In process remote parent\", \"duration\": 12000, \"localEndpoint\": { \"serviceName\": \"sampleApp\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"customAttribute\": \"A span that is a parent to a span from another entity will be displayed as an external span.\" } }, { \"traceId\": \"zipkinSampleTrace\", \"id\": \"11\", \"parentId\": \"10\", \"kind\": \"SERVER\", \"name\": \"Downstream entry span\", \"duration\": 12000, \"localEndpoint\": { \"serviceName\": \"downstreamSampleApp\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"customAttribute\": \"The attribute 'service.name' is used to detect process boundaries in the UI. For compatibility with data from Lambda monitoring and APM agents, the attribute 'entity.name' can be used to search across all traces.\" } } ] Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.25294,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Trace</em> <em>API</em>: Decorate spans with attributes",
        "sections": "<em>Trace</em> <em>API</em>: Decorate spans with attributes",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " customer.id or user.id in order to help you analyze your <em>trace</em> data. Some expected attribute values cause our <em>distributed</em> <em>tracing</em> UI to display some specific <em>trace</em> properties and details. For example, if a span has an attribute with an error. prefix, the UI displays that span with an error. For another"
      },
      "id": "6071cfc8196a678ed764a7b2"
    }
  ],
  "/docs/distributed-tracing/troubleshooting/infinite-tracing-trace-configuration-conflicts": [
    {
      "sections": [
        "Trace API general requirements and limits",
        "Endpoints",
        "Data formats",
        "Data limits",
        "Restricted attributes",
        "Request metadata (headers and query parameters)",
        "Important",
        "Response validation",
        "See HTTP status codes",
        "Exceeding span limits"
      ],
      "title": "Trace API general requirements and limits ",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "f77504082dae8374e0c7009a31abebbd4c0123f3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/trace-api-general-requirements-limits/",
      "published_at": "2021-06-14T18:07:42Z",
      "updated_at": "2021-06-09T00:57:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Information about Trace API data requirements, including: Data specifications and max limits Required metadata (headers, query parameters) Response validation details This document applies to the Trace API overall. For rules regarding specific data formats, see: New Relic-format trace data Zipkin-format trace data Endpoints All trace data is sent via a POST to a Trace API endpoint. We have a few endpoints, depending on your setup: Default Trace API endpoint: https://trace-api.newrelic.com/trace/v1 EU data centers: https://trace-api.eu.newrelic.com/trace/v1 (see other EU endpoints). Infinite Tracing: when you complete the Trace observer setup, you get a custom YOUR_TRACE_OBSERVER_URL value to use as an endpoint. If you're using an integration that uses the Trace API (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust the sampling of your tracing service to send us 100% of spans. For FedRAMP, see FedRAMP endpoints. Data formats Currently, the Trace API accepts two types of data formats: zipkin: For reporting Zipkin trace data. Zipkin data must be Zipkin JSON v2. newrelic: For reporting all other trace data. Data limits Data limits and rules: Condition Limit Max age of span timestamp values 20 minutes. timestamp must be within 20 minutes of current time at ingest, or within 20 minutes from the time the last span with the same trace.id was received by New Relic. Max payload size 1MB (10^6 bytes) (gzip compression supported) Max requests per minute 100K Max spans per minute per account family Dependent on agreement. Max limit: 2M. Max spans per trace 50K Max attributes per span 200 Max span attribute value length 4000 characters Allowed HTTP protocols HTTPS only Cross-account visibility of span details Potential data obfuscation To see an example of how span limits are enforced, see Exceeding limits. Restricted attributes The attributes in the table below are restricted in the newrelic-format JSON (in the attributes block) and in the zipkin-format JSON (in the tags block). Any values with these keys will be omitted: Restricted attribute Description entityGuid string Unique identifier for the entity that created this span. Generated from service.name, if available. guid string Used for backwards compatibility with data from APM agents. The attributes in the table below are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Restricted attribute description entity.guid string Unique identifier for the entity associated with this span. entity.name string Human-readable name of an entity, often used to identify an entity in the UI. entity.type string Used to differentiate between different types of entities, like hosts, applications, etc. Request metadata (headers and query parameters) The following table shows the required request metadata for all trace data formats. This metadata can be sent as HTTP headers on an ingest request or, in some cases, provided as query parameters, which may be required for tracing frameworks that don't allow header modification. Important Security note: We suggest using headers because query parameters are present in the URL and may be logged before being encrypted and received by New Relic. All data sent as query parameters must be URL-safe. Header Query param? Details Content-Type No Required. Must be application/json. Content-Length No Required. The length of the request body in octets (8-bit bytes) unless sent with chunked encoding. This header is generally set by default by the underlying HTTP client sending the data and in most cases should not require any additional effort by the end user. Api-Key Yes (case-sensitive) Required. The Trace API requires the Insights insert key. If this is provided as both a header and a query parameter, the values must match. Content-Encoding No Required if compressed payload. The value must be gzip. Data-Format Yes Required for zipkin. Optional for newrelic. If present, Data-Format-Version must also be present. Data-Format-Version Yes Required for zipkin. If present, Data-Format must also be present. There are only two possible pairings for these values: If Data-Format is zipkin, Data-Format-Version must be 2. If Data-Format is newrelic, Data-Format-Version must be 1. x-request-id No Optional - Reserved for future use. The value must be a valid UUID4. The value is expected to be unique for each request. Response validation A response for successfully sending trace data will include a requestId. For example: {\"requestId\":\"c1bb62fc-001a-b000-0000-016bb152e1bb\"} Copy There are two ways success/errors are signaled: HTTP status code (synchronous). Authentication and request errors will be signaled via HTTP status code. See HTTP status codes Code Meaning 202 Data accepted. This means that you've passed preliminary checks, but is not a guarantee that the data has been successfully parsed and indexed as part of a distributed trace. 400 The structure of the request was invalid. Errors with query parameters, etc. 403 Authentication error. May occur with an invalid license key or if you lack necessary entitlement to use the Trace API. 404 The request path is incorrect. 405 For any request method other than POST. 408 The request took too long to reach the endpoint. 411 The Content-Length header wasn’t included. 413 The payload was too big. 414 The request URI was too long. 415 The Content-Type or Content-Encoding was invalid. 429 The request rate quota has been exceeded. 431 The request headers are too long. 5xx There was a server error (please retry). NrIntegrationError events (asynchronous). Errors with the JSON payload or other semantic errors are asynchronously signaled via NrIntegrationError events that are stored in the account whose license key is associated with the request. For all errors of this type, the attribute newRelicFeature will be Distributed Tracing and requestId will be the requestId from the endpoint response. If you receive a 202 response and don't see an NrIntegrationError event, your data should be visible in New Relic One's global distributed tracing UI in about a minute. You should be able to find the trace using a standard trace search like: traceId = TRACE_ID_SENT Copy Exceeding span limits When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate limit messages with this NRQL: SELECT * FROM NrIntegrationError WHERE newRelicFeature = 'Distributed Tracing' AND category = 'RateLimit' AND rateLimitType = 'SpansPerMinute' Copy To get a notification when you exceed the limit, you can set up a NRQL alert. We calculate a rolling 10-minute average based on your span rate limit. This allows for temporary rate bursts, and lets us prioritize keeping and dropping complete traces instead of indiscriminately dropping spans on a per minute limit basis. In the example below of exceeding the rate, the rate limit is the default 100,000 spans per minute. New Relic allows a burst above 100K for a couple of minutes without downsampling, because the remaining minutes in the 10-minute window averaged under 100K spans/minute. For the previous 10 minutes (8:50 - 9:00) the service received 60,000 spans/minute. Minute Spans sent to API Total for past 10 minutes 8:59 60,000 600,000 9:00 40,000 580,000 9:01 50,000 570,000 9:02 250,000 760,000 9:03 220,000 920,000 9:04 125,000 985,000 9:05 70,000 995,000 9:06 50,000 985,000 9:07 40,000 965,000 9:08 40,000 945,000 9:09 40,000 925,000",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 206.8027,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Trace</em> API general requirements and limits ",
        "sections": "<em>Trace</em> API general requirements and limits",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " be visible in New Relic One&#x27;s global <em>distributed</em> <em>tracing</em> UI in about a minute. You should be able to find the <em>trace</em> using a standard <em>trace</em> search like: <em>trace</em>Id = <em>TRACE</em>_ID_SENT Copy Exceeding span limits When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate"
      },
      "id": "6071cf7628ccbcf8b851c158"
    },
    {
      "sections": [
        "Distributed tracing: Planning guide",
        "Impact to APM features",
        "External services page has less detail",
        "Transaction trace UI displays service URLs, not transaction links",
        "Cross-application tracing will be disabled",
        "Impacts related to mobile monitoring",
        "Plan your rollout",
        "Enable distributed tracing"
      ],
      "title": "Distributed tracing: Planning guide",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "10263f2b6ec929f082153e28cbce07fe3a1f106a",
      "image": "https://docs.newrelic.com/static/7072dfa9e494767baabba420d78e7094/c1b63/distributed-trace-txn-trace-affects.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/distributed-tracing-planning-guide/",
      "published_at": "2021-06-14T18:03:44Z",
      "updated_at": "2021-05-28T11:44:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you are new to New Relic distributed tracing, we recommend you read the following before you enable distributed tracing. Impact to APM features Our distributed tracing improves on APM's previous cross application tracing feature. Here are some key benefits: See more cross-service activity details and more complete end-to-end traces. Filter and query traces, as well as make custom charts. See the complete trace even when calls cross account boundaries (for accounts with the same master account or in the same customer partnership). See Introduction to distributed tracing for other features. Enabling distributed tracing may affect some APM features you currently use. These changes affect only applications monitored by agents that have distributed tracing enabled—they don't apply on an account-level. We may provide backward compatibility with some or all of the affected features in future releases. For now, you should understand the following changes before enabling distributed tracing: External services page has less detail When distributed tracing is enabled for an application, external calls do not have internal transaction details at one.newrelic.com > APM > (select an app) > Monitor > External services > (select external service). To find that information, you would instead go to the Distributed tracing UI page, find the external call URLs, and see what their child spans are. Transaction trace UI displays service URLs, not transaction links When distributed tracing is enabled for an application, the transaction trace UI will no longer have the transaction name and link for the called service (see screenshot below). This will be replaced with the called service's URL. one.newrelic.com > APM > (select an app) > Monitor > Transactions > (select a transaction trace): This shows the transaction trace UI before distributed tracing is enabled, with a link to the associated transaction. With distributed tracing enabled, it will display the service's URL. If you wanted to get more detail about trace activity, you would go to the Distributed tracing UI page and examine that trace. Cross-application tracing will be disabled Enabling distributed tracing will disable the cross application tracing feature. Distributed tracing is an improved version of cross-application tracing and only one can be enabled at a time. Impacts related to mobile monitoring APM-related impacts include: When distributed tracing is enabled for an APM-monitored entity, legacy service maps will not show applications monitored by mobile. The App server drill-down feature of the legacy Mobile HTTP requests UI page is not available. Plan your rollout If you're enabling distributed tracing for a large, distributed system, here are some tips: If you are a current APM user, see Impact to APM features. Determine the requests that are the most important for your business, or the most likely to require analysis and troubleshooting, and enable distributed tracing for those services. Enable tracing for services at roughly the same time so you can more easily gauge how complete your end-to-end traces are. When you look at traces in the distributed tracing UI, you'll see spans in the trace for external calls to other services. Then, you can enable distributed tracing for any of those services you want. If a service is fairly standalone and not often used in context with other services, you may not want to enable distributed tracing for it. Here's a visual representation of such a phased roll-out: If you are using APM for a large, monolithic service, there may be many sub-process spans per trace and APM limits may result in fewer traces than expected. You can solve this by using APM agent instrumentation to disable the reporting of unimportant data. Distributed tracing works by propagating header information from service to service in a request path. Some services may communicate through a proxy or other intermediary service that does not automatically propagate the header. In that case, you will need to configure that proxy so that it allows the newrelic header value to be propagated from source to destination. Enable distributed tracing If you are aware of the impact to APM features and have thought about your rollout, you are ready to set up distributed tracing. See Overview: Enable distributed tracing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 203.91891,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Distributed</em> <em>tracing</em>: Planning guide",
        "sections": "<em>Distributed</em> <em>tracing</em>: Planning guide",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " details and more complete end-to-end traces. Filter and query traces, as well as make custom charts. See the complete <em>trace</em> even when calls cross account boundaries (for accounts with the same master account or in the same customer partnership). See Introduction to <em>distributed</em> <em>tracing</em> for other features"
      },
      "id": "6072a60564441f3a629d8535"
    },
    {
      "sections": [
        "Understand and use the distributed tracing UI",
        "Open the distributed tracing UI",
        "View traces for a specific service",
        "View traces across all accounts",
        "Tip",
        "Find traces that are useful",
        "Filter using the query bar",
        "Find traces that touch two services",
        "Find error spans using the like operator",
        "Trace groups",
        "Filter using the scatter plot",
        "Filters",
        "Trace histograms",
        "Important",
        "Trace details UI page",
        "Span details pane",
        "View related logs",
        "Additional UI details",
        "How to understand span errors",
        "Anomalous spans",
        "Client span duration: time differences between client and server spans",
        "Fragmented traces",
        "Trace details obfuscated based on account access",
        "Span limits and sampling",
        "Incomplete span names in waterfall view",
        "Missing spans and span/service count discrepancies"
      ],
      "title": "Understand and use the distributed tracing UI",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "f5b66e03583e42613810f1390b4e5adab4ed2caa",
      "image": "https://docs.newrelic.com/static/ec08996f31e6586bb257c6f89b3c8f99/e5166/new-relic-distributed-tracing-client-span-time.jpg",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/understand-use-distributed-tracing-ui/",
      "published_at": "2021-06-14T18:10:30Z",
      "updated_at": "2021-06-02T17:03:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing helps you monitor and analyze the behavior of your distributed system. After you enable distributed tracing, you can use our UI tools to search for traces and analyze them. For example, let's say you are an engineer troubleshooting errors in a complex transaction spanning many services. Here's what you can do in our UI: Open the distributed tracing UI page. Sort through your traces using a filter to find that specific request and show only traces containing errors. On the trace details page, you review the span along the request route that originated the error. Noting the error class and message, navigate to the service from its span in the trace so you can see that the error is occurring at a high rate. Read on to explore the options in the distributed tracing UI. Open the distributed tracing UI Here's how you can access the distributed tracing UI, depending on the type of search you want to do: View traces for a specific service The New Relic Explorer and APM are two menu options that help you navigate to a specific service so you can see traces that include that service. Go to one.newrelic.com. Click Explorer or APM in the top menu bar. Filter to the service you enabled for distributed tracing by typing the service name, and then press Enter. In the left navigation's Monitor section, click Distributed tracing. View traces across all accounts If you want to view traces from across all accounts you have access to, go to one.newrelic.com, click Browse data, and then Traces. Tip If you don't have access to accounts for some services in a trace, we'll obfuscate some details for those services. Find traces that are useful We have a variety of tools to help you find traces and spans so you can resolve issues. The opening distributed tracing page is populated with a default list of traces, and you can quickly refine this list using these tools: Query bar Trace groups Scatter plot chart Filters Interactive histograms Tip In addition to these tools, you can also use other options mentioned in Query distributed trace data. Filter using the query bar The Find traces query bar is a quick way to narrow your search for traces. You can either start typing in the query bar or use the dropdown to create a compound query. Query returns are based on span attributes, not on trace attributes. You define spans that have certain criteria, and the search displays traces that contain those spans. If you use a multi-attribute filter, it is affected by first attribute selected. Distributed tracing reports on two types of data: transaction events and spans. When you select an attribute in the filter, the data type that attribute is attached to dictates the available attributes. For example, if you filter on an attribute that is attached to a transaction event, only transaction event attributes are available when you attempt to add filter on additional attribute values. Queries for traces are similar to NRQL (our query language). Here are the main exceptions: String values don't require quote marks (for example, you can use either appName = MyApp or appName = 'MyApp') The like operator doesn’t require % (for example, you can use either appName like product or appName like %product%). Tip Some queries that return a large number of results may return false positives. The trace list limits these incorrect results to 10% of the returned results. False positives may also result in histogram chart results that are not displayed in the trace list. Here are two query bar examples: Find traces that touch two services The query in the image below finds traces that: Pass through both WebPortal and Inventory Service applications Have an Inventory Service datastore call that takes longer than 500 ms Contains an error in any span. Go to one.newrelic.com > Apps > Distributed tracing Find error spans using the like operator The query in the image below finds traces that: Contain spans that pass through the WebPortal application and where an error occurred on any span in the WebPortal application Contain spans where the customer_user_email attribute contains a value ending with hotmail.com anywhere in the trace. Go to one.newrelic.com > Apps > Distributed tracing Trace groups The default view of distributed tracing shows traces grouped by the same root entry span. In other words, traces are grouped by the span where New Relic began recording the request. You can slide the toggle Group similar traces to turn this on and off. With trace groups you get a high-level view of traces so you can understand request behavior for groups of similar traces. This helps you understand dips or spikes in trace count, duration, and errors. When you click on one of the trace groups, you get all the standard details in context of the specific trace group you selected. Filter using the scatter plot The trace scatter plot is a quick way to search for outlying traces. This is available on the opening page of distributed tracing if you turn off the Group similar traces toggle at the top of the page. In the scatter plot, you can move the cursor across the chart to view trace details and you can click individual points to get details: Here's how you can control what's displayed in the scatter plot: In the View by dropdown, select the duration type: Back-end duration Root span duration Trace duration In Group traces by, select one of these options: Errors: Group by whether or not traces contain errors. Root service: Group by the name of the first service in traces. In a trace where Service A calls Service B and Service B calls Service C, the root service would be Service A. Root entry span: Group by the root transaction, which is the root service's endpoint. In a trace where Service A calls Service B and Service B calls Service C, the root entry span is Service A's endpoint. For example: \"Service A - GET /user/%\". Service entry span: Group by the span name of the service currently being viewed in APM. For example, for a trace where Service A calls Service B and Service B calls Service C, if you're viewing Service B in APM and select this grouping, the traces will be represented by their Service B span names. If a service has multiple spans in a trace, this grouping option will use that service's first entry point. Filters In the left pane, you can filter traces by multi-span traces, specific entities, or error types. Once you select a filter, only traces associated with that specific type are displayed. This makes it much easier to view the traces you're most interested in so you can find and fix issues faster. Trace histograms The histogram charts give you a quick understanding of trace distribution for important values, such as duration. Click Show filters at the bottom of the left pane to display the histograms. When you move the histogram sliders, they change the data displayed in the scatterplot or the trace group charts. For example, you can drag the Trace duration chart slider to show only traces over 500 ms, as shown in the histogram example below. Important Some queries that produce many results may result in false positives in histograms. This could manifest as histograms showing trace results that are not in the trace list. Trace details UI page When you select a trace from the trace list, you see that trace's timeline and spans: one.newrelic.com > APM > (select an application) > Monitor > Distributed tracing > (select a trace) > (select a span): See the spans in a trace. Examine individual span details and see notifications for spans with anomalous behavior. The UI indicates some span properties with icons: Span property Indicator Description Service This icon represents a span that's a service's entry point. In-process This icon represents an in-process span, which is a span that takes place within a process (as opposed to a cross-process span). Examples: middleware instrumentation, user-created spans. Datastore This icon represents a span call to a datastore. External This icon represents category representing a call to an external service made via HTTP. Browser app This icon represents a browser application span. Lambda This icon represents a span from a Lambda function. Some spans will have additional indicators: Span property Indicator Description Type of connection Solid lines indicate a direct parent-child relationship; in other words, one process or function directly calling another. A dotted line indicates a non-direct relationship. For more on relationships between spans, see Trace structure. Errors A span with an error. See How to understand span errors. Anomalous This icon represents the detection of an anomalous span. Orphaned spans Some spans may be \"orphaned,\" or separated, from the trace. These spans will appear at the bottom of the trace. For more details, see Fragmented traces. Multiple app names When beside a span name, this represents an entity that has had multiple app names set. Select this to see all app names it reports to. To search trace data by alternate app names, use the appName attribute. Client/server time difference If a span's duration indicator is not completely colored in (like in this example), it means that there is a time discrepancy between the server-side duration and the client-side duration for that activity. For details on this, see Client/server time difference. For more on the trace structure and how span properties are determined, see Trace structure. Span details pane When you select a span, a pane opens up with span details. These details can be helpful for troubleshooting performance issues. Details include: Performance charts Span attributes The span's data source Anomalous span details The span's full name What a span displays is based on its span type. For example, a datastore span's name attribute will contain the datastore query. View related logs If you are using our logs in context feature together with our log management, you can see any logs that are linked to your traces: Go to the trace details page by clicking on a trace. Click See logs in the upper-right corner. For details related to an individual log message, click directly on the message. Additional UI details Here are some additional distributed tracing UI details, rules, and limits: How to understand span errors Span-level errors show you where errors originated in a process, how they bubbled up, and where they were handled. Every span that ends with an exception is shown with an error in the UI and contributes to the total error count for that trace. Here are some general tips about understanding span errors: Spans with errors are highlighted red in the distributed tracing UI. You can see more information on the Error Details pane for each span. All spans that exit with errors are counted in the span error count. When multiple errors occur on the same span, only one is written to the span in this order of precedence: A noticeError The most recent span exception This table describes how different span errors are handled: Error type Description Spans ending in exceptions An exception that leaves the boundary of a span results in an error on that span and on any ancestor spans that also exit with an error, until the exception is caught or exits the transaction. You can see if an exception is caught in an ancestor span. Notice errors Errors noticed by calls to the agent noticeError API or by the automatic agent instrumentation are attached to the currently executing span. Response code errors Response code errors are attached to the associated span, such as: Client span: External transactions prefixed with http or db. Entry span: In the case of a transaction ending in a response code error. The response code for these spans is captured as an attribute httpResponseCode and attached to that span. Anomalous spans If a span is displayed as anomalous in the UI, it means that the following are both true: The span is more than two standard deviations slower than the average of all spans with the same name from the same service over the last six hours. The span's duration is more than 10% of the trace's duration. Client span duration: time differences between client and server spans When a process calls another process, and both processes are instrumented by New Relic, the trace contains both a client-side representation of the call and a server-side representation. The client span (calling process) can have time-related differences when compared to the server span (called process). These differences could be due to: Clock skew, due to system clock time differences Differences in duration, due to things like network latency or DNS resolution delay The UI shows these time-related differences by displaying an outline of the client span in the same space as the server span. This span represents the duration of the client span. It isn't possible to determine every factor contributing to these time-related discrepancies, but here are some common span patterns and tips for understanding them: When a client span is longer than the server span, this could be due to latency in a number of areas, such as: network time, queue time, DNS resolution time, or from a load balancer that we cannot see. When a client span starts and ends before a server span begins, this could be due to clock skew, or due to the server doing asynchronous work that continues after sending the response. When a client span starts after a server span, this is most likely clock skew. Fragmented traces Fragmented traces are traces with missing spans. When a span is missing or has invalid parent span IDs, its children spans become separated from the rest of the trace, which we refer to as \"orphaned.\" Orphaned spans appear at the bottom of the trace, and they will lack connecting lines to the rest of the trace. Types of orphaned span properties indicated in the UI: No root span. Missing the root span, which is the first operation in the request. When this happens, the span with the earliest timestamp is displayed as the root. Orphaned span. A single span with a missing parent span. This could be due to the parent span having an ID that doesn't match its child span. Orphaned trace fragment. A group of connected spans where the first span in the group is an orphan span. This can happen for a number of reasons, including: Collection limits. Some high-throughput applications may exceed collection limits (for example, APM agent collection limits, or API limits). When this happens, it may result in traces having missing spans. One way to remedy this is to turn off some reporting, so that the limit is not reached. Incorrect instrumentation. If an application is instrumented incorrectly, it won't pass trace context correctly and this will result in fragmented traces. To remedy this, examine the data source that is generating orphan spans to ensure instrumentation is done correctly. To discover a span's data source, select it and examine its span details. Spans still arriving. If some parent spans haven't been collected yet, this can result in temporary gaps until the entire trace has reported. UI display limits. Orphaned spans may result if a trace exceeds the 10K span display limit. Trace details obfuscated based on account access If you don’t have access to the New Relic accounts that monitor other services, some of the span and service details will be obfuscated in the UI. Obfuscation can include: Span name concealed by asterisks Service name replaced with New Relic account ID and app ID The two main factors affecting this obfuscation: Account permissions. Master/sub-account relationships will impact access. If you have access to only a sub-account, you’ll be able to see details for only that sub-account. If you have access to a master account, you’ll be able to see details for that account’s sub-accounts. Authentication. You’ll be able to see span details only for New Relic accounts you can access based on your current login. This means that, for example, even the admin of a master account may not be able to see all details if the trace crosses the boundaries of different authentication mechanisms. Span limits and sampling See Sampling. Incomplete span names in waterfall view When viewing the span waterfall, span names may be displayed in an incomplete form that is more human-readable than the complete span name. To find the complete name, select that span and look for the Full span name. Knowing the complete name can be valuable for querying that data with NRQL. Missing spans and span/service count discrepancies A trace may sometimes have (or seem to have) missing spans or services. This can manifest as a discrepancy between the count of a trace's spans or services displayed in the trace list and the count displayed on the trace details page. Reasons for missing spans and count discrepancies include: An APM agent may have hit its 1K span collection limit. A span may be initially counted but not make it into a trace display, for reasons such as network latency or a query issue. The UI may have hit its 10K span display limit. All spans collected, including those not displayed, can be queried with NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.289,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Understand</em> and use the <em>distributed</em> <em>tracing</em> UI",
        "sections": "<em>Understand</em> and use the <em>distributed</em> <em>tracing</em> UI",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "<em>Distributed</em> <em>tracing</em> helps you monitor and analyze the behavior of your <em>distributed</em> system. After you enable <em>distributed</em> <em>tracing</em>, you can use our UI tools to search for traces and analyze them. For example, let&#x27;s say you are an engineer <em>troubleshooting</em> errors in a complex transaction spanning many"
      },
      "id": "6072a70028ccbc265a51c13d"
    }
  ],
  "/docs/distributed-tracing/troubleshooting/missing-trace-data": [
    {
      "sections": [
        "Trace API general requirements and limits",
        "Endpoints",
        "Data formats",
        "Data limits",
        "Restricted attributes",
        "Request metadata (headers and query parameters)",
        "Important",
        "Response validation",
        "See HTTP status codes",
        "Exceeding span limits"
      ],
      "title": "Trace API general requirements and limits ",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "f77504082dae8374e0c7009a31abebbd4c0123f3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/trace-api-general-requirements-limits/",
      "published_at": "2021-06-14T18:07:42Z",
      "updated_at": "2021-06-09T00:57:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Information about Trace API data requirements, including: Data specifications and max limits Required metadata (headers, query parameters) Response validation details This document applies to the Trace API overall. For rules regarding specific data formats, see: New Relic-format trace data Zipkin-format trace data Endpoints All trace data is sent via a POST to a Trace API endpoint. We have a few endpoints, depending on your setup: Default Trace API endpoint: https://trace-api.newrelic.com/trace/v1 EU data centers: https://trace-api.eu.newrelic.com/trace/v1 (see other EU endpoints). Infinite Tracing: when you complete the Trace observer setup, you get a custom YOUR_TRACE_OBSERVER_URL value to use as an endpoint. If you're using an integration that uses the Trace API (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust the sampling of your tracing service to send us 100% of spans. For FedRAMP, see FedRAMP endpoints. Data formats Currently, the Trace API accepts two types of data formats: zipkin: For reporting Zipkin trace data. Zipkin data must be Zipkin JSON v2. newrelic: For reporting all other trace data. Data limits Data limits and rules: Condition Limit Max age of span timestamp values 20 minutes. timestamp must be within 20 minutes of current time at ingest, or within 20 minutes from the time the last span with the same trace.id was received by New Relic. Max payload size 1MB (10^6 bytes) (gzip compression supported) Max requests per minute 100K Max spans per minute per account family Dependent on agreement. Max limit: 2M. Max spans per trace 50K Max attributes per span 200 Max span attribute value length 4000 characters Allowed HTTP protocols HTTPS only Cross-account visibility of span details Potential data obfuscation To see an example of how span limits are enforced, see Exceeding limits. Restricted attributes The attributes in the table below are restricted in the newrelic-format JSON (in the attributes block) and in the zipkin-format JSON (in the tags block). Any values with these keys will be omitted: Restricted attribute Description entityGuid string Unique identifier for the entity that created this span. Generated from service.name, if available. guid string Used for backwards compatibility with data from APM agents. The attributes in the table below are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Restricted attribute description entity.guid string Unique identifier for the entity associated with this span. entity.name string Human-readable name of an entity, often used to identify an entity in the UI. entity.type string Used to differentiate between different types of entities, like hosts, applications, etc. Request metadata (headers and query parameters) The following table shows the required request metadata for all trace data formats. This metadata can be sent as HTTP headers on an ingest request or, in some cases, provided as query parameters, which may be required for tracing frameworks that don't allow header modification. Important Security note: We suggest using headers because query parameters are present in the URL and may be logged before being encrypted and received by New Relic. All data sent as query parameters must be URL-safe. Header Query param? Details Content-Type No Required. Must be application/json. Content-Length No Required. The length of the request body in octets (8-bit bytes) unless sent with chunked encoding. This header is generally set by default by the underlying HTTP client sending the data and in most cases should not require any additional effort by the end user. Api-Key Yes (case-sensitive) Required. The Trace API requires the Insights insert key. If this is provided as both a header and a query parameter, the values must match. Content-Encoding No Required if compressed payload. The value must be gzip. Data-Format Yes Required for zipkin. Optional for newrelic. If present, Data-Format-Version must also be present. Data-Format-Version Yes Required for zipkin. If present, Data-Format must also be present. There are only two possible pairings for these values: If Data-Format is zipkin, Data-Format-Version must be 2. If Data-Format is newrelic, Data-Format-Version must be 1. x-request-id No Optional - Reserved for future use. The value must be a valid UUID4. The value is expected to be unique for each request. Response validation A response for successfully sending trace data will include a requestId. For example: {\"requestId\":\"c1bb62fc-001a-b000-0000-016bb152e1bb\"} Copy There are two ways success/errors are signaled: HTTP status code (synchronous). Authentication and request errors will be signaled via HTTP status code. See HTTP status codes Code Meaning 202 Data accepted. This means that you've passed preliminary checks, but is not a guarantee that the data has been successfully parsed and indexed as part of a distributed trace. 400 The structure of the request was invalid. Errors with query parameters, etc. 403 Authentication error. May occur with an invalid license key or if you lack necessary entitlement to use the Trace API. 404 The request path is incorrect. 405 For any request method other than POST. 408 The request took too long to reach the endpoint. 411 The Content-Length header wasn’t included. 413 The payload was too big. 414 The request URI was too long. 415 The Content-Type or Content-Encoding was invalid. 429 The request rate quota has been exceeded. 431 The request headers are too long. 5xx There was a server error (please retry). NrIntegrationError events (asynchronous). Errors with the JSON payload or other semantic errors are asynchronously signaled via NrIntegrationError events that are stored in the account whose license key is associated with the request. For all errors of this type, the attribute newRelicFeature will be Distributed Tracing and requestId will be the requestId from the endpoint response. If you receive a 202 response and don't see an NrIntegrationError event, your data should be visible in New Relic One's global distributed tracing UI in about a minute. You should be able to find the trace using a standard trace search like: traceId = TRACE_ID_SENT Copy Exceeding span limits When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate limit messages with this NRQL: SELECT * FROM NrIntegrationError WHERE newRelicFeature = 'Distributed Tracing' AND category = 'RateLimit' AND rateLimitType = 'SpansPerMinute' Copy To get a notification when you exceed the limit, you can set up a NRQL alert. We calculate a rolling 10-minute average based on your span rate limit. This allows for temporary rate bursts, and lets us prioritize keeping and dropping complete traces instead of indiscriminately dropping spans on a per minute limit basis. In the example below of exceeding the rate, the rate limit is the default 100,000 spans per minute. New Relic allows a burst above 100K for a couple of minutes without downsampling, because the remaining minutes in the 10-minute window averaged under 100K spans/minute. For the previous 10 minutes (8:50 - 9:00) the service received 60,000 spans/minute. Minute Spans sent to API Total for past 10 minutes 8:59 60,000 600,000 9:00 40,000 580,000 9:01 50,000 570,000 9:02 250,000 760,000 9:03 220,000 920,000 9:04 125,000 985,000 9:05 70,000 995,000 9:06 50,000 985,000 9:07 40,000 965,000 9:08 40,000 945,000 9:09 40,000 925,000",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 206.8027,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Trace</em> API general requirements and limits ",
        "sections": "<em>Trace</em> API general requirements and limits",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " be visible in New Relic One&#x27;s global <em>distributed</em> <em>tracing</em> UI in about a minute. You should be able to find the <em>trace</em> using a standard <em>trace</em> search like: <em>trace</em>Id = <em>TRACE</em>_ID_SENT Copy Exceeding span limits When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate"
      },
      "id": "6071cf7628ccbcf8b851c158"
    },
    {
      "sections": [
        "Distributed tracing: Planning guide",
        "Impact to APM features",
        "External services page has less detail",
        "Transaction trace UI displays service URLs, not transaction links",
        "Cross-application tracing will be disabled",
        "Impacts related to mobile monitoring",
        "Plan your rollout",
        "Enable distributed tracing"
      ],
      "title": "Distributed tracing: Planning guide",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "10263f2b6ec929f082153e28cbce07fe3a1f106a",
      "image": "https://docs.newrelic.com/static/7072dfa9e494767baabba420d78e7094/c1b63/distributed-trace-txn-trace-affects.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/distributed-tracing-planning-guide/",
      "published_at": "2021-06-14T18:03:44Z",
      "updated_at": "2021-05-28T11:44:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you are new to New Relic distributed tracing, we recommend you read the following before you enable distributed tracing. Impact to APM features Our distributed tracing improves on APM's previous cross application tracing feature. Here are some key benefits: See more cross-service activity details and more complete end-to-end traces. Filter and query traces, as well as make custom charts. See the complete trace even when calls cross account boundaries (for accounts with the same master account or in the same customer partnership). See Introduction to distributed tracing for other features. Enabling distributed tracing may affect some APM features you currently use. These changes affect only applications monitored by agents that have distributed tracing enabled—they don't apply on an account-level. We may provide backward compatibility with some or all of the affected features in future releases. For now, you should understand the following changes before enabling distributed tracing: External services page has less detail When distributed tracing is enabled for an application, external calls do not have internal transaction details at one.newrelic.com > APM > (select an app) > Monitor > External services > (select external service). To find that information, you would instead go to the Distributed tracing UI page, find the external call URLs, and see what their child spans are. Transaction trace UI displays service URLs, not transaction links When distributed tracing is enabled for an application, the transaction trace UI will no longer have the transaction name and link for the called service (see screenshot below). This will be replaced with the called service's URL. one.newrelic.com > APM > (select an app) > Monitor > Transactions > (select a transaction trace): This shows the transaction trace UI before distributed tracing is enabled, with a link to the associated transaction. With distributed tracing enabled, it will display the service's URL. If you wanted to get more detail about trace activity, you would go to the Distributed tracing UI page and examine that trace. Cross-application tracing will be disabled Enabling distributed tracing will disable the cross application tracing feature. Distributed tracing is an improved version of cross-application tracing and only one can be enabled at a time. Impacts related to mobile monitoring APM-related impacts include: When distributed tracing is enabled for an APM-monitored entity, legacy service maps will not show applications monitored by mobile. The App server drill-down feature of the legacy Mobile HTTP requests UI page is not available. Plan your rollout If you're enabling distributed tracing for a large, distributed system, here are some tips: If you are a current APM user, see Impact to APM features. Determine the requests that are the most important for your business, or the most likely to require analysis and troubleshooting, and enable distributed tracing for those services. Enable tracing for services at roughly the same time so you can more easily gauge how complete your end-to-end traces are. When you look at traces in the distributed tracing UI, you'll see spans in the trace for external calls to other services. Then, you can enable distributed tracing for any of those services you want. If a service is fairly standalone and not often used in context with other services, you may not want to enable distributed tracing for it. Here's a visual representation of such a phased roll-out: If you are using APM for a large, monolithic service, there may be many sub-process spans per trace and APM limits may result in fewer traces than expected. You can solve this by using APM agent instrumentation to disable the reporting of unimportant data. Distributed tracing works by propagating header information from service to service in a request path. Some services may communicate through a proxy or other intermediary service that does not automatically propagate the header. In that case, you will need to configure that proxy so that it allows the newrelic header value to be propagated from source to destination. Enable distributed tracing If you are aware of the impact to APM features and have thought about your rollout, you are ready to set up distributed tracing. See Overview: Enable distributed tracing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 203.91891,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Distributed</em> <em>tracing</em>: Planning guide",
        "sections": "<em>Distributed</em> <em>tracing</em>: Planning guide",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " details and more complete end-to-end traces. Filter and query traces, as well as make custom charts. See the complete <em>trace</em> even when calls cross account boundaries (for accounts with the same master account or in the same customer partnership). See Introduction to <em>distributed</em> <em>tracing</em> for other features"
      },
      "id": "6072a60564441f3a629d8535"
    },
    {
      "sections": [
        "Understand and use the distributed tracing UI",
        "Open the distributed tracing UI",
        "View traces for a specific service",
        "View traces across all accounts",
        "Tip",
        "Find traces that are useful",
        "Filter using the query bar",
        "Find traces that touch two services",
        "Find error spans using the like operator",
        "Trace groups",
        "Filter using the scatter plot",
        "Filters",
        "Trace histograms",
        "Important",
        "Trace details UI page",
        "Span details pane",
        "View related logs",
        "Additional UI details",
        "How to understand span errors",
        "Anomalous spans",
        "Client span duration: time differences between client and server spans",
        "Fragmented traces",
        "Trace details obfuscated based on account access",
        "Span limits and sampling",
        "Incomplete span names in waterfall view",
        "Missing spans and span/service count discrepancies"
      ],
      "title": "Understand and use the distributed tracing UI",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "f5b66e03583e42613810f1390b4e5adab4ed2caa",
      "image": "https://docs.newrelic.com/static/ec08996f31e6586bb257c6f89b3c8f99/e5166/new-relic-distributed-tracing-client-span-time.jpg",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/understand-use-distributed-tracing-ui/",
      "published_at": "2021-06-14T18:10:30Z",
      "updated_at": "2021-06-02T17:03:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing helps you monitor and analyze the behavior of your distributed system. After you enable distributed tracing, you can use our UI tools to search for traces and analyze them. For example, let's say you are an engineer troubleshooting errors in a complex transaction spanning many services. Here's what you can do in our UI: Open the distributed tracing UI page. Sort through your traces using a filter to find that specific request and show only traces containing errors. On the trace details page, you review the span along the request route that originated the error. Noting the error class and message, navigate to the service from its span in the trace so you can see that the error is occurring at a high rate. Read on to explore the options in the distributed tracing UI. Open the distributed tracing UI Here's how you can access the distributed tracing UI, depending on the type of search you want to do: View traces for a specific service The New Relic Explorer and APM are two menu options that help you navigate to a specific service so you can see traces that include that service. Go to one.newrelic.com. Click Explorer or APM in the top menu bar. Filter to the service you enabled for distributed tracing by typing the service name, and then press Enter. In the left navigation's Monitor section, click Distributed tracing. View traces across all accounts If you want to view traces from across all accounts you have access to, go to one.newrelic.com, click Browse data, and then Traces. Tip If you don't have access to accounts for some services in a trace, we'll obfuscate some details for those services. Find traces that are useful We have a variety of tools to help you find traces and spans so you can resolve issues. The opening distributed tracing page is populated with a default list of traces, and you can quickly refine this list using these tools: Query bar Trace groups Scatter plot chart Filters Interactive histograms Tip In addition to these tools, you can also use other options mentioned in Query distributed trace data. Filter using the query bar The Find traces query bar is a quick way to narrow your search for traces. You can either start typing in the query bar or use the dropdown to create a compound query. Query returns are based on span attributes, not on trace attributes. You define spans that have certain criteria, and the search displays traces that contain those spans. If you use a multi-attribute filter, it is affected by first attribute selected. Distributed tracing reports on two types of data: transaction events and spans. When you select an attribute in the filter, the data type that attribute is attached to dictates the available attributes. For example, if you filter on an attribute that is attached to a transaction event, only transaction event attributes are available when you attempt to add filter on additional attribute values. Queries for traces are similar to NRQL (our query language). Here are the main exceptions: String values don't require quote marks (for example, you can use either appName = MyApp or appName = 'MyApp') The like operator doesn’t require % (for example, you can use either appName like product or appName like %product%). Tip Some queries that return a large number of results may return false positives. The trace list limits these incorrect results to 10% of the returned results. False positives may also result in histogram chart results that are not displayed in the trace list. Here are two query bar examples: Find traces that touch two services The query in the image below finds traces that: Pass through both WebPortal and Inventory Service applications Have an Inventory Service datastore call that takes longer than 500 ms Contains an error in any span. Go to one.newrelic.com > Apps > Distributed tracing Find error spans using the like operator The query in the image below finds traces that: Contain spans that pass through the WebPortal application and where an error occurred on any span in the WebPortal application Contain spans where the customer_user_email attribute contains a value ending with hotmail.com anywhere in the trace. Go to one.newrelic.com > Apps > Distributed tracing Trace groups The default view of distributed tracing shows traces grouped by the same root entry span. In other words, traces are grouped by the span where New Relic began recording the request. You can slide the toggle Group similar traces to turn this on and off. With trace groups you get a high-level view of traces so you can understand request behavior for groups of similar traces. This helps you understand dips or spikes in trace count, duration, and errors. When you click on one of the trace groups, you get all the standard details in context of the specific trace group you selected. Filter using the scatter plot The trace scatter plot is a quick way to search for outlying traces. This is available on the opening page of distributed tracing if you turn off the Group similar traces toggle at the top of the page. In the scatter plot, you can move the cursor across the chart to view trace details and you can click individual points to get details: Here's how you can control what's displayed in the scatter plot: In the View by dropdown, select the duration type: Back-end duration Root span duration Trace duration In Group traces by, select one of these options: Errors: Group by whether or not traces contain errors. Root service: Group by the name of the first service in traces. In a trace where Service A calls Service B and Service B calls Service C, the root service would be Service A. Root entry span: Group by the root transaction, which is the root service's endpoint. In a trace where Service A calls Service B and Service B calls Service C, the root entry span is Service A's endpoint. For example: \"Service A - GET /user/%\". Service entry span: Group by the span name of the service currently being viewed in APM. For example, for a trace where Service A calls Service B and Service B calls Service C, if you're viewing Service B in APM and select this grouping, the traces will be represented by their Service B span names. If a service has multiple spans in a trace, this grouping option will use that service's first entry point. Filters In the left pane, you can filter traces by multi-span traces, specific entities, or error types. Once you select a filter, only traces associated with that specific type are displayed. This makes it much easier to view the traces you're most interested in so you can find and fix issues faster. Trace histograms The histogram charts give you a quick understanding of trace distribution for important values, such as duration. Click Show filters at the bottom of the left pane to display the histograms. When you move the histogram sliders, they change the data displayed in the scatterplot or the trace group charts. For example, you can drag the Trace duration chart slider to show only traces over 500 ms, as shown in the histogram example below. Important Some queries that produce many results may result in false positives in histograms. This could manifest as histograms showing trace results that are not in the trace list. Trace details UI page When you select a trace from the trace list, you see that trace's timeline and spans: one.newrelic.com > APM > (select an application) > Monitor > Distributed tracing > (select a trace) > (select a span): See the spans in a trace. Examine individual span details and see notifications for spans with anomalous behavior. The UI indicates some span properties with icons: Span property Indicator Description Service This icon represents a span that's a service's entry point. In-process This icon represents an in-process span, which is a span that takes place within a process (as opposed to a cross-process span). Examples: middleware instrumentation, user-created spans. Datastore This icon represents a span call to a datastore. External This icon represents category representing a call to an external service made via HTTP. Browser app This icon represents a browser application span. Lambda This icon represents a span from a Lambda function. Some spans will have additional indicators: Span property Indicator Description Type of connection Solid lines indicate a direct parent-child relationship; in other words, one process or function directly calling another. A dotted line indicates a non-direct relationship. For more on relationships between spans, see Trace structure. Errors A span with an error. See How to understand span errors. Anomalous This icon represents the detection of an anomalous span. Orphaned spans Some spans may be \"orphaned,\" or separated, from the trace. These spans will appear at the bottom of the trace. For more details, see Fragmented traces. Multiple app names When beside a span name, this represents an entity that has had multiple app names set. Select this to see all app names it reports to. To search trace data by alternate app names, use the appName attribute. Client/server time difference If a span's duration indicator is not completely colored in (like in this example), it means that there is a time discrepancy between the server-side duration and the client-side duration for that activity. For details on this, see Client/server time difference. For more on the trace structure and how span properties are determined, see Trace structure. Span details pane When you select a span, a pane opens up with span details. These details can be helpful for troubleshooting performance issues. Details include: Performance charts Span attributes The span's data source Anomalous span details The span's full name What a span displays is based on its span type. For example, a datastore span's name attribute will contain the datastore query. View related logs If you are using our logs in context feature together with our log management, you can see any logs that are linked to your traces: Go to the trace details page by clicking on a trace. Click See logs in the upper-right corner. For details related to an individual log message, click directly on the message. Additional UI details Here are some additional distributed tracing UI details, rules, and limits: How to understand span errors Span-level errors show you where errors originated in a process, how they bubbled up, and where they were handled. Every span that ends with an exception is shown with an error in the UI and contributes to the total error count for that trace. Here are some general tips about understanding span errors: Spans with errors are highlighted red in the distributed tracing UI. You can see more information on the Error Details pane for each span. All spans that exit with errors are counted in the span error count. When multiple errors occur on the same span, only one is written to the span in this order of precedence: A noticeError The most recent span exception This table describes how different span errors are handled: Error type Description Spans ending in exceptions An exception that leaves the boundary of a span results in an error on that span and on any ancestor spans that also exit with an error, until the exception is caught or exits the transaction. You can see if an exception is caught in an ancestor span. Notice errors Errors noticed by calls to the agent noticeError API or by the automatic agent instrumentation are attached to the currently executing span. Response code errors Response code errors are attached to the associated span, such as: Client span: External transactions prefixed with http or db. Entry span: In the case of a transaction ending in a response code error. The response code for these spans is captured as an attribute httpResponseCode and attached to that span. Anomalous spans If a span is displayed as anomalous in the UI, it means that the following are both true: The span is more than two standard deviations slower than the average of all spans with the same name from the same service over the last six hours. The span's duration is more than 10% of the trace's duration. Client span duration: time differences between client and server spans When a process calls another process, and both processes are instrumented by New Relic, the trace contains both a client-side representation of the call and a server-side representation. The client span (calling process) can have time-related differences when compared to the server span (called process). These differences could be due to: Clock skew, due to system clock time differences Differences in duration, due to things like network latency or DNS resolution delay The UI shows these time-related differences by displaying an outline of the client span in the same space as the server span. This span represents the duration of the client span. It isn't possible to determine every factor contributing to these time-related discrepancies, but here are some common span patterns and tips for understanding them: When a client span is longer than the server span, this could be due to latency in a number of areas, such as: network time, queue time, DNS resolution time, or from a load balancer that we cannot see. When a client span starts and ends before a server span begins, this could be due to clock skew, or due to the server doing asynchronous work that continues after sending the response. When a client span starts after a server span, this is most likely clock skew. Fragmented traces Fragmented traces are traces with missing spans. When a span is missing or has invalid parent span IDs, its children spans become separated from the rest of the trace, which we refer to as \"orphaned.\" Orphaned spans appear at the bottom of the trace, and they will lack connecting lines to the rest of the trace. Types of orphaned span properties indicated in the UI: No root span. Missing the root span, which is the first operation in the request. When this happens, the span with the earliest timestamp is displayed as the root. Orphaned span. A single span with a missing parent span. This could be due to the parent span having an ID that doesn't match its child span. Orphaned trace fragment. A group of connected spans where the first span in the group is an orphan span. This can happen for a number of reasons, including: Collection limits. Some high-throughput applications may exceed collection limits (for example, APM agent collection limits, or API limits). When this happens, it may result in traces having missing spans. One way to remedy this is to turn off some reporting, so that the limit is not reached. Incorrect instrumentation. If an application is instrumented incorrectly, it won't pass trace context correctly and this will result in fragmented traces. To remedy this, examine the data source that is generating orphan spans to ensure instrumentation is done correctly. To discover a span's data source, select it and examine its span details. Spans still arriving. If some parent spans haven't been collected yet, this can result in temporary gaps until the entire trace has reported. UI display limits. Orphaned spans may result if a trace exceeds the 10K span display limit. Trace details obfuscated based on account access If you don’t have access to the New Relic accounts that monitor other services, some of the span and service details will be obfuscated in the UI. Obfuscation can include: Span name concealed by asterisks Service name replaced with New Relic account ID and app ID The two main factors affecting this obfuscation: Account permissions. Master/sub-account relationships will impact access. If you have access to only a sub-account, you’ll be able to see details for only that sub-account. If you have access to a master account, you’ll be able to see details for that account’s sub-accounts. Authentication. You’ll be able to see span details only for New Relic accounts you can access based on your current login. This means that, for example, even the admin of a master account may not be able to see all details if the trace crosses the boundaries of different authentication mechanisms. Span limits and sampling See Sampling. Incomplete span names in waterfall view When viewing the span waterfall, span names may be displayed in an incomplete form that is more human-readable than the complete span name. To find the complete name, select that span and look for the Full span name. Knowing the complete name can be valuable for querying that data with NRQL. Missing spans and span/service count discrepancies A trace may sometimes have (or seem to have) missing spans or services. This can manifest as a discrepancy between the count of a trace's spans or services displayed in the trace list and the count displayed on the trace details page. Reasons for missing spans and count discrepancies include: An APM agent may have hit its 1K span collection limit. A span may be initially counted but not make it into a trace display, for reasons such as network latency or a query issue. The UI may have hit its 10K span display limit. All spans collected, including those not displayed, can be queried with NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.289,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Understand</em> and use the <em>distributed</em> <em>tracing</em> UI",
        "sections": "<em>Understand</em> and use the <em>distributed</em> <em>tracing</em> UI",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "<em>Distributed</em> <em>tracing</em> helps you monitor and analyze the behavior of your <em>distributed</em> system. After you enable <em>distributed</em> <em>tracing</em>, you can use our UI tools to search for traces and analyze them. For example, let&#x27;s say you are an engineer <em>troubleshooting</em> errors in a complex transaction spanning many"
      },
      "id": "6072a70028ccbc265a51c13d"
    }
  ],
  "/docs/distributed-tracing/ui-data/query-distributed-trace-data": [
    {
      "sections": [
        "Span attributes"
      ],
      "title": "Span attributes",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "725c10cb22b5d8f3b2a825c2dbf38b8640f93b13",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/span-attributes/",
      "published_at": "2021-06-14T18:09:35Z",
      "updated_at": "2021-06-02T17:14:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing creates Span data that can be queried in New Relic. Here are ways to learn more about Span data: To explore your span data, you can use the query builder. To see the default attributes attached to span data, use the data dictionary. For help with NRQL queries using these attributes, see these example queries.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 285.59058,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "<em>Distributed</em> <em>tracing</em> creates Span <em>data</em> that can be queried in New Relic. Here are ways to learn more about Span <em>data</em>: To explore your span <em>data</em>, you can use the query builder. To see the default attributes attached to span <em>data</em>, use the <em>data</em> dictionary. For help with NRQL queries using these attributes, see these example queries."
      },
      "id": "6072a767196a673e9964a7c3"
    },
    {
      "sections": [
        "Understand and use the distributed tracing UI",
        "Open the distributed tracing UI",
        "View traces for a specific service",
        "View traces across all accounts",
        "Tip",
        "Find traces that are useful",
        "Filter using the query bar",
        "Find traces that touch two services",
        "Find error spans using the like operator",
        "Trace groups",
        "Filter using the scatter plot",
        "Filters",
        "Trace histograms",
        "Important",
        "Trace details UI page",
        "Span details pane",
        "View related logs",
        "Additional UI details",
        "How to understand span errors",
        "Anomalous spans",
        "Client span duration: time differences between client and server spans",
        "Fragmented traces",
        "Trace details obfuscated based on account access",
        "Span limits and sampling",
        "Incomplete span names in waterfall view",
        "Missing spans and span/service count discrepancies"
      ],
      "title": "Understand and use the distributed tracing UI",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "f5b66e03583e42613810f1390b4e5adab4ed2caa",
      "image": "https://docs.newrelic.com/static/ec08996f31e6586bb257c6f89b3c8f99/e5166/new-relic-distributed-tracing-client-span-time.jpg",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/understand-use-distributed-tracing-ui/",
      "published_at": "2021-06-14T18:10:30Z",
      "updated_at": "2021-06-02T17:03:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing helps you monitor and analyze the behavior of your distributed system. After you enable distributed tracing, you can use our UI tools to search for traces and analyze them. For example, let's say you are an engineer troubleshooting errors in a complex transaction spanning many services. Here's what you can do in our UI: Open the distributed tracing UI page. Sort through your traces using a filter to find that specific request and show only traces containing errors. On the trace details page, you review the span along the request route that originated the error. Noting the error class and message, navigate to the service from its span in the trace so you can see that the error is occurring at a high rate. Read on to explore the options in the distributed tracing UI. Open the distributed tracing UI Here's how you can access the distributed tracing UI, depending on the type of search you want to do: View traces for a specific service The New Relic Explorer and APM are two menu options that help you navigate to a specific service so you can see traces that include that service. Go to one.newrelic.com. Click Explorer or APM in the top menu bar. Filter to the service you enabled for distributed tracing by typing the service name, and then press Enter. In the left navigation's Monitor section, click Distributed tracing. View traces across all accounts If you want to view traces from across all accounts you have access to, go to one.newrelic.com, click Browse data, and then Traces. Tip If you don't have access to accounts for some services in a trace, we'll obfuscate some details for those services. Find traces that are useful We have a variety of tools to help you find traces and spans so you can resolve issues. The opening distributed tracing page is populated with a default list of traces, and you can quickly refine this list using these tools: Query bar Trace groups Scatter plot chart Filters Interactive histograms Tip In addition to these tools, you can also use other options mentioned in Query distributed trace data. Filter using the query bar The Find traces query bar is a quick way to narrow your search for traces. You can either start typing in the query bar or use the dropdown to create a compound query. Query returns are based on span attributes, not on trace attributes. You define spans that have certain criteria, and the search displays traces that contain those spans. If you use a multi-attribute filter, it is affected by first attribute selected. Distributed tracing reports on two types of data: transaction events and spans. When you select an attribute in the filter, the data type that attribute is attached to dictates the available attributes. For example, if you filter on an attribute that is attached to a transaction event, only transaction event attributes are available when you attempt to add filter on additional attribute values. Queries for traces are similar to NRQL (our query language). Here are the main exceptions: String values don't require quote marks (for example, you can use either appName = MyApp or appName = 'MyApp') The like operator doesn’t require % (for example, you can use either appName like product or appName like %product%). Tip Some queries that return a large number of results may return false positives. The trace list limits these incorrect results to 10% of the returned results. False positives may also result in histogram chart results that are not displayed in the trace list. Here are two query bar examples: Find traces that touch two services The query in the image below finds traces that: Pass through both WebPortal and Inventory Service applications Have an Inventory Service datastore call that takes longer than 500 ms Contains an error in any span. Go to one.newrelic.com > Apps > Distributed tracing Find error spans using the like operator The query in the image below finds traces that: Contain spans that pass through the WebPortal application and where an error occurred on any span in the WebPortal application Contain spans where the customer_user_email attribute contains a value ending with hotmail.com anywhere in the trace. Go to one.newrelic.com > Apps > Distributed tracing Trace groups The default view of distributed tracing shows traces grouped by the same root entry span. In other words, traces are grouped by the span where New Relic began recording the request. You can slide the toggle Group similar traces to turn this on and off. With trace groups you get a high-level view of traces so you can understand request behavior for groups of similar traces. This helps you understand dips or spikes in trace count, duration, and errors. When you click on one of the trace groups, you get all the standard details in context of the specific trace group you selected. Filter using the scatter plot The trace scatter plot is a quick way to search for outlying traces. This is available on the opening page of distributed tracing if you turn off the Group similar traces toggle at the top of the page. In the scatter plot, you can move the cursor across the chart to view trace details and you can click individual points to get details: Here's how you can control what's displayed in the scatter plot: In the View by dropdown, select the duration type: Back-end duration Root span duration Trace duration In Group traces by, select one of these options: Errors: Group by whether or not traces contain errors. Root service: Group by the name of the first service in traces. In a trace where Service A calls Service B and Service B calls Service C, the root service would be Service A. Root entry span: Group by the root transaction, which is the root service's endpoint. In a trace where Service A calls Service B and Service B calls Service C, the root entry span is Service A's endpoint. For example: \"Service A - GET /user/%\". Service entry span: Group by the span name of the service currently being viewed in APM. For example, for a trace where Service A calls Service B and Service B calls Service C, if you're viewing Service B in APM and select this grouping, the traces will be represented by their Service B span names. If a service has multiple spans in a trace, this grouping option will use that service's first entry point. Filters In the left pane, you can filter traces by multi-span traces, specific entities, or error types. Once you select a filter, only traces associated with that specific type are displayed. This makes it much easier to view the traces you're most interested in so you can find and fix issues faster. Trace histograms The histogram charts give you a quick understanding of trace distribution for important values, such as duration. Click Show filters at the bottom of the left pane to display the histograms. When you move the histogram sliders, they change the data displayed in the scatterplot or the trace group charts. For example, you can drag the Trace duration chart slider to show only traces over 500 ms, as shown in the histogram example below. Important Some queries that produce many results may result in false positives in histograms. This could manifest as histograms showing trace results that are not in the trace list. Trace details UI page When you select a trace from the trace list, you see that trace's timeline and spans: one.newrelic.com > APM > (select an application) > Monitor > Distributed tracing > (select a trace) > (select a span): See the spans in a trace. Examine individual span details and see notifications for spans with anomalous behavior. The UI indicates some span properties with icons: Span property Indicator Description Service This icon represents a span that's a service's entry point. In-process This icon represents an in-process span, which is a span that takes place within a process (as opposed to a cross-process span). Examples: middleware instrumentation, user-created spans. Datastore This icon represents a span call to a datastore. External This icon represents category representing a call to an external service made via HTTP. Browser app This icon represents a browser application span. Lambda This icon represents a span from a Lambda function. Some spans will have additional indicators: Span property Indicator Description Type of connection Solid lines indicate a direct parent-child relationship; in other words, one process or function directly calling another. A dotted line indicates a non-direct relationship. For more on relationships between spans, see Trace structure. Errors A span with an error. See How to understand span errors. Anomalous This icon represents the detection of an anomalous span. Orphaned spans Some spans may be \"orphaned,\" or separated, from the trace. These spans will appear at the bottom of the trace. For more details, see Fragmented traces. Multiple app names When beside a span name, this represents an entity that has had multiple app names set. Select this to see all app names it reports to. To search trace data by alternate app names, use the appName attribute. Client/server time difference If a span's duration indicator is not completely colored in (like in this example), it means that there is a time discrepancy between the server-side duration and the client-side duration for that activity. For details on this, see Client/server time difference. For more on the trace structure and how span properties are determined, see Trace structure. Span details pane When you select a span, a pane opens up with span details. These details can be helpful for troubleshooting performance issues. Details include: Performance charts Span attributes The span's data source Anomalous span details The span's full name What a span displays is based on its span type. For example, a datastore span's name attribute will contain the datastore query. View related logs If you are using our logs in context feature together with our log management, you can see any logs that are linked to your traces: Go to the trace details page by clicking on a trace. Click See logs in the upper-right corner. For details related to an individual log message, click directly on the message. Additional UI details Here are some additional distributed tracing UI details, rules, and limits: How to understand span errors Span-level errors show you where errors originated in a process, how they bubbled up, and where they were handled. Every span that ends with an exception is shown with an error in the UI and contributes to the total error count for that trace. Here are some general tips about understanding span errors: Spans with errors are highlighted red in the distributed tracing UI. You can see more information on the Error Details pane for each span. All spans that exit with errors are counted in the span error count. When multiple errors occur on the same span, only one is written to the span in this order of precedence: A noticeError The most recent span exception This table describes how different span errors are handled: Error type Description Spans ending in exceptions An exception that leaves the boundary of a span results in an error on that span and on any ancestor spans that also exit with an error, until the exception is caught or exits the transaction. You can see if an exception is caught in an ancestor span. Notice errors Errors noticed by calls to the agent noticeError API or by the automatic agent instrumentation are attached to the currently executing span. Response code errors Response code errors are attached to the associated span, such as: Client span: External transactions prefixed with http or db. Entry span: In the case of a transaction ending in a response code error. The response code for these spans is captured as an attribute httpResponseCode and attached to that span. Anomalous spans If a span is displayed as anomalous in the UI, it means that the following are both true: The span is more than two standard deviations slower than the average of all spans with the same name from the same service over the last six hours. The span's duration is more than 10% of the trace's duration. Client span duration: time differences between client and server spans When a process calls another process, and both processes are instrumented by New Relic, the trace contains both a client-side representation of the call and a server-side representation. The client span (calling process) can have time-related differences when compared to the server span (called process). These differences could be due to: Clock skew, due to system clock time differences Differences in duration, due to things like network latency or DNS resolution delay The UI shows these time-related differences by displaying an outline of the client span in the same space as the server span. This span represents the duration of the client span. It isn't possible to determine every factor contributing to these time-related discrepancies, but here are some common span patterns and tips for understanding them: When a client span is longer than the server span, this could be due to latency in a number of areas, such as: network time, queue time, DNS resolution time, or from a load balancer that we cannot see. When a client span starts and ends before a server span begins, this could be due to clock skew, or due to the server doing asynchronous work that continues after sending the response. When a client span starts after a server span, this is most likely clock skew. Fragmented traces Fragmented traces are traces with missing spans. When a span is missing or has invalid parent span IDs, its children spans become separated from the rest of the trace, which we refer to as \"orphaned.\" Orphaned spans appear at the bottom of the trace, and they will lack connecting lines to the rest of the trace. Types of orphaned span properties indicated in the UI: No root span. Missing the root span, which is the first operation in the request. When this happens, the span with the earliest timestamp is displayed as the root. Orphaned span. A single span with a missing parent span. This could be due to the parent span having an ID that doesn't match its child span. Orphaned trace fragment. A group of connected spans where the first span in the group is an orphan span. This can happen for a number of reasons, including: Collection limits. Some high-throughput applications may exceed collection limits (for example, APM agent collection limits, or API limits). When this happens, it may result in traces having missing spans. One way to remedy this is to turn off some reporting, so that the limit is not reached. Incorrect instrumentation. If an application is instrumented incorrectly, it won't pass trace context correctly and this will result in fragmented traces. To remedy this, examine the data source that is generating orphan spans to ensure instrumentation is done correctly. To discover a span's data source, select it and examine its span details. Spans still arriving. If some parent spans haven't been collected yet, this can result in temporary gaps until the entire trace has reported. UI display limits. Orphaned spans may result if a trace exceeds the 10K span display limit. Trace details obfuscated based on account access If you don’t have access to the New Relic accounts that monitor other services, some of the span and service details will be obfuscated in the UI. Obfuscation can include: Span name concealed by asterisks Service name replaced with New Relic account ID and app ID The two main factors affecting this obfuscation: Account permissions. Master/sub-account relationships will impact access. If you have access to only a sub-account, you’ll be able to see details for only that sub-account. If you have access to a master account, you’ll be able to see details for that account’s sub-accounts. Authentication. You’ll be able to see span details only for New Relic accounts you can access based on your current login. This means that, for example, even the admin of a master account may not be able to see all details if the trace crosses the boundaries of different authentication mechanisms. Span limits and sampling See Sampling. Incomplete span names in waterfall view When viewing the span waterfall, span names may be displayed in an incomplete form that is more human-readable than the complete span name. To find the complete name, select that span and look for the Full span name. Knowing the complete name can be valuable for querying that data with NRQL. Missing spans and span/service count discrepancies A trace may sometimes have (or seem to have) missing spans or services. This can manifest as a discrepancy between the count of a trace's spans or services displayed in the trace list and the count displayed on the trace details page. Reasons for missing spans and count discrepancies include: An APM agent may have hit its 1K span collection limit. A span may be initially counted but not make it into a trace display, for reasons such as network latency or a query issue. The UI may have hit its 10K span display limit. All spans collected, including those not displayed, can be queried with NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 285.5556,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Understand</em> <em>and</em> use the <em>distributed</em> <em>tracing</em> <em>UI</em>",
        "sections": "<em>Understand</em> <em>and</em> use the <em>distributed</em> <em>tracing</em> <em>UI</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " services. Here&#x27;s what you can do in our <em>UI</em>: Open the <em>distributed</em> <em>tracing</em> <em>UI</em> page. Sort through your traces using a filter to find that specific request and show only traces containing errors. On the <em>trace</em> details page, you review the span along the request route that originated the error. Noting"
      },
      "id": "6072a70028ccbc265a51c13d"
    },
    {
      "sections": [
        "Trace API general requirements and limits",
        "Endpoints",
        "Data formats",
        "Data limits",
        "Restricted attributes",
        "Request metadata (headers and query parameters)",
        "Important",
        "Response validation",
        "See HTTP status codes",
        "Exceeding span limits"
      ],
      "title": "Trace API general requirements and limits ",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "f77504082dae8374e0c7009a31abebbd4c0123f3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/trace-api-general-requirements-limits/",
      "published_at": "2021-06-14T18:07:42Z",
      "updated_at": "2021-06-09T00:57:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Information about Trace API data requirements, including: Data specifications and max limits Required metadata (headers, query parameters) Response validation details This document applies to the Trace API overall. For rules regarding specific data formats, see: New Relic-format trace data Zipkin-format trace data Endpoints All trace data is sent via a POST to a Trace API endpoint. We have a few endpoints, depending on your setup: Default Trace API endpoint: https://trace-api.newrelic.com/trace/v1 EU data centers: https://trace-api.eu.newrelic.com/trace/v1 (see other EU endpoints). Infinite Tracing: when you complete the Trace observer setup, you get a custom YOUR_TRACE_OBSERVER_URL value to use as an endpoint. If you're using an integration that uses the Trace API (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust the sampling of your tracing service to send us 100% of spans. For FedRAMP, see FedRAMP endpoints. Data formats Currently, the Trace API accepts two types of data formats: zipkin: For reporting Zipkin trace data. Zipkin data must be Zipkin JSON v2. newrelic: For reporting all other trace data. Data limits Data limits and rules: Condition Limit Max age of span timestamp values 20 minutes. timestamp must be within 20 minutes of current time at ingest, or within 20 minutes from the time the last span with the same trace.id was received by New Relic. Max payload size 1MB (10^6 bytes) (gzip compression supported) Max requests per minute 100K Max spans per minute per account family Dependent on agreement. Max limit: 2M. Max spans per trace 50K Max attributes per span 200 Max span attribute value length 4000 characters Allowed HTTP protocols HTTPS only Cross-account visibility of span details Potential data obfuscation To see an example of how span limits are enforced, see Exceeding limits. Restricted attributes The attributes in the table below are restricted in the newrelic-format JSON (in the attributes block) and in the zipkin-format JSON (in the tags block). Any values with these keys will be omitted: Restricted attribute Description entityGuid string Unique identifier for the entity that created this span. Generated from service.name, if available. guid string Used for backwards compatibility with data from APM agents. The attributes in the table below are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Restricted attribute description entity.guid string Unique identifier for the entity associated with this span. entity.name string Human-readable name of an entity, often used to identify an entity in the UI. entity.type string Used to differentiate between different types of entities, like hosts, applications, etc. Request metadata (headers and query parameters) The following table shows the required request metadata for all trace data formats. This metadata can be sent as HTTP headers on an ingest request or, in some cases, provided as query parameters, which may be required for tracing frameworks that don't allow header modification. Important Security note: We suggest using headers because query parameters are present in the URL and may be logged before being encrypted and received by New Relic. All data sent as query parameters must be URL-safe. Header Query param? Details Content-Type No Required. Must be application/json. Content-Length No Required. The length of the request body in octets (8-bit bytes) unless sent with chunked encoding. This header is generally set by default by the underlying HTTP client sending the data and in most cases should not require any additional effort by the end user. Api-Key Yes (case-sensitive) Required. The Trace API requires the Insights insert key. If this is provided as both a header and a query parameter, the values must match. Content-Encoding No Required if compressed payload. The value must be gzip. Data-Format Yes Required for zipkin. Optional for newrelic. If present, Data-Format-Version must also be present. Data-Format-Version Yes Required for zipkin. If present, Data-Format must also be present. There are only two possible pairings for these values: If Data-Format is zipkin, Data-Format-Version must be 2. If Data-Format is newrelic, Data-Format-Version must be 1. x-request-id No Optional - Reserved for future use. The value must be a valid UUID4. The value is expected to be unique for each request. Response validation A response for successfully sending trace data will include a requestId. For example: {\"requestId\":\"c1bb62fc-001a-b000-0000-016bb152e1bb\"} Copy There are two ways success/errors are signaled: HTTP status code (synchronous). Authentication and request errors will be signaled via HTTP status code. See HTTP status codes Code Meaning 202 Data accepted. This means that you've passed preliminary checks, but is not a guarantee that the data has been successfully parsed and indexed as part of a distributed trace. 400 The structure of the request was invalid. Errors with query parameters, etc. 403 Authentication error. May occur with an invalid license key or if you lack necessary entitlement to use the Trace API. 404 The request path is incorrect. 405 For any request method other than POST. 408 The request took too long to reach the endpoint. 411 The Content-Length header wasn’t included. 413 The payload was too big. 414 The request URI was too long. 415 The Content-Type or Content-Encoding was invalid. 429 The request rate quota has been exceeded. 431 The request headers are too long. 5xx There was a server error (please retry). NrIntegrationError events (asynchronous). Errors with the JSON payload or other semantic errors are asynchronously signaled via NrIntegrationError events that are stored in the account whose license key is associated with the request. For all errors of this type, the attribute newRelicFeature will be Distributed Tracing and requestId will be the requestId from the endpoint response. If you receive a 202 response and don't see an NrIntegrationError event, your data should be visible in New Relic One's global distributed tracing UI in about a minute. You should be able to find the trace using a standard trace search like: traceId = TRACE_ID_SENT Copy Exceeding span limits When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate limit messages with this NRQL: SELECT * FROM NrIntegrationError WHERE newRelicFeature = 'Distributed Tracing' AND category = 'RateLimit' AND rateLimitType = 'SpansPerMinute' Copy To get a notification when you exceed the limit, you can set up a NRQL alert. We calculate a rolling 10-minute average based on your span rate limit. This allows for temporary rate bursts, and lets us prioritize keeping and dropping complete traces instead of indiscriminately dropping spans on a per minute limit basis. In the example below of exceeding the rate, the rate limit is the default 100,000 spans per minute. New Relic allows a burst above 100K for a couple of minutes without downsampling, because the remaining minutes in the 10-minute window averaged under 100K spans/minute. For the previous 10 minutes (8:50 - 9:00) the service received 60,000 spans/minute. Minute Spans sent to API Total for past 10 minutes 8:59 60,000 600,000 9:00 40,000 580,000 9:01 50,000 570,000 9:02 250,000 760,000 9:03 220,000 920,000 9:04 125,000 985,000 9:05 70,000 995,000 9:06 50,000 985,000 9:07 40,000 965,000 9:08 40,000 945,000 9:09 40,000 925,000",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 206.80264,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Trace</em> API general requirements <em>and</em> limits ",
        "sections": "<em>Trace</em> API general requirements <em>and</em> limits",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " be visible in New Relic One&#x27;s global <em>distributed</em> <em>tracing</em> <em>UI</em> in about a minute. You should be able to find the <em>trace</em> using a standard <em>trace</em> search like: <em>trace</em>Id = <em>TRACE</em>_ID_SENT Copy Exceeding span limits When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate"
      },
      "id": "6071cf7628ccbcf8b851c158"
    }
  ],
  "/docs/distributed-tracing/ui-data/span-attributes": [
    {
      "sections": [
        "Understand and use the distributed tracing UI",
        "Open the distributed tracing UI",
        "View traces for a specific service",
        "View traces across all accounts",
        "Tip",
        "Find traces that are useful",
        "Filter using the query bar",
        "Find traces that touch two services",
        "Find error spans using the like operator",
        "Trace groups",
        "Filter using the scatter plot",
        "Filters",
        "Trace histograms",
        "Important",
        "Trace details UI page",
        "Span details pane",
        "View related logs",
        "Additional UI details",
        "How to understand span errors",
        "Anomalous spans",
        "Client span duration: time differences between client and server spans",
        "Fragmented traces",
        "Trace details obfuscated based on account access",
        "Span limits and sampling",
        "Incomplete span names in waterfall view",
        "Missing spans and span/service count discrepancies"
      ],
      "title": "Understand and use the distributed tracing UI",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "f5b66e03583e42613810f1390b4e5adab4ed2caa",
      "image": "https://docs.newrelic.com/static/ec08996f31e6586bb257c6f89b3c8f99/e5166/new-relic-distributed-tracing-client-span-time.jpg",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/understand-use-distributed-tracing-ui/",
      "published_at": "2021-06-14T18:10:30Z",
      "updated_at": "2021-06-02T17:03:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing helps you monitor and analyze the behavior of your distributed system. After you enable distributed tracing, you can use our UI tools to search for traces and analyze them. For example, let's say you are an engineer troubleshooting errors in a complex transaction spanning many services. Here's what you can do in our UI: Open the distributed tracing UI page. Sort through your traces using a filter to find that specific request and show only traces containing errors. On the trace details page, you review the span along the request route that originated the error. Noting the error class and message, navigate to the service from its span in the trace so you can see that the error is occurring at a high rate. Read on to explore the options in the distributed tracing UI. Open the distributed tracing UI Here's how you can access the distributed tracing UI, depending on the type of search you want to do: View traces for a specific service The New Relic Explorer and APM are two menu options that help you navigate to a specific service so you can see traces that include that service. Go to one.newrelic.com. Click Explorer or APM in the top menu bar. Filter to the service you enabled for distributed tracing by typing the service name, and then press Enter. In the left navigation's Monitor section, click Distributed tracing. View traces across all accounts If you want to view traces from across all accounts you have access to, go to one.newrelic.com, click Browse data, and then Traces. Tip If you don't have access to accounts for some services in a trace, we'll obfuscate some details for those services. Find traces that are useful We have a variety of tools to help you find traces and spans so you can resolve issues. The opening distributed tracing page is populated with a default list of traces, and you can quickly refine this list using these tools: Query bar Trace groups Scatter plot chart Filters Interactive histograms Tip In addition to these tools, you can also use other options mentioned in Query distributed trace data. Filter using the query bar The Find traces query bar is a quick way to narrow your search for traces. You can either start typing in the query bar or use the dropdown to create a compound query. Query returns are based on span attributes, not on trace attributes. You define spans that have certain criteria, and the search displays traces that contain those spans. If you use a multi-attribute filter, it is affected by first attribute selected. Distributed tracing reports on two types of data: transaction events and spans. When you select an attribute in the filter, the data type that attribute is attached to dictates the available attributes. For example, if you filter on an attribute that is attached to a transaction event, only transaction event attributes are available when you attempt to add filter on additional attribute values. Queries for traces are similar to NRQL (our query language). Here are the main exceptions: String values don't require quote marks (for example, you can use either appName = MyApp or appName = 'MyApp') The like operator doesn’t require % (for example, you can use either appName like product or appName like %product%). Tip Some queries that return a large number of results may return false positives. The trace list limits these incorrect results to 10% of the returned results. False positives may also result in histogram chart results that are not displayed in the trace list. Here are two query bar examples: Find traces that touch two services The query in the image below finds traces that: Pass through both WebPortal and Inventory Service applications Have an Inventory Service datastore call that takes longer than 500 ms Contains an error in any span. Go to one.newrelic.com > Apps > Distributed tracing Find error spans using the like operator The query in the image below finds traces that: Contain spans that pass through the WebPortal application and where an error occurred on any span in the WebPortal application Contain spans where the customer_user_email attribute contains a value ending with hotmail.com anywhere in the trace. Go to one.newrelic.com > Apps > Distributed tracing Trace groups The default view of distributed tracing shows traces grouped by the same root entry span. In other words, traces are grouped by the span where New Relic began recording the request. You can slide the toggle Group similar traces to turn this on and off. With trace groups you get a high-level view of traces so you can understand request behavior for groups of similar traces. This helps you understand dips or spikes in trace count, duration, and errors. When you click on one of the trace groups, you get all the standard details in context of the specific trace group you selected. Filter using the scatter plot The trace scatter plot is a quick way to search for outlying traces. This is available on the opening page of distributed tracing if you turn off the Group similar traces toggle at the top of the page. In the scatter plot, you can move the cursor across the chart to view trace details and you can click individual points to get details: Here's how you can control what's displayed in the scatter plot: In the View by dropdown, select the duration type: Back-end duration Root span duration Trace duration In Group traces by, select one of these options: Errors: Group by whether or not traces contain errors. Root service: Group by the name of the first service in traces. In a trace where Service A calls Service B and Service B calls Service C, the root service would be Service A. Root entry span: Group by the root transaction, which is the root service's endpoint. In a trace where Service A calls Service B and Service B calls Service C, the root entry span is Service A's endpoint. For example: \"Service A - GET /user/%\". Service entry span: Group by the span name of the service currently being viewed in APM. For example, for a trace where Service A calls Service B and Service B calls Service C, if you're viewing Service B in APM and select this grouping, the traces will be represented by their Service B span names. If a service has multiple spans in a trace, this grouping option will use that service's first entry point. Filters In the left pane, you can filter traces by multi-span traces, specific entities, or error types. Once you select a filter, only traces associated with that specific type are displayed. This makes it much easier to view the traces you're most interested in so you can find and fix issues faster. Trace histograms The histogram charts give you a quick understanding of trace distribution for important values, such as duration. Click Show filters at the bottom of the left pane to display the histograms. When you move the histogram sliders, they change the data displayed in the scatterplot or the trace group charts. For example, you can drag the Trace duration chart slider to show only traces over 500 ms, as shown in the histogram example below. Important Some queries that produce many results may result in false positives in histograms. This could manifest as histograms showing trace results that are not in the trace list. Trace details UI page When you select a trace from the trace list, you see that trace's timeline and spans: one.newrelic.com > APM > (select an application) > Monitor > Distributed tracing > (select a trace) > (select a span): See the spans in a trace. Examine individual span details and see notifications for spans with anomalous behavior. The UI indicates some span properties with icons: Span property Indicator Description Service This icon represents a span that's a service's entry point. In-process This icon represents an in-process span, which is a span that takes place within a process (as opposed to a cross-process span). Examples: middleware instrumentation, user-created spans. Datastore This icon represents a span call to a datastore. External This icon represents category representing a call to an external service made via HTTP. Browser app This icon represents a browser application span. Lambda This icon represents a span from a Lambda function. Some spans will have additional indicators: Span property Indicator Description Type of connection Solid lines indicate a direct parent-child relationship; in other words, one process or function directly calling another. A dotted line indicates a non-direct relationship. For more on relationships between spans, see Trace structure. Errors A span with an error. See How to understand span errors. Anomalous This icon represents the detection of an anomalous span. Orphaned spans Some spans may be \"orphaned,\" or separated, from the trace. These spans will appear at the bottom of the trace. For more details, see Fragmented traces. Multiple app names When beside a span name, this represents an entity that has had multiple app names set. Select this to see all app names it reports to. To search trace data by alternate app names, use the appName attribute. Client/server time difference If a span's duration indicator is not completely colored in (like in this example), it means that there is a time discrepancy between the server-side duration and the client-side duration for that activity. For details on this, see Client/server time difference. For more on the trace structure and how span properties are determined, see Trace structure. Span details pane When you select a span, a pane opens up with span details. These details can be helpful for troubleshooting performance issues. Details include: Performance charts Span attributes The span's data source Anomalous span details The span's full name What a span displays is based on its span type. For example, a datastore span's name attribute will contain the datastore query. View related logs If you are using our logs in context feature together with our log management, you can see any logs that are linked to your traces: Go to the trace details page by clicking on a trace. Click See logs in the upper-right corner. For details related to an individual log message, click directly on the message. Additional UI details Here are some additional distributed tracing UI details, rules, and limits: How to understand span errors Span-level errors show you where errors originated in a process, how they bubbled up, and where they were handled. Every span that ends with an exception is shown with an error in the UI and contributes to the total error count for that trace. Here are some general tips about understanding span errors: Spans with errors are highlighted red in the distributed tracing UI. You can see more information on the Error Details pane for each span. All spans that exit with errors are counted in the span error count. When multiple errors occur on the same span, only one is written to the span in this order of precedence: A noticeError The most recent span exception This table describes how different span errors are handled: Error type Description Spans ending in exceptions An exception that leaves the boundary of a span results in an error on that span and on any ancestor spans that also exit with an error, until the exception is caught or exits the transaction. You can see if an exception is caught in an ancestor span. Notice errors Errors noticed by calls to the agent noticeError API or by the automatic agent instrumentation are attached to the currently executing span. Response code errors Response code errors are attached to the associated span, such as: Client span: External transactions prefixed with http or db. Entry span: In the case of a transaction ending in a response code error. The response code for these spans is captured as an attribute httpResponseCode and attached to that span. Anomalous spans If a span is displayed as anomalous in the UI, it means that the following are both true: The span is more than two standard deviations slower than the average of all spans with the same name from the same service over the last six hours. The span's duration is more than 10% of the trace's duration. Client span duration: time differences between client and server spans When a process calls another process, and both processes are instrumented by New Relic, the trace contains both a client-side representation of the call and a server-side representation. The client span (calling process) can have time-related differences when compared to the server span (called process). These differences could be due to: Clock skew, due to system clock time differences Differences in duration, due to things like network latency or DNS resolution delay The UI shows these time-related differences by displaying an outline of the client span in the same space as the server span. This span represents the duration of the client span. It isn't possible to determine every factor contributing to these time-related discrepancies, but here are some common span patterns and tips for understanding them: When a client span is longer than the server span, this could be due to latency in a number of areas, such as: network time, queue time, DNS resolution time, or from a load balancer that we cannot see. When a client span starts and ends before a server span begins, this could be due to clock skew, or due to the server doing asynchronous work that continues after sending the response. When a client span starts after a server span, this is most likely clock skew. Fragmented traces Fragmented traces are traces with missing spans. When a span is missing or has invalid parent span IDs, its children spans become separated from the rest of the trace, which we refer to as \"orphaned.\" Orphaned spans appear at the bottom of the trace, and they will lack connecting lines to the rest of the trace. Types of orphaned span properties indicated in the UI: No root span. Missing the root span, which is the first operation in the request. When this happens, the span with the earliest timestamp is displayed as the root. Orphaned span. A single span with a missing parent span. This could be due to the parent span having an ID that doesn't match its child span. Orphaned trace fragment. A group of connected spans where the first span in the group is an orphan span. This can happen for a number of reasons, including: Collection limits. Some high-throughput applications may exceed collection limits (for example, APM agent collection limits, or API limits). When this happens, it may result in traces having missing spans. One way to remedy this is to turn off some reporting, so that the limit is not reached. Incorrect instrumentation. If an application is instrumented incorrectly, it won't pass trace context correctly and this will result in fragmented traces. To remedy this, examine the data source that is generating orphan spans to ensure instrumentation is done correctly. To discover a span's data source, select it and examine its span details. Spans still arriving. If some parent spans haven't been collected yet, this can result in temporary gaps until the entire trace has reported. UI display limits. Orphaned spans may result if a trace exceeds the 10K span display limit. Trace details obfuscated based on account access If you don’t have access to the New Relic accounts that monitor other services, some of the span and service details will be obfuscated in the UI. Obfuscation can include: Span name concealed by asterisks Service name replaced with New Relic account ID and app ID The two main factors affecting this obfuscation: Account permissions. Master/sub-account relationships will impact access. If you have access to only a sub-account, you’ll be able to see details for only that sub-account. If you have access to a master account, you’ll be able to see details for that account’s sub-accounts. Authentication. You’ll be able to see span details only for New Relic accounts you can access based on your current login. This means that, for example, even the admin of a master account may not be able to see all details if the trace crosses the boundaries of different authentication mechanisms. Span limits and sampling See Sampling. Incomplete span names in waterfall view When viewing the span waterfall, span names may be displayed in an incomplete form that is more human-readable than the complete span name. To find the complete name, select that span and look for the Full span name. Knowing the complete name can be valuable for querying that data with NRQL. Missing spans and span/service count discrepancies A trace may sometimes have (or seem to have) missing spans or services. This can manifest as a discrepancy between the count of a trace's spans or services displayed in the trace list and the count displayed on the trace details page. Reasons for missing spans and count discrepancies include: An APM agent may have hit its 1K span collection limit. A span may be initially counted but not make it into a trace display, for reasons such as network latency or a query issue. The UI may have hit its 10K span display limit. All spans collected, including those not displayed, can be queried with NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 285.5556,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Understand</em> <em>and</em> use the <em>distributed</em> <em>tracing</em> <em>UI</em>",
        "sections": "<em>Understand</em> <em>and</em> use the <em>distributed</em> <em>tracing</em> <em>UI</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " services. Here&#x27;s what you can do in our <em>UI</em>: Open the <em>distributed</em> <em>tracing</em> <em>UI</em> page. Sort through your traces using a filter to find that specific request and show only traces containing errors. On the <em>trace</em> details page, you review the span along the request route that originated the error. Noting"
      },
      "id": "6072a70028ccbc265a51c13d"
    },
    {
      "sections": [
        "Query distributed trace data",
        "Example NRQL queries",
        "Tip",
        "Datastore time percentile for an app",
        "Datastore query time for an app, faceted by host",
        "Average duration for a method of a service, faceted by host",
        "Histogram of external services called by a service, faceted by external URI",
        "Average duration for external calls across all applications",
        "Example NerdGraph queries",
        "Can't find data?"
      ],
      "title": "Query distributed trace data",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "7ad60264aa5c46ef3859a886fc5c97471ccfb02f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/query-distributed-trace-data/",
      "published_at": "2021-06-14T18:09:35Z",
      "updated_at": "2021-04-11T07:36:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can query your distributed tracing data in several ways: The search bar at top of the distributed tracing UI NRQL query NerdGraph GraphiQL explorer To learn about trace structure, see How distributed tracing works. Example NRQL queries Tip You can also construct complex queries in the search bar at the top of the distributed tracing UI. Some example NRQL queries: Datastore time percentile for an app SELECT percentile(duration, 50, 95) FROM Span WHERE category = 'datastore' and appName = 'YOUR_APP_NAME' SINCE 4 hours ago TIMESERIES 1 minute Copy Datastore query time for an app, faceted by host SELECT average(duration) FROM Span WHERE appName = 'YOUR_APP_NAME' and category = 'datastore' FACET host TIMESERIES 1 minute Copy Average duration for a method of a service, faceted by host SELECT average(duration) FROM Span WHERE appName = 'YOUR_APP_NAME' and name = 'FUNCTION_NAME' FACET host TIMESERIES 1 minute Copy Histogram of external services called by a service, faceted by external URI SELECT histogram(duration, 10, 60) FROM Span WHERE category = 'http' and appName = 'YOUR_APP_NAME' FACET `http.url` SINCE 4 hours ago Copy Average duration for external calls across all applications SELECT average(duration) FROM Span WHERE category = 'http' SINCE 4 hours ago FACET `http.url` TIMESERIES 1 minute Copy Example NerdGraph queries You can also use NerdGraph to query your trace data using the API. For more information, see the NerdGraph distributed tracing data query examples. Can't find data? Having trouble finding data when querying? See Troubleshooting: missing data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 223.57504,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Query <em>distributed</em> <em>trace</em> <em>data</em>",
        "sections": "Query <em>distributed</em> <em>trace</em> <em>data</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "You can query your <em>distributed</em> <em>tracing</em> <em>data</em> in several ways: The search bar at top of the <em>distributed</em> <em>tracing</em> <em>UI</em> NRQL query NerdGraph GraphiQL explorer To learn about <em>trace</em> structure, see How <em>distributed</em> <em>tracing</em> works. Example NRQL queries Tip You can also construct complex queries in the search"
      },
      "id": "6072a6ff196a67ddaf64a75a"
    },
    {
      "sections": [
        "Trace API general requirements and limits",
        "Endpoints",
        "Data formats",
        "Data limits",
        "Restricted attributes",
        "Request metadata (headers and query parameters)",
        "Important",
        "Response validation",
        "See HTTP status codes",
        "Exceeding span limits"
      ],
      "title": "Trace API general requirements and limits ",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "f77504082dae8374e0c7009a31abebbd4c0123f3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/trace-api-general-requirements-limits/",
      "published_at": "2021-06-14T18:07:42Z",
      "updated_at": "2021-06-09T00:57:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Information about Trace API data requirements, including: Data specifications and max limits Required metadata (headers, query parameters) Response validation details This document applies to the Trace API overall. For rules regarding specific data formats, see: New Relic-format trace data Zipkin-format trace data Endpoints All trace data is sent via a POST to a Trace API endpoint. We have a few endpoints, depending on your setup: Default Trace API endpoint: https://trace-api.newrelic.com/trace/v1 EU data centers: https://trace-api.eu.newrelic.com/trace/v1 (see other EU endpoints). Infinite Tracing: when you complete the Trace observer setup, you get a custom YOUR_TRACE_OBSERVER_URL value to use as an endpoint. If you're using an integration that uses the Trace API (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust the sampling of your tracing service to send us 100% of spans. For FedRAMP, see FedRAMP endpoints. Data formats Currently, the Trace API accepts two types of data formats: zipkin: For reporting Zipkin trace data. Zipkin data must be Zipkin JSON v2. newrelic: For reporting all other trace data. Data limits Data limits and rules: Condition Limit Max age of span timestamp values 20 minutes. timestamp must be within 20 minutes of current time at ingest, or within 20 minutes from the time the last span with the same trace.id was received by New Relic. Max payload size 1MB (10^6 bytes) (gzip compression supported) Max requests per minute 100K Max spans per minute per account family Dependent on agreement. Max limit: 2M. Max spans per trace 50K Max attributes per span 200 Max span attribute value length 4000 characters Allowed HTTP protocols HTTPS only Cross-account visibility of span details Potential data obfuscation To see an example of how span limits are enforced, see Exceeding limits. Restricted attributes The attributes in the table below are restricted in the newrelic-format JSON (in the attributes block) and in the zipkin-format JSON (in the tags block). Any values with these keys will be omitted: Restricted attribute Description entityGuid string Unique identifier for the entity that created this span. Generated from service.name, if available. guid string Used for backwards compatibility with data from APM agents. The attributes in the table below are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Restricted attribute description entity.guid string Unique identifier for the entity associated with this span. entity.name string Human-readable name of an entity, often used to identify an entity in the UI. entity.type string Used to differentiate between different types of entities, like hosts, applications, etc. Request metadata (headers and query parameters) The following table shows the required request metadata for all trace data formats. This metadata can be sent as HTTP headers on an ingest request or, in some cases, provided as query parameters, which may be required for tracing frameworks that don't allow header modification. Important Security note: We suggest using headers because query parameters are present in the URL and may be logged before being encrypted and received by New Relic. All data sent as query parameters must be URL-safe. Header Query param? Details Content-Type No Required. Must be application/json. Content-Length No Required. The length of the request body in octets (8-bit bytes) unless sent with chunked encoding. This header is generally set by default by the underlying HTTP client sending the data and in most cases should not require any additional effort by the end user. Api-Key Yes (case-sensitive) Required. The Trace API requires the Insights insert key. If this is provided as both a header and a query parameter, the values must match. Content-Encoding No Required if compressed payload. The value must be gzip. Data-Format Yes Required for zipkin. Optional for newrelic. If present, Data-Format-Version must also be present. Data-Format-Version Yes Required for zipkin. If present, Data-Format must also be present. There are only two possible pairings for these values: If Data-Format is zipkin, Data-Format-Version must be 2. If Data-Format is newrelic, Data-Format-Version must be 1. x-request-id No Optional - Reserved for future use. The value must be a valid UUID4. The value is expected to be unique for each request. Response validation A response for successfully sending trace data will include a requestId. For example: {\"requestId\":\"c1bb62fc-001a-b000-0000-016bb152e1bb\"} Copy There are two ways success/errors are signaled: HTTP status code (synchronous). Authentication and request errors will be signaled via HTTP status code. See HTTP status codes Code Meaning 202 Data accepted. This means that you've passed preliminary checks, but is not a guarantee that the data has been successfully parsed and indexed as part of a distributed trace. 400 The structure of the request was invalid. Errors with query parameters, etc. 403 Authentication error. May occur with an invalid license key or if you lack necessary entitlement to use the Trace API. 404 The request path is incorrect. 405 For any request method other than POST. 408 The request took too long to reach the endpoint. 411 The Content-Length header wasn’t included. 413 The payload was too big. 414 The request URI was too long. 415 The Content-Type or Content-Encoding was invalid. 429 The request rate quota has been exceeded. 431 The request headers are too long. 5xx There was a server error (please retry). NrIntegrationError events (asynchronous). Errors with the JSON payload or other semantic errors are asynchronously signaled via NrIntegrationError events that are stored in the account whose license key is associated with the request. For all errors of this type, the attribute newRelicFeature will be Distributed Tracing and requestId will be the requestId from the endpoint response. If you receive a 202 response and don't see an NrIntegrationError event, your data should be visible in New Relic One's global distributed tracing UI in about a minute. You should be able to find the trace using a standard trace search like: traceId = TRACE_ID_SENT Copy Exceeding span limits When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate limit messages with this NRQL: SELECT * FROM NrIntegrationError WHERE newRelicFeature = 'Distributed Tracing' AND category = 'RateLimit' AND rateLimitType = 'SpansPerMinute' Copy To get a notification when you exceed the limit, you can set up a NRQL alert. We calculate a rolling 10-minute average based on your span rate limit. This allows for temporary rate bursts, and lets us prioritize keeping and dropping complete traces instead of indiscriminately dropping spans on a per minute limit basis. In the example below of exceeding the rate, the rate limit is the default 100,000 spans per minute. New Relic allows a burst above 100K for a couple of minutes without downsampling, because the remaining minutes in the 10-minute window averaged under 100K spans/minute. For the previous 10 minutes (8:50 - 9:00) the service received 60,000 spans/minute. Minute Spans sent to API Total for past 10 minutes 8:59 60,000 600,000 9:00 40,000 580,000 9:01 50,000 570,000 9:02 250,000 760,000 9:03 220,000 920,000 9:04 125,000 985,000 9:05 70,000 995,000 9:06 50,000 985,000 9:07 40,000 965,000 9:08 40,000 945,000 9:09 40,000 925,000",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 206.80264,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Trace</em> API general requirements <em>and</em> limits ",
        "sections": "<em>Trace</em> API general requirements <em>and</em> limits",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " be visible in New Relic One&#x27;s global <em>distributed</em> <em>tracing</em> <em>UI</em> in about a minute. You should be able to find the <em>trace</em> using a standard <em>trace</em> search like: <em>trace</em>Id = <em>TRACE</em>_ID_SENT Copy Exceeding span limits When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate"
      },
      "id": "6071cf7628ccbcf8b851c158"
    }
  ],
  "/docs/distributed-tracing/ui-data/understand-use-distributed-tracing-ui": [
    {
      "sections": [
        "Span attributes"
      ],
      "title": "Span attributes",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "725c10cb22b5d8f3b2a825c2dbf38b8640f93b13",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/span-attributes/",
      "published_at": "2021-06-14T18:09:35Z",
      "updated_at": "2021-06-02T17:14:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing creates Span data that can be queried in New Relic. Here are ways to learn more about Span data: To explore your span data, you can use the query builder. To see the default attributes attached to span data, use the data dictionary. For help with NRQL queries using these attributes, see these example queries.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 285.5905,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "<em>Distributed</em> <em>tracing</em> creates Span <em>data</em> that can be queried in New Relic. Here are ways to learn more about Span <em>data</em>: To explore your span <em>data</em>, you can use the query builder. To see the default attributes attached to span <em>data</em>, use the <em>data</em> dictionary. For help with NRQL queries using these attributes, see these example queries."
      },
      "id": "6072a767196a673e9964a7c3"
    },
    {
      "sections": [
        "Query distributed trace data",
        "Example NRQL queries",
        "Tip",
        "Datastore time percentile for an app",
        "Datastore query time for an app, faceted by host",
        "Average duration for a method of a service, faceted by host",
        "Histogram of external services called by a service, faceted by external URI",
        "Average duration for external calls across all applications",
        "Example NerdGraph queries",
        "Can't find data?"
      ],
      "title": "Query distributed trace data",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "7ad60264aa5c46ef3859a886fc5c97471ccfb02f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/query-distributed-trace-data/",
      "published_at": "2021-06-14T18:09:35Z",
      "updated_at": "2021-04-11T07:36:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can query your distributed tracing data in several ways: The search bar at top of the distributed tracing UI NRQL query NerdGraph GraphiQL explorer To learn about trace structure, see How distributed tracing works. Example NRQL queries Tip You can also construct complex queries in the search bar at the top of the distributed tracing UI. Some example NRQL queries: Datastore time percentile for an app SELECT percentile(duration, 50, 95) FROM Span WHERE category = 'datastore' and appName = 'YOUR_APP_NAME' SINCE 4 hours ago TIMESERIES 1 minute Copy Datastore query time for an app, faceted by host SELECT average(duration) FROM Span WHERE appName = 'YOUR_APP_NAME' and category = 'datastore' FACET host TIMESERIES 1 minute Copy Average duration for a method of a service, faceted by host SELECT average(duration) FROM Span WHERE appName = 'YOUR_APP_NAME' and name = 'FUNCTION_NAME' FACET host TIMESERIES 1 minute Copy Histogram of external services called by a service, faceted by external URI SELECT histogram(duration, 10, 60) FROM Span WHERE category = 'http' and appName = 'YOUR_APP_NAME' FACET `http.url` SINCE 4 hours ago Copy Average duration for external calls across all applications SELECT average(duration) FROM Span WHERE category = 'http' SINCE 4 hours ago FACET `http.url` TIMESERIES 1 minute Copy Example NerdGraph queries You can also use NerdGraph to query your trace data using the API. For more information, see the NerdGraph distributed tracing data query examples. Can't find data? Having trouble finding data when querying? See Troubleshooting: missing data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 223.57504,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Query <em>distributed</em> <em>trace</em> <em>data</em>",
        "sections": "Query <em>distributed</em> <em>trace</em> <em>data</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "You can query your <em>distributed</em> <em>tracing</em> <em>data</em> in several ways: The search bar at top of the <em>distributed</em> <em>tracing</em> <em>UI</em> NRQL query NerdGraph GraphiQL explorer To learn about <em>trace</em> structure, see How <em>distributed</em> <em>tracing</em> works. Example NRQL queries Tip You can also construct complex queries in the search"
      },
      "id": "6072a6ff196a67ddaf64a75a"
    },
    {
      "sections": [
        "Trace API general requirements and limits",
        "Endpoints",
        "Data formats",
        "Data limits",
        "Restricted attributes",
        "Request metadata (headers and query parameters)",
        "Important",
        "Response validation",
        "See HTTP status codes",
        "Exceeding span limits"
      ],
      "title": "Trace API general requirements and limits ",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "f77504082dae8374e0c7009a31abebbd4c0123f3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/trace-api-general-requirements-limits/",
      "published_at": "2021-06-14T18:07:42Z",
      "updated_at": "2021-06-09T00:57:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Information about Trace API data requirements, including: Data specifications and max limits Required metadata (headers, query parameters) Response validation details This document applies to the Trace API overall. For rules regarding specific data formats, see: New Relic-format trace data Zipkin-format trace data Endpoints All trace data is sent via a POST to a Trace API endpoint. We have a few endpoints, depending on your setup: Default Trace API endpoint: https://trace-api.newrelic.com/trace/v1 EU data centers: https://trace-api.eu.newrelic.com/trace/v1 (see other EU endpoints). Infinite Tracing: when you complete the Trace observer setup, you get a custom YOUR_TRACE_OBSERVER_URL value to use as an endpoint. If you're using an integration that uses the Trace API (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust the sampling of your tracing service to send us 100% of spans. For FedRAMP, see FedRAMP endpoints. Data formats Currently, the Trace API accepts two types of data formats: zipkin: For reporting Zipkin trace data. Zipkin data must be Zipkin JSON v2. newrelic: For reporting all other trace data. Data limits Data limits and rules: Condition Limit Max age of span timestamp values 20 minutes. timestamp must be within 20 minutes of current time at ingest, or within 20 minutes from the time the last span with the same trace.id was received by New Relic. Max payload size 1MB (10^6 bytes) (gzip compression supported) Max requests per minute 100K Max spans per minute per account family Dependent on agreement. Max limit: 2M. Max spans per trace 50K Max attributes per span 200 Max span attribute value length 4000 characters Allowed HTTP protocols HTTPS only Cross-account visibility of span details Potential data obfuscation To see an example of how span limits are enforced, see Exceeding limits. Restricted attributes The attributes in the table below are restricted in the newrelic-format JSON (in the attributes block) and in the zipkin-format JSON (in the tags block). Any values with these keys will be omitted: Restricted attribute Description entityGuid string Unique identifier for the entity that created this span. Generated from service.name, if available. guid string Used for backwards compatibility with data from APM agents. The attributes in the table below are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Restricted attribute description entity.guid string Unique identifier for the entity associated with this span. entity.name string Human-readable name of an entity, often used to identify an entity in the UI. entity.type string Used to differentiate between different types of entities, like hosts, applications, etc. Request metadata (headers and query parameters) The following table shows the required request metadata for all trace data formats. This metadata can be sent as HTTP headers on an ingest request or, in some cases, provided as query parameters, which may be required for tracing frameworks that don't allow header modification. Important Security note: We suggest using headers because query parameters are present in the URL and may be logged before being encrypted and received by New Relic. All data sent as query parameters must be URL-safe. Header Query param? Details Content-Type No Required. Must be application/json. Content-Length No Required. The length of the request body in octets (8-bit bytes) unless sent with chunked encoding. This header is generally set by default by the underlying HTTP client sending the data and in most cases should not require any additional effort by the end user. Api-Key Yes (case-sensitive) Required. The Trace API requires the Insights insert key. If this is provided as both a header and a query parameter, the values must match. Content-Encoding No Required if compressed payload. The value must be gzip. Data-Format Yes Required for zipkin. Optional for newrelic. If present, Data-Format-Version must also be present. Data-Format-Version Yes Required for zipkin. If present, Data-Format must also be present. There are only two possible pairings for these values: If Data-Format is zipkin, Data-Format-Version must be 2. If Data-Format is newrelic, Data-Format-Version must be 1. x-request-id No Optional - Reserved for future use. The value must be a valid UUID4. The value is expected to be unique for each request. Response validation A response for successfully sending trace data will include a requestId. For example: {\"requestId\":\"c1bb62fc-001a-b000-0000-016bb152e1bb\"} Copy There are two ways success/errors are signaled: HTTP status code (synchronous). Authentication and request errors will be signaled via HTTP status code. See HTTP status codes Code Meaning 202 Data accepted. This means that you've passed preliminary checks, but is not a guarantee that the data has been successfully parsed and indexed as part of a distributed trace. 400 The structure of the request was invalid. Errors with query parameters, etc. 403 Authentication error. May occur with an invalid license key or if you lack necessary entitlement to use the Trace API. 404 The request path is incorrect. 405 For any request method other than POST. 408 The request took too long to reach the endpoint. 411 The Content-Length header wasn’t included. 413 The payload was too big. 414 The request URI was too long. 415 The Content-Type or Content-Encoding was invalid. 429 The request rate quota has been exceeded. 431 The request headers are too long. 5xx There was a server error (please retry). NrIntegrationError events (asynchronous). Errors with the JSON payload or other semantic errors are asynchronously signaled via NrIntegrationError events that are stored in the account whose license key is associated with the request. For all errors of this type, the attribute newRelicFeature will be Distributed Tracing and requestId will be the requestId from the endpoint response. If you receive a 202 response and don't see an NrIntegrationError event, your data should be visible in New Relic One's global distributed tracing UI in about a minute. You should be able to find the trace using a standard trace search like: traceId = TRACE_ID_SENT Copy Exceeding span limits When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate limit messages with this NRQL: SELECT * FROM NrIntegrationError WHERE newRelicFeature = 'Distributed Tracing' AND category = 'RateLimit' AND rateLimitType = 'SpansPerMinute' Copy To get a notification when you exceed the limit, you can set up a NRQL alert. We calculate a rolling 10-minute average based on your span rate limit. This allows for temporary rate bursts, and lets us prioritize keeping and dropping complete traces instead of indiscriminately dropping spans on a per minute limit basis. In the example below of exceeding the rate, the rate limit is the default 100,000 spans per minute. New Relic allows a burst above 100K for a couple of minutes without downsampling, because the remaining minutes in the 10-minute window averaged under 100K spans/minute. For the previous 10 minutes (8:50 - 9:00) the service received 60,000 spans/minute. Minute Spans sent to API Total for past 10 minutes 8:59 60,000 600,000 9:00 40,000 580,000 9:01 50,000 570,000 9:02 250,000 760,000 9:03 220,000 920,000 9:04 125,000 985,000 9:05 70,000 995,000 9:06 50,000 985,000 9:07 40,000 965,000 9:08 40,000 945,000 9:09 40,000 925,000",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 206.80258,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Trace</em> API general requirements <em>and</em> limits ",
        "sections": "<em>Trace</em> API general requirements <em>and</em> limits",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " be visible in New Relic One&#x27;s global <em>distributed</em> <em>tracing</em> <em>UI</em> in about a minute. You should be able to find the <em>trace</em> using a standard <em>trace</em> search like: <em>trace</em>Id = <em>TRACE</em>_ID_SENT Copy Exceeding span limits When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate"
      },
      "id": "6071cf7628ccbcf8b851c158"
    }
  ],
  "/docs/fedramp-endpoint-logs-metrics": [
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-06-15T11:17:48Z",
      "updated_at": "2021-05-04T18:28:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and error_beacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 381.6437,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>FedRAMP</em>-compliant <em>endpoints</em>",
        "sections": "<em>FedRAMP</em>-compliant <em>endpoints</em>",
        "tags": "Security <em>and</em> Privacy",
        "body": " and error_beacon, like this: window.NREUM||(NREUM={});NREUM.info={&quot;beacon&quot;:&quot;gov-bam.nr-data.net&quot;,&quot;errorBeacon&quot;:&quot;gov-bam.nr-data.net&quot;... Copy Data-ingest APIs Below are details about the <em>FedRAMP</em> <em>endpoint</em> for our ingest APIs: <em>Metric</em> API, the Event API, the <em>Log</em> API, and the Trace API. <em>Metric</em> API To ensure"
      },
      "id": "603e945164441f64384e8872"
    },
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-06-15T08:26:52Z",
      "updated_at": "2021-05-28T09:38:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 27 May 2021. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits In the following table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Error tracking Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 369.05115,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Regulatory audits <em>for</em> New Relic services",
        "sections": "Customer <em>FedRAMP</em> obligations",
        "tags": "Security <em>and</em> Privacy",
        "body": " to be determined. New Relic service SOC2 <em>FedRAMP</em> Moderate (Agency level ATO) Alerts APM AWS <em>Metric</em> Streams Browser monitoring Error tracking Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of <em>log</em> patterns) <em>Metric</em> API Mobile agents"
      },
      "id": "603e81e728ccbc68bfeba794"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/whats-new/2021/03/fedramp-logs-metrics/",
      "sections": [
        "FedRAMP: Logs and Metrics now certified",
        "Accelerate government IT modernization"
      ],
      "published_at": "2021-06-15T04:06:39Z",
      "title": "FedRAMP: Logs and Metrics now certified",
      "updated_at": "2021-05-09T18:03:29Z",
      "type": "docs",
      "external_id": "683cc62dc2addc69602ccc714dcada9713161d6c",
      "document_type": "nr1_announcement",
      "popularity": 1,
      "body": "Accelerate government IT modernization ​ Protecting your data is our highest priority, which is why we achieved the US Government’s rigorous FedRAMP Moderate certification in 2020. And now we’re adding support for Logs and Metrics to our long list of supported services. ​ New Relic’s FedRAMP authority to operate enables US federal government customers (and those that work with the federal government) to get the same level of real-time insights as commercial organizations, while still ensuring compliance with established security standards ​ Access to New Relic’s FedRAMP environment is based on the following: ​ Your account must be specifically approved by New Relic. You must send your data only to New Relic’s FedRAMP-designated endpoints. Check out the Nerdlog segment below to learn more: Don’t miss the Nerdlog LIVE every Thursday at 12 p.m. PT (8 p.m. UTC) on Twitch to get the latest product updates from the people who built them. Subscribe to our weekly Nerdlog emails to get product updates like these directly in your inbox.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 354.2864,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>FedRAMP</em>: <em>Logs</em> <em>and</em> <em>Metrics</em> now certified",
        "sections": "<em>FedRAMP</em>: <em>Logs</em> <em>and</em> <em>Metrics</em> now certified",
        "body": "Accelerate government IT modernization ​ Protecting your data is our highest priority, which is why we achieved the US Government’s rigorous <em>FedRAMP</em> Moderate certification in 2020. And now we’re adding support for <em>Logs</em> and <em>Metrics</em> to our long list of supported services. ​ New Relic’s <em>FedRAMP</em>"
      },
      "id": "606a22bfe7b9d2706694462a"
    }
  ],
  "/docs/full-stack-observability/index": [
    {
      "sections": [
        "APM best practices guide",
        "Tip",
        "1. Standardize application names",
        "How to do it",
        "2. Add tags to your applications",
        "Caution",
        "3. Create and evaluate alert policies",
        "4. Identify and set up key transactions",
        "5. Track deployment history",
        "6. Review APM reports",
        "7. Review your environment with service maps",
        "8. Keep current",
        "9. Manage user access",
        "Important"
      ],
      "title": "APM best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Full-stack observability"
      ],
      "external_id": "368a1a5688384d5bebf128604a9b8f190d335524",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/apm-best-practices-guide/",
      "published_at": "2021-06-15T10:15:04Z",
      "updated_at": "2021-06-08T18:52:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Application Monitoring Tips You Need To Know It's one thing to know how to use APM, but it's another thing to know how to use New Relic's application performance monitoring software well. Here are some best practices designed to help you become an APM master—and a key asset to your team! Tip To get a high-level overview of all your applications and services, use the New Relic Explorer in New Relic One. 1. Standardize application names Most New Relic agents provide a default application name, such as \"My Application\" or \"PHP Application,\" if you don't specify one in your New Relic configuration file. You don't want to end up with 20 identically named applications, be sure to select a descriptive identifier for your apps as soon you deploy them. To keep things consistent and easy to navigate, New Relic recommends standardizing your application naming (for example, all apps in Staging append [ Staging] or the like at the end of their names). Ideally, you want your new Java applications to be named automatically to reduce the chances of typographical errors and misnaming. How to do it For Java applications, automatic application naming can come from the following sources: Request attribute Servlet init parameter Filter init parameter Web app context parameter Web app context name (display name) Web app context path Choose the method that fits best your needs and follow these steps. For non-Java applications, there are no automatic naming methods, so refer to the documentation for your APM agent. 2. Add tags to your applications When several different applications use the same account, and each application spans multiple environments (for example, development, test, pre-production, production), it can be hard to find a specific application in your overview dashboard. That's why we recommend adding tags to your apps so that you can segment them into logical groups. The two most common tags that mature APM customers use are application name and environment. So, for example, if you wanted to view the billing application in Test, you could simply filter by \"billing app\" (name tag) and \"test\" (environment tag). Caution In the APM agent configuration settings files, use the labels field to add tags to your data. For example, see this description of the Python labels setting. APM is designed so that apps can roll up into an unlimited number of meaningful tag categories. How to do it Learn about tags. Learn how to add tags.. Learn how to query tags. 3. Create and evaluate alert policies When key performance indicators spike or drop, individuals and teams in your organization need to be notified. Alerting in New Relic provides a set of tools including dynamic baselines that allow you to detect problems before they impact your end users. Alert policies can be set up in two primary ways: Static threshold alerts are great when you already know the nature of an application and its normal behaviors aren't likely to change anytime soon. Apdex score, response time, error rate, throughput are some of the static thresholds you can create alert policies on. Dynamic baseline alerts make it easy to determine and set dynamic alert thresholds for applications with varying seasonal patterns and growth trends (which make it difficult to set thresholds that define normal behavior). These alerts use baselines modeled from your application’s historical metric data. Each alert policy can contain as many conditions as you need, and each alert condition includes three components: Type of condition (metric, external service, and so on) Entities that the policy targets (for example, apps monitored by New Relic APM or New Relic Browser, hosts monitored by New Relic Infrastructure, and so on) Thresholds that escalate into alerting situations with increasing severity Once you have your alerting set up, you then want to make sure you're taking advantage of all viable notification channels. After all, what good are alerts if no one knows about them? You can manage alerts by creating specific user groups and by leveraging New Relic's integrated alert channels, including Slack, PagerDuty, webhooks, and email. Be sure to evaluate alert policies on a regular basis to ensure that they are always valid. How to do it See the detailed documentation: To set up dynamic baseline alerts and choose an application, follow standard procedures. You will see a preview of the metric with the predicted baseline You can select a metric for that application and see the corresponding baseline. Then, using the threshold sliders, you can set how closely you want your threshold to follow the baseline prediction. To set up static threshold alerts for your Apdex settings, follow standard procedures. To set up your alert notification channels, follow standard procedures. 4. Identify and set up key transactions Depending on the nature of your application, some transactions may be more important to you than others. New Relic's key transactions feature is designed to help you closely monitor what you consider to be your app's most business-critical transactions, whether that's end-user or app response time, call counts, error rates, or something else. You can also set alert threshold levels for notifications when your key transactions are performing poorly. How to do it In the menu bar, select More > Key transactions, and then select Add more. Then select the app and web transaction or, from the selected transaction, select Track as key transaction. Type a name for the key transaction, and select Track key transaction. Optional: If the agent for the selected app supports custom alerting, use the default values that New Relic automatically fills, or select Edit key alert transaction policy to set the Apdex and alert threshold values. To view the key transactions dashboard details, select View new key transaction. 5. Track deployment history When development teams are pushing new code out as frequently as possible, it can be hard to measure the impact that each deployment is having on performance. One way to stay in tune with how these changes are affecting your application is with deployment reports. These reports list recent deployments and their impact on end-users and app servers' Apdex scores, along with response times, throughput, and errors. You can also view and drill down into the details to catch errors related to recent deployments, or file a ticket and share details with your team. How to do it From the New Relic menu bar, select APM > (selected app) > Events > Deployments. To view performance after a deployment, go to the selected app's Overview dashboard in the Recent events section. A blue vertical bar on a chart indicates a deployment. To view summary information about the deployment, point to the blue bar. 6. Review APM reports From SLA, deployment, and capacity to scalability, host usage reports, and more, New Relic APM offers a variety of downloadable reporting tools surfacing historical trends—all great ways to report to senior executive teams or customers. Take a look at the full list of reports and use them to your advantage. How to do it From the New Relic APM menu bar, select Applications > (selected app) > Reports. Select the report you'd like to see. If you want to save or export a report to share, select Download this report as .csv, which will create a report with comma-separated values. 7. Review your environment with service maps Use New Relic service maps, a feature included in APM, to understand how apps and services in your architecture connect and talk to each other. Service maps are visual, customizable representations of your application architecture. Maps automatically show you your app's connections and dependencies, including databases and external services. Health indicators and performance metrics show you the current operational status for every part of your architecture. How to do it Go to one.newrelic.com > More > service maps. To get started, read the instructions in Introduction to service maps. 8. Keep current With New Relic’s SaaS platform, getting new features is as easy as updating your agent. Most likely your organization already has a set of scripts for deploying application upgrades into your environment. In a similar fashion, you can also automate your New Relic agent deployment to ensure that your systems are up to date. Both Puppet and Chef scripts are great examples of deployment frameworks that make life easier by allowing you to automate your entire deployment and management process. How to do it Regularly review which version of the agent you're using so that you know when an update is needed. If the latest agent release contains a needed fix or added functionality, download it. To deploy the agent automatically (preferred as a method to avoid errors): Use existing deployment scripts, provided they can be adapted to handle the deployment. OR Create and maintain a script that specifically deploys and configures the New Relic agent. Ideally, the script would pull the agent files from a repository where the files are versioned (for rollback purposes). Once the script has been created, shut down the application (unless script handles this). Run the deployment script. Start the application (unless script handles this). If problems arise, run the script to roll back to the previous version. To deploy the agent manually: Back up the current agent directory. Deploy the updated agent into the existing agent directory. Modify configuration files by comparing new files with existing files. In particular, make sure things like license key and custom extensions are copied over to the new configuration. Restart the application. If problems arise, restore the old agent using the backup and restart. 9. Manage user access Important This is available only for accounts on our original product-based pricing plan. Enable role-based access control (RBAC) and single sign-on (SSO) New Relic allows authorized individuals to access the broadest possible amount of data, regardless of their assigned role. As an Owner or Administrator of your New Relic account, you can control the permissions of individual users or entire roles with RBAC. To find out what is possible and how to make changes, see Users and roles. Security is no doubt of utmost concern to your organization. To simplify password management for your employees and strengthen security, you may already be using SSO with your other systems. You should do the same with New Relic. Using New Relic's SSO integration feature, account administrators will be able to enforce strong passwords and restrict login via a corporate authentication mechanism. This way, New Relic users who have already authenticated using a corporate SSO system will be able to bypass the New Relic login prompt. How to do it Log in to New Relic as an admin and go to the SSO configuration page. From the New Relic title bar, select (your account name) > Account Settings > Integrations > Single Sign On. From the SAML Single Sign On page, review your New Relic SAML Service Provider details. To upload your SAML Identity Provider certificate, select Choose File, and then follow standard procedures to select and save the file. Copy and paste in (or type) the Remove login URL that your users will use for Single Sign-On. If your organization’s SAML integration provides a redirect URL for logout, copy and paste in (or type) the Logout landing URL; otherwise leave blank. Save, test, and enable.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 948.70654,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Full</em>-<em>stack</em> <em>observability</em>",
        "body": " offers a variety of downloadable reporting tools surfacing historical trends—all great ways to report to senior executive teams or customers. Take a look at the <em>full</em> list of reports and use them to your advantage. How to do it From the New Relic APM menu bar, select Applications &gt; (selected app"
      },
      "id": "6044186564441f1f94378ecc"
    },
    {
      "sections": [
        "New Relic guided install overview",
        "Supported APM agents",
        "Why it matters",
        "Some technical detail",
        "Important",
        "On-host integration (OHI) recipes",
        "Troubleshoot common problems",
        "MySQL: Incorrect user permissions",
        "NGINX: No status URL"
      ],
      "title": "New Relic guided install overview",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Observe everything",
        "Get started"
      ],
      "external_id": "2058522f6cb1e82dbbe111a176c22ec4aa515ae5",
      "image": "https://docs.newrelic.com/static/6bf45ccf002250f7ebaa69cbe3ff706c/c1b63/guided-install-cli.png",
      "url": "https://docs.newrelic.com/docs/full-stack-observability/observe-everything/get-started/new-relic-guided-install-overview/",
      "published_at": "2021-06-15T06:57:56Z",
      "updated_at": "2021-05-09T18:29:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Instrument your systems and send telemetry data to New Relic with guided install. Our guided install creates a customized CLI command for your environment that downloads and installs the New Relic CLI and the infrastructure agent. Ready to get started? Click the Guided install button. If your account reports data through our EU datacenter, click EU Guided install. Guided install EU Guided install Our infrastructure agent discovers the applications and infrastructure and log sources running in your environment, and recommends which ones should be instrumented. The install automates the configuration and deployment of each system you choose to instrument. Supported APM agents If you have a .NET Windows application on IIS, the guided install configures and enables an APM agent. Guided install for .NET EU Guided install for .NET Why it matters With our guided install, you can instrument your applications and infrastructure and start seeing your data in New Relic in minutes. The guided install uses our command line interface (CLI), the infrastructure agent for your host environment, and a library of installation recipes to instrument your applications and infrastructure for you. That means less toil for you. Because our instrumentation recipes are open source, you can modify existing recipes, or build new ones, to suit your needs. Some technical detail The New Relic guided install uses open source installation recipes to instrument on-host integrations. These recipes include installation and setup commands, information about logs, and metadata related to what’s being installed. They're collected in a YAML file for each type of system and have all of the installation details necessary to install the infrastructure agent for a specific integration. Important On Windows, our guided install only supports Microsoft SQL Server, logs, and the infrastructure agent. All other integrations are only supported on Linux. On-host integration (OHI) recipes The guided install automates the discovery, configuration, and installation of OHIs. However, there may be times when you want to instrument them one-by-one using the CLI install command. To install any individual on-host integration, run this command: curl -Ls https://raw.githubusercontent.com/newrelic/newrelic-cli/master/scripts/install.sh | bash && sudo NEW_RELIC_API_KEY=API_KEY NEW_RELIC_ACCOUNT_ID=ACCOUNT_ID /usr/local/bin/newrelic install -n INTEGRATION-FLAG Copy For example: curl -Ls https://raw.githubusercontent.com/newrelic/newrelic-cli/master/scripts/install.sh | bash && sudo NEW_RELIC_API_KEY=<API_KEY> NEW_RELIC_ACCOUNT_ID=<ACCOUNT_ID> /usr/local/bin/newrelic install -n apache-open-source-integration Copy The table lists the integrations supported by the guided install CLI command. The specific on-host integration commands are provided for your reference. Our open source integrations send performance metrics and inventory data from your servers and applications to the New Relic platform. You can view pre-built dashboards of your metric data, create alert policies, and create your own custom queries and charts. Integration Command Apache newrelic install -n apache-open-source-integration Cassandra newrelic install -n cassandra-open-source-integration Couchbase newrelic install -n couchbase-open-source-integration ElasticSearch newrelic install -n elasticsearch-open-source-integration HAProxy newrelic install -n haproxy-open-source-integration HashiCorp Consul newrelic install -n hashicorp-consul-open-source-integration JMX newrelic install -n jmx-open-source-integration Memcached newrelic install -n memcached-open-source-integration Microsoft SQL Server (Windows only) newrelic install -n mssql-server-integration-installer MongoDB newrelic install -n mongodb-open-source-integration MySQL newrelic install -n mysql-open-source-integration Nagios newrelic install -n nagios-open-source-integration Nginx newrelic install -n nginx-open-source-integration PostgreSQL newrelic install -n postgres-open-source-integration RabbitMQ newrelic install -n rabbitmq-open-source-integration Redis newrelic install -n redis-open-source-integration Varnish Cache newrelic install -n varnish-cache-open-source-integration Troubleshoot common problems As we identify areas where the guided install fails, we'll document them here and provide some troubleshooting guidance. MySQL: Incorrect user permissions To monitor MySQL health data, you need a valid username and password with specific permissions. These commands will create a user and grant the required permissions: Create a user newrelic@localhost with a specific password. sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY 'YOUR_SELECTED_PASSWORD';\" Copy Give replication privileges to newrelic@localhost with a maximum of 5 connections. sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Copy Give select privileges to newrelic@localhost with a maximum of 5 connections. sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Copy Once done, your next guided install attempt should work. NGINX: No status URL To monitor your NGINX server, you'll need to configure a valid status URL. status_url: The URL set up to provide the metrics using the status module. If the default value of 127.0.0.1 is incorrect, substitute the address/FQDN/URL for your system. Example: status_url: http://127.0.0.1/status You can read more about the status_url in these NGINX docs: For NGINX Open Source: HTTP stub status module For NGINX Plus: HTTP status module and HTTP API module There are different ways to set status_url, depending on how NGINX was installed: If enabled via Kubernetes: See Monitor services running on Kubernetes. If enabled via Amazon ECS: See Monitor services running on ECS. If installed on-host: Edit the config in the integration's YAML config file, nginx-config.yml.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 823.9621,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Full</em>-<em>Stack</em> <em>Observability</em>"
      },
      "id": "604130a7e7b9d299cb2a07c0"
    },
    {
      "sections": [
        "Get started with Full-Stack Observability",
        "Tip",
        "You’re in control because you understand your system",
        "All the answers in one place",
        "Start anywhere"
      ],
      "title": "Get started with Full-Stack Observability",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Observe everything",
        "Get started"
      ],
      "external_id": "e7fc0bf91fa26b38a11933b6570c8b1e483a1ff9",
      "image": "https://docs.newrelic.com/static/44970161aec793f3141cfcdc0fc96a57/c1b63/observability.png",
      "url": "https://docs.newrelic.com/docs/full-stack-observability/observe-everything/get-started/get-started-full-stack-observability/",
      "published_at": "2021-06-15T06:57:56Z",
      "updated_at": "2021-03-16T08:30:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Full-Stack Observability is the power of knowing what is happening in your digital system and why, at any time, whatever solution you’re using. It’s getting the whole picture of everything that enables your applications and devices to deliver value to your customers, from the container running a microservice in the cloud to a mobile website's shopping cart button. Tip To use Full-Stack Observability and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. You’re in control because you understand your system New Relic helps you cut through the layers of complexity surrounding your systems by bringing together and connecting data from any instrumented source and environment, without having to jump between tools. You can interrogate your data for patterns, discover them using our data platform, or get proactive results from our machine learning tools. New Relic provides answers to essential questions in one place. All the answers in one place As a full user you get access to our entire set of observability tools. All our tools are interconnected and accessible in New Relic One. All the data you bring to New Relic through agents and integrations are metrics, events, logs, and traces that feed our platform's analytics and monitoring capabilities. New Relic links your data in a meaningful way so that you can explore it, build dashboards, and set up alerts. Full-Stack Observability curated experiences allow to visualize, analyze, and troubleshoot your entire software stack in one unified platform. The New Relic Explorer consolidates all the entities in your system, and how they're connected, in a single place, so you can easily detect performance trends and issues. By automatically connecting infrastructure health with application performance and end-user behavior, you can cut through the noise to find the signal. Start anywhere Being fully-connected, New Relic allows you to start your observability journey from any element of your stack. For example, you can get to crucial infrastructure logs from traces of an application running on a problematic Kubernetes pod. The more entities you instrument, the more data you'll bring in. The more data you've brought to New Relic, the more you'll understand your metrics, events, logs, and traces. You want to instrument Start with Keep exploring Front-end applications Mobile applications User behavior and flows New Relic Explorer Browser monitoring Mobile monitoring Synthetic monitoring Single page monitoring Scripted browsers Containerized minions Workloads Backend applications Serverless applications New Relic Explorer Application monitoring Serverless monitoring Learning about Apdex Distributed tracing Logs in context APM data to infrastructure Workloads Infrastructure hosts and services (on-premise, cloud, orchestrated) Container environments and orchestration tools (Kubernetes, ECS, etc.) Infrastructure monitoring Infrastructure integrations Kubernetes integration Docker integration ECS integration Log forwarding APM data to infrastructure Custom integrations Kubernetes cluster explorer Infrastructure alerts Workloads",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 736.8173,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "sections": "Get started with <em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "tags": "<em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "body": "<em>Full</em>-<em>Stack</em> <em>Observability</em> is the power of knowing what is happening in your digital system and why, at any time, whatever solution you’re using. It’s getting the whole picture of everything that enables your applications and devices to deliver value to your customers, from the container running"
      },
      "id": "603e891528ccbce6d9eba765"
    }
  ],
  "/docs/full-stack-observability/instrument-everything/develop-own-integrations/flex-integration-dummy": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/release-notes/infrastructure-release-notes/infrastructure-agent-release-notes/new-relic-infrastructure-agent-11145/",
      "sections": [
        "Infrastructure agent v1.11.45",
        "Notes",
        "Added",
        "Changed"
      ],
      "published_at": "2021-06-15T17:18:46Z",
      "title": "Infrastructure agent v1.11.45",
      "updated_at": "2021-03-16T11:52:43Z",
      "type": "docs",
      "external_id": "2fd96bcda44c225b677b43d4ddb049dc959ef455",
      "document_type": "release_notes",
      "popularity": 1,
      "body": "Notes A new version of the agent has been released. Follow standard procedures to update your Infrastructure agent. Added SystemSample has two new attributes,MemoryUsedPercent and MemoryFreePercent. The log forwarder now supports the pattern parameter for tcp and syslog For more information on the log forwarder feature, see Forward your logs using New Relic Infrastructure. Changed The built-in Flex integration has been updated to version 1.3.1. For more information, see the Flex changelog. Fluent Bit Output plugin for New Relic has been upgraded to v1.3.0. For more information, see the changelog.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 394.75775,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " on the log forwarder feature, see Forward your logs using <em>New</em> <em>Relic</em> Infrastructure. Changed The built-in <em>Flex</em> <em>integration</em> has been updated to version 1.3.1. For more information, see the <em>Flex</em> changelog. Fluent Bit Output plugin for <em>New</em> <em>Relic</em> has been upgraded to v1.3.0. For more information, see the changelog."
      },
      "id": "603e9523196a675455a83dc4"
    },
    {
      "sections": [
        "New Relic Flex: Build your own integration",
        "What is Flex?",
        "Requirements",
        "How does Flex work?",
        "Example config",
        "Learn more"
      ],
      "title": "New Relic Flex: Build your own integration",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Instrument everything",
        "Develop your own integrations"
      ],
      "external_id": "d9e77fa458eb408a90de1ebdd60891694ea6feb2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/host-integrations/host-integrations-list/flex-integration-tool-build-your-own-integration/",
      "published_at": "2021-06-15T11:55:37Z",
      "updated_at": "2021-03-11T08:47:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic provides integrations for many popular services and frameworks. If you have New Relic and want to report data from a service we don't have an integration for, there are several ways New Relic lets you create your own integration: With New Relic infrastructure monitoring, you can use our lightweight Flex tool (recommended, documented below) or, to build a complete on-host integration, see our Integrations SDK. Telemetry (metrics, traces) monitoring solutions: Use our Telemetry SDKs. Build a custom New Relic One application that uses your own JavaScript UI functionality. What is Flex? New Relic Flex is an application-agnostic, all-in-one tool that allows you to collect metric data from a wide variety of services. It comes bundled with our infrastructure agent. You can instrument any app that exposes metrics over a standard protocol (HTTP, file, shell) in a standard format (for example, JSON or plain text): you create a YAML config file, start the Infrastructure agent, and your data is reported to New Relic. Flex can send event and metric data to New Relic from a wide range of sources. Using a simple YAML config file, you can run HTTP/HTTPS requests, run shell commands, and parse file content. You can also use standard regex expressions to customize and control the data gathered from those inputs. See an example config. After collecting and cleaning up the data, you can then query Flex data in New Relic, create custom charts for it, and use that data in your dashboards. Requirements Flex comes bundled with our infrastructure agent. To use Flex, you need: Infrastructure agent version 1.10.7 or higher (update | check version) running on Linux, Windows, or Kubernetes. How does Flex work? Flex uses our infrastructure agent to execute commands that generate the data you want to report. Here's a brief overview of how Flex works to report data: You define the data you want to report in a YAML configuration file, located in the infrastructure agent package. See an example configuration: Example config The following is an example of a Flex configuration for monitoring the uptime of a Linux server. This configuration is placed in a file named flex-uptime.yml. This would be placed in the infrastructure agent's integration configuration section, located at /etc/newrelic-infra/integrations.d/flex-uptime.yml. integrations: - name: nri-flex config: name: linuxUptimeIntegration apis: - name: Uptime commands: - run: 'cat /proc/uptime' split: horizontal split_by: \\s+ set_header: [uptimeSeconds,idletimeSeconds] Copy Some notes on what this configuration does: run defines the command to execute. The name indicated by name: Uptime is appended with Sample to generate an event called UptimeSample. The name should not start with the ESX or PCF prefix. The split_by: \\s+ splits the fields based on the space character. The command generates attributes attached to the UptimeSample event. The attributes are named uptimeSeconds and idletimeSeconds. The infrastructure agent runs Flex at a frequency based on its own configuration (default: every 30 seconds) and sends the data to New Relic. You can then query your data, create custom charts with it, and add it to dashboards. Learn more The Flex integration comes bundled with the infrastructure agent. Learn more about requirements. To learn more, see our complete documentation on GitHub: README Tutorial",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.4801,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> <em>Flex</em>: Build your own <em>integration</em>",
        "sections": "<em>New</em> <em>Relic</em> <em>Flex</em>: Build your own <em>integration</em>",
        "tags": "Develop your own <em>integrations</em>",
        "body": " lightweight <em>Flex</em> tool (recommended, documented below) or, to build a complete on-host <em>integration</em>, see our Integrations SDK. Telemetry (metrics, traces) monitoring solutions: Use our Telemetry SDKs. Build a custom <em>New</em> <em>Relic</em> One application that uses your own JavaScript UI functionality. What is <em>Flex</em>"
      },
      "id": "6044e44f196a678d15960f6e"
    },
    {
      "sections": [
        "Kubernetes integration: install and configure",
        "Tip",
        "Use automated installer",
        "Installs for managed services and platforms",
        "Amazon EKS",
        "Amazon EKS Fargate",
        "Google Kubernetes Engine (GKE)",
        "OpenShift container platform",
        "Azure Kubernetes Service (AKS)",
        "Pivotal Container Service (PKS / VMware Tanzu)",
        "Custom manifest",
        "Important",
        "Make sure New Relic pods can be scheduled",
        "Unprivileged installs of the Kubernetes integration",
        "Steps to complete an unprivileged install",
        "Configure the integration",
        "Select which processes should send their data to New Relic",
        "Specify the Kubernetes API host and port",
        "Kubernetes versions 1.6 to 1.7.5: Edit manifest file",
        "Use environment variables",
        "Disable kube-state-metrics parsing",
        "Caution",
        "Specify the kube-state-metrics URL",
        "Discover kube-state-metrics pods using a label",
        "Query kube-state-metrics behind RBAC",
        "kube-state-metrics timeout: Increase the client timeout",
        "Non-default namespace deployments: Edit config file",
        "Set the TTL for the Kubernetes API responses cache",
        "Specify base URLs for control plane component endpoints",
        "Configure the infrastructure agent",
        "Update to the latest version",
        "Using the automated installer",
        "Using helm",
        "Uninstall the Kubernetes integration"
      ],
      "title": "Kubernetes integration: install and configure",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Installation"
      ],
      "external_id": "ff06c8b1d8b2940d0b23034f3057377ce571e4ab",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/installation/kubernetes-integration-install-configure/",
      "published_at": "2021-06-15T13:05:55Z",
      "updated_at": "2021-06-15T13:05:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The easiest way to install the Kubernetes integration is to use our automated installer to generate a manifest. It bundles not just the integration DaemonSets, but also other New Relic Kubernetes configurations, like Kubernetes events, Prometheus OpenMetrics, and New Relic log monitoring. Tip To use Kubernetes integrations and infrastructure monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Use automated installer You can use the automated installer for servers, VMs, and unprivileged environments. The installer can also help you with managed services or platforms after you review a few preliminary notes. We also have separate instructions if you need a custom manifest or prefer to do a manual unprivileged installation. Start the installer If your New Relic account is in the EU region, access the installer from one.eu.newrelic.com. Installs for managed services and platforms Before starting our automated installer, check out these notes for your managed services or platforms: Amazon EKS The Kubernetes integration monitors worker nodes. In Amazon EKS, master nodes are managed by Amazon and abstracted from the Kubernetes platforms. Before starting our automated installer to deploy the Kubernetes integration in Amazon EKS, make sure you are using the version of kubectl provided by AWS. Amazon EKS Fargate For help installing our EKS Fargate integration, see these setup options. Google Kubernetes Engine (GKE) The Kubernetes integration monitors worker nodes. In GKE, master nodes are managed by Google and abstracted from the Kubernetes platforms. Before starting our automated installer to deploy the Kubernetes integration on GKE, ensure you have sufficient permissions: Go to console.cloud.google.com/iam-admin/iam and find your username. Click edit. Ensure you have permissions to create Roles and ClusterRoles: If you are not sure, add the Kubernetes Engine Cluster Admin role. If you cannot edit your user role, ask the owner of the GCP project to give you the necessary permissions. Ensure you have a RoleBinding that grants you the same permissions to create Roles and ClusterRoles: kubectl create clusterrolebinding YOUR_USERNAME-cluster-admin-binding --clusterrole=cluster-admin --user=YOUR_GCP_EMAIL Copy Creating a RoleBinding is necessary because of a known RBAC issue in Kubernetes and Kubernetes Engine versions 1.6 or higher. For more information, see Google Cloud's documentation on defining permissions in a role. OpenShift container platform To deploy the Kubernetes integration with OpenShift: Add the <>{'<release_name>'}</>-newrelic-infrastructure service account to your privileged Security Context Constraints: oc adm policy add-scc-to-user privileged \\ system:serviceaccount:<namespace>:<release_name>-newrelic-infrastructure Copy The default <>{'<release_name>'}</> provided by the installer is nri-bundle. Complete the steps in our automated installer. If you're using signed certificates, make sure they are properly configured by using the following variables in the DaemonSet portion of your manifest to set the .pem file: - name: NRIA_CA_BUNDLE_DIR value: YOUR_CA_BUNDLE_DIR - name: NRIA_CA_BUNDLE_FILE value: YOUR_CA_BUNDLE_NAME Copy YAML key path: spec.template.spec.containers.name.env Save your changes. Azure Kubernetes Service (AKS) The Kubernetes integration monitors worker nodes. In Azure Kubernetes Service, master nodes are managed by Azure and abstracted from the Kubernetes platforms. To deploy in Azure Kubernetes Service (AKS), complete the steps in our automated installer. Pivotal Container Service (PKS / VMware Tanzu) To deploy in PKS, we recommend that you use the automated installer, or you can follow the manual instructions provided in Install the Kubernetes integration using Helm. Custom manifest If the Kubernetes automated installer doesn't provide the settings you need, you can download our manifest template and install the integration manually. To activate the Kubernetes integration, you must deploy the newrelic-infra agent onto a Kubernetes cluster as a DaemonSet: Install kube-state-metrics and get it running on the cluster. For example: curl -L -o kube-state-metrics- 1.9.5 .zip https://github.com/kubernetes/kube-state-metrics/archive/v 1.9.5 .zip && unzip kube-state-metrics- 1.9.5 .zip && kubectl apply -f kube-state-metrics- 1.9.5 /examples/standard Copy Download the manifest file: curl -O https://download.newrelic.com/infrastructure_agent/integrations/kubernetes/newrelic-infrastructure-k8s-latest.yaml Copy In the DaemonSet portion of your manifest, add your New Relic license key and a cluster name to identify your Kubernetes cluster. Both values are required. Recommendation: Do not change the NRIA_PASSTHROUGH_ENVIRONMENT or NRIA_DISPLAY_NAME value in your manifest. YOUR_CLUSTER_NAME is your cluster’s id in New Relic Explorer. It doesn’t need to match the name of the cluster running in your environment. YAML key path: spec.template.spec.containers.name.env env: - name: NRIA_LICENSE_KEY value: YOUR_LICENSE_KEY - name: CLUSTER_NAME value: YOUR_CLUSTER_NAME Copy If you need to adapt the manifest to fit your environment, review the configure section in this doc. Confirm that kube-state-metrics is installed. kubectl get pods --all-namespaces | grep kube-state-metrics Copy Create the DaemonSet: kubectl create -f newrelic-infrastructure-k8s-latest.yaml Copy Confirm that the DaemonSet has been created successfully by looking for newrelic-infra in the results generated by this command: kubectl get daemonsets Copy To confirm that the integration is working: wait a few minutes, then look for data in the New Relic Kubernetes cluster explorer. If you don't see data, review the configuration procedures again, then follow the troubleshooting procedures. Important In the future, the number of labels collected on Kubernetes objects will be limited per object type (containers, pods, nodes, etc.). If objects have labels above the limit, you will be able to configure important labels that should always be sent to New Relic. When the limitation is in place, this documentation will be updated. Make sure New Relic pods can be scheduled Some of the New Relic pods are set up as DaemonSet in the manifest file so that they can run on every host. These include newrelic-infrastructure and newrelic-logging. In rare circumstances, other pods may be scheduled first and starve the New Relic pods of resources. Since each of these pods have to run on a specific host, they will stay in pending status until that host has enough resources, even if there are other hosts available. This could end up occurring for long periods of time and result in reporting gaps. To prevent this scenario, you can configure the Kubernetes scheduler to give New Relic pods a higher priority. Using the default scheduler: Ensure kube-scheduler flag disablePreemption is not set to true (by default it is false). Create a PriorityClass for the New Relic DaemonSet pods: Set the appropriate priority value, which should generally be higher than your other pods. preemptionPolicy is set to PreemptLowerPriority by default. This allows New Relic pods assigned this priority class to remove lower-priority pods that are taking up resources. Edit the manifest file to add priorityClassName to any DaemonSet specs. In the example below, the highlighted line sets the priority class for newrelic-infrastructure: apiVersion: apps/v1 kind: DaemonSet metadata: namespace: default labels: app: newrelic-infrastructure chart: newrelic-infrastructure-1.0.0 release: nri-bundle mode: privileged name: nri-bundle-newrelic-infrastructure spec: priorityClassName: your-priority-class ... Copy If you have already deployed the New Relic pods, re-deploy them and confirm they have been created: kubectl delete -f newrelic-infrastructure-k8s-latest.yaml kubectl create -f newrelic-infrastructure-k8s-latest.yaml kubectl get daemonsets Copy Unprivileged installs of the Kubernetes integration For platforms that have stringent security requirements, we provide an unprivileged version of the Kubernetes integration. Changes from the standard Kubernetes integration are: Runs the infrastructure agent and the Kubernetes integration as a standard user instead of root No access to the underlying host filesystem No access to /var/run/docker.sock Container's root filesystem mounted as read-only allowPrivilegeEscalation is set to false hostnetwork is set to false The tradeoff is that the solution will only collect metrics from Kubernetes, but it will not collect any metric from the underlying hosts directly. Kubernetes provides some data (metrics and metadata) about its nodes (hosts). Tip Optional: To collect the underlying host metrics, the non-containerized infrastructure agent can be deployed on the underlying host. The infrastructure agent already supports running as non-root. The combination of the Kubernetes integration in its unprivileged version and the agent running on the host will report all the metrics that our standard solution for monitoring Kubernetes receives. Steps to complete an unprivileged install Install kube-state-metrics and get it running on the cluster. For example: curl -L -o kube-state-metrics- 1.9.5 .zip https://github.com/kubernetes/kube-state-metrics/archive/v 1.9.5 .zip && unzip kube-state-metrics- 1.9.5 .zip && kubectl apply -f kube-state-metrics- 1.9.5 /examples/standard Copy Download the integration manifest: curl -O https://download.newrelic.com/infrastructure_agent/integrations/kubernetes/newrelic-infrastructure-k8s-unprivileged-latest.yaml Copy In the manifest, add your New Relic license key and a cluster name to identify your Kubernetes cluster. Both values are required. Important YOUR_CLUSTER_NAME is your cluster’s id in New Relic Explorer. It doesn’t need to match the name of the cluster running in your environment. env: - name: NRIA_LICENSE_KEY value: YOUR_LICENSE_KEY - name: CLUSTER_NAME value: YOUR_CLUSTER_NAME Copy YAML key path: spec.template.spec.containers.name.env Confirm that kube-state-metrics is installed. kubectl get pods --all-namespaces | grep kube-state-metrics Copy Create the DaemonSet: kubectl create -f newrelic-infrastructure-k8s-unprivileged-latest.yaml Copy Confirm that the DaemonSet has been created successfully by looking for newrelic-infra in the results generated by this command: kubectl get daemonsets Copy To confirm that the integration has been configured correctly, wait a few minutes, then run this NRQL query to see if data has been reported: SELECT * FROM K8sPodSample since 5 minutes ago Copy Configure the integration The Kubernetes integration comes with a default configuration that should work in most environments. To change the configuration, modify the manifest file: Select which processes should send their data to New Relic By default, data about the processes running on your pods is not sent to New Relic. You can enable it by setting enable_process_metrics to true. To choose what metric data you want to send to New Relic, configure the include_matching_metrics environment variable in your manifest. Specify the Kubernetes API host and port This is necessary when you are using SSL and not using the default FQDN. The Kubernetes API FQDN needs to match the FQDN of the SSL certificate. You do not need to specify both variables. For example, if you only specify the HOST, the default PORT will be used. - name: \"KUBERNETES_SERVICE_HOST\" value: \"KUBERNETES_API_HOST\" - name: \"KUBERNETES_SERVICE_PORT\" value: \"KUBERNETES_API_TCP_PORT\" Copy Kubernetes versions 1.6 to 1.7.5: Edit manifest file For Kubernetes versions 1.6 to 1.7.5, uncomment these two lines in the manifest file: - name: \"CADVISOR_PORT\" # Enable direct connection to cAdvisor by specifying the port. Needed for Kubernetes versions prior to 1.7.6. value: \"4194\" Copy Use environment variables Use environment variables that can be passed to the Kubernetes integration if you use a proxy to configure its URL. Disable kube-state-metrics parsing You can disable kube-state-metrics parsing for the DaemonSet by using the following configuration: - name: \"DISABLE_KUBE_STATE_METRICS\" value: \"true\" Copy Caution Disabling kube-state-metrics also disables data collection for the following: ReplicaSets DaemonSets StatefulSets Namespaces Deployments Services Endpoints Pods (that are pending) Additionally, disabling this affects the Kubernetes Cluster Explorer in the following ways: No pending pods are shown. No filters based on services. Specify the kube-state-metrics URL If several instances of kube-state-metrics are present in the cluster, uncomment and configure the following lines to specify which one to use: - name: \"KUBE_STATE_METRICS_URL\" value: \"http://KUBE_STATE_METRICS_IP_OR_FQDN:PORT\" Copy Important Even though a KUBE_STATE_METRICS_URL is defined, the KSM service should contain one of the following labels for the auto-discovery process: k8s-app=kube-state-metrics OR app=kube-state-metrics OR ​​app.kubernetes.io/name=kube-state-metrics Important This configuration option overrides KUBE_STATE_METRICS_POD_LABEL. If you have both defined, KUBE_STATE_METRICS_POD_LABEL has no effect. Discover kube-state-metrics pods using a label If several instances of kube-state-metrics are present in the cluster, another option to easily target one of these instances with the Kubernetes integration is to use label-based discovery. - name: \"KUBE_STATE_METRICS_POD_LABEL\" value: \"LABEL_NAME\" Copy Important When a KUBE_STATE_METRICS_POD_LABEL is defined, the label should have a value equal to true. For example, if the label name is my-ksm, ensure that my-ksm=true. Important This configuration option is incompatible with KUBE_STATE_METRICS_URL. If you have both defined, KUBE_STATE_METRICS_URL is used. Query kube-state-metrics behind RBAC If your instance of kube-state-metrics is behind kube-rbac-proxy, the integration can be configured in a compatible way using the combination of the label-based discovery and two other environment variables: - name: \"KUBE_STATE_METRICS_SCHEME\" value: \"https\" - name: \"KUBE_STATE_METRICS_PORT\" value: \"KSM_RBAC_PROXY_PORT\" Copy To confirm which port should be used as the value of KUBE_STATE_METRICS_PORT, we recommend running a describe command on the kube-state-metrics pod and look for the port exposed by the container named kube-rbac-proxy-main. Important These two configuration options only work when using the KUBE_STATE_METRICS_POD_LABEL configuration described above. kube-state-metrics timeout: Increase the client timeout To increase the client timeout of kube-state-metrics, add a new environment variable, TIMEOUT, to the manifest file: env: - name: TIMEOUT value: 5000 # The default client timeout when calling kube-state-metrics, in milliseconds Copy Then, add this new environment variable to the NRIA_PASSTHROUGH_ENVIRONMENT Non-default namespace deployments: Edit config file If you want to deploy in a different namespace from default, change all values of namespace in the manifest. Set the TTL for the Kubernetes API responses cache By default, the integration will cache any retrieved information from the Kubernetes API for 5 minutes. Use the API_SERVER_CACHE_TTL environment variable to set a custom cache duration for responses from the API server. Valid time unit values are: ns, us, ms, s, m, and h. To disable caching, set to 0s. env: - name: API_SERVER_CACHE_TTL value: \"1m\" Copy Specify base URLs for control plane component endpoints Use the following environment variables if any of the Kubernetes control plane components export metrics on base URLs that are different from the defaults. This is necessary for environments such as OpenShift when a control plane component metrics endpoint is using SSL or an alternate port. Values of these environment variables must be base URLs of the form [scheme]://[host]:[port]. URLs should not include a path component. For example: - name: \"SCHEDULER_ENDPOINT_URL\" value: \"https://localhost:10259\" - name: \"ETCD_ENDPOINT_URL\" value: \"https://localhost:9979\" - name: \"CONTROLLER_MANAGER_ENDPOINT_URL\" value: \"https://localhost:10257\" - name: \"API_SERVER_ENDPOINT_URL\" value: \"https://localhost:6443\" Copy The /metrics path segment is added automatically. In addition, if the https scheme is used, authentication to the control plane component pod(s) is accomplished via service accounts. Caution If a FQDN (fully qualified domain name) is used in a multi-master cluster, inconsistent results may be returned. Therefore, it is recommended to use localhost only. Important Even though a custom base URL is defined for a given control plane component, the control plane component pod(s) must contain one of the labels supported by the auto-discovery process. Important Even though a custom ETCD_ENDPOINT_URL can be defined, ETCD will always require https and mTLS authentication to be configured. Here are some additional configurations to consider: Do more configuration for control plane monitoring Link New Relic APM to the Kubernetes integration Monitor services that run on Kubernetes Configure the infrastructure agent The Kubernetes integration image comes with a default configurations for the agent that can be modified if needed. When installing with the manifest, you can modify the infrastructure agent configuration by editing the manifest and adding any needed configuration option of the agent as environment variables of the newrelic-infrastructure DaemonSet. When installing with Helm, you can specify the needed infrastructure agent configuration options in the values.yaml as shown in the example in GitHub. The config object is used to populate the configMap that is mounted automatically in the location of the infrastructure agent configuration file in the pods created by the newrelic-infrastructure DaemonSet. Update to the latest version Using the automated installer To update a Kubernetes integration installed with the automated installer, just run the installer again. It will always offer a manifest pointing to the last released version of the integration. Using helm See Install the Kubernetes integration using Helm Custom manifest If you are already running the Kubernetes integration and want to update the newrelic-infra agent to the latest agent version: Run this NRQL query to check which version you are currently running (this will return the image name by cluster): SELECT latest(containerImage) FROM K8sContainerSample WHERE containerImage LIKE '%newrelic/infrastructure%' FACET clusterName SINCE 1 day ago Copy If you've set a name other than newrelic/infrastructure for the integration's container image, the above query won't yield results: to make it work, edit the name in the query. Download the integration manifest file: curl -O https://download.newrelic.com/infrastructure_agent/integrations/kubernetes/newrelic-infrastructure-k8s-latest.yaml Copy Copy the changes you made to the manifest. At a minimum, include CLUSTER_NAME and NRIA_LICENSE_KEY, and paste your changes in the manifest you downloaded. Install the latest DaemonSet with the following command (Kubernetes will automatically do a rollout upgrade for the integration's pods): kubectl apply -f newrelic-infrastructure-k8s-latest.yaml Copy Uninstall the Kubernetes integration To uninstall the Kubernetes integration: Verify that newrelic-infrastructure-k8s-latest.yaml corresponds to the filename of the manifest as you have saved it. Example: If you are using the unprivileged version of the integration, the default filename will be newrelic-infrastructure-k8s-unprivileged-latest.yaml. After you verify the filename, use the following command: kubectl delete -f newrelic-infrastructure-k8s-latest.yaml Copy You only need to execute this command once, regardless of the number of nodes in your cluster.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 95.78129,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Kubernetes <em>integration</em>: install and configure",
        "sections": "Kubernetes <em>integration</em>: install and configure",
        "tags": "<em>Integrations</em>",
        "body": "The easiest way to install the Kubernetes <em>integration</em> is to use our automated installer to generate a manifest. It bundles not just the <em>integration</em> DaemonSets, but also other <em>New</em> <em>Relic</em> Kubernetes configurations, like Kubernetes events, Prometheus OpenMetrics, and <em>New</em> <em>Relic</em> log monitoring. Tip"
      },
      "id": "60450ae964441f0603378f15"
    }
  ],
  "/docs/full-stack-observability/instrument-everything/get-started-new-relic-instrumentation/introduction-new-relic-integrations": [
    {
      "sections": [
        "New Relic guided install overview",
        "Supported APM agents",
        "Why it matters",
        "Some technical detail",
        "Important",
        "On-host integration (OHI) recipes",
        "Troubleshoot common problems",
        "MySQL: Incorrect user permissions",
        "NGINX: No status URL"
      ],
      "title": "New Relic guided install overview",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Observe everything",
        "Get started"
      ],
      "external_id": "2058522f6cb1e82dbbe111a176c22ec4aa515ae5",
      "image": "https://docs.newrelic.com/static/6bf45ccf002250f7ebaa69cbe3ff706c/c1b63/guided-install-cli.png",
      "url": "https://docs.newrelic.com/docs/full-stack-observability/observe-everything/get-started/new-relic-guided-install-overview/",
      "published_at": "2021-06-15T06:57:56Z",
      "updated_at": "2021-05-09T18:29:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Instrument your systems and send telemetry data to New Relic with guided install. Our guided install creates a customized CLI command for your environment that downloads and installs the New Relic CLI and the infrastructure agent. Ready to get started? Click the Guided install button. If your account reports data through our EU datacenter, click EU Guided install. Guided install EU Guided install Our infrastructure agent discovers the applications and infrastructure and log sources running in your environment, and recommends which ones should be instrumented. The install automates the configuration and deployment of each system you choose to instrument. Supported APM agents If you have a .NET Windows application on IIS, the guided install configures and enables an APM agent. Guided install for .NET EU Guided install for .NET Why it matters With our guided install, you can instrument your applications and infrastructure and start seeing your data in New Relic in minutes. The guided install uses our command line interface (CLI), the infrastructure agent for your host environment, and a library of installation recipes to instrument your applications and infrastructure for you. That means less toil for you. Because our instrumentation recipes are open source, you can modify existing recipes, or build new ones, to suit your needs. Some technical detail The New Relic guided install uses open source installation recipes to instrument on-host integrations. These recipes include installation and setup commands, information about logs, and metadata related to what’s being installed. They're collected in a YAML file for each type of system and have all of the installation details necessary to install the infrastructure agent for a specific integration. Important On Windows, our guided install only supports Microsoft SQL Server, logs, and the infrastructure agent. All other integrations are only supported on Linux. On-host integration (OHI) recipes The guided install automates the discovery, configuration, and installation of OHIs. However, there may be times when you want to instrument them one-by-one using the CLI install command. To install any individual on-host integration, run this command: curl -Ls https://raw.githubusercontent.com/newrelic/newrelic-cli/master/scripts/install.sh | bash && sudo NEW_RELIC_API_KEY=API_KEY NEW_RELIC_ACCOUNT_ID=ACCOUNT_ID /usr/local/bin/newrelic install -n INTEGRATION-FLAG Copy For example: curl -Ls https://raw.githubusercontent.com/newrelic/newrelic-cli/master/scripts/install.sh | bash && sudo NEW_RELIC_API_KEY=<API_KEY> NEW_RELIC_ACCOUNT_ID=<ACCOUNT_ID> /usr/local/bin/newrelic install -n apache-open-source-integration Copy The table lists the integrations supported by the guided install CLI command. The specific on-host integration commands are provided for your reference. Our open source integrations send performance metrics and inventory data from your servers and applications to the New Relic platform. You can view pre-built dashboards of your metric data, create alert policies, and create your own custom queries and charts. Integration Command Apache newrelic install -n apache-open-source-integration Cassandra newrelic install -n cassandra-open-source-integration Couchbase newrelic install -n couchbase-open-source-integration ElasticSearch newrelic install -n elasticsearch-open-source-integration HAProxy newrelic install -n haproxy-open-source-integration HashiCorp Consul newrelic install -n hashicorp-consul-open-source-integration JMX newrelic install -n jmx-open-source-integration Memcached newrelic install -n memcached-open-source-integration Microsoft SQL Server (Windows only) newrelic install -n mssql-server-integration-installer MongoDB newrelic install -n mongodb-open-source-integration MySQL newrelic install -n mysql-open-source-integration Nagios newrelic install -n nagios-open-source-integration Nginx newrelic install -n nginx-open-source-integration PostgreSQL newrelic install -n postgres-open-source-integration RabbitMQ newrelic install -n rabbitmq-open-source-integration Redis newrelic install -n redis-open-source-integration Varnish Cache newrelic install -n varnish-cache-open-source-integration Troubleshoot common problems As we identify areas where the guided install fails, we'll document them here and provide some troubleshooting guidance. MySQL: Incorrect user permissions To monitor MySQL health data, you need a valid username and password with specific permissions. These commands will create a user and grant the required permissions: Create a user newrelic@localhost with a specific password. sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY 'YOUR_SELECTED_PASSWORD';\" Copy Give replication privileges to newrelic@localhost with a maximum of 5 connections. sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Copy Give select privileges to newrelic@localhost with a maximum of 5 connections. sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Copy Once done, your next guided install attempt should work. NGINX: No status URL To monitor your NGINX server, you'll need to configure a valid status URL. status_url: The URL set up to provide the metrics using the status module. If the default value of 127.0.0.1 is incorrect, substitute the address/FQDN/URL for your system. Example: status_url: http://127.0.0.1/status You can read more about the status_url in these NGINX docs: For NGINX Open Source: HTTP stub status module For NGINX Plus: HTTP status module and HTTP API module There are different ways to set status_url, depending on how NGINX was installed: If enabled via Kubernetes: See Monitor services running on Kubernetes. If enabled via Amazon ECS: See Monitor services running on ECS. If installed on-host: Edit the config in the integration's YAML config file, nginx-config.yml.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.91368,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "body": "<em>Instrument</em> your systems and send telemetry data to New Relic with guided install. Our guided install creates a customized CLI command for your environment that downloads and installs the New Relic CLI and the infrastructure agent. Ready to <em>get</em> <em>started</em>? Click the Guided install button. If your"
      },
      "id": "604130a7e7b9d299cb2a07c0"
    },
    {
      "sections": [
        "Cloud services integrations",
        "AWS integrations",
        "GCP integrations",
        "Azure integrations"
      ],
      "title": "Cloud services integrations",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Instrument everything",
        "Instrument core services and applications"
      ],
      "external_id": "71020c70edfb43072cbf081b3eccd3b18f9e6289",
      "image": "https://docs.newrelic.com/static/78ac85c1fc41f94776fce7235e327f01/69538/img-integration-aws%25402x.png",
      "url": "https://docs.newrelic.com/docs/full-stack-observability/instrument-everything/instrument-core-services-applications/cloud-services-integrations/",
      "published_at": "2021-06-14T21:34:14Z",
      "updated_at": "2021-03-16T06:35:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With New Relic you can easily instrument your services in AWS, Google Cloud Platform, and Azure. AWS integrations Introduction to AWS integrations List of AWS integrations GCP integrations Introduction to GCP integrations List of GCP integrations Azure integrations Introduction to Azure integrations List of Azure integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.32175,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "body": "With New Relic you can easily <em>instrument</em> your services in AWS, Google Cloud Platform, and Azure. AWS integrations Introduction to AWS integrations List of AWS integrations GCP integrations Introduction to GCP integrations List of GCP integrations Azure integrations Introduction to Azure integrations List of Azure integrations"
      },
      "id": "603e829ae7b9d20bb12a080c"
    },
    {
      "sections": [
        "New Relic Flex: Build your own integration",
        "What is Flex?",
        "Requirements",
        "How does Flex work?",
        "Example config",
        "Learn more"
      ],
      "title": "New Relic Flex: Build your own integration",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Instrument everything",
        "Develop your own integrations"
      ],
      "external_id": "d9e77fa458eb408a90de1ebdd60891694ea6feb2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/host-integrations/host-integrations-list/flex-integration-tool-build-your-own-integration/",
      "published_at": "2021-06-15T11:55:37Z",
      "updated_at": "2021-03-11T08:47:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic provides integrations for many popular services and frameworks. If you have New Relic and want to report data from a service we don't have an integration for, there are several ways New Relic lets you create your own integration: With New Relic infrastructure monitoring, you can use our lightweight Flex tool (recommended, documented below) or, to build a complete on-host integration, see our Integrations SDK. Telemetry (metrics, traces) monitoring solutions: Use our Telemetry SDKs. Build a custom New Relic One application that uses your own JavaScript UI functionality. What is Flex? New Relic Flex is an application-agnostic, all-in-one tool that allows you to collect metric data from a wide variety of services. It comes bundled with our infrastructure agent. You can instrument any app that exposes metrics over a standard protocol (HTTP, file, shell) in a standard format (for example, JSON or plain text): you create a YAML config file, start the Infrastructure agent, and your data is reported to New Relic. Flex can send event and metric data to New Relic from a wide range of sources. Using a simple YAML config file, you can run HTTP/HTTPS requests, run shell commands, and parse file content. You can also use standard regex expressions to customize and control the data gathered from those inputs. See an example config. After collecting and cleaning up the data, you can then query Flex data in New Relic, create custom charts for it, and use that data in your dashboards. Requirements Flex comes bundled with our infrastructure agent. To use Flex, you need: Infrastructure agent version 1.10.7 or higher (update | check version) running on Linux, Windows, or Kubernetes. How does Flex work? Flex uses our infrastructure agent to execute commands that generate the data you want to report. Here's a brief overview of how Flex works to report data: You define the data you want to report in a YAML configuration file, located in the infrastructure agent package. See an example configuration: Example config The following is an example of a Flex configuration for monitoring the uptime of a Linux server. This configuration is placed in a file named flex-uptime.yml. This would be placed in the infrastructure agent's integration configuration section, located at /etc/newrelic-infra/integrations.d/flex-uptime.yml. integrations: - name: nri-flex config: name: linuxUptimeIntegration apis: - name: Uptime commands: - run: 'cat /proc/uptime' split: horizontal split_by: \\s+ set_header: [uptimeSeconds,idletimeSeconds] Copy Some notes on what this configuration does: run defines the command to execute. The name indicated by name: Uptime is appended with Sample to generate an event called UptimeSample. The name should not start with the ESX or PCF prefix. The split_by: \\s+ splits the fields based on the space character. The command generates attributes attached to the UptimeSample event. The attributes are named uptimeSeconds and idletimeSeconds. The infrastructure agent runs Flex at a frequency based on its own configuration (default: every 30 seconds) and sends the data to New Relic. You can then query your data, create custom charts with it, and add it to dashboards. Learn more The Flex integration comes bundled with the infrastructure agent. Learn more about requirements. To learn more, see our complete documentation on GitHub: README Tutorial",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.64003,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "body": "? New Relic Flex is an application-agnostic, all-in-one tool that allows you to collect metric data from a wide variety of services. It comes bundled with our infrastructure agent. You can <em>instrument</em> any app that exposes metrics over a standard protocol (HTTP, file, shell) in a standard format"
      },
      "id": "6044e44f196a678d15960f6e"
    }
  ],
  "/docs/full-stack-observability/instrument-everything/instrument-core-services-applications/cloud-services-integrations": [
    {
      "sections": [
        "Introduction to New Relic integrations",
        "Tip",
        "Choose what's right for you",
        "Create your own solutions"
      ],
      "title": "Introduction to New Relic integrations",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Instrument everything",
        "Get started"
      ],
      "external_id": "03217983a29af22737c1163da9ef0811b29c2bcd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/full-stack-observability/instrument-everything/get-started-new-relic-instrumentation/introduction-new-relic-integrations/",
      "published_at": "2021-06-14T21:34:14Z",
      "updated_at": "2021-03-16T07:30:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We provide hundreds of solutions to get your data into New Relic so you can analyze the data in one place. They give you a steady flow of useful data to fix problems quickly, maintain complex systems, improve your code, and accelerate your digital transformation. You can bring in data from hundreds of applications, frameworks, services, operating systems, and other technologies. Our integrations gather the data, and the agents send it to New Relic. The solution you need may require you to install both an integration and an agent. In some cases, you can just install our agents that contain integrations, such as our APM agents. Whatever data you need to bring in, chances are that we have options for your environment. If you prefer to make your own solutions, we also offer tools to get you started. Tip To use integrations and infrastructure monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Choose what's right for you We offer a wide range of solutions so you can easily collect data across your environment. You may only need one of our solutions to get the data you need, or you can choose a variety of options to capture a broader range of data types. Go to New Relic Integrations to find solutions that fit your environment. Here is a sample of what you’ll find there: Application performance monitoring (APM): C, Go, Java, Node, .NET, PHP, Python, and Ruby Mobile apps: Android and iOS Browser monitoring: Google Chrome, Mozilla Firefox, Microsoft Internet Explorer, and Apple Safari Host monitoring: Linux and Microsoft Windows Cloud platform monitoring: Amazon Web Services (AWS), Microsoft Azure, and Google Cloud Platform (GCP) Core infrastructure services: Kubernetes, NGINX, MySQL, and more Open source telemetry integrations: Prometheus, Micrometer, OpenTelemetry, and more Create your own solutions If you are looking for custom options, we have tools to help you create your own: Use New Relic Flex to create lightweight monitoring solutions using infrastructure monitoring. Use New Relic Telemetry SDKs to build custom solutions for sending metrics, traces, and more. Build your own New Relic One applications that you can share with your colleagues, or edit open source applications in our catalog.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 175.89197,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "body": " of <em>applications</em>, frameworks, <em>services</em>, operating systems, and other technologies. Our integrations gather the data, and the agents send it to New Relic. The solution you need may require you to install both an integration and an agent. In some cases, you can just install our agents that contain"
      },
      "id": "603e817f28ccbc4857eba798"
    },
    {
      "sections": [
        "New Relic Flex: Build your own integration",
        "What is Flex?",
        "Requirements",
        "How does Flex work?",
        "Example config",
        "Learn more"
      ],
      "title": "New Relic Flex: Build your own integration",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Instrument everything",
        "Develop your own integrations"
      ],
      "external_id": "d9e77fa458eb408a90de1ebdd60891694ea6feb2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/host-integrations/host-integrations-list/flex-integration-tool-build-your-own-integration/",
      "published_at": "2021-06-15T11:55:37Z",
      "updated_at": "2021-03-11T08:47:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic provides integrations for many popular services and frameworks. If you have New Relic and want to report data from a service we don't have an integration for, there are several ways New Relic lets you create your own integration: With New Relic infrastructure monitoring, you can use our lightweight Flex tool (recommended, documented below) or, to build a complete on-host integration, see our Integrations SDK. Telemetry (metrics, traces) monitoring solutions: Use our Telemetry SDKs. Build a custom New Relic One application that uses your own JavaScript UI functionality. What is Flex? New Relic Flex is an application-agnostic, all-in-one tool that allows you to collect metric data from a wide variety of services. It comes bundled with our infrastructure agent. You can instrument any app that exposes metrics over a standard protocol (HTTP, file, shell) in a standard format (for example, JSON or plain text): you create a YAML config file, start the Infrastructure agent, and your data is reported to New Relic. Flex can send event and metric data to New Relic from a wide range of sources. Using a simple YAML config file, you can run HTTP/HTTPS requests, run shell commands, and parse file content. You can also use standard regex expressions to customize and control the data gathered from those inputs. See an example config. After collecting and cleaning up the data, you can then query Flex data in New Relic, create custom charts for it, and use that data in your dashboards. Requirements Flex comes bundled with our infrastructure agent. To use Flex, you need: Infrastructure agent version 1.10.7 or higher (update | check version) running on Linux, Windows, or Kubernetes. How does Flex work? Flex uses our infrastructure agent to execute commands that generate the data you want to report. Here's a brief overview of how Flex works to report data: You define the data you want to report in a YAML configuration file, located in the infrastructure agent package. See an example configuration: Example config The following is an example of a Flex configuration for monitoring the uptime of a Linux server. This configuration is placed in a file named flex-uptime.yml. This would be placed in the infrastructure agent's integration configuration section, located at /etc/newrelic-infra/integrations.d/flex-uptime.yml. integrations: - name: nri-flex config: name: linuxUptimeIntegration apis: - name: Uptime commands: - run: 'cat /proc/uptime' split: horizontal split_by: \\s+ set_header: [uptimeSeconds,idletimeSeconds] Copy Some notes on what this configuration does: run defines the command to execute. The name indicated by name: Uptime is appended with Sample to generate an event called UptimeSample. The name should not start with the ESX or PCF prefix. The split_by: \\s+ splits the fields based on the space character. The command generates attributes attached to the UptimeSample event. The attributes are named uptimeSeconds and idletimeSeconds. The infrastructure agent runs Flex at a frequency based on its own configuration (default: every 30 seconds) and sends the data to New Relic. You can then query your data, create custom charts with it, and add it to dashboards. Learn more The Flex integration comes bundled with the infrastructure agent. Learn more about requirements. To learn more, see our complete documentation on GitHub: README Tutorial",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.64003,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "body": "? New Relic Flex is an application-agnostic, all-in-one tool that allows you to collect metric data from a wide variety of <em>services</em>. It comes bundled with our infrastructure agent. You can <em>instrument</em> any app that exposes metrics over a standard protocol (HTTP, file, shell) in a standard format"
      },
      "id": "6044e44f196a678d15960f6e"
    },
    {
      "sections": [
        "APM best practices guide",
        "Tip",
        "1. Standardize application names",
        "How to do it",
        "2. Add tags to your applications",
        "Caution",
        "3. Create and evaluate alert policies",
        "4. Identify and set up key transactions",
        "5. Track deployment history",
        "6. Review APM reports",
        "7. Review your environment with service maps",
        "8. Keep current",
        "9. Manage user access",
        "Important"
      ],
      "title": "APM best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Full-stack observability"
      ],
      "external_id": "368a1a5688384d5bebf128604a9b8f190d335524",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/apm-best-practices-guide/",
      "published_at": "2021-06-15T10:15:04Z",
      "updated_at": "2021-06-08T18:52:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Application Monitoring Tips You Need To Know It's one thing to know how to use APM, but it's another thing to know how to use New Relic's application performance monitoring software well. Here are some best practices designed to help you become an APM master—and a key asset to your team! Tip To get a high-level overview of all your applications and services, use the New Relic Explorer in New Relic One. 1. Standardize application names Most New Relic agents provide a default application name, such as \"My Application\" or \"PHP Application,\" if you don't specify one in your New Relic configuration file. You don't want to end up with 20 identically named applications, be sure to select a descriptive identifier for your apps as soon you deploy them. To keep things consistent and easy to navigate, New Relic recommends standardizing your application naming (for example, all apps in Staging append [ Staging] or the like at the end of their names). Ideally, you want your new Java applications to be named automatically to reduce the chances of typographical errors and misnaming. How to do it For Java applications, automatic application naming can come from the following sources: Request attribute Servlet init parameter Filter init parameter Web app context parameter Web app context name (display name) Web app context path Choose the method that fits best your needs and follow these steps. For non-Java applications, there are no automatic naming methods, so refer to the documentation for your APM agent. 2. Add tags to your applications When several different applications use the same account, and each application spans multiple environments (for example, development, test, pre-production, production), it can be hard to find a specific application in your overview dashboard. That's why we recommend adding tags to your apps so that you can segment them into logical groups. The two most common tags that mature APM customers use are application name and environment. So, for example, if you wanted to view the billing application in Test, you could simply filter by \"billing app\" (name tag) and \"test\" (environment tag). Caution In the APM agent configuration settings files, use the labels field to add tags to your data. For example, see this description of the Python labels setting. APM is designed so that apps can roll up into an unlimited number of meaningful tag categories. How to do it Learn about tags. Learn how to add tags.. Learn how to query tags. 3. Create and evaluate alert policies When key performance indicators spike or drop, individuals and teams in your organization need to be notified. Alerting in New Relic provides a set of tools including dynamic baselines that allow you to detect problems before they impact your end users. Alert policies can be set up in two primary ways: Static threshold alerts are great when you already know the nature of an application and its normal behaviors aren't likely to change anytime soon. Apdex score, response time, error rate, throughput are some of the static thresholds you can create alert policies on. Dynamic baseline alerts make it easy to determine and set dynamic alert thresholds for applications with varying seasonal patterns and growth trends (which make it difficult to set thresholds that define normal behavior). These alerts use baselines modeled from your application’s historical metric data. Each alert policy can contain as many conditions as you need, and each alert condition includes three components: Type of condition (metric, external service, and so on) Entities that the policy targets (for example, apps monitored by New Relic APM or New Relic Browser, hosts monitored by New Relic Infrastructure, and so on) Thresholds that escalate into alerting situations with increasing severity Once you have your alerting set up, you then want to make sure you're taking advantage of all viable notification channels. After all, what good are alerts if no one knows about them? You can manage alerts by creating specific user groups and by leveraging New Relic's integrated alert channels, including Slack, PagerDuty, webhooks, and email. Be sure to evaluate alert policies on a regular basis to ensure that they are always valid. How to do it See the detailed documentation: To set up dynamic baseline alerts and choose an application, follow standard procedures. You will see a preview of the metric with the predicted baseline You can select a metric for that application and see the corresponding baseline. Then, using the threshold sliders, you can set how closely you want your threshold to follow the baseline prediction. To set up static threshold alerts for your Apdex settings, follow standard procedures. To set up your alert notification channels, follow standard procedures. 4. Identify and set up key transactions Depending on the nature of your application, some transactions may be more important to you than others. New Relic's key transactions feature is designed to help you closely monitor what you consider to be your app's most business-critical transactions, whether that's end-user or app response time, call counts, error rates, or something else. You can also set alert threshold levels for notifications when your key transactions are performing poorly. How to do it In the menu bar, select More > Key transactions, and then select Add more. Then select the app and web transaction or, from the selected transaction, select Track as key transaction. Type a name for the key transaction, and select Track key transaction. Optional: If the agent for the selected app supports custom alerting, use the default values that New Relic automatically fills, or select Edit key alert transaction policy to set the Apdex and alert threshold values. To view the key transactions dashboard details, select View new key transaction. 5. Track deployment history When development teams are pushing new code out as frequently as possible, it can be hard to measure the impact that each deployment is having on performance. One way to stay in tune with how these changes are affecting your application is with deployment reports. These reports list recent deployments and their impact on end-users and app servers' Apdex scores, along with response times, throughput, and errors. You can also view and drill down into the details to catch errors related to recent deployments, or file a ticket and share details with your team. How to do it From the New Relic menu bar, select APM > (selected app) > Events > Deployments. To view performance after a deployment, go to the selected app's Overview dashboard in the Recent events section. A blue vertical bar on a chart indicates a deployment. To view summary information about the deployment, point to the blue bar. 6. Review APM reports From SLA, deployment, and capacity to scalability, host usage reports, and more, New Relic APM offers a variety of downloadable reporting tools surfacing historical trends—all great ways to report to senior executive teams or customers. Take a look at the full list of reports and use them to your advantage. How to do it From the New Relic APM menu bar, select Applications > (selected app) > Reports. Select the report you'd like to see. If you want to save or export a report to share, select Download this report as .csv, which will create a report with comma-separated values. 7. Review your environment with service maps Use New Relic service maps, a feature included in APM, to understand how apps and services in your architecture connect and talk to each other. Service maps are visual, customizable representations of your application architecture. Maps automatically show you your app's connections and dependencies, including databases and external services. Health indicators and performance metrics show you the current operational status for every part of your architecture. How to do it Go to one.newrelic.com > More > service maps. To get started, read the instructions in Introduction to service maps. 8. Keep current With New Relic’s SaaS platform, getting new features is as easy as updating your agent. Most likely your organization already has a set of scripts for deploying application upgrades into your environment. In a similar fashion, you can also automate your New Relic agent deployment to ensure that your systems are up to date. Both Puppet and Chef scripts are great examples of deployment frameworks that make life easier by allowing you to automate your entire deployment and management process. How to do it Regularly review which version of the agent you're using so that you know when an update is needed. If the latest agent release contains a needed fix or added functionality, download it. To deploy the agent automatically (preferred as a method to avoid errors): Use existing deployment scripts, provided they can be adapted to handle the deployment. OR Create and maintain a script that specifically deploys and configures the New Relic agent. Ideally, the script would pull the agent files from a repository where the files are versioned (for rollback purposes). Once the script has been created, shut down the application (unless script handles this). Run the deployment script. Start the application (unless script handles this). If problems arise, run the script to roll back to the previous version. To deploy the agent manually: Back up the current agent directory. Deploy the updated agent into the existing agent directory. Modify configuration files by comparing new files with existing files. In particular, make sure things like license key and custom extensions are copied over to the new configuration. Restart the application. If problems arise, restore the old agent using the backup and restart. 9. Manage user access Important This is available only for accounts on our original product-based pricing plan. Enable role-based access control (RBAC) and single sign-on (SSO) New Relic allows authorized individuals to access the broadest possible amount of data, regardless of their assigned role. As an Owner or Administrator of your New Relic account, you can control the permissions of individual users or entire roles with RBAC. To find out what is possible and how to make changes, see Users and roles. Security is no doubt of utmost concern to your organization. To simplify password management for your employees and strengthen security, you may already be using SSO with your other systems. You should do the same with New Relic. Using New Relic's SSO integration feature, account administrators will be able to enforce strong passwords and restrict login via a corporate authentication mechanism. This way, New Relic users who have already authenticated using a corporate SSO system will be able to bypass the New Relic login prompt. How to do it Log in to New Relic as an admin and go to the SSO configuration page. From the New Relic title bar, select (your account name) > Account Settings > Integrations > Single Sign On. From the SAML Single Sign On page, review your New Relic SAML Service Provider details. To upload your SAML Identity Provider certificate, select Choose File, and then follow standard procedures to select and save the file. Copy and paste in (or type) the Remove login URL that your users will use for Single Sign-On. If your organization’s SAML integration provides a redirect URL for logout, copy and paste in (or type) the Logout landing URL; otherwise leave blank. Save, test, and enable.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.54008,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "2. Add tags to your <em>applications</em>",
        "tags": "<em>Full</em>-<em>stack</em> <em>observability</em>",
        "body": " a high-level overview of all your <em>applications</em> and <em>services</em>, use the New Relic Explorer in New Relic One. 1. Standardize application names Most New Relic agents provide a default application name, such as &quot;My Application&quot; or &quot;PHP Application,&quot; if you don&#x27;t specify one in your New Relic"
      },
      "id": "6044186564441f1f94378ecc"
    }
  ],
  "/docs/full-stack-observability/observe-everything/get-started/get-started-auto-telemetry-pixie": [
    {
      "sections": [
        "Query Auto-telemetry with Pixie data",
        "Important",
        "Metrics and specifications",
        "HTTP metrics",
        "JVM metrics",
        "HTTP server span"
      ],
      "title": "Query Auto-telemetry with Pixie data",
      "type": "docs",
      "tags": [
        "Pixie Auto-telemetry",
        "Service monitoring",
        "Kubernetes",
        "eBPF"
      ],
      "external_id": "b831bc206beeaa77720e0fed4dba93e503a9ffa3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/understand-use-data/auto-telemetry-pixie-data-model/",
      "published_at": "2021-06-15T13:11:14Z",
      "updated_at": "2021-05-26T17:51:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important Auto-telemetry with Pixie is a supported public beta. Therefore, the features and functionality are subject to change. By joining the beta for Auto-telemetry with Pixie, you agree to the terms in the New Relic Pre-Release Policy. Auto-telemetry with Pixie pulls data from the Pixie Cloud API and sends it to the New Relic OpenTelemetry endpoint. You can build your own charts and query your Auto-telemetry with Pixie data using the query builder and the NerdGraph API. Find out more about getting started with Auto-telemetry with Pixie here. Metrics and specifications HTTP metrics Query for duration of inbound HTTP request. For example: FROM Metric SELECT average(http.server.duration) FACET service.name WHERE instrumentation.provider='pixie' Copy Event type Metric Metric name http.server.duration Spec OpenTelemetry HTTP metric spec Description Measures the duration of the inbound HTTP request. OTEL data type MetricDataTypeDoubleSummary with min(quantile=0) and max(quantile=1) Unit milliseconds Required attributes service.name Static attributes instrumentation.provider = pixie HTTP attributes http.status_code Entity attributes service.instance.id k8s.cluster.name k8s.namespace.name k8s.pod.name k8s.container.name JVM metrics Query to measure the time spent in a given JVM garbage collectors in milliseconds. For example: FROM Metric SELECT average(runtime.jvm.gc.collection) FACET service.name, gc WHERE instrumentation.provider='pixie' Copy Event type Metric Metric name runtime.jvm.gc.collection Spec opentelemetry.jvm.gc.collection Description Time spent in a given JVM garbage collector in milliseconds. Unit milliseconds Required attributes service.name Static attributes instrumentation.provider = pixie JVM attributes gc = young|full Entity attributes service.instance.id k8s.cluster.name k8s.namespace.name k8s.pod.name k8s.container.name Query to find out the number of bytes in a given JVM memory area. For example: FROM Metric SELECT average(runtime.jvm.memory.area) FACET service.name WHERE type='used' AND instrumentation.provider='pixie' Copy Event type Metric Metric name runtime.jvm.memory.area Spec opentelemetry-java-instrumentation Description Bytes of a given JVM memory area. Unit bytes Required attributes service.name Static attributes instrumentation.provider = pixie JVM attributes type = used|total|max area = heap Entity attributes service.instance.id k8s.cluster.name k8s.namespace.name k8s.pod.name k8s.container.name HTTP server span Example query: FROM Span SELECT uniques(name) WHERE span.kind='server' AND instrumentation.provider='pixie' AND service.name='orders' Copy Spec Semantic conventions for HTTP spans Event type Span Required attributes name = normalized HTTP path service.name trace.id span.id Static attributes span.kind = server instrumentation.provider = pixie HTTP attributes http.host http.method http.path http.status_code http.url http.user_agent",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 357.2979,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Query <em>Auto</em>-<em>telemetry</em> with <em>Pixie</em> data",
        "sections": "Query <em>Auto</em>-<em>telemetry</em> with <em>Pixie</em> data",
        "tags": "<em>Pixie</em> <em>Auto</em>-<em>telemetry</em>",
        "body": "Important <em>Auto</em>-<em>telemetry</em> with <em>Pixie</em> is a supported public beta. Therefore, the features and functionality are subject to change. By joining the beta for <em>Auto</em>-<em>telemetry</em> with <em>Pixie</em>, you agree to the terms in the New Relic Pre-Release Policy. <em>Auto</em>-<em>telemetry</em> with <em>Pixie</em> pulls data from the <em>Pixie</em> Cloud"
      },
      "id": "60ae8aaf28ccbcc3c477a3ec"
    },
    {
      "image": "https://docs.newrelic.com/static/3b7d4417336ed5ef2eb3beb02d4affea/ae694/kubernetes-cluster-explorer.png",
      "url": "https://docs.newrelic.com/whats-new/2021/05/pixie-kubernetes-post-5-26/",
      "sections": [
        "Instant Kubernetes observability with Pixie",
        "Get started today"
      ],
      "published_at": "2021-06-15T04:22:12Z",
      "title": "Instant Kubernetes observability with Pixie",
      "updated_at": "2021-05-28T15:26:33Z",
      "type": "docs",
      "external_id": "f132310e72ece8cefc9e318b433c15cddfafa389",
      "document_type": "nr1_announcement",
      "popularity": 1,
      "body": "We've removed the largest barriers to Kubernetes observability: The time and expertise required to manually instrument application code, by integrating Pixie Auto-Telemetry into our Kubernetes solution. Now, you can get visibility into your Kubernetes clusters and workloads instantly without installing language agents. Pixie data helps you debug faster than ever before, giving you access to everything on-cluster without sampling, then using AI/ML models to send the most relevant subset of your data to the Telemetry Data Platform for correlation with other services, intelligent alerting, and long term storage. Pixie Auto-Telemetry uses eBPF to automatically collect metrics, events, logs, and traces for your Kubernetes clusters, applications, OS, and network layers. Start fast: No code to update, new deployments, or lengthy monitoring standardization processes. Observe everything: Analyze data on-cluster using AI/ML without sampling, storing high-value telemetry data for alerting, correlation, and long term storage. Debug faster with Pixie’s developer-focused workflows, providing code-level insights. Get started today In New Relic One, choose Add more data. Choose Guided install or EU Guided install. Choose Kubernetes, and then follow the on-screen prompts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 314.5839,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Instant <em>Kubernetes</em> observability with <em>Pixie</em>",
        "sections": "Instant <em>Kubernetes</em> observability with <em>Pixie</em>",
        "body": ", and long term storage. <em>Pixie</em> <em>Auto</em>-<em>Telemetry</em> uses <em>eBPF</em> to automatically collect metrics, events, logs, and traces for your <em>Kubernetes</em> clusters, applications, OS, and network layers. Start fast: No code to update, new deployments, or lengthy <em>monitoring</em> standardization processes. Observe everything: Analyze"
      },
      "id": "60aeed8a28ccbc146b77a392"
    },
    {
      "sections": [
        "Kubernetes integration: compatibility and requirements",
        "Compatibility",
        "Requirements",
        "Install using Helm"
      ],
      "title": "Kubernetes integration: compatibility and requirements",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Get started"
      ],
      "external_id": "e9bbd729904fa01739eb91e4f3c74561b51c2ba1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/get-started/kubernetes-integration-compatibility-requirements/",
      "published_at": "2021-06-15T13:04:07Z",
      "updated_at": "2021-06-15T13:04:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Kubernetes integration can be installed directly on a server or VM, or through several cloud platforms, such as GKE, EKS, AKS, or OpenShift. Each has a different compatibility with our integration. Compatibility Our Kubernetes integration is compatible with the following versions, depending on the installation mode: Install mode or feature Kubernetes versions Kubernetes cluster Currently tested with versions 1.10 to 1.21 Kubernetes cluster GKE Currently tested with versions 1.10 and 1.17 Kubernetes cluster EKS (EC2 nodes or Fargate) Compatible with version 1.11 or higher Kubernetes cluster AKS Compatible with version 1.11 or higher Kubernetes cluster OpenShift Currently tested with versions 3.7, 3.9, 4.2, 4.3, 4.4, 4.5 and 4.6 Control plane monitoring Compatible with version 1.11 or higher Service monitoring Compatible with version 1.13 or higher Requirements The New Relic Kubernetes integration has the following requirements: Linux distribution compatible with New Relic infrastructure agent. kube-state-metrics version 1.9.5 running on the cluster. When using CRI-O as the container runtime, the processes inside containers are not reported. Performance data is collected at the container level. Install using Helm For compatibility and requirements when installing the Kubernetes integration using Helm, see Alternative install using Helm.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 96.33374,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Kubernetes</em> integration: compatibility and requirements",
        "sections": "<em>Kubernetes</em> integration: compatibility and requirements",
        "tags": "<em>Kubernetes</em> integration",
        "body": " <em>Kubernetes</em> cluster AKS Compatible with version 1.11 or higher <em>Kubernetes</em> cluster OpenShift Currently tested with versions 3.7, 3.9, 4.2, 4.3, 4.4, 4.5 and 4.6 Control plane <em>monitoring</em> Compatible with version 1.11 or higher <em>Service</em> <em>monitoring</em> Compatible with version 1.13 or higher Requirements The New Relic"
      },
      "id": "603e92dc64441f3a974e8891"
    }
  ],
  "/docs/full-stack-observability/observe-everything/get-started/get-started-full-stack-observability": [
    {
      "sections": [
        "New Relic guided install overview",
        "Supported APM agents",
        "Why it matters",
        "Some technical detail",
        "Important",
        "On-host integration (OHI) recipes",
        "Troubleshoot common problems",
        "MySQL: Incorrect user permissions",
        "NGINX: No status URL"
      ],
      "title": "New Relic guided install overview",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Observe everything",
        "Get started"
      ],
      "external_id": "2058522f6cb1e82dbbe111a176c22ec4aa515ae5",
      "image": "https://docs.newrelic.com/static/6bf45ccf002250f7ebaa69cbe3ff706c/c1b63/guided-install-cli.png",
      "url": "https://docs.newrelic.com/docs/full-stack-observability/observe-everything/get-started/new-relic-guided-install-overview/",
      "published_at": "2021-06-15T06:57:56Z",
      "updated_at": "2021-05-09T18:29:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Instrument your systems and send telemetry data to New Relic with guided install. Our guided install creates a customized CLI command for your environment that downloads and installs the New Relic CLI and the infrastructure agent. Ready to get started? Click the Guided install button. If your account reports data through our EU datacenter, click EU Guided install. Guided install EU Guided install Our infrastructure agent discovers the applications and infrastructure and log sources running in your environment, and recommends which ones should be instrumented. The install automates the configuration and deployment of each system you choose to instrument. Supported APM agents If you have a .NET Windows application on IIS, the guided install configures and enables an APM agent. Guided install for .NET EU Guided install for .NET Why it matters With our guided install, you can instrument your applications and infrastructure and start seeing your data in New Relic in minutes. The guided install uses our command line interface (CLI), the infrastructure agent for your host environment, and a library of installation recipes to instrument your applications and infrastructure for you. That means less toil for you. Because our instrumentation recipes are open source, you can modify existing recipes, or build new ones, to suit your needs. Some technical detail The New Relic guided install uses open source installation recipes to instrument on-host integrations. These recipes include installation and setup commands, information about logs, and metadata related to what’s being installed. They're collected in a YAML file for each type of system and have all of the installation details necessary to install the infrastructure agent for a specific integration. Important On Windows, our guided install only supports Microsoft SQL Server, logs, and the infrastructure agent. All other integrations are only supported on Linux. On-host integration (OHI) recipes The guided install automates the discovery, configuration, and installation of OHIs. However, there may be times when you want to instrument them one-by-one using the CLI install command. To install any individual on-host integration, run this command: curl -Ls https://raw.githubusercontent.com/newrelic/newrelic-cli/master/scripts/install.sh | bash && sudo NEW_RELIC_API_KEY=API_KEY NEW_RELIC_ACCOUNT_ID=ACCOUNT_ID /usr/local/bin/newrelic install -n INTEGRATION-FLAG Copy For example: curl -Ls https://raw.githubusercontent.com/newrelic/newrelic-cli/master/scripts/install.sh | bash && sudo NEW_RELIC_API_KEY=<API_KEY> NEW_RELIC_ACCOUNT_ID=<ACCOUNT_ID> /usr/local/bin/newrelic install -n apache-open-source-integration Copy The table lists the integrations supported by the guided install CLI command. The specific on-host integration commands are provided for your reference. Our open source integrations send performance metrics and inventory data from your servers and applications to the New Relic platform. You can view pre-built dashboards of your metric data, create alert policies, and create your own custom queries and charts. Integration Command Apache newrelic install -n apache-open-source-integration Cassandra newrelic install -n cassandra-open-source-integration Couchbase newrelic install -n couchbase-open-source-integration ElasticSearch newrelic install -n elasticsearch-open-source-integration HAProxy newrelic install -n haproxy-open-source-integration HashiCorp Consul newrelic install -n hashicorp-consul-open-source-integration JMX newrelic install -n jmx-open-source-integration Memcached newrelic install -n memcached-open-source-integration Microsoft SQL Server (Windows only) newrelic install -n mssql-server-integration-installer MongoDB newrelic install -n mongodb-open-source-integration MySQL newrelic install -n mysql-open-source-integration Nagios newrelic install -n nagios-open-source-integration Nginx newrelic install -n nginx-open-source-integration PostgreSQL newrelic install -n postgres-open-source-integration RabbitMQ newrelic install -n rabbitmq-open-source-integration Redis newrelic install -n redis-open-source-integration Varnish Cache newrelic install -n varnish-cache-open-source-integration Troubleshoot common problems As we identify areas where the guided install fails, we'll document them here and provide some troubleshooting guidance. MySQL: Incorrect user permissions To monitor MySQL health data, you need a valid username and password with specific permissions. These commands will create a user and grant the required permissions: Create a user newrelic@localhost with a specific password. sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY 'YOUR_SELECTED_PASSWORD';\" Copy Give replication privileges to newrelic@localhost with a maximum of 5 connections. sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Copy Give select privileges to newrelic@localhost with a maximum of 5 connections. sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Copy Once done, your next guided install attempt should work. NGINX: No status URL To monitor your NGINX server, you'll need to configure a valid status URL. status_url: The URL set up to provide the metrics using the status module. If the default value of 127.0.0.1 is incorrect, substitute the address/FQDN/URL for your system. Example: status_url: http://127.0.0.1/status You can read more about the status_url in these NGINX docs: For NGINX Open Source: HTTP stub status module For NGINX Plus: HTTP status module and HTTP API module There are different ways to set status_url, depending on how NGINX was installed: If enabled via Kubernetes: See Monitor services running on Kubernetes. If enabled via Amazon ECS: See Monitor services running on ECS. If installed on-host: Edit the config in the integration's YAML config file, nginx-config.yml.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 244.45534,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "body": "Instrument your systems and send telemetry data to New Relic with guided install. Our guided install creates a customized CLI command for your environment that downloads and installs the New Relic CLI and the infrastructure agent. Ready to <em>get</em> <em>started</em>? Click the Guided install button. If your"
      },
      "id": "604130a7e7b9d299cb2a07c0"
    },
    {
      "sections": [
        "APM best practices guide",
        "Tip",
        "1. Standardize application names",
        "How to do it",
        "2. Add tags to your applications",
        "Caution",
        "3. Create and evaluate alert policies",
        "4. Identify and set up key transactions",
        "5. Track deployment history",
        "6. Review APM reports",
        "7. Review your environment with service maps",
        "8. Keep current",
        "9. Manage user access",
        "Important"
      ],
      "title": "APM best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Full-stack observability"
      ],
      "external_id": "368a1a5688384d5bebf128604a9b8f190d335524",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/apm-best-practices-guide/",
      "published_at": "2021-06-15T10:15:04Z",
      "updated_at": "2021-06-08T18:52:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Application Monitoring Tips You Need To Know It's one thing to know how to use APM, but it's another thing to know how to use New Relic's application performance monitoring software well. Here are some best practices designed to help you become an APM master—and a key asset to your team! Tip To get a high-level overview of all your applications and services, use the New Relic Explorer in New Relic One. 1. Standardize application names Most New Relic agents provide a default application name, such as \"My Application\" or \"PHP Application,\" if you don't specify one in your New Relic configuration file. You don't want to end up with 20 identically named applications, be sure to select a descriptive identifier for your apps as soon you deploy them. To keep things consistent and easy to navigate, New Relic recommends standardizing your application naming (for example, all apps in Staging append [ Staging] or the like at the end of their names). Ideally, you want your new Java applications to be named automatically to reduce the chances of typographical errors and misnaming. How to do it For Java applications, automatic application naming can come from the following sources: Request attribute Servlet init parameter Filter init parameter Web app context parameter Web app context name (display name) Web app context path Choose the method that fits best your needs and follow these steps. For non-Java applications, there are no automatic naming methods, so refer to the documentation for your APM agent. 2. Add tags to your applications When several different applications use the same account, and each application spans multiple environments (for example, development, test, pre-production, production), it can be hard to find a specific application in your overview dashboard. That's why we recommend adding tags to your apps so that you can segment them into logical groups. The two most common tags that mature APM customers use are application name and environment. So, for example, if you wanted to view the billing application in Test, you could simply filter by \"billing app\" (name tag) and \"test\" (environment tag). Caution In the APM agent configuration settings files, use the labels field to add tags to your data. For example, see this description of the Python labels setting. APM is designed so that apps can roll up into an unlimited number of meaningful tag categories. How to do it Learn about tags. Learn how to add tags.. Learn how to query tags. 3. Create and evaluate alert policies When key performance indicators spike or drop, individuals and teams in your organization need to be notified. Alerting in New Relic provides a set of tools including dynamic baselines that allow you to detect problems before they impact your end users. Alert policies can be set up in two primary ways: Static threshold alerts are great when you already know the nature of an application and its normal behaviors aren't likely to change anytime soon. Apdex score, response time, error rate, throughput are some of the static thresholds you can create alert policies on. Dynamic baseline alerts make it easy to determine and set dynamic alert thresholds for applications with varying seasonal patterns and growth trends (which make it difficult to set thresholds that define normal behavior). These alerts use baselines modeled from your application’s historical metric data. Each alert policy can contain as many conditions as you need, and each alert condition includes three components: Type of condition (metric, external service, and so on) Entities that the policy targets (for example, apps monitored by New Relic APM or New Relic Browser, hosts monitored by New Relic Infrastructure, and so on) Thresholds that escalate into alerting situations with increasing severity Once you have your alerting set up, you then want to make sure you're taking advantage of all viable notification channels. After all, what good are alerts if no one knows about them? You can manage alerts by creating specific user groups and by leveraging New Relic's integrated alert channels, including Slack, PagerDuty, webhooks, and email. Be sure to evaluate alert policies on a regular basis to ensure that they are always valid. How to do it See the detailed documentation: To set up dynamic baseline alerts and choose an application, follow standard procedures. You will see a preview of the metric with the predicted baseline You can select a metric for that application and see the corresponding baseline. Then, using the threshold sliders, you can set how closely you want your threshold to follow the baseline prediction. To set up static threshold alerts for your Apdex settings, follow standard procedures. To set up your alert notification channels, follow standard procedures. 4. Identify and set up key transactions Depending on the nature of your application, some transactions may be more important to you than others. New Relic's key transactions feature is designed to help you closely monitor what you consider to be your app's most business-critical transactions, whether that's end-user or app response time, call counts, error rates, or something else. You can also set alert threshold levels for notifications when your key transactions are performing poorly. How to do it In the menu bar, select More > Key transactions, and then select Add more. Then select the app and web transaction or, from the selected transaction, select Track as key transaction. Type a name for the key transaction, and select Track key transaction. Optional: If the agent for the selected app supports custom alerting, use the default values that New Relic automatically fills, or select Edit key alert transaction policy to set the Apdex and alert threshold values. To view the key transactions dashboard details, select View new key transaction. 5. Track deployment history When development teams are pushing new code out as frequently as possible, it can be hard to measure the impact that each deployment is having on performance. One way to stay in tune with how these changes are affecting your application is with deployment reports. These reports list recent deployments and their impact on end-users and app servers' Apdex scores, along with response times, throughput, and errors. You can also view and drill down into the details to catch errors related to recent deployments, or file a ticket and share details with your team. How to do it From the New Relic menu bar, select APM > (selected app) > Events > Deployments. To view performance after a deployment, go to the selected app's Overview dashboard in the Recent events section. A blue vertical bar on a chart indicates a deployment. To view summary information about the deployment, point to the blue bar. 6. Review APM reports From SLA, deployment, and capacity to scalability, host usage reports, and more, New Relic APM offers a variety of downloadable reporting tools surfacing historical trends—all great ways to report to senior executive teams or customers. Take a look at the full list of reports and use them to your advantage. How to do it From the New Relic APM menu bar, select Applications > (selected app) > Reports. Select the report you'd like to see. If you want to save or export a report to share, select Download this report as .csv, which will create a report with comma-separated values. 7. Review your environment with service maps Use New Relic service maps, a feature included in APM, to understand how apps and services in your architecture connect and talk to each other. Service maps are visual, customizable representations of your application architecture. Maps automatically show you your app's connections and dependencies, including databases and external services. Health indicators and performance metrics show you the current operational status for every part of your architecture. How to do it Go to one.newrelic.com > More > service maps. To get started, read the instructions in Introduction to service maps. 8. Keep current With New Relic’s SaaS platform, getting new features is as easy as updating your agent. Most likely your organization already has a set of scripts for deploying application upgrades into your environment. In a similar fashion, you can also automate your New Relic agent deployment to ensure that your systems are up to date. Both Puppet and Chef scripts are great examples of deployment frameworks that make life easier by allowing you to automate your entire deployment and management process. How to do it Regularly review which version of the agent you're using so that you know when an update is needed. If the latest agent release contains a needed fix or added functionality, download it. To deploy the agent automatically (preferred as a method to avoid errors): Use existing deployment scripts, provided they can be adapted to handle the deployment. OR Create and maintain a script that specifically deploys and configures the New Relic agent. Ideally, the script would pull the agent files from a repository where the files are versioned (for rollback purposes). Once the script has been created, shut down the application (unless script handles this). Run the deployment script. Start the application (unless script handles this). If problems arise, run the script to roll back to the previous version. To deploy the agent manually: Back up the current agent directory. Deploy the updated agent into the existing agent directory. Modify configuration files by comparing new files with existing files. In particular, make sure things like license key and custom extensions are copied over to the new configuration. Restart the application. If problems arise, restore the old agent using the backup and restart. 9. Manage user access Important This is available only for accounts on our original product-based pricing plan. Enable role-based access control (RBAC) and single sign-on (SSO) New Relic allows authorized individuals to access the broadest possible amount of data, regardless of their assigned role. As an Owner or Administrator of your New Relic account, you can control the permissions of individual users or entire roles with RBAC. To find out what is possible and how to make changes, see Users and roles. Security is no doubt of utmost concern to your organization. To simplify password management for your employees and strengthen security, you may already be using SSO with your other systems. You should do the same with New Relic. Using New Relic's SSO integration feature, account administrators will be able to enforce strong passwords and restrict login via a corporate authentication mechanism. This way, New Relic users who have already authenticated using a corporate SSO system will be able to bypass the New Relic login prompt. How to do it Log in to New Relic as an admin and go to the SSO configuration page. From the New Relic title bar, select (your account name) > Account Settings > Integrations > Single Sign On. From the SAML Single Sign On page, review your New Relic SAML Service Provider details. To upload your SAML Identity Provider certificate, select Choose File, and then follow standard procedures to select and save the file. Copy and paste in (or type) the Remove login URL that your users will use for Single Sign-On. If your organization’s SAML integration provides a redirect URL for logout, copy and paste in (or type) the Logout landing URL; otherwise leave blank. Save, test, and enable.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.31004,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Full</em>-<em>stack</em> <em>observability</em>",
        "body": " and performance metrics show you the current operational status for every part of your architecture. How to do it Go to one.newrelic.com &gt; More &gt; service maps. To <em>get</em> <em>started</em>, read the instructions in Introduction to service maps. 8. Keep current With New Relic’s SaaS platform, getting new features is as easy"
      },
      "id": "6044186564441f1f94378ecc"
    },
    {
      "sections": [
        "Introduction to New Relic integrations",
        "Tip",
        "Choose what's right for you",
        "Create your own solutions"
      ],
      "title": "Introduction to New Relic integrations",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Instrument everything",
        "Get started"
      ],
      "external_id": "03217983a29af22737c1163da9ef0811b29c2bcd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/full-stack-observability/instrument-everything/get-started-new-relic-instrumentation/introduction-new-relic-integrations/",
      "published_at": "2021-06-14T21:34:14Z",
      "updated_at": "2021-03-16T07:30:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We provide hundreds of solutions to get your data into New Relic so you can analyze the data in one place. They give you a steady flow of useful data to fix problems quickly, maintain complex systems, improve your code, and accelerate your digital transformation. You can bring in data from hundreds of applications, frameworks, services, operating systems, and other technologies. Our integrations gather the data, and the agents send it to New Relic. The solution you need may require you to install both an integration and an agent. In some cases, you can just install our agents that contain integrations, such as our APM agents. Whatever data you need to bring in, chances are that we have options for your environment. If you prefer to make your own solutions, we also offer tools to get you started. Tip To use integrations and infrastructure monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Choose what's right for you We offer a wide range of solutions so you can easily collect data across your environment. You may only need one of our solutions to get the data you need, or you can choose a variety of options to capture a broader range of data types. Go to New Relic Integrations to find solutions that fit your environment. Here is a sample of what you’ll find there: Application performance monitoring (APM): C, Go, Java, Node, .NET, PHP, Python, and Ruby Mobile apps: Android and iOS Browser monitoring: Google Chrome, Mozilla Firefox, Microsoft Internet Explorer, and Apple Safari Host monitoring: Linux and Microsoft Windows Cloud platform monitoring: Amazon Web Services (AWS), Microsoft Azure, and Google Cloud Platform (GCP) Core infrastructure services: Kubernetes, NGINX, MySQL, and more Open source telemetry integrations: Prometheus, Micrometer, OpenTelemetry, and more Create your own solutions If you are looking for custom options, we have tools to help you create your own: Use New Relic Flex to create lightweight monitoring solutions using infrastructure monitoring. Use New Relic Telemetry SDKs to build custom solutions for sending metrics, traces, and more. Build your own New Relic One applications that you can share with your colleagues, or edit open source applications in our catalog.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 141.75964,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "body": " integrations, such as our APM agents. Whatever data you need to bring in, chances are that we have options for your environment. If you prefer to make your own solutions, we also offer tools to <em>get</em> you <em>started</em>. Tip To use integrations and infrastructure monitoring, as well as the rest of our"
      },
      "id": "603e817f28ccbc4857eba798"
    }
  ],
  "/docs/full-stack-observability/observe-everything/get-started/new-relic-guided-install-overview": [
    {
      "sections": [
        "Get started with Full-Stack Observability",
        "Tip",
        "You’re in control because you understand your system",
        "All the answers in one place",
        "Start anywhere"
      ],
      "title": "Get started with Full-Stack Observability",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Observe everything",
        "Get started"
      ],
      "external_id": "e7fc0bf91fa26b38a11933b6570c8b1e483a1ff9",
      "image": "https://docs.newrelic.com/static/44970161aec793f3141cfcdc0fc96a57/c1b63/observability.png",
      "url": "https://docs.newrelic.com/docs/full-stack-observability/observe-everything/get-started/get-started-full-stack-observability/",
      "published_at": "2021-06-15T06:57:56Z",
      "updated_at": "2021-03-16T08:30:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Full-Stack Observability is the power of knowing what is happening in your digital system and why, at any time, whatever solution you’re using. It’s getting the whole picture of everything that enables your applications and devices to deliver value to your customers, from the container running a microservice in the cloud to a mobile website's shopping cart button. Tip To use Full-Stack Observability and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. You’re in control because you understand your system New Relic helps you cut through the layers of complexity surrounding your systems by bringing together and connecting data from any instrumented source and environment, without having to jump between tools. You can interrogate your data for patterns, discover them using our data platform, or get proactive results from our machine learning tools. New Relic provides answers to essential questions in one place. All the answers in one place As a full user you get access to our entire set of observability tools. All our tools are interconnected and accessible in New Relic One. All the data you bring to New Relic through agents and integrations are metrics, events, logs, and traces that feed our platform's analytics and monitoring capabilities. New Relic links your data in a meaningful way so that you can explore it, build dashboards, and set up alerts. Full-Stack Observability curated experiences allow to visualize, analyze, and troubleshoot your entire software stack in one unified platform. The New Relic Explorer consolidates all the entities in your system, and how they're connected, in a single place, so you can easily detect performance trends and issues. By automatically connecting infrastructure health with application performance and end-user behavior, you can cut through the noise to find the signal. Start anywhere Being fully-connected, New Relic allows you to start your observability journey from any element of your stack. For example, you can get to crucial infrastructure logs from traces of an application running on a problematic Kubernetes pod. The more entities you instrument, the more data you'll bring in. The more data you've brought to New Relic, the more you'll understand your metrics, events, logs, and traces. You want to instrument Start with Keep exploring Front-end applications Mobile applications User behavior and flows New Relic Explorer Browser monitoring Mobile monitoring Synthetic monitoring Single page monitoring Scripted browsers Containerized minions Workloads Backend applications Serverless applications New Relic Explorer Application monitoring Serverless monitoring Learning about Apdex Distributed tracing Logs in context APM data to infrastructure Workloads Infrastructure hosts and services (on-premise, cloud, orchestrated) Container environments and orchestration tools (Kubernetes, ECS, etc.) Infrastructure monitoring Infrastructure integrations Kubernetes integration Docker integration ECS integration Log forwarding APM data to infrastructure Custom integrations Kubernetes cluster explorer Infrastructure alerts Workloads",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 218.601,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> <em>started</em> with <em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "sections": "<em>Get</em> <em>started</em> with <em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "tags": "<em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "body": "<em>Full</em>-<em>Stack</em> <em>Observability</em> is the power of knowing what is happening in your digital system and why, at any time, whatever solution you’re using. It’s getting the whole picture of <em>everything</em> that enables your applications and devices to deliver value to your customers, from the container running"
      },
      "id": "603e891528ccbce6d9eba765"
    },
    {
      "sections": [
        "APM best practices guide",
        "Tip",
        "1. Standardize application names",
        "How to do it",
        "2. Add tags to your applications",
        "Caution",
        "3. Create and evaluate alert policies",
        "4. Identify and set up key transactions",
        "5. Track deployment history",
        "6. Review APM reports",
        "7. Review your environment with service maps",
        "8. Keep current",
        "9. Manage user access",
        "Important"
      ],
      "title": "APM best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Full-stack observability"
      ],
      "external_id": "368a1a5688384d5bebf128604a9b8f190d335524",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/apm-best-practices-guide/",
      "published_at": "2021-06-15T10:15:04Z",
      "updated_at": "2021-06-08T18:52:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Application Monitoring Tips You Need To Know It's one thing to know how to use APM, but it's another thing to know how to use New Relic's application performance monitoring software well. Here are some best practices designed to help you become an APM master—and a key asset to your team! Tip To get a high-level overview of all your applications and services, use the New Relic Explorer in New Relic One. 1. Standardize application names Most New Relic agents provide a default application name, such as \"My Application\" or \"PHP Application,\" if you don't specify one in your New Relic configuration file. You don't want to end up with 20 identically named applications, be sure to select a descriptive identifier for your apps as soon you deploy them. To keep things consistent and easy to navigate, New Relic recommends standardizing your application naming (for example, all apps in Staging append [ Staging] or the like at the end of their names). Ideally, you want your new Java applications to be named automatically to reduce the chances of typographical errors and misnaming. How to do it For Java applications, automatic application naming can come from the following sources: Request attribute Servlet init parameter Filter init parameter Web app context parameter Web app context name (display name) Web app context path Choose the method that fits best your needs and follow these steps. For non-Java applications, there are no automatic naming methods, so refer to the documentation for your APM agent. 2. Add tags to your applications When several different applications use the same account, and each application spans multiple environments (for example, development, test, pre-production, production), it can be hard to find a specific application in your overview dashboard. That's why we recommend adding tags to your apps so that you can segment them into logical groups. The two most common tags that mature APM customers use are application name and environment. So, for example, if you wanted to view the billing application in Test, you could simply filter by \"billing app\" (name tag) and \"test\" (environment tag). Caution In the APM agent configuration settings files, use the labels field to add tags to your data. For example, see this description of the Python labels setting. APM is designed so that apps can roll up into an unlimited number of meaningful tag categories. How to do it Learn about tags. Learn how to add tags.. Learn how to query tags. 3. Create and evaluate alert policies When key performance indicators spike or drop, individuals and teams in your organization need to be notified. Alerting in New Relic provides a set of tools including dynamic baselines that allow you to detect problems before they impact your end users. Alert policies can be set up in two primary ways: Static threshold alerts are great when you already know the nature of an application and its normal behaviors aren't likely to change anytime soon. Apdex score, response time, error rate, throughput are some of the static thresholds you can create alert policies on. Dynamic baseline alerts make it easy to determine and set dynamic alert thresholds for applications with varying seasonal patterns and growth trends (which make it difficult to set thresholds that define normal behavior). These alerts use baselines modeled from your application’s historical metric data. Each alert policy can contain as many conditions as you need, and each alert condition includes three components: Type of condition (metric, external service, and so on) Entities that the policy targets (for example, apps monitored by New Relic APM or New Relic Browser, hosts monitored by New Relic Infrastructure, and so on) Thresholds that escalate into alerting situations with increasing severity Once you have your alerting set up, you then want to make sure you're taking advantage of all viable notification channels. After all, what good are alerts if no one knows about them? You can manage alerts by creating specific user groups and by leveraging New Relic's integrated alert channels, including Slack, PagerDuty, webhooks, and email. Be sure to evaluate alert policies on a regular basis to ensure that they are always valid. How to do it See the detailed documentation: To set up dynamic baseline alerts and choose an application, follow standard procedures. You will see a preview of the metric with the predicted baseline You can select a metric for that application and see the corresponding baseline. Then, using the threshold sliders, you can set how closely you want your threshold to follow the baseline prediction. To set up static threshold alerts for your Apdex settings, follow standard procedures. To set up your alert notification channels, follow standard procedures. 4. Identify and set up key transactions Depending on the nature of your application, some transactions may be more important to you than others. New Relic's key transactions feature is designed to help you closely monitor what you consider to be your app's most business-critical transactions, whether that's end-user or app response time, call counts, error rates, or something else. You can also set alert threshold levels for notifications when your key transactions are performing poorly. How to do it In the menu bar, select More > Key transactions, and then select Add more. Then select the app and web transaction or, from the selected transaction, select Track as key transaction. Type a name for the key transaction, and select Track key transaction. Optional: If the agent for the selected app supports custom alerting, use the default values that New Relic automatically fills, or select Edit key alert transaction policy to set the Apdex and alert threshold values. To view the key transactions dashboard details, select View new key transaction. 5. Track deployment history When development teams are pushing new code out as frequently as possible, it can be hard to measure the impact that each deployment is having on performance. One way to stay in tune with how these changes are affecting your application is with deployment reports. These reports list recent deployments and their impact on end-users and app servers' Apdex scores, along with response times, throughput, and errors. You can also view and drill down into the details to catch errors related to recent deployments, or file a ticket and share details with your team. How to do it From the New Relic menu bar, select APM > (selected app) > Events > Deployments. To view performance after a deployment, go to the selected app's Overview dashboard in the Recent events section. A blue vertical bar on a chart indicates a deployment. To view summary information about the deployment, point to the blue bar. 6. Review APM reports From SLA, deployment, and capacity to scalability, host usage reports, and more, New Relic APM offers a variety of downloadable reporting tools surfacing historical trends—all great ways to report to senior executive teams or customers. Take a look at the full list of reports and use them to your advantage. How to do it From the New Relic APM menu bar, select Applications > (selected app) > Reports. Select the report you'd like to see. If you want to save or export a report to share, select Download this report as .csv, which will create a report with comma-separated values. 7. Review your environment with service maps Use New Relic service maps, a feature included in APM, to understand how apps and services in your architecture connect and talk to each other. Service maps are visual, customizable representations of your application architecture. Maps automatically show you your app's connections and dependencies, including databases and external services. Health indicators and performance metrics show you the current operational status for every part of your architecture. How to do it Go to one.newrelic.com > More > service maps. To get started, read the instructions in Introduction to service maps. 8. Keep current With New Relic’s SaaS platform, getting new features is as easy as updating your agent. Most likely your organization already has a set of scripts for deploying application upgrades into your environment. In a similar fashion, you can also automate your New Relic agent deployment to ensure that your systems are up to date. Both Puppet and Chef scripts are great examples of deployment frameworks that make life easier by allowing you to automate your entire deployment and management process. How to do it Regularly review which version of the agent you're using so that you know when an update is needed. If the latest agent release contains a needed fix or added functionality, download it. To deploy the agent automatically (preferred as a method to avoid errors): Use existing deployment scripts, provided they can be adapted to handle the deployment. OR Create and maintain a script that specifically deploys and configures the New Relic agent. Ideally, the script would pull the agent files from a repository where the files are versioned (for rollback purposes). Once the script has been created, shut down the application (unless script handles this). Run the deployment script. Start the application (unless script handles this). If problems arise, run the script to roll back to the previous version. To deploy the agent manually: Back up the current agent directory. Deploy the updated agent into the existing agent directory. Modify configuration files by comparing new files with existing files. In particular, make sure things like license key and custom extensions are copied over to the new configuration. Restart the application. If problems arise, restore the old agent using the backup and restart. 9. Manage user access Important This is available only for accounts on our original product-based pricing plan. Enable role-based access control (RBAC) and single sign-on (SSO) New Relic allows authorized individuals to access the broadest possible amount of data, regardless of their assigned role. As an Owner or Administrator of your New Relic account, you can control the permissions of individual users or entire roles with RBAC. To find out what is possible and how to make changes, see Users and roles. Security is no doubt of utmost concern to your organization. To simplify password management for your employees and strengthen security, you may already be using SSO with your other systems. You should do the same with New Relic. Using New Relic's SSO integration feature, account administrators will be able to enforce strong passwords and restrict login via a corporate authentication mechanism. This way, New Relic users who have already authenticated using a corporate SSO system will be able to bypass the New Relic login prompt. How to do it Log in to New Relic as an admin and go to the SSO configuration page. From the New Relic title bar, select (your account name) > Account Settings > Integrations > Single Sign On. From the SAML Single Sign On page, review your New Relic SAML Service Provider details. To upload your SAML Identity Provider certificate, select Choose File, and then follow standard procedures to select and save the file. Copy and paste in (or type) the Remove login URL that your users will use for Single Sign-On. If your organization’s SAML integration provides a redirect URL for logout, copy and paste in (or type) the Logout landing URL; otherwise leave blank. Save, test, and enable.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.31004,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Full</em>-<em>stack</em> <em>observability</em>",
        "body": " and performance metrics show you the current operational status for every part of your architecture. How to do it Go to one.newrelic.com &gt; More &gt; service maps. To <em>get</em> <em>started</em>, read the instructions in Introduction to service maps. 8. Keep current With New Relic’s SaaS platform, getting new features is as easy"
      },
      "id": "6044186564441f1f94378ecc"
    },
    {
      "sections": [
        "Introduction to New Relic integrations",
        "Tip",
        "Choose what's right for you",
        "Create your own solutions"
      ],
      "title": "Introduction to New Relic integrations",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Instrument everything",
        "Get started"
      ],
      "external_id": "03217983a29af22737c1163da9ef0811b29c2bcd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/full-stack-observability/instrument-everything/get-started-new-relic-instrumentation/introduction-new-relic-integrations/",
      "published_at": "2021-06-14T21:34:14Z",
      "updated_at": "2021-03-16T07:30:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We provide hundreds of solutions to get your data into New Relic so you can analyze the data in one place. They give you a steady flow of useful data to fix problems quickly, maintain complex systems, improve your code, and accelerate your digital transformation. You can bring in data from hundreds of applications, frameworks, services, operating systems, and other technologies. Our integrations gather the data, and the agents send it to New Relic. The solution you need may require you to install both an integration and an agent. In some cases, you can just install our agents that contain integrations, such as our APM agents. Whatever data you need to bring in, chances are that we have options for your environment. If you prefer to make your own solutions, we also offer tools to get you started. Tip To use integrations and infrastructure monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Choose what's right for you We offer a wide range of solutions so you can easily collect data across your environment. You may only need one of our solutions to get the data you need, or you can choose a variety of options to capture a broader range of data types. Go to New Relic Integrations to find solutions that fit your environment. Here is a sample of what you’ll find there: Application performance monitoring (APM): C, Go, Java, Node, .NET, PHP, Python, and Ruby Mobile apps: Android and iOS Browser monitoring: Google Chrome, Mozilla Firefox, Microsoft Internet Explorer, and Apple Safari Host monitoring: Linux and Microsoft Windows Cloud platform monitoring: Amazon Web Services (AWS), Microsoft Azure, and Google Cloud Platform (GCP) Core infrastructure services: Kubernetes, NGINX, MySQL, and more Open source telemetry integrations: Prometheus, Micrometer, OpenTelemetry, and more Create your own solutions If you are looking for custom options, we have tools to help you create your own: Use New Relic Flex to create lightweight monitoring solutions using infrastructure monitoring. Use New Relic Telemetry SDKs to build custom solutions for sending metrics, traces, and more. Build your own New Relic One applications that you can share with your colleagues, or edit open source applications in our catalog.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 141.75964,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "body": " integrations, such as our APM agents. Whatever data you need to bring in, chances are that we have options for your environment. If you prefer to make your own solutions, we also offer tools to <em>get</em> you <em>started</em>. Tip To use integrations and infrastructure monitoring, as well as the rest of our"
      },
      "id": "603e817f28ccbc4857eba798"
    }
  ],
  "/docs/gateway-api-import-data-other-observability-platforms": [
    {
      "sections": [
        "Configure polling frequency and data collection for cloud integrations",
        "Tip",
        "Overview of settings",
        "Caution",
        "Change polling frequency",
        "Specify data to be fetched",
        "Data collection",
        "Filters",
        "Potential impact on alerts and charts"
      ],
      "title": "Configure polling frequency and data collection for cloud integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Infrastructure integrations",
        "Cloud integrations"
      ],
      "external_id": "b900b7545f9032201c212449be114e10176bf789",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/infrastructure-integrations/cloud-integrations/configure-polling-frequency-data-collection-cloud-integrations/",
      "published_at": "2021-06-15T13:00:43Z",
      "updated_at": "2021-06-15T13:00:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our cloud integrations get data from cloud provider APIs. In New Relic, you can change some of the data collection-related settings for your cloud integrations. Read on to see what changes you can make and the reasons for making them. Tip To use integrations and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Overview of settings New Relic cloud integrations get data from cloud providers' APIs. Data is generally collected from monitoring APIs such as AWS CloudWatch, Azure Monitor, and GCP Stackdriver, and inventory metadata is collected from the specific services' APIs. You can use the account status dashboard to see how your cloud integrations are handling data from a cloud service provider. If you want to report more or less data from your cloud integrations, or if you need to control the use of the cloud providers' APIs to prevent reaching rate and throttling limits in your cloud account, you can change the configuration settings to modify the amount of data they report. The two main controls are: Change polling frequency Change what data is reported Examples of business reasons for wanting to change your polling frequency include: Billing: If you need to manage your AWS CloudWatch bill, you may want to decrease the polling frequency. Before you do this, make sure that any alert conditions set for your cloud integrations are not affected by this reduction. New services: If you are deploying a new service or configuration and you want to collect data more often, you may want to increase the polling frequency temporarily. Caution Changing the configuration settings for your integrations may impact alert conditions and chart trends. Change polling frequency The polling frequency configuration determines how often New Relic reports data from your cloud provider for each service. By default, the polling frequency is set to the maximum frequency that is available for each service. To change the polling frequency for a cloud integration: Go to one.newrelic.com > Infrastructure. Select the tab that corresponds to your cloud service provider. Select Configure next to the integration. Use the dropdowns next to Data polling interval every to select how frequently you want New Relic to capture your cloud integration data. Specify data to be fetched You can specify which information you want captured for your cloud integration by enabling the collection of additional data and by applying multiple filters to each integration. To change this settings for your cloud integration: Go to one.newrelic.com > Infrastructure. Select the tab that corresponds to your cloud service provider. Select Configure next to the integration. Under Data collections and filters, turn the toggles you want On. For filters, select or enter the values that you want included in your reported data. Data collection For some cloud integrations, an additional number of calls to the cloud provider APIs are needed in order to collect data. For example, to fetch tags for AWS Elastic Map Reduce clusters, an additional call to the service API is required. To better control the amount of API calls that are sent to your cloud account for these integrations, you can specify when you need these types of data to be collected. Different data collection toggles are available, depending on the integration. Toggle Description Collect tags Some integrations require additional API calls to the cloud provider to report tags. Tag collection is enabled by default. Switch this to Off if you don't want the integration to collect your cloud resource tags and thus reduce the volume of API calls. Collect extended inventory Some integrations can collect extended inventory metadata about your cloud resources by making additional API calls to the cloud provider. The metadata included within the extended inventory for each cloud integration is described in the integration documentation. Extended inventory collection is disabled by default. Switch this to On if you want to monitor extended inventory. This will increase the volume of API calls. Collect shards data Available for AWS Kinesis Streams integration. By default, we don't report shard metrics. Switch this to On if you want to monitor shard metrics in addition to data stream metrics. Collect Lambda@Edge data Available for AWS CloudFront integration. By default, we don't report Lambda@Edge data. Switch this to On if you're using Lambda@Edge in AWS CloudFront and want to get Lambda execution location metadata. Collect node data Available for AWS Elasticsearch integration. By default, we don't report Elasticsearch node metrics. Switch this to On if you want to monitor node metrics in addition to cluster metrics. Collect NAT Gateway data and Collect VPN data Available for AWS VPC integration. By default, we don't report NAT Gateway nor VPN metrics. Switch these to On if you want to monitor NAT Gateway and VPN metrics and inventory, in addition to other VPC related entities inventory. Collect IP addresses Available for AWS EC2 integration. By default, we collect EC2 instance metadata that includes public and private IP addresses, and network interface details. Switch this to Off if you don't want New Relic to store and display these IP data. Filters When a filter is On, you specify the data that you want to be collected; for example, if the Limit to AWS region is On, the regions that you select will be the ones that data will be collected for. There are different filters available, depending on the integration: Filter Description Region Select the regions that include the resources that you want to monitor. Queue prefixes Available for AWS SQS integration. Enter each name or prefix for the queues that you want to monitor. Filter values are case-sensitive. Load balancer prefixes Available for AWS ALB integration. Enter each name or prefix for the application load balancers that you want to monitor. Filter values are case-sensitive. Stage name prefixes Available for AWS API Gateway integration. Enter each name or prefix for the stages that you want to monitor. Filter values are case-sensitive. Tag key Enter one tag key that is associated with the resources that you want to monitor. Filter values are case-sensitive, and you can use this filter in combination with tag value filter. Tag value Enter one tag value that is associated with the resources that you want to monitor. Filter values are case-sensitive, and you can use this filter in combination with tag key. Resource group Select the resource groups that are associated with the resources that you want to monitor. Potential impact on alerts and charts If you change an integration's configuration, it can impact alert conditions and charts. Here are some things to consider: If you change this setting... It may have this impact... Any configuration setting When you change the configuration settings, the data that New Relic displays in infrastructure charts, on the inventory page, and in the events feed changes as well. Any filters When you create alert conditions after you set filters, make sure that your alerts are not triggered by resources that you filtered out. Filter for regions If you filter for specific regions, it may lower the amount of data reported to New Relic, which could trigger an alert. If you create an alert condition for a specific region and then filter that region out, the region would no longer report data and would never trigger the alert. Polling frequency When you create an alert, make sure that you define the threshold for a time period that is longer than the polling frequency. Tags and extended inventory If you turn on tags and/or extended inventory, New Relic makes more API calls to the cloud provider, which could increase your cloud provider API usage bill.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 133.79553,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure polling frequency and <em>data</em> collection for cloud integrations",
        "sections": "Configure polling frequency and <em>data</em> collection for cloud integrations",
        "body": "Our cloud integrations get <em>data</em> <em>from</em> cloud provider APIs. In New Relic, you can change some of the <em>data</em> collection-related settings for your cloud integrations. Read on to see what changes you can make and the reasons for making them. Tip To use integrations and the rest of our <em>observability</em>"
      },
      "id": "603e8eef64441fcc7e4e8853"
    },
    {
      "sections": [
        "Kubernetes integration: install and configure",
        "Tip",
        "Use automated installer",
        "Installs for managed services and platforms",
        "Amazon EKS",
        "Amazon EKS Fargate",
        "Google Kubernetes Engine (GKE)",
        "OpenShift container platform",
        "Azure Kubernetes Service (AKS)",
        "Pivotal Container Service (PKS / VMware Tanzu)",
        "Custom manifest",
        "Important",
        "Make sure New Relic pods can be scheduled",
        "Unprivileged installs of the Kubernetes integration",
        "Steps to complete an unprivileged install",
        "Configure the integration",
        "Select which processes should send their data to New Relic",
        "Specify the Kubernetes API host and port",
        "Kubernetes versions 1.6 to 1.7.5: Edit manifest file",
        "Use environment variables",
        "Disable kube-state-metrics parsing",
        "Caution",
        "Specify the kube-state-metrics URL",
        "Discover kube-state-metrics pods using a label",
        "Query kube-state-metrics behind RBAC",
        "kube-state-metrics timeout: Increase the client timeout",
        "Non-default namespace deployments: Edit config file",
        "Set the TTL for the Kubernetes API responses cache",
        "Specify base URLs for control plane component endpoints",
        "Configure the infrastructure agent",
        "Update to the latest version",
        "Using the automated installer",
        "Using helm",
        "Uninstall the Kubernetes integration"
      ],
      "title": "Kubernetes integration: install and configure",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Installation"
      ],
      "external_id": "ff06c8b1d8b2940d0b23034f3057377ce571e4ab",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/installation/kubernetes-integration-install-configure/",
      "published_at": "2021-06-15T13:05:55Z",
      "updated_at": "2021-06-15T13:05:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The easiest way to install the Kubernetes integration is to use our automated installer to generate a manifest. It bundles not just the integration DaemonSets, but also other New Relic Kubernetes configurations, like Kubernetes events, Prometheus OpenMetrics, and New Relic log monitoring. Tip To use Kubernetes integrations and infrastructure monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Use automated installer You can use the automated installer for servers, VMs, and unprivileged environments. The installer can also help you with managed services or platforms after you review a few preliminary notes. We also have separate instructions if you need a custom manifest or prefer to do a manual unprivileged installation. Start the installer If your New Relic account is in the EU region, access the installer from one.eu.newrelic.com. Installs for managed services and platforms Before starting our automated installer, check out these notes for your managed services or platforms: Amazon EKS The Kubernetes integration monitors worker nodes. In Amazon EKS, master nodes are managed by Amazon and abstracted from the Kubernetes platforms. Before starting our automated installer to deploy the Kubernetes integration in Amazon EKS, make sure you are using the version of kubectl provided by AWS. Amazon EKS Fargate For help installing our EKS Fargate integration, see these setup options. Google Kubernetes Engine (GKE) The Kubernetes integration monitors worker nodes. In GKE, master nodes are managed by Google and abstracted from the Kubernetes platforms. Before starting our automated installer to deploy the Kubernetes integration on GKE, ensure you have sufficient permissions: Go to console.cloud.google.com/iam-admin/iam and find your username. Click edit. Ensure you have permissions to create Roles and ClusterRoles: If you are not sure, add the Kubernetes Engine Cluster Admin role. If you cannot edit your user role, ask the owner of the GCP project to give you the necessary permissions. Ensure you have a RoleBinding that grants you the same permissions to create Roles and ClusterRoles: kubectl create clusterrolebinding YOUR_USERNAME-cluster-admin-binding --clusterrole=cluster-admin --user=YOUR_GCP_EMAIL Copy Creating a RoleBinding is necessary because of a known RBAC issue in Kubernetes and Kubernetes Engine versions 1.6 or higher. For more information, see Google Cloud's documentation on defining permissions in a role. OpenShift container platform To deploy the Kubernetes integration with OpenShift: Add the <>{'<release_name>'}</>-newrelic-infrastructure service account to your privileged Security Context Constraints: oc adm policy add-scc-to-user privileged \\ system:serviceaccount:<namespace>:<release_name>-newrelic-infrastructure Copy The default <>{'<release_name>'}</> provided by the installer is nri-bundle. Complete the steps in our automated installer. If you're using signed certificates, make sure they are properly configured by using the following variables in the DaemonSet portion of your manifest to set the .pem file: - name: NRIA_CA_BUNDLE_DIR value: YOUR_CA_BUNDLE_DIR - name: NRIA_CA_BUNDLE_FILE value: YOUR_CA_BUNDLE_NAME Copy YAML key path: spec.template.spec.containers.name.env Save your changes. Azure Kubernetes Service (AKS) The Kubernetes integration monitors worker nodes. In Azure Kubernetes Service, master nodes are managed by Azure and abstracted from the Kubernetes platforms. To deploy in Azure Kubernetes Service (AKS), complete the steps in our automated installer. Pivotal Container Service (PKS / VMware Tanzu) To deploy in PKS, we recommend that you use the automated installer, or you can follow the manual instructions provided in Install the Kubernetes integration using Helm. Custom manifest If the Kubernetes automated installer doesn't provide the settings you need, you can download our manifest template and install the integration manually. To activate the Kubernetes integration, you must deploy the newrelic-infra agent onto a Kubernetes cluster as a DaemonSet: Install kube-state-metrics and get it running on the cluster. For example: curl -L -o kube-state-metrics- 1.9.5 .zip https://github.com/kubernetes/kube-state-metrics/archive/v 1.9.5 .zip && unzip kube-state-metrics- 1.9.5 .zip && kubectl apply -f kube-state-metrics- 1.9.5 /examples/standard Copy Download the manifest file: curl -O https://download.newrelic.com/infrastructure_agent/integrations/kubernetes/newrelic-infrastructure-k8s-latest.yaml Copy In the DaemonSet portion of your manifest, add your New Relic license key and a cluster name to identify your Kubernetes cluster. Both values are required. Recommendation: Do not change the NRIA_PASSTHROUGH_ENVIRONMENT or NRIA_DISPLAY_NAME value in your manifest. YOUR_CLUSTER_NAME is your cluster’s id in New Relic Explorer. It doesn’t need to match the name of the cluster running in your environment. YAML key path: spec.template.spec.containers.name.env env: - name: NRIA_LICENSE_KEY value: YOUR_LICENSE_KEY - name: CLUSTER_NAME value: YOUR_CLUSTER_NAME Copy If you need to adapt the manifest to fit your environment, review the configure section in this doc. Confirm that kube-state-metrics is installed. kubectl get pods --all-namespaces | grep kube-state-metrics Copy Create the DaemonSet: kubectl create -f newrelic-infrastructure-k8s-latest.yaml Copy Confirm that the DaemonSet has been created successfully by looking for newrelic-infra in the results generated by this command: kubectl get daemonsets Copy To confirm that the integration is working: wait a few minutes, then look for data in the New Relic Kubernetes cluster explorer. If you don't see data, review the configuration procedures again, then follow the troubleshooting procedures. Important In the future, the number of labels collected on Kubernetes objects will be limited per object type (containers, pods, nodes, etc.). If objects have labels above the limit, you will be able to configure important labels that should always be sent to New Relic. When the limitation is in place, this documentation will be updated. Make sure New Relic pods can be scheduled Some of the New Relic pods are set up as DaemonSet in the manifest file so that they can run on every host. These include newrelic-infrastructure and newrelic-logging. In rare circumstances, other pods may be scheduled first and starve the New Relic pods of resources. Since each of these pods have to run on a specific host, they will stay in pending status until that host has enough resources, even if there are other hosts available. This could end up occurring for long periods of time and result in reporting gaps. To prevent this scenario, you can configure the Kubernetes scheduler to give New Relic pods a higher priority. Using the default scheduler: Ensure kube-scheduler flag disablePreemption is not set to true (by default it is false). Create a PriorityClass for the New Relic DaemonSet pods: Set the appropriate priority value, which should generally be higher than your other pods. preemptionPolicy is set to PreemptLowerPriority by default. This allows New Relic pods assigned this priority class to remove lower-priority pods that are taking up resources. Edit the manifest file to add priorityClassName to any DaemonSet specs. In the example below, the highlighted line sets the priority class for newrelic-infrastructure: apiVersion: apps/v1 kind: DaemonSet metadata: namespace: default labels: app: newrelic-infrastructure chart: newrelic-infrastructure-1.0.0 release: nri-bundle mode: privileged name: nri-bundle-newrelic-infrastructure spec: priorityClassName: your-priority-class ... Copy If you have already deployed the New Relic pods, re-deploy them and confirm they have been created: kubectl delete -f newrelic-infrastructure-k8s-latest.yaml kubectl create -f newrelic-infrastructure-k8s-latest.yaml kubectl get daemonsets Copy Unprivileged installs of the Kubernetes integration For platforms that have stringent security requirements, we provide an unprivileged version of the Kubernetes integration. Changes from the standard Kubernetes integration are: Runs the infrastructure agent and the Kubernetes integration as a standard user instead of root No access to the underlying host filesystem No access to /var/run/docker.sock Container's root filesystem mounted as read-only allowPrivilegeEscalation is set to false hostnetwork is set to false The tradeoff is that the solution will only collect metrics from Kubernetes, but it will not collect any metric from the underlying hosts directly. Kubernetes provides some data (metrics and metadata) about its nodes (hosts). Tip Optional: To collect the underlying host metrics, the non-containerized infrastructure agent can be deployed on the underlying host. The infrastructure agent already supports running as non-root. The combination of the Kubernetes integration in its unprivileged version and the agent running on the host will report all the metrics that our standard solution for monitoring Kubernetes receives. Steps to complete an unprivileged install Install kube-state-metrics and get it running on the cluster. For example: curl -L -o kube-state-metrics- 1.9.5 .zip https://github.com/kubernetes/kube-state-metrics/archive/v 1.9.5 .zip && unzip kube-state-metrics- 1.9.5 .zip && kubectl apply -f kube-state-metrics- 1.9.5 /examples/standard Copy Download the integration manifest: curl -O https://download.newrelic.com/infrastructure_agent/integrations/kubernetes/newrelic-infrastructure-k8s-unprivileged-latest.yaml Copy In the manifest, add your New Relic license key and a cluster name to identify your Kubernetes cluster. Both values are required. Important YOUR_CLUSTER_NAME is your cluster’s id in New Relic Explorer. It doesn’t need to match the name of the cluster running in your environment. env: - name: NRIA_LICENSE_KEY value: YOUR_LICENSE_KEY - name: CLUSTER_NAME value: YOUR_CLUSTER_NAME Copy YAML key path: spec.template.spec.containers.name.env Confirm that kube-state-metrics is installed. kubectl get pods --all-namespaces | grep kube-state-metrics Copy Create the DaemonSet: kubectl create -f newrelic-infrastructure-k8s-unprivileged-latest.yaml Copy Confirm that the DaemonSet has been created successfully by looking for newrelic-infra in the results generated by this command: kubectl get daemonsets Copy To confirm that the integration has been configured correctly, wait a few minutes, then run this NRQL query to see if data has been reported: SELECT * FROM K8sPodSample since 5 minutes ago Copy Configure the integration The Kubernetes integration comes with a default configuration that should work in most environments. To change the configuration, modify the manifest file: Select which processes should send their data to New Relic By default, data about the processes running on your pods is not sent to New Relic. You can enable it by setting enable_process_metrics to true. To choose what metric data you want to send to New Relic, configure the include_matching_metrics environment variable in your manifest. Specify the Kubernetes API host and port This is necessary when you are using SSL and not using the default FQDN. The Kubernetes API FQDN needs to match the FQDN of the SSL certificate. You do not need to specify both variables. For example, if you only specify the HOST, the default PORT will be used. - name: \"KUBERNETES_SERVICE_HOST\" value: \"KUBERNETES_API_HOST\" - name: \"KUBERNETES_SERVICE_PORT\" value: \"KUBERNETES_API_TCP_PORT\" Copy Kubernetes versions 1.6 to 1.7.5: Edit manifest file For Kubernetes versions 1.6 to 1.7.5, uncomment these two lines in the manifest file: - name: \"CADVISOR_PORT\" # Enable direct connection to cAdvisor by specifying the port. Needed for Kubernetes versions prior to 1.7.6. value: \"4194\" Copy Use environment variables Use environment variables that can be passed to the Kubernetes integration if you use a proxy to configure its URL. Disable kube-state-metrics parsing You can disable kube-state-metrics parsing for the DaemonSet by using the following configuration: - name: \"DISABLE_KUBE_STATE_METRICS\" value: \"true\" Copy Caution Disabling kube-state-metrics also disables data collection for the following: ReplicaSets DaemonSets StatefulSets Namespaces Deployments Services Endpoints Pods (that are pending) Additionally, disabling this affects the Kubernetes Cluster Explorer in the following ways: No pending pods are shown. No filters based on services. Specify the kube-state-metrics URL If several instances of kube-state-metrics are present in the cluster, uncomment and configure the following lines to specify which one to use: - name: \"KUBE_STATE_METRICS_URL\" value: \"http://KUBE_STATE_METRICS_IP_OR_FQDN:PORT\" Copy Important Even though a KUBE_STATE_METRICS_URL is defined, the KSM service should contain one of the following labels for the auto-discovery process: k8s-app=kube-state-metrics OR app=kube-state-metrics OR ​​app.kubernetes.io/name=kube-state-metrics Important This configuration option overrides KUBE_STATE_METRICS_POD_LABEL. If you have both defined, KUBE_STATE_METRICS_POD_LABEL has no effect. Discover kube-state-metrics pods using a label If several instances of kube-state-metrics are present in the cluster, another option to easily target one of these instances with the Kubernetes integration is to use label-based discovery. - name: \"KUBE_STATE_METRICS_POD_LABEL\" value: \"LABEL_NAME\" Copy Important When a KUBE_STATE_METRICS_POD_LABEL is defined, the label should have a value equal to true. For example, if the label name is my-ksm, ensure that my-ksm=true. Important This configuration option is incompatible with KUBE_STATE_METRICS_URL. If you have both defined, KUBE_STATE_METRICS_URL is used. Query kube-state-metrics behind RBAC If your instance of kube-state-metrics is behind kube-rbac-proxy, the integration can be configured in a compatible way using the combination of the label-based discovery and two other environment variables: - name: \"KUBE_STATE_METRICS_SCHEME\" value: \"https\" - name: \"KUBE_STATE_METRICS_PORT\" value: \"KSM_RBAC_PROXY_PORT\" Copy To confirm which port should be used as the value of KUBE_STATE_METRICS_PORT, we recommend running a describe command on the kube-state-metrics pod and look for the port exposed by the container named kube-rbac-proxy-main. Important These two configuration options only work when using the KUBE_STATE_METRICS_POD_LABEL configuration described above. kube-state-metrics timeout: Increase the client timeout To increase the client timeout of kube-state-metrics, add a new environment variable, TIMEOUT, to the manifest file: env: - name: TIMEOUT value: 5000 # The default client timeout when calling kube-state-metrics, in milliseconds Copy Then, add this new environment variable to the NRIA_PASSTHROUGH_ENVIRONMENT Non-default namespace deployments: Edit config file If you want to deploy in a different namespace from default, change all values of namespace in the manifest. Set the TTL for the Kubernetes API responses cache By default, the integration will cache any retrieved information from the Kubernetes API for 5 minutes. Use the API_SERVER_CACHE_TTL environment variable to set a custom cache duration for responses from the API server. Valid time unit values are: ns, us, ms, s, m, and h. To disable caching, set to 0s. env: - name: API_SERVER_CACHE_TTL value: \"1m\" Copy Specify base URLs for control plane component endpoints Use the following environment variables if any of the Kubernetes control plane components export metrics on base URLs that are different from the defaults. This is necessary for environments such as OpenShift when a control plane component metrics endpoint is using SSL or an alternate port. Values of these environment variables must be base URLs of the form [scheme]://[host]:[port]. URLs should not include a path component. For example: - name: \"SCHEDULER_ENDPOINT_URL\" value: \"https://localhost:10259\" - name: \"ETCD_ENDPOINT_URL\" value: \"https://localhost:9979\" - name: \"CONTROLLER_MANAGER_ENDPOINT_URL\" value: \"https://localhost:10257\" - name: \"API_SERVER_ENDPOINT_URL\" value: \"https://localhost:6443\" Copy The /metrics path segment is added automatically. In addition, if the https scheme is used, authentication to the control plane component pod(s) is accomplished via service accounts. Caution If a FQDN (fully qualified domain name) is used in a multi-master cluster, inconsistent results may be returned. Therefore, it is recommended to use localhost only. Important Even though a custom base URL is defined for a given control plane component, the control plane component pod(s) must contain one of the labels supported by the auto-discovery process. Important Even though a custom ETCD_ENDPOINT_URL can be defined, ETCD will always require https and mTLS authentication to be configured. Here are some additional configurations to consider: Do more configuration for control plane monitoring Link New Relic APM to the Kubernetes integration Monitor services that run on Kubernetes Configure the infrastructure agent The Kubernetes integration image comes with a default configurations for the agent that can be modified if needed. When installing with the manifest, you can modify the infrastructure agent configuration by editing the manifest and adding any needed configuration option of the agent as environment variables of the newrelic-infrastructure DaemonSet. When installing with Helm, you can specify the needed infrastructure agent configuration options in the values.yaml as shown in the example in GitHub. The config object is used to populate the configMap that is mounted automatically in the location of the infrastructure agent configuration file in the pods created by the newrelic-infrastructure DaemonSet. Update to the latest version Using the automated installer To update a Kubernetes integration installed with the automated installer, just run the installer again. It will always offer a manifest pointing to the last released version of the integration. Using helm See Install the Kubernetes integration using Helm Custom manifest If you are already running the Kubernetes integration and want to update the newrelic-infra agent to the latest agent version: Run this NRQL query to check which version you are currently running (this will return the image name by cluster): SELECT latest(containerImage) FROM K8sContainerSample WHERE containerImage LIKE '%newrelic/infrastructure%' FACET clusterName SINCE 1 day ago Copy If you've set a name other than newrelic/infrastructure for the integration's container image, the above query won't yield results: to make it work, edit the name in the query. Download the integration manifest file: curl -O https://download.newrelic.com/infrastructure_agent/integrations/kubernetes/newrelic-infrastructure-k8s-latest.yaml Copy Copy the changes you made to the manifest. At a minimum, include CLUSTER_NAME and NRIA_LICENSE_KEY, and paste your changes in the manifest you downloaded. Install the latest DaemonSet with the following command (Kubernetes will automatically do a rollout upgrade for the integration's pods): kubectl apply -f newrelic-infrastructure-k8s-latest.yaml Copy Uninstall the Kubernetes integration To uninstall the Kubernetes integration: Verify that newrelic-infrastructure-k8s-latest.yaml corresponds to the filename of the manifest as you have saved it. Example: If you are using the unprivileged version of the integration, the default filename will be newrelic-infrastructure-k8s-unprivileged-latest.yaml. After you verify the filename, use the following command: kubectl delete -f newrelic-infrastructure-k8s-latest.yaml Copy You only need to execute this command once, regardless of the number of nodes in your cluster.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 120.95,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Installs for managed services and <em>platforms</em>",
        "body": " To use Kubernetes integrations and infrastructure monitoring, as well as the rest of our <em>observability</em> <em>platform</em>, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of <em>data</em> for free each month. Forever. Use automated installer You can use"
      },
      "id": "60450ae964441f0603378f15"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from poll-based AWS integrations",
        "Query, dashboard, and alert considerations",
        "Troubleshooting",
        "No metrics or errors appear on New Relic",
        "Missing metrics for certain AWS namespaces",
        "Metric values discrepancies between AWS CloudWatch and New Relic",
        "AWS Metric Streams Operation",
        "Errors in the Status Dashboard"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-06-15T11:35:32Z",
      "updated_at": "2021-06-15T11:35:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from all services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in CloudWatch Metric Stream is order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from poll-based AWS integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. The AWS CloudWatch Metric Streams integration only collects metrics. Integrations such as AWS Health, AWS Billing, and AWS CloudTrail collect additional instrumentation that's not available for metric streams. In order to continue collecting that additional data, keep those enabled as polling integrations. Troubleshooting No metrics or errors appear on New Relic If you are not seeing data in New Relic once the AWS CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to troubleshoot your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS Troubleshooting docs for additional details. Check the Metric Stream metrics under AWS/CloudWatch/MetricStreams namespace. You will see a count of metric updates and errors per Metric Streams. This will indicate that the Metric Stream is successfully emitting data. If you see errors, confirm the IAM role specified in the Metric Streams configuration grants the CloudWatch service principal permissions to write to it. Check the Monitoring tab of the Kinesis Data Firehose in the Kinesis console to see if the Firehose is successfully receiving data. You can enable CloudWatch error logging on your Kinesis Data Firehose to get more detailed information for debugging issues. Refer to Amazon Kinesis Data Firehose official documentation for more details. Confirm that you have configured your Kinesis Data Firehose with the correct destination details: Ensure the New Relic API Key/License Key contains your 40 hexadecimal chars license key. Ensure the right data center US or EU has been selected for your New Relic account (hint: if the license_key starts with “eu” then you need to select the EU data center). Check that your Kinesis Data Firehose has permissions to write to the configured destination, for example: the S3 bucket policy allows write. Missing metrics for certain AWS namespaces New Relic does not apply any filter on the metrics received from the AWS CloudWatch metric stream. If you are expecting certain metrics to be ingested and it’s not the case, please verify the following: Make sure there’s no Inclusion or Exclusion filter in your CloudWatch Metric Stream. Make sure metrics are available in AWS as part of CloudWatch. Confirm you see the metrics in the AWS CloudWatch interface. Important AWS CloudWatch doesn't include metrics that are not available in less than 2 hours. For example, some S3 metrics are aggregated on a daily basis. We plan to make some of these special metrics available in New Relic. Metric values discrepancies between AWS CloudWatch and New Relic Metrics are processed, mapped, and stored as received from AWS CloudWatch metric stream. Some discrepancies might be observed when comparing AWS CloudWatch and New Relic dashboards. On limited scenarios, AWS CloudWatch applies specific functions and logic before rendering the metrics. These guidelines should help understand the root cause of the discrepancy: Check that the same function is used on the metrics (for example average, min, max). On the New Relic side, make sure you filter the same timestamp or timeframe (considering the timezone) to show the exact same time as in AWS CloudWatch. When using timeseries, the New Relic user interface might perform some rounding based on intervals. You can get a list of the raw metric received by time using a query like this one (note that no function is applied to the selected metric): FROM Metric SELECT aws.outposts.InstanceTypeCapacityUtilization WHERE collector.name = 'cloudwatch-metric-streams' Copy Remember that AWS fixes the maximum resolution for every metric reported in AWS CloudWatch (for example: 1 minute, 5 minutes, etc). AWS Metric Streams Operation You can see the state of the Metric Stream(s) in the Streams tab in the CloudWatch console. In particular, a Metric Stream can be in one of two states: running or stopped. Running: The stream is running correctly. Note that there may not be any metric data been streamed due to the configured filters. Although there is no data corresponding to the configured filters, the status of the Metric Stream can be running still. Stopped: The stream has been explicitly set to the halted state (not because of an error). This state is useful to temporarily stop the streaming of data without deleting the configuration. Errors in the Status Dashboard New Relic relies on the AWS Config service to collect additional metadata from resources in order to enrich metrics received via CloudWatch Metric Stream. Make sure AWS Config is enabled in your AWS Account, and ensure the linked Role has the following permission or inline policy created: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": \"config:BatchGetResourceConfig\", \"Resource\": \"*\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 102.41817,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Import</em> dashboards <em>from</em> Quickstarts App",
        "body": " template we provide in the last step of our UI. Manual setup using AWS Console, <em>API</em>, or calls Create a Kinesis <em>Data</em> Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or <em>other</em> sources <em>Data</em> transformation: Disabled Record format conversion: Disabled Destination"
      },
      "id": "606a036de7b9d2bfef9445f2"
    }
  ],
  "/docs/infrastructure/index": [
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-06-14T21:07:01Z",
      "updated_at": "2021-06-14T21:07:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. Built-in log forwarding and on-host integrations are not yet available. Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.10 to 1.16 Red Hat Enterprise Linux (RHEL) Version 6 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, and 12.4 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 (only the infrastructure agent is supported). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 70.34433,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> agent",
        "sections": "Requirements for the <em>infrastructure</em> agent",
        "tags": "<em>Infrastructure</em>",
        "body": "Before installing our <em>infrastructure</em> agent, make sure your system and any on-host integrations you configure meet the requirements. Processor architectures The <em>infrastructure</em> agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Configure polling frequency and data collection for cloud integrations",
        "Tip",
        "Overview of settings",
        "Caution",
        "Change polling frequency",
        "Specify data to be fetched",
        "Data collection",
        "Filters",
        "Potential impact on alerts and charts"
      ],
      "title": "Configure polling frequency and data collection for cloud integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Infrastructure integrations",
        "Cloud integrations"
      ],
      "external_id": "b900b7545f9032201c212449be114e10176bf789",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/infrastructure-integrations/cloud-integrations/configure-polling-frequency-data-collection-cloud-integrations/",
      "published_at": "2021-06-15T13:00:43Z",
      "updated_at": "2021-06-15T13:00:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our cloud integrations get data from cloud provider APIs. In New Relic, you can change some of the data collection-related settings for your cloud integrations. Read on to see what changes you can make and the reasons for making them. Tip To use integrations and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Overview of settings New Relic cloud integrations get data from cloud providers' APIs. Data is generally collected from monitoring APIs such as AWS CloudWatch, Azure Monitor, and GCP Stackdriver, and inventory metadata is collected from the specific services' APIs. You can use the account status dashboard to see how your cloud integrations are handling data from a cloud service provider. If you want to report more or less data from your cloud integrations, or if you need to control the use of the cloud providers' APIs to prevent reaching rate and throttling limits in your cloud account, you can change the configuration settings to modify the amount of data they report. The two main controls are: Change polling frequency Change what data is reported Examples of business reasons for wanting to change your polling frequency include: Billing: If you need to manage your AWS CloudWatch bill, you may want to decrease the polling frequency. Before you do this, make sure that any alert conditions set for your cloud integrations are not affected by this reduction. New services: If you are deploying a new service or configuration and you want to collect data more often, you may want to increase the polling frequency temporarily. Caution Changing the configuration settings for your integrations may impact alert conditions and chart trends. Change polling frequency The polling frequency configuration determines how often New Relic reports data from your cloud provider for each service. By default, the polling frequency is set to the maximum frequency that is available for each service. To change the polling frequency for a cloud integration: Go to one.newrelic.com > Infrastructure. Select the tab that corresponds to your cloud service provider. Select Configure next to the integration. Use the dropdowns next to Data polling interval every to select how frequently you want New Relic to capture your cloud integration data. Specify data to be fetched You can specify which information you want captured for your cloud integration by enabling the collection of additional data and by applying multiple filters to each integration. To change this settings for your cloud integration: Go to one.newrelic.com > Infrastructure. Select the tab that corresponds to your cloud service provider. Select Configure next to the integration. Under Data collections and filters, turn the toggles you want On. For filters, select or enter the values that you want included in your reported data. Data collection For some cloud integrations, an additional number of calls to the cloud provider APIs are needed in order to collect data. For example, to fetch tags for AWS Elastic Map Reduce clusters, an additional call to the service API is required. To better control the amount of API calls that are sent to your cloud account for these integrations, you can specify when you need these types of data to be collected. Different data collection toggles are available, depending on the integration. Toggle Description Collect tags Some integrations require additional API calls to the cloud provider to report tags. Tag collection is enabled by default. Switch this to Off if you don't want the integration to collect your cloud resource tags and thus reduce the volume of API calls. Collect extended inventory Some integrations can collect extended inventory metadata about your cloud resources by making additional API calls to the cloud provider. The metadata included within the extended inventory for each cloud integration is described in the integration documentation. Extended inventory collection is disabled by default. Switch this to On if you want to monitor extended inventory. This will increase the volume of API calls. Collect shards data Available for AWS Kinesis Streams integration. By default, we don't report shard metrics. Switch this to On if you want to monitor shard metrics in addition to data stream metrics. Collect Lambda@Edge data Available for AWS CloudFront integration. By default, we don't report Lambda@Edge data. Switch this to On if you're using Lambda@Edge in AWS CloudFront and want to get Lambda execution location metadata. Collect node data Available for AWS Elasticsearch integration. By default, we don't report Elasticsearch node metrics. Switch this to On if you want to monitor node metrics in addition to cluster metrics. Collect NAT Gateway data and Collect VPN data Available for AWS VPC integration. By default, we don't report NAT Gateway nor VPN metrics. Switch these to On if you want to monitor NAT Gateway and VPN metrics and inventory, in addition to other VPC related entities inventory. Collect IP addresses Available for AWS EC2 integration. By default, we collect EC2 instance metadata that includes public and private IP addresses, and network interface details. Switch this to Off if you don't want New Relic to store and display these IP data. Filters When a filter is On, you specify the data that you want to be collected; for example, if the Limit to AWS region is On, the regions that you select will be the ones that data will be collected for. There are different filters available, depending on the integration: Filter Description Region Select the regions that include the resources that you want to monitor. Queue prefixes Available for AWS SQS integration. Enter each name or prefix for the queues that you want to monitor. Filter values are case-sensitive. Load balancer prefixes Available for AWS ALB integration. Enter each name or prefix for the application load balancers that you want to monitor. Filter values are case-sensitive. Stage name prefixes Available for AWS API Gateway integration. Enter each name or prefix for the stages that you want to monitor. Filter values are case-sensitive. Tag key Enter one tag key that is associated with the resources that you want to monitor. Filter values are case-sensitive, and you can use this filter in combination with tag value filter. Tag value Enter one tag value that is associated with the resources that you want to monitor. Filter values are case-sensitive, and you can use this filter in combination with tag key. Resource group Select the resource groups that are associated with the resources that you want to monitor. Potential impact on alerts and charts If you change an integration's configuration, it can impact alert conditions and charts. Here are some things to consider: If you change this setting... It may have this impact... Any configuration setting When you change the configuration settings, the data that New Relic displays in infrastructure charts, on the inventory page, and in the events feed changes as well. Any filters When you create alert conditions after you set filters, make sure that your alerts are not triggered by resources that you filtered out. Filter for regions If you filter for specific regions, it may lower the amount of data reported to New Relic, which could trigger an alert. If you create an alert condition for a specific region and then filter that region out, the region would no longer report data and would never trigger the alert. Polling frequency When you create an alert, make sure that you define the threshold for a time period that is longer than the polling frequency. Tags and extended inventory If you turn on tags and/or extended inventory, New Relic makes more API calls to the cloud provider, which could increase your cloud provider API usage bill.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 59.273224,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Infrastructure</em> integrations",
        "body": " integration: Go to one.newrelic.com &gt; <em>Infrastructure</em>. Select the tab that corresponds to your cloud service provider. Select Configure next to the integration. Use the dropdowns next to Data polling interval every to select how frequently you want New Relic to capture your cloud integration data"
      },
      "id": "603e8eef64441fcc7e4e8853"
    },
    {
      "sections": [
        "On-host integrations metrics",
        "New Relic Integrations Metrics"
      ],
      "title": "On-host integrations metrics",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "fe96c0c4950380504b1a33c3ad861bcb17507cba",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/host-integrations-metrics/",
      "published_at": "2021-06-15T01:04:56Z",
      "updated_at": "2021-06-15T01:04:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Integrations Metrics The following table contains the metrics we collect for our infrastructure integrations. Integration Dimensional Metric Name (new) Sample Metric Name (previous) Agent host.cpuIdlePercent cpuIdlePercent Agent host.cpuIoWaitPercent cpuIOWaitPercent Agent host.cpuPercent cpuPercent Agent host.cpuStealPercent cpuStealPercent Agent host.cpuSystemPercent cpuSystemPercent Agent host.cpuUserPercent cpuUserPercent Agent host.disk.avgQueueLen avgQueueLen Agent host.disk.avgReadQueueLen avgReadQueueLen Agent host.disk.avgWriteQueueLen avgWriteQueueLen Agent host.disk.currentQueueLen currentQueueLen Agent host.disk.freeBytes diskFreeBytes Agent host.disk.freePercent diskFreePercent Agent host.disk.inodesFree inodesFree Agent host.disk.inodesTotal inodesTotal Agent host.disk.inodesUsed inodesUsed Agent host.disk.inodesUsedPercent inodesUsedPercent Agent host.disk.readBytesPerSecond readBytesPerSecond Agent host.disk.readIoPerSecond readIoPerSecond Agent host.disk.readUtilizationPercent readUtilizationPercent Agent host.disk.readWriteBytesPerSecond readWriteBytesPerSecond Agent host.disk.totalBytes diskTotalBytes Agent host.disk.totalUtilizationPercent totalUtilizationPercent Agent host.disk.usedBytes diskUsedBytes Agent host.disk.usedPercent diskUsedPercent Agent host.disk.writeBytesPerSecond writeBytesPerSecond Agent host.disk.writeIoPerSecond writeIoPerSecond Agent host.disk.writeUtilizationPercent writeUtilizationPercent Agent host.diskFreeBytes diskFreeBytes Agent host.diskFreePercent diskFreePercent Agent host.diskReadsPerSecond diskReadsPerSecond Agent host.diskReadUtilizationPercent diskReadUtilizationPercent Agent host.diskTotalBytes diskTotalBytes Agent host.diskUsedBytes diskUsedBytes Agent host.diskUsedPercent diskUsedPercent Agent host.diskUtilizationPercent diskUtilizationPercent Agent host.diskWritesPerSecond diskWritesPerSecond Agent host.diskWriteUtilizationPercent diskWriteUtilizationPercent Agent host.loadAverageFifteenMinute loadAverageFifteenMinute Agent host.loadAverageFiveMinute loadAverageFiveMinute Agent host.loadAverageOneMinute loadAverageOneMinute Agent host.memoryFreeBytes memoryFreeBytes Agent host.memoryFreePercent memoryFreePercent Agent host.memoryTotalBytes memoryTotalBytes Agent host.memoryUsedBytes memoryUsedBytes Agent host.memoryUsedPercent memoryUsedPercent Agent host.net.receiveBytesPerSecond receiveBytesPerSecond Agent host.net.receiveDroppedPerSecond receiveDroppedPerSecond Agent host.net.receiveErrorsPerSecond receiveErrorsPerSecond Agent host.net.receivePacketsPerSecond receivePacketsPerSecond Agent host.net.transmitBytesPerSecond transmitBytesPerSecond Agent host.net.transmitDroppedPerSecond transmitDroppedPerSecond Agent host.net.transmitErrorsPerSecond transmitErrorsPerSecond Agent host.net.transmitPacketsPerSecond transmitPacketsPerSecond Agent host.process.cpuPercent cpuPercent Agent host.process.cpuSystemPercent cpuSystemPercent Agent host.process.cpuUserPercent cpuUserPercent Agent host.process.fileDescriptorCount fileDescriptorCount Agent host.process.ioReadBytesPerSecond ioReadBytesPerSecond Agent host.process.ioReadCountPerSecond ioReadCountPerSecond Agent host.process.ioTotalReadBytes ioTotalReadBytes Agent host.process.ioTotalReadCount ioTotalReadCount Agent host.process.ioTotalWriteBytes ioTotalWriteBytes Agent host.process.ioTotalWriteCount ioTotalWriteCount Agent host.process.ioWriteBytesPerSecond ioWriteBytesPerSecond Agent host.process.ioWriteCountPerSecond ioWriteCountPerSecond Agent host.process.memoryResidentSizeBytes memoryResidentSizeBytes Agent host.process.memoryVirtualSizeBytes memoryVirtualSizeBytes Agent host.process.threadCount threadCount Agent host.swapFreeBytes swapFreeBytes Agent host.swapTotalBytes swapTotalBytes Agent host.swapUsedBytes swapUsedBytes Apache apache.server.busyWorkers server.busyWorkers Apache apache.server.idleWorkers server.idleWorkers Apache apache.server.net.bytesPerSecond net.bytesPerSecond Apache apache.server.net.requestsPerSecond net.requestsPerSecond Apache apache.server.scoreboard.closingWorkers server.scoreboard.closingWorkers Apache apache.server.scoreboard.dnsLookupWorkers server.scoreboard.dnsLookupWorkers Apache apache.server.scoreboard.finishingWorkers server.scoreboard.finishingWorkers Apache apache.server.scoreboard.idleCleanupWorkers server.scoreboard.idleCleanupWorkers Apache apache.server.scoreboard.keepAliveWorkers server.scoreboard.keepAliveWorkers Apache apache.server.scoreboard.loggingWorkers server.scoreboard.loggingWorkers Apache apache.server.scoreboard.readingWorkers server.scoreboard.readingWorkers Apache apache.server.scoreboard.startingWorkers server.scoreboard.startingWorkers Apache apache.server.scoreboard.totalWorkers server.scoreboard.totalWorkers Apache apache.server.scoreboard.writingWorkers server.scoreboard.writingWorkers Cassandra cassandra.node.allMemtablesOffHeapSizeBytes db.allMemtablesOffHeapSizeBytes Cassandra cassandra.node.allMemtablesOnHeapSizeBytes db.allMemtablesOnHeapSizeBytes Cassandra cassandra.node.client.connectedNativeClients client.connectedNativeClients Cassandra cassandra.node.commitLogCompletedTasksPerSecond db.commitLogCompletedTasksPerSecond Cassandra cassandra.node.commitLogPendingTasks db.commitLogPendindTasks Cassandra cassandra.node.commitLogTotalSizeBytes db.commitLogTotalSizeBytes Cassandra cassandra.node.droppedBatchRemoveMessagesPerSecond db.droppedBatchRemoveMessagesPerSecond Cassandra cassandra.node.droppedBatchStoreMessagesPerSecond db.droppedBatchStoreMessagesPerSecond Cassandra cassandra.node.droppedCounterMutationMessagesPerSecond db.droppedCounterMutationMessagesPerSecond Cassandra cassandra.node.droppedHintMessagesPerSecond db.droppedHintMessagesPerSecond Cassandra cassandra.node.droppedMutationMessagesPerSecond db.droppedMutationMessagesPerSecond Cassandra cassandra.node.droppedPagedRangeMessagesPerSecond db.droppedPagedRangeMessagesPerSecond Cassandra cassandra.node.droppedRangeSliceMessagesPerSecond db.droppedRangeSliceMessagesPerSecond Cassandra cassandra.node.droppedReadMessagesPerSecond db.droppedReadMessagesPerSecond Cassandra cassandra.node.droppedReadRepairMessagesPerSecond db.droppedReadRepairMessagesPerSecond Cassandra cassandra.node.droppedRequestResponseMessagesPerSecond db.droppedRequestResponseMessagesPerSecond Cassandra cassandra.node.droppedTraceMessagesPerSecond db.droppedTraceMessagesPerSecond Cassandra cassandra.node.keyCacheCapacityBytes db.keyCacheCapacityBytes Cassandra cassandra.node.keyCacheHitRate db.keyCacheHitRate Cassandra cassandra.node.keyCacheHitsPerSecond db.keyCacheHitsPerSecond Cassandra cassandra.node.keyCacheRequestsPerSecond db.keyCacheRequestsPerSecond Cassandra cassandra.node.keyCacheSizeBytes db.keyCacheSizeBytes Cassandra cassandra.node.liveSsTableCount db.liveSSTableCount Cassandra cassandra.node.loadBytes db.loadBytes Cassandra cassandra.node.query.casReadRequestsPerSecond query.CASReadRequestsPerSecond Cassandra cassandra.node.query.casWriteRequestsPerSecond query.CASWriteRequestsPerSecond Cassandra cassandra.node.query.rangeSliceRequestsPerSecond query.rangeSliceRequestsPerSecond Cassandra cassandra.node.query.rangeSliceTimeoutsPerSecond query.rangeSliceTimeoutsPerSecond Cassandra cassandra.node.query.rangeSliceUnavailablesPerSecond query.rangeSliceUnavailablesPerSecond Cassandra cassandra.node.query.readLatency50ThPercentileMilliseconds query.readLatency50thPercentileMilliseconds Cassandra cassandra.node.query.readLatency75ThPercentileMilliseconds query.readLatency75thPercentileMilliseconds Cassandra cassandra.node.query.readLatency95ThPercentileMilliseconds query.readLatency95thPercentileMilliseconds Cassandra cassandra.node.query.readLatency98ThPercentileMilliseconds query.readLatency98thPercentileMilliseconds Cassandra cassandra.node.query.readLatency999ThPercentileMilliseconds query.readLatency999thPercentileMilliseconds Cassandra cassandra.node.query.readLatency99ThPercentileMilliseconds query.readLatency99thPercentileMilliseconds Cassandra cassandra.node.query.readRequestsPerSecond query.readRequestsPerSecond Cassandra cassandra.node.query.readTimeoutsPerSecond query.readTimeoutsPerSecond Cassandra cassandra.node.query.readUnavailablesPerSecond query.readUnavailablesPerSecond Cassandra cassandra.node.query.viewWriteRequestsPerSecond query.viewWriteRequestsPerSecond Cassandra cassandra.node.query.writeLatency50ThPercentileMilliseconds query.writeLatency50thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency75ThPercentileMilliseconds query.writeLatency75thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency95ThPercentileMilliseconds query.writeLatency95thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency98ThPercentileMilliseconds query.writeLatency98thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency999ThPercentileMilliseconds query.writeLatency999thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency99ThPercentileMilliseconds query.writeLatency99thPercentileMilliseconds Cassandra cassandra.node.query.writeRequestsPerSecond query.writeRequestsPerSecond Cassandra cassandra.node.query.writeTimeoutsPerSecond query.writeTimeoutsPerSecond Cassandra cassandra.node.query.writeUnavailablesPerSecond query.writeUnavailablesPerSecond Cassandra cassandra.node.rowCacheCapacityBytes db.rowCacheCapacityBytes Cassandra cassandra.node.rowCacheHitRate db.rowCacheHitRate Cassandra cassandra.node.rowCacheHitsPerSecond db.rowCacheHitsPerSecond Cassandra cassandra.node.rowCacheRequestsPerSecond db.rowCacheRequestsPerSecond Cassandra cassandra.node.rowCacheSizeBytes db.rowCacheSizeBytes Cassandra cassandra.node.storage.exceptionCount storage.exceptionCount Cassandra cassandra.node.threadPool.antiEntropyStage.activeTasks db.threadpool.internalAntiEntropyStageActiveTasks Cassandra cassandra.node.threadPool.antiEntropyStage.completedTasks db.threadpool.internalAntiEntropyStageCompletedTasks Cassandra cassandra.node.threadPool.antiEntropyStage.currentlyBlockedTasks db.threadpool.internalAntiEntropyStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.antiEntropyStage.pendingTasks db.threadpool.internalAntiEntropyStagePendingTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.activeTasks db.threadpool.internalCacheCleanupExecutorActiveTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.completedTasks db.threadpool.internalCacheCleanupExecutorCompletedTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.currentlyBlockedTasks db.threadpool.internalCacheCleanupExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.pendingTasks db.threadpool.internalCacheCleanupExecutorPendingTasks Cassandra cassandra.node.threadPool.compactionExecutor.activeTasks db.threadpool.internalCompactionExecutorActiveTasks Cassandra cassandra.node.threadPool.compactionExecutor.completedTasks db.threadpool.internalCompactionExecutorCompletedTasks Cassandra cassandra.node.threadPool.compactionExecutor.currentlyBlockedTasks db.threadpool.internalCompactionExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.compactionExecutor.pendingTasks db.threadpool.internalCompactionExecutorPendingTasks Cassandra cassandra.node.threadPool.counterMutationStage.activeTasks db.threadpool.requestCounterMutationStageActiveTasks Cassandra cassandra.node.threadPool.counterMutationStage.completedTasks db.threadpool.requestCounterMutationStageCompletedTasks Cassandra cassandra.node.threadPool.counterMutationStage.currentlyBlockedTasks db.threadpool.requestCounterMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.counterMutationStage.pendingTasks db.threadpool.requestCounterMutationStagePendingTasks Cassandra cassandra.node.threadPool.gossipStage.activeTasks db.threadpool.internalGossipStageActiveTasks Cassandra cassandra.node.threadPool.gossipStage.completedTasks db.threadpool.internalGossipStageCompletedTasks Cassandra cassandra.node.threadPool.gossipStage.currentlyBlockedTasks db.threadpool.internalGossipStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.gossipStage.pendingTasks db.threadpool.internalGossipStagePendingTasks Cassandra cassandra.node.threadPool.hintsDispatcher.activeTasks db.threadpool.internalHintsDispatcherActiveTasks Cassandra cassandra.node.threadPool.hintsDispatcher.completedTasks db.threadpool.internalHintsDispatcherCompletedTasks Cassandra cassandra.node.threadPool.hintsDispatcher.currentlyBlockedTasks db.threadpool.internalHintsDispatcherCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.hintsDispatcher.pendingTasks db.threadpool.internalHintsDispatcherPendingTasks Cassandra cassandra.node.threadPool.internalResponseStage.activeTasks db.threadpool.internalInternalResponseStageActiveTasks Cassandra cassandra.node.threadPool.internalResponseStage.completedTasks db.threadpool.internalInternalResponseStageCompletedTasks Cassandra cassandra.node.threadPool.internalResponseStage.pCurrentlyBlockedTasks db.threadpool.internalInternalResponseStagePCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.internalResponseStage.pendingTasks db.threadpool.internalInternalResponseStagePendingTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.activeTasks db.threadpool.internalMemtableFlushWriterActiveTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.completedTasks db.threadpool.internalMemtableFlushWriterCompletedTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.currentlyBlockedTasks db.threadpool.internalMemtableFlushWriterCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.pendingTasks db.threadpool.internalMemtableFlushWriterPendingTasks Cassandra cassandra.node.threadPool.memtablePostFlush.activeTasks db.threadpool.internalMemtablePostFlushActiveTasks Cassandra cassandra.node.threadPool.memtablePostFlush.completedTasks db.threadpool.internalMemtablePostFlushCompletedTasks Cassandra cassandra.node.threadPool.memtablePostFlush.currentlyBlockedTasks db.threadpool.internalMemtablePostFlushCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtablePostFlush.pendingTasks db.threadpool.internalMemtablePostFlushPendingTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.activeTasks db.threadpool.internalMemtableReclaimMemoryActiveTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.completedTasks db.threadpool.internalMemtableReclaimMemoryCompletedTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.currentlyBlockedTasks db.threadpool.internalMemtableReclaimMemoryCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.pendingTasks db.threadpool.internalMemtableReclaimMemoryPendingTasks Cassandra cassandra.node.threadPool.migrationStage.activeTasks db.threadpool.internalMigrationStageActiveTasks Cassandra cassandra.node.threadPool.migrationStage.completedTasks db.threadpool.internalMigrationStageCompletedTasks Cassandra cassandra.node.threadPool.migrationStage.currentlyBlockedTasks db.threadpool.internalMigrationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.migrationStage.pendingTasks db.threadpool.internalMigrationStagePendingTasks Cassandra cassandra.node.threadPool.miscStage.activeTasks db.threadpool.internalMiscStageActiveTasks Cassandra cassandra.node.threadPool.miscStage.completedTasks db.threadpool.internalMiscStageCompletedTasks Cassandra cassandra.node.threadPool.miscStage.currentlyBlockedTasks db.threadpool.internalMiscStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.miscStage.pendingTasks db.threadpool.internalMiscStagePendingTasks Cassandra cassandra.node.threadPool.mutationStage.activeTasks db.threadpool.requestMutationStageActiveTasks Cassandra cassandra.node.threadPool.mutationStage.completedTasks db.threadpool.requestMutationStageCompletedTasks Cassandra cassandra.node.threadPool.mutationStage.currentlyBlockedTasks db.threadpool.requestMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.mutationStage.pendingTasks db.threadpool.requestMutationStagePendingTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.activeTasks db.threadpool.internalPendingRangeCalculatorActiveTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.completedTasks db.threadpool.internalPendingRangeCalculatorCompletedTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.currentlyBlockedTasks db.threadpool.internalPendingRangeCalculatorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.pendingTasks db.threadpool.internalPendingRangeCalculatorPendingTasks Cassandra cassandra.node.threadPool.readRepairStage.activeTasks db.threadpool.requestReadRepairStageActiveTasks Cassandra cassandra.node.threadPool.readRepairStage.completedTasks db.threadpool.requestReadRepairStageCompletedTasks Cassandra cassandra.node.threadPool.readRepairStage.currentlyBlockedTasks db.threadpool.requestReadRepairStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.readRepairStage.pendingTasks db.threadpool.requestReadRepairStagePendingTasks Cassandra cassandra.node.threadPool.readStage.activeTasks db.threadpool.requestReadStageActiveTasks Cassandra cassandra.node.threadPool.readStage.completedTasks db.threadpool.requestReadStageCompletedTasks Cassandra cassandra.node.threadPool.readStage.currentlyBlockedTasks db.threadpool.requestReadStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.readStage.pendingTasks db.threadpool.requestReadStagePendingTasks Cassandra cassandra.node.threadPool.requestResponseStage.activeTasks db.threadpool.requestRequestResponseStageActiveTasks Cassandra cassandra.node.threadPool.requestResponseStage.completedTasks db.threadpool.requestRequestResponseStageCompletedTasks Cassandra cassandra.node.threadPool.requestResponseStage.currentlyBlockedTasks db.threadpool.requestRequestResponseStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.requestResponseStage.pendingTasks db.threadpool.requestRequestResponseStagePendingTasks Cassandra cassandra.node.threadPool.sampler.activeTasks db.threadpool.internalSamplerActiveTasks Cassandra cassandra.node.threadPool.sampler.completedTasks db.threadpool.internalSamplerCompletedTasks Cassandra cassandra.node.threadPool.sampler.currentlyBlockedTasks db.threadpool.internalSamplerCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.sampler.pendingTasks db.threadpool.internalSamplerPendingTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.activeTasks db.threadpool.internalSecondaryIndexManagementActiveTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.completedTasks db.threadpool.internalSecondaryIndexManagementCompletedTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.currentlyBlockedTasks db.threadpool.internalSecondaryIndexManagementCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.pendingTasks db.threadpool.internalSecondaryIndexManagementPendingTasks Cassandra cassandra.node.threadPool.validationExecutor.activeTasks db.threadpool.internalValidationExecutorActiveTasks Cassandra cassandra.node.threadPool.validationExecutor.completedTasks db.threadpool.internalValidationExecutorCompletedTasks Cassandra cassandra.node.threadPool.validationExecutor.currentlyBlockedTasks db.threadpool.internalValidationExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.validationExecutor.pendingTasks db.threadpool.internalValidationExecutorPendingTasks Cassandra cassandra.node.threadPool.viewMutationStage.activeTasks db.threadpool.requestViewMutationStageActiveTasks Cassandra cassandra.node.threadPool.viewMutationStage.completedTasks db.threadpool.requestViewMutationStageCompletedTasks Cassandra cassandra.node.threadPool.viewMutationStage.currentlyBlockedTasks db.threadpool.requestViewMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.viewMutationStage.pendingTasks db.threadpool.requestViewMutationStagePendingTasks Cassandra cassandra.node.totalHintsInProgress db.totalHintsInProgress Cassandra cassandra.node.totalHintsPerSecond db.totalHintsPerSecond Cassandra cassandra.columnFamily.allMemtablesOffHeapSizeBytes db.allMemtablesOffHeapSizeBytes Cassandra cassandra.columnFamily.allMemtablesOnHeapSizeBytes db.allMemtablesOnHeapSizeBytes Cassandra cassandra.columnFamily.bloomFilterFalseRatio db.bloomFilterFalseRatio Cassandra cassandra.columnFamily.liveDiskSpaceUsedBytes db.liveDiskSpaceUsedBytes Cassandra cassandra.columnFamily.liveSsTableCount db.liveSSTableCount Cassandra cassandra.columnFamily.maxRowSize db.maxRowSize Cassandra cassandra.columnFamily.meanRowSize db.meanRowSize Cassandra cassandra.columnFamily.memtableLiveDataSize db.memtableLiveDataSize Cassandra cassandra.columnFamily.minRowSize db.minRowSize Cassandra cassandra.columnFamily.pendingCompactions db.pendingCompactions Cassandra cassandra.columnFamily.query.readLatency50ThPercentileMilliseconds query.readLatency50thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency75ThPercentileMilliseconds query.readLatency75thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency95ThPercentileMilliseconds query.readLatency95thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency98ThPercentileMilliseconds query.readLatency98thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency999ThPercentileMilliseconds query.readLatency999thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency99ThPercentileMilliseconds query.readLatency99thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readRequestsPerSecond query.readRequestsPerSecond Cassandra cassandra.columnFamily.query.writeLatency50ThPercentileMilliseconds query.writeLatency50thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency75ThPercentileMilliseconds query.writeLatency75thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency95ThPercentileMilliseconds query.writeLatency95thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency98ThPercentileMilliseconds query.writeLatency98thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency999ThPercentileMilliseconds query.writeLatency999thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency99ThPercentileMilliseconds query.writeLatency99thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeRequestsPerSecond query.writeRequestsPerSecond Cassandra cassandra.columnFamily.speculativeRetries db.speculativeRetries Cassandra cassandra.columnFamily.ssTablesPerRead50ThPercentileMilliseconds db.SSTablesPerRead50thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead75ThPercentileMilliseconds db.SSTablesPerRead75thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead95ThPercentileMilliseconds db.SSTablesPerRead95thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead98ThPercentileMilliseconds db.SSTablesPerRead98thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead999ThPercentileMilliseconds db.SSTablesPerRead999thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead99ThPercentileMilliseconds db.SSTablesPerRead99thPercentileMilliseconds Cassandra cassandra.columnFamily.tombstoneScannedHistogram50ThPercentile db.tombstoneScannedHistogram50thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram75ThPercentile db.tombstoneScannedHistogram75thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram95ThPercentile db.tombstoneScannedHistogram95thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram98ThPercentile db.tombstoneScannedHistogram98thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram999ThPercentile db.tombstoneScannedHistogram999thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram99ThPercentile db.tombstoneScannedHistogram99thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogramCount db.tombstoneScannedHistogramCount Consul consul.datacenter.catalog.criticalNodes catalog.criticalNodes Consul consul.datacenter.catalog.passingNodes catalog.passingNodes Consul consul.datacenter.catalog.registeredNodes catalog.registeredNodes Consul consul.datacenter.catalog.upNodes catalog.upNodes Consul consul.datacenter.catalog.warningNodes catalog.warningNodes Consul consul.datacenter.cluster.flaps cluster.flaps Consul consul.datacenter.cluster.suspects cluster.suspects Consul consul.datacenter.raft.commitTime raft.commitTimes Consul consul.datacenter.raft.commitTimeAvgInMilliseconds raft.commitTimeAvgInMilliseconds Consul consul.datacenter.raft.commitTimeMaxInMilliseconds raft.commitTimeMaxInMilliseconds Consul consul.datacenter.raft.completedLeaderElections raft.completedLeaderElections Consul consul.datacenter.raft.initiatedLeaderElections raft.initiatedLeaderElections Consul consul.datacenter.raft.lastContactAvgInMilliseconds raft.lastContactAvgInMilliseconds Consul consul.datacenter.raft.lastContactMaxInMilliseconds raft.lastContactMaxInMilliseconds Consul consul.datacenter.raft.lastContacts raft.lastContacts Consul consul.datacenter.raft.logDispatchAvgInMilliseconds raft.logDispatchAvgInMilliseconds Consul consul.datacenter.raft.logDispatches raft.logDispatches Consul consul.datacenter.raft.logDispatchMaxInMilliseconds raft.logDispatchMaxInMilliseconds Consul consul.datacenter.raft.txns raft.txns Consul consul.agent.aclCacheHitPerSecond agent.aclCacheHit Consul consul.agent.aclCacheMissPerSecond agent.aclCacheMiss Consul consul.agent.client.rpcFailed client.rpcFailed Consul consul.agent.client.rpcLoad client.rpcLoad Consul consul.agent.kvStores agent.kvStoress Consul consul.agent.kvStoresAvgInMilliseconds agent.kvStoresAvgInMilliseconds Consul consul.agent.kvStoresMaxInMilliseconds agent.kvStoresMaxInMilliseconds Consul consul.agent.net.agent.maxLatencyInMilliseconds net.agent.maxLatencyInMilliseconds Consul consul.agent.net.medianLatencyInMilliseconds net.agent.medianLatencyInMilliseconds Consul consul.agent.net.minLatencyInMilliseconds net.agent.minLatencyInMilliseconds Consul consul.agent.net.p25LatencyInMilliseconds net.agent.p25LatencyInMilliseconds Consul consul.agent.net.p75LatencyInMilliseconds net.agent.p75LatencyInMilliseconds Consul consul.agent.net.p90LatencyInMilliseconds net.agent.p90LatencyInMilliseconds Consul consul.agent.net.p95LatencyInMilliseconds net.agent.p95LatencyInMilliseconds Consul consul.agent.net.p99LatencyInMilliseconds net.agent.p99LatencyInMilliseconds Consul consul.agent.peers agent.peers Consul consul.agent.runtime.allocations runtime.allocations Consul consul.agent.runtime.allocationsInBytes runtime.allocationsInBytes Consul consul.agent.runtime.frees runtime.frees Consul consul.agent.runtime.gcCycles runtime.gcCycles Consul consul.agent.runtime.gcPauseInMilliseconds runtime.gcPauseInMilliseconds Consul consul.agent.runtime.goroutines runtime.goroutines Consul consul.agent.runtime.heapObjects runtime.heapObjects Consul consul.agent.runtime.virtualAddressSpaceInBytes runtime.virtualAddressSpaceInBytes Consul consul.agent.staleQueries agent.staleQueries Consul consul.agent.txnAvgInMilliseconds agent.txnAvgInMilliseconds Consul consul.agent.txnMaxInMilliseconds agent.txnMaxInMilliseconds Consul consul.agent.txns agent.txns Couchbase couchbase.bucket.activeItemsEnteringDiskQueuePerSecond bucket.activeItemsEnteringDiskQueuePerSecond Couchbase couchbase.bucket.activeItemsInMemory bucket.activeItemsInMemory Couchbase couchbase.bucket.activeResidentItemsRatio bucket.activeResidentItemsRatio Couchbase couchbase.bucket.averageDiskCommitTimeInMilliseconds bucket.averageDiskCommitTimeInMilliseconds Couchbase couchbase.bucket.averageDiskUpdateTimeInMilliseconds bucket.averageDiskUpdateTimeInMilliseconds Couchbase couchbase.bucket.cacheMisses bucket.cacheMisses Couchbase couchbase.bucket.cacheMissRatio bucket.cacheMissRatio Couchbase couchbase.bucket.casHits bucket.casHits Couchbase couchbase.bucket.casMisses bucket.casMisses Couchbase couchbase.bucket.couchDocsFragmentationPercent bucket.couchDocsFragmentationPercent Couchbase couchbase.bucket.currentConnections bucket.currentConnections Couchbase couchbase.bucket.dataUsedInBytes bucket.dataUsedInBytes Couchbase couchbase.bucket.decrementHitsPerSecond bucket.decrementHitsPerSecond Couchbase couchbase.bucket.decrementMissesPerSecond bucket.decrementMissesPerSecond Couchbase couchbase.bucket.deleteHitsPerSecond bucket.deleteHitsPerSecond Couchbase couchbase.bucket.deleteMissesPerSecond bucket.deleteMissesPerSecond Couchbase couchbase.bucket.diskCreateOperationsPerSecond bucket.diskCreateOperationsPerSecond Couchbase couchbase.bucket.diskFetchesPerSecond bucket.diskFetchesPerSecond Couchbase couchbase.bucket.diskReadsPerSecond bucket.diskReadsPerSecond Couchbase couchbase.bucket.diskUpdateOperationsPerSecond bucket.diskUpdateOperationsPerSecond Couchbase couchbase.bucket.diskUsedInBytes bucket.diskUsedInBytes Couchbase couchbase.bucket.diskWriteQueue bucket.diskWriteQueue Couchbase couchbase.bucket.drainedItemsInQueue bucket.drainedItemsInQueue Couchbase couchbase.bucket.drainedItemsOnDiskQueue bucket.drainedItemsOnDiskQueue Couchbase couchbase.bucket.drainedPendingItemsInQueue bucket.drainedPendingItemsInQueue Couchbase couchbase.bucket.ejectionsPerSecond bucket.ejectionsPerSecond Couchbase couchbase.bucket.evictionsPerSecond bucket.evictionsPerSecond Couchbase couchbase.bucket.getHitsPerSecond bucket.getHitsPerSecond Couchbase couchbase.bucket.getMissesPerSecond bucket.getMissesPerSecond Couchbase couchbase.bucket.hitRatio bucket.hitRatio Couchbase couchbase.bucket.incrementHitsPerSecond bucket.incrementHitsPerSecond Couchbase couchbase.bucket.incrementMissesPerSecond bucket.incrementMissesPerSecond Couchbase couchbase.bucket.itemCount bucket.itemCount Couchbase couchbase.bucket.itemsBeingWritten bucket.itemsBeingWritten Couchbase couchbase.bucket.itemsEjectedFromMemoryToDisk bucket.itemsEjectedFromMemoryToDisk Couchbase couchbase.bucket.itemsOnDiskQueue bucket.itemsOnDiskQueue Couchbase couchbase.bucket.itemsQueuedForStorage bucket.itemsQueuedForStorage Couchbase couchbase.bucket.maximumMemoryUsage bucket.maximumMemoryUsage Couchbase couchbase.bucket.memoryHighWaterMarkInBytes bucket.memoryHighWaterMarkInBytes Couchbase couchbase.bucket.memoryLowWaterMarkInBytes bucket.memoryLowWaterMarkInBytes Couchbase couchbase.bucket.memoryUsedInBytes bucket.memoryUsedInBytes Couchbase couchbase.bucket.metadataInRamInBytes bucket.metadataInRAMInBytes Couchbase couchbase.bucket.missesPerSecond bucket.missesPerSecond Couchbase couchbase.bucket.outOfMemoryErrorsPerSecond bucket.outOfMemoryErrorsPerSecond Couchbase couchbase.bucket.overheadInBytes bucket.overheadInBytes Couchbase couchbase.bucket.pendingItemsInDiskQueue bucket.pendingItemsInDiskQueue Couchbase couchbase.bucket.pendingResidentItemsRatio bucket.pendingResidentItemsRatio Couchbase couchbase.bucket.quotaUtilization bucket.quotaUtilization Couchbase couchbase.bucket.readOperationsPerSecond bucket.readOperationsPerSecond Couchbase couchbase.bucket.readRatePerSecond bucket.readRatePerSecond Couchbase couchbase.bucket.recoverableOutOfMemoryCount bucket.recoverableOutOfMemoryCount Couchbase couchbase.bucket.replicaIndex bucket.replicaIndex Couchbase couchbase.bucket.replicaNumber bucket.replicaNumber Couchbase couchbase.bucket.replicaResidentItemsRatio bucket.replicaResidentItemsRatio Couchbase couchbase.bucket.residentItemsRatio bucket.residentItemsRatio Couchbase couchbase.bucket.temporaryOutOfMemoryErrorsPerSecond bucket.temporaryOutOfMemoryErrorsPerSecond Couchbase couchbase.bucket.threadsNumber bucket.threadsNumber Couchbase couchbase.bucket.totalItems bucket.totalItems Couchbase couchbase.bucket.totalOperationsPerSecond bucket.totalOperationsPerSecond Couchbase couchbase.bucket.viewFragmentationPercent bucket.viewFragmentationPercent Couchbase couchbase.bucket.writeOperationsPerSecond bucket.writeOperationsPerSecond Couchbase couchbase.bucket.writeRatePerSecond bucket.writeRatePerSecond Couchbase couchbase.cluster.autoFailoverCount cluster.autoFailoverCount Couchbase couchbase.cluster.autoFailoverEnabled cluster.autoFailoverEnabled Couchbase couchbase.cluster.databaseFragmentationThreshold cluster.databaseFragmentationThreshold Couchbase couchbase.cluster.diskFreeInBytes cluster.diskFreeInBytes Couchbase couchbase.cluster.diskQuotaTotalInBytes cluster.diskQuotaTotalInBytes Couchbase couchbase.cluster.diskTotalInBytes cluster.diskTotalInBytes Couchbase couchbase.cluster.diskUsedByDataInBytes cluster.diskUsedByDataInBytes Couchbase couchbase.cluster.diskUsedInBytes cluster.diskUsedInBytes Couchbase couchbase.cluster.indexFragmentationThreshold cluster.indexFragmentationThreshold Couchbase couchbase.cluster.maximumBucketCount cluster.maximumBucketCount Couchbase couchbase.cluster.memoryQuotaTotalInBytes cluster.memoryQuotaTotalInBytes Couchbase couchbase.cluster.memoryQuotaTotalPerNodeInBytes cluster.memoryQuotaTotalPerNodeInBytes Couchbase couchbase.cluster.memoryQuotaUsedInBytes cluster.memoryQuotaUsedInBytes Couchbase couchbase.cluster.memoryQuotaUsedPerNodeInBytes cluster.memoryQuotaUsedPerNodeInBytes Couchbase couchbase.cluster.memoryTotalInBytes cluster.memoryTotalInBytes Couchbase couchbase.cluster.memoryUsedByDataInBytes cluster.memoryUsedByDataInBytes Couchbase couchbase.cluster.memoryUsedInBytes cluster.memoryUsedInBytes Couchbase couchbase.cluster.viewFragmentationThreshold cluster.viewFragmentationThreshold Couchbase couchbase.node.backgroundFetches node.backgroundFetches Couchbase couchbase.node.cmdGet node.cmdGet Couchbase couchbase.node.couchDocsActualDiskSizeInBytes node.couchDocsActualDiskSizeInBytes Couchbase couchbase.node.couchDocsDataSizeInBytes node.couchDocsDataSizeInBytes Couchbase couchbase.node.couchSpatialDataSizeInBytes node.couchSpatialDataSizeInBytes Couchbase couchbase.node.couchSpatialDiskSizeInBytes node.couchSpatialDiskSizeInBytes Couchbase couchbase.node.couchViewsActualDiskSizeInBytes node.couchViewsActualDiskSizeInBytes Couchbase couchbase.node.couchViewsDataSizeInBytes node.couchViewsDataSizeInBytes Couchbase couchbase.node.cpuUtilization node.cpuUtilization Couchbase couchbase.node.currentItems node.currentItems Couchbase couchbase.node.currentItemsTotal node.currentItemsTotal Couchbase couchbase.node.getHits node.getHits Couchbase couchbase.node.memoryFreeInBytes node.memoryFreeInBytes Couchbase couchbase.node.memoryTotalInBytes node.memoryTotalInBytes Couchbase couchbase.node.memoryUsedInBytes node.memoryUsedInBytes Couchbase couchbase.node.ops node.ops Couchbase couchbase.node.swapTotalInBytes node.swapTotalInBytes Couchbase couchbase.node.swapUsedInBytes node.swapUsedInBytes Couchbase couchbase.node.uptimeInMilliseconds node.uptimeInMilliseconds Couchbase couchbase.node.vbucketActiveNonResidentItems node.vbucketActiveNonResidentItems Couchbase couchbase.node.vbucketInMemoryItems node.vbucketInMemoryItems Couchbase couchbase.queryengine.activeRequests queryengine.activeRequests Couchbase couchbase.queryengine.averageRequestTimeInMilliseconds queryengine.averageRequestTimeInMilliseconds Couchbase couchbase.queryengine.completedLimit queryengine.completedLimit Couchbase couchbase.queryengine.completedRequests queryengine.completedRequests Couchbase couchbase.queryengine.completedThresholdInMilliseconds queryengine.completedThresholdInMilliseconds Couchbase couchbase.queryengine.cores queryengine.cores Couchbase couchbase.queryengine.garbageCollectionNumber queryengine.garbageCollectionNumber Couchbase couchbase.queryengine.garbageCollectionPaused queryengine.garbageCollectionPaused Couchbase couchbase.queryengine.garbageCollectionTimePausedInMilliseconds queryengine.garbageCollectionTimePausedInMilliseconds Couchbase couchbase.queryengine.medianRequestTimeInMilliseconds queryengine.medianRequestTimeInMilliseconds Couchbase couchbase.queryengine.preparedStatementUtilization queryengine.preparedStatementUtilization Couchbase couchbase.queryengine.requestsLast15MinutesPerSecond queryengine.requestsLast15MinutesPerSecond Couchbase couchbase.queryengine.requestsLast1MinutesPerSecond queryengine.requestsLast1MinutesPerSecond Couchbase couchbase.queryengine.requestsLast5MinutesPerSecond queryengine.requestsLast5MinutesPerSecond Couchbase couchbase.queryengine.requestTime80thPercentileInMilliseconds queryengine.requestTime80thPercentileInMilliseconds Couchbase couchbase.queryengine.requestTime95thPercentileInMilliseconds queryengine.requestTime95thPercentileInMilliseconds Couchbase couchbase.queryengine.requestTime99thPercentileInMilliseconds queryengine.requestTime99thPercentileInMilliseconds Couchbase couchbase.queryengine.systemCpuUtilization queryengine.systemCPUUtilization Couchbase couchbase.queryengine.systemMemoryInBytes queryengine.systemMemoryInBytes Couchbase couchbase.queryengine.totalMemoryInBytes queryengine.totalMemoryInBytes Couchbase couchbase.queryengine.totalThreads queryengine.totalThreads Couchbase couchbase.queryengine.uptimeInMilliseconds queryengine.uptimeInMilliseconds Couchbase couchbase.queryengine.usedMemoryInBytes queryengine.usedMemoryInBytes Couchbase couchbase.queryengine.userCpuUtilization queryengine.userCPUUtilization Docker docker.container.cpuKernelPercent cpuKernelPercent Docker docker.container.cpuLimitCores cpuLimitCores Docker docker.container.cpuPercent cpuPercent Docker docker.container.cpuThrottlePeriods cpuThrottlePeriods Docker docker.container.cpuThrottleTimeMs cpuThrottleTimeMs Docker docker.container.cpuUsedCores cpuUsedCores Docker docker.container.cpuUsedCoresPercent cpuUsedCoresPercent Docker docker.container.cpuUserPercent cpuUserPercent Docker docker.container.ioReadBytesPerSecond ioReadBytesPerSecond Docker docker.container.ioReadCountPerSecond ioReadCountPerSecond Docker docker.container.ioTotalBytes ioTotalBytes Docker docker.container.ioTotalReadBytes ioTotalReadBytes Docker docker.container.ioTotalReadCount ioTotalReadCount Docker docker.container.ioTotalWriteBytes ioTotalWriteBytes Docker docker.container.ioTotalWriteCount ioTotalWriteCount Docker docker.container.ioWriteBytesPerSecond ioWriteBytesPerSecond Docker docker.container.ioWriteCountPerSecond ioWriteCountPerSecond Docker docker.container.memoryCacheBytes memoryCacheBytes Docker docker.container.memoryResidentSizeBytes memoryResidentSizeBytes Docker docker.container.memorySizeLimitBytes memorySizeLimitBytes Docker docker.container.memoryUsageBytes memoryUsageBytes Docker docker.container.memoryUsageLimitPercent memoryUsageLimitPercent Docker docker.container.networkRxBytes networkRxBytes Docker docker.container.networkRxBytesPerSecond networkRxBytesPerSecond Docker docker.container.networkRxDropped networkRxDropped Docker docker.container.networkRxDroppedPerSecond networkRxDroppedPerSecond Docker docker.container.networkRxErrors networkRxErrors Docker docker.container.networkRxErrorsPerSecond networkRxErrorsPerSecond Docker docker.container.networkRxPackets networkRxPackets Docker docker.container.networkRxPacketsPerSecond networkRxPacketsPerSecond Docker docker.container.networkTxBytes networkTxBytes Docker docker.container.networkTxBytesPerSecond networkTxBytesPerSecond Docker docker.container.networkTxDropped networkTxDropped Docker docker.container.networkTxDroppedPerSecond networkTxDroppedPerSecond Docker docker.container.networkTxErrors networkTxErrors Docker docker.container.networkTxErrorsPerSecond networkTxErrorsPerSecond Docker docker.container.networkTxPackets networkTxPackets Docker docker.container.networkTxPacketsPerSecond networkTxPacketsPerSecond Docker docker.container.pids pids Docker docker.container.processCount processCount Docker docker.container.processCountLimit processCountLimit Docker docker.container.restartCount restartCount Docker docker.container.threadCount threadCount Docker docker.container.threadCountLimit threadCountLimit ElasticSearch elasticsearch.cluster.dataNodes cluster.dataNodes ElasticSearch elasticsearch.cluster.nodes cluster.nodes ElasticSearch elasticsearch.cluster.shards.active shards.active ElasticSearch elasticsearch.cluster.shards.initializing shards.initializing ElasticSearch elasticsearch.cluster.shards.primaryActive shards.primaryActive ElasticSearch elasticsearch.cluster.shards.relocating shards.relocating ElasticSearch elasticsearch.cluster.shards.unassigned shards.unassigned ElasticSearch elasticsearch.cluster.tempData temp-data ElasticSearch elasticsearch.index.docs index.docs ElasticSearch elasticsearch.index.docsDeleted index.docsDeleted ElasticSearch elasticsearch.index.primaryShards index.primaryShards ElasticSearch elasticsearch.index.primaryStoreSizeInBytes index.primaryStoreSizeInBytes ElasticSearch elasticsearch.index.replicaShards index.replicaShards ElasticSearch elasticsearch.index.rollup.docsCount primaries.docsnumber ElasticSearch elasticsearch.index.rollup.docsDeleted primaries.docsDeleted ElasticSearch elasticsearch.index.rollup.flushTotal primaries.flushesTotal ElasticSearch elasticsearch.index.rollup.flushTotalTimeInMilliseconds primaries.flushTotalTimeInMilliseconds ElasticSearch elasticsearch.index.rollup.get.documentsExist primaries.get.documentsExist ElasticSearch elasticsearch.index.rollup.get.documentsExistInMilliseconds primaries.get.documentsExistInMilliseconds ElasticSearch elasticsearch.index.rollup.get.documentsMissing primaries.get.documentsMissing ElasticSearch elasticsearch.index.rollup.get.documentsMissingInMilliseconds primaries.get.documentsMissingInMilliseconds ElasticSearch elasticsearch.index.rollup.get.requests primaries.get.requests ElasticSearch elasticsearch.index.rollup.get.requestsCurrent primaries.get.requestsCurrent ElasticSearch elasticsearch.index.rollup.get.requestsInMilliseconds primaries.get.requestsInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyDeleted primaries.index.docsCurrentlyDeleted ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyDeletedInMilliseconds primaries.index.docsCurrentlyDeletedInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyIndexing primaries.index.docsCurrentlyIndexing ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyIndexingInMilliseconds primaries.index.docsCurrentlyIndexingInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsDeleted primaries.index.docsDeleted ElasticSearch elasticsearch.index.rollup.index.docsTotal primaries.index.docsTotal ElasticSearch elasticsearch.index.rollup.indexRefreshesTotal primaries.indexRefreshesTotal ElasticSearch elasticsearch.index.rollup.indexRefreshesTotalInMilliseconds primaries.indexRefreshesTotalInMilliseconds ElasticSearch elasticsearch.index.rollup.merges.current primaries.merges.current ElasticSearch elasticsearch.index.rollup.merges.docsSegmentsCurrentlyMerged primaries.merges.docsSegmentsCurrentlyMerged ElasticSearch elasticsearch.index.rollup.merges.docsTotal primaries.merges.docsTotal ElasticSearch elasticsearch.index.rollup.merges.segmentsCurrentlyMergedInBytes primaries.merges.segmentsCurrentlyMergedInBytes ElasticSearch elasticsearch.index.rollup.merges.segmentsTotal primaries.merges.segmentsTotal ElasticSearch elasticsearch.index.rollup.merges.segmentsTotalInBytes primaries.merges.segmentsTotalInBytes ElasticSearch elasticsearch.index.rollup.merges.segmentsTotalInMilliseconds primaries.merges.segmentsTotalInMilliseconds ElasticSearch elasticsearch.index.rollup.queriesInMilliseconds primaries.queriesInMilliseconds ElasticSearch elasticsearch.index.rollup.queriesTotal primaries.queriesTotal ElasticSearch elasticsearch.index.rollup.queryActive primaries.queryActive ElasticSearch elasticsearch.index.rollup.queryFetches primaries.queryFetches ElasticSearch elasticsearch.index.rollup.queryFetchesInMilliseconds primaries.queryFetchesInMilliseconds ElasticSearch elasticsearch.index.rollup.queryFetchesTotal primaries.queryFetchesTotal ElasticSearch elasticsearch.index.rollup.sizeInBytes primaries.sizeInBytes ElasticSearch elasticsearch.index.storeSizeInBytes index.storeSizeInBytes ElasticSearch elasticsearch.node.activeSearches activeSearches ElasticSearch elasticsearch.node.activeSearchesInMilliseconds activeSearchesInMilliseconds ElasticSearch elasticsearch.node.breakers.estimatedSizeFieldDataCircuitBreakerInBytes breakers.estimatedSizeFieldDataCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.estimatedSizeParentCircuitBreakerInBytes breakers.estimatedSizeParentCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.estimatedSizeRequestCircuitBreakerInBytes breakers.estimatedSizeRequestCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.fieldDataCircuitBreakerTripped breakers.fieldDataCircuitBreakerTripped ElasticSearch elasticsearch.node.breakers.parentCircuitBreakerTripped breakers.parentCircuitBreakerTripped ElasticSearch elasticsearch.node.breakers.requestCircuitBreakerTripped breakers.requestCircuitBreakerTripped ElasticSearch elasticsearch.node.flush.indexRefreshesTotal flush.indexRefreshesTotal ElasticSearch elasticsearch.node.flush.indexRefreshesTotalInMilliseconds flush.indexRefreshesTotalInMilliseconds ElasticSearch elasticsearch.node.fs.bytesAvailableJvmInBytes fs.bytesAvailableJVMInBytes ElasticSearch elasticsearch.node.fs.dataRead fs.bytesReadsInBytes ElasticSearch elasticsearch.node.fs.dataWritten fs.writesInBytes ElasticSearch elasticsearch.node.fs.ioOperations fs.iOOperations ElasticSearch elasticsearch.node.fs.readOperations fs.reads ElasticSearch elasticsearch.node.fs.totalSizeInBytes fs.totalSizeInBytes ElasticSearch elasticsearch.node.fs.unallocatedBytes fs.unallocatedBytesInBYtes ElasticSearch elasticsearch.node.fs.writeOperations fs.writeOperations ElasticSearch elasticsearch.node.get.currentRequestsRunning get.currentRequestsRunning ElasticSearch elasticsearch.node.get.requestsDocumentExists get.requestsDocumentExists ElasticSearch elasticsearch.node.get.requestsDocumentExistsInMilliseconds get.requestsDocumentExistsInMilliseconds ElasticSearch elasticsearch.node.get.requestsDocumentMissing get.requestsDocumentMissing ElasticSearch elasticsearch.node.get.requestsDocumentMissingInMilliseconds get.requestsDocumentMissingInMilliseconds ElasticSearch elasticsearch.node.get.timeGetRequestsInMilliseconds get.timeGetRequestsInMilliseconds ElasticSearch elasticsearch.node.get.totalGetRequests get.totalGetRequests ElasticSearch elasticsearch.node.http.currentOpenConnections http.currentOpenConnections ElasticSearch elasticsearch.node.http.openedConnections http.openedConnections ElasticSearch elasticsearch.node.index.indexingOperationsFailed indices.indexingOperationsFailed ElasticSearch elasticsearch.node.index.indexingWaitedThrottlingInMilliseconds indices.indexingWaitedThrottlingInMilliseconds ElasticSearch elasticsearch.node.index.memoryQueryCacheInBytes indices.memoryQueryCacheInBytes ElasticSearch elasticsearch.node.index.numberIndices indices.numberIndices ElasticSearch elasticsearch.node.index.queryCacheEvictions indices.queryCacheEvictions ElasticSearch elasticsearch.node.index.queryCacheHits indices.queryCacheHits ElasticSearch elasticsearch.node.index.queryCacheMisses indices.queryCacheMisses ElasticSearch elasticsearch.node.index.recoveryOngoingShardSource indices.recoveryOngoingShardSource ElasticSearch elasticsearch.node.index.recoveryOngoingShardTarget indices.recoveryOngoingShardTarget ElasticSearch elasticsearch.node.index.recoveryWaitedThrottlingInMilliseconds indices.recoveryWaitedThrottlingInMilliseconds ElasticSearch elasticsearch.node.index.requestCacheEvictions indices.requestCacheEvictions ElasticSearch elasticsearch.node.index.requestCacheHits indices.requestCacheHits ElasticSearch elasticsearch.node.index.requestCacheMemoryInBytes indices.requestCacheMemoryInBytes ElasticSearch elasticsearch.node.index.requestCacheMisses indices.requestCacheMisses ElasticSearch elasticsearch.node.index.segmentsIndexShard indices.segmentsIndexShard ElasticSearch elasticsearch.node.index.segmentsMemoryUsedDocValuesInBytes indices.segmentsMemoryUsedDocValuesInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedFixedBitSetInBytes indices.segmentsMemoryUsedFixedBitSetInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedIndexSegmentsInBytes indices.segmentsMemoryUsedIndexSegmentsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedIndexWriterInBytes indices.segmentsMemoryUsedIndexWriterInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedNormsInBytes indices.segmentsMemoryUsedNormsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedSegmentVersionMapInBytes indices.segmentsMemoryUsedSegmentVersionMapInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedStoredFieldsInBytes indices.segmentsMemoryUsedStoredFieldsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedTermsInBytes indices.segmentsMemoryUsedTermsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedTermVectorsInBytes indices.segmentsMemoryUsedTermVectorsInBytes ElasticSearch elasticsearch.node.index.translogOperations indices.translogOperations ElasticSearch elasticsearch.node.index.translogOperationsInBytes indices.translogOperationsInBytes ElasticSearch elasticsearch.node.indexing.docsCurrentlyDeleted indexing.docsCurrentlyDeleted ElasticSearch elasticsearch.node.indexing.documentsCurrentlyIndexing indexing.documentsCurrentlyIndexing ElasticSearch elasticsearch.node.indexing.documentsIndexed indexing.documentsIndexed ElasticSearch elasticsearch.node.indexing.timeDeletingDocumentsInMilliseconds indexing.timeDeletingDocumentsInMilliseconds ElasticSearch elasticsearch.node.indexing.timeIndexingDocumentsInMilliseconds indexing.timeIndexingDocumentsInMilliseconds ElasticSearch elasticsearch.node.indexing.totalDocumentsDeleted indexing.totalDocumentsDeleted ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsOldGenerationObjects jvm.gc.majorCollectionsOldGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsOldGenerationObjectsInMilliseconds jvm.gc.majorCollectionsOldGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsYoungGenerationObjects jvm.gc.majorCollectionsYoungGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsYoungGenerationObjectsInMilliseconds jvm.gc.majorCollectionsYoungGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.gc.minorCollectionsYoungGenerationObjects jvm.gc.minorCollectionsYoungGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.minorCollectionsYoungGenerationObjectsInMilliseconds jvm.gc.minorCollectionsYoungGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.mem.heapCommittedInBytes jvm.mem.heapCommittedInBytes ElasticSearch elasticsearch.node.jvm.mem.heapMaxInBytes jvm.mem.heapMaxInBytes ElasticSearch elasticsearch.node.jvm.mem.heapUsed jvm.mem.heapUsed ElasticSearch elasticsearch.node.jvm.mem.heapUsedInBytes jvm.mem.heapUsedInBytes ElasticSearch elasticsearch.node.jvm.mem.maxOldGenerationHeapInBytes jvm.mem.maxOldGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.maxSurvivorSpaceInBytes jvm.mem.maxSurvivorSpaceInBYtes ElasticSearch elasticsearch.node.jvm.mem.maxYoungGenerationHeapInBytes jvm.mem.maxYoungGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.nonHeapCommittedInBytes jvm.mem.nonHeapCommittedInBytes ElasticSearch elasticsearch.node.jvm.mem.nonHeapUsedInBytes jvm.mem.nonHeapUsedInBytes ElasticSearch elasticsearch.node.jvm.mem.usedOldGenerationHeapInBytes jvm.mem.usedOldGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.usedSurvivorSpaceInBytes jvm.mem.usedSurvivorSpaceInBytes ElasticSearch elasticsearch.node.jvm.mem.usedYoungGenerationHeapInBytes jvm.mem.usedYoungGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.threadsActive jvm.ThreadsActive ElasticSearch elasticsearch.node.jvm.threadsPeak jvm.ThreadsPeak ElasticSearch elasticsearch.node.merges.currentActive merges.currentActive ElasticSearch elasticsearch.node.merges.docsSegmentMerges merges.docsSegmentMerges ElasticSearch elasticsearch.node.merges.docsSegmentsMerging merges.docsSegmentsMerging ElasticSearch elasticsearch.node.merges.mergedSegmentsInBytes merges.mergedSegmentsInBytes ElasticSearch elasticsearch.node.merges.segmentMerges merges.segmentMerges ElasticSearch elasticsearch.node.merges.sizeSegmentsMergingInBytes merges.sizeSegmentsMergingInBytes ElasticSearch elasticsearch.node.merges.totalSegmentMergingInMilliseconds merges.totalSegmentMergingInMilliseconds ElasticSearch elasticsearch.node.openFd openFD ElasticSearch elasticsearch.node.queriesTotal queriesTotal ElasticSearch elasticsearch.node.refresh.total refresh.total ElasticSearch elasticsearch.node.refresh.totalInMilliseconds refresh.totalInMilliseconds ElasticSearch elasticsearch.node.searchFetchCurrentlyRunning searchFetchCurrentlyRunning ElasticSearch elasticsearch.node.searchFetches searchFetches ElasticSearch elasticsearch.node.sizeStoreInBytes sizeStoreInBytes ElasticSearch elasticsearch.node.threadpool.activeFetchShardStarted threadpool.activeFetchShardStarted ElasticSearch elasticsearch.node.threadpool.bulkActive threadpool.bulkActive ElasticSearch elasticsearch.node.threadpool.bulkQueue threadpool.bulkQueue ElasticSearch elasticsearch.node.threadpool.bulkRejected threadpool.bulkRejected ElasticSearch elasticsearch.node.threadpool.bulkThreads threadpool.bulkThreads ElasticSearch elasticsearch.node.threadpool.fetchShardStartedQueue threadpool.fetchShardStartedQueue ElasticSearch elasticsearch.node.threadpool.fetchShardStartedRejected threadpool.fetchShardStartedRejected ElasticSearch elasticsearch.node.threadpool.fetchShardStartedThreads threadpool.fetchShardStartedThreads ElasticSearch elasticsearch.node.threadpool.fetchShardStoreActive threadpool.fetchShardStoreActive ElasticSearch elasticsearch.node.threadpool.fetchShardStoreQueue threadpool.fetchShardStoreQueue ElasticSearch elasticsearch.node.threadpool.fetchShardStoreRejected threadpool.fetchShardStoreRejected ElasticSearch elasticsearch.node.threadpool.fetchShardStoreThreads threadpool.fetchShardStoreThreads ElasticSearch elasticsearch.node.threadpool.flushActive threadpool.flushActive ElasticSearch elasticsearch.node.threadpool.flushQueue threadpool.flushQueue ElasticSearch elasticsearch.node.threadpool.flushRejected threadpool.flushRejected ElasticSearch elasticsearch.node.threadpool.flushThreads threadpool.flushThreads ElasticSearch elasticsearch.node.threadpool.forceMergeActive threadpool.forceMergeActive ElasticSearch elasticsearch.node.threadpool.forceMergeQueue threadpool.forceMergeQueue ElasticSearch elasticsearch.node.threadpool.forceMergeRejected threadpool.forceMergeRejected ElasticSearch elasticsearch.node.threadpool.forceMergeThreads threadpool.forceMergeThreads ElasticSearch elasticsearch.node.threadpool.genericActive threadpool.genericActive ElasticSearch elasticsearch.node.threadpool.genericQueue threadpool.genericQueue ElasticSearch elasticsearch.node.threadpool.genericRejected threadpool.genericRejected ElasticSearch elasticsearch.node.threadpool.genericThreads threadpool.genericThreads ElasticSearch elasticsearch.node.threadpool.getActive threadpool.getActive ElasticSearch elasticsearch.node.threadpool.getQueue threadpool.getQueue ElasticSearch elasticsearch.node.threadpool.getRejected threadpool.getRejected ElasticSearch elasticsearch.node.threadpool.getThreads threadpool.getThreads ElasticSearch elasticsearch.node.threadpool.indexActive threadpool.indexActive ElasticSearch elasticsearch.node.threadpool.indexQueue threadpool.indexQueue ElasticSearch elasticsearch.node.threadpool.indexRejected threadpool.indexRejected ElasticSearch elasticsearch.node.threadpool.indexThreads threadpool.indexThreads ElasticSearch elasticsearch.node.threadpool.listenerActive threadpool.listenerActive ElasticSearch elasticsearch.node.threadpool.listenerQueue threadpool.listenerQueue ElasticSearch elasticsearch.node.threadpool.listenerRejected threadpool.listenerRejected ElasticSearch elasticsearch.node.threadpool.listenerThreads threadpool.listenerThreads ElasticSearch elasticsearch.node.threadpool.managementActive threadpool.managementActive ElasticSearch elasticsearch.node.threadpool.managementQueue threadpool.managementQueue ElasticSearch elasticsearch.node.threadpool.managementRejected threadpool.managementRejected ElasticSearch elasticsearch.node.threadpool.managementThreads threadpool.managementThreads ElasticSearch elasticsearch.node.threadpool.refreshActive threadpool.refreshActive ElasticSearch elasticsearch.node.threadpool.refreshQueue threadpool.refreshQueue ElasticSearch elasticsearch.node.threadpool.refreshRejected threadpool.refreshRejected ElasticSearch elasticsearch.node.threadpool.refreshThreads threadpool.refreshThreads ElasticSearch elasticsearch.node.threadpool.searchActive threadpool.searchActive ElasticSearch elasticsearch.node.threadpool.searchQueue threadpool.searchQueue ElasticSearch elasticsearch.node.threadpool.searchRejected threadpool.searchRejected ElasticSearch elasticsearch.node.threadpool.searchThreads threadpool.searchThreads ElasticSearch elasticsearch.node.threadpool.snapshotActive threadpool.snapshotActive ElasticSearch elasticsearch.node.threadpool.snapshotQueue threadpool.snapshotQueue ElasticSearch elasticsearch.node.threadpool.snapshotRejected threadpool.snapshotRejected ElasticSearch elasticsearch.node.threadpool.snapshotThreads threadpool.snapshotThreads ElasticSearch elasticsearch.node.transport.connectionsOpened transport.connectionsOpened ElasticSearch elasticsearch.node.transport.packetsReceived transport.packetsReceived ElasticSearch elasticsearch.node.transport.packetsReceivedInBytes transport.packetsReceivedInBytes ElasticSearch elasticsearch.node.transport.packetsSent transport.packetsSent ElasticSearch elasticsearch.node.transport.packetsSentInBytes transport.packetsSentInBytes F5 f5.node.availabilityState node.availabilityState F5 f5.node.connections node.connections F5 f5.node.connectionsPerSecond node.connectionsPerSecond F5 f5.node.enabled node.enabled F5 f5.node.inDataInBytesPerSecond node.inDataInBytesPerSecond F5 f5.node.monitorStatus node.monitorStatus F5 f5.node.outDataInBytesPerSecond node.outDataInBytesPerSecond F5 f5.node.packetsReceivedPerSecond node.packetsReceivedPerSecond F5 f5.node.packetsSentPerSecond node.packetsSentPerSecond F5 f5.node.requestsPerSecond node.requestsPerSecond F5 f5.node.sessions node.sessions F5 f5.node.sessionStatus node.sessionStatus F5 f5.poolMember.availabilityState member.availabilityState F5 f5.poolMember.connections member.connections F5 f5.poolMember.enabled member.enabled F5 f5.poolMember.inDataInBytesPerSecond member.inDataInBytesPerSecond F5 f5.poolMember.monitorStatus member.monitorStatus F5 f5.poolMember.outDataInBytesPerSecond member.outDataInBytesPerSecond F5 f5.poolMember.packetsReceivedPerSecond member.packetsReceivedPerSecond F5 f5.poolMember.packetsSentPerSecond member.packetsSentPerSecond F5 f5.poolMember.requestsPerSecond member.requestsPerSecond F5 f5.poolMember.sessions member.sessions F5 f5.poolMember.sessionStatus member.sessionStatus F5 f5.pool.activeMembers pool.activeMembers F5 f5.pool.availabilityState pool.availabilityState F5 f5.pool.connections pool.connections F5 f5.pool.connqAgeEdm pool.connqAgeEdm F5 f5.pool.connqAgeEma pool.connqAgeEma F5 f5.pool.connqAgeHead pool.connqAgeHead F5 f5.pool.connqAgeMax pool.connqAgeMax F5 f5.pool.connqAllAgeEdm pool.connqAllAgeEdm F5 f5.pool.connqAllAgeEma pool.connqAllAgeEma F5 f5.pool.connqAllAgeHead pool.connqAllAgeHead F5 f5.pool.connqAllAgeMax pool.connqAllAgeMax F5 f5.pool.connqAllDepth pool.connqAllDepth F5 f5.pool.connqDepth pool.connqDepth F5 f5.pool.currentConnections pool.currentConnections F5 f5.pool.enabled pool.enabled F5 f5.pool.inDataInBytesPerSecond pool.inDataInBytesPerSecond F5 f5.pool.minActiveMembers pool.minActiveMembers F5 f5.pool.outDataInBytesPerSecond pool.outDataInBytesPerSecond F5 f5.pool.packetsReceivedPerSecond pool.packetsReceivedPerSecond F5 f5.pool.packetsSentPerSecond pool.packetsSentPerSecond F5 f5.pool.requestsPerSecond pool.requestsPerSecond F5 f5.pool.sessions pool.sessions F5 f5.system.cpuIdleTicksPerSecond system.cpuIdleTicksPerSecond F5 f5.system.cpuIdleUtilization system.cpuIdleUtilization F5 f5.system.cpuInterruptRequestUtilization system.cpuInterruptRequestUtilization F5 f5.system.cpuIoWaitUtilization system.cpuIOWaitUtilization F5 f5.system.cpuNiceLevelUtilization system.cpuNiceLevelUtilization F5 f5.system.cpuSoftInterruptRequestUtilization system.cpuSoftInterruptRequestUtilization F5 f5.system.cpuStolenUtilization system.cpuStolenUtilization F5 f5.system.cpuSystemTicksPerSecond system.cpuSystemTicksPerSecond F5 f5.system.cpuSystemUtilization system.cpuSystemUtilization F5 f5.system.cpuUserTicksPerSecond system.cpuUserTicksPerSecond F5 f5.system.cpuUserUtilization system.cpuUserUtilization F5 f5.system.memoryFreeInBytes system.memoryFreeInBytes F5 f5.system.memoryTotalInBytes system.memoryTotalInBytes F5 f5.system.memoryUsedInBytes system.memoryUsedInBytes F5 f5.system.otherMemoryFreeInBytes system.otherMemoryFreeInBytes F5 f5.system.otherMemoryTotalInBytes system.otherMemoryTotalInBytes F5 f5.system.otherMemoryUsedInBytes system.otherMemoryUsedInBytes F5 f5.system.swapFreeInBytes system.swapFreeInBytes F5 f5.system.swapTotalInBytes system.swapTotalInBytes F5 f5.system.swapUsedInBytes system.swapUsedInBytes F5 f5.system.tmmMemoryFreeInBytes system.tmmMemoryFreeInBytes F5 f5.system.tmmMemoryTotalInBytes system.tmmMemoryTotalInBytes F5 f5.system.tmmMemoryUsedInBytes system.tmmMemoryUsedInBytes F5 f5.virtualserver.availabilityState virtualserver.availabilityState F5 f5.virtualserver.clientsideConnectionsPerSecond virtualserver.clientsideConnectionsPerSecond F5 f5.virtualserver.connections virtualserver.connections F5 f5.virtualserver.csMaxConnDur virtualserver.csMaxConnDur F5 f5.virtualserver.csMeanConnDur virtualserver.csMeanConnDur F5 f5.virtualserver.csMinConnDur virtualserver.csMinConnDur F5 f5.virtualserver.enabled virtualserver.enabled F5 f5.virtualserver.ephemeralBytesInPerSecond virtualserver.ephemeralBytesInPerSecond F5 f5.virtualserver.ephemeralBytesOutPerSecond virtualserver.ephemeralBytesOutPerSecond F5 f5.virtualserver.ephemeralConnectionsPerSecond virtualserver.ephemeralConnectionsPerSecond F5 f5.virtualserver.ephemeralCurrentConnections virtualserver.ephemeralCurrentConnections F5 f5.virtualserver.ephemeralEvictedConnectionsPerSecond virtualserver.ephemeralEvictedConnectionsPerSecond F5 f5.virtualserver.ephemeralMaxConnections virtualserver.ephemeralMaxConnections F5 f5.virtualserver.ephemeralPacketsReceivedPerSecond virtualserver.ephemeralPacketsReceivedPerSecond F5 f5.virtualserver.ephemeralPacketsSentPerSecond virtualserver.ephemeralPacketsSentPerSecond F5 f5.virtualserver.ephemeralSlowKilledPerSecond virtualserver.ephemeralSlowKilledPerSecond F5 f5.virtualserver.evictedConnsPerSecond virtualserver.evictedConnsPerSecond F5 f5.virtualserver.inDataInBytesPerSecond virtualserver.inDataInBytesPerSecond F5 f5.virtualserver.outDataInBytesPerSecond virtualserver.outDataInBytesPerSecond F5 f5.virtualserver.packetsReceivedPerSecond virtualserver.packetsReceivedPerSecond F5 f5.virtualserver.packetsSentPerSecond virtualserver.packetsSentPerSecond F5 f5.virtualserver.requestsPerSecond virtualserver.requestsPerSecond F5 f5.virtualserver.slowKilledPerSecond virtualserver.slowKilledPerSecond F5 f5.virtualserver.usageRatio virtualserver.usageRatio HAProxy haproxy.backend.activeServers backend.activeServers HAProxy haproxy.backend.averageConnectTimeInSeconds backend.averageConnectTimeInSeconds HAProxy haproxy.backend.averageQueueTimeInSeconds backend.averageQueueTimeInSeconds HAProxy haproxy.backend.averageResponseTimeInSeconds backend.averageResponseTimeInSeconds HAProxy haproxy.backend.averageTotalSessionTimeInSeconds backend.averageTotalSessionTimeInSeconds HAProxy haproxy.backend.backupServers backend.backupServers HAProxy haproxy.backend.bytesInPerSecond backend.bytesInPerSecond HAProxy haproxy.backend.bytesOutPerSecond backend.bytesOutPerSecond HAProxy haproxy.backend.bytesThatBypassedCompressorPerSecond backend.bytesThatBypassedCompressorPerSecond HAProxy haproxy.backend.connectingRequestErrorsPerSecond backend.connectingRequestErrorsPerSecond HAProxy haproxy.backend.connectionRetriesPerSecond backend.connectionRetriesPerSecond HAProxy haproxy.backend.currentQueuedRequestsWithoutServer backend.currentQueuedRequestsWithoutServer HAProxy haproxy.backend.currentSessions backend.currentSessions HAProxy haproxy.backend.dataTransfersAbortedByClientPerSecond backend.dataTransfersAbortedByClientPerSecond HAProxy haproxy.backend.dataTransfersAbortedByServerPerSecond backend.dataTransfersAbortedByServerPerSecond HAProxy haproxy.backend.downtimeInSeconds backend.downtimeInSeconds HAProxy haproxy.backend.http100ResponsesPerSecond backend.http100ResponsesPerSecond HAProxy haproxy.backend.http200ResponsesPerSecond backend.http200ResponsesPerSecond HAProxy haproxy.backend.http300ResponsesPerSecond backend.http300ResponsesPerSecond HAProxy haproxy.backend.http400ResponsesPerSecond backend.http400ResponsesPerSecond HAProxy haproxy.backend.http500ResponsesPerSecond backend.http500ResponsesPerSecond HAProxy haproxy.backend.httpOtherResponsesPerSecond backend.httpOtherResponsesPerSecond HAProxy haproxy.backend.httpRequestsPerSecond backend.httpRequestsPerSecond HAProxy haproxy.backend.httpResponseBytesEmittedByCompressorPerSecond backend.httpResponseBytesEmittedByCompressorPerSecond HAProxy haproxy.backend.httpResponseBytesFedToCompressorPerSecond backend.httpResponseBytesFedToCompressorPerSecond HAProxy haproxy.backend.httpResponsesCompressedPerSecond backend.httpResponsesCompressedPerSecond HAProxy haproxy.backend.interceptedRequestsPerSecond backend.interceptedRequestsPerSecond HAProxy haproxy.backend.maxQueuedRequestsWithoutServer backend.maxQueuedRequestsWithoutServer HAProxy haproxy.backend.maxSessions backend.maxSessions HAProxy haproxy.backend.maxSessionsPerSecond backend.maxSessionsPerSecond HAProxy haproxy.backend.requestRedispatchPerSecond backend.requestRedispatchPerSecond HAProxy haproxy.backend.requestsDenied.securityConcernsPerSecond backend.requestsDenied.securityConcernsPerSecond HAProxy haproxy.backend.responseErrorsPerSecond backend.responseErrorsPerSecond HAProxy haproxy.backend.responsesDenied.securityConcernsPerSecond backend.responsesDenied.securityConcernsPerSecond HAProxy haproxy.backend.serverSelectedPerSecond backend.serverSelectedPerSecond HAProxy haproxy.backend.sessionsPerSecond backend.sessionsPerSecond HAProxy haproxy.backend.timeSinceLastSessionAssignedInSeconds backend.timeSinceLastSessionAssignedInSeconds HAProxy haproxy.backend.timeSinceLastUpDownTransitionInSeconds backend.timeSinceLastUpDownTransitionInSeconds HAProxy haproxy.backend.totalWeight backend.totalWeight HAProxy haproxy.backend.type backend.type HAProxy haproxy.backend.upToDownTransitionsPerSecond backend.upToDownTransitionsPerSecond HAProxy haproxy.frontend.bytesInPerSecond frontend.bytesInPerSecond HAProxy haproxy.frontend.bytesOutPerSecond frontend.bytesOutPerSecond HAProxy haproxy.frontend.connectionsPerSecond frontend.connectionsPerSecond HAProxy haproxy.frontend.currentSessions frontend.currentSessions HAProxy haproxy.frontend.http100ResponsesPerSecond frontend.http100ResponsesPerSecond HAProxy haproxy.frontend.http200ResponsesPerSecond frontend.http200ResponsesPerSecond HAProxy haproxy.frontend.http300ResponsesPerSecond frontend.http300ResponsesPerSecond HAProxy haproxy.frontend.http400ResponsesPerSecond frontend.http400ResponsesPerSecond HAProxy haproxy.frontend.http500ResponsesPerSecond frontend.http500ResponsesPerSecond HAProxy haproxy.frontend.httpOtherResponsesPerSecond frontend.httpOtherResponsesPerSecond HAProxy haproxy.frontend.httpRequests.maxPerSecond frontend.httpRequests.maxPerSecond HAProxy haproxy.frontend.httpRequestsPerSecond frontend.httpRequestsPerSecond HAProxy haproxy.frontend.interceptedRequestsPerSecond frontend.interceptedRequestsPerSecond HAProxy haproxy.frontend.maxConnectionsPerSecond frontend.maxConnectionsPerSecond HAProxy haproxy.frontend.maxSessions frontend.maxSessions HAProxy haproxy.frontend.maxSessionsPerSecond frontend.maxSessionsPerSecond HAProxy haproxy.frontend.requestErrorsPerSecond frontend.requestErrorsPerSecond HAProxy haproxy.frontend.requestsDenied.securityConcernsPerSecond frontend.requestsDenied.securityConcernsPerSecond HAProxy haproxy.frontend.requestsDenied.tcpRequestConnectionRulesPerSecond frontend.requestsDenied.tcpRequestConnectionRulesPerSecond HAProxy haproxy.frontend.requestsDenied.tcpRequestSessionRulesPerSecond frontend.requestsDenied.tcpRequestSessionRulesPerSecond HAProxy haproxy.frontend.responsesDenied.securityConcernsPerSecond frontend.responsesDenied.securityConcernsPerSecond HAProxy haproxy.frontend.sessionsPerSecond frontend.sessionsPerSecond HAProxy haproxy.server.averageConnectTimeInSeconds server.averageConnectTimeInSeconds HAProxy haproxy.server.averageQueueTimeInSeconds server.averageQueueTimeInSeconds HAProxy haproxy.server.averageResponseTimeInSeconds server.averageResponseTimeInSeconds HAProxy haproxy.server.averageTotalSessionTimeInSeconds server.averageTotalSessionTimeInSeconds HAProxy haproxy.server.bytesInPerSecond server.bytesInPerSecond HAProxy haproxy.server.bytesOutPerSecond server.bytesOutPerSecond HAProxy haproxy.server.connectingRequestErrorsPerSecond server.connectingRequestErrorsPerSecond HAProxy haproxy.server.connectionRetriesPerSecond server.connectionRetriesPerSecond HAProxy haproxy.server.currentQueuedRequestsWithoutServer server.currentQueuedRequestsWithoutServer HAProxy haproxy.server.currentSessions server.currentSessions HAProxy haproxy.server.dataTransfersAbortedByClientPerSecond server.dataTransfersAbortedByClientPerSecond HAProxy haproxy.server.dataTransfersAbortedByServerPerSecond server.dataTransfersAbortedByServerPerSecond HAProxy haproxy.server.downtimeInSeconds server.downtimeInSeconds HAProxy haproxy.server.failedChecksPerSecond server.failedChecksPerSecond HAProxy haproxy.server.healthCheckDurationInMilliseconds server.healthCheckDurationInMilliseconds HAProxy haproxy.server.http100ResponsesPerSecond server.http100ResponsesPerSecond HAProxy haproxy.server.http200ResponsesPerSecond server.http200ResponsesPerSecond HAProxy haproxy.server.http300ResponsesPerSecond server.http300ResponsesPerSecond HAProxy haproxy.server.http400ResponsesPerSecond server.http400ResponsesPerSecond HAProxy haproxy.server.http500ResponsesPerSecond server.http500ResponsesPerSecond HAProxy haproxy.server.httpOtherResponsesPerSecond server.httpOtherResponsesPerSecond HAProxy haproxy.server.isActive server.isActive HAProxy haproxy.server.isBackup server.isBackup HAProxy haproxy.server.maxQueuedRequestsWithoutServer server.maxQueuedRequestsWithoutServer HAProxy haproxy.server.maxSessions server.maxSessions HAProxy haproxy.server.maxSessionsPerSecond server.maxSessionsPerSecond HAProxy haproxy.server.requestRedispatchPerSecond server.requestRedispatchPerSecond HAProxy haproxy.server.requestsDenied.securityConcernsPerSecond server.requestsDenied.securityConcernsPerSecond HAProxy haproxy.server.responseErrorsPerSecond server.responseErrorsPerSecond HAProxy haproxy.server.responsesDenied.securityConcernsPerSecond server.responsesDenied.securityConcernsPerSecond HAProxy haproxy.server.serverSelectedPerSecond server.serverSelectedPerSecond HAProxy haproxy.server.serverWeight server.serverWeight HAProxy haproxy.server.sessionsPerSecond server.sessionsPerSecond HAProxy haproxy.server.throttlePercentage server.throttlePercentage HAProxy haproxy.server.timeSinceLastSessionAssignedInSeconds server.timeSinceLastSessionAssignedInSeconds HAProxy haproxy.server.timeSinceLastUpDownTransitionInSeconds server.timeSinceLastUpDownTransitionInSeconds HAProxy haproxy.server.type server.type HAProxy haproxy.server.upToDownTransitionsPerSecond server.upToDownTransitionsPerSecond Kafka kafka.broker.bytesWrittenToTopicPerSecond broker.bytesWrittenToTopicPerSecond Kafka kafka.broker.consumer.requestsExpiredPerSecond consumer.requestsExpiredPerSecond Kafka kafka.broker.follower.requestExpirationPerSecond follower.requestExpirationPerSecond Kafka kafka.broker.ioInPerSecond broker.IOInPerSecond Kafka kafka.broker.ioOutPerSecond broker.IOOutPerSecond Kafka kafka.broker.logFlushPerSecond broker.logFlushPerSecond Kafka kafka.broker.messagesInPerSecond broker.messagesInPerSecond Kafka kafka.broker.net.bytesRejectedPerSecond net.bytesRejectedPerSecond Kafka kafka.broker.replication.isrExpandsPerSecond replication.isrExpandsPerSecond Kafka kafka.broker.replication.isrShrinksPerSecond replication.isrShrinksPerSecond Kafka kafka.broker.replication.leaderElectionPerSecond replication.leaderElectionPerSecond Kafka kafka.broker.replication.uncleanLeaderElectionPerSecond replication.uncleanLeaderElectionPerSecond Kafka kafka.broker.replication.unreplicatedPartitions replication.unreplicatedPartitions Kafka kafka.broker.request.avgTimeFetch request.avgTimeFetch Kafka kafka.broker.request.avgTimeMetadata request.avgTimeMetadata Kafka kafka.broker.request.avgTimeMetadata99Percentile request.avgTimeMetadata99Percentile Kafka kafka.broker.request.avgTimeOffset request.avgTimeOffset Kafka kafka.broker.request.avgTimeOffset99Percentile request.avgTimeOffset99Percentile Kafka kafka.broker.request.avgTimeProduceRequest request.avgTimeProduceRequest Kafka kafka.broker.request.avgTimeUpdateMetadata request.avgTimeUpdateMetadata Kafka kafka.broker.request.avgTimeUpdateMetadata99Percentile request.avgTimeUpdateMetadata99Percentile Kafka kafka.broker.request.clientFetchesFailedPerSecond request.clientFetchesFailedPerSecond Kafka kafka.broker.request.fetchConsumerRequestsPerSecond request.fetchConsumerRequestsPerSecond Kafka kafka.broker.request.fetchFollowerRequestsPerSecond request.fetchFollowerRequestsPerSecond Kafka kafka.broker.request.fetchTime99Percentile request.fetchTime99Percentile Kafka kafka.broker.request.handlerIdle request.handlerIdle Kafka kafka.broker.request.listGroupsRequestsPerSecond request.listGroupsRequestsPerSecond Kafka kafka.broker.request.metadataRequestsPerSecond request.metadataRequestsPerSecond Kafka kafka.broker.request.offsetCommitRequestsPerSecond request.offsetCommitRequestsPerSecond Kafka kafka.broker.request.produceRequestsFailedPerSecond request.produceRequestsFailedPerSecond Kafka kafka.broker.request.produceRequestsPerSecond request.produceRequestsPerSecond Kafka kafka.broker.request.produceTime99Percentile request.produceTime99Percentile Kafka kafka.broker.topic.diskSize topic.diskSize Kafka kafka.topic.bytesInPerSec topic.BytesInPerSec Kafka kafka.topic.bytesOutPerSec topic.BytesOutPerSec Kafka kafka.topic.messagesInPerSec topic.MessagesInPerSec Kafka kafka.topic.partitionsWithNonPreferredLeader topic.partitionsWithNonPreferredLeader Kafka kafka.topic.respondsToMetadataRequests topic.respondsToMetadataRequests Kafka kafka.topic.retentionBytesOrTime topic.retentionBytesOrTime Kafka kafka.topic.underReplicatedPartitions topic.underReplicatedPartitions Kafka kafka.producer.ageMetadataUsedInMilliseconds producer.ageMetadataUsedInMilliseconds Kafka kafka.producer.availableBufferInBytes producer.availableBufferInBytes Kafka kafka.producer.avgBytesSentPerRequestInBytes producer.avgBytesSentPerRequestInBytes Kafka kafka.producer.avgCompressionRateRecordBatches producer.avgCompressionRateRecordBatches Kafka kafka.producer.avgRecordAccumulatorsInMilliseconds producer.avgRecordAccumulatorsInMilliseconds Kafka kafka.producer.avgRecordSizeInBytes producer.avgRecordSizeInBytes Kafka kafka.producer.avgRecordsSentPerSecond producer.avgRecordsSentPerSecond Kafka kafka.producer.avgRecordsSentPerTopicPerSecond producer.avgRecordsSentPerTopicPerSecond Kafka kafka.producer.avgRequestLatency producer.avgRequestLatencyPerSecond Kafka kafka.producer.avgThrottleTime producer.avgThrottleTime Kafka kafka.producer.bufferMemoryAvailableInBytes producer.bufferMemoryAvailableInBytes Kafka kafka.producer.bufferpoolWaitTime producer.bufferpoolWaitTime Kafka kafka.producer.bytesOutPerSecond producer.bytesOutPerSecond Kafka kafka.producer.compressionRateRecordBatches producer.compressionRateRecordBatches Kafka kafka.producer.ioWaitTime producer.ioWaitTime Kafka kafka.producer.maxBytesSentPerRequestInBytes producer.maxBytesSentPerRequestInBytes Kafka kafka.producer.maxRecordSizeInBytes producer.maxRecordSizeInBytes Kafka kafka.producer.maxRequestLatencyInMilliseconds producer.maxRequestLatencyInMilliseconds Kafka kafka.producer.maxThrottleTime producer.maxThrottleTime Kafka kafka.producer.requestPerSecond producer.requestPerSecond Kafka kafka.producer.requestsWaitingResponse producer.requestsWaitingResponse Kafka kafka.producer.responsePerSecond producer.responsePerSecond Kafka kafka.producer.threadsWaiting producer.threadsWaiting Kafka kafka.consumer.avgFetchSizeInBytes consumer.avgFetchSizeInBytes Kafka kafka.consumer.avgRecordConsumedPerTopic consumer.avgRecordConsumedPerTopic Kafka kafka.consumer.avgRecordConsumedPerTopicPerSecond consumer.avgRecordConsumedPerTopicPerSecond Kafka kafka.consumer.bytesInPerSecond consumer.bytesInPerSecond Kafka kafka.consumer.fetchPerSecond consumer.fetchPerSecond Kafka kafka.consumer.hwm consumer.hwm Kafka kafka.consumer.lag consumer.lag Kafka kafka.consumer.maxFetchSizeInBytes consumer.maxFetchSizeInBytes Kafka kafka.consumer.maxLag consumer.maxLag Kafka kafka.consumer.messageConsumptionPerSecond consumer.messageConsumptionPerSecond Kafka kafka.consumer.offset consumer.offset Kafka kafka.consumer.totalLag consumer.totalLag Kafka kafka.consumerGroup.maxLag consumerGroup.maxLag Kafka kafka.consumerGroup.totalLag consumerGroup.totalLag Kubernetes k8s.apiserver.goGoroutines goGoroutines Kubernetes k8s.apiserver.goThreads goThreads Kubernetes k8s.apiserver.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.apiserver.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.controllermanager.goGoroutines goGoroutines Kubernetes k8s.controllermanager.goThreads goThreads Kubernetes k8s.controllermanager.leaderElectionMasterStatus leaderElectionMasterStatus Kubernetes k8s.controllermanager.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.controllermanager.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.etcd.goGoroutines goGoroutines Kubernetes k8s.etcd.goThreads goThreads Kubernetes k8s.etcd.mvccDbTotalSizeInBytes etcdMvccDbTotalSizeInBytes Kubernetes k8s.etcd.networkClientGrpcReceivedBytesRate etcdNetworkClientGrpcReceivedBytesRate Kubernetes k8s.etcd.networkClientGrpcSentBytesRate etcdNetworkClientGrpcSentBytesRate Kubernetes k8s.etcd.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.etcd.process.maxFds processMaxFds Kubernetes k8s.etcd.process.openFds processOpenFds Kubernetes k8s.etcd.process.processFdsUtilization processFdsUtilization Kubernetes k8s.etcd.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.etcd.serverHasLeader etcdServerHasLeader Kubernetes k8s.etcd.serverLeaderChangesSeenDelta etcdServerLeaderChangesSeenDelta Kubernetes k8s.etcd.serverProposalsAppliedDelta etcdServerProposalsAppliedDelta Kubernetes k8s.etcd.serverProposalsAppliedRate etcdServerProposalsAppliedRate Kubernetes k8s.etcd.serverProposalsCommittedDelta etcdServerProposalsCommittedDelta Kubernetes k8s.etcd.serverProposalsCommittedRate etcdServerProposalsCommittedRate Kubernetes k8s.etcd.serverProposalsFailedDelta etcdServerProposalsFailedDelta Kubernetes k8s.etcd.serverProposalsFailedRate etcdServerProposalsFailedRate Kubernetes k8s.etcd.serverProposalsPending etcdServerProposalsPending Kubernetes k8s.scheduler.goGoroutines goGoroutines Kubernetes k8s.scheduler.goThreads goThreads Kubernetes k8s.scheduler.leaderElectionMasterStatus leaderElectionMasterStatus Kubernetes k8s.scheduler.podPreemptionVictims schedulerPodPreemptionVictims Kubernetes k8s.scheduler.preemptionAttemptsDelta schedulerPreemptionAttemptsDelta Kubernetes k8s.scheduler.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.scheduler.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.container.cpuCfsPeriodsDelta containerCpuCfsPeriodsDelta Kubernetes k8s.container.cpuCfsPeriodsTotal containerCpuCfsPeriodsTotal Kubernetes k8s.container.cpuCfsThrottledPeriodsDelta containerCpuCfsThrottledPeriodsDelta Kubernetes k8s.container.cpuCfsThrottledPeriodsTotal containerCpuCfsThrottledPeriodsTotal Kubernetes k8s.container.cpuCfsThrottledSecondsDelta containerCpuCfsThrottledSecondsDelta Kubernetes k8s.container.cpuCfsThrottledSecondsTotal containerCpuCfsThrottledSecondsTotal Kubernetes k8s.container.cpuCoresUtilization cpuCoresUtilization Kubernetes k8s.container.cpuLimitCores cpuLimitCores Kubernetes k8s.container.cpuRequestedCores cpuRequestedCores Kubernetes k8s.container.cpuUsedCores cpuUsedCores Kubernetes k8s.container.fsAvailableBytes fsAvailableBytes Kubernetes k8s.container.fsCapacityBytes fsCapacityBytes Kubernetes k8s.container.fsInodes fsInodes Kubernetes k8s.container.fsInodesFree fsInodesFree Kubernetes k8s.container.fsInodesUsed fsInodesUsed Kubernetes k8s.container.fsUsedBytes fsUsedBytes Kubernetes k8s.container.fsUsedPercent fsUsedPercent Kubernetes k8s.container.isReady isReady Kubernetes k8s.container.memoryLimitBytes memoryLimitBytes Kubernetes k8s.container.memoryMappedFileBytes containerMemoryMappedFileBytes Kubernetes k8s.container.memoryRequestedBytes memoryRequestedBytes Kubernetes k8s.container.memoryUsedBytes memoryUsedBytes Kubernetes k8s.container.memoryUtilization memoryUtilization Kubernetes k8s.container.memoryWorkingSetBytes memoryWorkingSetBytes Kubernetes k8s.container.requestedCpuCoresUtilization requestedCpuCoresUtilization Kubernetes k8s.container.requestedMemoryUtilization requestedMemoryUtilization Kubernetes k8s.container.restartCount restartCount Kubernetes k8s.daemonset.createdAt createdAt Kubernetes k8s.daemonset.metadataGeneration metadataGeneration Kubernetes k8s.daemonset.podsAvailable podsAvailable Kubernetes k8s.daemonset.podsDesired podsDesired Kubernetes k8s.daemonset.podsMisscheduled podsMisscheduled Kubernetes k8s.daemonset.podsReady podsReady Kubernetes k8s.daemonset.podsScheduled podsScheduled Kubernetes k8s.daemonset.podsUnavailable podsUnavailable Kubernetes k8s.daemonset.podsUpdatedScheduled podsUpdatedScheduled Kubernetes k8s.deployment.createdAt createdAt Kubernetes k8s.deployment.podsAvailable podsAvailable Kubernetes k8s.deployment.podsDesired podsDesired Kubernetes k8s.deployment.podsMaxUnavailable podsMaxUnavailable Kubernetes k8s.deployment.podsTotal podsTotal Kubernetes k8s.deployment.podsUnavailable podsUnavailable Kubernetes k8s.deployment.podsUpdated podsUpdated Kubernetes k8s.endpoint.addressAvailable addressAvailable Kubernetes k8s.endpoint.addressNotReady addressNotReady Kubernetes k8s.endpoint.createdAt createdAt Kubernetes k8s.namespace.createdAt createdAt Kubernetes k8s.node.allocatableAttachableVolumes* allocatableAttachableVolumes* Kubernetes k8s.node.allocatableCpuCores allocatableCpuCores Kubernetes k8s.node.allocatableCpuCoresUtilization allocatableCpuCoresUtilization Kubernetes k8s.node.allocatableEphemeralStorageBytes allocatableEphemeralStorageBytes Kubernetes k8s.node.allocatableHugepages* allocatableHugepages* Kubernetes k8s.node.allocatableMemoryBytes allocatableMemoryBytes Kubernetes k8s.node.allocatableMemoryUtilization allocatableMemoryUtilization Kubernetes k8s.node.allocatablePods allocatablePods Kubernetes k8s.node.capacityAttachableVolumes* capacityAttachableVolumes* Kubernetes k8s.node.capacityCpuCores capacityCpuCores Kubernetes k8s.node.capacityEphemeralStorageBytes capacityEphemeralStorageBytes Kubernetes k8s.node.capacityHugepages* capacityHugepages* Kubernetes k8s.node.capacityMemoryBytes capacityMemoryBytes Kubernetes k8s.node.capacityPods capacityPods Kubernetes k8s.node.cpuUsedCoreMilliseconds cpuUsedCoreMilliseconds Kubernetes k8s.node.cpuUsedCores cpuUsedCores Kubernetes k8s.node.fsAvailableBytes fsAvailableBytes Kubernetes k8s.node.fsCapacityBytes fsCapacityBytes Kubernetes k8s.node.fsCapacityUtilization fsCapacityUtilization Kubernetes k8s.node.fsInodes fsInodes Kubernetes k8s.node.fsInodesFree fsInodesFree Kubernetes k8s.node.fsInodesUsed fsInodesUsed Kubernetes k8s.node.fsUsedBytes fsUsedBytes Kubernetes k8s.node.memoryAvailableBytes memoryAvailableBytes Kubernetes k8s.node.memoryMajorPageFaultsPerSecond memoryMajorPageFaultsPerSecond Kubernetes k8s.node.memoryPageFaults memoryPageFaults Kubernetes k8s.node.memoryRssBytes memoryRssBytes Kubernetes k8s.node.memoryUsedBytes memoryUsedBytes Kubernetes k8s.node.memoryWorkingSetBytes memoryWorkingSetBytes Kubernetes k8s.node.netErrorsPerSecond net.errorsPerSecond Kubernetes k8s.node.netRxBytesPerSecond net.rxBytesPerSecond Kubernetes k8s.node.netTxBytesPerSecond net.txBytesPerSecond Kubernetes k8s.node.runtimeAvailableBytes runtimeAvailableBytes Kubernetes k8s.node.runtimeCapacityBytes runtimeCapacityBytes Kubernetes k8s.node.runtimeInodes runtimeInodes Kubernetes k8s.node.runtimeInodesFree runtimeInodesFree Kubernetes k8s.node.runtimeInodesUsed runtimeInodesUsed Kubernetes k8s.node.runtimeUsedBytes runtimeUsedBytes Kubernetes k8s.pod.createdAt createdAt Kubernetes k8s.pod.isReady isReady Kubernetes k8s.pod.isScheduled isScheduled Kubernetes k8s.pod.netErrorsPerSecond net.errorsPerSecond Kubernetes k8s.pod.netRxBytesPerSecond net.rxBytesPerSecond Kubernetes k8s.pod.netTxBytesPerSecond net.txBytesPerSecond Kubernetes k8s.pod.startTime startTime Kubernetes k8s.replicaset.createdAt createdAt Kubernetes k8s.replicaset.observedGeneration observedGeneration Kubernetes k8s.replicaset.podsDesired podsDesired Kubernetes k8s.replicaset.podsFullyLabeled podsFullyLabeled Kubernetes k8s.replicaset.podsMissing podsMissing Kubernetes k8s.replicaset.podsReady podsReady Kubernetes k8s.replicaset.podsTotal podsTotal Kubernetes k8s.service.createdAt createdAt Kubernetes k8s.statefulset.createdAt createdAt Kubernetes k8s.statefulset.currentRevision currentRevision Kubernetes k8s.statefulset.metadataGeneration metadataGeneration Kubernetes k8s.statefulset.observedGeneration observedGeneration Kubernetes k8s.statefulset.podsCurrent podsCurrent Kubernetes k8s.statefulset.podsDesired podsDesired Kubernetes k8s.statefulset.podsReady podsReady Kubernetes k8s.statefulset.podsTotal podsTotal Kubernetes k8s.statefulset.podsUpdated podsUpdated Kubernetes k8s.statefulset.updateRevision updateRevision Kubernetes k8s.volume.fsAvailableBytes fsAvailableBytes Kubernetes k8s.volume.fsCapacityBytes fsCapacityBytes Kubernetes k8s.volume.fsInodes fsInodes Kubernetes k8s.volume.fsInodesFree fsInodesFree Kubernetes k8s.volume.fsInodesUsed fsInodesUsed Kubernetes k8s.volume.fsUsedBytes fsUsedBytes Kubernetes k8s.volume.fsUsedPercent fsUsedPercent Memcached memcached.server.activeSlabs activeSlabs Memcached memcached.server.avgItemSizeInBytes avgItemSizeInBytes Memcached memcached.server.bytesReadServerPerSecond bytesReadServerPerSecond Memcached memcached.server.bytesUsedServerInBytes bytesUsedServerInBytes Memcached memcached.server.bytesWrittenServerPerSecond bytesWrittenServerPerSecond Memcached memcached.server.casHitRatePerSecond casHitRatePerSecond Memcached memcached.server.casMissRatePerSecond casMissRatePerSecond Memcached memcached.server.casWrongRatePerSecond casWrongRatePerSecond Memcached memcached.server.cmdFlushRatePerSecond cmdFlushRatePerSecond Memcached memcached.server.cmdGetRatePerSecond cmdGetRatePerSecond Memcached memcached.server.cmdSetRatePerSecond cmdSetRatePerSecond Memcached memcached.server.connectionRateServerPerSecond connectionRateServerPerSecond Memcached memcached.server.connectionStructuresAllocated connectionStructuresAllocated Memcached memcached.server.currentItemsStoredServer currentItemsStoredServer Memcached memcached.server.deleteCmdNoneRemovedPerSecond deleteCmdNoneRemovedPerSecond Memcached memcached.server.deleteCmdRemovedPerSecond deleteCmdRemovedPerSecond Memcached memcached.server.evictionsPerSecond evictionsPerSecond Memcached memcached.server.getHitPercent getHitPercent Memcached memcached.server.getHitPerSecond getHitPerSecond Memcached memcached.server.getMissPerSecond getMissPerSecond Memcached memcached.server.itemsStoredPerSecond itemsStoredPerSecond Memcached memcached.server.limitBytesStorage limitBytesStorage Memcached memcached.server.limitMaxBytes limitMaxBytes Memcached memcached.server.maxConnectionLimitPerSecond serverMaxConnectionLimitPerSecond Memcached memcached.server.memAllocatedSlabsInBytes memAllocatedSlabsInBytes Memcached memcached.server.openConnectionsServer openConnectionsServer Memcached memcached.server.pointerSize pointerSize Memcached memcached.server.rusageSystem usageRate Memcached memcached.server.rusageUser executionTime Memcached memcached.server.storingItemsPercentMemory storingItemsPercentMemory Memcached memcached.server.threads threads Memcached memcached.server.uptimeInMilliseconds uptimeInMilliseconds Memcached memcached.slab.activeItemsBumpedPerSecond activeItemsBumpedPerSecond Memcached memcached.slab.casBadValPerSecond casBadValPerSecond Memcached memcached.slab.casModifiedSlabPerSecond casModifiedSlabPerSecond Memcached memcached.slab.chunkSizeInBytes chunkSizeInBytes Memcached memcached.slab.chunksPerPage chunksPerPage Memcached memcached.slab.cmdSetRateSlabPerSecond cmdSetRateSlabPerSecond Memcached memcached.slab.decrsModifySlabPerSecond decrsModifySlabPerSecond Memcached memcached.slab.deleteRateSlabPerSecond deleteRateSlabPerSecond Memcached memcached.slab.entriesReclaimedPerSecond entriesReclaimedPerSecond Memcached memcached.slab.evictionsBeforeExpirationPerSecond evictionsBeforeExpirationPerSecond Memcached memcached.slab.evictionsBeforeExplicitExpirationPerSecond evictionsBeforeExplicitExpirationPerSecond Memcached memcached.slab.expiredItemsReclaimedPerSecond expiredItemsReclaimedPerSecond Memcached memcached.slab.freedChunks freedChunks Memcached memcached.slab.freedChunksEnd freedChunksEnd Memcached memcached.slab.getHitRateSlabPerSecond getHitRateSlabPerSecond Memcached memcached.slab.incrsModifySlabPerSecond incrsModifySlabPerSecond Memcached memcached.slab.itemsCold itemsCold Memcached memcached.slab.itemsColdPerSecond itemsColdPerSecond Memcached memcached.slab.itemsDirectReclaimedPerSecond itemsDirectReclaimedPerSecond Memcached memcached.slab.itemsFreedCrawlerPerSecond itemsFreedCrawlerPerSecond Memcached memcached.slab.itemsHot itemsHot Memcached memcached.slab.itemsOldestInMilliseconds itemsOldestInMilliseconds Memcached memcached.slab.itemsRefcountLockedPerSecond itemsRefcountLockedPerSecond Memcached memcached.slab.itemsSlabClass itemsSlabClass Memcached memcached.slab.itemsTimeSinceEvictionInMilliseconds itemsTimeSinceEvictionInMilliseconds Memcached memcached.slab.itemsWarm itemsWarm Memcached memcached.slab.itemsWarmPerSecond itemsWarmPerSecond Memcached memcached.slab.memRequestedSlabInBytesPerSecond memRequestedSlabInBytesPerSecond Memcached memcached.slab.outOfMemoryPerSecond outOfMemoryPerSecond Memcached memcached.slab.selfHealedSlabPerSecond selfHealedSlabPerSecond Memcached memcached.slab.totalChunksSlab totalChunksSlab Memcached memcached.slab.totalPagesSlab totalPagesSlab Memcached memcached.slab.touchHitSlabPerSecond touchHitSlabPerSecond Memcached memcached.slab.usedChunksItems usedChunksItems Memcached memcached.slab.usedChunksPerSecond usedChunksPerSecond Memcached memcached.slab.validItemsEvictedPerSecond validItemsEvictedPerSecond MongoDB mongo.index.accesses collection.indexAccesses MongoDB mongo.index.sizeInBytes collection.indexSizeInBytes MongoDB mongo.collection.avgObjSizeInBytes collection.avgObjSizeInBytes MongoDB mongo.collection.capped collection.capped MongoDB mongo.collection.count collection.count MongoDB mongo.collection.max collection.max MongoDB mongo.collection.maxSizeInBytes collection.maxSizeInBytes MongoDB mongo.collection.nindexes collection.nindexes MongoDB mongo.collection.sizeInBytes collection.sizeInBytes MongoDB mongo.collection.storageSizeInBytes collection.storageSizeInBytes MongoDB mongo.configServer.asserts.messagesPerSecond asserts.messagesPerSecond MongoDB mongo.configServer.asserts.regularPerSecond asserts.regularPerSecond MongoDB mongo.configServer.asserts.rolloversPerSecond asserts.rolloversPerSecond MongoDB mongo.configServer.asserts.userPerSecond asserts.userPerSecond MongoDB mongo.configServer.asserts.warningPerSecond asserts.warningPerSecond MongoDB mongo.configServer.commands.countFailedPerSecond commands.countFailedPerSecond MongoDB mongo.configServer.commands.countPerSecond commands.countPerSecond MongoDB mongo.configServer.commands.createIndexesFailedPerSecond commands.createIndexesFailedPerSecond MongoDB mongo.configServer.commands.createIndexesPerSecond commands.createIndexesPerSecond MongoDB mongo.configServer.commands.deleteFailedPerSecond commands.deleteFailedPerSecond MongoDB mongo.configServer.commands.deletePerSecond commands.deletePerSecond MongoDB mongo.configServer.commands.evalFailedPerSecond commands.evalFailedPerSecond MongoDB mongo.configServer.commands.evalPerSecond commands.evalPerSecond MongoDB mongo.configServer.commands.findAndModifyFailedPerSecond commands.findAndModifyFailedPerSecond MongoDB mongo.configServer.commands.findAndModifyPerSecond commands.findAndModifyPerSecond MongoDB mongo.configServer.commands.insertFailedPerSecond commands.insertFailedPerSecond MongoDB mongo.configServer.commands.insertPerSecond commands.insertPerSecond MongoDB mongo.configServer.commands.updateFailedPerSecond commands.updateFailedPerSecond MongoDB mongo.configServer.commands.updatePerSecond commands.updatePerSecond MongoDB mongo.configServer.connections.available connections.available MongoDB mongo.configServer.connections.current connections.current MongoDB mongo.configServer.connections.totalCreated connections.totalCreated MongoDB mongo.configServer.cursor.openNoTimeout cursor.openNoTimeout MongoDB mongo.configServer.cursor.openPinned cursor.openPinned MongoDB mongo.configServer.cursor.openTotal cursor.openTotal MongoDB mongo.configServer.cursor.timedOutPerSecond cursor.timedOutPerSecond MongoDB mongo.configServer.document.deletedPerSecond document.deletedPerSecond MongoDB mongo.configServer.document.insertedPerSecond document.insertedPerSecond MongoDB mongo.configServer.document.returnedPerSecond document.returnedPerSecond MongoDB mongo.configServer.document.updatedPerSecond document.updatedPerSecond MongoDB mongo.configServer.dur.commits dur.commits MongoDB mongo.configServer.dur.commitsInWriteLock dur.commitsInWriteLock MongoDB mongo.configServer.dur.compression dur.compression MongoDB mongo.configServer.dur.earlyCommits dur.earlyCommits MongoDB mongo.configServer.dur.preparingInMilliseconds dur.preparingInMilliseconds MongoDB mongo.configServer.dur.remappingInMilliseconds dur.remappingInMilliseconds MongoDB mongo.configServer.dur.timeCollectedCommitsInMilliseconds dur.timeCollectedCommitsInMilliseconds MongoDB mongo.configServer.dur.writingDataFilesInMilliseconds dur.writingDataFilesInMilliseconds MongoDB mongo.configServer.dur.writingJournalInMilliseconds dur.writingJournalInMilliseconds MongoDB mongo.configServer.flush.averageInMilliseconds flush.averageInMilliseconds MongoDB mongo.configServer.flush.flushesDisk flush.flushesDisk MongoDB mongo.configServer.flush.lastInMilliseconds flush.lastInMilliseconds MongoDB mongo.configServer.flush.totalInMilliseconds flush.totalInMilliseconds MongoDB mongo.configServer.getlasterror.wtimeMillisPerSecond getlasterror.wtimeMillisPerSecond MongoDB mongo.configServer.getlasterror.wtimeoutsPerSecond getlasterror.wtimeoutsPerSecond MongoDB mongo.configServer.globallock.activeClientsReaders globallock.activeClientsReaders MongoDB mongo.configServer.globallock.activeClientsTotal globallock.activeClientsTotal MongoDB mongo.configServer.globallock.activeClientsWriters globallock.activeClientsWriters MongoDB mongo.configServer.globallock.currentQueueReaders globallock.currentQueueReaders MongoDB mongo.configServer.globallock.currentQueueTotal globallock.currentQueueTotal MongoDB mongo.configServer.globallock.currentQueueWriters globallock.currentQueueWriters MongoDB mongo.configServer.globallock.totalTime globallock.totaltime MongoDB mongo.configServer.locks.collectionAcquireExclusive locks.collectionAcquireExclusive MongoDB mongo.configServer.locks.collectionAcquireIntentExclusive locks.collectionAcquireIntentExclusive MongoDB mongo.configServer.locks.collectionAcquireIntentShared locks.collectionAcquireIntentShared MongoDB mongo.configServer.locks.collectionAcquireWaitCountExclusive locks.collectionAcquireWaitCountExclusive MongoDB mongo.configServer.locks.collectionTimeAcquiringMicrosExclusive locks.collectionTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.databaseAcquireExclusive locks.databaseAcquireExclusive MongoDB mongo.configServer.locks.databaseAcquireIntentExclusive locks.databaseAcquireIntentExclusive MongoDB mongo.configServer.locks.databaseAcquireIntentShared locks.databaseAcquireIntentShared MongoDB mongo.configServer.locks.databaseAcquireShared locks.databaseAcquireShared MongoDB mongo.configServer.locks.databaseAcquireWaitExclusive locks.databaseAcquireWaitExclusive MongoDB mongo.configServer.locks.databaseAcquireWaitIntentExclusive locks.databaseAcquireWaitIntentExclusive MongoDB mongo.configServer.locks.databaseAcquireWaitIntentShared locks.databaseAcquireWaitIntentShared MongoDB mongo.configServer.locks.databaseAcquireWaitShared locks.databaseAcquireWaitShared MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosExclusive locks.databaseTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosIntentExclusive locks.databaseTimeAcquiringMicrosIntentExclusive MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosIntentShared locks.databaseTimeAcquiringMicrosIntentShared MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosShared locks.databaseTimeAcquiringMicrosShared MongoDB mongo.configServer.locks.globalAcquireExclusive locks.globalAcquireExclusive MongoDB mongo.configServer.locks.globalAcquireIntentExclusive locks.globalAcquireIntentExclusive MongoDB mongo.configServer.locks.globalAcquireIntentShared locks.globalAcquireIntentShared MongoDB mongo.configServer.locks.globalAcquireShared locks.globalAcquireShared MongoDB mongo.configServer.locks.globalAcquireWaitExclusive locks.globalAcquireWaitExclusive MongoDB mongo.configServer.locks.globalAcquireWaitIntentExclusive locks.globalAcquireWaitIntentExclusive MongoDB mongo.configServer.locks.globalAcquireWaitIntentShared locks.globalAcquireWaitIntentShared MongoDB mongo.configServer.locks.globalAcquireWaitShared locks.globalAcquireWaitShared MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosExclusive locks.globalTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosIntentExclusive locks.globalTimeAcquiringMicrosIntentExclusive MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosIntentShared locks.globalTimeAcquiringMicrosIntentShared MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosShared locks.globalTimeAcquiringMicrosShared MongoDB mongo.configServer.locks.metadataAcquireExclusive locks.metadataAcquireExclusive MongoDB mongo.configServer.locks.oplogAcquireExclusive locks.oplogAcquireExclusive MongoDB mongo.configServer.locks.oplogAcquireIntentExclusive locks.oplogAcquireIntentExclusive MongoDB mongo.configServer.locks.oplogAcquireIntentShared locks.oplogAcquireIntentShared MongoDB mongo",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 56.681793,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Infrastructure</em>",
        "body": "New Relic Integrations Metrics The following table contains the metrics we collect for our <em>infrastructure</em> integrations. Integration Dimensional Metric Name (new) Sample Metric Name (previous) Agent host.cpuIdlePercent cpuIdlePercent Agent host.cpuIoWaitPercent cpuIOWaitPercent Agent host.cpuPercent"
      },
      "id": "603e8a8a64441f69a34e8841"
    }
  ],
  "/docs/infrastructure/infrastructure-alerts/infrastructure-alert-conditions/create-infrastructure-host-not-reporting-condition": [
    {
      "sections": [
        "REST API calls for infrastructure alerts",
        "Requirements",
        "Tip",
        "Using infrastructure API calls",
        "GET infrastructure conditions",
        "GET a list of infrastructure conditions",
        "Example GET a list of conditions",
        "GET a specific infrastructure condition",
        "Example GET a specific condition",
        "Create (POST) an infrastructure condition",
        "Important",
        "Update (PUT) an infrastructure condition",
        "Example update (PUT) a condition",
        "Remove (DELETE) an infrastructure condition",
        "Types of conditions",
        "Process running conditions API data",
        "Example condition types",
        "Metric conditions API data",
        "Example",
        "Host not reporting condition",
        "Definitions",
        "value",
        "duration_minutes",
        "time_function"
      ],
      "title": "REST API calls for infrastructure alerts",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "c35aa43cdb6645473d02886a49d6f9aeb37e577f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/rest-api-calls-new-relic-infrastructure-alerts/",
      "published_at": "2021-06-15T02:33:21Z",
      "updated_at": "2021-04-06T06:04:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the infrastructure REST API to add, update, delete, and list alerting conditions. You can also manage individual alerting conditions using the infrastructure monitoring UI. REST API calls for infrastructure alerts are not available in the API Explorer. Why use the API Examples Consistency Define the same set of conditions for every cluster without having to set up identical conditions in the Infrastructure monitoring UI each time. Manage multiple conditions quickly, without having to update them one by one using the UI. Flexibility Create conditions for an arbitrary group of hosts. Disable or delete conditions for hosts taken offline anytime. Create a condition with exclusionary filtering (for instance, environment NOT LIKE x). For more on this, see this post on exclusion filtering. For AWS Cloud integrations, select attributes that haven't been sent up by AWS yet. Create compound alert conditions by using the where_clause, which allows you to specify the limits on a secondary or tertiary metric. Exceed the 500-facet limitation on NRQL alert conditions. Reliability Audit when a condition was last updated. Requirements In order to use the Infrastructure REST API, you need: An API key The alerting condition's related policy_id from New Relic, available via GET list of conditions or via the Alerts REST API The condition id, available via GET list of conditions, or via the condition's URL in the Infrastructure monitoring UI Tip If your account hosts data in the EU data center, make sure you are using the proper API endpoints for EU region accounts. Using infrastructure API calls Here are some basic cURL commands and their responses for Infrastructure alert conditions. Depending on the type of condition, the DATA information you provide in the call will vary for POST (add) and PUT (update) calls. Definitions of each attribute used in the data blocks can be found in the Definitions section. GET infrastructure conditions You can either GET a list of infrastructure conditions or GET a specific infrastructure condition. Here are a few tips for listing infrastructure conditions. For pagination, use limit (records per page) and offset (how many records to skip) parameters. Default is 50 records per page, and offset starts at 0 (skip no records). To scope the results to a specific policy, use policy_id. Tip If you want to use the GET response as a template for your PUT or POST input, be sure to remove the created_at_epoch_millis, updated_at_epoch_millis and id information. GET a list of infrastructure conditions curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions?policy_id=111111\" Copy Example GET a list of conditions Response showing 2 of the 3 conditions for the example policy (formatted for readability and truncated): HTTP/1.1 200 OK Content-Length: 622 Content-Type: application/json { \"data\":[ { \"type\":\"infra_process_running\", \"name\":\"Java is running\", \"enabled\":true, \"where_clause\":\"(`hostname` LIKE '%cassandra%')\", \"id\":13890, \"created_at_epoch_millis\":1490996713872, \"updated_at_epoch_millis\":1490996713872, \"policy_id\":111111, \"comparison\":\"equal\", \"critical_threshold\":{ \"value\":0, \"duration_minutes\":6 }, \"process_where_clause\":\"(`commandName` = 'java')\" }, { \"created_at_epoch_millis\": 1501704525462, \"critical_threshold\": { \"duration_minutes\": 5 }, \"enabled\": true, \"filter\": { \"and\": [ { \"like\": { \"fullHostname\": \"Production_1\" } } ] }, \"id\": 448036, \"name\": \"PROD - Host Machine's Agent Not Responding ....\", \"policy_id\": 98485, \"type\": \"infra_host_not_reporting\", \"updated_at_epoch_millis\": 1504879191220 } . . . ], \"meta\":{ \"limit\":50, \"offset\":0, \"total\":3 }, \"links\":{} } Copy To get a list of the 10 Infrastructure conditions beyond the 50 limit: curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions?policy_id=111111&offset=50&list=10\" Copy GET a specific infrastructure condition To get information about a single Infrastructure condition: curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions/condition-id\" Copy Example GET a specific condition Response (formatted for readability): HTTP/1.1 200 OK Content-Length: 246 Content-Type: application/json { \"data\":{ \"type\":\"infra_host_not_reporting\", \"name\":\"demo condition\", \"enabled\":false, \"id\":13887, \"created_at_epoch_millis\":1490981583580, \"updated_at_epoch_millis\":1490981583580, \"policy_id\":23635, \"critical_threshold\":{ \"duration_minutes\":100 } } } Copy Create (POST) an infrastructure condition Important Do not include an \"id\": when adding a new condition (POST). It will be generated when the condition is created. To add an infrastructure condition, use this basic cURL command: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{\"data\":{DATA object details}}' Copy Include details in the DATA object (-d \\ section) for the type of infrastructure condition you are adding: Process running conditions API data Metric conditions API data Host not reporting conditions API data Update (PUT) an infrastructure condition You only need to include the fields that need to be changed when updating an infrastructure condition. The API keeps the existing values for any missing fields. Important If you want to change the condition type, do not use PUT. Instead, delete the existing condition, then add (POST) a new condition with the new condition type and all fields. To update an infrastructure condition, use this basic cURL command. To indicate which condition is to be updated, be sure to include the \"id\": . Example update (PUT) a condition curl -X PUT 'https://infra-api.newrelic.com/v2/alerts/conditions/condition-id' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{\"data\":{DATA object details}}' Copy Include details in the DATA object (-d \\ section) for the type of infrastructure condition you are updating: Process running conditions API data Metric conditions API data Host not reporting conditions API data Remove (DELETE) an infrastructure condition To delete an infrastructure condition, use this basic cURL command: curl -v -X DELETE --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions/condition_id\" Copy Types of conditions Process running conditions API data A process running condition alerts you when the number of processes is above, below, or equal to the threshold you define. To add (POST) or update (PUT) a process running condition, use your API key, and refer to the definitions to customize your values in the API call. Example condition types For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_process_running\", \"name\":\"Java is running\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"comparison\":\"equal\", \"critical_threshold\":{ \"value\":0, \"duration_minutes\":6 }, \"process_where_clause\":\"(commandName = '\\''java'\\'')\" } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause and process_where_clause Metric conditions API data A metric condition alerts you when the metric of your choice is above, below, or equal to the threshold you define. This includes: System metrics Process metrics Network metrics Storage metrics Cloud integration metrics To add (POST) or update (PUT) a metric condition, use your API key, and refer to the definitions to customize your values in the API call. If you are adding or updating a cloud integration alert condition: For the event_type field, enter the event type generated by your selected cloud integration service (for example, ComputeSample for the AWS EC2 integration). If you are setting up an alert condition on a cloud integration service that requires a provider value (for example, AWS RDS uses DatastoreSample with a provider value of RdsDbInstance or RdsDbCluster), you will need to add the \"integration_provider\" field and use the value that is appropriate for the service your alert condition is targeting (for example, \"integration_provider\":\"RdsDbInstance\"). For the select_value field, build the metric name by using the following syntax, where provider is a standard prefix string: provider.metric.aggregation_type Copy metric: Use the metric name as described in the New Relic documentation for your integration. aggregation_type: Use Sum, Average, Minimum, or Maximum. Refer to the original documentation by the integration's cloud provider to see which statistic aggregations are available for each metric. Example For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_metric\", \"name\":\"Disk Space Condition\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"event_type\":\"StorageSample\", \"select_value\":\"diskFreePercent\", \"comparison\":\"below\", \"critical_threshold\":{ \"value\":10, \"duration_minutes\":1, \"time_function\":\"any\" }, \"warning_threshold\":{ \"value\":30, \"duration_minutes\":2, \"time_function\":\"any\" } } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause Host not reporting condition A host not reporting condition alerts you when a host stops reporting. To add (POST) or update (PUT) a host not reporting condition, use your API key, and refer to the definitions to customize your values in the API call. Example For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_host_not_reporting\", \"name\":\"Cassandra Host Reporting Condition\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"critical_threshold\":{ \"duration_minutes\":12 } } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause Definitions When formatting your cURL commands, use these values as needed. These are listed in alphabetical order, not the order they appear in your API calls. Field Definition comparison (enum) Condition type: infra_metric, infra_process_running The value used to define the threshold; for example, \"[\"above\", \"below\", \"equal\"]. critical_threshold and warning_threshold Condition type: all This object identifies the threshold value before opening a violation. The critical_threshold is required. The warning_threshold is optional and may only be used with infra_metric conditions. The keys of this object depend on the condition type. Condition type: infra_metric format: \"critical_threshold\":{ \"value\":<number>, \"duration_minutes\":<integer>, \"time_function\":\"any\" or \"all\" }, Copy Condition type: infra_process_running format: \"critical_threshold\":{ \"value\":<integer>, \"duration_minutes\":<integer>, }, Copy Condition type: infra_host_not_reporting format: \"critical_threshold\":{ \"duration_minutes\":<integer>, }, Copy value The numeric value that must be breached for the condition to open a violation duration_minutes The number of minutes the value must be passed or met for the condition to open a violation time_function Indicates if the condition needs to be sustained for a certain period of time to create a violation, or if it only needs to break the threshold once within a certain period of time. If you're setting up a for at least x minutes threshold, use all; for an at least once in x minutes threshold, use any. enabled (boolean) Condition type: all Whether the condition is turned on or off; true or false. event_type (string) Condition type: infra_metric The metric event; for example, system metrics, process metrics, storage metrics, or network metrics. This automatically populates for infrastructure integrations; for example, StorageSample or SystemSample. filter (string) Condition type: all If the condition was made in the UI, filter appears instead of where_clause; for example: {and: [{is: {ec2InstanceType: \"m3.medium\"}}]} Copy Recommendation: Use where_clause when creating a new condition. id (integer) Condition type: all The condition ID located in the URL. GET: This value appears in the GET response. PUT: Include this value in the DATA section. POST: Do not include this in the DATA section. DELETE: Include this value in the -X DELETE call. integration_provider (string) Condition type: infra_metric For alerts on integrations, use integration_provider instead of event_type. To see valid values: From the New Relic documentation for your cloud service, check the Find and use data section. Example: In the AWS RDS monitoring integration documentation, you can see that the DatastoreSample event type can be used with an integration_provider value of either RdsDbInstance for DB instances, or RdsDbCluster for Aurora DB clusters. name (string) Condition type: all The infrastructure alerting condition's name; for example: \"[test] process running\" Copy policy_id (integer) Condition type: all The unique ID for the alert policy's account ID associated with the condition; for example, 1234567890. This is not the policy's global ID. process_where_clause (string) Condition type: infra_process_running Any filters applied to processes, specifically in process running alert conditions. This parameter is mandatory for those types of alert conditions. For example: \"commandName = '\\''java'\\''\" Copy runbook_url (string) Condition type: all The runbook URL to display in notifications. select_value (string) Condition type: infra_metric The attribute name to identify the metric being targeted; for example, \"cpuPercent\", \"diskFreePercent\", \"memoryResidentSizeBytes\", or \"memoryFreeBytes/memoryTotalBytes*100\". This automatically populates for Infrastructure Integrations; for example, diskFreePercent. type (enum) Condition type: all The type of infrastructure alert condition: \"infra_process_running\", \"infra_metric\", or \"infra_host_not_reporting\". violation_close_timer (integer) Condition type: all The Violation time limit setting, expressed as hours. Possible values are 0, 1, 2, 4, 8,12, 24, 48, 72. This determines how much time will pass before a violation is automatically closed. Setting the time limit to 0 prevents a violation from being force-closed. For new conditions, if a value is not provided, the following default values are used: Host Not Responding (HNR) conditions: 0 (disabled) All other conditions: 24 When updating existing conditions, if a value is provided, it overrides the existing value, but does not affect already opened violations. where_clause (string) Condition type: all If applicable, this identifies any infrastructure host filters used; for example: \"(`hostname` LIKE '\\''%cassandra%'\\'')\", Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.2571,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>infrastructure</em> <em>alerts</em>",
        "sections": "REST API calls for <em>infrastructure</em> <em>alerts</em>",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "Use the <em>infrastructure</em> REST API to add, update, delete, and list alerting <em>conditions</em>. You can also manage individual alerting <em>conditions</em> using the <em>infrastructure</em> monitoring UI. REST API calls for <em>infrastructure</em> <em>alerts</em> are not available in the API Explorer. Why use the API Examples Consistency"
      },
      "id": "6043fa6c196a678ae2960f31"
    },
    {
      "sections": [
        "Alert on infrastructure processes",
        "Important",
        "Examples",
        "Ensure enough processes are running to satisfy load",
        "Ensure that critical services run constantly",
        "Monitor startup for critical processes that require special attention",
        "Make sure a job doesn't take too long",
        "Validate that services started successfully",
        "Watch for runaway processes or configuration problems",
        "Create an infrastructure process running condition"
      ],
      "title": "Alert on infrastructure processes",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "5fcbe11b9beb16723ff2521fca981f19a4c716ce",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/alert-infrastructure-processes/",
      "published_at": "2021-06-15T02:33:23Z",
      "updated_at": "2021-03-16T08:35:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use New Relic infrastructure's Process running alert condition to be notified when a set of processes on your filtered hosts stop running for a configurable number of minutes. This is useful, for example, when: Any of the processes on the hosts stop reporting A process you expected to start on a host (such as a new program) is not actually running This feature's flexibility allows you to easily filter what hosts and processes to monitor and when to notify selected individuals or teams. In addition, the email notification includes links to help you quickly troubleshoot the situation. Important By default, the infrastructure agent doesn't send data about the operating system's processes. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Examples By applying filters to the hosts and processes that are important to your business, you can define alerting thresholds to decide when violations open and New Relic sends an email notification to you depending on the policy's incident preferences. These examples illustrate how to use infrastructure monitoring's Process running condition to monitor your processes. Ensure enough processes are running to satisfy load Problem: Some load balancers and application servers work by running many worker processes in parallel. Here, for example, you may want an alert violation when fewer than eight processes are running for a service like gunicorn. Solution: Depending on the situation, use any of these Process running thresholds options as needed: More than the defined number of processes are running Exactly the defined number of processes are running Fewer than the defined number of processes are running Ensure that critical services run constantly Problem: A service, such as a database or application server, is expected to be running constantly on certain hosts, and you need to know when it has stopped. Solution: Use the No processes are running (default) threshold. Monitor startup for critical processes that require special attention Problem: You have processes requiring special attention due to security or potential performance impact. Solution: Use the At least one process is running threshold with condition filters set to a username and specific executable so that New Relic can open a violation when the process is running. Make sure a job doesn't take too long Problem: You have a job that runs periodically, and you want to open a violation when it has been running longer than an expected number of minutes. Solution: Use the At least one process is running threshold. Validate that services started successfully Problem: When provisioning new hosts, you want to open a violation if a required service fails to successfully start up. Solution: Use the No processes are running (default) threshold. Watch for runaway processes or configuration problems Problem: Sometimes problems with processes can be solved with changes to your configuration. For example, you have more than one Chef process running, and you may need to address an issue with how that service is configured. Solution: Depending on the situation, use any of these Process running thresholds options as needed: More than the defined number of processes are running Exactly the defined number of processes are running Fewer than the defined number of processes are running Create an infrastructure process running condition To define the Process running alert criteria: Follow standard procedures to create an infrastructure alert condition. Select Process running as the Alert type. Filter what hosts and processes you want the alert condition to apply to. Define the Critical threshold for triggering the alert notification: minimum 1 minute, default 5 minutes, maximum 60 minutes. If you create the alert condition directly with infrastructure monitoring, New Relic will send an email notification when the defined threshold for the alert condition passes depending on the policy's incident preferences. Your alert policy defines which personnel or teams and which notification channels we use.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.89563,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alert</em> on <em>infrastructure</em> processes",
        "sections": "<em>Alert</em> on <em>infrastructure</em> processes",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "Use New Relic <em>infrastructure</em>&#x27;s Process running <em>alert</em> condition to be notified when a set of processes on your filtered hosts stop running for a configurable number of minutes. This is useful, for example, when: Any of the processes on the hosts stop reporting A process you expected to start"
      },
      "id": "603eb49128ccbca939eba74a"
    },
    {
      "sections": [
        "Infrastructure alerting examples",
        "Examples: Infrastructure pages",
        "Examples: Threshold options",
        "Integrations providers",
        "CPU, disk, load average, memory, swap",
        "Byte size"
      ],
      "title": "Infrastructure alerting examples",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "1ec5f86b745413b2a8d6a5b676ecbe622c674ab1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/infrastructure-alerting-examples/",
      "published_at": "2021-06-14T21:16:54Z",
      "updated_at": "2021-03-16T07:35:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Alert type field in infrastructure monitoring's Settings > Alerts page shows what options you can select to create infrastructure alert conditions. You can also create alert conditions from any infrastructure chart by selecting the ellipses icon and then Create alert. Examples: Infrastructure pages Here are some examples of how to create alert conditions within the context of the Infrastructure monitoring UI page you are currently viewing. To create an alerts condition from any chart, select the ellipses icon and then Create alert. New Relic will automatically select the appropriate Alert type. Example Problem and solution High CPU usage Problem: Your Ops team monitors a filtered set of host clusters in your eastern region and notices that the CPU usage is constantly high. Solution: Use the CPU chart on Infrastructure monitoring's Hosts page to create an alert condition for system metrics. Virtual memory capacity Problem: Your night shift needs to be alerted when virtual memory for a set of background workers reaches an average of 10G for at least two minutes. Solution: Use the Top memory consumers chart on Infrastructure monitoring's Processes page to create an alert condition for process metrics. Limited bandwidth Problem: You want to monitor performance based on the average number of errors received or transmitted. Solution: Use the Top bandwidth chart on Infrastructure monitoring's Network page to create an alert condition for network metrics. I/O read and write operations Problem: You are testing a new set of hosts in your staging environment, and you want to be notified when their read or write capacity rises above your test threshold level. Solution: Use the Top I/O operations chart on Infrastructure monitoring's Storage page to create an alert condition for storage metrics. Host not reporting Problem: You want to be notified when we have stopped receiving data from an infrastructure agent. Solution: From the Hosts, Processes, Network, or Storage pages, create a host not reporting alert condition. Processes not running as expected Problem: You want to be notified if any of the processes on your hosts stop reporting. OR A process you expected to start on a host (such as a new program) is not actually running. Solution: From the Processes page (or from the Hosts, Network, or Storage pages), create a process running alert condition. Examples: Threshold options Use the thresholds dropdown for the selected Alert type to further define how you want to be alerted. Here are some examples of the options available. Integrations providers With infrastructure integrations, you can create an alert condition from your Integrations page. Depending on the type of provider selected (CloudFront, DynamoDB, EBS, etc.), options will vary from the Define thresholds dropdown; for example, bytes, errors, requests, CPU, connections, memory, records, latency, etc. CPU, disk, load average, memory, swap The System metrics thresholds dropdown allows you to select various criteria for CPU, disk, load average, memory, and swap metrics. Byte size The Network metrics thresholds provide flexibility with your business needs. Depending on the size of your network, you can easily set the threshold in bytes, KB, MB, GB, or TB.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.88727,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>alerting</em> examples",
        "sections": "<em>Infrastructure</em> <em>alerting</em> examples",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "The <em>Alert</em> type field in <em>infrastructure</em> monitoring&#x27;s Settings &gt; <em>Alerts</em> page shows what options you can select to create <em>infrastructure</em> <em>alert</em> <em>conditions</em>. You can also create <em>alert</em> <em>conditions</em> from any <em>infrastructure</em> chart by selecting the ellipses icon and then Create <em>alert</em>. Examples: <em>Infrastructure</em>"
      },
      "id": "603eb52a28ccbc9027eba7bb"
    }
  ],
  "/docs/infrastructure/infrastructure-monitoring/get-started/get-started-infrastructure-monitoring": [
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-15T15:13:51Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.32507,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of synthetic <em>monitors</em>",
        "sections": "Types of synthetic <em>monitors</em>",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": " not reporting feature in <em>infrastructure</em> <em>monitoring</em>. This allows you to take advantage of enhanced <em>monitoring</em> options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic <em>monitoring</em> and the rest of our observability platform, join the New Relic family! Sign up to create"
      },
      "id": "603e873864441f3e154e888f"
    },
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-06-14T21:07:01Z",
      "updated_at": "2021-06-14T21:07:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. Built-in log forwarding and on-host integrations are not yet available. Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.10 to 1.16 Red Hat Enterprise Linux (RHEL) Version 6 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, and 12.4 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 (only the infrastructure agent is supported). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 142.21368,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> agent",
        "sections": "Requirements for the <em>infrastructure</em> agent",
        "tags": "<em>Get</em> <em>started</em>",
        "body": " can also <em>monitor</em> Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The <em>infrastructure</em> agent uses the hostname to uniquely identify each server. To avoid"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Introduction to New Relic APIs",
        "Tip",
        "NerdGraph (GraphQL)",
        "REST APIs by capability",
        "Alerts",
        "APM",
        "Browser monitoring",
        "Infrastructure monitoring",
        "Mobile monitoring",
        "Synthetic monitoring",
        "Telemetry APIs for core data types",
        "Account management, admin, and usage APIs",
        "Other APIs",
        "Insights",
        "Plugins",
        "See APIs in action"
      ],
      "title": "Introduction to New Relic APIs",
      "type": "docs",
      "tags": [
        "APIs",
        "Get started",
        "Intro to APIs"
      ],
      "external_id": "01e9799a214baad5de04de6146483f6dbbc198aa",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/intro-apis/introduction-new-relic-apis/",
      "published_at": "2021-06-14T18:02:47Z",
      "updated_at": "2021-06-02T16:33:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a variety of APIs and SDKs you can use to: Retrieve data from New Relic. Send data to New Relic. Adjust settings. This document provides examples and reference information for our API endpoints. For developer-focused content on how to use and customize New Relic, see developer.newrelic.com. Tip To use APIs and SDKs, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. NerdGraph (GraphQL) NerdGraph is New Relic's GraphQL-format API, an efficient and flexible query language that lets you request exactly the data you need, without over-fetching or under-fetching. NerdGraph is the preferred API for querying New Relic data and making a range of feature configurations. To get started, see Introduction to NerdGraph. REST APIs by capability New Relic capabilities, like APM, infrastructure monitoring, or alerts, are often used together, and sometimes they overlap in functionality. This is why multiple APIs may be relevant to each area. Some API functionality will depend on your access to features and data. Tip To learn more about different API key types, see Understand New Relic API keys. Alerts Use the REST API for alerts and the API Explorer to: Create and manage policies, conditions, and notification channels. Create alert conditions based on NRQL queries. Create alert conditions based on data from other New Relic capabilities. APM API resources for application monitoring include: Resource Details REST API REST API features include: Retrieve APM data, including metrics, Apdex, error rates, and host data. Report deployments. Change the app name in the UI. Agent APIs Every APM language agent has an API that lets you customize the agent's default behavior, including reporting custom data. APM agent APIs include: C SDK API Go agent API Java agent API .NET agent API Node.js agent API PHP agent API Python agent API Ruby agent API Query API To query APM data, use the Query API. Account management APIs For APIs related to accounts and subscription usage, see the account-related APIs. Browser monitoring The Browser API resources include: Resource Details Browser agent API Use the Browser agent API for tasks such as: Report custom end user data to browser monitoring. Monitor asynchronous browser activity using SPA API calls. Insert custom data into New Relic dashboards . Manage source maps. REST API With the REST API you can: Retrieve page load timing data and throughput. Add or list apps monitored by browser monitoring. Manage alerts conditions for your browser data. Query API To retrieve browser monitoring data, use the Query API. Account management APIs For APIs related to accounts and subscription usage, see the account-related APIs. Infrastructure monitoring The Infrastructure API resources include: Resource Details Query API To retrieve infrastructure data, use the Query API. This API can also be used to retrieve subscription usage data. Infrastructure alert API To manage your infrastructure alerts, use the Infrastructure alert API. Integrations SDK To make your own custom integrations for reporting data to infrastructure monitoring, use the Integrations SDK. NerdGraph You can use NerdGraph (our GraphQL API) to query your cloud integration data and make changes to cloud integration settings. Mobile monitoring Mobile API resources include: Resource Details Mobile agent APIs Mobile APIs let you custom instrument your own code and send events to New Relic. See the platform-specific documentation: iOS Android Unity REST API Use the REST API for such tasks as: Retrieve a list of monitored apps. Get subscription usage data. Get metric names and data. Get crash count and crash rate data. Manage New Relic alerts conditions for your mobile apps. Query API To retrieve Mobile data from New Relic, use the Query API. Account management APIs For account-related APIs, see Account APIs. Synthetic monitoring Synthetics API resources include: Resource Details Synthetics REST API The Synthetics REST API functionality includes: Create and manage synthetics monitors. Manage synthetics alert notifications. Add labels to monitors, and retrieve monitors with specific labels. Query API To retrieve synthetics event data, use the Query API. Alerts API To create and manage alert conditions that target synthetics monitors, use the Alerts API. Telemetry APIs for core data types We offer several APIs that allow you to get our core data types (metrics, logs, traces, and events) into New Relic without the use of an installed agent. Data type Description Trace API Send distributed tracing data to New Relic. Event API Send event data to New Relic. Metric API Send metrics to New Relic from any source (including other telemetry monitoring services). Log API Send your log data to New Relic. Account management, admin, and usage APIs Like any other New Relic product or service, you want to be confident that your APIs protect you and your customers' data privacy. The following are API resources related to New Relic account administration and usage. For more information about API capabilities, see the specific New Relic API. For more information about New Relic's security measures, see our security and privacy documentation, or visit the New Relic security website. Resource Details REST API REST API features include: Find your API keys, account ID, and information needed to use the REST API. Return a list of account users (original user model only). Get SLA report data for browser and application monitoring. Subscription usage You can use the Query API to retrieve subscription usage data. This can be helpful to see how usage compares to your current subscription level, or for doing departmental chargebacks. Partner API To retrieve information about your New Relic partner account, sub-accounts, and users, use the Partner API. Other APIs Insights New Relic Insights was the name of our original product that governed custom event reporting and querying. The features associated with Insights have been rolled into our New Relic One platform (learn more), but there are still some APIs and original pricing plans that use the term \"Insights\" for these historical reasons. Insights-related APIs include: Resource Details Event API To report custom events, use the Event API. Query API To query your data using NRQL-format queries, you can use the Query API. Note that this API is deprecated and NerdGraph is preferred for querying your data. Dashboard API See the Insights Dashboard API. Plugins Use the REST API for New Relic plugins and the API Explorer to: Get a list of plugins, including their names, IDs, and GUIDs. List one or more plugin components, their output, and their metric timeslice data. Developers and New Relic partners can also use New Relic's Plugin API to write an agent in any language that can work directly with the API for plugins. This allows you to send your own metric data to our plugins and view data received from the API in New Relic. See APIs in action For more on how you as a developer can optimize your ability to solve problems using New Relic, go to developer.newrelic.com.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 119.25532,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Infrastructure</em> <em>monitoring</em>",
        "tags": "<em>Get</em> <em>started</em>",
        "body": ", an efficient and flexible query language that lets you request exactly the data you need, without over-fetching or under-fetching. NerdGraph is the preferred API for querying New Relic data and making a range of feature configurations. To <em>get</em> <em>started</em>, see Introduction to NerdGraph. REST APIs"
      },
      "id": "609fa5cf196a67066022b194"
    }
  ],
  "/docs/infrastructure/infrastructure-monitoring/infrastructure-security/infrastructure-security": [
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Tip",
        "Quick start",
        "Install using the launcher",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-06-14T21:08:05Z",
      "updated_at": "2021-06-03T13:38:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. Tip To use infrastructure monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Install using the launcher Before installing our infrastructure monitoring agent for Linux, be sure to: Review the requirements. Have a valid New Relic license key. To install our infrastructure monitoring agent, click the button for your Linux distribution, then follow the instructions: Amazon Linux CentOS Container (Docker) Debian RHEL SLES Ubuntu Other Linux distros To use the links above, you must be logged to your New Relic account. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our step-by-step tutorial in the next section. Step-by-step instructions To install the infrastructure monitoring agent in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 12 (\"Precise\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt precise main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 14 (\"Trusty\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt trusty main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS / RHEL CentOS 7.x, RHEL 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS 7.x, RHEL 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS 8.x, RHEL 8.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS 8.x, RHEL 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 94.35059,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install the <em>infrastructure</em> <em>monitoring</em> agent for Linux",
        "sections": "Install the <em>infrastructure</em> <em>monitoring</em> agent for Linux",
        "tags": "<em>Infrastructure</em>",
        "body": "Our <em>infrastructure</em> <em>monitoring</em> agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. Tip To use <em>infrastructure</em> <em>monitoring</em> and the rest of our observability platform, join the New Relic"
      },
      "id": "6043edce64441f5335378f15"
    },
    {
      "sections": [
        "Incorrect host name reported",
        "Problem",
        "Solution",
        "Restart the agent with SystemD",
        "Restart the agent with System V",
        "Restart the agent with Upstart",
        "Restart the agent in Windows",
        "Cause"
      ],
      "title": "Incorrect host name reported",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "d6a81c3fae24464898bea92df4c6a57945b6c731",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/incorrect-host-name-reported/",
      "published_at": "2021-06-14T21:19:46Z",
      "updated_at": "2021-05-16T07:48:02Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem The agent is working, but the infrastructure monitoring UI shows the wrong hostname. Solution To set the correct hostname, try the following steps: Edit the newrelic-infra.yml configuration file and add the override_hostname option, whose value is your expected hostname. For example: override_hostname: correct-host.domain.com Copy Use your init system to restart the agent service: Restart the agent with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: sudo systemctl restart newrelic-infra Copy Restart the agent with System V Use System V commands with Debian 7: sudo /etc/init.d/newrelic-infra restart Copy Restart the agent with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10 or lower: sudo initctl restart newrelic-infra Copy Restart the agent in Windows net stop newrelic-infra net start newrelic-infra Copy Cause The New Relic infrastructure agent tries to resolve its fully qualified domain name against a domain name server, which may not be properly configured or not controlled by the same user as the New Relic infrastructure agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 89.13788,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Infrastructure</em> <em>monitoring</em> troubleshooting",
        "body": "Problem The agent is working, but the <em>infrastructure</em> <em>monitoring</em> UI shows the wrong hostname. Solution To set the correct hostname, try the following steps: Edit the newrelic-infra.yml configuration file and add the override_hostname option, whose value is your expected hostname. For example"
      },
      "id": "6043fd9028ccbc23872c60c5"
    },
    {
      "sections": [
        "Get started with infrastructure monitoring",
        "Tip",
        "Quick start: Use our guided install",
        "Reduce MTTR with actionable data",
        "Install and configure the infrastructure agent",
        "Add integrations to gather data about your services",
        "Filter your hosts any way you want",
        "Explore your infrastructure data",
        "Check the source code"
      ],
      "title": "Get started with infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring",
        "Get started"
      ],
      "external_id": "0451d55a1af096a3b33ceda0bb08b9d956e0472a",
      "image": "https://docs.newrelic.com/static/0552c14ad1f127cde466137f57e562ba/c1b63/nrone-infrastructure-hosts.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-monitoring/get-started/get-started-infrastructure-monitoring/",
      "published_at": "2021-06-15T02:04:18Z",
      "updated_at": "2021-03-30T09:50:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic provides flexible, dynamic observability of your entire infrastructure, from services running in the cloud or on dedicated hosts to containers running in orchestrated environments. You can connect the health and performance of all your hosts to application context, logs, and configuration changes. With infrastructure monitoring, modern operations teams get complete observability of complex and hybrid systems, from a datacenter to thousands of Amazon, Google Cloud, or Azure instances. Tip To use infrastructure monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. The Hosts page for your infrastructure in New Relic One shows performance indicators for systems, networks, processes, and storage. Quick start: Use our guided install The quickest way to get started with our infrastructure monitoring agent is through our guided install. Guided install EU Guided install Our guided install not only installs the infrastructure agent, but also discovers the applications and log sources running in your environment. It recommends which ones you should instrument. The guided install works with most setups. But if it doesn't suit your needs, you can find other methods below to get started monitoring your infrastructure. Reduce MTTR with actionable data Real-time metrics and analytics reduce your mean-time-to-resolution (MTTR) by connecting changes in host performance to changes in your configuration. From the Inventory page you can search across your entire estate to find exactly which of your hosts contain particular packages, configs, or startup scripts. The Inventory page in New Relic One focuses on all the infrastructure entities in your estate. From the Events page you can track config changes, restarts, SSH sessions, and other key event changes. A real-time feed gives you a changelog for your entire infrastructure. Our solution securely collects and displays your data in five seconds, so your monitoring never lags behind reality. The Events page in New Relic One contains a real-time feed of all that is happening in your hosts. With our infrastructure monitoring tools you can also: Query your data to drill down into your infrastructure events and build custom dashboards that you can share with your team. Troubleshoot performance issues, no matter where the issue occurs—server-side or application-side—thanks to APM data connection with infrastructure monitoring. Create, view, or update alert settings directly from the relevant infrastructure chart. For example, you can create a host not reporting alert condition. Forward logs to our logs monitoring by adding as many configuration files as log sources you need to push to our platform. Install and configure the infrastructure agent You can send metric data to our platform using our open source infrastructure agent, a lightweight executable file that works in the background to collect the information you need. The simplest way to install and run the infrastructure agent is using a package manager (Linux) or the MSI installer (Windows). You can also use our installation assistants: Amazon Linux CentOS Container (Docker) Debian RHEL SLES Ubuntu Windows To use the links above, you must be logged to your New Relic account. If you don't have a New Relic account yet, or prefer to follow the procedure step-by-step, see our tutorials to install the agent for Linux | Windows | Elastic Beanstalk | Ansible | Chef | Puppet. Add integrations to gather data about your services Integrations give you access to the metrics of many popular systems, including Amazon Web Services (AWS), Google Cloud Platform, Microsoft Azure, Kubernetes, MySQL, Cassandra, and more. You can also make your own integrations using New Relic Flex or the Integrations SDK to collect data from other applications. With New Relic Flex, you can instrument any command-line tool without coding. Our Kubernetes cluster explorer in New Relic One gives you a powerful and innovative solution to the challenges associated with running Kubernetes at a large scale. Filter your hosts any way you want Filter sets allow you to organize your hosts based on criteria that matter most to you. You can filter your hosts by any infrastructure attribute, such as geographic location, hostname, or Linux distribution. You can also filter on Amazon attributes, such as region or instance type, and add custom attributes to define unique metadata, such as what team manages the host or the services running. Explore your infrastructure data You can query and visualize your infrastructure data in New Relic One: Sample and search infrastructure events, such as to gain full understanding of the data being collected. Browse your data visually with the data explorer. Create custom SQL-like queries of your data using the New Relic Query Language (NRQL), or query your data using our PromQL-style queries. Use dashboards to build advanced data visualizations, contextualize data, and understand what's going on in your system, real-time. Check the source code The infrastructure agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 78.12216,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>infrastructure</em> <em>monitoring</em>",
        "sections": "Get started with <em>infrastructure</em> <em>monitoring</em>",
        "tags": "<em>Infrastructure</em> <em>monitoring</em>",
        "body": " changes. With <em>infrastructure</em> <em>monitoring</em>, modern operations teams get complete observability of complex and hybrid systems, from a datacenter to thousands of Amazon, Google Cloud, or Azure instances. Tip To use <em>infrastructure</em> <em>monitoring</em> and the rest of our observability platform, join the New Relic"
      },
      "id": "6043fb59e7b9d272d9579a16"
    }
  ],
  "/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-infrastructure/no-data-appears-infrastructure": [
    {
      "sections": [
        "Incorrect host name reported",
        "Problem",
        "Solution",
        "Restart the agent with SystemD",
        "Restart the agent with System V",
        "Restart the agent with Upstart",
        "Restart the agent in Windows",
        "Cause"
      ],
      "title": "Incorrect host name reported",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "d6a81c3fae24464898bea92df4c6a57945b6c731",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/incorrect-host-name-reported/",
      "published_at": "2021-06-14T21:19:46Z",
      "updated_at": "2021-05-16T07:48:02Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem The agent is working, but the infrastructure monitoring UI shows the wrong hostname. Solution To set the correct hostname, try the following steps: Edit the newrelic-infra.yml configuration file and add the override_hostname option, whose value is your expected hostname. For example: override_hostname: correct-host.domain.com Copy Use your init system to restart the agent service: Restart the agent with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: sudo systemctl restart newrelic-infra Copy Restart the agent with System V Use System V commands with Debian 7: sudo /etc/init.d/newrelic-infra restart Copy Restart the agent with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10 or lower: sudo initctl restart newrelic-infra Copy Restart the agent in Windows net stop newrelic-infra net start newrelic-infra Copy Cause The New Relic infrastructure agent tries to resolve its fully qualified domain name against a domain name server, which may not be properly configured or not controlled by the same user as the New Relic infrastructure agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.81445,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem The agent is working, but the <em>infrastructure</em> <em>monitoring</em> UI shows the wrong hostname. Solution To set the correct hostname, try the following steps: Edit the newrelic-infra.yml configuration file and add the override_hostname option, whose value is your expected hostname. For example"
      },
      "id": "6043fd9028ccbc23872c60c5"
    },
    {
      "sections": [
        "Reduce the infrastructure agent's CPU footprint",
        "Problem",
        "Solution",
        "Reduce event sampling",
        "Important",
        "Reduce agent plugin reporting",
        "How to enable and disable plugins",
        "Disable SELinux semodule -l (Linux only)",
        "Reduce or disable Sysctl (Linux only)",
        "Additional plugins to reduce or disable",
        "Review on-host integrations"
      ],
      "title": "Reduce the infrastructure agent's CPU footprint",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "4eea817bfabb6b698ea3ce001b8c5eeca20d475e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/reduce-infrastructure-agents-cpu-footprint/",
      "published_at": "2021-06-14T21:19:46Z",
      "updated_at": "2021-03-16T08:35:01Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem The New Relic infrastructure agent is consuming too much CPU. Solution The New Relic infrastructure agent is designed to report a broad range of system data with minimal CPU and memory consumption. However, if you have a need to reduce your CPU consumption, you can disable or decrease the sampling frequency of various samplers and plugins. This topic highlights some newrelic-infra.yml configurations that may reduce your CPU usage: Reduce event sampling Reduce agent plugin reporting Review on-host integrations Reduce event sampling The infrastructure agent reports several default events at specific frequencies. To lower the overhead, you can reduce the sampling frequency in seconds, or you can completely disable the samplers by setting the corresponding property value to -1. Important We don't recommend a sample rate larger than 60 seconds because you may see gaps in the New Relic user interface charts. The table below lists some samplers to configure: Event Sampling frequency Allow/deny list Network Network sampling rate Not available Process Process sampling rate Allow list (Windows only) Storage Storage sampling rate Deny list System System sampling rate Not available Reduce agent plugin reporting The infrastructure agent has built-in plugins that collect inventory data (specific system configuration and state information). For some systems, the CPU consumption may be relatively high if the plugins are gathering a lot of data. To reduce the footprint, you can disable or decrease the sampling frequency for specific plugins that report data you don’t want. How to enable and disable plugins Disable a single plugin: To disable a plugin, set the corresponding property value to -1. Disable all plugins: disable_all_plugins: true Enable selected plugins: To enable certain plugins, insert an exception in disable_all_plugins. For example, the following configuration disables all plugins, but the Network Interfaces plugin reports every 120 seconds: disable_all_plugins: true network_interface_interval_sec: 120 Copy Disable SELinux semodule -l (Linux only) The SELinux plugin periodically invokes the semodule -l system command to get information about the existing SELinux modules. In most CentOS/RedHat distributions, this command will generate CPU consumption peaks. To disable this functionality, insert the following configuration option in your /etc/newrelic-infra.yml file: selinux_enable_semodule: false Reduce or disable Sysctl (Linux only) The Sysctl plugin walks the whole /sys directory structure and reads values from all the files there. Disabling it or reducing the interval may decrease some CPU System time in the Infrastructure agent. You can disable inventory frequency by setting it to a negative number or reduce the frequeny by setting the sysctl_interval_sec configuration value to the number of seconds between consecutive executions of the plugin. For example, to execute the plugin once every 10 minutes: sysctl_interval_sec: 600 Copy To disable the Sysctl plugin: sysctl_interval_sec: -1 Copy The current default value for the sysctl_interval_sec property is 60. Additional plugins to reduce or disable The following inventory plugins are not especially CPU consuming, but you can still reduce their frequency or disable them by setting the corresponding configuration options. Linux plugins For configuration of these Linux plugins, see Plugin variables: Cloud Security Groups Daemon Tools DPKG Facter Kernel Modules Network interfaces RPM SELinux Supervisord Sysctl Systemd SysV Upstart Users SSHD configuration Windows plugins For configuration of these Windows plugins, see Plugin variables: Network interfaces Windows services Windows updates Review on-host integrations If you use infrastructure on-host integrations, this may have additional impacts on CPU usage. The nature of the impact and the methods to adjust the impact depend on the integration you're using. Here are some ways to adjust on-host integration CPU usage: See if your integration has configuration options you can adjust. If possible, spread out the monitoring load by adding additional infrastructure agents. For example, the Kafka integration allows a multi-agent deployment.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.28973,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Reduce the <em>infrastructure</em> agent&#x27;s CPU footprint",
        "sections": "Reduce the <em>infrastructure</em> agent&#x27;s CPU footprint",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": " on the integration you&#x27;re using. Here are some ways to adjust on-host integration CPU usage: See if your integration has configuration options you can adjust. If possible, spread out the <em>monitoring</em> load by adding additional <em>infrastructure</em> agents. For example, the Kafka integration allows a multi-agent deployment."
      },
      "id": "603eb9dc64441fbf1f4e8847"
    },
    {
      "sections": [
        "APM data missing from infrastructure monitoring",
        "Problem",
        "Solution",
        "Restart the app server.",
        "Make sure the hostnames are the same in APM and Infrastructure.",
        "Check for replacement host FQDN recognition problems."
      ],
      "title": "APM data missing from infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "68c926e4922c558a2ab2b0f9557f2fe7973ee0af",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/apm-data-missing-infrastructure/",
      "published_at": "2021-06-14T21:18:51Z",
      "updated_at": "2021-03-16T07:35:33Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When APM and infrastructure agents are installed on the same hosts and use the same New Relic license key, APM data should appear in Infrastructure, and vice versa. If you do not see this APM-Infrastructure linkage, follow these troubleshooting tips. Solution If you completed the APM/Infrastructure integration but do not see New Relic APM data in Infrastructure, try these troubleshooting procedures. Restart the app server. If you have not restarted your APM-monitored application in a few weeks or months, the data streams from Infrastructure and APM may not be linked. Restart your app server. Generate some traffic for your app. Wait a few minutes, and then check for APM data in infrastructure monitoring. Make sure the hostnames are the same in APM and Infrastructure. If the hostnames are different in APM and infrastructure monitoring, New Relic cannot integrate the data. One common cause for this issue is that the default hostnames are different. For example, infrastructure monitoring uses a host's FQDN (such as myhost1.example.com), while APM uses the host's name (such as myhost1). Go to one[.newrelic.com](http://one.newrelic.com) > APM > (select an app). From the app's APM Overview page, look at the app's associated host name. Compare that name with the same host's name in infrastructure monitoring. If the names are different, either set the APM agent host's display_name to match its FQDN, or set the host's display_name in Infrastructure to match the one set in APM. Check for replacement host FQDN recognition problems. If the APM-Infrastructure integration previously worked but has stopped, the server may have been replaced by another server that has the same FQDN. If both servers existed simultaneously for a period of time, New Relic cannot automatically recognize the new server. That will break the connection between APM and infrastructure data. To solve this problem, get help at support.newrelic.com. To prevent this problem, make sure there is a time gap between taking down an old server going down and creating a new server.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.2822,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "sections": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem When APM and <em>infrastructure</em> agents are installed on the same hosts and use the same New Relic license key, APM data should appear in <em>Infrastructure</em>, and vice versa. If you do not see this APM-<em>Infrastructure</em> linkage, follow these <em>troubleshooting</em> tips. Solution If you completed the APM"
      },
      "id": "603e9100e7b9d2b2962a07e8"
    }
  ],
  "/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-logs/generate-logs-troubleshooting-infrastructure": [
    {
      "sections": [
        "The agent is not starting and there are no logs",
        "Problem",
        "Solution",
        "Check requiretty",
        "Important",
        "Review log permissions"
      ],
      "title": "The agent is not starting and there are no logs",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot logs"
      ],
      "external_id": "fefb6cf577c3c825a6908eba8e378de3ceca4cd7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/agent-not-starting-there-are-no-logs/",
      "published_at": "2021-06-14T21:17:52Z",
      "updated_at": "2021-03-16T08:35:01Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem The infrastructure agent is not starting, and logs are not created. Solution Here are some troubleshooting options for non-root users if the infrastructure agent is not starting and there are no logs: Check requiretty To see if requiretty is causing logging issues: In /var/log/messages or /var/log/syslog, look for the message sudo: sorry, you must have a tty to run sudo . Important When using old Linux versions, sometimes the nri-agent user fails to execute a service because it does not have any TTY attached. If you find this message, edit your /etc/sudoers file with the visudo command and comment or remove the following line: Defaults requiretty Save and exit the file. Restart the newrelic-infra service. Review log permissions Check the agent's permission to open log_file. It's possible that the log file you are using was created when the agent was running as root, and now the nri-agent user does not have permissions to write it. To solve this, try one of these options: Change the owner of the log file. Change the log_file entry in the /etc/newrelic-infra.yml configuration file. Our installation scripts create the /var/log/newrelic-infra/ folder for that purpose, so we recommend the following value: log_file: /var/log/newrelic-infra/newrelic-infra.log Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.56216,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "The agent is not starting and there are no <em>logs</em>",
        "sections": "The agent is not starting and there are no <em>logs</em>",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem The <em>infrastructure</em> agent is not starting, and <em>logs</em> are not created. Solution Here are some <em>troubleshooting</em> options for non-root users if the <em>infrastructure</em> agent is not starting and there are no <em>logs</em>: Check requiretty To see if requiretty is causing logging issues: In &#x2F;var&#x2F;<em>log</em>&#x2F;messages"
      },
      "id": "603eba9e28ccbc5f64eba786"
    },
    {
      "sections": [
        "Infrastructure agent logging behavior",
        "Logging severity levels",
        "Important",
        "Log formatting",
        "Log rotation",
        "Logrotate config file sample",
        "Tip",
        "Smart verbose mode",
        "Logging before Infrastructure agent v1.4.9",
        "Integration log management",
        "Integration STDERR expected format"
      ],
      "title": "Infrastructure agent logging behavior",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot logs"
      ],
      "external_id": "0dc6570e893e47c4d5b5c4232283432926c6476a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-logs/infrastructure-agent-logging-behavior/",
      "published_at": "2021-06-15T02:05:39Z",
      "updated_at": "2021-03-16T07:31:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's infrastructure agent gathers its own data as well as integrations's logs and consolidates them in a single source. By default, logs appear in standard-output and are added to a log file. To disable logs in standard output, see the agent's config options. Logging severity levels Infrastructure uses a subset of the standard Syslog severity levels: ERROR: Error conditions met WARN: Warning conditions met INFO: Informational messages DEBUG: Contains debug-level messages (useful when troubleshooting) Important DEBUG level is only shown when the verbose mode is enabled. Log formatting For infrastructure agent v1.4.9 or higher, log messages are inlined with context values. This offers better grouping and filtering; for example: containerized agent found in container containerID: VALUE Copy By default, Infrastructure logs are formatted as text: In foreground mode, log output is colored, without a timestamp: DEBUG Sending deltas divided in blocks component=PatchSender mentityKey=ohaimaci mnumberOfBlocks=1 Copy In background mode, logs are timestamped output, used when running as a service or dumping logs to a file: time=\"2019-07-12T09:54:15+02:00\" level=info msg=\"Agent service manager shutdown completed successfully.\" component=AgentService service=newrelic-infra Copy Alternatively, logs can be formatted as a JSON file: {\"context\":{},\"level\":\"info\",\"msg\":\"upstart_interval_sec: 0\",\"timestamp\":\"2019-07-11T18:24:03+02:00\"} {\"context\":{},\"level\":\"info\",\"msg\":\"plugin_dir: \",\"timestamp\":\"2019-07-11T18:24:03+02:00\"} Copy To change the log format, see the agent configuration settings. Log rotation The infrastructure agent does not provide any native log rotation or compression mechanism. Instead, we encourage you to use consolidated log rotation tools, such as the Linux logrotate tool, which is usually installed by default in most Linux distributions. Logrotate can be configured as an entry in /etc/logrotate.conf, or as a file in the /etc/logrotate.d directory. Logrotate config file sample A sample logrotate config file looks like this: /var/log/newrelic-infra/newrelic-infra.log { copytruncate compress daily dateext maxage 7 } Copy Where: /var/log/newrelic-infra/newrelic-infra.log: The Infrastructure agent log file. It must match the log_file configuration parameter in the /etc/newrelic-infra.yml file. copytruncate: Indicates that the log file is truncated but not deleted when it is rotated. This configuration option is mandatory, otherwise the log file will be deleted and won’t be recreated. compress: Compresses (usually in Gzip format) the rotated log files. daily: The agent rotates logs daily. dateext: Appends a date (by default, in the format YYYYMMDD) to the rotated log file (e.g. newrelic-infra.log-20190708.gz) maxage 7: Makes logrotate remove rotated files after 7 days. Tip For a complete description of the logrotate configuration options, see the Linux Logrotate documentation. Since logrotate is usually executed automatically as a cron job, verify that there is a logrotate entry in cron (for example, /etc/cron.daily/logrotate) similar to: #!/bin/sh /usr/sbin/logrotate -s /var/lib/logrotate/logrotate.status /etc/logrotate.conf EXITVALUE=$? if [ $EXITVALUE != 0 ]; then /usr/bin/logger -t logrotate \"ALERT exited abnormally with [$EXITVALUE]\" fi exit 0 Copy Smart verbose mode For infrastructure agent versions 1.9.0 or higher, you can enable smart verbose mode for logs. Smart verbose mode prevents debug messages being logged until an error message is logged. Once an error has been logged, the cached debug messages are logged, but only the most recent number of configured debug messages. For example, if you have a configured limit of 10, after an error is logged, only the 10 most recent debug messages are logged, and older logs are discarded. For more information on how to enable smart verbose mode and the debug message limit, see Infrastructure configuration settings. Logging before Infrastructure agent v1.4.9 Here is a comparison of functionality for Infrastructure agent versions before and after v1.4.9: Agent v1.4.9 and higher Before v1.4.9 Foreground mode logged. The agent couldn't log some entries in foreground mode because the logging service wasn't able to write data until the agent was completely configured. Logs in text and JSON formats. Logs in text only. Logs displayed as inline text. Logs displayed as static literals in a single, decontextualized line. Integration log management Integrations write JSON payloads into STDOUT and plain-text (JSON structured in the future) logs into STDERR. The infrastructure agent handles integration STDERR lines and forward this output into the agent one, usually the service log. Agent handles each STDERR line as follows: when agent runs in verbose mode: it just forwards the full STDERR line as a DEBUG agent log entry placing integration line contexts within the ` msg ` field. otherwise: it parses the line against the expected format (see below) and only logs as agent ERROR level, entries produced by integrations with ` fatal ` or ` error ` severity levels. In this case fields are extracted and forwarded in structured manner (therefore if JSON output is enabled for the agent fields become queryable. Integration STDERR expected format A line is expected to be a list of key-value pairs separated by an equal character. Keys can contain any character, whereas values can have three different formats: string: < quote>any character including escaped quotes \\ \" < quote> map: & { any character} word: any character except spaces Internally agent used this regex to extract the fields: ([^\\s]*?)=(\".*?[^\\\\]\"|&{.*?}|[^\\s]*) Copy For instance, this line: time=\"2015-03-26T01:27:38-04:00\" level=error msg=\"Foo bar baz\" foo=bar Copy Will generate a structured agent log line with these fields: - \"time\": \"2015-03-26T01:27:38-04:00\" - \"level\": \"error\" - \"msg\": \"Foo bar baz\" - \"foo\": \"bar\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.55469,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> agent <em>logging</em> behavior",
        "sections": "<em>Infrastructure</em> agent <em>logging</em> behavior",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "New Relic&#x27;s <em>infrastructure</em> agent gathers its own data as well as integrations&#x27;s <em>logs</em> and consolidates them in a single source. By default, <em>logs</em> appear in standard-output and are added to a <em>log</em> file. To disable <em>logs</em> in standard output, see the agent&#x27;s config options. Logging severity levels"
      },
      "id": "603eb3a228ccbc6badeba7a5"
    },
    {
      "sections": [
        "Incorrect host name reported",
        "Problem",
        "Solution",
        "Restart the agent with SystemD",
        "Restart the agent with System V",
        "Restart the agent with Upstart",
        "Restart the agent in Windows",
        "Cause"
      ],
      "title": "Incorrect host name reported",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "d6a81c3fae24464898bea92df4c6a57945b6c731",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/incorrect-host-name-reported/",
      "published_at": "2021-06-14T21:19:46Z",
      "updated_at": "2021-05-16T07:48:02Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem The agent is working, but the infrastructure monitoring UI shows the wrong hostname. Solution To set the correct hostname, try the following steps: Edit the newrelic-infra.yml configuration file and add the override_hostname option, whose value is your expected hostname. For example: override_hostname: correct-host.domain.com Copy Use your init system to restart the agent service: Restart the agent with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: sudo systemctl restart newrelic-infra Copy Restart the agent with System V Use System V commands with Debian 7: sudo /etc/init.d/newrelic-infra restart Copy Restart the agent with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10 or lower: sudo initctl restart newrelic-infra Copy Restart the agent in Windows net stop newrelic-infra net start newrelic-infra Copy Cause The New Relic infrastructure agent tries to resolve its fully qualified domain name against a domain name server, which may not be properly configured or not controlled by the same user as the New Relic infrastructure agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.70099,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem The agent is working, but the <em>infrastructure</em> <em>monitoring</em> UI shows the wrong hostname. Solution To set the correct hostname, try the following steps: Edit the newrelic-infra.yml configuration file and add the override_hostname option, whose value is your expected hostname. For example"
      },
      "id": "6043fd9028ccbc23872c60c5"
    }
  ],
  "/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-logs/infrastructure-agent-logging-behavior": [
    {
      "sections": [
        "The agent is not starting and there are no logs",
        "Problem",
        "Solution",
        "Check requiretty",
        "Important",
        "Review log permissions"
      ],
      "title": "The agent is not starting and there are no logs",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot logs"
      ],
      "external_id": "fefb6cf577c3c825a6908eba8e378de3ceca4cd7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/agent-not-starting-there-are-no-logs/",
      "published_at": "2021-06-14T21:17:52Z",
      "updated_at": "2021-03-16T08:35:01Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem The infrastructure agent is not starting, and logs are not created. Solution Here are some troubleshooting options for non-root users if the infrastructure agent is not starting and there are no logs: Check requiretty To see if requiretty is causing logging issues: In /var/log/messages or /var/log/syslog, look for the message sudo: sorry, you must have a tty to run sudo . Important When using old Linux versions, sometimes the nri-agent user fails to execute a service because it does not have any TTY attached. If you find this message, edit your /etc/sudoers file with the visudo command and comment or remove the following line: Defaults requiretty Save and exit the file. Restart the newrelic-infra service. Review log permissions Check the agent's permission to open log_file. It's possible that the log file you are using was created when the agent was running as root, and now the nri-agent user does not have permissions to write it. To solve this, try one of these options: Change the owner of the log file. Change the log_file entry in the /etc/newrelic-infra.yml configuration file. Our installation scripts create the /var/log/newrelic-infra/ folder for that purpose, so we recommend the following value: log_file: /var/log/newrelic-infra/newrelic-infra.log Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.56215,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "The agent is not starting and there are no <em>logs</em>",
        "sections": "The agent is not starting and there are no <em>logs</em>",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem The <em>infrastructure</em> agent is not starting, and <em>logs</em> are not created. Solution Here are some <em>troubleshooting</em> options for non-root users if the <em>infrastructure</em> agent is not starting and there are no <em>logs</em>: Check requiretty To see if requiretty is causing logging issues: In &#x2F;var&#x2F;<em>log</em>&#x2F;messages"
      },
      "id": "603eba9e28ccbc5f64eba786"
    },
    {
      "sections": [
        "Generate logs for troubleshooting the infrastructure agent",
        "Problem",
        "Important",
        "Solution",
        "Smart verbose mode",
        "Forward the agent logs to New Relic Logs",
        "Notes for specific systems",
        "Containerized agent on CoreOS"
      ],
      "title": "Generate logs for troubleshooting the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot logs"
      ],
      "external_id": "a0c2ca22e3fca2b3add8c94d211adffce686661c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-logs/generate-logs-troubleshooting-infrastructure/",
      "published_at": "2021-06-15T02:30:07Z",
      "updated_at": "2021-03-16T06:35:54Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When troubleshooting your infrastructure agent, generate verbose logs for a few minutes to find and investigate errors. This can be useful for your own troubleshooting or when working with New Relic Support. Important Verbose logging generates a lot of data very quickly. When finished generating logs, be sure to set verbose: 0 to reduce disk space consumption. If you have New Relic infrastructure agent 1.4.0 or higher, you can automate this process by using the newrelic-infra-ctl command. For more information, see the troubleshooting binary documentation. Solution Generating verbose log files requires editing your configuration file. For a sample config file that includes all applicable settings, see the example template. To generate detailed logs: Step Procedures Edit your newrelic-infra.yml file: Enable verbose logging: verbose: 1. (If you use a containerized infrastructure agent on CoreOS, see system-specific notes.) Set log_file to a convenient log file location. Restart the agent so the agent notices the new settings. Let your host run at normal load for about three minutes to generate sufficient logging data. Return your settings to default: Disable verbose logging by setting verbose: 0 in newrelic-infra.yml. Optional: Disable logging to a custom file by removing the log_file line from newrelic-infra.yml. Restart the agent so the agent notices the new settings. Examine the log file for errors. If you need to send your log file to New Relic Support: Include the line in your log file that contains the agent version: New Relic infrastructure agent version X.YY.ZZZ Copy Attach the log file to your support ticket, along with your newrelic-infra.yml. Smart verbose mode Sometimes errors don't occur until after quite some time has passed. This makes debugging difficult, because typically verbose logs are only enabled for a short period time; otherwise there will be many debug logs. For example, if an error occurs one hour after the infrastructure agent has started, getting debug logs around the time of the error can be tricky or impractical. As of infrastructure agent v1.9.0 or higher, you can use smart verbose mode for logs. Smart verbose mode only logs the most recent debug messages after an error has been logged. This allows you to leave smart verbose mode running until an error occurs, without logging lots of irrelevant debug messages, and only logging the most recent debug messages. (The number of messages is determined by your configuration.) For more information on smart verbose mode, see the Infrastructure agent logging behavior docs, and use the Infrastructure configuration settings documentation for details on how to enable smart verbose mode. Forward the agent logs to New Relic Logs The Infrastructure agent can be configured to send its own logs to New Relic Logs. This can be useful for troubleshooting issues with log forwarding, the Infrastructure agent, or when contacting support. For details on how to enable log forwarding for the Infrastructure agent, see Troubleshoot log forwarding. Notes for specific systems These are some additional notes and requirements for specific systems, used to supplement the general logging instructions: Containerized agent on CoreOS If you are using a containerized infrastructure agent on CoreOS: Choose one of these options to change the log level to verbose: Recommended: Set the environment variable NRIA_VERBOSE to 1. Running this on the command line would look like: -e NRIA_VERBOSE=1 Copy OR Edit the config file to set verbose: 1. (Editing the config file in a container is not recommended, because it requires rebuilding the image twice: once to add verbose logging and once to remove it.) Use journalctl to collect the logs: journalctl -u newrelic-infra > newrelic-infra.log Copy Set the verbose logging level back to 0 after collecting logs for a few minutes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.54811,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Generate <em>logs</em> for <em>troubleshooting</em> the <em>infrastructure</em> agent",
        "sections": "Generate <em>logs</em> for <em>troubleshooting</em> the <em>infrastructure</em> agent",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": " verbose mode. Forward the agent <em>logs</em> to New Relic <em>Logs</em> The <em>Infrastructure</em> agent can be configured to send its own <em>logs</em> to New Relic <em>Logs</em>. This can be useful for <em>troubleshooting</em> issues with <em>log</em> forwarding, the <em>Infrastructure</em> agent, or when contacting support. For details on how to enable <em>log</em> forwarding"
      },
      "id": "603e910028ccbc6304eba76d"
    },
    {
      "sections": [
        "Incorrect host name reported",
        "Problem",
        "Solution",
        "Restart the agent with SystemD",
        "Restart the agent with System V",
        "Restart the agent with Upstart",
        "Restart the agent in Windows",
        "Cause"
      ],
      "title": "Incorrect host name reported",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "d6a81c3fae24464898bea92df4c6a57945b6c731",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/incorrect-host-name-reported/",
      "published_at": "2021-06-14T21:19:46Z",
      "updated_at": "2021-05-16T07:48:02Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem The agent is working, but the infrastructure monitoring UI shows the wrong hostname. Solution To set the correct hostname, try the following steps: Edit the newrelic-infra.yml configuration file and add the override_hostname option, whose value is your expected hostname. For example: override_hostname: correct-host.domain.com Copy Use your init system to restart the agent service: Restart the agent with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: sudo systemctl restart newrelic-infra Copy Restart the agent with System V Use System V commands with Debian 7: sudo /etc/init.d/newrelic-infra restart Copy Restart the agent with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10 or lower: sudo initctl restart newrelic-infra Copy Restart the agent in Windows net stop newrelic-infra net start newrelic-infra Copy Cause The New Relic infrastructure agent tries to resolve its fully qualified domain name against a domain name server, which may not be properly configured or not controlled by the same user as the New Relic infrastructure agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.70099,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem The agent is working, but the <em>infrastructure</em> <em>monitoring</em> UI shows the wrong hostname. Solution To set the correct hostname, try the following steps: Edit the newrelic-infra.yml configuration file and add the override_hostname option, whose value is your expected hostname. For example"
      },
      "id": "6043fd9028ccbc23872c60c5"
    }
  ],
  "/docs/infrastructure/infrastructure-ui-pages/infra-ui-pages/infrastructure-inventory-page-search-your-entire-infrastructure": [
    {
      "sections": [
        "Events heatmap: Examine patterns in time range"
      ],
      "title": "Events heatmap: Examine patterns in time range",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring UI",
        "Infrastructure UI"
      ],
      "external_id": "bc50e789884c9c4eea404d558d4070519a3eab0c",
      "image": "https://docs.newrelic.com/static/96c3e087c9dfb8b4cb4ad72b79c47e94/c1b63/infra-events-timeline.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-ui-pages/events-heatmap-examine-patterns-time-range/",
      "published_at": "2021-06-15T02:33:21Z",
      "updated_at": "2021-03-16T08:35:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "he events heatmap provides a snapshot of the infrastructure events occurring within the same time range as the displayed metrics. The darker the color on the heatmap, the more events occurred during that time period. By comparing the heatmap to the charts on the infrastructure page, you can quickly pinpoint issues in your ecosystem. For example, if a massive CPU spike occurs, you can click on the events heatmap for that time range to find the event that caused it. From there you can dive deeper to uncover the real issue. one.newrelic.com > Infrastructure: The heatmap on Infrastructure monitoring UI pages visually shows patterns with events occurring at the same time period for the displayed metrics. The heatmap appears on several Infrastructure UI pages, including: System Network Processes Storage Events",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.33862,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>UI</em>",
        "body": " <em>monitoring</em> <em>UI</em> pages visually shows patterns with events occurring at the same time period for the displayed metrics. The heatmap appears on several <em>Infrastructure</em> <em>UI</em> pages, including: System Network Processes Storage Events"
      },
      "id": "603e8455196a67833da83dc2"
    },
    {
      "sections": [
        "Infrastructure Events page: Live feed of config changes",
        "Event types",
        "Events page features",
        "Chart data attributes"
      ],
      "title": "Infrastructure Events page: Live feed of config changes",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring UI",
        "Infrastructure UI"
      ],
      "external_id": "e4a87670c8671072ae7cc6531721f46edc7f925d",
      "image": "https://docs.newrelic.com/static/75373d03d819516d3cbe23f1ea65957b/c1b63/infra-events-ui.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-ui-pages/infrastructure-events-page-live-feed-every-config-change/",
      "published_at": "2021-06-14T21:17:53Z",
      "updated_at": "2021-03-11T11:47:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Events page is a live feed of important system and host activity, including inventory change events, configuration changes, and log analytics events. The event feed helps you understand correlations between these events and system performance. Search and filter through your events to decrease the mean time to detect and repair infrastructure issues. You can access the Events page by going to one.newrelic.com > Infrastructure > Events. Event types New Relic collects a variety of change events so you can understand each change in your environment: Events Comments Alert incidents When a violation is opened or closed, New Relic generates an event indicating the host and associated alert condition. Agent connection When an infrastructure agent connects to New Relic, our platform generates an Agent connected event. If New Relic doesn't receive data from an agent for three minutes, the platform generates an Agent disconnected event. Inventory changes These events are generated when inventory data is added, removed, or modified. Select the source icon to to understand which category corresponds to the altered inventory path. For additional details, select an inventory event to see a side-by-side comparison of the old and new state. Inventory events can include: Kernel (includes modules and configuration): Can be added, modified, or deleted. Metadata (includes various additional information about hosts): Can be added, modified, or deleted. Packages: Can be installed, removed, or modified. Services: Can be started, stopped, or restarted. Sessions (includes users): Can be connected or disconnected. Events page features To view the live event feed: Go to one.newrelic.com > Infrastructure > E * *vents. The Events * * page includes a heatmap, which provides a snapshot of the events occurring within the selected time range. one.newrelic.com > Infrastructure > Events: Use the Events to view important, real-time activity in your infrastructure. With the Events page, you can easily search through your event log to quickly find vulnerable packages. If you want to... Do this... Focus on specific events Use the Search events field to look for specific events, config changes or agent installations. To focus on a specific set of events, select or change the filter set. Search within a particular time range Enter a time range to the right of the search bar to investigate events within a specific time range. For example, if you encountered a CPU spike around 11am on the previous day, search Yesterday at 11 am to investigate the possible cause. Compare events with host load, memory, CPU, and more View the events feed on the Hosts page. To compare infrastructure events and performance for a specific time, select a range via the time picker or drag and select a range on a chart. View events specifically related to agents, config, metadata, services, or sessions Group or sort events by selecting the filter icon be the search bar. Drill down into additional details Select an event to view additional details, such as attributes and values. To drill down further, select View in Inventory to see additional details in the Inventory page. View host's alert threshold violation Select the host's Critical icon or Warning icon. Chart data attributes For a technical explanation of the attributes used to populate the Events page, see InfrastructureEvent attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 170.55109,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> Events page: Live feed of config changes",
        "sections": "<em>Infrastructure</em> Events page: Live feed of config changes",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>UI</em>",
        "body": " the mean time to detect and repair <em>infrastructure</em> issues. You can access the Events page by going to one.newrelic.com &gt; <em>Infrastructure</em> &gt; Events. Event types New Relic collects a variety of change events so you can understand each change in your environment: Events Comments Alert incidents When"
      },
      "id": "6043fa6c28ccbc13742c60a5"
    },
    {
      "sections": [
        "Infrastructure monitoring Hosts page",
        "System tab",
        "System tab functions",
        "APM and infrastructure data",
        "Important",
        "Network tab",
        "Network tab functions",
        "Processes tab",
        "Tip",
        "Processes tab functions",
        "Storage tab",
        "Storage tab functions",
        "Docker containers tab",
        "Docker containers tab functions"
      ],
      "title": "Infrastructure monitoring Hosts page",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring UI",
        "Infrastructure UI"
      ],
      "external_id": "41d8a2ac3ecbbdee164fd0bec6ac94bb3e8def64",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-ui-pages/infrastructure-ui/infrastructure-hosts-page/",
      "published_at": "2021-06-15T02:30:08Z",
      "updated_at": "2021-03-09T04:04:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Hosts page to better understand important performance metrics, like resource usage, network and processes performance, and data about your containers. You can filter your hosts by attributes and compare their performance with inventory change events to help determine root causes. You can also set alert notifications to help prevent problems. To view your hosts information, go to one.newrelic.com > Infrastructure > Hosts, then click any of the following tabs: System: Overview of your hosts' performance Network: Bandwidth and error data about your network interfaces Processes: Data about CPU percentage, I/O bytes, and memory usage for individual or groups of processes Storage: Resources' capacity and efficiency, including your devices' overall utilization, disk usage, or I/O operations Docker containers: CPU percentage, I/O bytes, and memory usage for individual or group of containers System tab Here are the default graphs shown on the Hosts page. For additional chart options, select the dropdown for any chart. CPU %: On the System tab, CPU Percent is a derived metric that is part of the SystemSample event. The CPU percentage is not collected by New Relic, but derived from several other metrics. Specifically, the cpuPercent attribute is an aggregation of cpuUserPercent, cpuSystemPercent, cpuIoWaitPercent and cpuStealPercent. Load average five minute: represents an average of the number of tasks waiting to do work on a system over the last 5 minutes. Memory free %: compares the amount of free memory bytes to the amount of used memory bytes. For explanations of different chart metrics, see Default infrastructure attributes and events. Functions for adjusting chart data include: Select different host groups: Use the host filter. Change time range: Use the time picker above the charts, or drag and select a time range on a chart. Change the number of elements on charts: use the Chart shows dropdown. Change data used to order hosts: Use the table below the charts to order the chart elements by different metrics; for example, from highest to lowest CPU user % to lowest, or from lowest to highest Disk free. System tab functions Here are some of the things you can do from the System tab: If you want to... Do this... Filter and group hosts Use filter sets to show only hosts matching certain criteria, or use group by to aggregate the results. Understand host health Use the Health column of the table. To see more details about specific violations, select the health status icons. Find root causes of issues Use the Events heatmap at the top of the page to compare performance to important events happening in your infrastructure. For more, see Events heatmap. Set an alert condition for a metric Mouse over a chart, select and then Create alert. View host's alert threshold violation If present, select the host's Critical icon or Warning icon. APM and infrastructure data If you have APM data associated with your infrastructure data, there are several ways to access your APM data on the Hosts page: Use the hosts filter to filter on hosts running specific applications. In the host list below the charts, select the Application column to filter on specific applications. From the chart selector dropdown beside a chart's name, select one of the application-related charts. Important APM charts in infrastructure monitoring do not have View query or Create alert options like the other infrastructure charts do. For more about using APM and infrastructure monitoring together, see APM data in infrastructure. Network tab The Network page provides real-time visibility into the health and performance of individual hosts, web servers, or other groups of resources across your network. Default charts show bandwidth metrics by packet, bandwidth by bytes, and errors per second. Details about individual interfaces can help you: Examine saturation levels across your network or for selected filter sets. Compare load balances between specific resources. Identify unexpected differences in capacity patterns between similar hosts. Evaluate the top five network errors that New Relic automatically presents for the selected time period. This real-time network data can then help you determine whether to resolve errors by reconfiguring your network, rebalancing the loads, or taking other preventative maintenance actions before needing to make a purchase decision. From the Network tab you can view bandwidth and error data about your network interfaces. The Network page includes an Events heatmap, which provides a snapshot of the events occurring within the same time range as the displayed metrics. For a technical explanation of the attributes used to populate the Network page chart, see NetworkSample attributes. Network tab functions Here are some of the things you can do from the Network tab: If you want to... Do this... Filter and group Use filter sets to show only hosts matching certain criteria, or use Group by to aggregate the results. Select a time range Use the time picker to change the range of time selected. You can also click and drag on the chart to select a custom time range. When you select a time range, it carries over when you go from one infrastructure page to another. Change metrics displayed in chart Use the sorting dropdown to switch what metric the chart is displaying for the chosen process groupings, including: Received Bytes Received Dropped Received Errors Received Packets Transmitted Bytes Transmitted Dropped Transmitted Errors Transmitted Packets Search and filter the list Type in the Search interfaces search bar to filter the list to only those items containing the text you've typed. You can also filter the list by simply selecting the list item or user name you want to filter for. The chosen filters are displayed beside the filter icon above the chart. Add items to chart The chart, by default, displays the top five results. Use the Chart shows dropdown to display more results. To remove an item from a chart, select its name below the chart. Set an alert condition for a metric Mouse over a chart, select and then Create alert. (Not available on APM charts.) View host's alert threshold violation Select the host's Critical icon or Warning icon. Processes tab Important By default, the infrastructure agent doesn't send data about the operating system's processes. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Use the Processes tab to get information about processes running on your hosts, and to set alerts on process metrics. The Processes tab shows data such as CPU percentage, I/O bytes, and memory usage for individual processes or groupings of processes. The page also includes an events heatmap, which provides a snapshot of the events occurring within the same time range as the displayed metrics. Use this information to: Pinpoint processes that are causing performance issues. Create alerts for conditions such as CPU percentage and memory usage. On the Processes page, CPU percent is scoped to individual processes, rather than hosts. Because of this, the CPU percent metric does not take into account the resources of the entire system. Instead, it shows how much of a single CPU core each process is taking. Example Here's an example of how to pinpoint an issue and set an alert: You notice on the Hosts page that a cluster has a CPU percentage much higher than normal. You go to the Processes page and filter down to that cluster's processes. You notice that several instances of the same process have excessive CPU percentage. After fixing the issue, you decide to create an alert condition that triggers when the CPU percentage for that process type exceeds a certain threshold. For a technical explanation of the attributes used to populate the Processes page chart, see ProcessSample attributes. Tip You cannot start, stop, or restart processes from the UI. Instead, follow standard procedures to start, stop, check, or restart the infrastructure agent manually. Processes tab functions Here are some of the things you can do from the Processes tab: If you want to... Do this... Only show hosts matching certain criteria Use filter sets. Aggregate results or group by host attributes Use Group by to change how the processes are grouped in the chart and the list. The dropdown contains host-related attributes such as hostID and entityName. If you are monitoring AWS EC2 instances, EC2-related attributes such as awsRegion will be available. Select a time range Use either of these options: Select any of the time picker options at the top of the page. Click and drag on the chart to select a custom time range. After you select a time range, it carries over from one infrastructure page to another. View Docker metrics To view process usage by Docker containers, see Docker instrumentation. Change charts Select the dropdown beside the chart's name to switch what metric the chart displays. Choices include: Memory: Resident or virtual size CPU percentage Disk I/O: Read or write Search and filter the list Use either of these options: Type in the Search processes search bar. Select the list item or user name you want to filter for. The selected filters appear beside the filter icon above the chart, where you can select and remove them as needed. Set an alert condition for a metric Mouse over a chart. Select and then Create alert. (Not available on APM charts.) View host's alert threshold violation Select the host's Critical icon or Warning icon. Storage tab The Storage page allows you to monitor your resources' capacity and efficiency, including your devices' overall utilization, disk usage, or I/O operations. This can help you to: Examine unexpected patterns; for example, a cluster of mirrored machines that do not process I/O tasks uniformly. Monitor usage levels before disk space completely runs out. Set alert conditions to notify you about problems with one or more hosts; for example, long processing times for read or write operations, disk availability or utilization based on percentage or bytes, etc. Make informed decisions about where to redistribute hosts with higher or lower than normal processing requests. Use data to help plan for additions or changes to your infrastructure budget before an emergency arises. The Storage page includes an Events heatmap, which provides a snapshot of the events occurring within the same time range as the displayed metrics. For a technical explanation of the attributes used to populate the Storage page chart, see StorageSample attributes. Storage tab functions Here are some of the things you can do from the Storage tab: If you want to... Do this... Filter and group Use filter sets to show only hosts matching certain criteria, or use Group by to aggregate the results. Select a time range Use the time picker on the upper right to change the range of time selected. You can also click and drag on the chart to select a custom time range. When you select a time range, it carries over when you go from one infrastructure page to another. Change metrics displayed in chart Use the sorting dropdown to switch what metric the chart is displaying for the chosen process groupings. Choices include: Total Utilization % Read Utilization % Write Utilization % Disk Used Bytes Disk Free Bytes I/O Read Operations I/O Write Operations Search and filter the list Type in the Search devices search bar to filter the list. You can also filter the list by simply selecting the list item or user name you want to filter for. The chosen filters are displayed beside the filter icon above the chart. Add/remove chart items The chart, by default, displays the top five results. Use the Chart shows dropdown to display more results. To remove an item, select its name below the chart. Set an alert condition for a metric Mouse over a chart. Select and then Create alert. (Not available on APM charts.) View host's alert threshold violation Select the host's Critical icon or Warning icon. Docker containers tab Use the Docker containers tab to get information about the containers running on your hosts, and to set alerts on container metrics. The Docker containers tab shows data such as CPU percentage, I/O bytes, and memory usage for individual containers or groupings of containers. The page also includes an events heatmap, which provides a snapshot of the events occurring within the same time range as the displayed metrics. Use this information to: Identify containers that are experiencing performance issues. Create alerts for conditions such as CPU percentage and memory usage. Docker containers tab functions Here are some of the things you can do from the Docker containers tab: If you want to... Do this... Only show hosts matching certain criteria Use filter sets. Aggregate results or group by host attributes Use Group by to change how the processes are grouped in the chart and the list. The dropdown contains host-related attributes such as image and operatingSystem. Select a time range Use either of these options: Select any of the time picker options at the top of the page. Click and drag on the chart to select a custom time range. After you select a time range, it carries over from one infrastructure page to another. View Docker integration dashboard To open the Docker integration dashboard, click the Dashboard link above the data table. Change charts Select the dropdown beside the chart's name to switch what metric the chart displays. Choices include: CPU: Used cores, kernel percentage Memory: Size limit, cache bytes I/O: Write count per second, total bytes Network: Errors per second, packets Process: Process count, restart count Search and filter the list Use either of these options: Type in the Search processes search bar. Select the list item or user name you want to filter for. The selected filters appear beside the filter icon above the chart, where you can select and remove them as needed. Set an alert condition for a metric Mouse over a chart. Select and then Create alert. View host's alert threshold violation Select the host's Critical icon or Warning icon.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 170.20055,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>monitoring</em> Hosts page",
        "sections": "<em>Infrastructure</em> <em>monitoring</em> Hosts page",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>UI</em>",
        "body": "-related charts. Important APM charts in <em>infrastructure</em> <em>monitoring</em> do not have View query or Create alert options like the other <em>infrastructure</em> charts do. For more about using APM and <em>infrastructure</em> <em>monitoring</em> together, see APM data in <em>infrastructure</em>. Network tab The Network page provides real-time"
      },
      "id": "60440a6d196a675f6c960f58"
    }
  ],
  "/docs/infrastructure/infrastructure-ui-pages/infrastructure-ui/infrastructure-hosts-page": [
    {
      "sections": [
        "Events heatmap: Examine patterns in time range"
      ],
      "title": "Events heatmap: Examine patterns in time range",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring UI",
        "Infrastructure UI"
      ],
      "external_id": "bc50e789884c9c4eea404d558d4070519a3eab0c",
      "image": "https://docs.newrelic.com/static/96c3e087c9dfb8b4cb4ad72b79c47e94/c1b63/infra-events-timeline.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-ui-pages/events-heatmap-examine-patterns-time-range/",
      "published_at": "2021-06-15T02:33:21Z",
      "updated_at": "2021-03-16T08:35:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "he events heatmap provides a snapshot of the infrastructure events occurring within the same time range as the displayed metrics. The darker the color on the heatmap, the more events occurred during that time period. By comparing the heatmap to the charts on the infrastructure page, you can quickly pinpoint issues in your ecosystem. For example, if a massive CPU spike occurs, you can click on the events heatmap for that time range to find the event that caused it. From there you can dive deeper to uncover the real issue. one.newrelic.com > Infrastructure: The heatmap on Infrastructure monitoring UI pages visually shows patterns with events occurring at the same time period for the displayed metrics. The heatmap appears on several Infrastructure UI pages, including: System Network Processes Storage Events",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.33862,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>UI</em>",
        "body": " <em>monitoring</em> <em>UI</em> pages visually shows patterns with events occurring at the same time period for the displayed metrics. The heatmap appears on several <em>Infrastructure</em> <em>UI</em> pages, including: System Network Processes Storage Events"
      },
      "id": "603e8455196a67833da83dc2"
    },
    {
      "sections": [
        "Infrastructure Inventory page: Search your entire infrastructure",
        "Inventory item naming",
        "Tip",
        "Page functions",
        "Filter the data",
        "Search inventory",
        "View inventory item details",
        "View host's alert threshold violations",
        "Inventory data collection",
        "Linux built-in agent data",
        "Windows built-in agent data",
        "Amazon AWS cloud integrations inventory",
        "Inventory data retention",
        "Chart data attributes"
      ],
      "title": "Infrastructure Inventory page: Search your entire infrastructure",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring UI",
        "Infrastructure UI"
      ],
      "external_id": "64aef10b24b74ac3c0f070358d37f3cab099e5b2",
      "image": "https://docs.newrelic.com/static/2d17c192725956ff09b5e987be5b997b/747d8/inventory-name-source-path.jpg",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-ui-pages/infra-ui-pages/infrastructure-inventory-page-search-your-entire-infrastructure/",
      "published_at": "2021-06-15T02:30:08Z",
      "updated_at": "2021-03-11T12:47:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic can collect detailed information about a system's configuration per host, including system modules, configuration files, metadata, packages, services, user sessions, etc. The Inventory page provides a real-time, filterable, searchable view into each host's configuration. Use the Inventory page to: Ensure a version update was applied successfully across all your hosts. Audit version discrepancies across your hosts. Quickly identify which hosts require an update to fix a security vulnerability. To view and search your inventory data: Go to one.newrelic.com > Infrastructure > Inventory. Inventory item naming The infrastructure inventory is a qualified namespace (structured like a directory) that organizes inventory items into names that resemble a source path. The inventory item name is comprised of three elements: Element Description Category Basic, top level type of data source, typically based on its role in the system. Common examples include config, package, kernel, user session, services, and modules. Source The specific data source for the inventory item. Label The name of the specific inventory item; for example, the filename, package name, or system setting name. Tip For detailed metadata and other information about your hosts, use tagging with New Relic One. Page functions Use Inventory page functions to find information about a particular item on your hosts: Filter the data Use Filter Sets to show only hosts matching certain criteria. Search inventory Search for an inventory item using the search function. For example, if you want to find information related to OpenSSL, search openssl. The search term is matched again the inventory item name. View inventory item details Inventory item details provide host and system information for each host it resides on according to the New Relic inventory item name. If you have different versions of the same item on other hosts, New Relic detects that and flags them on the Inventory page with the variant hosts label and lists each host running each version. Item details are attributes (key/value pairs) that are dictated by their source. Specific attributes are generally stable over time, but new ones may be added and others could be deprecated. Attributes carry the critical metadata that are at the heart of each inventory item. Common inventory item attributes include: Variant hosts (hostname) Architecture Description Essential Priority Status Version View host's alert threshold violations To view one or more host's alert threshold violations, select the host's Critical icon or Warning icon. Inventory data collection Inventory is collected from the infrastructure agent's built-in data collectors, Amazon Elastic Compute Cloud (EC2) integrations, agent integrations provided by New Relic, and customer-built integrations. The data appears on the Inventory page and in other places within the Infrastructure monitoring's user interface. Linux built-in agent data The infrastructure agent collects this data for Linux systems. Category Source Data collected using... applications apm APM Language Agent metadata config selinux sestatus -b, semodule -l selinux-policies sestatus -b, semodule -l selinux-modules sestatus -b, semodule -l sshd /etc/sshd_config (PermitRootLogin, PermitEmptyPasswords, PasswordAuthentication, and ChallengeResponseAuthentication only) kernel modules /sbin/modinfo, /sbin/lsmod, /proc/modules sysctl /proc/sys metadata agent_config Agent's complete config file attributes Agent's custom_attributes host_aliases Agent's display_name, Cloud provider instance-id, os.Hostname(), hostname -f, hostname cloud_security_groups Cloud provider security-groups system uptime -s, /etc/redhat-release, /proc/cpuinfo, /etc/os-release, /proc/sys/kernel/random/boot_id, /proc/sys/kernel/osrelease, /sys/class/dmi/id/product_uuid, /sys/devices/virtual/dmi/id/sys_vendor, /sys/devices/virtual/dmi/id/product_name facter facter -p -j services daemontool ps -e, svstat systemd initctl list upstart systemctl -l, systemctl show, modinfo, lsmod supervisord /var/run/supervisor.sock unix socket connection, supervisor.getAllProcessInfo pidfile var/run, find -L -name, /proc/N/status, /proc/N/stat sessions users who system network_interfaces net.Interfaces() packages dpkg dpkg-query -W -f rpm rpm -qa Windows built-in agent data The infrastructure agent collects this data for Windows systems. Category Source Data collected using... applications apm APM language agent metadata metadata agent_config Agent's complete config file attributes Agent's custom_attributes host_aliases Agent's display_name, Cloud provider instance-id, os.Hostname(), Registry (SYSTEM \\ CurrentControlSet \\ Services \\ Tcpip \\ Parameters (Domain, DhcpDomain, Hostname) system kernel32.dll (GetPhysicallyInstalledSystemMemory), WMI (Win32_OperatingSystem, Win32_Processor), os.Hostname() services windows_services WMI (Win32_Service WHERE State = \"Running\" AND StartMode = \"Auto\") system network_interfaces net.Interfaces() packages windows_programs Registry (SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Uninstall\\, SOFTWARE\\WOW6432Node\\Microsoft\\Windows\\CurrentVersion\\Uninstall\\) windows_updates WMI (Win32_QuickFixEngineering) (off by default) Amazon AWS cloud integrations inventory Data collected varies by Amazon Elastic Compute Cloud (EC2) integration. For more information, see New Relic's individual Amazon Integrations documentation. Inventory data retention Inventory data is real-time. If a host stops reporting, its inventory data still displays for up to 24 hours. Chart data attributes For a technical explanation about attributes used to populate the Inventory page, see Default infrastructure attributes and events. This includes a summary of common events by operating system.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 170.55753,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> Inventory page: Search your entire <em>infrastructure</em>",
        "sections": "<em>Infrastructure</em> Inventory page: Search your entire <em>infrastructure</em>",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>UI</em>",
        "body": ", Amazon Elastic Compute Cloud (EC2) integrations, agent integrations provided by New Relic, and customer-built integrations. The data appears on the Inventory page and in other places within the <em>Infrastructure</em> <em>monitoring</em>&#x27;s user interface. Linux built-in agent data The <em>infrastructure</em> agent collects"
      },
      "id": "60440a6d64441fdf50378ee7"
    },
    {
      "sections": [
        "Infrastructure Events page: Live feed of config changes",
        "Event types",
        "Events page features",
        "Chart data attributes"
      ],
      "title": "Infrastructure Events page: Live feed of config changes",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring UI",
        "Infrastructure UI"
      ],
      "external_id": "e4a87670c8671072ae7cc6531721f46edc7f925d",
      "image": "https://docs.newrelic.com/static/75373d03d819516d3cbe23f1ea65957b/c1b63/infra-events-ui.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-ui-pages/infrastructure-events-page-live-feed-every-config-change/",
      "published_at": "2021-06-14T21:17:53Z",
      "updated_at": "2021-03-11T11:47:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Events page is a live feed of important system and host activity, including inventory change events, configuration changes, and log analytics events. The event feed helps you understand correlations between these events and system performance. Search and filter through your events to decrease the mean time to detect and repair infrastructure issues. You can access the Events page by going to one.newrelic.com > Infrastructure > Events. Event types New Relic collects a variety of change events so you can understand each change in your environment: Events Comments Alert incidents When a violation is opened or closed, New Relic generates an event indicating the host and associated alert condition. Agent connection When an infrastructure agent connects to New Relic, our platform generates an Agent connected event. If New Relic doesn't receive data from an agent for three minutes, the platform generates an Agent disconnected event. Inventory changes These events are generated when inventory data is added, removed, or modified. Select the source icon to to understand which category corresponds to the altered inventory path. For additional details, select an inventory event to see a side-by-side comparison of the old and new state. Inventory events can include: Kernel (includes modules and configuration): Can be added, modified, or deleted. Metadata (includes various additional information about hosts): Can be added, modified, or deleted. Packages: Can be installed, removed, or modified. Services: Can be started, stopped, or restarted. Sessions (includes users): Can be connected or disconnected. Events page features To view the live event feed: Go to one.newrelic.com > Infrastructure > E * *vents. The Events * * page includes a heatmap, which provides a snapshot of the events occurring within the selected time range. one.newrelic.com > Infrastructure > Events: Use the Events to view important, real-time activity in your infrastructure. With the Events page, you can easily search through your event log to quickly find vulnerable packages. If you want to... Do this... Focus on specific events Use the Search events field to look for specific events, config changes or agent installations. To focus on a specific set of events, select or change the filter set. Search within a particular time range Enter a time range to the right of the search bar to investigate events within a specific time range. For example, if you encountered a CPU spike around 11am on the previous day, search Yesterday at 11 am to investigate the possible cause. Compare events with host load, memory, CPU, and more View the events feed on the Hosts page. To compare infrastructure events and performance for a specific time, select a range via the time picker or drag and select a range on a chart. View events specifically related to agents, config, metadata, services, or sessions Group or sort events by selecting the filter icon be the search bar. Drill down into additional details Select an event to view additional details, such as attributes and values. To drill down further, select View in Inventory to see additional details in the Inventory page. View host's alert threshold violation Select the host's Critical icon or Warning icon. Chart data attributes For a technical explanation of the attributes used to populate the Events page, see InfrastructureEvent attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 170.55109,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> Events page: Live feed of config changes",
        "sections": "<em>Infrastructure</em> Events page: Live feed of config changes",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>UI</em>",
        "body": " the mean time to detect and repair <em>infrastructure</em> issues. You can access the Events page by going to one.newrelic.com &gt; <em>Infrastructure</em> &gt; Events. Event types New Relic collects a variety of change events so you can understand each change in your environment: Events Comments Alert incidents When"
      },
      "id": "6043fa6c28ccbc13742c60a5"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-aws-elastic-beanstalk": [
    {
      "sections": [
        "Configure the infrastructure agent with Puppet",
        "Requirements",
        "Module description",
        "Run newrelic-infra module",
        "Install the infrastructure agent with the module",
        "Puppet parameters",
        "For more help"
      ],
      "title": "Configure the infrastructure agent with Puppet",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Config management tools"
      ],
      "external_id": "d78919080b3cac0164fd79d2f4e4c36009e0711a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-puppet/",
      "published_at": "2021-06-14T20:59:24Z",
      "updated_at": "2021-03-16T08:31:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to use Puppet to install and configure New Relic's infrastructure agent using the newrelic-infra module. For an explanation of how to use Puppet, see Puppet documentation. This is a community-supported effort. Here we provide basic information needed to use this configuration management tool. Detailed configuration will have to conform to your company standards. Requirements The Infrastructure Puppet module has these requirements: Infrastructure-supported Linux operating systems Puppet version 3.0 or higher Module description Use the newrelic-infra module to: Add the New Relic's infrastructure agent package repository source. Install, configure, and manage the New Relic infrastructure agent. The New Relic Puppet module is available on Puppet Forge. Run newrelic-infra module To run the default newrelic-infra module, declare the main ::agent class. Install the infrastructure agent with the module All interactions with newrelic-infra are done through the main agent class. To install New Relic's infrastructure agent using Puppet, use: class { 'newrelic_infra::agent': ensure => 'latest', license_key => 'YOUR_LICENSE_KEY', } Copy Puppet parameters Here are the parameters for the newrelic_infra::agent public class: Parameter Parameter description custom_configs A hash of key-value pairs. Corresponds directly with the available general configuration settings. ensure Specifies the Infrastructure agent ensure status. Valid values include: 'latest' - (default) Installs the latest agent version 'absent' - Uninstalls the agent VERSION_STRING - A string containing a specific version to pin license_key Specifies the New Relic license key to use. For more help If you need additional help, file an issue at newrelic/infrastructure-agent-puppet on GitHub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 341.27094,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure the <em>infrastructure</em> <em>agent</em> with Puppet",
        "sections": "<em>Install</em> the <em>infrastructure</em> <em>agent</em> with the module",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Read on to learn how to use Puppet to <em>install</em> and configure New Relic&#x27;s <em>infrastructure</em> <em>agent</em> using the newrelic-infra module. For an explanation of how to use Puppet, see Puppet documentation. This is a community-supported effort. Here we provide basic information needed to use this configuration"
      },
      "id": "603e88b4e7b9d299092a07d9"
    },
    {
      "sections": [
        "Configure the infrastructure agent using Chef",
        "Compatibility and requirements",
        "Chef recipes",
        "Chef attributes",
        "default\\['newrelic_infra']\\['config']\\['license_key'] (REQUIRED)",
        "default\\['newrelic_infra']\\['packages']\\['agent']\\['action']",
        "default\\['newrelic_infra']\\['packages']\\['agent']\\['retries']",
        "default\\['newrelic_infra']\\['packages']\\['agent']\\['version']",
        "Use the basic recipe",
        "For more help"
      ],
      "title": "Configure the infrastructure agent using Chef",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Config management tools"
      ],
      "external_id": "c73f19ee6533c7028bdf2ba595ea88436df6c5c6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-using-chef/",
      "published_at": "2021-06-15T02:32:22Z",
      "updated_at": "2021-03-13T07:15:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to use New Relic's Chef recipes to install and configure New Relic's infrastructure agent. For instructions on how to use Chef recipes, see the Chef documentation. The New Relic cookbook is available from the public Chef Supermarket. This is a community-supported effort. Compatibility and requirements The Infrastructure Chef recipe has the following requirements: Chef versions 12 or higher Supports all operating systems compatible with the infrastructure agent Chef recipes Infrastructure monitoring has one default recipe: default. Include this recipe to install and configure the infrastructure agent. If this recipe detects an unsupported platform or version, the Chef run fails. Configuration depends on your specific setup and standards. Chef attributes The default recipe supplies the following Chef attributes: default\\['newrelic_infra']\\['config']\\['license_key'] (REQUIRED) Type String Default (none) Defines your New Relic license key. default\\['newrelic_infra']\\['packages']\\['agent']\\['action'] Type String Default install Valid values install, upgrade, or remove Select what type of package resource actions action you want to perform: install: Installs the infrastructure agent. If [agent_version] is specified, that version will be installed. The first time the cookbook runs on each host, it will install the latest infrastructure agent. However, the agent will not be upgraded with install on subsequent Chef runs. Use upgrade to install newer versions. upgrade: Upgrades hosts to the latest infrastructure agent version. remove: Uninstalls the infrastructure agent. default\\['newrelic_infra']\\['packages']\\['agent']\\['retries'] Type Integer Default 0 The number of times to catch exceptions and retry the resource. default\\['newrelic_infra']\\['packages']\\['agent']\\['version'] Type String Default (none) Use with 'install' to set a specific agent version. If no value is set, the recipe defaults to the latest agent version. Use the basic recipe The New Relic cookbook is available from the public Chef Supermarket. To install and configure New Relic's infrastructure agent using Chef: Add the newrelic-infra dependency in your own Chef metadata.rb or Berksfile. Set the New Relic license key attribute. For example, add the following to your recipes/default.rb: default['newrelic_infra']['config']['license_key'] = 'YOUR_LICENSE_KEY' Copy Optional: To control version usage and updating, customize the recipe with Chef attributes. Include the default New Relic recipe by using include_recipe ‘newrelic-infra::default' or by adding the recipe to your run list. For more help If you need additional help, file an issue at newrelic/infrastructure-agent-chef on GitHub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 340.26974,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure the <em>infrastructure</em> <em>agent</em> using Chef",
        "sections": "Configure the <em>infrastructure</em> <em>agent</em> using Chef",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Read on to learn how to use New Relic&#x27;s Chef recipes to <em>install</em> and configure New Relic&#x27;s <em>infrastructure</em> <em>agent</em>. For instructions on how to use Chef recipes, see the Chef documentation. The New Relic cookbook is available from the public Chef Supermarket. This is a community-supported effort"
      },
      "id": "60440aa264441f8cff378ee5"
    },
    {
      "sections": [
        "Configure the infrastructure agent using Ansible",
        "Sample code",
        "Compatibility and requirements",
        "Set up Ansible with New Relic",
        "Tip",
        "Role configuration variables",
        "For more help"
      ],
      "title": "Configure the infrastructure agent using Ansible",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Config management tools"
      ],
      "external_id": "1f13326e09d6da78f08f645bc069c22342fbac6c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-using-ansible/",
      "published_at": "2021-06-15T02:31:17Z",
      "updated_at": "2021-03-13T02:47:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's Ansible role to install and configure our infrastructure monitoring agent. For instructions on how to use Ansible, see the Ansible documentation. This is a community-supported effort. Sample code New Relic provides configuration management sample code to help you install our infrastructure monitoring agent using workflows and tools that are common with many Ops teams. This is a basic Ansible role and is intended to be used as a starting place for creating your own customized workflow. Configuration depends on your specific setup and standards. To view an Ansible sample role and more integration information, see the Ansible Galaxy documentation. Compatibility and requirements The Ansible role with New Relic's infrastructure monitoring agent requires a supported Linux operating system. Set up Ansible with New Relic Tip To use Ansible configurations and infrastructure monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. The newrelic.newrelic-infra role: Adds the New Relic infrastructure agent package repository source. Installs and configures the infrastructure agent. To get started using this role: Include the role in your playbook. Customize the required variables. All typical interactions with newrelic.newrelic-infra use role configuration. Here is an example of configuring your role to install the infrastructure agent: - hosts: ap_northeast_1 roles: - name: newrelic.newrelic-infra vars: nrinfragent_os_name: YOUR_OS_NAME nrinfragent_os_version: YOUR_OS_VERSION nrinfragent_config: license_key: YOUR_LICENSE_KEY log_file: /var/log/newrelic/nr-infra.log log_to_stdout: false Copy Role configuration variables Here are available variables for configuring the newrelic.newrelic-infra role: Variable Description nrinfragent_config Required. A map of key-value pairs. Corresponds directly with the available general configuration settings. nrinfragent_state Describes what you want to do with the agent: 'latest': Default. Installs the latest version of the infrastructure agent. 'absent': Uninstall the agent. nrinfragent_version The version of the agent you want to install: '*': Default. Installs the latest version of the infrastructure agent. 'x.y.zzz': String specifying a specific agent version number you want to install; for example, 1.0.682. nrinfragent_os_name Specifies the target OS that the infrastructure agent will be installed on. See the meta/main.yml file for the latest list. nrinfragent_os_version Specifies the OS version of the installer package needed for this machine. See the meta/main.yml file for the latest list. For more help If you need additional help, file an issue at newrelic/infrastructure-agent-ansible on GitHub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 340.21048,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure the <em>infrastructure</em> <em>agent</em> using Ansible",
        "sections": "Configure the <em>infrastructure</em> <em>agent</em> using Ansible",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "You can use New Relic&#x27;s Ansible role to <em>install</em> and configure our <em>infrastructure</em> monitoring <em>agent</em>. For instructions on how to use Ansible, see the Ansible documentation. This is a community-supported effort. Sample code New Relic provides configuration <em>management</em> sample code to help you <em>install</em> our"
      },
      "id": "60440aa3196a675fb6960f5c"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-puppet": [
    {
      "sections": [
        "Configure the infrastructure agent using Chef",
        "Compatibility and requirements",
        "Chef recipes",
        "Chef attributes",
        "default\\['newrelic_infra']\\['config']\\['license_key'] (REQUIRED)",
        "default\\['newrelic_infra']\\['packages']\\['agent']\\['action']",
        "default\\['newrelic_infra']\\['packages']\\['agent']\\['retries']",
        "default\\['newrelic_infra']\\['packages']\\['agent']\\['version']",
        "Use the basic recipe",
        "For more help"
      ],
      "title": "Configure the infrastructure agent using Chef",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Config management tools"
      ],
      "external_id": "c73f19ee6533c7028bdf2ba595ea88436df6c5c6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-using-chef/",
      "published_at": "2021-06-15T02:32:22Z",
      "updated_at": "2021-03-13T07:15:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to use New Relic's Chef recipes to install and configure New Relic's infrastructure agent. For instructions on how to use Chef recipes, see the Chef documentation. The New Relic cookbook is available from the public Chef Supermarket. This is a community-supported effort. Compatibility and requirements The Infrastructure Chef recipe has the following requirements: Chef versions 12 or higher Supports all operating systems compatible with the infrastructure agent Chef recipes Infrastructure monitoring has one default recipe: default. Include this recipe to install and configure the infrastructure agent. If this recipe detects an unsupported platform or version, the Chef run fails. Configuration depends on your specific setup and standards. Chef attributes The default recipe supplies the following Chef attributes: default\\['newrelic_infra']\\['config']\\['license_key'] (REQUIRED) Type String Default (none) Defines your New Relic license key. default\\['newrelic_infra']\\['packages']\\['agent']\\['action'] Type String Default install Valid values install, upgrade, or remove Select what type of package resource actions action you want to perform: install: Installs the infrastructure agent. If [agent_version] is specified, that version will be installed. The first time the cookbook runs on each host, it will install the latest infrastructure agent. However, the agent will not be upgraded with install on subsequent Chef runs. Use upgrade to install newer versions. upgrade: Upgrades hosts to the latest infrastructure agent version. remove: Uninstalls the infrastructure agent. default\\['newrelic_infra']\\['packages']\\['agent']\\['retries'] Type Integer Default 0 The number of times to catch exceptions and retry the resource. default\\['newrelic_infra']\\['packages']\\['agent']\\['version'] Type String Default (none) Use with 'install' to set a specific agent version. If no value is set, the recipe defaults to the latest agent version. Use the basic recipe The New Relic cookbook is available from the public Chef Supermarket. To install and configure New Relic's infrastructure agent using Chef: Add the newrelic-infra dependency in your own Chef metadata.rb or Berksfile. Set the New Relic license key attribute. For example, add the following to your recipes/default.rb: default['newrelic_infra']['config']['license_key'] = 'YOUR_LICENSE_KEY' Copy Optional: To control version usage and updating, customize the recipe with Chef attributes. Include the default New Relic recipe by using include_recipe ‘newrelic-infra::default' or by adding the recipe to your run list. For more help If you need additional help, file an issue at newrelic/infrastructure-agent-chef on GitHub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 340.26974,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure the <em>infrastructure</em> <em>agent</em> using Chef",
        "sections": "Configure the <em>infrastructure</em> <em>agent</em> using Chef",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Read on to learn how to use New Relic&#x27;s Chef recipes to <em>install</em> and configure New Relic&#x27;s <em>infrastructure</em> <em>agent</em>. For instructions on how to use Chef recipes, see the Chef documentation. The New Relic cookbook is available from the public Chef Supermarket. This is a community-supported effort"
      },
      "id": "60440aa264441f8cff378ee5"
    },
    {
      "sections": [
        "Configure the infrastructure agent on AWS Elastic Beanstalk",
        "Requirements",
        "Install the infrastructure agent",
        "Amazon Linux AMI",
        "Amazon Linux 2",
        "Windows",
        "Uninstall the infrastructure agent"
      ],
      "title": "Configure the infrastructure agent on AWS Elastic Beanstalk",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Config management tools"
      ],
      "external_id": "63fee84da30d8fb761d1cab41d31aa7bad9f3adf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-aws-elastic-beanstalk/",
      "published_at": "2021-06-15T02:31:17Z",
      "updated_at": "2021-03-13T03:06:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Amazon Web Services (AWS) Elastic Beanstalk is a dynamic service that allows easy deployment and scalability for your applications. Follow these instructions to deploy the infrastructure agent to the instances launched with your AWS Elastic Beanstalk applications. In addition to deploying the infrastructure agent you can also integrate New Relic with AWS and bring Elastic Beanstalk monitoring information into New Relic. If you haven't already done so, follow these instructions for Amazon integrations with infrastructure monitoring. Requirements Make sure you have a supported Amazon Web Services account. In addition, for any New Relic installation, you will need your New Relic license key. This is a 40-character hexadecimal string that New Relic provides when you sign up for your account. Install the infrastructure agent To install the infrastructure agent on instances launched with AWS Elastic Beanstalk: In the .ebextensions folder inside your Elastic BeanStalk application, create a new file named newrelic.config. Based on the operating system, add the following content to the file, replacing YOUR_LICENSE_KEY with your New Relic license key. Amazon Linux AMI files: \"/etc/newrelic-infra.yml\" : mode: \"000644\" owner: root group: root content: | license_key: YOUR_LICENSE_KEY commands: # Create the agent’s yum repository \"01-agent-repository\": command: sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/6/x86_64/newrelic-infra.repo # # Update your yum cache \"02-update-yum-cache\": command: yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' # # Run the installation script \"03-run-installation-script\": command: sudo yum install newrelic-infra -y Copy Amazon Linux 2 files: \"/etc/newrelic-infra.yml\" : mode: \"000644\" owner: root group: root content: | license_key: YOUR_LICENSE_KEY commands: # Create the agent’s yum repository \"01-agent-repository\": command: sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo # # Update your yum cache \"02-update-yum-cache\": command: yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' # # Run the installation script \"03-run-installation-script\": command: sudo yum install newrelic-infra -y Copy Windows packages: msi: infrastructure: https://download.newrelic.com/infrastructure_agent/windows/newrelic-infra.msi files: \"C:\\\\Program Files\\\\New Relic\\\\newrelic-infra\\\\newrelic-infra.yml\": content: | license_key: YOUR_LICENSE_KEY commands: 01_stop-newrelic-infra: command: net stop newrelic-infra ignoreErrors: true 02_start-newrelic-infra: command: net start newrelic-infra ignoreErrors: true Copy Push your app to Elastic BeanStalk: In general, use eb deploy. If you are still using Eb CLI 2.6 , use git aws.push if required. Optional: Use the AWS Console UI. After a successful setup, it can take up to fifteen minutes before metrics begin to appear in New Relic. View your host's infrastructure pages at one.newrelic.com. Uninstall the infrastructure agent To uninstall the agent, remove newrelic.config from .ebextensions, then deploy using the CLI.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 340.21466,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure the <em>infrastructure</em> <em>agent</em> on AWS Elastic Beanstalk",
        "sections": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " Services account. In addition, for any New Relic installation, you will need your New Relic license key. This is a 40-character hexadecimal string that New Relic provides when you sign up for your account. <em>Install</em> the <em>infrastructure</em> <em>agent</em> To <em>install</em> the <em>infrastructure</em> <em>agent</em> on instances launched with AWS"
      },
      "id": "60440a6d28ccbc37982c60c5"
    },
    {
      "sections": [
        "Configure the infrastructure agent using Ansible",
        "Sample code",
        "Compatibility and requirements",
        "Set up Ansible with New Relic",
        "Tip",
        "Role configuration variables",
        "For more help"
      ],
      "title": "Configure the infrastructure agent using Ansible",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Config management tools"
      ],
      "external_id": "1f13326e09d6da78f08f645bc069c22342fbac6c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-using-ansible/",
      "published_at": "2021-06-15T02:31:17Z",
      "updated_at": "2021-03-13T02:47:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's Ansible role to install and configure our infrastructure monitoring agent. For instructions on how to use Ansible, see the Ansible documentation. This is a community-supported effort. Sample code New Relic provides configuration management sample code to help you install our infrastructure monitoring agent using workflows and tools that are common with many Ops teams. This is a basic Ansible role and is intended to be used as a starting place for creating your own customized workflow. Configuration depends on your specific setup and standards. To view an Ansible sample role and more integration information, see the Ansible Galaxy documentation. Compatibility and requirements The Ansible role with New Relic's infrastructure monitoring agent requires a supported Linux operating system. Set up Ansible with New Relic Tip To use Ansible configurations and infrastructure monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. The newrelic.newrelic-infra role: Adds the New Relic infrastructure agent package repository source. Installs and configures the infrastructure agent. To get started using this role: Include the role in your playbook. Customize the required variables. All typical interactions with newrelic.newrelic-infra use role configuration. Here is an example of configuring your role to install the infrastructure agent: - hosts: ap_northeast_1 roles: - name: newrelic.newrelic-infra vars: nrinfragent_os_name: YOUR_OS_NAME nrinfragent_os_version: YOUR_OS_VERSION nrinfragent_config: license_key: YOUR_LICENSE_KEY log_file: /var/log/newrelic/nr-infra.log log_to_stdout: false Copy Role configuration variables Here are available variables for configuring the newrelic.newrelic-infra role: Variable Description nrinfragent_config Required. A map of key-value pairs. Corresponds directly with the available general configuration settings. nrinfragent_state Describes what you want to do with the agent: 'latest': Default. Installs the latest version of the infrastructure agent. 'absent': Uninstall the agent. nrinfragent_version The version of the agent you want to install: '*': Default. Installs the latest version of the infrastructure agent. 'x.y.zzz': String specifying a specific agent version number you want to install; for example, 1.0.682. nrinfragent_os_name Specifies the target OS that the infrastructure agent will be installed on. See the meta/main.yml file for the latest list. nrinfragent_os_version Specifies the OS version of the installer package needed for this machine. See the meta/main.yml file for the latest list. For more help If you need additional help, file an issue at newrelic/infrastructure-agent-ansible on GitHub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 340.21048,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure the <em>infrastructure</em> <em>agent</em> using Ansible",
        "sections": "Configure the <em>infrastructure</em> <em>agent</em> using Ansible",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "You can use New Relic&#x27;s Ansible role to <em>install</em> and configure our <em>infrastructure</em> monitoring <em>agent</em>. For instructions on how to use Ansible, see the Ansible documentation. This is a community-supported effort. Sample code New Relic provides configuration <em>management</em> sample code to help you <em>install</em> our"
      },
      "id": "60440aa3196a675fb6960f5c"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-using-ansible": [
    {
      "sections": [
        "Configure the infrastructure agent with Puppet",
        "Requirements",
        "Module description",
        "Run newrelic-infra module",
        "Install the infrastructure agent with the module",
        "Puppet parameters",
        "For more help"
      ],
      "title": "Configure the infrastructure agent with Puppet",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Config management tools"
      ],
      "external_id": "d78919080b3cac0164fd79d2f4e4c36009e0711a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-puppet/",
      "published_at": "2021-06-14T20:59:24Z",
      "updated_at": "2021-03-16T08:31:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to use Puppet to install and configure New Relic's infrastructure agent using the newrelic-infra module. For an explanation of how to use Puppet, see Puppet documentation. This is a community-supported effort. Here we provide basic information needed to use this configuration management tool. Detailed configuration will have to conform to your company standards. Requirements The Infrastructure Puppet module has these requirements: Infrastructure-supported Linux operating systems Puppet version 3.0 or higher Module description Use the newrelic-infra module to: Add the New Relic's infrastructure agent package repository source. Install, configure, and manage the New Relic infrastructure agent. The New Relic Puppet module is available on Puppet Forge. Run newrelic-infra module To run the default newrelic-infra module, declare the main ::agent class. Install the infrastructure agent with the module All interactions with newrelic-infra are done through the main agent class. To install New Relic's infrastructure agent using Puppet, use: class { 'newrelic_infra::agent': ensure => 'latest', license_key => 'YOUR_LICENSE_KEY', } Copy Puppet parameters Here are the parameters for the newrelic_infra::agent public class: Parameter Parameter description custom_configs A hash of key-value pairs. Corresponds directly with the available general configuration settings. ensure Specifies the Infrastructure agent ensure status. Valid values include: 'latest' - (default) Installs the latest agent version 'absent' - Uninstalls the agent VERSION_STRING - A string containing a specific version to pin license_key Specifies the New Relic license key to use. For more help If you need additional help, file an issue at newrelic/infrastructure-agent-puppet on GitHub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 341.27094,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure the <em>infrastructure</em> <em>agent</em> with Puppet",
        "sections": "<em>Install</em> the <em>infrastructure</em> <em>agent</em> with the module",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Read on to learn how to use Puppet to <em>install</em> and configure New Relic&#x27;s <em>infrastructure</em> <em>agent</em> using the newrelic-infra module. For an explanation of how to use Puppet, see Puppet documentation. This is a community-supported effort. Here we provide basic information needed to use this configuration"
      },
      "id": "603e88b4e7b9d299092a07d9"
    },
    {
      "sections": [
        "Configure the infrastructure agent using Chef",
        "Compatibility and requirements",
        "Chef recipes",
        "Chef attributes",
        "default\\['newrelic_infra']\\['config']\\['license_key'] (REQUIRED)",
        "default\\['newrelic_infra']\\['packages']\\['agent']\\['action']",
        "default\\['newrelic_infra']\\['packages']\\['agent']\\['retries']",
        "default\\['newrelic_infra']\\['packages']\\['agent']\\['version']",
        "Use the basic recipe",
        "For more help"
      ],
      "title": "Configure the infrastructure agent using Chef",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Config management tools"
      ],
      "external_id": "c73f19ee6533c7028bdf2ba595ea88436df6c5c6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-using-chef/",
      "published_at": "2021-06-15T02:32:22Z",
      "updated_at": "2021-03-13T07:15:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to use New Relic's Chef recipes to install and configure New Relic's infrastructure agent. For instructions on how to use Chef recipes, see the Chef documentation. The New Relic cookbook is available from the public Chef Supermarket. This is a community-supported effort. Compatibility and requirements The Infrastructure Chef recipe has the following requirements: Chef versions 12 or higher Supports all operating systems compatible with the infrastructure agent Chef recipes Infrastructure monitoring has one default recipe: default. Include this recipe to install and configure the infrastructure agent. If this recipe detects an unsupported platform or version, the Chef run fails. Configuration depends on your specific setup and standards. Chef attributes The default recipe supplies the following Chef attributes: default\\['newrelic_infra']\\['config']\\['license_key'] (REQUIRED) Type String Default (none) Defines your New Relic license key. default\\['newrelic_infra']\\['packages']\\['agent']\\['action'] Type String Default install Valid values install, upgrade, or remove Select what type of package resource actions action you want to perform: install: Installs the infrastructure agent. If [agent_version] is specified, that version will be installed. The first time the cookbook runs on each host, it will install the latest infrastructure agent. However, the agent will not be upgraded with install on subsequent Chef runs. Use upgrade to install newer versions. upgrade: Upgrades hosts to the latest infrastructure agent version. remove: Uninstalls the infrastructure agent. default\\['newrelic_infra']\\['packages']\\['agent']\\['retries'] Type Integer Default 0 The number of times to catch exceptions and retry the resource. default\\['newrelic_infra']\\['packages']\\['agent']\\['version'] Type String Default (none) Use with 'install' to set a specific agent version. If no value is set, the recipe defaults to the latest agent version. Use the basic recipe The New Relic cookbook is available from the public Chef Supermarket. To install and configure New Relic's infrastructure agent using Chef: Add the newrelic-infra dependency in your own Chef metadata.rb or Berksfile. Set the New Relic license key attribute. For example, add the following to your recipes/default.rb: default['newrelic_infra']['config']['license_key'] = 'YOUR_LICENSE_KEY' Copy Optional: To control version usage and updating, customize the recipe with Chef attributes. Include the default New Relic recipe by using include_recipe ‘newrelic-infra::default' or by adding the recipe to your run list. For more help If you need additional help, file an issue at newrelic/infrastructure-agent-chef on GitHub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 340.26974,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure the <em>infrastructure</em> <em>agent</em> using Chef",
        "sections": "Configure the <em>infrastructure</em> <em>agent</em> using Chef",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Read on to learn how to use New Relic&#x27;s Chef recipes to <em>install</em> and configure New Relic&#x27;s <em>infrastructure</em> <em>agent</em>. For instructions on how to use Chef recipes, see the Chef documentation. The New Relic cookbook is available from the public Chef Supermarket. This is a community-supported effort"
      },
      "id": "60440aa264441f8cff378ee5"
    },
    {
      "sections": [
        "Configure the infrastructure agent on AWS Elastic Beanstalk",
        "Requirements",
        "Install the infrastructure agent",
        "Amazon Linux AMI",
        "Amazon Linux 2",
        "Windows",
        "Uninstall the infrastructure agent"
      ],
      "title": "Configure the infrastructure agent on AWS Elastic Beanstalk",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Config management tools"
      ],
      "external_id": "63fee84da30d8fb761d1cab41d31aa7bad9f3adf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-aws-elastic-beanstalk/",
      "published_at": "2021-06-15T02:31:17Z",
      "updated_at": "2021-03-13T03:06:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Amazon Web Services (AWS) Elastic Beanstalk is a dynamic service that allows easy deployment and scalability for your applications. Follow these instructions to deploy the infrastructure agent to the instances launched with your AWS Elastic Beanstalk applications. In addition to deploying the infrastructure agent you can also integrate New Relic with AWS and bring Elastic Beanstalk monitoring information into New Relic. If you haven't already done so, follow these instructions for Amazon integrations with infrastructure monitoring. Requirements Make sure you have a supported Amazon Web Services account. In addition, for any New Relic installation, you will need your New Relic license key. This is a 40-character hexadecimal string that New Relic provides when you sign up for your account. Install the infrastructure agent To install the infrastructure agent on instances launched with AWS Elastic Beanstalk: In the .ebextensions folder inside your Elastic BeanStalk application, create a new file named newrelic.config. Based on the operating system, add the following content to the file, replacing YOUR_LICENSE_KEY with your New Relic license key. Amazon Linux AMI files: \"/etc/newrelic-infra.yml\" : mode: \"000644\" owner: root group: root content: | license_key: YOUR_LICENSE_KEY commands: # Create the agent’s yum repository \"01-agent-repository\": command: sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/6/x86_64/newrelic-infra.repo # # Update your yum cache \"02-update-yum-cache\": command: yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' # # Run the installation script \"03-run-installation-script\": command: sudo yum install newrelic-infra -y Copy Amazon Linux 2 files: \"/etc/newrelic-infra.yml\" : mode: \"000644\" owner: root group: root content: | license_key: YOUR_LICENSE_KEY commands: # Create the agent’s yum repository \"01-agent-repository\": command: sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo # # Update your yum cache \"02-update-yum-cache\": command: yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' # # Run the installation script \"03-run-installation-script\": command: sudo yum install newrelic-infra -y Copy Windows packages: msi: infrastructure: https://download.newrelic.com/infrastructure_agent/windows/newrelic-infra.msi files: \"C:\\\\Program Files\\\\New Relic\\\\newrelic-infra\\\\newrelic-infra.yml\": content: | license_key: YOUR_LICENSE_KEY commands: 01_stop-newrelic-infra: command: net stop newrelic-infra ignoreErrors: true 02_start-newrelic-infra: command: net start newrelic-infra ignoreErrors: true Copy Push your app to Elastic BeanStalk: In general, use eb deploy. If you are still using Eb CLI 2.6 , use git aws.push if required. Optional: Use the AWS Console UI. After a successful setup, it can take up to fifteen minutes before metrics begin to appear in New Relic. View your host's infrastructure pages at one.newrelic.com. Uninstall the infrastructure agent To uninstall the agent, remove newrelic.config from .ebextensions, then deploy using the CLI.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 340.21466,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure the <em>infrastructure</em> <em>agent</em> on AWS Elastic Beanstalk",
        "sections": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " Services account. In addition, for any New Relic installation, you will need your New Relic license key. This is a 40-character hexadecimal string that New Relic provides when you sign up for your account. <em>Install</em> the <em>infrastructure</em> <em>agent</em> To <em>install</em> the <em>infrastructure</em> <em>agent</em> on instances launched with AWS"
      },
      "id": "60440a6d28ccbc37982c60c5"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-using-chef": [
    {
      "sections": [
        "Configure the infrastructure agent with Puppet",
        "Requirements",
        "Module description",
        "Run newrelic-infra module",
        "Install the infrastructure agent with the module",
        "Puppet parameters",
        "For more help"
      ],
      "title": "Configure the infrastructure agent with Puppet",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Config management tools"
      ],
      "external_id": "d78919080b3cac0164fd79d2f4e4c36009e0711a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-puppet/",
      "published_at": "2021-06-14T20:59:24Z",
      "updated_at": "2021-03-16T08:31:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to use Puppet to install and configure New Relic's infrastructure agent using the newrelic-infra module. For an explanation of how to use Puppet, see Puppet documentation. This is a community-supported effort. Here we provide basic information needed to use this configuration management tool. Detailed configuration will have to conform to your company standards. Requirements The Infrastructure Puppet module has these requirements: Infrastructure-supported Linux operating systems Puppet version 3.0 or higher Module description Use the newrelic-infra module to: Add the New Relic's infrastructure agent package repository source. Install, configure, and manage the New Relic infrastructure agent. The New Relic Puppet module is available on Puppet Forge. Run newrelic-infra module To run the default newrelic-infra module, declare the main ::agent class. Install the infrastructure agent with the module All interactions with newrelic-infra are done through the main agent class. To install New Relic's infrastructure agent using Puppet, use: class { 'newrelic_infra::agent': ensure => 'latest', license_key => 'YOUR_LICENSE_KEY', } Copy Puppet parameters Here are the parameters for the newrelic_infra::agent public class: Parameter Parameter description custom_configs A hash of key-value pairs. Corresponds directly with the available general configuration settings. ensure Specifies the Infrastructure agent ensure status. Valid values include: 'latest' - (default) Installs the latest agent version 'absent' - Uninstalls the agent VERSION_STRING - A string containing a specific version to pin license_key Specifies the New Relic license key to use. For more help If you need additional help, file an issue at newrelic/infrastructure-agent-puppet on GitHub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 341.27094,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure the <em>infrastructure</em> <em>agent</em> with Puppet",
        "sections": "<em>Install</em> the <em>infrastructure</em> <em>agent</em> with the module",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Read on to learn how to use Puppet to <em>install</em> and configure New Relic&#x27;s <em>infrastructure</em> <em>agent</em> using the newrelic-infra module. For an explanation of how to use Puppet, see Puppet documentation. This is a community-supported effort. Here we provide basic information needed to use this configuration"
      },
      "id": "603e88b4e7b9d299092a07d9"
    },
    {
      "sections": [
        "Configure the infrastructure agent on AWS Elastic Beanstalk",
        "Requirements",
        "Install the infrastructure agent",
        "Amazon Linux AMI",
        "Amazon Linux 2",
        "Windows",
        "Uninstall the infrastructure agent"
      ],
      "title": "Configure the infrastructure agent on AWS Elastic Beanstalk",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Config management tools"
      ],
      "external_id": "63fee84da30d8fb761d1cab41d31aa7bad9f3adf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-aws-elastic-beanstalk/",
      "published_at": "2021-06-15T02:31:17Z",
      "updated_at": "2021-03-13T03:06:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Amazon Web Services (AWS) Elastic Beanstalk is a dynamic service that allows easy deployment and scalability for your applications. Follow these instructions to deploy the infrastructure agent to the instances launched with your AWS Elastic Beanstalk applications. In addition to deploying the infrastructure agent you can also integrate New Relic with AWS and bring Elastic Beanstalk monitoring information into New Relic. If you haven't already done so, follow these instructions for Amazon integrations with infrastructure monitoring. Requirements Make sure you have a supported Amazon Web Services account. In addition, for any New Relic installation, you will need your New Relic license key. This is a 40-character hexadecimal string that New Relic provides when you sign up for your account. Install the infrastructure agent To install the infrastructure agent on instances launched with AWS Elastic Beanstalk: In the .ebextensions folder inside your Elastic BeanStalk application, create a new file named newrelic.config. Based on the operating system, add the following content to the file, replacing YOUR_LICENSE_KEY with your New Relic license key. Amazon Linux AMI files: \"/etc/newrelic-infra.yml\" : mode: \"000644\" owner: root group: root content: | license_key: YOUR_LICENSE_KEY commands: # Create the agent’s yum repository \"01-agent-repository\": command: sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/6/x86_64/newrelic-infra.repo # # Update your yum cache \"02-update-yum-cache\": command: yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' # # Run the installation script \"03-run-installation-script\": command: sudo yum install newrelic-infra -y Copy Amazon Linux 2 files: \"/etc/newrelic-infra.yml\" : mode: \"000644\" owner: root group: root content: | license_key: YOUR_LICENSE_KEY commands: # Create the agent’s yum repository \"01-agent-repository\": command: sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo # # Update your yum cache \"02-update-yum-cache\": command: yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' # # Run the installation script \"03-run-installation-script\": command: sudo yum install newrelic-infra -y Copy Windows packages: msi: infrastructure: https://download.newrelic.com/infrastructure_agent/windows/newrelic-infra.msi files: \"C:\\\\Program Files\\\\New Relic\\\\newrelic-infra\\\\newrelic-infra.yml\": content: | license_key: YOUR_LICENSE_KEY commands: 01_stop-newrelic-infra: command: net stop newrelic-infra ignoreErrors: true 02_start-newrelic-infra: command: net start newrelic-infra ignoreErrors: true Copy Push your app to Elastic BeanStalk: In general, use eb deploy. If you are still using Eb CLI 2.6 , use git aws.push if required. Optional: Use the AWS Console UI. After a successful setup, it can take up to fifteen minutes before metrics begin to appear in New Relic. View your host's infrastructure pages at one.newrelic.com. Uninstall the infrastructure agent To uninstall the agent, remove newrelic.config from .ebextensions, then deploy using the CLI.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 340.21466,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure the <em>infrastructure</em> <em>agent</em> on AWS Elastic Beanstalk",
        "sections": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " Services account. In addition, for any New Relic installation, you will need your New Relic license key. This is a 40-character hexadecimal string that New Relic provides when you sign up for your account. <em>Install</em> the <em>infrastructure</em> <em>agent</em> To <em>install</em> the <em>infrastructure</em> <em>agent</em> on instances launched with AWS"
      },
      "id": "60440a6d28ccbc37982c60c5"
    },
    {
      "sections": [
        "Configure the infrastructure agent using Ansible",
        "Sample code",
        "Compatibility and requirements",
        "Set up Ansible with New Relic",
        "Tip",
        "Role configuration variables",
        "For more help"
      ],
      "title": "Configure the infrastructure agent using Ansible",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Config management tools"
      ],
      "external_id": "1f13326e09d6da78f08f645bc069c22342fbac6c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-using-ansible/",
      "published_at": "2021-06-15T02:31:17Z",
      "updated_at": "2021-03-13T02:47:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's Ansible role to install and configure our infrastructure monitoring agent. For instructions on how to use Ansible, see the Ansible documentation. This is a community-supported effort. Sample code New Relic provides configuration management sample code to help you install our infrastructure monitoring agent using workflows and tools that are common with many Ops teams. This is a basic Ansible role and is intended to be used as a starting place for creating your own customized workflow. Configuration depends on your specific setup and standards. To view an Ansible sample role and more integration information, see the Ansible Galaxy documentation. Compatibility and requirements The Ansible role with New Relic's infrastructure monitoring agent requires a supported Linux operating system. Set up Ansible with New Relic Tip To use Ansible configurations and infrastructure monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. The newrelic.newrelic-infra role: Adds the New Relic infrastructure agent package repository source. Installs and configures the infrastructure agent. To get started using this role: Include the role in your playbook. Customize the required variables. All typical interactions with newrelic.newrelic-infra use role configuration. Here is an example of configuring your role to install the infrastructure agent: - hosts: ap_northeast_1 roles: - name: newrelic.newrelic-infra vars: nrinfragent_os_name: YOUR_OS_NAME nrinfragent_os_version: YOUR_OS_VERSION nrinfragent_config: license_key: YOUR_LICENSE_KEY log_file: /var/log/newrelic/nr-infra.log log_to_stdout: false Copy Role configuration variables Here are available variables for configuring the newrelic.newrelic-infra role: Variable Description nrinfragent_config Required. A map of key-value pairs. Corresponds directly with the available general configuration settings. nrinfragent_state Describes what you want to do with the agent: 'latest': Default. Installs the latest version of the infrastructure agent. 'absent': Uninstall the agent. nrinfragent_version The version of the agent you want to install: '*': Default. Installs the latest version of the infrastructure agent. 'x.y.zzz': String specifying a specific agent version number you want to install; for example, 1.0.682. nrinfragent_os_name Specifies the target OS that the infrastructure agent will be installed on. See the meta/main.yml file for the latest list. nrinfragent_os_version Specifies the OS version of the installer package needed for this machine. See the meta/main.yml file for the latest list. For more help If you need additional help, file an issue at newrelic/infrastructure-agent-ansible on GitHub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 340.21048,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure the <em>infrastructure</em> <em>agent</em> using Ansible",
        "sections": "Configure the <em>infrastructure</em> <em>agent</em> using Ansible",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "You can use New Relic&#x27;s Ansible role to <em>install</em> and configure our <em>infrastructure</em> monitoring <em>agent</em>. For instructions on how to use Ansible, see the Ansible documentation. This is a community-supported effort. Sample code New Relic provides configuration <em>management</em> sample code to help you <em>install</em> our"
      },
      "id": "60440aa3196a675fb6960f5c"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/configuration/config-file-template-newrelic-infrayml": [
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-06-14T21:07:01Z",
      "updated_at": "2021-06-14T21:07:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. Built-in log forwarding and on-host integrations are not yet available. Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.10 to 1.16 Red Hat Enterprise Linux (RHEL) Version 6 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, and 12.4 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 (only the infrastructure agent is supported). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 367.0923,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized <em>agent</em>. On EKS, <em>install</em> the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The <em>infrastructure</em> <em>agent</em> uses the hostname to uniquely identify each server. To avoid"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Tip",
        "Quick start",
        "Install using the launcher",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-06-14T21:08:05Z",
      "updated_at": "2021-06-03T13:38:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. Tip To use infrastructure monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Install using the launcher Before installing our infrastructure monitoring agent for Linux, be sure to: Review the requirements. Have a valid New Relic license key. To install our infrastructure monitoring agent, click the button for your Linux distribution, then follow the instructions: Amazon Linux CentOS Container (Docker) Debian RHEL SLES Ubuntu Other Linux distros To use the links above, you must be logged to your New Relic account. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our step-by-step tutorial in the next section. Step-by-step instructions To install the infrastructure monitoring agent in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 12 (\"Precise\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt precise main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 14 (\"Trusty\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt trusty main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS / RHEL CentOS 7.x, RHEL 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS 7.x, RHEL 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS 8.x, RHEL 8.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS 8.x, RHEL 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 263.11722,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for Linux",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for Linux",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " tutorial in the next section. Step-by-step instructions To <em>install</em> the <em>infrastructure</em> monitoring <em>agent</em> in Linux, follow these instructions: Create the <em>configuration</em> file and add your license key: echo &quot;license_key: YOUR_LICENSE_KEY&quot; | sudo tee -a &#x2F;etc&#x2F;newrelic-infra.yml Copy Determine the distribution"
      },
      "id": "6043edce64441f5335378f15"
    },
    {
      "sections": [
        "Monitor services running on Amazon ECS",
        "Requirements",
        "How to enable",
        "Step 1: Enable EC2 to install the infrastructure agent",
        "For CentOS 6, RHEL 6, Amazon Linux 1",
        "CentOS 7, RHEL 7, Amazon Linux 2",
        "Step 2: Enable monitoring of services"
      ],
      "title": "Monitor services running on Amazon ECS",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "dc178f5c162c1979019d97819db2cc77e0ce220a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/host-integrations/host-integrations-list/monitor-services-running-amazon-ecs/",
      "published_at": "2021-06-15T11:57:52Z",
      "updated_at": "2021-06-15T11:57:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have services that run on Docker containers in Amazon ECS (like Cassandra, Redis, MySQL, and other supported services), you can use New Relic to report data from those services, from the host, and from the containers. Requirements To monitor services running on ECS, you must meet these requirements: An auto-scaling ECS cluster running Amazon Linux, CentOS, or RHEL that meets the infrastructure agent compatibility and requirements. ECS tasks must have network mode set to none or bridge (awsvpc and host not supported). A supported service running on ECS that meets our integration requirements: Apache (does not report inventory data) Cassandra Couchbase Elasticsearch HAProxy HashiCorp Consul JMX Kafka Memcached MongoDB MySQL NGINX PostgreSQL RabbitMQ (does not report inventory data) Redis SNMP How to enable Before explaining how to enable monitoring of services running in ECS, here's an overview of the process: Enable Amazon EC2 to install our infrastructure agent on your ECS clusters. Enable monitoring of services using a service-specific configuration file. Step 1: Enable EC2 to install the infrastructure agent First, you must enable Amazon EC2 to install our infrastructure agent on ECS clusters. To do this, you'll first need to update your user data to install the infrastructure agent on launch. Here are instructions for changing EC2 launch configuration (taken from Amazon EC2 documentation): Open the Amazon EC2 console. On the navigation pane, under Auto scaling, choose Launch configurations. On the next page, select the launch configuration you want to update. Right click and select Copy launch configuration. On the Launch configuration details tab, click Edit details. Replace user data with one of the following snippets: For CentOS 6, RHEL 6, Amazon Linux 1 Replace the highlighted fields with relevant values: Content-Type: multipart/mixed; boundary=\"MIMEBOUNDARY\" MIME-Version: 1.0 --MIMEBOUNDARY Content-Disposition: attachment; filename=\"init.cfg\" Content-Transfer-Encoding: 7bit Content-Type: text/cloud-config Mime-Version: 1.0 yum_repos: newrelic-infra: baseurl: https://download.newrelic.com/infrastructure_agent/linux/yum/el/6/x86_64 gpgkey: https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg gpgcheck: 1 repo_gpgcheck: 1 enabled: true name: New Relic Infrastructure write_files: - content: | --- # New Relic config file license_key: YOUR_LICENSE_KEY path: /etc/newrelic-infra.yml packages: - newrelic-infra - nri-* runcmd: - [ yum, install, newrelic-infra, -y ] - [ systemctl, daemon-reload ] - [ systemctl, enable, newrelic-infra.service ] - [ systemctl, start, --no-block, newrelic-infra.service ] --MIMEBOUNDARY Content-Transfer-Encoding: 7bit Content-Type: text/x-shellscript Mime-Version: 1.0 #!/bin/bash # ECS config { echo \"ECS_CLUSTER=YOUR_CLUSTER_NAME\" } >> /etc/ecs/ecs.config start ecs echo \"Done\" --MIMEBOUNDARY-- Copy CentOS 7, RHEL 7, Amazon Linux 2 Replace the highlighted fields with relevant values: Content-Type: multipart/mixed; boundary=\"MIMEBOUNDARY\" MIME-Version: 1.0 --MIMEBOUNDARY Content-Disposition: attachment; filename=\"init.cfg\" Content-Transfer-Encoding: 7bit Content-Type: text/cloud-config Mime-Version: 1.0 yum_repos: newrelic-infra: baseurl: https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64 gpgkey: https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg gpgcheck: 1 repo_gpgcheck: 1 enabled: true name: New Relic Infrastructure write_files: - content: | --- # New Relic config file license_key: YOUR_LICENSE_KEY path: /etc/newrelic-infra.yml packages: - newrelic-infra - nri-* runcmd: - [ yum, install, newrelic-infra, -y ] - [ systemctl, daemon-reload ] - [ systemctl, enable, newrelic-infra.service ] - [ systemctl, start, --no-block, newrelic-infra.service ] --MIMEBOUNDARY Content-Transfer-Encoding: 7bit Content-Type: text/x-shellscript Mime-Version: 1.0 #!/bin/bash # ECS config { echo \"ECS_CLUSTER=YOUR_ECS_CLUSTER_NAME\" } >> /etc/ecs/ecs.config start ecs echo \"Done\" --MIMEBOUNDARY-- Copy Choose Skip to review. Choose Create launch configuration. Next, update the auto scaling group: Open the Amazon EC2 console. On the navigation pane, under Auto scaling, choose Auto scaling groups. Select the auto scaling group you want to update. From the Actions menu, choose Edit. In the drop-down menu for Launch configuration, select the new launch configuration created. Click Save. To test if the agent is automatically detecting instances, terminate an EC2 instance in the auto scaling group: the replacement instance will now be launched with the new user data. After five minutes, you should see data from the new host on the Hosts page. Next, move on to enabling the monitoring of services. Step 2: Enable monitoring of services Once you've enabled EC2 to run the infrastructure agent, the agent starts monitoring the containers running on that host. Next, we'll explain how to monitor services deployed on ECS. For example, you can monitor an ECS task containing an NGINX instance that sits in front of your application server. Here's a brief overview of how you'd monitor a supported service deployed on ECS: Create a YAML configuration file for the service you want to monitor. This will eventually be placed in the EC2 user data section via the AWS console. But before doing that, you can test that the config is working by placing that file in the infrastructure agent folder (etc/newrelic-infra/integrations.d) in EC2. That config file must use our container auto-discovery format, which allows it to automatically find containers. The exact config options will depend on the specific integration. Check to see that data from the service is being reported to New Relic. If you are satisfied with the data you see, you can then use the EC2 console to add that configuration to the appropriate launch configuration, in the write_files section, and then update the auto scaling group. In the runcmd section, add the yum command to install the integration to the appropriate launch configuration. Here's a detailed example of doing the above procedure for NGINX: Ensure you have SSH access to the server or access to AWS Systems Manager Session Manager. Log in to the host running the infrastructure agent. Via the command line, change the directory to the integrations configuration folder: cd /etc/newrelic-infra/integrations.d Copy Create a file called nginx-config.yml and add the following snippet: --- discovery: docker: match: image: /nginx/ integrations: - name: nri-nginx env: STATUS_URL: http://${discovery.ip}:/status REMOTE_MONITORING: true METRICS: 1 Copy This configuration causes the infrastructure agent to look for containers in ECS that contain nginx. Once a container matches, it then connects to the NGINX status page. For details on how the discovery.ip snippet works, see auto-discovery. For details on general NGINX configuration, see the NGINX integration. If your NGINX status page is set to serve requests from the STATUS_URL on port 80, the infrastructure agent starts monitoring it. After five minutes, verify that NGINX data is appearing in the Infrastructure UI (either: one.newrelic.com > Infrastructure > Third party services, or one.newrelic.com > Explorer > On-host). If the configuration works, place it in the EC2 launch configuration: Open the Amazon EC2 console. On the navigation pane, under Auto scaling, choose Launch configurations. On the next page, select the launch configuration you want to update. Right click and select Copy launch configuration. On the Launch configuration details tab, click Edit details. In the User data section, edit the write_files section (in the part marked text/cloud-config). Add a new file/content entry: - content: | --- discovery: docker: match: image: /nginx/ integrations: - name: nri-nginx env: STATUS_URL: http://${discovery.ip}:/status REMOTE_MONITORING: true METRICS: 1 path: /etc/newrelic-infra/integrations.d/nginx-config.yml Copy Also edit the runcmd section to include the yum command to install nri-nginx: runcmd: - [ yum, install, newrelic-infra, -y ] - [ yum, install, nri-nginx, -y ] - [ systemctl, daemon-reload ] - [ systemctl, enable, newrelic-infra.service ] - [ systemctl, start, --no-block, newrelic-infra.service ] Copy Choose Skip to review. Choose Create launch configuration. Next, update the auto scaling group: Open the Amazon EC2 console. On the navigation pane, under Auto scaling, choose Auto scaling groups. Select the auto scaling group you want to update. From the Actions menu, choose Edit. In the drop down menu for Launch configuration, select the new launch configuration created. Click Save. When an EC2 instance is terminated, it is replaced with a new one that automatically looks for new NGINX containers.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 248.77432,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Step 1: Enable EC2 to <em>install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "&#x27;s an overview of the process: Enable Amazon EC2 to <em>install</em> our <em>infrastructure</em> <em>agent</em> on your ECS clusters. Enable monitoring of services using a service-specific <em>configuration</em> file. Step 1: Enable EC2 to <em>install</em> the <em>infrastructure</em> <em>agent</em> First, you must enable Amazon EC2 to <em>install</em> our <em>infrastructure</em>"
      },
      "id": "60450959e7b9d2475c579a0f"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/configuration/configure-infrastructure-agent": [
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-06-14T21:07:01Z",
      "updated_at": "2021-06-14T21:07:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. Built-in log forwarding and on-host integrations are not yet available. Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.10 to 1.16 Red Hat Enterprise Linux (RHEL) Version 6 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, and 12.4 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 (only the infrastructure agent is supported). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 367.0923,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized <em>agent</em>. On EKS, <em>install</em> the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The <em>infrastructure</em> <em>agent</em> uses the hostname to uniquely identify each server. To avoid"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Tip",
        "Quick start",
        "Install using the launcher",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-06-14T21:08:05Z",
      "updated_at": "2021-06-03T13:38:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. Tip To use infrastructure monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Install using the launcher Before installing our infrastructure monitoring agent for Linux, be sure to: Review the requirements. Have a valid New Relic license key. To install our infrastructure monitoring agent, click the button for your Linux distribution, then follow the instructions: Amazon Linux CentOS Container (Docker) Debian RHEL SLES Ubuntu Other Linux distros To use the links above, you must be logged to your New Relic account. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our step-by-step tutorial in the next section. Step-by-step instructions To install the infrastructure monitoring agent in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 12 (\"Precise\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt precise main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 14 (\"Trusty\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt trusty main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS / RHEL CentOS 7.x, RHEL 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS 7.x, RHEL 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS 8.x, RHEL 8.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS 8.x, RHEL 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 263.11722,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for Linux",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for Linux",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " tutorial in the next section. Step-by-step instructions To <em>install</em> the <em>infrastructure</em> monitoring <em>agent</em> in Linux, follow these instructions: Create the <em>configuration</em> file and add your license key: echo &quot;license_key: YOUR_LICENSE_KEY&quot; | sudo tee -a &#x2F;etc&#x2F;newrelic-infra.yml Copy Determine the distribution"
      },
      "id": "6043edce64441f5335378f15"
    },
    {
      "sections": [
        "Monitor services running on Amazon ECS",
        "Requirements",
        "How to enable",
        "Step 1: Enable EC2 to install the infrastructure agent",
        "For CentOS 6, RHEL 6, Amazon Linux 1",
        "CentOS 7, RHEL 7, Amazon Linux 2",
        "Step 2: Enable monitoring of services"
      ],
      "title": "Monitor services running on Amazon ECS",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "dc178f5c162c1979019d97819db2cc77e0ce220a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/host-integrations/host-integrations-list/monitor-services-running-amazon-ecs/",
      "published_at": "2021-06-15T11:57:52Z",
      "updated_at": "2021-06-15T11:57:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have services that run on Docker containers in Amazon ECS (like Cassandra, Redis, MySQL, and other supported services), you can use New Relic to report data from those services, from the host, and from the containers. Requirements To monitor services running on ECS, you must meet these requirements: An auto-scaling ECS cluster running Amazon Linux, CentOS, or RHEL that meets the infrastructure agent compatibility and requirements. ECS tasks must have network mode set to none or bridge (awsvpc and host not supported). A supported service running on ECS that meets our integration requirements: Apache (does not report inventory data) Cassandra Couchbase Elasticsearch HAProxy HashiCorp Consul JMX Kafka Memcached MongoDB MySQL NGINX PostgreSQL RabbitMQ (does not report inventory data) Redis SNMP How to enable Before explaining how to enable monitoring of services running in ECS, here's an overview of the process: Enable Amazon EC2 to install our infrastructure agent on your ECS clusters. Enable monitoring of services using a service-specific configuration file. Step 1: Enable EC2 to install the infrastructure agent First, you must enable Amazon EC2 to install our infrastructure agent on ECS clusters. To do this, you'll first need to update your user data to install the infrastructure agent on launch. Here are instructions for changing EC2 launch configuration (taken from Amazon EC2 documentation): Open the Amazon EC2 console. On the navigation pane, under Auto scaling, choose Launch configurations. On the next page, select the launch configuration you want to update. Right click and select Copy launch configuration. On the Launch configuration details tab, click Edit details. Replace user data with one of the following snippets: For CentOS 6, RHEL 6, Amazon Linux 1 Replace the highlighted fields with relevant values: Content-Type: multipart/mixed; boundary=\"MIMEBOUNDARY\" MIME-Version: 1.0 --MIMEBOUNDARY Content-Disposition: attachment; filename=\"init.cfg\" Content-Transfer-Encoding: 7bit Content-Type: text/cloud-config Mime-Version: 1.0 yum_repos: newrelic-infra: baseurl: https://download.newrelic.com/infrastructure_agent/linux/yum/el/6/x86_64 gpgkey: https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg gpgcheck: 1 repo_gpgcheck: 1 enabled: true name: New Relic Infrastructure write_files: - content: | --- # New Relic config file license_key: YOUR_LICENSE_KEY path: /etc/newrelic-infra.yml packages: - newrelic-infra - nri-* runcmd: - [ yum, install, newrelic-infra, -y ] - [ systemctl, daemon-reload ] - [ systemctl, enable, newrelic-infra.service ] - [ systemctl, start, --no-block, newrelic-infra.service ] --MIMEBOUNDARY Content-Transfer-Encoding: 7bit Content-Type: text/x-shellscript Mime-Version: 1.0 #!/bin/bash # ECS config { echo \"ECS_CLUSTER=YOUR_CLUSTER_NAME\" } >> /etc/ecs/ecs.config start ecs echo \"Done\" --MIMEBOUNDARY-- Copy CentOS 7, RHEL 7, Amazon Linux 2 Replace the highlighted fields with relevant values: Content-Type: multipart/mixed; boundary=\"MIMEBOUNDARY\" MIME-Version: 1.0 --MIMEBOUNDARY Content-Disposition: attachment; filename=\"init.cfg\" Content-Transfer-Encoding: 7bit Content-Type: text/cloud-config Mime-Version: 1.0 yum_repos: newrelic-infra: baseurl: https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64 gpgkey: https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg gpgcheck: 1 repo_gpgcheck: 1 enabled: true name: New Relic Infrastructure write_files: - content: | --- # New Relic config file license_key: YOUR_LICENSE_KEY path: /etc/newrelic-infra.yml packages: - newrelic-infra - nri-* runcmd: - [ yum, install, newrelic-infra, -y ] - [ systemctl, daemon-reload ] - [ systemctl, enable, newrelic-infra.service ] - [ systemctl, start, --no-block, newrelic-infra.service ] --MIMEBOUNDARY Content-Transfer-Encoding: 7bit Content-Type: text/x-shellscript Mime-Version: 1.0 #!/bin/bash # ECS config { echo \"ECS_CLUSTER=YOUR_ECS_CLUSTER_NAME\" } >> /etc/ecs/ecs.config start ecs echo \"Done\" --MIMEBOUNDARY-- Copy Choose Skip to review. Choose Create launch configuration. Next, update the auto scaling group: Open the Amazon EC2 console. On the navigation pane, under Auto scaling, choose Auto scaling groups. Select the auto scaling group you want to update. From the Actions menu, choose Edit. In the drop-down menu for Launch configuration, select the new launch configuration created. Click Save. To test if the agent is automatically detecting instances, terminate an EC2 instance in the auto scaling group: the replacement instance will now be launched with the new user data. After five minutes, you should see data from the new host on the Hosts page. Next, move on to enabling the monitoring of services. Step 2: Enable monitoring of services Once you've enabled EC2 to run the infrastructure agent, the agent starts monitoring the containers running on that host. Next, we'll explain how to monitor services deployed on ECS. For example, you can monitor an ECS task containing an NGINX instance that sits in front of your application server. Here's a brief overview of how you'd monitor a supported service deployed on ECS: Create a YAML configuration file for the service you want to monitor. This will eventually be placed in the EC2 user data section via the AWS console. But before doing that, you can test that the config is working by placing that file in the infrastructure agent folder (etc/newrelic-infra/integrations.d) in EC2. That config file must use our container auto-discovery format, which allows it to automatically find containers. The exact config options will depend on the specific integration. Check to see that data from the service is being reported to New Relic. If you are satisfied with the data you see, you can then use the EC2 console to add that configuration to the appropriate launch configuration, in the write_files section, and then update the auto scaling group. In the runcmd section, add the yum command to install the integration to the appropriate launch configuration. Here's a detailed example of doing the above procedure for NGINX: Ensure you have SSH access to the server or access to AWS Systems Manager Session Manager. Log in to the host running the infrastructure agent. Via the command line, change the directory to the integrations configuration folder: cd /etc/newrelic-infra/integrations.d Copy Create a file called nginx-config.yml and add the following snippet: --- discovery: docker: match: image: /nginx/ integrations: - name: nri-nginx env: STATUS_URL: http://${discovery.ip}:/status REMOTE_MONITORING: true METRICS: 1 Copy This configuration causes the infrastructure agent to look for containers in ECS that contain nginx. Once a container matches, it then connects to the NGINX status page. For details on how the discovery.ip snippet works, see auto-discovery. For details on general NGINX configuration, see the NGINX integration. If your NGINX status page is set to serve requests from the STATUS_URL on port 80, the infrastructure agent starts monitoring it. After five minutes, verify that NGINX data is appearing in the Infrastructure UI (either: one.newrelic.com > Infrastructure > Third party services, or one.newrelic.com > Explorer > On-host). If the configuration works, place it in the EC2 launch configuration: Open the Amazon EC2 console. On the navigation pane, under Auto scaling, choose Launch configurations. On the next page, select the launch configuration you want to update. Right click and select Copy launch configuration. On the Launch configuration details tab, click Edit details. In the User data section, edit the write_files section (in the part marked text/cloud-config). Add a new file/content entry: - content: | --- discovery: docker: match: image: /nginx/ integrations: - name: nri-nginx env: STATUS_URL: http://${discovery.ip}:/status REMOTE_MONITORING: true METRICS: 1 path: /etc/newrelic-infra/integrations.d/nginx-config.yml Copy Also edit the runcmd section to include the yum command to install nri-nginx: runcmd: - [ yum, install, newrelic-infra, -y ] - [ yum, install, nri-nginx, -y ] - [ systemctl, daemon-reload ] - [ systemctl, enable, newrelic-infra.service ] - [ systemctl, start, --no-block, newrelic-infra.service ] Copy Choose Skip to review. Choose Create launch configuration. Next, update the auto scaling group: Open the Amazon EC2 console. On the navigation pane, under Auto scaling, choose Auto scaling groups. Select the auto scaling group you want to update. From the Actions menu, choose Edit. In the drop down menu for Launch configuration, select the new launch configuration created. Click Save. When an EC2 instance is terminated, it is replaced with a new one that automatically looks for new NGINX containers.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 248.77432,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Step 1: Enable EC2 to <em>install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "&#x27;s an overview of the process: Enable Amazon EC2 to <em>install</em> our <em>infrastructure</em> <em>agent</em> on your ECS clusters. Enable monitoring of services using a service-specific <em>configuration</em> file. Step 1: Enable EC2 to <em>install</em> the <em>infrastructure</em> <em>agent</em> First, you must enable Amazon EC2 to <em>install</em> our <em>infrastructure</em>"
      },
      "id": "60450959e7b9d2475c579a0f"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings": [
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-06-14T21:07:01Z",
      "updated_at": "2021-06-14T21:07:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. Built-in log forwarding and on-host integrations are not yet available. Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.10 to 1.16 Red Hat Enterprise Linux (RHEL) Version 6 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, and 12.4 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 (only the infrastructure agent is supported). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 367.09204,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized <em>agent</em>. On EKS, <em>install</em> the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The <em>infrastructure</em> <em>agent</em> uses the hostname to uniquely identify each server. To avoid"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Tip",
        "Quick start",
        "Install using the launcher",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-06-14T21:08:05Z",
      "updated_at": "2021-06-03T13:38:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. Tip To use infrastructure monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Install using the launcher Before installing our infrastructure monitoring agent for Linux, be sure to: Review the requirements. Have a valid New Relic license key. To install our infrastructure monitoring agent, click the button for your Linux distribution, then follow the instructions: Amazon Linux CentOS Container (Docker) Debian RHEL SLES Ubuntu Other Linux distros To use the links above, you must be logged to your New Relic account. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our step-by-step tutorial in the next section. Step-by-step instructions To install the infrastructure monitoring agent in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 12 (\"Precise\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt precise main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 14 (\"Trusty\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt trusty main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS / RHEL CentOS 7.x, RHEL 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS 7.x, RHEL 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS 8.x, RHEL 8.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS 8.x, RHEL 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 263.11716,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for Linux",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for Linux",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " tutorial in the next section. Step-by-step instructions To <em>install</em> the <em>infrastructure</em> monitoring <em>agent</em> in Linux, follow these instructions: Create the <em>configuration</em> file and add your license key: echo &quot;license_key: YOUR_LICENSE_KEY&quot; | sudo tee -a &#x2F;etc&#x2F;newrelic-infra.yml Copy Determine the distribution"
      },
      "id": "6043edce64441f5335378f15"
    },
    {
      "sections": [
        "Monitor services running on Amazon ECS",
        "Requirements",
        "How to enable",
        "Step 1: Enable EC2 to install the infrastructure agent",
        "For CentOS 6, RHEL 6, Amazon Linux 1",
        "CentOS 7, RHEL 7, Amazon Linux 2",
        "Step 2: Enable monitoring of services"
      ],
      "title": "Monitor services running on Amazon ECS",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "dc178f5c162c1979019d97819db2cc77e0ce220a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/host-integrations/host-integrations-list/monitor-services-running-amazon-ecs/",
      "published_at": "2021-06-15T11:57:52Z",
      "updated_at": "2021-06-15T11:57:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have services that run on Docker containers in Amazon ECS (like Cassandra, Redis, MySQL, and other supported services), you can use New Relic to report data from those services, from the host, and from the containers. Requirements To monitor services running on ECS, you must meet these requirements: An auto-scaling ECS cluster running Amazon Linux, CentOS, or RHEL that meets the infrastructure agent compatibility and requirements. ECS tasks must have network mode set to none or bridge (awsvpc and host not supported). A supported service running on ECS that meets our integration requirements: Apache (does not report inventory data) Cassandra Couchbase Elasticsearch HAProxy HashiCorp Consul JMX Kafka Memcached MongoDB MySQL NGINX PostgreSQL RabbitMQ (does not report inventory data) Redis SNMP How to enable Before explaining how to enable monitoring of services running in ECS, here's an overview of the process: Enable Amazon EC2 to install our infrastructure agent on your ECS clusters. Enable monitoring of services using a service-specific configuration file. Step 1: Enable EC2 to install the infrastructure agent First, you must enable Amazon EC2 to install our infrastructure agent on ECS clusters. To do this, you'll first need to update your user data to install the infrastructure agent on launch. Here are instructions for changing EC2 launch configuration (taken from Amazon EC2 documentation): Open the Amazon EC2 console. On the navigation pane, under Auto scaling, choose Launch configurations. On the next page, select the launch configuration you want to update. Right click and select Copy launch configuration. On the Launch configuration details tab, click Edit details. Replace user data with one of the following snippets: For CentOS 6, RHEL 6, Amazon Linux 1 Replace the highlighted fields with relevant values: Content-Type: multipart/mixed; boundary=\"MIMEBOUNDARY\" MIME-Version: 1.0 --MIMEBOUNDARY Content-Disposition: attachment; filename=\"init.cfg\" Content-Transfer-Encoding: 7bit Content-Type: text/cloud-config Mime-Version: 1.0 yum_repos: newrelic-infra: baseurl: https://download.newrelic.com/infrastructure_agent/linux/yum/el/6/x86_64 gpgkey: https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg gpgcheck: 1 repo_gpgcheck: 1 enabled: true name: New Relic Infrastructure write_files: - content: | --- # New Relic config file license_key: YOUR_LICENSE_KEY path: /etc/newrelic-infra.yml packages: - newrelic-infra - nri-* runcmd: - [ yum, install, newrelic-infra, -y ] - [ systemctl, daemon-reload ] - [ systemctl, enable, newrelic-infra.service ] - [ systemctl, start, --no-block, newrelic-infra.service ] --MIMEBOUNDARY Content-Transfer-Encoding: 7bit Content-Type: text/x-shellscript Mime-Version: 1.0 #!/bin/bash # ECS config { echo \"ECS_CLUSTER=YOUR_CLUSTER_NAME\" } >> /etc/ecs/ecs.config start ecs echo \"Done\" --MIMEBOUNDARY-- Copy CentOS 7, RHEL 7, Amazon Linux 2 Replace the highlighted fields with relevant values: Content-Type: multipart/mixed; boundary=\"MIMEBOUNDARY\" MIME-Version: 1.0 --MIMEBOUNDARY Content-Disposition: attachment; filename=\"init.cfg\" Content-Transfer-Encoding: 7bit Content-Type: text/cloud-config Mime-Version: 1.0 yum_repos: newrelic-infra: baseurl: https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64 gpgkey: https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg gpgcheck: 1 repo_gpgcheck: 1 enabled: true name: New Relic Infrastructure write_files: - content: | --- # New Relic config file license_key: YOUR_LICENSE_KEY path: /etc/newrelic-infra.yml packages: - newrelic-infra - nri-* runcmd: - [ yum, install, newrelic-infra, -y ] - [ systemctl, daemon-reload ] - [ systemctl, enable, newrelic-infra.service ] - [ systemctl, start, --no-block, newrelic-infra.service ] --MIMEBOUNDARY Content-Transfer-Encoding: 7bit Content-Type: text/x-shellscript Mime-Version: 1.0 #!/bin/bash # ECS config { echo \"ECS_CLUSTER=YOUR_ECS_CLUSTER_NAME\" } >> /etc/ecs/ecs.config start ecs echo \"Done\" --MIMEBOUNDARY-- Copy Choose Skip to review. Choose Create launch configuration. Next, update the auto scaling group: Open the Amazon EC2 console. On the navigation pane, under Auto scaling, choose Auto scaling groups. Select the auto scaling group you want to update. From the Actions menu, choose Edit. In the drop-down menu for Launch configuration, select the new launch configuration created. Click Save. To test if the agent is automatically detecting instances, terminate an EC2 instance in the auto scaling group: the replacement instance will now be launched with the new user data. After five minutes, you should see data from the new host on the Hosts page. Next, move on to enabling the monitoring of services. Step 2: Enable monitoring of services Once you've enabled EC2 to run the infrastructure agent, the agent starts monitoring the containers running on that host. Next, we'll explain how to monitor services deployed on ECS. For example, you can monitor an ECS task containing an NGINX instance that sits in front of your application server. Here's a brief overview of how you'd monitor a supported service deployed on ECS: Create a YAML configuration file for the service you want to monitor. This will eventually be placed in the EC2 user data section via the AWS console. But before doing that, you can test that the config is working by placing that file in the infrastructure agent folder (etc/newrelic-infra/integrations.d) in EC2. That config file must use our container auto-discovery format, which allows it to automatically find containers. The exact config options will depend on the specific integration. Check to see that data from the service is being reported to New Relic. If you are satisfied with the data you see, you can then use the EC2 console to add that configuration to the appropriate launch configuration, in the write_files section, and then update the auto scaling group. In the runcmd section, add the yum command to install the integration to the appropriate launch configuration. Here's a detailed example of doing the above procedure for NGINX: Ensure you have SSH access to the server or access to AWS Systems Manager Session Manager. Log in to the host running the infrastructure agent. Via the command line, change the directory to the integrations configuration folder: cd /etc/newrelic-infra/integrations.d Copy Create a file called nginx-config.yml and add the following snippet: --- discovery: docker: match: image: /nginx/ integrations: - name: nri-nginx env: STATUS_URL: http://${discovery.ip}:/status REMOTE_MONITORING: true METRICS: 1 Copy This configuration causes the infrastructure agent to look for containers in ECS that contain nginx. Once a container matches, it then connects to the NGINX status page. For details on how the discovery.ip snippet works, see auto-discovery. For details on general NGINX configuration, see the NGINX integration. If your NGINX status page is set to serve requests from the STATUS_URL on port 80, the infrastructure agent starts monitoring it. After five minutes, verify that NGINX data is appearing in the Infrastructure UI (either: one.newrelic.com > Infrastructure > Third party services, or one.newrelic.com > Explorer > On-host). If the configuration works, place it in the EC2 launch configuration: Open the Amazon EC2 console. On the navigation pane, under Auto scaling, choose Launch configurations. On the next page, select the launch configuration you want to update. Right click and select Copy launch configuration. On the Launch configuration details tab, click Edit details. In the User data section, edit the write_files section (in the part marked text/cloud-config). Add a new file/content entry: - content: | --- discovery: docker: match: image: /nginx/ integrations: - name: nri-nginx env: STATUS_URL: http://${discovery.ip}:/status REMOTE_MONITORING: true METRICS: 1 path: /etc/newrelic-infra/integrations.d/nginx-config.yml Copy Also edit the runcmd section to include the yum command to install nri-nginx: runcmd: - [ yum, install, newrelic-infra, -y ] - [ yum, install, nri-nginx, -y ] - [ systemctl, daemon-reload ] - [ systemctl, enable, newrelic-infra.service ] - [ systemctl, start, --no-block, newrelic-infra.service ] Copy Choose Skip to review. Choose Create launch configuration. Next, update the auto scaling group: Open the Amazon EC2 console. On the navigation pane, under Auto scaling, choose Auto scaling groups. Select the auto scaling group you want to update. From the Actions menu, choose Edit. In the drop down menu for Launch configuration, select the new launch configuration created. Click Save. When an EC2 instance is terminated, it is replaced with a new one that automatically looks for new NGINX containers.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 248.77414,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Step 1: Enable EC2 to <em>install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "&#x27;s an overview of the process: Enable Amazon EC2 to <em>install</em> our <em>infrastructure</em> <em>agent</em> on your ECS clusters. Enable monitoring of services using a service-specific <em>configuration</em> file. Step 1: Enable EC2 to <em>install</em> the <em>infrastructure</em> <em>agent</em> First, you must enable Amazon EC2 to <em>install</em> our <em>infrastructure</em>"
      },
      "id": "60450959e7b9d2475c579a0f"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/get-started/install-infrastructure-agent": [
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-06-14T21:07:01Z",
      "updated_at": "2021-06-14T21:07:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. Built-in log forwarding and on-host integrations are not yet available. Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.10 to 1.16 Red Hat Enterprise Linux (RHEL) Version 6 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, and 12.4 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 (only the infrastructure agent is supported). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 449.6148,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized <em>agent</em>. On EKS, <em>install</em> the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The <em>infrastructure</em> <em>agent</em> uses the hostname to uniquely identify each server. To avoid"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Tip",
        "Quick start",
        "Install using the launcher",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-06-14T21:08:05Z",
      "updated_at": "2021-06-03T13:38:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. Tip To use infrastructure monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Install using the launcher Before installing our infrastructure monitoring agent for Linux, be sure to: Review the requirements. Have a valid New Relic license key. To install our infrastructure monitoring agent, click the button for your Linux distribution, then follow the instructions: Amazon Linux CentOS Container (Docker) Debian RHEL SLES Ubuntu Other Linux distros To use the links above, you must be logged to your New Relic account. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our step-by-step tutorial in the next section. Step-by-step instructions To install the infrastructure monitoring agent in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 12 (\"Precise\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt precise main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 14 (\"Trusty\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt trusty main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS / RHEL CentOS 7.x, RHEL 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS 7.x, RHEL 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS 8.x, RHEL 8.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS 8.x, RHEL 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 245.75882,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for Linux",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for Linux",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Quick <em>start</em> The quickest way to <em>get</em> <em>started</em> with our <em>infrastructure</em> monitoring <em>agent</em> is through our guided <em>install</em>. Tip Try our guided <em>install</em> for yourself. (If you&#x27;re"
      },
      "id": "6043edce64441f5335378f15"
    },
    {
      "sections": [
        "Kubernetes integration: compatibility and requirements",
        "Compatibility",
        "Requirements",
        "Install using Helm"
      ],
      "title": "Kubernetes integration: compatibility and requirements",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Get started"
      ],
      "external_id": "e9bbd729904fa01739eb91e4f3c74561b51c2ba1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/get-started/kubernetes-integration-compatibility-requirements/",
      "published_at": "2021-06-15T13:04:07Z",
      "updated_at": "2021-06-15T13:04:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Kubernetes integration can be installed directly on a server or VM, or through several cloud platforms, such as GKE, EKS, AKS, or OpenShift. Each has a different compatibility with our integration. Compatibility Our Kubernetes integration is compatible with the following versions, depending on the installation mode: Install mode or feature Kubernetes versions Kubernetes cluster Currently tested with versions 1.10 to 1.21 Kubernetes cluster GKE Currently tested with versions 1.10 and 1.17 Kubernetes cluster EKS (EC2 nodes or Fargate) Compatible with version 1.11 or higher Kubernetes cluster AKS Compatible with version 1.11 or higher Kubernetes cluster OpenShift Currently tested with versions 3.7, 3.9, 4.2, 4.3, 4.4, 4.5 and 4.6 Control plane monitoring Compatible with version 1.11 or higher Service monitoring Compatible with version 1.13 or higher Requirements The New Relic Kubernetes integration has the following requirements: Linux distribution compatible with New Relic infrastructure agent. kube-state-metrics version 1.9.5 running on the cluster. When using CRI-O as the container runtime, the processes inside containers are not reported. Performance data is collected at the container level. Install using Helm For compatibility and requirements when installing the Kubernetes integration using Helm, see Alternative install using Helm.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.16,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Install</em> using Helm",
        "tags": "<em>Get</em> <em>started</em>",
        "body": " Kubernetes integration has the following requirements: Linux distribution compatible with New Relic <em>infrastructure</em> <em>agent</em>. kube-state-metrics version 1.9.5 running on the cluster. When using CRI-O as the container runtime, the processes inside containers are not reported. Performance data is collected"
      },
      "id": "603e92dc64441f3a974e8891"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent": [
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Tip",
        "Quick start",
        "Install using the launcher",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-06-14T21:08:05Z",
      "updated_at": "2021-06-03T13:38:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. Tip To use infrastructure monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Install using the launcher Before installing our infrastructure monitoring agent for Linux, be sure to: Review the requirements. Have a valid New Relic license key. To install our infrastructure monitoring agent, click the button for your Linux distribution, then follow the instructions: Amazon Linux CentOS Container (Docker) Debian RHEL SLES Ubuntu Other Linux distros To use the links above, you must be logged to your New Relic account. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our step-by-step tutorial in the next section. Step-by-step instructions To install the infrastructure monitoring agent in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 12 (\"Precise\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt precise main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 14 (\"Trusty\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt trusty main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS / RHEL CentOS 7.x, RHEL 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS 7.x, RHEL 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS 8.x, RHEL 8.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS 8.x, RHEL 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 245.75877,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for Linux",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for Linux",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Quick <em>start</em> The quickest way to <em>get</em> <em>started</em> with our <em>infrastructure</em> monitoring <em>agent</em> is through our guided <em>install</em>. Tip Try our guided <em>install</em> for yourself. (If you&#x27;re"
      },
      "id": "6043edce64441f5335378f15"
    },
    {
      "sections": [
        "Install the infrastructure agent",
        "Tip",
        "Quick start: Use our guided install",
        "One agent, many capabilities",
        "Install the infrastructure monitoring agent",
        "Linux",
        "Windows Server and 10",
        "Other installation scenarios",
        "Check the source code",
        "What's next"
      ],
      "title": "Install the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "ccb11bfd79824202d189a3e743771cfc81e77710",
      "image": "https://docs.newrelic.com/static/6bf45ccf002250f7ebaa69cbe3ff706c/c1b63/guided-install-cli.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/install-infrastructure-agent/",
      "published_at": "2021-06-14T21:06:03Z",
      "updated_at": "2021-03-30T08:28:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's infrastructure monitoring agent is a lightweight executable file that collects data about your hosts. It also forwards data from infrastructure integrations to New Relic, as well as log data for log analytics. There are multiple ways to install and deploy the infrastructure monitoring agent, depending on your setup and needs. This document describes how the infrastructure monitoring agent works and how to install it. Tip To use infrastructure monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Quick start: Use our guided install The quickest way to get started with our infrastructure monitoring agent is through our guided install. Ready to get started? Click one of these button to try it out. Guided install EU Guided install Our guided install not only installs the infrastructure agent, but also discovers the applications and log sources running in your environment. It recommends which ones you should instrument. The guided install works with most setups. But if it doesn't suit your needs, you can find other methods below to get started monitoring your infrastructure. One agent, many capabilities Our infrastructure monitoring agent collects performance and health data about the system resources and processes of the host where it's enabled (on-premises or virtualized). At the same time, it acts as a forwarder for two types of data: core services metrics, which are collected by on-host integrations, and logs. If you want to collect data about core services running on your host, you need to install the infrastructure monitoring agent first, and then install or enable on-host integrations. Our infrastructure monitoring agent and its integrations collect data from the system and core services. It can also forward logs to New Relic. Backend application metrics (APM) are collected by separate language agents. Notice how each integration and forwarder feed different data types in the New Relic database (NRDB). Install the infrastructure monitoring agent If our guided install doesn't work for your setup, follow the instructions for your Linux, Windows, or other setup. The infrastructure monitoring agent can currently run on many Linux distributions, as well as Windows Server. For more information on where you can run the agent, check the compatibility and requirements page. Linux The preferred way to install the Linux agent is through the package manager of your distribution. Select your distribution from the list for step-by-step instructions. Amazon Linux CentOS Container (Docker) Debian RHEL SLES Ubuntu Other Linux distros To use these installation links, you must be logged to your New Relic account. If you don't have a New Relic account yet, or if you prefer to follow the procedure manually, see our tutorial. For advanced install needs, you can deploy the agent using our tarball files in assisted or manual mode. Windows Server and 10 To deploy the agent on a Windows Server host, install it using our MSI installer. For a guided procedure, click the button below and follow the step-by-step instructions: Windows If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial. For advanced installation needs, you can deploy the agent using our zip files in assisted or manual mode. Other installation scenarios The infrastructure monitoring agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Check the source code The infrastructure monitoring agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README. What's next After you've installed the infrastructure monitoring agent: Learn how to configure the agent or edit the config template. Install on-host integrations (for example, for Apache or MySQL). Enable log forwarding using the infrastructure agent. Learn how to manage the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 234.46944,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "sections": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": ". Then ingest up to 100GB of data for free each month. Forever. Quick <em>start</em>: Use our guided <em>install</em> The quickest way to <em>get</em> <em>started</em> with our <em>infrastructure</em> monitoring <em>agent</em> is through our guided <em>install</em>. Ready to <em>get</em> <em>started</em>? Click one of these button to try it out. Guided <em>install</em> EU Guided <em>install</em>"
      },
      "id": "603e79bd64441f99814e8888"
    },
    {
      "sections": [
        "Kubernetes integration: compatibility and requirements",
        "Compatibility",
        "Requirements",
        "Install using Helm"
      ],
      "title": "Kubernetes integration: compatibility and requirements",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Get started"
      ],
      "external_id": "e9bbd729904fa01739eb91e4f3c74561b51c2ba1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/get-started/kubernetes-integration-compatibility-requirements/",
      "published_at": "2021-06-15T13:04:07Z",
      "updated_at": "2021-06-15T13:04:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Kubernetes integration can be installed directly on a server or VM, or through several cloud platforms, such as GKE, EKS, AKS, or OpenShift. Each has a different compatibility with our integration. Compatibility Our Kubernetes integration is compatible with the following versions, depending on the installation mode: Install mode or feature Kubernetes versions Kubernetes cluster Currently tested with versions 1.10 to 1.21 Kubernetes cluster GKE Currently tested with versions 1.10 and 1.17 Kubernetes cluster EKS (EC2 nodes or Fargate) Compatible with version 1.11 or higher Kubernetes cluster AKS Compatible with version 1.11 or higher Kubernetes cluster OpenShift Currently tested with versions 3.7, 3.9, 4.2, 4.3, 4.4, 4.5 and 4.6 Control plane monitoring Compatible with version 1.11 or higher Service monitoring Compatible with version 1.13 or higher Requirements The New Relic Kubernetes integration has the following requirements: Linux distribution compatible with New Relic infrastructure agent. kube-state-metrics version 1.9.5 running on the cluster. When using CRI-O as the container runtime, the processes inside containers are not reported. Performance data is collected at the container level. Install using Helm For compatibility and requirements when installing the Kubernetes integration using Helm, see Alternative install using Helm.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.15985,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Install</em> using Helm",
        "tags": "<em>Get</em> <em>started</em>",
        "body": " Kubernetes integration has the following requirements: Linux distribution compatible with New Relic <em>infrastructure</em> <em>agent</em>. kube-state-metrics version 1.9.5 running on the cluster. When using CRI-O as the container runtime, the processes inside containers are not reported. Performance data is collected"
      },
      "id": "603e92dc64441f3a974e8891"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/linux-installation/azure-extensions-infrastructure": [
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Tip",
        "Quick start",
        "Install using the launcher",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-06-14T21:08:05Z",
      "updated_at": "2021-06-03T13:38:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. Tip To use infrastructure monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Install using the launcher Before installing our infrastructure monitoring agent for Linux, be sure to: Review the requirements. Have a valid New Relic license key. To install our infrastructure monitoring agent, click the button for your Linux distribution, then follow the instructions: Amazon Linux CentOS Container (Docker) Debian RHEL SLES Ubuntu Other Linux distros To use the links above, you must be logged to your New Relic account. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our step-by-step tutorial in the next section. Step-by-step instructions To install the infrastructure monitoring agent in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 12 (\"Precise\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt precise main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 14 (\"Trusty\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt trusty main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS / RHEL CentOS 7.x, RHEL 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS 7.x, RHEL 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS 8.x, RHEL 8.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS 8.x, RHEL 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 353.67053,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Our <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em> can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic <em>installation</em>. Tip To use <em>infrastructure</em> monitoring and the rest of our observability platform, join the New Relic"
      },
      "id": "6043edce64441f5335378f15"
    },
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-06-14T21:07:01Z",
      "updated_at": "2021-06-14T21:07:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. Built-in log forwarding and on-host integrations are not yet available. Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.10 to 1.16 Red Hat Enterprise Linux (RHEL) Version 6 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, and 12.4 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 (only the infrastructure agent is supported). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 292.4444,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Before installing our <em>infrastructure</em> <em>agent</em>, make sure your system and any on-host integrations you configure meet the requirements. Processor architectures The <em>infrastructure</em> <em>agent</em> supports these processor architectures: <em>Linux</em>: 64-bit for x86 processor architectures (also requires 64-bit package"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Tarball manual install of the infrastructure agent for Linux",
        "Caution",
        "Install the agent",
        "Install: Optional steps",
        "Install the service script",
        "Important",
        "Determine your service manager",
        "Tip",
        "Systemd",
        "SysV",
        "Upstart",
        "Change config file's location",
        "Change the pid-file location",
        "If the agent creates the pid-file",
        "If the agent uses the PIDFILE environment variable",
        "Change the user and runtime mode",
        "Configure the plugin directory",
        "Configure the agent directory",
        "Configure the log file",
        "Change the location of the agent binary",
        "What's next?"
      ],
      "title": "Tarball manual install of the infrastructure agent for Linux ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "3ed96e6fe181b3f1219f83dbecc10dc6002b69cb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/tarball-manual-install-infrastructure-agent-linux/",
      "published_at": "2021-06-14T21:10:26Z",
      "updated_at": "2021-03-16T08:32:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our custom Linux installation process for infrastructure monitoring allows you to tailor all aspects of the installation process, and to place files and folders on your filesystem. You have full control of the installation. Caution The manual install process is not supervised. If you opt for manual install, you are responsible for placing the different files in the correct folders, providing the correct parameterized configuration values, and ensuring the agent has all the permissions to execute. Install the agent Before installation, check the compatibility and requirements. Additional agent package options Comments Troubleshooting As of version 1.4.0, the infrastructure agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend that you add it in your path. Daemon process As of version 1.5.59, the infrastructure agent package includes the additional newrelic-infra-service binary, which is used to safely manage usual agent daemon process newrelic-infra. To install the agent: Download the packaged agent file. Unpack the file. Make sure the file unpacks with the following structure: newrelic-infra |-- config_defaults.sh |-- etc | |-- init_scripts | | |-- systemd | | | `-- newrelic-infra.service | | |-- sysv | | | `-- newrelic-infra | | `-- upstart | | `-- newrelic-infra | `-- newrelic-infra | `-- integrations.d |-- installer.sh |-- usr | `-- bin | |-- newrelic-infra | |-- newrelic-infra-ctl | `-- newrelic-infra-service `-- var |-- db | `-- newrelic-infra | |-- custom-integrations | |-- integrations.d | |-- LICENSE.txt | `-- newrelic-integrations |-- log | `-- newrelic-infra `-- run `-- newrelic-infra Copy Install the service script. Optional: Additional install steps. Install: Optional steps You can also carry out these additional steps: Change the location of the configuration file. Change the location of the PID file. Change the user and runtime mode. Configure the plugin directory. Configure the agent directory. Configure the log file. Change the location of the agent binary. Install the service script Before you proceed to install the service script, you need to determine which service manager your system is using: If you use one of the supported service managers (SystemD, SysV, and Upstart), use the service script provided in the tarball. If you use a service manager we do not support, you must write your own service script. Important In case of doubt, check your Linux distribution's official documentation. Determine your service manager There's no good way you can programmatically know which service manager is being used in your host, but we can give you some heuristics. To determine the service manager, use the following commands: command -v systemctl (used in Systemd) command -v update-rc.d (used in SysV) command -v initctl (used in Upstart) The first command that returns an output indicates which service manager your system uses. Tip For example, run the following sequence: $ command -v systemctl $ command -v initctl /sbin/initctl Copy Based on this output, Upstart is the service manager, since it's the command that obtained a return. Important Before copying the service manager script, check if you need to change the user, the path of the agent’s binary, or the pid file location. All these changes need to be reflected in the service script. If you use one of the supported service managers, install the service script for your host: Systemd Copy the service file ./newrelic-infra/etc/init_scripts/systemd/newrelic-infra.service to /etc/systemd/system/newrelic-infra.service Enable the service script: systemctl enable newrelic-infra.service Copy SysV Copy the service file ./newrelic-infra/etc/init_scripts/sysv/newrelic-infra to /etc/init.d/system/newrelic-infra Run the following commands: update-rc.d newrelic-infra defaults update-rc.d newrelic-infra enable Copy Upstart Copy the service file ./newrelic-infra/etc/init_scripts/upstart/newrelic-infra to /etc/init/newrelic-infra.conf Run the following command: initctl reload-configuration Copy Your service script is configured. Configure the rest of the options and start the service manually. Change config file's location The infrastructure agent includes a configuration file, usually named newrelic-infra.yml, to fine-tune the agent's behavior. For more information, see a config file template and how to configure the agent. By default, the agent searches for the configuration file in one of these locations: newrelic-infra.yml (working directory root folder) /etc/newrelic-infra.yml /etc/newrelic-infra/newrelic-infra.yml To specify a different location, use the -config flag command-line. For example: usr/bin/newrelic-infra -config /whatever/path/custom_config_name.yml Copy To make this change permanent, edit the service script: Systemd Open the service script ./newrelic-infra/etc/init_scripts/systemd/newrelic-infra.service. Search for the line ExecStart=/usr/bin/newrelic-infra. Add the config flag and the config file path. In this example the config file is located in the /opt directory ExecStart=/usr/bin/newrelic-infra -config /opt/config.yaml. Save the file. SysV Open the service script ./newrelic-infra/etc/init_scripts/sysv/newrelic-infra. Search for the line DAEMON=/usr/bin/$NAME”. Below the DAEMON variable, add this new line: EXTRA_OPTS=\"-config config_file\" (with the quotation marks). Replace config_file with the path to the config file you want to use. Save the file. Upstart Open the service script ./newrelic-infra/etc/init_scripts/upstart/newrelic-infra. Search for the line exec /usr/bin/newrelic-infra. Add the config flag and the config file path. Here the config file is located in the /opt directory exec /usr/bin/newrelic-infra -config /opt/config.yaml. Save the file. Change the pid-file location The infrastructure agent uses a pid-file to keep the process identification number (pid), which is used to identify a running instance of the agent. How to change the location of the pid-file depends on how the agent is configured. Important By default, we recommend that the agent creates the pid-file. You can edit the location if necessary. To change the location of the pid-file: If the agent creates the pid-file On startup, the agent writes its process pid into the pid-file. If the file doesn’t exist it will create it. By default, the agent creates the pid-file using the path /var/run/newrelic-infra/newrelic-infra.pid. To modify it, use one of these options: Add the pid_file configuration option in the configuration file newrelic-infra.yml. Provide the pid_file using the command line when running the newrelic-infra binary. Set the NRIA_PID_FILE environment variable. Important Since the agent creates or updates the pid-file every time it’s initialized, the user who runs the agent must have read/write permissions over the pid-file location. Use the chown command to give owner rights to a user. For example, if the user nri-agent is running the agent and the pid-file location is set to/var/run/newrelic-infra-custom/nr.pid, then you can give the user rights with: chown nri-agent:nri-agent /var/run/newrelic-infra-custom/ Copy If the agent uses the PIDFILE environment variable Caution We do not recommend using the PIDFILE environment variable to manage the pid-file. If the environment variable PIDFILE is set, the agent will not try to create the pid-file. Create the pid-file in a location of your choice. Tip Use this approach if someone else takes care of the pid-file lifecycle. For example, our init script sets the PIDFILE variable for some service managers, such as SysV, because they handle the creation and content of the pid-file. Change the user and runtime mode The Linux agent runs as root by default, but it also supports running with users with less privileges: PRIVILEGED and UNPRIVILEGED. For more information, see our documentation on agent running modes. Important To execute the agent as a non-root user (PRIVILEGED or UNPRIVILEGED), make sure to grant read/write access to the folders and files provided in the tarball. To change the running mode: Edit the service script: Systemd Open the service script ./newrelic-infra/etc/init_scripts/systemd/newrelic-infra.service. Search for the line [Service]. Add the line User=user_name, and replace user_name with the user that you want to execute the agent (PRIVILEGED or UNPRIVILEGED). Save the file. SysV Open the service script ./newrelic-infra/etc/init_scripts/sysv/newrelic-infra. Search for the line USER=root. Replace root with the user that you want to execute the agent (PRIVILEGED or UNPRIVILEGED). Save the file. Upstart Open the service script ./newrelic-infra/etc/init_scripts/upstart/newrelic-infra. Search for the line exec /usr/bin/newrelic-infra. Replace it with exec su -s /bin/sh -c ‘exec “$0” “$@“’ user_name-- /usr/bin/newrelic-infra. Replace user_name with the user that you want to execute the agent (PRIVILEGED or UNPRIVILEGED). Save the file. If you're running the agent as PRIVILEGED, you must give it two additional Linux capabilities: Make sure the libcap library is installed in your host. (You need the setcap and getcap commands that come with it.) Extract the contents of the tarball and execute the following command with root permission: setcap CAP_SYS_PTRACE,CAP_DAC_READ_SEARCH=+ep ./newrelic-infra/usr/bin/newrelic-infra Copy The run mode will be selected based on the current user and the Kernel Capabilities assigned to it. Configure the plugin directory The infrastructure agent allows you to install integrations that monitor and report data from popular services such as Kubernetes, AWS, MySQL, Redis, Kafka, etc. Each integration has its own configuration file, named by default integration-name-config.yml, placed in the predefined location /etc/newrelic-infra/integrations.d/. On initialization, the agent loads the config file. To overwrite the predefined location of the integration configuration file, use one of the following methods: Set the location in the NRIA_PLUGIN_DIR environment variable. Set the custom path in the newrelic-infra.yml configuration file using the plugin_dir field. Pass it as a command line argument using -plugin_dir when you run the newrelic-infra binary. Configure the agent directory The agent requires its own defined directory to run the installed integrations, caching data (inventory), etc. The default location is /var/db/newrelic-infra/. The agent directory has the following structure and content: LICENSE: Text file containing the New Relic Infrastructure agent license. custom-integrations: Directory that stores the installed the custom integrations. newrelic-integrations: Directory that stores the New Relic official integrations. data: Directory where the agent stores cache data (inventory). Important The user running the agent must have read/write permissions to the agent directory. To overwrite the predefined location of the agent directory, use one of the following methods: Set the location in the NRIA_AGENT_DIR environment variable. Set the custom path in the newrelic-infra.yml configuration file using the agent_dir field. Pass it as a command line argument using -agent_dir when you run the newrelic-infra binary. Configure the log file By default the agent stores the log files in /var/db/newrelic-infra/newrelic-infra.log. Important The user running the agent must have write permissions on the log file. To overwrite the predefined location of the log file, use one of the following methods: Set the location in the NRIA_LOG_FILE environment variable. Set the custom path in the newrelic-infra.yml configuration file using the log_file field. Pass it as a command line argument using -log_file when you run the newrelic-infra binary. Change the location of the agent binary To change the location of the executable, edit the service script: Systemd Open the service script ./newrelic-infra/etc/init_scripts/systemd/newrelic-infra.service. Search for the line [ExecStart=/usr/bin/newrelic-infra]. Replace the path. Save the file. SysV Open the service script ./newrelic-infra/etc/init_scripts/sysv/newrelic-infra. Search for the line DAEMON=/usr/bin/$NAME. Replace the path. Save the file. Upstart Open the service script ./newrelic-infra/etc/init_scripts/upstart/newrelic-infra. Search for the line exec /usr/bin/newrelic-infra. Replace the path. Save the file. What's next? You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Add other infrastructure integrations to collect data from external services. Manually start, stop, restart, or check the agent status.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 256.69296,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Tarball manual <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Linux</em> ",
        "sections": "Tarball manual <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Linux</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Our custom <em>Linux</em> <em>installation</em> process for <em>infrastructure</em> monitoring allows you to tailor all aspects of the <em>installation</em> process, and to place files and folders on your filesystem. You have full control of the <em>installation</em>. Caution The manual <em>install</em> process is not supervised. If you opt for manual"
      },
      "id": "603ea506196a671c21a83d8d"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/linux-installation/docker-container-infrastructure-monitoring": [
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Tip",
        "Quick start",
        "Install using the launcher",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-06-14T21:08:05Z",
      "updated_at": "2021-06-03T13:38:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. Tip To use infrastructure monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Install using the launcher Before installing our infrastructure monitoring agent for Linux, be sure to: Review the requirements. Have a valid New Relic license key. To install our infrastructure monitoring agent, click the button for your Linux distribution, then follow the instructions: Amazon Linux CentOS Container (Docker) Debian RHEL SLES Ubuntu Other Linux distros To use the links above, you must be logged to your New Relic account. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our step-by-step tutorial in the next section. Step-by-step instructions To install the infrastructure monitoring agent in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 12 (\"Precise\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt precise main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 14 (\"Trusty\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt trusty main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS / RHEL CentOS 7.x, RHEL 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS 7.x, RHEL 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS 8.x, RHEL 8.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS 8.x, RHEL 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 353.67053,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Our <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em> can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic <em>installation</em>. Tip To use <em>infrastructure</em> monitoring and the rest of our observability platform, join the New Relic"
      },
      "id": "6043edce64441f5335378f15"
    },
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-06-14T21:07:01Z",
      "updated_at": "2021-06-14T21:07:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. Built-in log forwarding and on-host integrations are not yet available. Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.10 to 1.16 Red Hat Enterprise Linux (RHEL) Version 6 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, and 12.4 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 (only the infrastructure agent is supported). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 292.4444,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Before installing our <em>infrastructure</em> <em>agent</em>, make sure your system and any on-host integrations you configure meet the requirements. Processor architectures The <em>infrastructure</em> <em>agent</em> supports these processor architectures: <em>Linux</em>: 64-bit for x86 processor architectures (also requires 64-bit package"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Tarball manual install of the infrastructure agent for Linux",
        "Caution",
        "Install the agent",
        "Install: Optional steps",
        "Install the service script",
        "Important",
        "Determine your service manager",
        "Tip",
        "Systemd",
        "SysV",
        "Upstart",
        "Change config file's location",
        "Change the pid-file location",
        "If the agent creates the pid-file",
        "If the agent uses the PIDFILE environment variable",
        "Change the user and runtime mode",
        "Configure the plugin directory",
        "Configure the agent directory",
        "Configure the log file",
        "Change the location of the agent binary",
        "What's next?"
      ],
      "title": "Tarball manual install of the infrastructure agent for Linux ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "3ed96e6fe181b3f1219f83dbecc10dc6002b69cb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/tarball-manual-install-infrastructure-agent-linux/",
      "published_at": "2021-06-14T21:10:26Z",
      "updated_at": "2021-03-16T08:32:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our custom Linux installation process for infrastructure monitoring allows you to tailor all aspects of the installation process, and to place files and folders on your filesystem. You have full control of the installation. Caution The manual install process is not supervised. If you opt for manual install, you are responsible for placing the different files in the correct folders, providing the correct parameterized configuration values, and ensuring the agent has all the permissions to execute. Install the agent Before installation, check the compatibility and requirements. Additional agent package options Comments Troubleshooting As of version 1.4.0, the infrastructure agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend that you add it in your path. Daemon process As of version 1.5.59, the infrastructure agent package includes the additional newrelic-infra-service binary, which is used to safely manage usual agent daemon process newrelic-infra. To install the agent: Download the packaged agent file. Unpack the file. Make sure the file unpacks with the following structure: newrelic-infra |-- config_defaults.sh |-- etc | |-- init_scripts | | |-- systemd | | | `-- newrelic-infra.service | | |-- sysv | | | `-- newrelic-infra | | `-- upstart | | `-- newrelic-infra | `-- newrelic-infra | `-- integrations.d |-- installer.sh |-- usr | `-- bin | |-- newrelic-infra | |-- newrelic-infra-ctl | `-- newrelic-infra-service `-- var |-- db | `-- newrelic-infra | |-- custom-integrations | |-- integrations.d | |-- LICENSE.txt | `-- newrelic-integrations |-- log | `-- newrelic-infra `-- run `-- newrelic-infra Copy Install the service script. Optional: Additional install steps. Install: Optional steps You can also carry out these additional steps: Change the location of the configuration file. Change the location of the PID file. Change the user and runtime mode. Configure the plugin directory. Configure the agent directory. Configure the log file. Change the location of the agent binary. Install the service script Before you proceed to install the service script, you need to determine which service manager your system is using: If you use one of the supported service managers (SystemD, SysV, and Upstart), use the service script provided in the tarball. If you use a service manager we do not support, you must write your own service script. Important In case of doubt, check your Linux distribution's official documentation. Determine your service manager There's no good way you can programmatically know which service manager is being used in your host, but we can give you some heuristics. To determine the service manager, use the following commands: command -v systemctl (used in Systemd) command -v update-rc.d (used in SysV) command -v initctl (used in Upstart) The first command that returns an output indicates which service manager your system uses. Tip For example, run the following sequence: $ command -v systemctl $ command -v initctl /sbin/initctl Copy Based on this output, Upstart is the service manager, since it's the command that obtained a return. Important Before copying the service manager script, check if you need to change the user, the path of the agent’s binary, or the pid file location. All these changes need to be reflected in the service script. If you use one of the supported service managers, install the service script for your host: Systemd Copy the service file ./newrelic-infra/etc/init_scripts/systemd/newrelic-infra.service to /etc/systemd/system/newrelic-infra.service Enable the service script: systemctl enable newrelic-infra.service Copy SysV Copy the service file ./newrelic-infra/etc/init_scripts/sysv/newrelic-infra to /etc/init.d/system/newrelic-infra Run the following commands: update-rc.d newrelic-infra defaults update-rc.d newrelic-infra enable Copy Upstart Copy the service file ./newrelic-infra/etc/init_scripts/upstart/newrelic-infra to /etc/init/newrelic-infra.conf Run the following command: initctl reload-configuration Copy Your service script is configured. Configure the rest of the options and start the service manually. Change config file's location The infrastructure agent includes a configuration file, usually named newrelic-infra.yml, to fine-tune the agent's behavior. For more information, see a config file template and how to configure the agent. By default, the agent searches for the configuration file in one of these locations: newrelic-infra.yml (working directory root folder) /etc/newrelic-infra.yml /etc/newrelic-infra/newrelic-infra.yml To specify a different location, use the -config flag command-line. For example: usr/bin/newrelic-infra -config /whatever/path/custom_config_name.yml Copy To make this change permanent, edit the service script: Systemd Open the service script ./newrelic-infra/etc/init_scripts/systemd/newrelic-infra.service. Search for the line ExecStart=/usr/bin/newrelic-infra. Add the config flag and the config file path. In this example the config file is located in the /opt directory ExecStart=/usr/bin/newrelic-infra -config /opt/config.yaml. Save the file. SysV Open the service script ./newrelic-infra/etc/init_scripts/sysv/newrelic-infra. Search for the line DAEMON=/usr/bin/$NAME”. Below the DAEMON variable, add this new line: EXTRA_OPTS=\"-config config_file\" (with the quotation marks). Replace config_file with the path to the config file you want to use. Save the file. Upstart Open the service script ./newrelic-infra/etc/init_scripts/upstart/newrelic-infra. Search for the line exec /usr/bin/newrelic-infra. Add the config flag and the config file path. Here the config file is located in the /opt directory exec /usr/bin/newrelic-infra -config /opt/config.yaml. Save the file. Change the pid-file location The infrastructure agent uses a pid-file to keep the process identification number (pid), which is used to identify a running instance of the agent. How to change the location of the pid-file depends on how the agent is configured. Important By default, we recommend that the agent creates the pid-file. You can edit the location if necessary. To change the location of the pid-file: If the agent creates the pid-file On startup, the agent writes its process pid into the pid-file. If the file doesn’t exist it will create it. By default, the agent creates the pid-file using the path /var/run/newrelic-infra/newrelic-infra.pid. To modify it, use one of these options: Add the pid_file configuration option in the configuration file newrelic-infra.yml. Provide the pid_file using the command line when running the newrelic-infra binary. Set the NRIA_PID_FILE environment variable. Important Since the agent creates or updates the pid-file every time it’s initialized, the user who runs the agent must have read/write permissions over the pid-file location. Use the chown command to give owner rights to a user. For example, if the user nri-agent is running the agent and the pid-file location is set to/var/run/newrelic-infra-custom/nr.pid, then you can give the user rights with: chown nri-agent:nri-agent /var/run/newrelic-infra-custom/ Copy If the agent uses the PIDFILE environment variable Caution We do not recommend using the PIDFILE environment variable to manage the pid-file. If the environment variable PIDFILE is set, the agent will not try to create the pid-file. Create the pid-file in a location of your choice. Tip Use this approach if someone else takes care of the pid-file lifecycle. For example, our init script sets the PIDFILE variable for some service managers, such as SysV, because they handle the creation and content of the pid-file. Change the user and runtime mode The Linux agent runs as root by default, but it also supports running with users with less privileges: PRIVILEGED and UNPRIVILEGED. For more information, see our documentation on agent running modes. Important To execute the agent as a non-root user (PRIVILEGED or UNPRIVILEGED), make sure to grant read/write access to the folders and files provided in the tarball. To change the running mode: Edit the service script: Systemd Open the service script ./newrelic-infra/etc/init_scripts/systemd/newrelic-infra.service. Search for the line [Service]. Add the line User=user_name, and replace user_name with the user that you want to execute the agent (PRIVILEGED or UNPRIVILEGED). Save the file. SysV Open the service script ./newrelic-infra/etc/init_scripts/sysv/newrelic-infra. Search for the line USER=root. Replace root with the user that you want to execute the agent (PRIVILEGED or UNPRIVILEGED). Save the file. Upstart Open the service script ./newrelic-infra/etc/init_scripts/upstart/newrelic-infra. Search for the line exec /usr/bin/newrelic-infra. Replace it with exec su -s /bin/sh -c ‘exec “$0” “$@“’ user_name-- /usr/bin/newrelic-infra. Replace user_name with the user that you want to execute the agent (PRIVILEGED or UNPRIVILEGED). Save the file. If you're running the agent as PRIVILEGED, you must give it two additional Linux capabilities: Make sure the libcap library is installed in your host. (You need the setcap and getcap commands that come with it.) Extract the contents of the tarball and execute the following command with root permission: setcap CAP_SYS_PTRACE,CAP_DAC_READ_SEARCH=+ep ./newrelic-infra/usr/bin/newrelic-infra Copy The run mode will be selected based on the current user and the Kernel Capabilities assigned to it. Configure the plugin directory The infrastructure agent allows you to install integrations that monitor and report data from popular services such as Kubernetes, AWS, MySQL, Redis, Kafka, etc. Each integration has its own configuration file, named by default integration-name-config.yml, placed in the predefined location /etc/newrelic-infra/integrations.d/. On initialization, the agent loads the config file. To overwrite the predefined location of the integration configuration file, use one of the following methods: Set the location in the NRIA_PLUGIN_DIR environment variable. Set the custom path in the newrelic-infra.yml configuration file using the plugin_dir field. Pass it as a command line argument using -plugin_dir when you run the newrelic-infra binary. Configure the agent directory The agent requires its own defined directory to run the installed integrations, caching data (inventory), etc. The default location is /var/db/newrelic-infra/. The agent directory has the following structure and content: LICENSE: Text file containing the New Relic Infrastructure agent license. custom-integrations: Directory that stores the installed the custom integrations. newrelic-integrations: Directory that stores the New Relic official integrations. data: Directory where the agent stores cache data (inventory). Important The user running the agent must have read/write permissions to the agent directory. To overwrite the predefined location of the agent directory, use one of the following methods: Set the location in the NRIA_AGENT_DIR environment variable. Set the custom path in the newrelic-infra.yml configuration file using the agent_dir field. Pass it as a command line argument using -agent_dir when you run the newrelic-infra binary. Configure the log file By default the agent stores the log files in /var/db/newrelic-infra/newrelic-infra.log. Important The user running the agent must have write permissions on the log file. To overwrite the predefined location of the log file, use one of the following methods: Set the location in the NRIA_LOG_FILE environment variable. Set the custom path in the newrelic-infra.yml configuration file using the log_file field. Pass it as a command line argument using -log_file when you run the newrelic-infra binary. Change the location of the agent binary To change the location of the executable, edit the service script: Systemd Open the service script ./newrelic-infra/etc/init_scripts/systemd/newrelic-infra.service. Search for the line [ExecStart=/usr/bin/newrelic-infra]. Replace the path. Save the file. SysV Open the service script ./newrelic-infra/etc/init_scripts/sysv/newrelic-infra. Search for the line DAEMON=/usr/bin/$NAME. Replace the path. Save the file. Upstart Open the service script ./newrelic-infra/etc/init_scripts/upstart/newrelic-infra. Search for the line exec /usr/bin/newrelic-infra. Replace the path. Save the file. What's next? You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Add other infrastructure integrations to collect data from external services. Manually start, stop, restart, or check the agent status.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 256.69296,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Tarball manual <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Linux</em> ",
        "sections": "Tarball manual <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Linux</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Our custom <em>Linux</em> <em>installation</em> process for <em>infrastructure</em> monitoring allows you to tailor all aspects of the <em>installation</em> process, and to place files and folders on your filesystem. You have full control of the <em>installation</em>. Caution The manual <em>install</em> process is not supervised. If you opt for manual"
      },
      "id": "603ea506196a671c21a83d8d"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/linux-installation/docker-instrumentation-infrastructure-monitoring": [
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Tip",
        "Quick start",
        "Install using the launcher",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-06-14T21:08:05Z",
      "updated_at": "2021-06-03T13:38:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. Tip To use infrastructure monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Install using the launcher Before installing our infrastructure monitoring agent for Linux, be sure to: Review the requirements. Have a valid New Relic license key. To install our infrastructure monitoring agent, click the button for your Linux distribution, then follow the instructions: Amazon Linux CentOS Container (Docker) Debian RHEL SLES Ubuntu Other Linux distros To use the links above, you must be logged to your New Relic account. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our step-by-step tutorial in the next section. Step-by-step instructions To install the infrastructure monitoring agent in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 12 (\"Precise\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt precise main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 14 (\"Trusty\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt trusty main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS / RHEL CentOS 7.x, RHEL 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS 7.x, RHEL 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS 8.x, RHEL 8.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS 8.x, RHEL 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 353.67047,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Our <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em> can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic <em>installation</em>. Tip To use <em>infrastructure</em> monitoring and the rest of our observability platform, join the New Relic"
      },
      "id": "6043edce64441f5335378f15"
    },
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-06-14T21:07:01Z",
      "updated_at": "2021-06-14T21:07:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. Built-in log forwarding and on-host integrations are not yet available. Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.10 to 1.16 Red Hat Enterprise Linux (RHEL) Version 6 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, and 12.4 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 (only the infrastructure agent is supported). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 292.4442,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Before installing our <em>infrastructure</em> <em>agent</em>, make sure your system and any on-host integrations you configure meet the requirements. Processor architectures The <em>infrastructure</em> <em>agent</em> supports these processor architectures: <em>Linux</em>: 64-bit for x86 processor architectures (also requires 64-bit package"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Tarball manual install of the infrastructure agent for Linux",
        "Caution",
        "Install the agent",
        "Install: Optional steps",
        "Install the service script",
        "Important",
        "Determine your service manager",
        "Tip",
        "Systemd",
        "SysV",
        "Upstart",
        "Change config file's location",
        "Change the pid-file location",
        "If the agent creates the pid-file",
        "If the agent uses the PIDFILE environment variable",
        "Change the user and runtime mode",
        "Configure the plugin directory",
        "Configure the agent directory",
        "Configure the log file",
        "Change the location of the agent binary",
        "What's next?"
      ],
      "title": "Tarball manual install of the infrastructure agent for Linux ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "3ed96e6fe181b3f1219f83dbecc10dc6002b69cb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/tarball-manual-install-infrastructure-agent-linux/",
      "published_at": "2021-06-14T21:10:26Z",
      "updated_at": "2021-03-16T08:32:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our custom Linux installation process for infrastructure monitoring allows you to tailor all aspects of the installation process, and to place files and folders on your filesystem. You have full control of the installation. Caution The manual install process is not supervised. If you opt for manual install, you are responsible for placing the different files in the correct folders, providing the correct parameterized configuration values, and ensuring the agent has all the permissions to execute. Install the agent Before installation, check the compatibility and requirements. Additional agent package options Comments Troubleshooting As of version 1.4.0, the infrastructure agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend that you add it in your path. Daemon process As of version 1.5.59, the infrastructure agent package includes the additional newrelic-infra-service binary, which is used to safely manage usual agent daemon process newrelic-infra. To install the agent: Download the packaged agent file. Unpack the file. Make sure the file unpacks with the following structure: newrelic-infra |-- config_defaults.sh |-- etc | |-- init_scripts | | |-- systemd | | | `-- newrelic-infra.service | | |-- sysv | | | `-- newrelic-infra | | `-- upstart | | `-- newrelic-infra | `-- newrelic-infra | `-- integrations.d |-- installer.sh |-- usr | `-- bin | |-- newrelic-infra | |-- newrelic-infra-ctl | `-- newrelic-infra-service `-- var |-- db | `-- newrelic-infra | |-- custom-integrations | |-- integrations.d | |-- LICENSE.txt | `-- newrelic-integrations |-- log | `-- newrelic-infra `-- run `-- newrelic-infra Copy Install the service script. Optional: Additional install steps. Install: Optional steps You can also carry out these additional steps: Change the location of the configuration file. Change the location of the PID file. Change the user and runtime mode. Configure the plugin directory. Configure the agent directory. Configure the log file. Change the location of the agent binary. Install the service script Before you proceed to install the service script, you need to determine which service manager your system is using: If you use one of the supported service managers (SystemD, SysV, and Upstart), use the service script provided in the tarball. If you use a service manager we do not support, you must write your own service script. Important In case of doubt, check your Linux distribution's official documentation. Determine your service manager There's no good way you can programmatically know which service manager is being used in your host, but we can give you some heuristics. To determine the service manager, use the following commands: command -v systemctl (used in Systemd) command -v update-rc.d (used in SysV) command -v initctl (used in Upstart) The first command that returns an output indicates which service manager your system uses. Tip For example, run the following sequence: $ command -v systemctl $ command -v initctl /sbin/initctl Copy Based on this output, Upstart is the service manager, since it's the command that obtained a return. Important Before copying the service manager script, check if you need to change the user, the path of the agent’s binary, or the pid file location. All these changes need to be reflected in the service script. If you use one of the supported service managers, install the service script for your host: Systemd Copy the service file ./newrelic-infra/etc/init_scripts/systemd/newrelic-infra.service to /etc/systemd/system/newrelic-infra.service Enable the service script: systemctl enable newrelic-infra.service Copy SysV Copy the service file ./newrelic-infra/etc/init_scripts/sysv/newrelic-infra to /etc/init.d/system/newrelic-infra Run the following commands: update-rc.d newrelic-infra defaults update-rc.d newrelic-infra enable Copy Upstart Copy the service file ./newrelic-infra/etc/init_scripts/upstart/newrelic-infra to /etc/init/newrelic-infra.conf Run the following command: initctl reload-configuration Copy Your service script is configured. Configure the rest of the options and start the service manually. Change config file's location The infrastructure agent includes a configuration file, usually named newrelic-infra.yml, to fine-tune the agent's behavior. For more information, see a config file template and how to configure the agent. By default, the agent searches for the configuration file in one of these locations: newrelic-infra.yml (working directory root folder) /etc/newrelic-infra.yml /etc/newrelic-infra/newrelic-infra.yml To specify a different location, use the -config flag command-line. For example: usr/bin/newrelic-infra -config /whatever/path/custom_config_name.yml Copy To make this change permanent, edit the service script: Systemd Open the service script ./newrelic-infra/etc/init_scripts/systemd/newrelic-infra.service. Search for the line ExecStart=/usr/bin/newrelic-infra. Add the config flag and the config file path. In this example the config file is located in the /opt directory ExecStart=/usr/bin/newrelic-infra -config /opt/config.yaml. Save the file. SysV Open the service script ./newrelic-infra/etc/init_scripts/sysv/newrelic-infra. Search for the line DAEMON=/usr/bin/$NAME”. Below the DAEMON variable, add this new line: EXTRA_OPTS=\"-config config_file\" (with the quotation marks). Replace config_file with the path to the config file you want to use. Save the file. Upstart Open the service script ./newrelic-infra/etc/init_scripts/upstart/newrelic-infra. Search for the line exec /usr/bin/newrelic-infra. Add the config flag and the config file path. Here the config file is located in the /opt directory exec /usr/bin/newrelic-infra -config /opt/config.yaml. Save the file. Change the pid-file location The infrastructure agent uses a pid-file to keep the process identification number (pid), which is used to identify a running instance of the agent. How to change the location of the pid-file depends on how the agent is configured. Important By default, we recommend that the agent creates the pid-file. You can edit the location if necessary. To change the location of the pid-file: If the agent creates the pid-file On startup, the agent writes its process pid into the pid-file. If the file doesn’t exist it will create it. By default, the agent creates the pid-file using the path /var/run/newrelic-infra/newrelic-infra.pid. To modify it, use one of these options: Add the pid_file configuration option in the configuration file newrelic-infra.yml. Provide the pid_file using the command line when running the newrelic-infra binary. Set the NRIA_PID_FILE environment variable. Important Since the agent creates or updates the pid-file every time it’s initialized, the user who runs the agent must have read/write permissions over the pid-file location. Use the chown command to give owner rights to a user. For example, if the user nri-agent is running the agent and the pid-file location is set to/var/run/newrelic-infra-custom/nr.pid, then you can give the user rights with: chown nri-agent:nri-agent /var/run/newrelic-infra-custom/ Copy If the agent uses the PIDFILE environment variable Caution We do not recommend using the PIDFILE environment variable to manage the pid-file. If the environment variable PIDFILE is set, the agent will not try to create the pid-file. Create the pid-file in a location of your choice. Tip Use this approach if someone else takes care of the pid-file lifecycle. For example, our init script sets the PIDFILE variable for some service managers, such as SysV, because they handle the creation and content of the pid-file. Change the user and runtime mode The Linux agent runs as root by default, but it also supports running with users with less privileges: PRIVILEGED and UNPRIVILEGED. For more information, see our documentation on agent running modes. Important To execute the agent as a non-root user (PRIVILEGED or UNPRIVILEGED), make sure to grant read/write access to the folders and files provided in the tarball. To change the running mode: Edit the service script: Systemd Open the service script ./newrelic-infra/etc/init_scripts/systemd/newrelic-infra.service. Search for the line [Service]. Add the line User=user_name, and replace user_name with the user that you want to execute the agent (PRIVILEGED or UNPRIVILEGED). Save the file. SysV Open the service script ./newrelic-infra/etc/init_scripts/sysv/newrelic-infra. Search for the line USER=root. Replace root with the user that you want to execute the agent (PRIVILEGED or UNPRIVILEGED). Save the file. Upstart Open the service script ./newrelic-infra/etc/init_scripts/upstart/newrelic-infra. Search for the line exec /usr/bin/newrelic-infra. Replace it with exec su -s /bin/sh -c ‘exec “$0” “$@“’ user_name-- /usr/bin/newrelic-infra. Replace user_name with the user that you want to execute the agent (PRIVILEGED or UNPRIVILEGED). Save the file. If you're running the agent as PRIVILEGED, you must give it two additional Linux capabilities: Make sure the libcap library is installed in your host. (You need the setcap and getcap commands that come with it.) Extract the contents of the tarball and execute the following command with root permission: setcap CAP_SYS_PTRACE,CAP_DAC_READ_SEARCH=+ep ./newrelic-infra/usr/bin/newrelic-infra Copy The run mode will be selected based on the current user and the Kernel Capabilities assigned to it. Configure the plugin directory The infrastructure agent allows you to install integrations that monitor and report data from popular services such as Kubernetes, AWS, MySQL, Redis, Kafka, etc. Each integration has its own configuration file, named by default integration-name-config.yml, placed in the predefined location /etc/newrelic-infra/integrations.d/. On initialization, the agent loads the config file. To overwrite the predefined location of the integration configuration file, use one of the following methods: Set the location in the NRIA_PLUGIN_DIR environment variable. Set the custom path in the newrelic-infra.yml configuration file using the plugin_dir field. Pass it as a command line argument using -plugin_dir when you run the newrelic-infra binary. Configure the agent directory The agent requires its own defined directory to run the installed integrations, caching data (inventory), etc. The default location is /var/db/newrelic-infra/. The agent directory has the following structure and content: LICENSE: Text file containing the New Relic Infrastructure agent license. custom-integrations: Directory that stores the installed the custom integrations. newrelic-integrations: Directory that stores the New Relic official integrations. data: Directory where the agent stores cache data (inventory). Important The user running the agent must have read/write permissions to the agent directory. To overwrite the predefined location of the agent directory, use one of the following methods: Set the location in the NRIA_AGENT_DIR environment variable. Set the custom path in the newrelic-infra.yml configuration file using the agent_dir field. Pass it as a command line argument using -agent_dir when you run the newrelic-infra binary. Configure the log file By default the agent stores the log files in /var/db/newrelic-infra/newrelic-infra.log. Important The user running the agent must have write permissions on the log file. To overwrite the predefined location of the log file, use one of the following methods: Set the location in the NRIA_LOG_FILE environment variable. Set the custom path in the newrelic-infra.yml configuration file using the log_file field. Pass it as a command line argument using -log_file when you run the newrelic-infra binary. Change the location of the agent binary To change the location of the executable, edit the service script: Systemd Open the service script ./newrelic-infra/etc/init_scripts/systemd/newrelic-infra.service. Search for the line [ExecStart=/usr/bin/newrelic-infra]. Replace the path. Save the file. SysV Open the service script ./newrelic-infra/etc/init_scripts/sysv/newrelic-infra. Search for the line DAEMON=/usr/bin/$NAME. Replace the path. Save the file. Upstart Open the service script ./newrelic-infra/etc/init_scripts/upstart/newrelic-infra. Search for the line exec /usr/bin/newrelic-infra. Replace the path. Save the file. What's next? You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Add other infrastructure integrations to collect data from external services. Manually start, stop, restart, or check the agent status.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 256.69296,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Tarball manual <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Linux</em> ",
        "sections": "Tarball manual <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Linux</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Our custom <em>Linux</em> <em>installation</em> process for <em>infrastructure</em> monitoring allows you to tailor all aspects of the <em>installation</em> process, and to place files and folders on your filesystem. You have full control of the <em>installation</em>. Caution The manual <em>install</em> process is not supervised. If you opt for manual"
      },
      "id": "603ea506196a671c21a83d8d"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux": [
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-06-14T21:07:01Z",
      "updated_at": "2021-06-14T21:07:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. Built-in log forwarding and on-host integrations are not yet available. Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.10 to 1.16 Red Hat Enterprise Linux (RHEL) Version 6 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, and 12.4 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 (only the infrastructure agent is supported). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 292.4442,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Before installing our <em>infrastructure</em> <em>agent</em>, make sure your system and any on-host integrations you configure meet the requirements. Processor architectures The <em>infrastructure</em> <em>agent</em> supports these processor architectures: <em>Linux</em>: 64-bit for x86 processor architectures (also requires 64-bit package"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Tarball manual install of the infrastructure agent for Linux",
        "Caution",
        "Install the agent",
        "Install: Optional steps",
        "Install the service script",
        "Important",
        "Determine your service manager",
        "Tip",
        "Systemd",
        "SysV",
        "Upstart",
        "Change config file's location",
        "Change the pid-file location",
        "If the agent creates the pid-file",
        "If the agent uses the PIDFILE environment variable",
        "Change the user and runtime mode",
        "Configure the plugin directory",
        "Configure the agent directory",
        "Configure the log file",
        "Change the location of the agent binary",
        "What's next?"
      ],
      "title": "Tarball manual install of the infrastructure agent for Linux ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "3ed96e6fe181b3f1219f83dbecc10dc6002b69cb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/tarball-manual-install-infrastructure-agent-linux/",
      "published_at": "2021-06-14T21:10:26Z",
      "updated_at": "2021-03-16T08:32:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our custom Linux installation process for infrastructure monitoring allows you to tailor all aspects of the installation process, and to place files and folders on your filesystem. You have full control of the installation. Caution The manual install process is not supervised. If you opt for manual install, you are responsible for placing the different files in the correct folders, providing the correct parameterized configuration values, and ensuring the agent has all the permissions to execute. Install the agent Before installation, check the compatibility and requirements. Additional agent package options Comments Troubleshooting As of version 1.4.0, the infrastructure agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend that you add it in your path. Daemon process As of version 1.5.59, the infrastructure agent package includes the additional newrelic-infra-service binary, which is used to safely manage usual agent daemon process newrelic-infra. To install the agent: Download the packaged agent file. Unpack the file. Make sure the file unpacks with the following structure: newrelic-infra |-- config_defaults.sh |-- etc | |-- init_scripts | | |-- systemd | | | `-- newrelic-infra.service | | |-- sysv | | | `-- newrelic-infra | | `-- upstart | | `-- newrelic-infra | `-- newrelic-infra | `-- integrations.d |-- installer.sh |-- usr | `-- bin | |-- newrelic-infra | |-- newrelic-infra-ctl | `-- newrelic-infra-service `-- var |-- db | `-- newrelic-infra | |-- custom-integrations | |-- integrations.d | |-- LICENSE.txt | `-- newrelic-integrations |-- log | `-- newrelic-infra `-- run `-- newrelic-infra Copy Install the service script. Optional: Additional install steps. Install: Optional steps You can also carry out these additional steps: Change the location of the configuration file. Change the location of the PID file. Change the user and runtime mode. Configure the plugin directory. Configure the agent directory. Configure the log file. Change the location of the agent binary. Install the service script Before you proceed to install the service script, you need to determine which service manager your system is using: If you use one of the supported service managers (SystemD, SysV, and Upstart), use the service script provided in the tarball. If you use a service manager we do not support, you must write your own service script. Important In case of doubt, check your Linux distribution's official documentation. Determine your service manager There's no good way you can programmatically know which service manager is being used in your host, but we can give you some heuristics. To determine the service manager, use the following commands: command -v systemctl (used in Systemd) command -v update-rc.d (used in SysV) command -v initctl (used in Upstart) The first command that returns an output indicates which service manager your system uses. Tip For example, run the following sequence: $ command -v systemctl $ command -v initctl /sbin/initctl Copy Based on this output, Upstart is the service manager, since it's the command that obtained a return. Important Before copying the service manager script, check if you need to change the user, the path of the agent’s binary, or the pid file location. All these changes need to be reflected in the service script. If you use one of the supported service managers, install the service script for your host: Systemd Copy the service file ./newrelic-infra/etc/init_scripts/systemd/newrelic-infra.service to /etc/systemd/system/newrelic-infra.service Enable the service script: systemctl enable newrelic-infra.service Copy SysV Copy the service file ./newrelic-infra/etc/init_scripts/sysv/newrelic-infra to /etc/init.d/system/newrelic-infra Run the following commands: update-rc.d newrelic-infra defaults update-rc.d newrelic-infra enable Copy Upstart Copy the service file ./newrelic-infra/etc/init_scripts/upstart/newrelic-infra to /etc/init/newrelic-infra.conf Run the following command: initctl reload-configuration Copy Your service script is configured. Configure the rest of the options and start the service manually. Change config file's location The infrastructure agent includes a configuration file, usually named newrelic-infra.yml, to fine-tune the agent's behavior. For more information, see a config file template and how to configure the agent. By default, the agent searches for the configuration file in one of these locations: newrelic-infra.yml (working directory root folder) /etc/newrelic-infra.yml /etc/newrelic-infra/newrelic-infra.yml To specify a different location, use the -config flag command-line. For example: usr/bin/newrelic-infra -config /whatever/path/custom_config_name.yml Copy To make this change permanent, edit the service script: Systemd Open the service script ./newrelic-infra/etc/init_scripts/systemd/newrelic-infra.service. Search for the line ExecStart=/usr/bin/newrelic-infra. Add the config flag and the config file path. In this example the config file is located in the /opt directory ExecStart=/usr/bin/newrelic-infra -config /opt/config.yaml. Save the file. SysV Open the service script ./newrelic-infra/etc/init_scripts/sysv/newrelic-infra. Search for the line DAEMON=/usr/bin/$NAME”. Below the DAEMON variable, add this new line: EXTRA_OPTS=\"-config config_file\" (with the quotation marks). Replace config_file with the path to the config file you want to use. Save the file. Upstart Open the service script ./newrelic-infra/etc/init_scripts/upstart/newrelic-infra. Search for the line exec /usr/bin/newrelic-infra. Add the config flag and the config file path. Here the config file is located in the /opt directory exec /usr/bin/newrelic-infra -config /opt/config.yaml. Save the file. Change the pid-file location The infrastructure agent uses a pid-file to keep the process identification number (pid), which is used to identify a running instance of the agent. How to change the location of the pid-file depends on how the agent is configured. Important By default, we recommend that the agent creates the pid-file. You can edit the location if necessary. To change the location of the pid-file: If the agent creates the pid-file On startup, the agent writes its process pid into the pid-file. If the file doesn’t exist it will create it. By default, the agent creates the pid-file using the path /var/run/newrelic-infra/newrelic-infra.pid. To modify it, use one of these options: Add the pid_file configuration option in the configuration file newrelic-infra.yml. Provide the pid_file using the command line when running the newrelic-infra binary. Set the NRIA_PID_FILE environment variable. Important Since the agent creates or updates the pid-file every time it’s initialized, the user who runs the agent must have read/write permissions over the pid-file location. Use the chown command to give owner rights to a user. For example, if the user nri-agent is running the agent and the pid-file location is set to/var/run/newrelic-infra-custom/nr.pid, then you can give the user rights with: chown nri-agent:nri-agent /var/run/newrelic-infra-custom/ Copy If the agent uses the PIDFILE environment variable Caution We do not recommend using the PIDFILE environment variable to manage the pid-file. If the environment variable PIDFILE is set, the agent will not try to create the pid-file. Create the pid-file in a location of your choice. Tip Use this approach if someone else takes care of the pid-file lifecycle. For example, our init script sets the PIDFILE variable for some service managers, such as SysV, because they handle the creation and content of the pid-file. Change the user and runtime mode The Linux agent runs as root by default, but it also supports running with users with less privileges: PRIVILEGED and UNPRIVILEGED. For more information, see our documentation on agent running modes. Important To execute the agent as a non-root user (PRIVILEGED or UNPRIVILEGED), make sure to grant read/write access to the folders and files provided in the tarball. To change the running mode: Edit the service script: Systemd Open the service script ./newrelic-infra/etc/init_scripts/systemd/newrelic-infra.service. Search for the line [Service]. Add the line User=user_name, and replace user_name with the user that you want to execute the agent (PRIVILEGED or UNPRIVILEGED). Save the file. SysV Open the service script ./newrelic-infra/etc/init_scripts/sysv/newrelic-infra. Search for the line USER=root. Replace root with the user that you want to execute the agent (PRIVILEGED or UNPRIVILEGED). Save the file. Upstart Open the service script ./newrelic-infra/etc/init_scripts/upstart/newrelic-infra. Search for the line exec /usr/bin/newrelic-infra. Replace it with exec su -s /bin/sh -c ‘exec “$0” “$@“’ user_name-- /usr/bin/newrelic-infra. Replace user_name with the user that you want to execute the agent (PRIVILEGED or UNPRIVILEGED). Save the file. If you're running the agent as PRIVILEGED, you must give it two additional Linux capabilities: Make sure the libcap library is installed in your host. (You need the setcap and getcap commands that come with it.) Extract the contents of the tarball and execute the following command with root permission: setcap CAP_SYS_PTRACE,CAP_DAC_READ_SEARCH=+ep ./newrelic-infra/usr/bin/newrelic-infra Copy The run mode will be selected based on the current user and the Kernel Capabilities assigned to it. Configure the plugin directory The infrastructure agent allows you to install integrations that monitor and report data from popular services such as Kubernetes, AWS, MySQL, Redis, Kafka, etc. Each integration has its own configuration file, named by default integration-name-config.yml, placed in the predefined location /etc/newrelic-infra/integrations.d/. On initialization, the agent loads the config file. To overwrite the predefined location of the integration configuration file, use one of the following methods: Set the location in the NRIA_PLUGIN_DIR environment variable. Set the custom path in the newrelic-infra.yml configuration file using the plugin_dir field. Pass it as a command line argument using -plugin_dir when you run the newrelic-infra binary. Configure the agent directory The agent requires its own defined directory to run the installed integrations, caching data (inventory), etc. The default location is /var/db/newrelic-infra/. The agent directory has the following structure and content: LICENSE: Text file containing the New Relic Infrastructure agent license. custom-integrations: Directory that stores the installed the custom integrations. newrelic-integrations: Directory that stores the New Relic official integrations. data: Directory where the agent stores cache data (inventory). Important The user running the agent must have read/write permissions to the agent directory. To overwrite the predefined location of the agent directory, use one of the following methods: Set the location in the NRIA_AGENT_DIR environment variable. Set the custom path in the newrelic-infra.yml configuration file using the agent_dir field. Pass it as a command line argument using -agent_dir when you run the newrelic-infra binary. Configure the log file By default the agent stores the log files in /var/db/newrelic-infra/newrelic-infra.log. Important The user running the agent must have write permissions on the log file. To overwrite the predefined location of the log file, use one of the following methods: Set the location in the NRIA_LOG_FILE environment variable. Set the custom path in the newrelic-infra.yml configuration file using the log_file field. Pass it as a command line argument using -log_file when you run the newrelic-infra binary. Change the location of the agent binary To change the location of the executable, edit the service script: Systemd Open the service script ./newrelic-infra/etc/init_scripts/systemd/newrelic-infra.service. Search for the line [ExecStart=/usr/bin/newrelic-infra]. Replace the path. Save the file. SysV Open the service script ./newrelic-infra/etc/init_scripts/sysv/newrelic-infra. Search for the line DAEMON=/usr/bin/$NAME. Replace the path. Save the file. Upstart Open the service script ./newrelic-infra/etc/init_scripts/upstart/newrelic-infra. Search for the line exec /usr/bin/newrelic-infra. Replace the path. Save the file. What's next? You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Add other infrastructure integrations to collect data from external services. Manually start, stop, restart, or check the agent status.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 256.69296,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Tarball manual <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Linux</em> ",
        "sections": "Tarball manual <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Linux</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Our custom <em>Linux</em> <em>installation</em> process for <em>infrastructure</em> monitoring allows you to tailor all aspects of the <em>installation</em> process, and to place files and folders on your filesystem. You have full control of the <em>installation</em>. Caution The manual <em>install</em> process is not supervised. If you opt for manual"
      },
      "id": "603ea506196a671c21a83d8d"
    },
    {
      "sections": [
        "Linux agent running modes",
        "Metrics and inventory provided",
        "Run integrations",
        "On-host integrations",
        "Custom integrations",
        "Set the running mode for your agent",
        "Tip",
        "Switch running modes",
        "From root to privileged/unprivileged",
        "From privileged/unprivileged to any other mode",
        "Update the agent"
      ],
      "title": "Linux agent running modes",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "3b639657001e3b6d4456132ec586f24898e8ca99",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/linux-agent-running-modes/",
      "published_at": "2021-06-14T21:09:20Z",
      "updated_at": "2021-03-16T08:32:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent for Linux environments can run as root, privileged, or unprivileged user, which are described below: Mode Overview Root Installed by default. Runs as root and has total access to all the system metrics and inventory. Privileged Runs as a non-privileged user named nri-agent that is created automatically during the installation process. Normal users do not have READ access to all the system metrics, so the agent will not be able to report all the metrics of the root mode. However, privileged mode can collect more metrics than unprivileged mode, including most of the inventory. This is because at installation time, the /usr/bin/newrelic-infra executable is granted with CAP_SYS_PTRACE and CAP_DAC_READ_SEARCH kernel capabilities. Unprivileged Runs as a non-privileged user named nri-agent that is created automatically during the installation process. This mode is the most restricted. Normal users do not have READ access to all the system metrics, so the agent will not be able to report all the metrics of the root or privileged modes. Metrics and inventory provided The agent provides different metrics and inventory depending on the running mode: Mode Metrics and inventory Root All of the documented data and instrumentation values. Privileged All of the values from root mode, except: SELinux inventory: This depends on the semodule command, which requires root access. Docker process metrics: These are not enabled by default. However, you can manually enable them by giving access rights to the nri-agent user. Unprivileged All of the values from privileged mode, except: Process samples do not report these metrics: File descriptor count I/O read bytes per second I/O read count per second I/O total read bytes I/O total read count I/O total write bytes I/O total write count I/O write bytes per second I/O write count per second The following inventory sources are not reported: config/sshd kernel/sysctl packages/rpm packages/dpkg services/pidfile on SysV-based distributions Run integrations As root, integrations will run as usual. When running as privileged or unprivileged user, integrations will execute properly, although some custom integrations (for example, built by customers or technical sales staff) that depend on access to root may need additional configuration. On-host integrations In general, on-host integrations will run with the non-root agent as long as the nri-agent has permissions on the integration cache files. The default path where the integration cache files are stored is /tmp. To change the path, set the environment variable NRIA_CACHE_PATH. In this situation, use the following instructions to target the provided cache path folder instead of /tmp. On-host integrations Cache path folder Apache sudo chown nri-agent:nri-agent -R /tmp/nr-apache.json Copy Cassandra sudo chown nri-agent:nri-agent -R /tmp/nr-integrations Copy MySQL sudo chown nri-agent:nri-agent -R /tmp/nr-mysql.json Copy Nginx sudo chown nri-agent:nri-agent -R /tmp/nr-nginx.json Copy Redis sudo chown nri-agent:nri-agent -R /tmp/nr-redis.json Copy Custom integrations If your custom integration doesn't require root privileges, then it’s compatible with the rootless mode. To run it, you just need to change the owner:group of the cache file as explained above. If your integration requires to be executed with a privileged user, you can use the integration_user argument in the configuration integration. Set the running mode for your agent Tip When deciding which run mode to use, consider how much data you want to be able to collect and analyze, or how much data you want to restrict. For default and assisted installations, you can set the running mode by including the NRIA_MODE environment variable set to either ROOT, PRIVILEGED, or UNPRIVILEGED. For manual installations, follow the instructions described in our docs. Switch running modes From root to privileged/unprivileged To switch the running mode from root to privileged or unprivileged, follow the installation/update instructions in this doc. From privileged/unprivileged to any other mode To change the running mode from privileged or unprivileged to any other mode: Follow these steps: Debian/Ubuntu dpkg --purge newrelic-infra Copy OR sudo apt-get remove --purge newrelic-infra Copy Centos/Suse/RedHat/Amazon rpm -e newrelic-infra Copy OR sudo yum remove newrelic-infra Copy OR sudo zypper rm newrelic-infra Copy After making sure the agent is completely removed, reinstall the agent with the selected mode. Update the agent Follow standard procedures to update the infrastructure agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 256.69296,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Linux</em> <em>agent</em> running modes",
        "sections": "<em>Linux</em> <em>agent</em> running modes",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "The <em>infrastructure</em> <em>agent</em> for <em>Linux</em> environments can run as root, privileged, or unprivileged user, which are described below: Mode Overview Root Installed by default. Runs as root and has total access to all the system metrics and inventory. Privileged Runs as a non-privileged user named nri-<em>agent</em>"
      },
      "id": "603ea28464441f30a54e888a"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/linux-installation/linux-agent-running-modes": [
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Tip",
        "Quick start",
        "Install using the launcher",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-06-14T21:08:05Z",
      "updated_at": "2021-06-03T13:38:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. Tip To use infrastructure monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Install using the launcher Before installing our infrastructure monitoring agent for Linux, be sure to: Review the requirements. Have a valid New Relic license key. To install our infrastructure monitoring agent, click the button for your Linux distribution, then follow the instructions: Amazon Linux CentOS Container (Docker) Debian RHEL SLES Ubuntu Other Linux distros To use the links above, you must be logged to your New Relic account. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our step-by-step tutorial in the next section. Step-by-step instructions To install the infrastructure monitoring agent in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 12 (\"Precise\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt precise main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 14 (\"Trusty\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt trusty main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS / RHEL CentOS 7.x, RHEL 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS 7.x, RHEL 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS 8.x, RHEL 8.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS 8.x, RHEL 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 353.6704,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Our <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em> can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic <em>installation</em>. Tip To use <em>infrastructure</em> monitoring and the rest of our observability platform, join the New Relic"
      },
      "id": "6043edce64441f5335378f15"
    },
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-06-14T21:07:01Z",
      "updated_at": "2021-06-14T21:07:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. Built-in log forwarding and on-host integrations are not yet available. Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.10 to 1.16 Red Hat Enterprise Linux (RHEL) Version 6 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, and 12.4 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 (only the infrastructure agent is supported). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 292.44403,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Before installing our <em>infrastructure</em> <em>agent</em>, make sure your system and any on-host integrations you configure meet the requirements. Processor architectures The <em>infrastructure</em> <em>agent</em> supports these processor architectures: <em>Linux</em>: 64-bit for x86 processor architectures (also requires 64-bit package"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Tarball manual install of the infrastructure agent for Linux",
        "Caution",
        "Install the agent",
        "Install: Optional steps",
        "Install the service script",
        "Important",
        "Determine your service manager",
        "Tip",
        "Systemd",
        "SysV",
        "Upstart",
        "Change config file's location",
        "Change the pid-file location",
        "If the agent creates the pid-file",
        "If the agent uses the PIDFILE environment variable",
        "Change the user and runtime mode",
        "Configure the plugin directory",
        "Configure the agent directory",
        "Configure the log file",
        "Change the location of the agent binary",
        "What's next?"
      ],
      "title": "Tarball manual install of the infrastructure agent for Linux ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "3ed96e6fe181b3f1219f83dbecc10dc6002b69cb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/tarball-manual-install-infrastructure-agent-linux/",
      "published_at": "2021-06-14T21:10:26Z",
      "updated_at": "2021-03-16T08:32:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our custom Linux installation process for infrastructure monitoring allows you to tailor all aspects of the installation process, and to place files and folders on your filesystem. You have full control of the installation. Caution The manual install process is not supervised. If you opt for manual install, you are responsible for placing the different files in the correct folders, providing the correct parameterized configuration values, and ensuring the agent has all the permissions to execute. Install the agent Before installation, check the compatibility and requirements. Additional agent package options Comments Troubleshooting As of version 1.4.0, the infrastructure agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend that you add it in your path. Daemon process As of version 1.5.59, the infrastructure agent package includes the additional newrelic-infra-service binary, which is used to safely manage usual agent daemon process newrelic-infra. To install the agent: Download the packaged agent file. Unpack the file. Make sure the file unpacks with the following structure: newrelic-infra |-- config_defaults.sh |-- etc | |-- init_scripts | | |-- systemd | | | `-- newrelic-infra.service | | |-- sysv | | | `-- newrelic-infra | | `-- upstart | | `-- newrelic-infra | `-- newrelic-infra | `-- integrations.d |-- installer.sh |-- usr | `-- bin | |-- newrelic-infra | |-- newrelic-infra-ctl | `-- newrelic-infra-service `-- var |-- db | `-- newrelic-infra | |-- custom-integrations | |-- integrations.d | |-- LICENSE.txt | `-- newrelic-integrations |-- log | `-- newrelic-infra `-- run `-- newrelic-infra Copy Install the service script. Optional: Additional install steps. Install: Optional steps You can also carry out these additional steps: Change the location of the configuration file. Change the location of the PID file. Change the user and runtime mode. Configure the plugin directory. Configure the agent directory. Configure the log file. Change the location of the agent binary. Install the service script Before you proceed to install the service script, you need to determine which service manager your system is using: If you use one of the supported service managers (SystemD, SysV, and Upstart), use the service script provided in the tarball. If you use a service manager we do not support, you must write your own service script. Important In case of doubt, check your Linux distribution's official documentation. Determine your service manager There's no good way you can programmatically know which service manager is being used in your host, but we can give you some heuristics. To determine the service manager, use the following commands: command -v systemctl (used in Systemd) command -v update-rc.d (used in SysV) command -v initctl (used in Upstart) The first command that returns an output indicates which service manager your system uses. Tip For example, run the following sequence: $ command -v systemctl $ command -v initctl /sbin/initctl Copy Based on this output, Upstart is the service manager, since it's the command that obtained a return. Important Before copying the service manager script, check if you need to change the user, the path of the agent’s binary, or the pid file location. All these changes need to be reflected in the service script. If you use one of the supported service managers, install the service script for your host: Systemd Copy the service file ./newrelic-infra/etc/init_scripts/systemd/newrelic-infra.service to /etc/systemd/system/newrelic-infra.service Enable the service script: systemctl enable newrelic-infra.service Copy SysV Copy the service file ./newrelic-infra/etc/init_scripts/sysv/newrelic-infra to /etc/init.d/system/newrelic-infra Run the following commands: update-rc.d newrelic-infra defaults update-rc.d newrelic-infra enable Copy Upstart Copy the service file ./newrelic-infra/etc/init_scripts/upstart/newrelic-infra to /etc/init/newrelic-infra.conf Run the following command: initctl reload-configuration Copy Your service script is configured. Configure the rest of the options and start the service manually. Change config file's location The infrastructure agent includes a configuration file, usually named newrelic-infra.yml, to fine-tune the agent's behavior. For more information, see a config file template and how to configure the agent. By default, the agent searches for the configuration file in one of these locations: newrelic-infra.yml (working directory root folder) /etc/newrelic-infra.yml /etc/newrelic-infra/newrelic-infra.yml To specify a different location, use the -config flag command-line. For example: usr/bin/newrelic-infra -config /whatever/path/custom_config_name.yml Copy To make this change permanent, edit the service script: Systemd Open the service script ./newrelic-infra/etc/init_scripts/systemd/newrelic-infra.service. Search for the line ExecStart=/usr/bin/newrelic-infra. Add the config flag and the config file path. In this example the config file is located in the /opt directory ExecStart=/usr/bin/newrelic-infra -config /opt/config.yaml. Save the file. SysV Open the service script ./newrelic-infra/etc/init_scripts/sysv/newrelic-infra. Search for the line DAEMON=/usr/bin/$NAME”. Below the DAEMON variable, add this new line: EXTRA_OPTS=\"-config config_file\" (with the quotation marks). Replace config_file with the path to the config file you want to use. Save the file. Upstart Open the service script ./newrelic-infra/etc/init_scripts/upstart/newrelic-infra. Search for the line exec /usr/bin/newrelic-infra. Add the config flag and the config file path. Here the config file is located in the /opt directory exec /usr/bin/newrelic-infra -config /opt/config.yaml. Save the file. Change the pid-file location The infrastructure agent uses a pid-file to keep the process identification number (pid), which is used to identify a running instance of the agent. How to change the location of the pid-file depends on how the agent is configured. Important By default, we recommend that the agent creates the pid-file. You can edit the location if necessary. To change the location of the pid-file: If the agent creates the pid-file On startup, the agent writes its process pid into the pid-file. If the file doesn’t exist it will create it. By default, the agent creates the pid-file using the path /var/run/newrelic-infra/newrelic-infra.pid. To modify it, use one of these options: Add the pid_file configuration option in the configuration file newrelic-infra.yml. Provide the pid_file using the command line when running the newrelic-infra binary. Set the NRIA_PID_FILE environment variable. Important Since the agent creates or updates the pid-file every time it’s initialized, the user who runs the agent must have read/write permissions over the pid-file location. Use the chown command to give owner rights to a user. For example, if the user nri-agent is running the agent and the pid-file location is set to/var/run/newrelic-infra-custom/nr.pid, then you can give the user rights with: chown nri-agent:nri-agent /var/run/newrelic-infra-custom/ Copy If the agent uses the PIDFILE environment variable Caution We do not recommend using the PIDFILE environment variable to manage the pid-file. If the environment variable PIDFILE is set, the agent will not try to create the pid-file. Create the pid-file in a location of your choice. Tip Use this approach if someone else takes care of the pid-file lifecycle. For example, our init script sets the PIDFILE variable for some service managers, such as SysV, because they handle the creation and content of the pid-file. Change the user and runtime mode The Linux agent runs as root by default, but it also supports running with users with less privileges: PRIVILEGED and UNPRIVILEGED. For more information, see our documentation on agent running modes. Important To execute the agent as a non-root user (PRIVILEGED or UNPRIVILEGED), make sure to grant read/write access to the folders and files provided in the tarball. To change the running mode: Edit the service script: Systemd Open the service script ./newrelic-infra/etc/init_scripts/systemd/newrelic-infra.service. Search for the line [Service]. Add the line User=user_name, and replace user_name with the user that you want to execute the agent (PRIVILEGED or UNPRIVILEGED). Save the file. SysV Open the service script ./newrelic-infra/etc/init_scripts/sysv/newrelic-infra. Search for the line USER=root. Replace root with the user that you want to execute the agent (PRIVILEGED or UNPRIVILEGED). Save the file. Upstart Open the service script ./newrelic-infra/etc/init_scripts/upstart/newrelic-infra. Search for the line exec /usr/bin/newrelic-infra. Replace it with exec su -s /bin/sh -c ‘exec “$0” “$@“’ user_name-- /usr/bin/newrelic-infra. Replace user_name with the user that you want to execute the agent (PRIVILEGED or UNPRIVILEGED). Save the file. If you're running the agent as PRIVILEGED, you must give it two additional Linux capabilities: Make sure the libcap library is installed in your host. (You need the setcap and getcap commands that come with it.) Extract the contents of the tarball and execute the following command with root permission: setcap CAP_SYS_PTRACE,CAP_DAC_READ_SEARCH=+ep ./newrelic-infra/usr/bin/newrelic-infra Copy The run mode will be selected based on the current user and the Kernel Capabilities assigned to it. Configure the plugin directory The infrastructure agent allows you to install integrations that monitor and report data from popular services such as Kubernetes, AWS, MySQL, Redis, Kafka, etc. Each integration has its own configuration file, named by default integration-name-config.yml, placed in the predefined location /etc/newrelic-infra/integrations.d/. On initialization, the agent loads the config file. To overwrite the predefined location of the integration configuration file, use one of the following methods: Set the location in the NRIA_PLUGIN_DIR environment variable. Set the custom path in the newrelic-infra.yml configuration file using the plugin_dir field. Pass it as a command line argument using -plugin_dir when you run the newrelic-infra binary. Configure the agent directory The agent requires its own defined directory to run the installed integrations, caching data (inventory), etc. The default location is /var/db/newrelic-infra/. The agent directory has the following structure and content: LICENSE: Text file containing the New Relic Infrastructure agent license. custom-integrations: Directory that stores the installed the custom integrations. newrelic-integrations: Directory that stores the New Relic official integrations. data: Directory where the agent stores cache data (inventory). Important The user running the agent must have read/write permissions to the agent directory. To overwrite the predefined location of the agent directory, use one of the following methods: Set the location in the NRIA_AGENT_DIR environment variable. Set the custom path in the newrelic-infra.yml configuration file using the agent_dir field. Pass it as a command line argument using -agent_dir when you run the newrelic-infra binary. Configure the log file By default the agent stores the log files in /var/db/newrelic-infra/newrelic-infra.log. Important The user running the agent must have write permissions on the log file. To overwrite the predefined location of the log file, use one of the following methods: Set the location in the NRIA_LOG_FILE environment variable. Set the custom path in the newrelic-infra.yml configuration file using the log_file field. Pass it as a command line argument using -log_file when you run the newrelic-infra binary. Change the location of the agent binary To change the location of the executable, edit the service script: Systemd Open the service script ./newrelic-infra/etc/init_scripts/systemd/newrelic-infra.service. Search for the line [ExecStart=/usr/bin/newrelic-infra]. Replace the path. Save the file. SysV Open the service script ./newrelic-infra/etc/init_scripts/sysv/newrelic-infra. Search for the line DAEMON=/usr/bin/$NAME. Replace the path. Save the file. Upstart Open the service script ./newrelic-infra/etc/init_scripts/upstart/newrelic-infra. Search for the line exec /usr/bin/newrelic-infra. Replace the path. Save the file. What's next? You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Add other infrastructure integrations to collect data from external services. Manually start, stop, restart, or check the agent status.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 256.69296,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Tarball manual <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Linux</em> ",
        "sections": "Tarball manual <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Linux</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Our custom <em>Linux</em> <em>installation</em> process for <em>infrastructure</em> monitoring allows you to tailor all aspects of the <em>installation</em> process, and to place files and folders on your filesystem. You have full control of the <em>installation</em>. Caution The manual <em>install</em> process is not supervised. If you opt for manual"
      },
      "id": "603ea506196a671c21a83d8d"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/linux-installation/tarball-assisted-install-infrastructure-agent-linux": [
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Tip",
        "Quick start",
        "Install using the launcher",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-06-14T21:08:05Z",
      "updated_at": "2021-06-03T13:38:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. Tip To use infrastructure monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Install using the launcher Before installing our infrastructure monitoring agent for Linux, be sure to: Review the requirements. Have a valid New Relic license key. To install our infrastructure monitoring agent, click the button for your Linux distribution, then follow the instructions: Amazon Linux CentOS Container (Docker) Debian RHEL SLES Ubuntu Other Linux distros To use the links above, you must be logged to your New Relic account. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our step-by-step tutorial in the next section. Step-by-step instructions To install the infrastructure monitoring agent in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 12 (\"Precise\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt precise main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 14 (\"Trusty\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt trusty main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS / RHEL CentOS 7.x, RHEL 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS 7.x, RHEL 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS 8.x, RHEL 8.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS 8.x, RHEL 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 353.6704,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Our <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em> can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic <em>installation</em>. Tip To use <em>infrastructure</em> monitoring and the rest of our observability platform, join the New Relic"
      },
      "id": "6043edce64441f5335378f15"
    },
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-06-14T21:07:01Z",
      "updated_at": "2021-06-14T21:07:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. Built-in log forwarding and on-host integrations are not yet available. Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.10 to 1.16 Red Hat Enterprise Linux (RHEL) Version 6 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, and 12.4 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 (only the infrastructure agent is supported). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 292.44403,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Before installing our <em>infrastructure</em> <em>agent</em>, make sure your system and any on-host integrations you configure meet the requirements. Processor architectures The <em>infrastructure</em> <em>agent</em> supports these processor architectures: <em>Linux</em>: 64-bit for x86 processor architectures (also requires 64-bit package"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Tarball manual install of the infrastructure agent for Linux",
        "Caution",
        "Install the agent",
        "Install: Optional steps",
        "Install the service script",
        "Important",
        "Determine your service manager",
        "Tip",
        "Systemd",
        "SysV",
        "Upstart",
        "Change config file's location",
        "Change the pid-file location",
        "If the agent creates the pid-file",
        "If the agent uses the PIDFILE environment variable",
        "Change the user and runtime mode",
        "Configure the plugin directory",
        "Configure the agent directory",
        "Configure the log file",
        "Change the location of the agent binary",
        "What's next?"
      ],
      "title": "Tarball manual install of the infrastructure agent for Linux ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "3ed96e6fe181b3f1219f83dbecc10dc6002b69cb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/tarball-manual-install-infrastructure-agent-linux/",
      "published_at": "2021-06-14T21:10:26Z",
      "updated_at": "2021-03-16T08:32:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our custom Linux installation process for infrastructure monitoring allows you to tailor all aspects of the installation process, and to place files and folders on your filesystem. You have full control of the installation. Caution The manual install process is not supervised. If you opt for manual install, you are responsible for placing the different files in the correct folders, providing the correct parameterized configuration values, and ensuring the agent has all the permissions to execute. Install the agent Before installation, check the compatibility and requirements. Additional agent package options Comments Troubleshooting As of version 1.4.0, the infrastructure agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend that you add it in your path. Daemon process As of version 1.5.59, the infrastructure agent package includes the additional newrelic-infra-service binary, which is used to safely manage usual agent daemon process newrelic-infra. To install the agent: Download the packaged agent file. Unpack the file. Make sure the file unpacks with the following structure: newrelic-infra |-- config_defaults.sh |-- etc | |-- init_scripts | | |-- systemd | | | `-- newrelic-infra.service | | |-- sysv | | | `-- newrelic-infra | | `-- upstart | | `-- newrelic-infra | `-- newrelic-infra | `-- integrations.d |-- installer.sh |-- usr | `-- bin | |-- newrelic-infra | |-- newrelic-infra-ctl | `-- newrelic-infra-service `-- var |-- db | `-- newrelic-infra | |-- custom-integrations | |-- integrations.d | |-- LICENSE.txt | `-- newrelic-integrations |-- log | `-- newrelic-infra `-- run `-- newrelic-infra Copy Install the service script. Optional: Additional install steps. Install: Optional steps You can also carry out these additional steps: Change the location of the configuration file. Change the location of the PID file. Change the user and runtime mode. Configure the plugin directory. Configure the agent directory. Configure the log file. Change the location of the agent binary. Install the service script Before you proceed to install the service script, you need to determine which service manager your system is using: If you use one of the supported service managers (SystemD, SysV, and Upstart), use the service script provided in the tarball. If you use a service manager we do not support, you must write your own service script. Important In case of doubt, check your Linux distribution's official documentation. Determine your service manager There's no good way you can programmatically know which service manager is being used in your host, but we can give you some heuristics. To determine the service manager, use the following commands: command -v systemctl (used in Systemd) command -v update-rc.d (used in SysV) command -v initctl (used in Upstart) The first command that returns an output indicates which service manager your system uses. Tip For example, run the following sequence: $ command -v systemctl $ command -v initctl /sbin/initctl Copy Based on this output, Upstart is the service manager, since it's the command that obtained a return. Important Before copying the service manager script, check if you need to change the user, the path of the agent’s binary, or the pid file location. All these changes need to be reflected in the service script. If you use one of the supported service managers, install the service script for your host: Systemd Copy the service file ./newrelic-infra/etc/init_scripts/systemd/newrelic-infra.service to /etc/systemd/system/newrelic-infra.service Enable the service script: systemctl enable newrelic-infra.service Copy SysV Copy the service file ./newrelic-infra/etc/init_scripts/sysv/newrelic-infra to /etc/init.d/system/newrelic-infra Run the following commands: update-rc.d newrelic-infra defaults update-rc.d newrelic-infra enable Copy Upstart Copy the service file ./newrelic-infra/etc/init_scripts/upstart/newrelic-infra to /etc/init/newrelic-infra.conf Run the following command: initctl reload-configuration Copy Your service script is configured. Configure the rest of the options and start the service manually. Change config file's location The infrastructure agent includes a configuration file, usually named newrelic-infra.yml, to fine-tune the agent's behavior. For more information, see a config file template and how to configure the agent. By default, the agent searches for the configuration file in one of these locations: newrelic-infra.yml (working directory root folder) /etc/newrelic-infra.yml /etc/newrelic-infra/newrelic-infra.yml To specify a different location, use the -config flag command-line. For example: usr/bin/newrelic-infra -config /whatever/path/custom_config_name.yml Copy To make this change permanent, edit the service script: Systemd Open the service script ./newrelic-infra/etc/init_scripts/systemd/newrelic-infra.service. Search for the line ExecStart=/usr/bin/newrelic-infra. Add the config flag and the config file path. In this example the config file is located in the /opt directory ExecStart=/usr/bin/newrelic-infra -config /opt/config.yaml. Save the file. SysV Open the service script ./newrelic-infra/etc/init_scripts/sysv/newrelic-infra. Search for the line DAEMON=/usr/bin/$NAME”. Below the DAEMON variable, add this new line: EXTRA_OPTS=\"-config config_file\" (with the quotation marks). Replace config_file with the path to the config file you want to use. Save the file. Upstart Open the service script ./newrelic-infra/etc/init_scripts/upstart/newrelic-infra. Search for the line exec /usr/bin/newrelic-infra. Add the config flag and the config file path. Here the config file is located in the /opt directory exec /usr/bin/newrelic-infra -config /opt/config.yaml. Save the file. Change the pid-file location The infrastructure agent uses a pid-file to keep the process identification number (pid), which is used to identify a running instance of the agent. How to change the location of the pid-file depends on how the agent is configured. Important By default, we recommend that the agent creates the pid-file. You can edit the location if necessary. To change the location of the pid-file: If the agent creates the pid-file On startup, the agent writes its process pid into the pid-file. If the file doesn’t exist it will create it. By default, the agent creates the pid-file using the path /var/run/newrelic-infra/newrelic-infra.pid. To modify it, use one of these options: Add the pid_file configuration option in the configuration file newrelic-infra.yml. Provide the pid_file using the command line when running the newrelic-infra binary. Set the NRIA_PID_FILE environment variable. Important Since the agent creates or updates the pid-file every time it’s initialized, the user who runs the agent must have read/write permissions over the pid-file location. Use the chown command to give owner rights to a user. For example, if the user nri-agent is running the agent and the pid-file location is set to/var/run/newrelic-infra-custom/nr.pid, then you can give the user rights with: chown nri-agent:nri-agent /var/run/newrelic-infra-custom/ Copy If the agent uses the PIDFILE environment variable Caution We do not recommend using the PIDFILE environment variable to manage the pid-file. If the environment variable PIDFILE is set, the agent will not try to create the pid-file. Create the pid-file in a location of your choice. Tip Use this approach if someone else takes care of the pid-file lifecycle. For example, our init script sets the PIDFILE variable for some service managers, such as SysV, because they handle the creation and content of the pid-file. Change the user and runtime mode The Linux agent runs as root by default, but it also supports running with users with less privileges: PRIVILEGED and UNPRIVILEGED. For more information, see our documentation on agent running modes. Important To execute the agent as a non-root user (PRIVILEGED or UNPRIVILEGED), make sure to grant read/write access to the folders and files provided in the tarball. To change the running mode: Edit the service script: Systemd Open the service script ./newrelic-infra/etc/init_scripts/systemd/newrelic-infra.service. Search for the line [Service]. Add the line User=user_name, and replace user_name with the user that you want to execute the agent (PRIVILEGED or UNPRIVILEGED). Save the file. SysV Open the service script ./newrelic-infra/etc/init_scripts/sysv/newrelic-infra. Search for the line USER=root. Replace root with the user that you want to execute the agent (PRIVILEGED or UNPRIVILEGED). Save the file. Upstart Open the service script ./newrelic-infra/etc/init_scripts/upstart/newrelic-infra. Search for the line exec /usr/bin/newrelic-infra. Replace it with exec su -s /bin/sh -c ‘exec “$0” “$@“’ user_name-- /usr/bin/newrelic-infra. Replace user_name with the user that you want to execute the agent (PRIVILEGED or UNPRIVILEGED). Save the file. If you're running the agent as PRIVILEGED, you must give it two additional Linux capabilities: Make sure the libcap library is installed in your host. (You need the setcap and getcap commands that come with it.) Extract the contents of the tarball and execute the following command with root permission: setcap CAP_SYS_PTRACE,CAP_DAC_READ_SEARCH=+ep ./newrelic-infra/usr/bin/newrelic-infra Copy The run mode will be selected based on the current user and the Kernel Capabilities assigned to it. Configure the plugin directory The infrastructure agent allows you to install integrations that monitor and report data from popular services such as Kubernetes, AWS, MySQL, Redis, Kafka, etc. Each integration has its own configuration file, named by default integration-name-config.yml, placed in the predefined location /etc/newrelic-infra/integrations.d/. On initialization, the agent loads the config file. To overwrite the predefined location of the integration configuration file, use one of the following methods: Set the location in the NRIA_PLUGIN_DIR environment variable. Set the custom path in the newrelic-infra.yml configuration file using the plugin_dir field. Pass it as a command line argument using -plugin_dir when you run the newrelic-infra binary. Configure the agent directory The agent requires its own defined directory to run the installed integrations, caching data (inventory), etc. The default location is /var/db/newrelic-infra/. The agent directory has the following structure and content: LICENSE: Text file containing the New Relic Infrastructure agent license. custom-integrations: Directory that stores the installed the custom integrations. newrelic-integrations: Directory that stores the New Relic official integrations. data: Directory where the agent stores cache data (inventory). Important The user running the agent must have read/write permissions to the agent directory. To overwrite the predefined location of the agent directory, use one of the following methods: Set the location in the NRIA_AGENT_DIR environment variable. Set the custom path in the newrelic-infra.yml configuration file using the agent_dir field. Pass it as a command line argument using -agent_dir when you run the newrelic-infra binary. Configure the log file By default the agent stores the log files in /var/db/newrelic-infra/newrelic-infra.log. Important The user running the agent must have write permissions on the log file. To overwrite the predefined location of the log file, use one of the following methods: Set the location in the NRIA_LOG_FILE environment variable. Set the custom path in the newrelic-infra.yml configuration file using the log_file field. Pass it as a command line argument using -log_file when you run the newrelic-infra binary. Change the location of the agent binary To change the location of the executable, edit the service script: Systemd Open the service script ./newrelic-infra/etc/init_scripts/systemd/newrelic-infra.service. Search for the line [ExecStart=/usr/bin/newrelic-infra]. Replace the path. Save the file. SysV Open the service script ./newrelic-infra/etc/init_scripts/sysv/newrelic-infra. Search for the line DAEMON=/usr/bin/$NAME. Replace the path. Save the file. Upstart Open the service script ./newrelic-infra/etc/init_scripts/upstart/newrelic-infra. Search for the line exec /usr/bin/newrelic-infra. Replace the path. Save the file. What's next? You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Add other infrastructure integrations to collect data from external services. Manually start, stop, restart, or check the agent status.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 256.69296,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Tarball manual <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Linux</em> ",
        "sections": "Tarball manual <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Linux</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Our custom <em>Linux</em> <em>installation</em> process for <em>infrastructure</em> monitoring allows you to tailor all aspects of the <em>installation</em> process, and to place files and folders on your filesystem. You have full control of the <em>installation</em>. Caution The manual <em>install</em> process is not supervised. If you opt for manual"
      },
      "id": "603ea506196a671c21a83d8d"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/linux-installation/tarball-manual-install-infrastructure-agent-linux": [
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Tip",
        "Quick start",
        "Install using the launcher",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-06-14T21:08:05Z",
      "updated_at": "2021-06-03T13:38:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. Tip To use infrastructure monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Install using the launcher Before installing our infrastructure monitoring agent for Linux, be sure to: Review the requirements. Have a valid New Relic license key. To install our infrastructure monitoring agent, click the button for your Linux distribution, then follow the instructions: Amazon Linux CentOS Container (Docker) Debian RHEL SLES Ubuntu Other Linux distros To use the links above, you must be logged to your New Relic account. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our step-by-step tutorial in the next section. Step-by-step instructions To install the infrastructure monitoring agent in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 12 (\"Precise\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt precise main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 14 (\"Trusty\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt trusty main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS / RHEL CentOS 7.x, RHEL 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS 7.x, RHEL 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS 8.x, RHEL 8.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS 8.x, RHEL 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 353.67035,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Our <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em> can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic <em>installation</em>. Tip To use <em>infrastructure</em> monitoring and the rest of our observability platform, join the New Relic"
      },
      "id": "6043edce64441f5335378f15"
    },
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-06-14T21:07:01Z",
      "updated_at": "2021-06-14T21:07:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. Built-in log forwarding and on-host integrations are not yet available. Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.10 to 1.16 Red Hat Enterprise Linux (RHEL) Version 6 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, and 12.4 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 (only the infrastructure agent is supported). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 292.44382,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Before installing our <em>infrastructure</em> <em>agent</em>, make sure your system and any on-host integrations you configure meet the requirements. Processor architectures The <em>infrastructure</em> <em>agent</em> supports these processor architectures: <em>Linux</em>: 64-bit for x86 processor architectures (also requires 64-bit package"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Linux agent running modes",
        "Metrics and inventory provided",
        "Run integrations",
        "On-host integrations",
        "Custom integrations",
        "Set the running mode for your agent",
        "Tip",
        "Switch running modes",
        "From root to privileged/unprivileged",
        "From privileged/unprivileged to any other mode",
        "Update the agent"
      ],
      "title": "Linux agent running modes",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "3b639657001e3b6d4456132ec586f24898e8ca99",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/linux-agent-running-modes/",
      "published_at": "2021-06-14T21:09:20Z",
      "updated_at": "2021-03-16T08:32:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent for Linux environments can run as root, privileged, or unprivileged user, which are described below: Mode Overview Root Installed by default. Runs as root and has total access to all the system metrics and inventory. Privileged Runs as a non-privileged user named nri-agent that is created automatically during the installation process. Normal users do not have READ access to all the system metrics, so the agent will not be able to report all the metrics of the root mode. However, privileged mode can collect more metrics than unprivileged mode, including most of the inventory. This is because at installation time, the /usr/bin/newrelic-infra executable is granted with CAP_SYS_PTRACE and CAP_DAC_READ_SEARCH kernel capabilities. Unprivileged Runs as a non-privileged user named nri-agent that is created automatically during the installation process. This mode is the most restricted. Normal users do not have READ access to all the system metrics, so the agent will not be able to report all the metrics of the root or privileged modes. Metrics and inventory provided The agent provides different metrics and inventory depending on the running mode: Mode Metrics and inventory Root All of the documented data and instrumentation values. Privileged All of the values from root mode, except: SELinux inventory: This depends on the semodule command, which requires root access. Docker process metrics: These are not enabled by default. However, you can manually enable them by giving access rights to the nri-agent user. Unprivileged All of the values from privileged mode, except: Process samples do not report these metrics: File descriptor count I/O read bytes per second I/O read count per second I/O total read bytes I/O total read count I/O total write bytes I/O total write count I/O write bytes per second I/O write count per second The following inventory sources are not reported: config/sshd kernel/sysctl packages/rpm packages/dpkg services/pidfile on SysV-based distributions Run integrations As root, integrations will run as usual. When running as privileged or unprivileged user, integrations will execute properly, although some custom integrations (for example, built by customers or technical sales staff) that depend on access to root may need additional configuration. On-host integrations In general, on-host integrations will run with the non-root agent as long as the nri-agent has permissions on the integration cache files. The default path where the integration cache files are stored is /tmp. To change the path, set the environment variable NRIA_CACHE_PATH. In this situation, use the following instructions to target the provided cache path folder instead of /tmp. On-host integrations Cache path folder Apache sudo chown nri-agent:nri-agent -R /tmp/nr-apache.json Copy Cassandra sudo chown nri-agent:nri-agent -R /tmp/nr-integrations Copy MySQL sudo chown nri-agent:nri-agent -R /tmp/nr-mysql.json Copy Nginx sudo chown nri-agent:nri-agent -R /tmp/nr-nginx.json Copy Redis sudo chown nri-agent:nri-agent -R /tmp/nr-redis.json Copy Custom integrations If your custom integration doesn't require root privileges, then it’s compatible with the rootless mode. To run it, you just need to change the owner:group of the cache file as explained above. If your integration requires to be executed with a privileged user, you can use the integration_user argument in the configuration integration. Set the running mode for your agent Tip When deciding which run mode to use, consider how much data you want to be able to collect and analyze, or how much data you want to restrict. For default and assisted installations, you can set the running mode by including the NRIA_MODE environment variable set to either ROOT, PRIVILEGED, or UNPRIVILEGED. For manual installations, follow the instructions described in our docs. Switch running modes From root to privileged/unprivileged To switch the running mode from root to privileged or unprivileged, follow the installation/update instructions in this doc. From privileged/unprivileged to any other mode To change the running mode from privileged or unprivileged to any other mode: Follow these steps: Debian/Ubuntu dpkg --purge newrelic-infra Copy OR sudo apt-get remove --purge newrelic-infra Copy Centos/Suse/RedHat/Amazon rpm -e newrelic-infra Copy OR sudo yum remove newrelic-infra Copy OR sudo zypper rm newrelic-infra Copy After making sure the agent is completely removed, reinstall the agent with the selected mode. Update the agent Follow standard procedures to update the infrastructure agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 256.69296,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Linux</em> <em>agent</em> running modes",
        "sections": "<em>Linux</em> <em>agent</em> running modes",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "The <em>infrastructure</em> <em>agent</em> for <em>Linux</em> environments can run as root, privileged, or unprivileged user, which are described below: Mode Overview Root Installed by default. Runs as root and has total access to all the system metrics and inventory. Privileged Runs as a non-privileged user named nri-<em>agent</em>"
      },
      "id": "603ea28464441f30a54e888a"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/manage-your-agent/agent-message-size": [
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-06-14T21:07:01Z",
      "updated_at": "2021-06-14T21:07:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. Built-in log forwarding and on-host integrations are not yet available. Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.10 to 1.16 Red Hat Enterprise Linux (RHEL) Version 6 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, and 12.4 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 (only the infrastructure agent is supported). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 323.843,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " to run. Libraries For <em>agent</em> versions 1.1.19 or higher, you need the libcap library in order to <em>install</em> <em>Infrastructure</em>. It&#x27;s available in the official repositories of <em>your</em> distribution. Network access In order to report data to New Relic, our <em>infrastructure</em> <em>agent</em> must have outbound access to certain"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Infrastructure agent behavior",
        "Agent service",
        "Agent startup",
        "Monitoring and resource caps",
        "Integration data",
        "Agent shutdown",
        "Maintenance",
        "Retry behavior",
        "Manage data reporting"
      ],
      "title": "Infrastructure agent behavior",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "704d0716fb7aa5a09d0db4a9fff12e53adb31758",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/infrastructure-agent-behavior/",
      "published_at": "2021-06-14T21:10:26Z",
      "updated_at": "2021-03-16T08:32:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the infrastructure agent, you can monitor not only individual servers, but also understand how your service performs as a whole. The agent supports Amazon Linux, CentOS, Debian, RHEL, and Ubuntu as well as Windows Server. All of these agent versions exhibit a common set of behaviors. Agent service As of infrastructure agent v1.5.59, the agent bundles a binary named newrelic-infra-service. This binary can be managed by the OS service manager. At service startup time, this binary spawns (executes) the usual newrelic-infra process and supervises its child execution. Therefore agent service process should never be restarted, unless triggered via OS service manager. Agent startup During startup the agent will: Register a signal handler. Set the loggers. Load the configuration from file, environment variables, and call arguments. Register plugins for harvesting inventory, samplers, and integrations. StatsD integration with http_server_enabled\" Open an http port (by default, 8001) for receiving data. Startup duration before harvesting and sending data is usually less than six seconds. Monitoring and resource caps By default, the infrastructure agent runs in a single core. Every second it checks if there are events to send and, if there are, it sends them to the New Relic collector. Events that may be sent include: Default infrastructure events Events recorded by New Relic integrations. For descriptions of the default infrastructure events and their collection frequencies, see Infrastructure events. Integration data Integration monitoring is done by executing integration commands at given intervals (set in the config files) and reading their stout/err. The more integrations you enable, the greater the footprint of the agent. For more information, see the documentation for specific integrations. Agent shutdown When a shutdown signal is received, the agent stops all the registered plugins and integration processes. Maintenance The agent runs as a service. On installation, we set up all the service manager-required files, such as the systemD. service file. In case of a catastrophic failure, the service manager configuration will restart the agent. There are no automatic updates to agents. To install a new agent version: Linux: Manually install agent versions through the appropriate package manager (apt, yum, zypper). Windows: Manually download the msi package and install it with msiexec.exe. Retry behavior If a request made to the ingest service is unsuccessful, the payload is discarded; subsequent requests follow an exponential backoff pattern until one succeeds. For inventory, we store the deltas between system states in cache files. On failure, these deltas are not deleted but are reused on requests that follow. Manage data reporting For information about configuring reporting of data, see Manage data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.56064,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> behavior",
        "sections": "<em>Infrastructure</em> <em>agent</em> behavior",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "With the <em>infrastructure</em> <em>agent</em>, you can monitor not only individual servers, but also understand how <em>your</em> service performs as a whole. The <em>agent</em> supports Amazon Linux, CentOS, Debian, RHEL, and Ubuntu as well as Windows Server. All of these <em>agent</em> versions exhibit a common set of behaviors. <em>Agent</em>"
      },
      "id": "603eb68428ccbc8576eba7a5"
    },
    {
      "sections": [
        "Troubleshoot a running infrastructure agent",
        "Linux newrelic-infra-ctl",
        "Important",
        "Windows newrelic-infra-ctl"
      ],
      "title": "Troubleshoot a running infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "e1f206feb686f819c00db0619a8534609fe19c53",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/troubleshoot-running-infrastructure-agent/",
      "published_at": "2021-06-14T21:12:22Z",
      "updated_at": "2021-03-16T07:33:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can troubleshoot our infrastructure agent using our newrelic-infra-ctl utility. This binary is also included in the installation package, in the same directory as the newrelic-infra default binary. Upon receiving the newrelic-infra-ctl command, the agent: Enables verbose logs for a period of five minutes, then reverts the log level to its previous setting. Logs all the agent config options. Logs all the integrations config options. Executes a health check for every loaded integration. (A health check is an immediate execution of the integration with extra logs and output validation.) Linux newrelic-infra-ctl In Linux systems, the troubleshooting binary is /usr/bin/newrelic-infra-ctl, available in both the package manager or the tarball assisted install methods. Important When running on Linux, newrelic-infra-ctl must be executed by either the root user or the same user running the newrelic-infra process. The newrelic-infra-ctl binary can automatically detect the agent process running in the host. It can also detect whether the agent is running inside a container. To change the default settings of newrelic-infra-ctl: To change... Execute pid newrelic-infra-ctl -pid 14580 cid (when using a containerized version of the agent) newrelic-infra-ctl -cid 8fddbcbb101c docker-api-version newrelic-infra-ctl -docker-api-version 1.24 Windows newrelic-infra-ctl In Windows, using the MSI installer, the troubleshooting binary is C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra-ctl.exe. Important In Windows, the agent process is always automatically detected. It does not depend on the pid or the cid.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.54913,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot a running <em>infrastructure</em> <em>agent</em>",
        "sections": "Troubleshoot a running <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "You can troubleshoot our <em>infrastructure</em> <em>agent</em> using our newrelic-infra-ctl utility. This binary is also included in the installation package, in the same directory as the newrelic-infra default binary. Upon receiving the newrelic-infra-ctl command, the <em>agent</em>: Enables verbose logs for a period"
      },
      "id": "603eb3dee7b9d22a5f2f736b"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/manage-your-agent/infrastructure-agent-behavior": [
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-06-14T21:07:01Z",
      "updated_at": "2021-06-14T21:07:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. Built-in log forwarding and on-host integrations are not yet available. Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.10 to 1.16 Red Hat Enterprise Linux (RHEL) Version 6 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, and 12.4 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 (only the infrastructure agent is supported). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 323.84277,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " to run. Libraries For <em>agent</em> versions 1.1.19 or higher, you need the libcap library in order to <em>install</em> <em>Infrastructure</em>. It&#x27;s available in the official repositories of <em>your</em> distribution. Network access In order to report data to New Relic, our <em>infrastructure</em> <em>agent</em> must have outbound access to certain"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Agent message size"
      ],
      "title": "Agent message size",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "a762f70a367322dd6fa16c0825cbf3c3495b6b6c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/agent-message-size/",
      "published_at": "2021-06-14T21:10:26Z",
      "updated_at": "2021-03-16T08:32:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Since infrastructure agent version 1.0.989, the maximum message size is 1MB (10^6 bytes), and it can include events, metrics, and inventory integrations indistinctly. Previously, the maximum message size was 5MB, although inventory data was limited to 3MB.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.5606,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Agent</em> message size",
        "sections": "<em>Agent</em> message size",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Since <em>infrastructure</em> <em>agent</em> version 1.0.989, the maximum message size is 1MB (10^6 bytes), and it can include events, metrics, and inventory integrations indistinctly. Previously, the maximum message size was 5MB, although inventory data was limited to 3MB."
      },
      "id": "603ea87628ccbc6062eba74a"
    },
    {
      "sections": [
        "Troubleshoot a running infrastructure agent",
        "Linux newrelic-infra-ctl",
        "Important",
        "Windows newrelic-infra-ctl"
      ],
      "title": "Troubleshoot a running infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "e1f206feb686f819c00db0619a8534609fe19c53",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/troubleshoot-running-infrastructure-agent/",
      "published_at": "2021-06-14T21:12:22Z",
      "updated_at": "2021-03-16T07:33:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can troubleshoot our infrastructure agent using our newrelic-infra-ctl utility. This binary is also included in the installation package, in the same directory as the newrelic-infra default binary. Upon receiving the newrelic-infra-ctl command, the agent: Enables verbose logs for a period of five minutes, then reverts the log level to its previous setting. Logs all the agent config options. Logs all the integrations config options. Executes a health check for every loaded integration. (A health check is an immediate execution of the integration with extra logs and output validation.) Linux newrelic-infra-ctl In Linux systems, the troubleshooting binary is /usr/bin/newrelic-infra-ctl, available in both the package manager or the tarball assisted install methods. Important When running on Linux, newrelic-infra-ctl must be executed by either the root user or the same user running the newrelic-infra process. The newrelic-infra-ctl binary can automatically detect the agent process running in the host. It can also detect whether the agent is running inside a container. To change the default settings of newrelic-infra-ctl: To change... Execute pid newrelic-infra-ctl -pid 14580 cid (when using a containerized version of the agent) newrelic-infra-ctl -cid 8fddbcbb101c docker-api-version newrelic-infra-ctl -docker-api-version 1.24 Windows newrelic-infra-ctl In Windows, using the MSI installer, the troubleshooting binary is C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra-ctl.exe. Important In Windows, the agent process is always automatically detected. It does not depend on the pid or the cid.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.54913,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot a running <em>infrastructure</em> <em>agent</em>",
        "sections": "Troubleshoot a running <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "You can troubleshoot our <em>infrastructure</em> <em>agent</em> using our newrelic-infra-ctl utility. This binary is also included in the installation package, in the same directory as the newrelic-infra default binary. Upon receiving the newrelic-infra-ctl command, the <em>agent</em>: Enables verbose logs for a period"
      },
      "id": "603eb3dee7b9d22a5f2f736b"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/manage-your-agent/infrastructure-agent-performance-overhead": [
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-06-14T21:07:01Z",
      "updated_at": "2021-06-14T21:07:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. Built-in log forwarding and on-host integrations are not yet available. Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.10 to 1.16 Red Hat Enterprise Linux (RHEL) Version 6 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, and 12.4 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 (only the infrastructure agent is supported). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 323.84277,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " to run. Libraries For <em>agent</em> versions 1.1.19 or higher, you need the libcap library in order to <em>install</em> <em>Infrastructure</em>. It&#x27;s available in the official repositories of <em>your</em> distribution. Network access In order to report data to New Relic, our <em>infrastructure</em> <em>agent</em> must have outbound access to certain"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Agent message size"
      ],
      "title": "Agent message size",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "a762f70a367322dd6fa16c0825cbf3c3495b6b6c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/agent-message-size/",
      "published_at": "2021-06-14T21:10:26Z",
      "updated_at": "2021-03-16T08:32:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Since infrastructure agent version 1.0.989, the maximum message size is 1MB (10^6 bytes), and it can include events, metrics, and inventory integrations indistinctly. Previously, the maximum message size was 5MB, although inventory data was limited to 3MB.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.5606,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Agent</em> message size",
        "sections": "<em>Agent</em> message size",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Since <em>infrastructure</em> <em>agent</em> version 1.0.989, the maximum message size is 1MB (10^6 bytes), and it can include events, metrics, and inventory integrations indistinctly. Previously, the maximum message size was 5MB, although inventory data was limited to 3MB."
      },
      "id": "603ea87628ccbc6062eba74a"
    },
    {
      "sections": [
        "Infrastructure agent behavior",
        "Agent service",
        "Agent startup",
        "Monitoring and resource caps",
        "Integration data",
        "Agent shutdown",
        "Maintenance",
        "Retry behavior",
        "Manage data reporting"
      ],
      "title": "Infrastructure agent behavior",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "704d0716fb7aa5a09d0db4a9fff12e53adb31758",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/infrastructure-agent-behavior/",
      "published_at": "2021-06-14T21:10:26Z",
      "updated_at": "2021-03-16T08:32:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the infrastructure agent, you can monitor not only individual servers, but also understand how your service performs as a whole. The agent supports Amazon Linux, CentOS, Debian, RHEL, and Ubuntu as well as Windows Server. All of these agent versions exhibit a common set of behaviors. Agent service As of infrastructure agent v1.5.59, the agent bundles a binary named newrelic-infra-service. This binary can be managed by the OS service manager. At service startup time, this binary spawns (executes) the usual newrelic-infra process and supervises its child execution. Therefore agent service process should never be restarted, unless triggered via OS service manager. Agent startup During startup the agent will: Register a signal handler. Set the loggers. Load the configuration from file, environment variables, and call arguments. Register plugins for harvesting inventory, samplers, and integrations. StatsD integration with http_server_enabled\" Open an http port (by default, 8001) for receiving data. Startup duration before harvesting and sending data is usually less than six seconds. Monitoring and resource caps By default, the infrastructure agent runs in a single core. Every second it checks if there are events to send and, if there are, it sends them to the New Relic collector. Events that may be sent include: Default infrastructure events Events recorded by New Relic integrations. For descriptions of the default infrastructure events and their collection frequencies, see Infrastructure events. Integration data Integration monitoring is done by executing integration commands at given intervals (set in the config files) and reading their stout/err. The more integrations you enable, the greater the footprint of the agent. For more information, see the documentation for specific integrations. Agent shutdown When a shutdown signal is received, the agent stops all the registered plugins and integration processes. Maintenance The agent runs as a service. On installation, we set up all the service manager-required files, such as the systemD. service file. In case of a catastrophic failure, the service manager configuration will restart the agent. There are no automatic updates to agents. To install a new agent version: Linux: Manually install agent versions through the appropriate package manager (apt, yum, zypper). Windows: Manually download the msi package and install it with msiexec.exe. Retry behavior If a request made to the ingest service is unsuccessful, the payload is discarded; subsequent requests follow an exponential backoff pattern until one succeeds. For inventory, we store the deltas between system states in cache files. On failure, these deltas are not deleted but are reused on requests that follow. Manage data reporting For information about configuring reporting of data, see Manage data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.5606,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> behavior",
        "sections": "<em>Infrastructure</em> <em>agent</em> behavior",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "With the <em>infrastructure</em> <em>agent</em>, you can monitor not only individual servers, but also understand how <em>your</em> service performs as a whole. The <em>agent</em> supports Amazon Linux, CentOS, Debian, RHEL, and Ubuntu as well as Windows Server. All of these <em>agent</em> versions exhibit a common set of behaviors. <em>Agent</em>"
      },
      "id": "603eb68428ccbc8576eba7a5"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/manage-your-agent/start-stop-restart-infrastructure-agent": [
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-06-14T21:07:01Z",
      "updated_at": "2021-06-14T21:07:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. Built-in log forwarding and on-host integrations are not yet available. Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.10 to 1.16 Red Hat Enterprise Linux (RHEL) Version 6 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, and 12.4 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 (only the infrastructure agent is supported). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 323.84277,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " to run. Libraries For <em>agent</em> versions 1.1.19 or higher, you need the libcap library in order to <em>install</em> <em>Infrastructure</em>. It&#x27;s available in the official repositories of <em>your</em> distribution. Network access In order to report data to New Relic, our <em>infrastructure</em> <em>agent</em> must have outbound access to certain"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Agent message size"
      ],
      "title": "Agent message size",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "a762f70a367322dd6fa16c0825cbf3c3495b6b6c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/agent-message-size/",
      "published_at": "2021-06-14T21:10:26Z",
      "updated_at": "2021-03-16T08:32:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Since infrastructure agent version 1.0.989, the maximum message size is 1MB (10^6 bytes), and it can include events, metrics, and inventory integrations indistinctly. Previously, the maximum message size was 5MB, although inventory data was limited to 3MB.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.5606,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Agent</em> message size",
        "sections": "<em>Agent</em> message size",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Since <em>infrastructure</em> <em>agent</em> version 1.0.989, the maximum message size is 1MB (10^6 bytes), and it can include events, metrics, and inventory integrations indistinctly. Previously, the maximum message size was 5MB, although inventory data was limited to 3MB."
      },
      "id": "603ea87628ccbc6062eba74a"
    },
    {
      "sections": [
        "Infrastructure agent behavior",
        "Agent service",
        "Agent startup",
        "Monitoring and resource caps",
        "Integration data",
        "Agent shutdown",
        "Maintenance",
        "Retry behavior",
        "Manage data reporting"
      ],
      "title": "Infrastructure agent behavior",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "704d0716fb7aa5a09d0db4a9fff12e53adb31758",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/infrastructure-agent-behavior/",
      "published_at": "2021-06-14T21:10:26Z",
      "updated_at": "2021-03-16T08:32:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the infrastructure agent, you can monitor not only individual servers, but also understand how your service performs as a whole. The agent supports Amazon Linux, CentOS, Debian, RHEL, and Ubuntu as well as Windows Server. All of these agent versions exhibit a common set of behaviors. Agent service As of infrastructure agent v1.5.59, the agent bundles a binary named newrelic-infra-service. This binary can be managed by the OS service manager. At service startup time, this binary spawns (executes) the usual newrelic-infra process and supervises its child execution. Therefore agent service process should never be restarted, unless triggered via OS service manager. Agent startup During startup the agent will: Register a signal handler. Set the loggers. Load the configuration from file, environment variables, and call arguments. Register plugins for harvesting inventory, samplers, and integrations. StatsD integration with http_server_enabled\" Open an http port (by default, 8001) for receiving data. Startup duration before harvesting and sending data is usually less than six seconds. Monitoring and resource caps By default, the infrastructure agent runs in a single core. Every second it checks if there are events to send and, if there are, it sends them to the New Relic collector. Events that may be sent include: Default infrastructure events Events recorded by New Relic integrations. For descriptions of the default infrastructure events and their collection frequencies, see Infrastructure events. Integration data Integration monitoring is done by executing integration commands at given intervals (set in the config files) and reading their stout/err. The more integrations you enable, the greater the footprint of the agent. For more information, see the documentation for specific integrations. Agent shutdown When a shutdown signal is received, the agent stops all the registered plugins and integration processes. Maintenance The agent runs as a service. On installation, we set up all the service manager-required files, such as the systemD. service file. In case of a catastrophic failure, the service manager configuration will restart the agent. There are no automatic updates to agents. To install a new agent version: Linux: Manually install agent versions through the appropriate package manager (apt, yum, zypper). Windows: Manually download the msi package and install it with msiexec.exe. Retry behavior If a request made to the ingest service is unsuccessful, the payload is discarded; subsequent requests follow an exponential backoff pattern until one succeeds. For inventory, we store the deltas between system states in cache files. On failure, these deltas are not deleted but are reused on requests that follow. Manage data reporting For information about configuring reporting of data, see Manage data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.5606,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> behavior",
        "sections": "<em>Infrastructure</em> <em>agent</em> behavior",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "With the <em>infrastructure</em> <em>agent</em>, you can monitor not only individual servers, but also understand how <em>your</em> service performs as a whole. The <em>agent</em> supports Amazon Linux, CentOS, Debian, RHEL, and Ubuntu as well as Windows Server. All of these <em>agent</em> versions exhibit a common set of behaviors. <em>Agent</em>"
      },
      "id": "603eb68428ccbc8576eba7a5"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/manage-your-agent/troubleshoot-running-infrastructure-agent": [
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-06-14T21:07:01Z",
      "updated_at": "2021-06-14T21:07:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. Built-in log forwarding and on-host integrations are not yet available. Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.10 to 1.16 Red Hat Enterprise Linux (RHEL) Version 6 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, and 12.4 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 (only the infrastructure agent is supported). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 323.84256,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " to run. Libraries For <em>agent</em> versions 1.1.19 or higher, you need the libcap library in order to <em>install</em> <em>Infrastructure</em>. It&#x27;s available in the official repositories of <em>your</em> distribution. Network access In order to report data to New Relic, our <em>infrastructure</em> <em>agent</em> must have outbound access to certain"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Agent message size"
      ],
      "title": "Agent message size",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "a762f70a367322dd6fa16c0825cbf3c3495b6b6c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/agent-message-size/",
      "published_at": "2021-06-14T21:10:26Z",
      "updated_at": "2021-03-16T08:32:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Since infrastructure agent version 1.0.989, the maximum message size is 1MB (10^6 bytes), and it can include events, metrics, and inventory integrations indistinctly. Previously, the maximum message size was 5MB, although inventory data was limited to 3MB.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.5606,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Agent</em> message size",
        "sections": "<em>Agent</em> message size",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Since <em>infrastructure</em> <em>agent</em> version 1.0.989, the maximum message size is 1MB (10^6 bytes), and it can include events, metrics, and inventory integrations indistinctly. Previously, the maximum message size was 5MB, although inventory data was limited to 3MB."
      },
      "id": "603ea87628ccbc6062eba74a"
    },
    {
      "sections": [
        "Infrastructure agent behavior",
        "Agent service",
        "Agent startup",
        "Monitoring and resource caps",
        "Integration data",
        "Agent shutdown",
        "Maintenance",
        "Retry behavior",
        "Manage data reporting"
      ],
      "title": "Infrastructure agent behavior",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "704d0716fb7aa5a09d0db4a9fff12e53adb31758",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/infrastructure-agent-behavior/",
      "published_at": "2021-06-14T21:10:26Z",
      "updated_at": "2021-03-16T08:32:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the infrastructure agent, you can monitor not only individual servers, but also understand how your service performs as a whole. The agent supports Amazon Linux, CentOS, Debian, RHEL, and Ubuntu as well as Windows Server. All of these agent versions exhibit a common set of behaviors. Agent service As of infrastructure agent v1.5.59, the agent bundles a binary named newrelic-infra-service. This binary can be managed by the OS service manager. At service startup time, this binary spawns (executes) the usual newrelic-infra process and supervises its child execution. Therefore agent service process should never be restarted, unless triggered via OS service manager. Agent startup During startup the agent will: Register a signal handler. Set the loggers. Load the configuration from file, environment variables, and call arguments. Register plugins for harvesting inventory, samplers, and integrations. StatsD integration with http_server_enabled\" Open an http port (by default, 8001) for receiving data. Startup duration before harvesting and sending data is usually less than six seconds. Monitoring and resource caps By default, the infrastructure agent runs in a single core. Every second it checks if there are events to send and, if there are, it sends them to the New Relic collector. Events that may be sent include: Default infrastructure events Events recorded by New Relic integrations. For descriptions of the default infrastructure events and their collection frequencies, see Infrastructure events. Integration data Integration monitoring is done by executing integration commands at given intervals (set in the config files) and reading their stout/err. The more integrations you enable, the greater the footprint of the agent. For more information, see the documentation for specific integrations. Agent shutdown When a shutdown signal is received, the agent stops all the registered plugins and integration processes. Maintenance The agent runs as a service. On installation, we set up all the service manager-required files, such as the systemD. service file. In case of a catastrophic failure, the service manager configuration will restart the agent. There are no automatic updates to agents. To install a new agent version: Linux: Manually install agent versions through the appropriate package manager (apt, yum, zypper). Windows: Manually download the msi package and install it with msiexec.exe. Retry behavior If a request made to the ingest service is unsuccessful, the payload is discarded; subsequent requests follow an exponential backoff pattern until one succeeds. For inventory, we store the deltas between system states in cache files. On failure, these deltas are not deleted but are reused on requests that follow. Manage data reporting For information about configuring reporting of data, see Manage data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.5606,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> behavior",
        "sections": "<em>Infrastructure</em> <em>agent</em> behavior",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "With the <em>infrastructure</em> <em>agent</em>, you can monitor not only individual servers, but also understand how <em>your</em> service performs as a whole. The <em>agent</em> supports Amazon Linux, CentOS, Debian, RHEL, and Ubuntu as well as Windows Server. All of these <em>agent</em> versions exhibit a common set of behaviors. <em>Agent</em>"
      },
      "id": "603eb68428ccbc8576eba7a5"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/update-or-uninstall/uninstall-infrastructure-agent": [
    {
      "sections": [
        "Uninstall infrastructure integrations",
        "Cloud integrations",
        "AWS",
        "Azure",
        "Google Cloud Platform (GCP)",
        "On-host integrations",
        "Apache",
        "Cassandra",
        "Kubernetes",
        "MySQL",
        "NGINX",
        "Redis",
        "StatsD",
        "Moving away from the integrations package",
        "Uninstall package"
      ],
      "title": "Uninstall infrastructure integrations",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Update or uninstall"
      ],
      "external_id": "1e9232193cbf71bdbe1a6c6d0374ed0d6b7e7b0f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/update-or-uninstall/uninstall-infrastructure-integrations/",
      "published_at": "2021-06-15T02:32:23Z",
      "updated_at": "2021-05-16T10:05:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Uninstalling the infrastructure agent does not directly affect any of your infrastructure Integrations: if you uninstall the agent, your integrations will remain. Similarly, if you disable or uninstall your integrations, the infrastructure agent will remain. To uninstall any of your integrations, follow the procedure corresponding to the type of integration. Cloud integrations AWS You can disable infrastructure AWS integrations and still retain the connection between your AWS account and New Relic. We recommend not to disable your EC2 and EBS integrations because those add important metadata to your infrastructure data. If you want to... Do this Disable one or more AWS service integrations To disable services while keeping your AWS account linked to New Relic: From one.newrelic.com > Infrastructure, select AWS > Manage services. From your Edit AWS account page, clear the checkbox for each active service you want to disable. Save your changes. Disable all AWS integrations To disconnect your AWS account completely from New Relic, you need to unlink your AWS account. This disables all New Relic integrations associated with that AWS account. Go to one.newrelic.com > Infrastructure > AWS > Manage services. From your Edit AWS account page, select Unlink this account. Save your changes. Sign in to AWS and select Services > IAM > Roles. Select the checkbox for the role you want to delete, then select Role Actions > Delete Role. Unlinking your AWS account will disable the trust relationship set up via your ARN. Azure If you want to... Do this Disable one or more Azure service integrations To disable services while keeping your Azure account linked to New Relic: Go to one.newrelic.com > Infrastructure > Azure > Manage services. From your Edit Azure account page, clear the checkbox for each active service you want to disable. Save your changes. Disable all Azure integrations To disconnect your Azure account completely from New Relic, you need to unlink your Azure account. This requires being either the user who registered the app or an administrator. This procedure will disable all New Relic integrations associated with that Azure account. Go to one.newrelic.com > Infrastructure > Azure > Manage services. From your Edit Azure account page, select Unlink this account. Save your changes. Sign in to Azure and go into All Services > Identity > App registrations, or go to Azure Active Directory service and select App registrations. Find the registered app (the recommended name is NewRelic-Integrations). To see the full list of available apps, select the dropdown menu beside the search field and select All apps. Select the app and, on the panel that opens, select Delete. Google Cloud Platform (GCP) If you want to... Do this Disable one or more GCP service integrations To disable services while keeping your GCP account linked to New Relic: From one.newrelic.com > Infrastructure > GCP > Manage services. From your Edit GCP account page, clear the checkbox for each active service you want to disable. Save your changes. Disable all GCP integrations To disconnect your GCP account completely from New Relic, you need to unlink your GCP account. This disables all New Relic integrations associated with that GCP account. If you registered the GCP project using a User account, follow these steps. Go to one.newrelic.com > Infrastructure > GCP > Manage services. From your Edit GCP account page, select Unlink this account. Save your changes. If you registered the GCP project using a Service account, follow these steps. If you are deleting a custom role, be aware that this role may be used for other purposes besides New Relic access. Sign in to New Relic and go to Infrastructure > Integrations > Google Cloud Platform. For a standard (non-custom) user role, select Manage Services for the account you want to remove. Copy the value of User and save it. OR For a custom user role, go to IAM > admin > Roles, search for the role, select it, and select DELETE. You are now finished and can skip the remaining steps. Standard (non-custom) user role: Sign in to Google Cloud and select the correct project in the Select a project box. From the navigation menu, select IAM & admin > IAM. Search for and select the user value you saved, then select REMOVE. On-host integrations If you used the integrations package, see the integrations package instructions. Here are some examples: Apache Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove nri-apache yum (Amazon Linux, CentOS, or RHEL) sudo yum remove nri-apache zypper (SLES) sudo zypper -n remove nri-apache Cassandra Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove nri-cassandra yum (Amazon Linux, CentOS, or RHEL) sudo yum remove nri-cassandra zypper (SLES) sudo zypper -n remove nri-cassandra Kubernetes Each cluster will have a single node where kubectl is running. To uninstall the Kubernetes integration, use the following command on each of these nodes: kubectl delete -f newrelic-infrastructure-k8s-latest.yaml Copy MySQL Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove nri-mysql yum (Amazon Linux, CentOS, or RHEL) sudo yum remove nri-mysql zypper (SLES) sudo zypper -n remove nri-mysql NGINX Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove nri-nginx yum (Amazon Linux, CentOS, or RHEL) sudo yum remove nri-nginx zypper (SLES) sudo zypper -n remove nri-nginx Redis Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove nri-redis yum (Amazon Linux, CentOS, or RHEL) sudo yum remove nri-redis zypper (SLES) sudo zypper -n remove nri-redis StatsD cd /path/to/statsd npm uninstall @newrelic/statsd-infra-backend From the StatsD config.js, remove the \"@newrelic/statsd-infra-backend\" entry from the list of backends. Restart StatsD. Moving away from the integrations package While it is still possible to use the integrations package, we recommend removing it completely and working with integrations on an individual basis. The last integration package contains the following versions of the integrations: Apache 1.1.2 Cassandra 2.0.3 MySQL 1.1.5 Nginx 1.0.2 Redis 1.0.1 If you remove the integrations package and want to continue using the related on-host integrations, you will need to install them one by one. To uninstall the package and re-install your integrations: Remove the integrations package by following these instructions. The config files from the old integrations will not be deleted, so you won’t have to configure them again. Uninstall package Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove newrelic-infra-integrations sudo apt-get autoremove yum (Amazon Linux, CentOS, or RHEL) sudo yum remove newrelic-infra-integrations sudo yum autoremove zypper (SLES) sudo zypper -n remove newrelic-infra-integrations --clean-deps Copy Install your integrations one by one following these instructions. To replicate the integrations package, you will need to install all the available integrations again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 377.45898,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Uninstall</em> <em>infrastructure</em> integrations",
        "sections": "<em>Uninstall</em> <em>infrastructure</em> integrations",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Uninstalling the <em>infrastructure</em> <em>agent</em> does not directly affect any of your <em>infrastructure</em> Integrations: if you <em>uninstall</em> the <em>agent</em>, your integrations will remain. Similarly, if you disable or <em>uninstall</em> your integrations, the <em>infrastructure</em> <em>agent</em> will remain. To <em>uninstall</em> any of your integrations"
      },
      "id": "603ea831196a67fc6fa83db5"
    },
    {
      "sections": [
        "Update the infrastructure agent",
        "Tip",
        "View the infrastructure agent version",
        "Update the agent for installs using the package manager",
        "Update using apt (Debian, Ubuntu)",
        "Update using yum (Amazon Linux, CentOS, RHEL)",
        "Update using Zypper (SLES)",
        "Update on Windows Server (32 bits)",
        "Update on Windows Server (64 bits)",
        "Update with config management tools",
        "Update the agent for assisted and manual tarball installs",
        "Important",
        "Update the containerized version of the agent",
        "Identify outdated agent versions from the UI"
      ],
      "title": "Update the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Update or uninstall"
      ],
      "external_id": "1ddaa00ceaf5936084d25f207f868d89fd0957f6",
      "image": "https://docs.newrelic.com/static/06b72c159cd2d6b502bb7cbab7a98e67/103b3/ebs.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/update-or-uninstall/update-infrastructure-agent/",
      "published_at": "2021-06-15T02:32:23Z",
      "updated_at": "2021-05-16T10:05:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to update the infrastructure agent to the latest version for Linux and Windows servers. Tip To install the infrastructure agent for the first time, see the installation documentation for Linux, Windows, or configuration management tools. To uninstall the infrastructure agent, see Uninstall the Infrastructure agent. View the infrastructure agent version The infrastructure agent does not update itself automatically. Check the infrastructure agent release notes to make sure you have the latest agent version. To view the current infrastructure agent version for a host, use any of these options: Go to one.newrelic.com > Infrastructure > Settings > Agents > Agent version. Go to one.newrelic.com > Infrastructure > Hosts > (select a host). Create a query for SystemSample. Update the agent for installs using the package manager If you used the default installation process, use your package manager to update the program and its dependencies to the latest version. Here are examples for some common systems: Update using apt ( Debian, Ubuntu) To manually update the infrastructure agent with apt-get: sudo apt-get update && sudo apt-get install --only-upgrade newrelic-infra -y Copy Update using yum ( Amazon Linux, CentOS, RHEL) To manually update the infrastructure agent with yum: sudo yum update newrelic-infra -y Copy After updating you may need to start the agent. Update using Zypper ( SLES) To manually update the infrastructure agent with Zypper: sudo zypper -n update newrelic-infra Copy After updating you may need to start the agent. Update on Windows Server (32 bits) To manually update the infrastructure agent on Windows Server: Download the latest .MSI installer image from download.newrelic.com/infrastructure_agent/windows/386/newrelic-infra-386.msi Run the install script. To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\newrelic-infra-386.msi Copy After updating you may need to start the agent. Update on Windows Server (64 bits) To manually update the infrastructure agent on Windows Server: Download the latest .MSI installer image from download.newrelic.com/infrastructure_agent/windows/newrelic-infra.msi Run the install script. To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\newrelic-infra.msi Copy After updating you may need to start the agent. Update with config management tools To update the infrastructure agent using your configuration management tool, see the documentation for your tool: Configure with Ansible Configure with Chef Configure with AWS Elastic Beanstalk Configure with Puppet Update the agent for assisted and manual tarball installs Important Since there are are no automated scripts, old files may remain when you update. Be sure to manually remove outdated files. To update the agent, download the file again and follow the installation procedure for Linux (assisted or manual) or Windows (assisted or manual). This will overwrite your old installation. Update the containerized version of the agent Use the latest label to ensure that our Docker image is automatically updated. Identify outdated agent versions from the UI You can use the Infrastructure monitoring UI to search for outdated agent versions: Go to one.newrelic.com > Infrastructure > Inventory * * * * . In the search bar, type newrelic-infra. Select a group's dropdown to see the agent versions for that group. To manually check the infrastructure agent versions, you can log onto a server and run newrelic-infra --version, or the applicable command for your package manager.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 377.45898,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Update</em> the <em>infrastructure</em> <em>agent</em>",
        "sections": "<em>Update</em> <em>the</em> <em>agent</em> for <em>installs</em> using <em>the</em> package manager",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Read on to learn how to <em>update</em> the <em>infrastructure</em> <em>agent</em> to the latest version for Linux and Windows servers. Tip To <em>install</em> the <em>infrastructure</em> <em>agent</em> for the first time, see the installation documentation for Linux, Windows, or configuration management tools. To <em>uninstall</em> the <em>infrastructure</em> <em>agent</em>"
      },
      "id": "60440e8fe7b9d252a2579a19"
    },
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-06-14T21:07:01Z",
      "updated_at": "2021-06-14T21:07:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. Built-in log forwarding and on-host integrations are not yet available. Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.10 to 1.16 Red Hat Enterprise Linux (RHEL) Version 6 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, and 12.4 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 (only the infrastructure agent is supported). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 323.84256,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized <em>agent</em>. On EKS, <em>install</em> the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The <em>infrastructure</em> <em>agent</em> uses the hostname to uniquely identify each server. To avoid"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/update-or-uninstall/uninstall-infrastructure-integrations": [
    {
      "sections": [
        "Update the infrastructure agent",
        "Tip",
        "View the infrastructure agent version",
        "Update the agent for installs using the package manager",
        "Update using apt (Debian, Ubuntu)",
        "Update using yum (Amazon Linux, CentOS, RHEL)",
        "Update using Zypper (SLES)",
        "Update on Windows Server (32 bits)",
        "Update on Windows Server (64 bits)",
        "Update with config management tools",
        "Update the agent for assisted and manual tarball installs",
        "Important",
        "Update the containerized version of the agent",
        "Identify outdated agent versions from the UI"
      ],
      "title": "Update the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Update or uninstall"
      ],
      "external_id": "1ddaa00ceaf5936084d25f207f868d89fd0957f6",
      "image": "https://docs.newrelic.com/static/06b72c159cd2d6b502bb7cbab7a98e67/103b3/ebs.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/update-or-uninstall/update-infrastructure-agent/",
      "published_at": "2021-06-15T02:32:23Z",
      "updated_at": "2021-05-16T10:05:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to update the infrastructure agent to the latest version for Linux and Windows servers. Tip To install the infrastructure agent for the first time, see the installation documentation for Linux, Windows, or configuration management tools. To uninstall the infrastructure agent, see Uninstall the Infrastructure agent. View the infrastructure agent version The infrastructure agent does not update itself automatically. Check the infrastructure agent release notes to make sure you have the latest agent version. To view the current infrastructure agent version for a host, use any of these options: Go to one.newrelic.com > Infrastructure > Settings > Agents > Agent version. Go to one.newrelic.com > Infrastructure > Hosts > (select a host). Create a query for SystemSample. Update the agent for installs using the package manager If you used the default installation process, use your package manager to update the program and its dependencies to the latest version. Here are examples for some common systems: Update using apt ( Debian, Ubuntu) To manually update the infrastructure agent with apt-get: sudo apt-get update && sudo apt-get install --only-upgrade newrelic-infra -y Copy Update using yum ( Amazon Linux, CentOS, RHEL) To manually update the infrastructure agent with yum: sudo yum update newrelic-infra -y Copy After updating you may need to start the agent. Update using Zypper ( SLES) To manually update the infrastructure agent with Zypper: sudo zypper -n update newrelic-infra Copy After updating you may need to start the agent. Update on Windows Server (32 bits) To manually update the infrastructure agent on Windows Server: Download the latest .MSI installer image from download.newrelic.com/infrastructure_agent/windows/386/newrelic-infra-386.msi Run the install script. To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\newrelic-infra-386.msi Copy After updating you may need to start the agent. Update on Windows Server (64 bits) To manually update the infrastructure agent on Windows Server: Download the latest .MSI installer image from download.newrelic.com/infrastructure_agent/windows/newrelic-infra.msi Run the install script. To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\newrelic-infra.msi Copy After updating you may need to start the agent. Update with config management tools To update the infrastructure agent using your configuration management tool, see the documentation for your tool: Configure with Ansible Configure with Chef Configure with AWS Elastic Beanstalk Configure with Puppet Update the agent for assisted and manual tarball installs Important Since there are are no automated scripts, old files may remain when you update. Be sure to manually remove outdated files. To update the agent, download the file again and follow the installation procedure for Linux (assisted or manual) or Windows (assisted or manual). This will overwrite your old installation. Update the containerized version of the agent Use the latest label to ensure that our Docker image is automatically updated. Identify outdated agent versions from the UI You can use the Infrastructure monitoring UI to search for outdated agent versions: Go to one.newrelic.com > Infrastructure > Inventory * * * * . In the search bar, type newrelic-infra. Select a group's dropdown to see the agent versions for that group. To manually check the infrastructure agent versions, you can log onto a server and run newrelic-infra --version, or the applicable command for your package manager.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 377.45892,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Update</em> the <em>infrastructure</em> <em>agent</em>",
        "sections": "<em>Update</em> <em>the</em> <em>agent</em> for <em>installs</em> using <em>the</em> package manager",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Read on to learn how to <em>update</em> the <em>infrastructure</em> <em>agent</em> to the latest version for Linux and Windows servers. Tip To <em>install</em> the <em>infrastructure</em> <em>agent</em> for the first time, see the installation documentation for Linux, Windows, or configuration management tools. To <em>uninstall</em> the <em>infrastructure</em> <em>agent</em>"
      },
      "id": "60440e8fe7b9d252a2579a19"
    },
    {
      "sections": [
        "Uninstall the infrastructure agent",
        "Uninstall the Linux infrastructure agent",
        "Uninstall with apt (Debian, Ubuntu)",
        "Uninstall with yum (Amazon Linux, CentOS, RHEL)",
        "Uninstall with Zypper (SLES)",
        "Important",
        "Uninstall the Windows infrastructure agent",
        "Tip",
        "Uninstall using config management tools",
        "Optional: Purge remaining files"
      ],
      "title": "Uninstall the infrastructure agent ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Update or uninstall"
      ],
      "external_id": "d99fe6244698657f7f2e67bc6f6fcbfc9d8ffbf9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/update-or-uninstall/uninstall-infrastructure-agent/",
      "published_at": "2021-06-14T21:12:22Z",
      "updated_at": "2021-03-16T08:33:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Your hosts are added automatically when you install the infrastructure agent for your Linux or Windows operating system, or update the agent. Similarly, your hosts disappear automatically when you uninstall the agent. You do not need to manually add or remove your hosts. Uninstalling the agent does not directly affect any of your integrations. To uninstall an integration, see Uninstall integrations. Uninstall the Linux infrastructure agent If you used the default install procedure for your infrastructure agent for Linux environments, use your package management tools to uninstall it. You do not need to stop the service before running the uninstall command. Uninstall with apt ( Debian, Ubuntu) Execute the following command as root: sudo apt-get remove newrelic-infra Copy Uninstall with yum ( Amazon Linux, CentOS, RHEL) Execute the following command as root: sudo yum remove newrelic-infra Copy Uninstall with Zypper ( SLES) Execute the following command as root: sudo zypper -n remove newrelic-infra Copy If you followed an assisted or manual installation process, you need to manually delete all the files created when you unpacked the agent file. Important Since there are are no automated scripts, old files may remain when you uninstall. Be sure to manually remove outdated files. Uninstall the Windows infrastructure agent Tip Requires Administrator rights in your Windows admin group. If you used the default install procedure for the infrastructure agent for Windows environments, to uninstall: Stop the infrastructure agent. From the Windows Control Panel, use the Add/Remove Programs and Features tool to uninstall the infrastructure agent. From the Windows Program Files, manually delete the New Relic folder to delete all files associated with the infrastructure agent for Windows. If you followed an assisted or manual installation process, you need to manually delete all the files created when you unpacked the agent file. Important Since there are are no automated scripts, old files may remain when you uninstall. Be sure to manually remove outdated files. Uninstall using config management tools To uninstall the infrastructure agent if you used a configuration management tool: Config management tools Uninstall New Relic infrastructure agent Ansible Set the 'agent_state' parameter to 'absent' Chef Set the 'agent_action' node to uninstall AWS Elastic Beanstalk Remove newrelic.config from .ebextensions, then deploy. Puppet Set the 'ensure' parameter to 'absent' Optional: Purge remaining files If you use standard package management tools for your selected platform, the uninstall process typically leaves configuration and other miscellaneous files. If you need to completely purge any of the remaining files after uninstalling the New Relic infrastructure agent, follow standard procedures for your operating system.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 326.6892,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Uninstall</em> the <em>infrastructure</em> <em>agent</em> ",
        "sections": "<em>Uninstall</em> the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Your hosts are added automatically when you <em>install</em> the <em>infrastructure</em> <em>agent</em> for your Linux or Windows operating system, or <em>update</em> the <em>agent</em>. Similarly, your hosts disappear automatically when you <em>uninstall</em> the <em>agent</em>. You do not need to manually add or remove your hosts. Uninstalling the <em>agent</em> does"
      },
      "id": "603ea0e964441f31114e885c"
    },
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-06-14T21:07:01Z",
      "updated_at": "2021-06-14T21:07:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. Built-in log forwarding and on-host integrations are not yet available. Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.10 to 1.16 Red Hat Enterprise Linux (RHEL) Version 6 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, and 12.4 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 (only the infrastructure agent is supported). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 323.84235,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized <em>agent</em>. On EKS, <em>install</em> the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The <em>infrastructure</em> <em>agent</em> uses the hostname to uniquely identify each server. To avoid"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/update-or-uninstall/update-infrastructure-agent": [
    {
      "sections": [
        "Uninstall infrastructure integrations",
        "Cloud integrations",
        "AWS",
        "Azure",
        "Google Cloud Platform (GCP)",
        "On-host integrations",
        "Apache",
        "Cassandra",
        "Kubernetes",
        "MySQL",
        "NGINX",
        "Redis",
        "StatsD",
        "Moving away from the integrations package",
        "Uninstall package"
      ],
      "title": "Uninstall infrastructure integrations",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Update or uninstall"
      ],
      "external_id": "1e9232193cbf71bdbe1a6c6d0374ed0d6b7e7b0f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/update-or-uninstall/uninstall-infrastructure-integrations/",
      "published_at": "2021-06-15T02:32:23Z",
      "updated_at": "2021-05-16T10:05:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Uninstalling the infrastructure agent does not directly affect any of your infrastructure Integrations: if you uninstall the agent, your integrations will remain. Similarly, if you disable or uninstall your integrations, the infrastructure agent will remain. To uninstall any of your integrations, follow the procedure corresponding to the type of integration. Cloud integrations AWS You can disable infrastructure AWS integrations and still retain the connection between your AWS account and New Relic. We recommend not to disable your EC2 and EBS integrations because those add important metadata to your infrastructure data. If you want to... Do this Disable one or more AWS service integrations To disable services while keeping your AWS account linked to New Relic: From one.newrelic.com > Infrastructure, select AWS > Manage services. From your Edit AWS account page, clear the checkbox for each active service you want to disable. Save your changes. Disable all AWS integrations To disconnect your AWS account completely from New Relic, you need to unlink your AWS account. This disables all New Relic integrations associated with that AWS account. Go to one.newrelic.com > Infrastructure > AWS > Manage services. From your Edit AWS account page, select Unlink this account. Save your changes. Sign in to AWS and select Services > IAM > Roles. Select the checkbox for the role you want to delete, then select Role Actions > Delete Role. Unlinking your AWS account will disable the trust relationship set up via your ARN. Azure If you want to... Do this Disable one or more Azure service integrations To disable services while keeping your Azure account linked to New Relic: Go to one.newrelic.com > Infrastructure > Azure > Manage services. From your Edit Azure account page, clear the checkbox for each active service you want to disable. Save your changes. Disable all Azure integrations To disconnect your Azure account completely from New Relic, you need to unlink your Azure account. This requires being either the user who registered the app or an administrator. This procedure will disable all New Relic integrations associated with that Azure account. Go to one.newrelic.com > Infrastructure > Azure > Manage services. From your Edit Azure account page, select Unlink this account. Save your changes. Sign in to Azure and go into All Services > Identity > App registrations, or go to Azure Active Directory service and select App registrations. Find the registered app (the recommended name is NewRelic-Integrations). To see the full list of available apps, select the dropdown menu beside the search field and select All apps. Select the app and, on the panel that opens, select Delete. Google Cloud Platform (GCP) If you want to... Do this Disable one or more GCP service integrations To disable services while keeping your GCP account linked to New Relic: From one.newrelic.com > Infrastructure > GCP > Manage services. From your Edit GCP account page, clear the checkbox for each active service you want to disable. Save your changes. Disable all GCP integrations To disconnect your GCP account completely from New Relic, you need to unlink your GCP account. This disables all New Relic integrations associated with that GCP account. If you registered the GCP project using a User account, follow these steps. Go to one.newrelic.com > Infrastructure > GCP > Manage services. From your Edit GCP account page, select Unlink this account. Save your changes. If you registered the GCP project using a Service account, follow these steps. If you are deleting a custom role, be aware that this role may be used for other purposes besides New Relic access. Sign in to New Relic and go to Infrastructure > Integrations > Google Cloud Platform. For a standard (non-custom) user role, select Manage Services for the account you want to remove. Copy the value of User and save it. OR For a custom user role, go to IAM > admin > Roles, search for the role, select it, and select DELETE. You are now finished and can skip the remaining steps. Standard (non-custom) user role: Sign in to Google Cloud and select the correct project in the Select a project box. From the navigation menu, select IAM & admin > IAM. Search for and select the user value you saved, then select REMOVE. On-host integrations If you used the integrations package, see the integrations package instructions. Here are some examples: Apache Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove nri-apache yum (Amazon Linux, CentOS, or RHEL) sudo yum remove nri-apache zypper (SLES) sudo zypper -n remove nri-apache Cassandra Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove nri-cassandra yum (Amazon Linux, CentOS, or RHEL) sudo yum remove nri-cassandra zypper (SLES) sudo zypper -n remove nri-cassandra Kubernetes Each cluster will have a single node where kubectl is running. To uninstall the Kubernetes integration, use the following command on each of these nodes: kubectl delete -f newrelic-infrastructure-k8s-latest.yaml Copy MySQL Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove nri-mysql yum (Amazon Linux, CentOS, or RHEL) sudo yum remove nri-mysql zypper (SLES) sudo zypper -n remove nri-mysql NGINX Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove nri-nginx yum (Amazon Linux, CentOS, or RHEL) sudo yum remove nri-nginx zypper (SLES) sudo zypper -n remove nri-nginx Redis Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove nri-redis yum (Amazon Linux, CentOS, or RHEL) sudo yum remove nri-redis zypper (SLES) sudo zypper -n remove nri-redis StatsD cd /path/to/statsd npm uninstall @newrelic/statsd-infra-backend From the StatsD config.js, remove the \"@newrelic/statsd-infra-backend\" entry from the list of backends. Restart StatsD. Moving away from the integrations package While it is still possible to use the integrations package, we recommend removing it completely and working with integrations on an individual basis. The last integration package contains the following versions of the integrations: Apache 1.1.2 Cassandra 2.0.3 MySQL 1.1.5 Nginx 1.0.2 Redis 1.0.1 If you remove the integrations package and want to continue using the related on-host integrations, you will need to install them one by one. To uninstall the package and re-install your integrations: Remove the integrations package by following these instructions. The config files from the old integrations will not be deleted, so you won’t have to configure them again. Uninstall package Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove newrelic-infra-integrations sudo apt-get autoremove yum (Amazon Linux, CentOS, or RHEL) sudo yum remove newrelic-infra-integrations sudo yum autoremove zypper (SLES) sudo zypper -n remove newrelic-infra-integrations --clean-deps Copy Install your integrations one by one following these instructions. To replicate the integrations package, you will need to install all the available integrations again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 377.45892,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Uninstall</em> <em>infrastructure</em> integrations",
        "sections": "<em>Uninstall</em> <em>infrastructure</em> integrations",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Uninstalling the <em>infrastructure</em> <em>agent</em> does not directly affect any of your <em>infrastructure</em> Integrations: if you <em>uninstall</em> the <em>agent</em>, your integrations will remain. Similarly, if you disable or <em>uninstall</em> your integrations, the <em>infrastructure</em> <em>agent</em> will remain. To <em>uninstall</em> any of your integrations"
      },
      "id": "603ea831196a67fc6fa83db5"
    },
    {
      "sections": [
        "Uninstall the infrastructure agent",
        "Uninstall the Linux infrastructure agent",
        "Uninstall with apt (Debian, Ubuntu)",
        "Uninstall with yum (Amazon Linux, CentOS, RHEL)",
        "Uninstall with Zypper (SLES)",
        "Important",
        "Uninstall the Windows infrastructure agent",
        "Tip",
        "Uninstall using config management tools",
        "Optional: Purge remaining files"
      ],
      "title": "Uninstall the infrastructure agent ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Update or uninstall"
      ],
      "external_id": "d99fe6244698657f7f2e67bc6f6fcbfc9d8ffbf9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/update-or-uninstall/uninstall-infrastructure-agent/",
      "published_at": "2021-06-14T21:12:22Z",
      "updated_at": "2021-03-16T08:33:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Your hosts are added automatically when you install the infrastructure agent for your Linux or Windows operating system, or update the agent. Similarly, your hosts disappear automatically when you uninstall the agent. You do not need to manually add or remove your hosts. Uninstalling the agent does not directly affect any of your integrations. To uninstall an integration, see Uninstall integrations. Uninstall the Linux infrastructure agent If you used the default install procedure for your infrastructure agent for Linux environments, use your package management tools to uninstall it. You do not need to stop the service before running the uninstall command. Uninstall with apt ( Debian, Ubuntu) Execute the following command as root: sudo apt-get remove newrelic-infra Copy Uninstall with yum ( Amazon Linux, CentOS, RHEL) Execute the following command as root: sudo yum remove newrelic-infra Copy Uninstall with Zypper ( SLES) Execute the following command as root: sudo zypper -n remove newrelic-infra Copy If you followed an assisted or manual installation process, you need to manually delete all the files created when you unpacked the agent file. Important Since there are are no automated scripts, old files may remain when you uninstall. Be sure to manually remove outdated files. Uninstall the Windows infrastructure agent Tip Requires Administrator rights in your Windows admin group. If you used the default install procedure for the infrastructure agent for Windows environments, to uninstall: Stop the infrastructure agent. From the Windows Control Panel, use the Add/Remove Programs and Features tool to uninstall the infrastructure agent. From the Windows Program Files, manually delete the New Relic folder to delete all files associated with the infrastructure agent for Windows. If you followed an assisted or manual installation process, you need to manually delete all the files created when you unpacked the agent file. Important Since there are are no automated scripts, old files may remain when you uninstall. Be sure to manually remove outdated files. Uninstall using config management tools To uninstall the infrastructure agent if you used a configuration management tool: Config management tools Uninstall New Relic infrastructure agent Ansible Set the 'agent_state' parameter to 'absent' Chef Set the 'agent_action' node to uninstall AWS Elastic Beanstalk Remove newrelic.config from .ebextensions, then deploy. Puppet Set the 'ensure' parameter to 'absent' Optional: Purge remaining files If you use standard package management tools for your selected platform, the uninstall process typically leaves configuration and other miscellaneous files. If you need to completely purge any of the remaining files after uninstalling the New Relic infrastructure agent, follow standard procedures for your operating system.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 326.6892,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Uninstall</em> the <em>infrastructure</em> <em>agent</em> ",
        "sections": "<em>Uninstall</em> the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Your hosts are added automatically when you <em>install</em> the <em>infrastructure</em> <em>agent</em> for your Linux or Windows operating system, or <em>update</em> the <em>agent</em>. Similarly, your hosts disappear automatically when you <em>uninstall</em> the <em>agent</em>. You do not need to manually add or remove your hosts. Uninstalling the <em>agent</em> does"
      },
      "id": "603ea0e964441f31114e885c"
    },
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-06-14T21:07:01Z",
      "updated_at": "2021-06-14T21:07:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. Built-in log forwarding and on-host integrations are not yet available. Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.10 to 1.16 Red Hat Enterprise Linux (RHEL) Version 6 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, and 12.4 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 (only the infrastructure agent is supported). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 323.84235,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized <em>agent</em>. On EKS, <em>install</em> the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The <em>infrastructure</em> <em>agent</em> uses the hostname to uniquely identify each server. To avoid"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/windows-installation/install-infrastructure-monitoring-agent-windows": [
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-06-14T21:07:01Z",
      "updated_at": "2021-06-14T21:07:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. Built-in log forwarding and on-host integrations are not yet available. Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.10 to 1.16 Red Hat Enterprise Linux (RHEL) Version 6 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, and 12.4 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 (only the infrastructure agent is supported). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 323.84213,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " Enterprise Linux (RHEL) Version 6 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, and 12.4 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x <em>Windows</em> <em>Windows</em> Server 2012, 2016, and 2019, and their service packs. <em>Windows</em> 10 (only the <em>infrastructure</em> <em>agent</em> is supported). You"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Zip assisted install of the infrastructure agent for Windows",
        "Install the agent",
        "Important",
        "Configure your installation",
        "What's next?"
      ],
      "title": "Zip assisted install of the infrastructure agent for Windows",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Windows installation"
      ],
      "external_id": "fcadbeed626401863b6b16e5c52e9a472a5ac13e",
      "image": "https://docs.newrelic.com/static/6ca3d6d18f535376b153baaece37fdcb/0abdd/Infra-windows-files.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/windows-installation/zip-assisted-install-infrastructure-agent-windows/",
      "published_at": "2021-06-14T21:13:26Z",
      "updated_at": "2021-04-16T02:59:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the assisted install of the infrastructure agent for Windows, you can make the changes you need to the installation script we provide so you can adapt it to your environment. Before installation, make sure to check the compatibility and requirements. Install the agent Important As of version 1.4.0, the infrastructure agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. See our docs for more information. To install the agent: Download the packaged agent file. Unpack the file. Make sure the file unpacks with the following structure: Once it's unpacked, access and edit the installation PowerShell script installer.ps1. Update your license key. Optional: Update any other parameters. Execute installer.ps1 with admin rights. Configure your installation Important Make sure any custom folder defined in the installation settings has permissions limitations properly defined. The infrastructure agent might execute any integration defined in the NRIA_PLUGIN_DIR directory with Administrator permissions. You can configure the following parameters during the assisted install for Windows: Variable Description NRIA_AGENT_DIR Required at agent startup. The agent home directory. Default: C:\\Program Files\\New Relic\\newrelic-infra Copy NRIA_APP_DATA_DIR This configures the data directory to store inventory and other agent files. Default: C:\\%ProgramData%\\New Relic\\newrelic-infra Copy NRIA_CONFIG_FILE Required at installation. The agent configuration file's location. Default: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.yml Copy NRIA_LICENSE_KEY Only configuration option required at startup. The New Relic license key. NRIA_LOG_FILE Required at agent startup. The location where the agent will log. Default: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy NRIA_OVERWRITE By default and for security reasons, Windows does not install a service if there's another service with the same name already installed. To bypass this check, make sure this setting NRIA_OVERWRITE is TRUE. Default: TRUE Copy NRIA_PLUGIN_DIR Required at agent startup. The directory containing the configuration files of the integrations. Default: C:\\Program Files\\NewRelic\\newrelic-infra\\inregrations.d Copy NRIA_SERVICE_NAME This provides the name for the Windows service. What's next? You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Add other New Relic infrastructure integrations to collect data from external services. Manually start, stop, restart, or check the agent status.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 299.59958,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Zip assisted <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Windows</em>",
        "sections": "Zip assisted <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Windows</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "With the assisted <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Windows</em>, you can make the changes you need to the <em>installation</em> script we provide so you can adapt it to your environment. Before <em>installation</em>, make sure to check the compatibility and requirements. <em>Install</em> the <em>agent</em> Important As of version"
      },
      "id": "603ea7af196a67dab0a83d9d"
    },
    {
      "sections": [
        "Zip manual install of the infrastructure agent for Windows",
        "Install the agent",
        "Important",
        "Install the service script",
        "Configuration file",
        "Changing the config file's location",
        "Configure the plugin directory",
        "Configure the agent directory",
        "Configure the log file",
        "What's next?"
      ],
      "title": "Zip manual install of the infrastructure agent for Windows",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Windows installation"
      ],
      "external_id": "f7c89a92aefa26a400384c4334bcdc876dd07546",
      "image": "https://docs.newrelic.com/static/6ca3d6d18f535376b153baaece37fdcb/0abdd/Infra-windows-files.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/windows-installation/zip-manual-install-infrastructure-agent-windows/",
      "published_at": "2021-06-14T21:14:35Z",
      "updated_at": "2021-03-16T08:33:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our custom installation process for the infrastructure agent for Windows allows you to tailor all aspects of the installation, and place files and folders wherever you want on your filesystem. This method gives you full control of the installation: you are responsible for placing the files in the correct folders, providing the correct configuration values, and ensuring the agent has all the right permissions. Before installation, check the compatibility and requirements. Install the agent To install the agent: Download the packaged agent file. Unpack the file. Make sure the file unpacks with the following structure: Install the service script. Optionally, you can: Change the location of the configuration file. Configure the plugin directory. Configure the agent directory. Configure the log file. Important As of version 1.4.0, the infrastructure agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. See our docs for more information. Install the service script To proceed with the installation, you need to create the service. Check the file provided in the zip file for reference: C:\\Program Files\\New Relic\\newrelic-infra\\installer.ps1 Copy Configuration file The Infrastructure agent depends on a configuration file, usually named newrelic-infra.yml, placed in the same folder with the agent, to configure the agent's behavior. You can create a new config file based on config file template. For more information, see how to configure the agent. Changing the config file's location By default, the configuration file is located in C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.yml. To change the location of the configuration file: Execute the command regedit.exe. Browse to the folder Computer\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\newrelic-infra\\ImagePath. Retrieve the ImagePath key. If the agent binary is on the default path, look for the key at C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.exe. Use the -config flag to add the new location of the configuration file to the key: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.exe -config c:\\config.yaml Copy Configure the plugin directory The Infrastructure agent allows you to install integrations that monitor and report data from popular services such as Kubernetes, AWS, MySQL, Redis, Kafka, etc. Each integration has its own configuration file, named by default integration-name-config.yml, placed in the predefined location C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d. On initialization, the agent loads the config file. To overwrite the predefined location of the integration configuration file, use one of the following methods: Set the location in the NRIA_PLUGIN_DIR environment variable. Set the custom path in the newrelic-infra.yml configuration file using the plugin_dir field. Pass it as a command line argument using -plugin_dir when you run the newrelic-infra binary. Configure the agent directory The agent requires its own defined directory to run the installed integrations, caching data (inventory), etc. The default location is C:\\Program Files\\New Relic\\newrelic-infra\\. The agent directory has the following structure and content: LICENSE: Text file containing the New Relic Infrastructure agent license. custom-integrations: Directory that stores the installed the custom integrations. newrelic-integrations: Directory that stores the New Relic official integrations. Additionally, the agent uses a different folder, app_data_dir, to store data. By default it points to C:\\ProgramData\\New Relic\\newrelic-infra\\. To overwrite the predefined location of the agent directory, use one of the following methods: Set the location in the NRIA_AGENT_DIR environment variable. Set the custom path in the newrelic-infra.yml configuration file using the agent_dir field. Pass it as a command line argument using -agent_dir when you run the newrelic-infra binary. Configure the log file By default the agent stores the log files in C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log. To overwrite the predefined location of the log file, use one of the following methods: Set the location in the NRIA_LOG_FILE environment variable. Set the custom path in the newrelic-infra.yml configuration file using the log_file field. Pass it as a command line argument using -log_file when you run the newrelic-infra binary. What's next? You may also want to: Add custom attributes to annotate your Infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Add other New Relic Infrastructure integrations to collect data from external services. Manually start, stop, restart, or check the agent status.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 286.9659,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Zip manual <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Windows</em>",
        "sections": "Zip manual <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Windows</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Our custom <em>installation</em> process for the <em>infrastructure</em> <em>agent</em> for <em>Windows</em> allows you to tailor all aspects of the <em>installation</em>, and place files and folders wherever you want on your filesystem. This method gives you full control of the <em>installation</em>: you are responsible for placing the files"
      },
      "id": "603ea57b196a678ad3a83dbf"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/windows-installation/zip-assisted-install-infrastructure-agent-windows": [
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-06-14T21:07:01Z",
      "updated_at": "2021-06-14T21:07:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. Built-in log forwarding and on-host integrations are not yet available. Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.10 to 1.16 Red Hat Enterprise Linux (RHEL) Version 6 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, and 12.4 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 (only the infrastructure agent is supported). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 323.84213,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " Enterprise Linux (RHEL) Version 6 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, and 12.4 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x <em>Windows</em> <em>Windows</em> Server 2012, 2016, and 2019, and their service packs. <em>Windows</em> 10 (only the <em>infrastructure</em> <em>agent</em> is supported). You"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Zip manual install of the infrastructure agent for Windows",
        "Install the agent",
        "Important",
        "Install the service script",
        "Configuration file",
        "Changing the config file's location",
        "Configure the plugin directory",
        "Configure the agent directory",
        "Configure the log file",
        "What's next?"
      ],
      "title": "Zip manual install of the infrastructure agent for Windows",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Windows installation"
      ],
      "external_id": "f7c89a92aefa26a400384c4334bcdc876dd07546",
      "image": "https://docs.newrelic.com/static/6ca3d6d18f535376b153baaece37fdcb/0abdd/Infra-windows-files.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/windows-installation/zip-manual-install-infrastructure-agent-windows/",
      "published_at": "2021-06-14T21:14:35Z",
      "updated_at": "2021-03-16T08:33:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our custom installation process for the infrastructure agent for Windows allows you to tailor all aspects of the installation, and place files and folders wherever you want on your filesystem. This method gives you full control of the installation: you are responsible for placing the files in the correct folders, providing the correct configuration values, and ensuring the agent has all the right permissions. Before installation, check the compatibility and requirements. Install the agent To install the agent: Download the packaged agent file. Unpack the file. Make sure the file unpacks with the following structure: Install the service script. Optionally, you can: Change the location of the configuration file. Configure the plugin directory. Configure the agent directory. Configure the log file. Important As of version 1.4.0, the infrastructure agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. See our docs for more information. Install the service script To proceed with the installation, you need to create the service. Check the file provided in the zip file for reference: C:\\Program Files\\New Relic\\newrelic-infra\\installer.ps1 Copy Configuration file The Infrastructure agent depends on a configuration file, usually named newrelic-infra.yml, placed in the same folder with the agent, to configure the agent's behavior. You can create a new config file based on config file template. For more information, see how to configure the agent. Changing the config file's location By default, the configuration file is located in C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.yml. To change the location of the configuration file: Execute the command regedit.exe. Browse to the folder Computer\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\newrelic-infra\\ImagePath. Retrieve the ImagePath key. If the agent binary is on the default path, look for the key at C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.exe. Use the -config flag to add the new location of the configuration file to the key: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.exe -config c:\\config.yaml Copy Configure the plugin directory The Infrastructure agent allows you to install integrations that monitor and report data from popular services such as Kubernetes, AWS, MySQL, Redis, Kafka, etc. Each integration has its own configuration file, named by default integration-name-config.yml, placed in the predefined location C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d. On initialization, the agent loads the config file. To overwrite the predefined location of the integration configuration file, use one of the following methods: Set the location in the NRIA_PLUGIN_DIR environment variable. Set the custom path in the newrelic-infra.yml configuration file using the plugin_dir field. Pass it as a command line argument using -plugin_dir when you run the newrelic-infra binary. Configure the agent directory The agent requires its own defined directory to run the installed integrations, caching data (inventory), etc. The default location is C:\\Program Files\\New Relic\\newrelic-infra\\. The agent directory has the following structure and content: LICENSE: Text file containing the New Relic Infrastructure agent license. custom-integrations: Directory that stores the installed the custom integrations. newrelic-integrations: Directory that stores the New Relic official integrations. Additionally, the agent uses a different folder, app_data_dir, to store data. By default it points to C:\\ProgramData\\New Relic\\newrelic-infra\\. To overwrite the predefined location of the agent directory, use one of the following methods: Set the location in the NRIA_AGENT_DIR environment variable. Set the custom path in the newrelic-infra.yml configuration file using the agent_dir field. Pass it as a command line argument using -agent_dir when you run the newrelic-infra binary. Configure the log file By default the agent stores the log files in C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log. To overwrite the predefined location of the log file, use one of the following methods: Set the location in the NRIA_LOG_FILE environment variable. Set the custom path in the newrelic-infra.yml configuration file using the log_file field. Pass it as a command line argument using -log_file when you run the newrelic-infra binary. What's next? You may also want to: Add custom attributes to annotate your Infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Add other New Relic Infrastructure integrations to collect data from external services. Manually start, stop, restart, or check the agent status.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 286.9659,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Zip manual <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Windows</em>",
        "sections": "Zip manual <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Windows</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Our custom <em>installation</em> process for the <em>infrastructure</em> <em>agent</em> for <em>Windows</em> allows you to tailor all aspects of the <em>installation</em>, and place files and folders wherever you want on your filesystem. This method gives you full control of the <em>installation</em>: you are responsible for placing the files"
      },
      "id": "603ea57b196a678ad3a83dbf"
    },
    {
      "sections": [
        "Install the infrastructure monitoring agent for Windows",
        "Tip",
        "Install for Windows Server and Windows 10 using our wizard",
        "Step-by-step instructions",
        "PowerShell install",
        "32-bit Windows",
        "64-bit Windows",
        "Step-by-step install",
        "Important",
        "Scripted installation",
        "What's next?",
        "Install using zip files",
        "Caution",
        "Update the agent"
      ],
      "title": "Install the infrastructure monitoring agent for Windows",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Windows installation"
      ],
      "external_id": "32766f16044664c9c7d66075801930ff53ca5c49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/windows-installation/install-infrastructure-monitoring-agent-windows/",
      "published_at": "2021-06-14T21:13:26Z",
      "updated_at": "2021-03-13T01:56:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With New Relic's infrastructure monitoring agent for Windows, you can monitor individual servers and also analyze how your service performs as a whole. The Windows agent can run on your own hardware or in cloud systems such as Amazon EC2 or Windows Azure. The infrastructure monitoring agent supports Windows Server and Windows 10. You can also install with Chef. Tip To use infrastructure monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Install for Windows Server and Windows 10 using our wizard Before installation, be sure to review the requirements. Then, to install the infrastructure monitoring agent for Windows, you can use our launcher, or follow the instructions in this document to complete a basic installation. Windows If you don't have a New Relic account yet, or prefer to follow the procedure manually, follow our step-by-step tutorial, which follows. Step-by-step instructions To install the infrastructure monitoring agent, use our PowerShell script, or follow the step-by-step instructions: PowerShell install Review the agent requirements and supported operating systems. Open the PowerShell as administrator and run the following command: 32-bit Windows $LICENSE_KEY=\"YOUR_LICENSE_KEY\"; ` (New-Object System.Net.WebClient).DownloadFile(\"https://download.newrelic.com/infrastructure_agent/windows/386/newrelic-infra-386.msi\", \"$env:TEMP\\newrelic-infra.msi\"); ` msiexec.exe /qn /i \"$env:TEMP\\newrelic-infra.msi\" GENERATE_CONFIG=true LICENSE_KEY=\"$LICENSE_KEY\" | Out-Null; ` net start newrelic-infra Copy 64-bit Windows $LICENSE_KEY=\"YOUR_LICENSE_KEY\"; ` (New-Object System.Net.WebClient).DownloadFile(\"https://download.newrelic.com/infrastructure_agent/windows/newrelic-infra.msi\", \"$env:TEMP\\newrelic-infra.msi\"); ` msiexec.exe /qn /i \"$env:TEMP\\newrelic-infra.msi\" GENERATE_CONFIG=true LICENSE_KEY=\"$LICENSE_KEY\" | Out-Null; ` net start newrelic-infra Copy For a scripted installation, you can pass in configuration parameters. You must first add GENERATE_CONFIG=true and LICENSE_KEY=YOUR_LICENSE_KEY. You may then add these optional config settings: DISPLAY_NAME=YOUR_DISPLAY_NAME PROXY=http://YOUR_PROXY_SERVER:PROXY_PORT CUSTOM_ATTRIBUTES=\"{'ATTRIBUTE_1':'VALUE_1','ATTRIBUTE_2':'VALUE_2'}\" The following example sets the license key and configures a proxy server for outbound communication, as well as adding one custom attribute: msiexec.exe /qn /i PATH\\TO\\newrelic-infra.msi GENERATE_CONFIG=true LICENSE_KEY=YOUR_LICENSE_KEY PROXY=http://YOUR_PROXY_SERVER:PROXY_PORT CUSTOM_ATTRIBUTES=\"{'ATTRIBUTE_1':'VALUE_1'}\" Copy Step-by-step install Review the infrastructure monitoring agent requirements and supported operating systems. Download the latest .MSI installer image from: 32-bit Windows https://download.newrelic.com/infrastructure_agent/windows/386/newrelic-infra-386.msi​ Copy 64-bit Windows https://download.newrelic.com/infrastructure_agent/windows/newrelic-infra.msi Copy Important Do not double-click the installer. This will not fully install the local agent and can result in permissions issues. In an admin account, run the install script using an absolute path. 32-bit Windows To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\newrelic-infra-386.msi Copy 64-bit Windows To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\newrelic-infra.msi Copy Scripted installation For a scripted installation, you can also pass in configuration parameters. You must first add GENERATE_CONFIG=true and LICENSE_KEY=YOUR_LICENSE_KEY. You may then add these optional config settings: DISPLAY_NAME=YOUR_DISPLAY_NAME PROXY=http://YOUR_PROXY_SERVER:PROXY_PORT CUSTOM_ATTRIBUTES=\"{'ATTRIBUTE_1':'VALUE_1','ATTRIBUTE_2':'VALUE_2'}\" The following example sets the license key and configures a proxy server for outbound communication, as well as adding one custom attribute: msiexec.exe /qn /i PATH\\TO\\newrelic-infra.msi GENERATE_CONFIG=true LICENSE_KEY=YOUR_LICENSE_KEY PROXY=http://YOUR_PROXY_SERVER:PROXY_PORT CUSTOM_ATTRIBUTES=\"{'ATTRIBUTE_1':'VALUE_1'}\" Copy Add your New Relic license key to the license_key attribute in newrelic-infra.yml, located in C:\\Program Files\\New Relic\\newrelic-infra\\. When finished, the contents of newrelic-infra.yml should resemble the following: license_key: YOUR_LICENSE_KEY Copy Start the newrelic-infra service. To start from the Windows command prompt, run: net start newrelic-infra Copy Wait a few minutes, then view your server in the Infrastructure UI. If no data appears after waiting a few minutes, follow the troubleshooting steps. Tip As of version 1.4.0, the infrastructure monitoring agent package includes newrelic-infra-ctl, which is used to help troubleshoot a running agent. We recommend adding it to PATH. What's next? The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services. Install using zip files For custom setup scenarios, you can install the infrastructure monitoring agent using our zip files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment. Caution Installing the infrastructure monitoring agent using zip files is not supported. Update the agent To upgrade to the latest version, follow standard procedures to update the infrastructure monitoring agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 286.06433,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Windows</em>",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Windows</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": ". <em>Install</em> for <em>Windows</em> Server and <em>Windows</em> 10 using our wizard Before <em>installation</em>, be sure to review the requirements. Then, to <em>install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Windows</em>, you can use our launcher, or follow the instructions in this document to complete a basic <em>installation</em>. <em>Windows</em> If you don&#x27;t"
      },
      "id": "6044672464441f9bb6378ed9"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/windows-installation/zip-manual-install-infrastructure-agent-windows": [
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-06-14T21:07:01Z",
      "updated_at": "2021-06-14T21:07:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. Built-in log forwarding and on-host integrations are not yet available. Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.10 to 1.16 Red Hat Enterprise Linux (RHEL) Version 6 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, and 12.4 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 (only the infrastructure agent is supported). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 323.84192,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " Enterprise Linux (RHEL) Version 6 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, and 12.4 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x <em>Windows</em> <em>Windows</em> Server 2012, 2016, and 2019, and their service packs. <em>Windows</em> 10 (only the <em>infrastructure</em> <em>agent</em> is supported). You"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Zip assisted install of the infrastructure agent for Windows",
        "Install the agent",
        "Important",
        "Configure your installation",
        "What's next?"
      ],
      "title": "Zip assisted install of the infrastructure agent for Windows",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Windows installation"
      ],
      "external_id": "fcadbeed626401863b6b16e5c52e9a472a5ac13e",
      "image": "https://docs.newrelic.com/static/6ca3d6d18f535376b153baaece37fdcb/0abdd/Infra-windows-files.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/windows-installation/zip-assisted-install-infrastructure-agent-windows/",
      "published_at": "2021-06-14T21:13:26Z",
      "updated_at": "2021-04-16T02:59:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the assisted install of the infrastructure agent for Windows, you can make the changes you need to the installation script we provide so you can adapt it to your environment. Before installation, make sure to check the compatibility and requirements. Install the agent Important As of version 1.4.0, the infrastructure agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. See our docs for more information. To install the agent: Download the packaged agent file. Unpack the file. Make sure the file unpacks with the following structure: Once it's unpacked, access and edit the installation PowerShell script installer.ps1. Update your license key. Optional: Update any other parameters. Execute installer.ps1 with admin rights. Configure your installation Important Make sure any custom folder defined in the installation settings has permissions limitations properly defined. The infrastructure agent might execute any integration defined in the NRIA_PLUGIN_DIR directory with Administrator permissions. You can configure the following parameters during the assisted install for Windows: Variable Description NRIA_AGENT_DIR Required at agent startup. The agent home directory. Default: C:\\Program Files\\New Relic\\newrelic-infra Copy NRIA_APP_DATA_DIR This configures the data directory to store inventory and other agent files. Default: C:\\%ProgramData%\\New Relic\\newrelic-infra Copy NRIA_CONFIG_FILE Required at installation. The agent configuration file's location. Default: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.yml Copy NRIA_LICENSE_KEY Only configuration option required at startup. The New Relic license key. NRIA_LOG_FILE Required at agent startup. The location where the agent will log. Default: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy NRIA_OVERWRITE By default and for security reasons, Windows does not install a service if there's another service with the same name already installed. To bypass this check, make sure this setting NRIA_OVERWRITE is TRUE. Default: TRUE Copy NRIA_PLUGIN_DIR Required at agent startup. The directory containing the configuration files of the integrations. Default: C:\\Program Files\\NewRelic\\newrelic-infra\\inregrations.d Copy NRIA_SERVICE_NAME This provides the name for the Windows service. What's next? You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Add other New Relic infrastructure integrations to collect data from external services. Manually start, stop, restart, or check the agent status.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 299.59958,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Zip assisted <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Windows</em>",
        "sections": "Zip assisted <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Windows</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "With the assisted <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Windows</em>, you can make the changes you need to the <em>installation</em> script we provide so you can adapt it to your environment. Before <em>installation</em>, make sure to check the compatibility and requirements. <em>Install</em> the <em>agent</em> Important As of version"
      },
      "id": "603ea7af196a67dab0a83d9d"
    },
    {
      "sections": [
        "Install the infrastructure monitoring agent for Windows",
        "Tip",
        "Install for Windows Server and Windows 10 using our wizard",
        "Step-by-step instructions",
        "PowerShell install",
        "32-bit Windows",
        "64-bit Windows",
        "Step-by-step install",
        "Important",
        "Scripted installation",
        "What's next?",
        "Install using zip files",
        "Caution",
        "Update the agent"
      ],
      "title": "Install the infrastructure monitoring agent for Windows",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Windows installation"
      ],
      "external_id": "32766f16044664c9c7d66075801930ff53ca5c49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/windows-installation/install-infrastructure-monitoring-agent-windows/",
      "published_at": "2021-06-14T21:13:26Z",
      "updated_at": "2021-03-13T01:56:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With New Relic's infrastructure monitoring agent for Windows, you can monitor individual servers and also analyze how your service performs as a whole. The Windows agent can run on your own hardware or in cloud systems such as Amazon EC2 or Windows Azure. The infrastructure monitoring agent supports Windows Server and Windows 10. You can also install with Chef. Tip To use infrastructure monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Install for Windows Server and Windows 10 using our wizard Before installation, be sure to review the requirements. Then, to install the infrastructure monitoring agent for Windows, you can use our launcher, or follow the instructions in this document to complete a basic installation. Windows If you don't have a New Relic account yet, or prefer to follow the procedure manually, follow our step-by-step tutorial, which follows. Step-by-step instructions To install the infrastructure monitoring agent, use our PowerShell script, or follow the step-by-step instructions: PowerShell install Review the agent requirements and supported operating systems. Open the PowerShell as administrator and run the following command: 32-bit Windows $LICENSE_KEY=\"YOUR_LICENSE_KEY\"; ` (New-Object System.Net.WebClient).DownloadFile(\"https://download.newrelic.com/infrastructure_agent/windows/386/newrelic-infra-386.msi\", \"$env:TEMP\\newrelic-infra.msi\"); ` msiexec.exe /qn /i \"$env:TEMP\\newrelic-infra.msi\" GENERATE_CONFIG=true LICENSE_KEY=\"$LICENSE_KEY\" | Out-Null; ` net start newrelic-infra Copy 64-bit Windows $LICENSE_KEY=\"YOUR_LICENSE_KEY\"; ` (New-Object System.Net.WebClient).DownloadFile(\"https://download.newrelic.com/infrastructure_agent/windows/newrelic-infra.msi\", \"$env:TEMP\\newrelic-infra.msi\"); ` msiexec.exe /qn /i \"$env:TEMP\\newrelic-infra.msi\" GENERATE_CONFIG=true LICENSE_KEY=\"$LICENSE_KEY\" | Out-Null; ` net start newrelic-infra Copy For a scripted installation, you can pass in configuration parameters. You must first add GENERATE_CONFIG=true and LICENSE_KEY=YOUR_LICENSE_KEY. You may then add these optional config settings: DISPLAY_NAME=YOUR_DISPLAY_NAME PROXY=http://YOUR_PROXY_SERVER:PROXY_PORT CUSTOM_ATTRIBUTES=\"{'ATTRIBUTE_1':'VALUE_1','ATTRIBUTE_2':'VALUE_2'}\" The following example sets the license key and configures a proxy server for outbound communication, as well as adding one custom attribute: msiexec.exe /qn /i PATH\\TO\\newrelic-infra.msi GENERATE_CONFIG=true LICENSE_KEY=YOUR_LICENSE_KEY PROXY=http://YOUR_PROXY_SERVER:PROXY_PORT CUSTOM_ATTRIBUTES=\"{'ATTRIBUTE_1':'VALUE_1'}\" Copy Step-by-step install Review the infrastructure monitoring agent requirements and supported operating systems. Download the latest .MSI installer image from: 32-bit Windows https://download.newrelic.com/infrastructure_agent/windows/386/newrelic-infra-386.msi​ Copy 64-bit Windows https://download.newrelic.com/infrastructure_agent/windows/newrelic-infra.msi Copy Important Do not double-click the installer. This will not fully install the local agent and can result in permissions issues. In an admin account, run the install script using an absolute path. 32-bit Windows To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\newrelic-infra-386.msi Copy 64-bit Windows To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\newrelic-infra.msi Copy Scripted installation For a scripted installation, you can also pass in configuration parameters. You must first add GENERATE_CONFIG=true and LICENSE_KEY=YOUR_LICENSE_KEY. You may then add these optional config settings: DISPLAY_NAME=YOUR_DISPLAY_NAME PROXY=http://YOUR_PROXY_SERVER:PROXY_PORT CUSTOM_ATTRIBUTES=\"{'ATTRIBUTE_1':'VALUE_1','ATTRIBUTE_2':'VALUE_2'}\" The following example sets the license key and configures a proxy server for outbound communication, as well as adding one custom attribute: msiexec.exe /qn /i PATH\\TO\\newrelic-infra.msi GENERATE_CONFIG=true LICENSE_KEY=YOUR_LICENSE_KEY PROXY=http://YOUR_PROXY_SERVER:PROXY_PORT CUSTOM_ATTRIBUTES=\"{'ATTRIBUTE_1':'VALUE_1'}\" Copy Add your New Relic license key to the license_key attribute in newrelic-infra.yml, located in C:\\Program Files\\New Relic\\newrelic-infra\\. When finished, the contents of newrelic-infra.yml should resemble the following: license_key: YOUR_LICENSE_KEY Copy Start the newrelic-infra service. To start from the Windows command prompt, run: net start newrelic-infra Copy Wait a few minutes, then view your server in the Infrastructure UI. If no data appears after waiting a few minutes, follow the troubleshooting steps. Tip As of version 1.4.0, the infrastructure monitoring agent package includes newrelic-infra-ctl, which is used to help troubleshoot a running agent. We recommend adding it to PATH. What's next? The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services. Install using zip files For custom setup scenarios, you can install the infrastructure monitoring agent using our zip files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment. Caution Installing the infrastructure monitoring agent using zip files is not supported. Update the agent To upgrade to the latest version, follow standard procedures to update the infrastructure monitoring agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 286.06433,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Windows</em>",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Windows</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": ". <em>Install</em> for <em>Windows</em> Server and <em>Windows</em> 10 using our wizard Before <em>installation</em>, be sure to review the requirements. Then, to <em>install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Windows</em>, you can use our launcher, or follow the instructions in this document to complete a basic <em>installation</em>. <em>Windows</em> If you don&#x27;t"
      },
      "id": "6044672464441f9bb6378ed9"
    }
  ],
  "/docs/infrastructure/manage-your-data/data-instrumentation/apm-data-infrastructure-monitoring": [
    {
      "sections": [
        "On-host integrations metrics",
        "New Relic Integrations Metrics"
      ],
      "title": "On-host integrations metrics",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "fe96c0c4950380504b1a33c3ad861bcb17507cba",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/host-integrations-metrics/",
      "published_at": "2021-06-15T01:04:56Z",
      "updated_at": "2021-06-15T01:04:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Integrations Metrics The following table contains the metrics we collect for our infrastructure integrations. Integration Dimensional Metric Name (new) Sample Metric Name (previous) Agent host.cpuIdlePercent cpuIdlePercent Agent host.cpuIoWaitPercent cpuIOWaitPercent Agent host.cpuPercent cpuPercent Agent host.cpuStealPercent cpuStealPercent Agent host.cpuSystemPercent cpuSystemPercent Agent host.cpuUserPercent cpuUserPercent Agent host.disk.avgQueueLen avgQueueLen Agent host.disk.avgReadQueueLen avgReadQueueLen Agent host.disk.avgWriteQueueLen avgWriteQueueLen Agent host.disk.currentQueueLen currentQueueLen Agent host.disk.freeBytes diskFreeBytes Agent host.disk.freePercent diskFreePercent Agent host.disk.inodesFree inodesFree Agent host.disk.inodesTotal inodesTotal Agent host.disk.inodesUsed inodesUsed Agent host.disk.inodesUsedPercent inodesUsedPercent Agent host.disk.readBytesPerSecond readBytesPerSecond Agent host.disk.readIoPerSecond readIoPerSecond Agent host.disk.readUtilizationPercent readUtilizationPercent Agent host.disk.readWriteBytesPerSecond readWriteBytesPerSecond Agent host.disk.totalBytes diskTotalBytes Agent host.disk.totalUtilizationPercent totalUtilizationPercent Agent host.disk.usedBytes diskUsedBytes Agent host.disk.usedPercent diskUsedPercent Agent host.disk.writeBytesPerSecond writeBytesPerSecond Agent host.disk.writeIoPerSecond writeIoPerSecond Agent host.disk.writeUtilizationPercent writeUtilizationPercent Agent host.diskFreeBytes diskFreeBytes Agent host.diskFreePercent diskFreePercent Agent host.diskReadsPerSecond diskReadsPerSecond Agent host.diskReadUtilizationPercent diskReadUtilizationPercent Agent host.diskTotalBytes diskTotalBytes Agent host.diskUsedBytes diskUsedBytes Agent host.diskUsedPercent diskUsedPercent Agent host.diskUtilizationPercent diskUtilizationPercent Agent host.diskWritesPerSecond diskWritesPerSecond Agent host.diskWriteUtilizationPercent diskWriteUtilizationPercent Agent host.loadAverageFifteenMinute loadAverageFifteenMinute Agent host.loadAverageFiveMinute loadAverageFiveMinute Agent host.loadAverageOneMinute loadAverageOneMinute Agent host.memoryFreeBytes memoryFreeBytes Agent host.memoryFreePercent memoryFreePercent Agent host.memoryTotalBytes memoryTotalBytes Agent host.memoryUsedBytes memoryUsedBytes Agent host.memoryUsedPercent memoryUsedPercent Agent host.net.receiveBytesPerSecond receiveBytesPerSecond Agent host.net.receiveDroppedPerSecond receiveDroppedPerSecond Agent host.net.receiveErrorsPerSecond receiveErrorsPerSecond Agent host.net.receivePacketsPerSecond receivePacketsPerSecond Agent host.net.transmitBytesPerSecond transmitBytesPerSecond Agent host.net.transmitDroppedPerSecond transmitDroppedPerSecond Agent host.net.transmitErrorsPerSecond transmitErrorsPerSecond Agent host.net.transmitPacketsPerSecond transmitPacketsPerSecond Agent host.process.cpuPercent cpuPercent Agent host.process.cpuSystemPercent cpuSystemPercent Agent host.process.cpuUserPercent cpuUserPercent Agent host.process.fileDescriptorCount fileDescriptorCount Agent host.process.ioReadBytesPerSecond ioReadBytesPerSecond Agent host.process.ioReadCountPerSecond ioReadCountPerSecond Agent host.process.ioTotalReadBytes ioTotalReadBytes Agent host.process.ioTotalReadCount ioTotalReadCount Agent host.process.ioTotalWriteBytes ioTotalWriteBytes Agent host.process.ioTotalWriteCount ioTotalWriteCount Agent host.process.ioWriteBytesPerSecond ioWriteBytesPerSecond Agent host.process.ioWriteCountPerSecond ioWriteCountPerSecond Agent host.process.memoryResidentSizeBytes memoryResidentSizeBytes Agent host.process.memoryVirtualSizeBytes memoryVirtualSizeBytes Agent host.process.threadCount threadCount Agent host.swapFreeBytes swapFreeBytes Agent host.swapTotalBytes swapTotalBytes Agent host.swapUsedBytes swapUsedBytes Apache apache.server.busyWorkers server.busyWorkers Apache apache.server.idleWorkers server.idleWorkers Apache apache.server.net.bytesPerSecond net.bytesPerSecond Apache apache.server.net.requestsPerSecond net.requestsPerSecond Apache apache.server.scoreboard.closingWorkers server.scoreboard.closingWorkers Apache apache.server.scoreboard.dnsLookupWorkers server.scoreboard.dnsLookupWorkers Apache apache.server.scoreboard.finishingWorkers server.scoreboard.finishingWorkers Apache apache.server.scoreboard.idleCleanupWorkers server.scoreboard.idleCleanupWorkers Apache apache.server.scoreboard.keepAliveWorkers server.scoreboard.keepAliveWorkers Apache apache.server.scoreboard.loggingWorkers server.scoreboard.loggingWorkers Apache apache.server.scoreboard.readingWorkers server.scoreboard.readingWorkers Apache apache.server.scoreboard.startingWorkers server.scoreboard.startingWorkers Apache apache.server.scoreboard.totalWorkers server.scoreboard.totalWorkers Apache apache.server.scoreboard.writingWorkers server.scoreboard.writingWorkers Cassandra cassandra.node.allMemtablesOffHeapSizeBytes db.allMemtablesOffHeapSizeBytes Cassandra cassandra.node.allMemtablesOnHeapSizeBytes db.allMemtablesOnHeapSizeBytes Cassandra cassandra.node.client.connectedNativeClients client.connectedNativeClients Cassandra cassandra.node.commitLogCompletedTasksPerSecond db.commitLogCompletedTasksPerSecond Cassandra cassandra.node.commitLogPendingTasks db.commitLogPendindTasks Cassandra cassandra.node.commitLogTotalSizeBytes db.commitLogTotalSizeBytes Cassandra cassandra.node.droppedBatchRemoveMessagesPerSecond db.droppedBatchRemoveMessagesPerSecond Cassandra cassandra.node.droppedBatchStoreMessagesPerSecond db.droppedBatchStoreMessagesPerSecond Cassandra cassandra.node.droppedCounterMutationMessagesPerSecond db.droppedCounterMutationMessagesPerSecond Cassandra cassandra.node.droppedHintMessagesPerSecond db.droppedHintMessagesPerSecond Cassandra cassandra.node.droppedMutationMessagesPerSecond db.droppedMutationMessagesPerSecond Cassandra cassandra.node.droppedPagedRangeMessagesPerSecond db.droppedPagedRangeMessagesPerSecond Cassandra cassandra.node.droppedRangeSliceMessagesPerSecond db.droppedRangeSliceMessagesPerSecond Cassandra cassandra.node.droppedReadMessagesPerSecond db.droppedReadMessagesPerSecond Cassandra cassandra.node.droppedReadRepairMessagesPerSecond db.droppedReadRepairMessagesPerSecond Cassandra cassandra.node.droppedRequestResponseMessagesPerSecond db.droppedRequestResponseMessagesPerSecond Cassandra cassandra.node.droppedTraceMessagesPerSecond db.droppedTraceMessagesPerSecond Cassandra cassandra.node.keyCacheCapacityBytes db.keyCacheCapacityBytes Cassandra cassandra.node.keyCacheHitRate db.keyCacheHitRate Cassandra cassandra.node.keyCacheHitsPerSecond db.keyCacheHitsPerSecond Cassandra cassandra.node.keyCacheRequestsPerSecond db.keyCacheRequestsPerSecond Cassandra cassandra.node.keyCacheSizeBytes db.keyCacheSizeBytes Cassandra cassandra.node.liveSsTableCount db.liveSSTableCount Cassandra cassandra.node.loadBytes db.loadBytes Cassandra cassandra.node.query.casReadRequestsPerSecond query.CASReadRequestsPerSecond Cassandra cassandra.node.query.casWriteRequestsPerSecond query.CASWriteRequestsPerSecond Cassandra cassandra.node.query.rangeSliceRequestsPerSecond query.rangeSliceRequestsPerSecond Cassandra cassandra.node.query.rangeSliceTimeoutsPerSecond query.rangeSliceTimeoutsPerSecond Cassandra cassandra.node.query.rangeSliceUnavailablesPerSecond query.rangeSliceUnavailablesPerSecond Cassandra cassandra.node.query.readLatency50ThPercentileMilliseconds query.readLatency50thPercentileMilliseconds Cassandra cassandra.node.query.readLatency75ThPercentileMilliseconds query.readLatency75thPercentileMilliseconds Cassandra cassandra.node.query.readLatency95ThPercentileMilliseconds query.readLatency95thPercentileMilliseconds Cassandra cassandra.node.query.readLatency98ThPercentileMilliseconds query.readLatency98thPercentileMilliseconds Cassandra cassandra.node.query.readLatency999ThPercentileMilliseconds query.readLatency999thPercentileMilliseconds Cassandra cassandra.node.query.readLatency99ThPercentileMilliseconds query.readLatency99thPercentileMilliseconds Cassandra cassandra.node.query.readRequestsPerSecond query.readRequestsPerSecond Cassandra cassandra.node.query.readTimeoutsPerSecond query.readTimeoutsPerSecond Cassandra cassandra.node.query.readUnavailablesPerSecond query.readUnavailablesPerSecond Cassandra cassandra.node.query.viewWriteRequestsPerSecond query.viewWriteRequestsPerSecond Cassandra cassandra.node.query.writeLatency50ThPercentileMilliseconds query.writeLatency50thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency75ThPercentileMilliseconds query.writeLatency75thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency95ThPercentileMilliseconds query.writeLatency95thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency98ThPercentileMilliseconds query.writeLatency98thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency999ThPercentileMilliseconds query.writeLatency999thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency99ThPercentileMilliseconds query.writeLatency99thPercentileMilliseconds Cassandra cassandra.node.query.writeRequestsPerSecond query.writeRequestsPerSecond Cassandra cassandra.node.query.writeTimeoutsPerSecond query.writeTimeoutsPerSecond Cassandra cassandra.node.query.writeUnavailablesPerSecond query.writeUnavailablesPerSecond Cassandra cassandra.node.rowCacheCapacityBytes db.rowCacheCapacityBytes Cassandra cassandra.node.rowCacheHitRate db.rowCacheHitRate Cassandra cassandra.node.rowCacheHitsPerSecond db.rowCacheHitsPerSecond Cassandra cassandra.node.rowCacheRequestsPerSecond db.rowCacheRequestsPerSecond Cassandra cassandra.node.rowCacheSizeBytes db.rowCacheSizeBytes Cassandra cassandra.node.storage.exceptionCount storage.exceptionCount Cassandra cassandra.node.threadPool.antiEntropyStage.activeTasks db.threadpool.internalAntiEntropyStageActiveTasks Cassandra cassandra.node.threadPool.antiEntropyStage.completedTasks db.threadpool.internalAntiEntropyStageCompletedTasks Cassandra cassandra.node.threadPool.antiEntropyStage.currentlyBlockedTasks db.threadpool.internalAntiEntropyStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.antiEntropyStage.pendingTasks db.threadpool.internalAntiEntropyStagePendingTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.activeTasks db.threadpool.internalCacheCleanupExecutorActiveTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.completedTasks db.threadpool.internalCacheCleanupExecutorCompletedTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.currentlyBlockedTasks db.threadpool.internalCacheCleanupExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.pendingTasks db.threadpool.internalCacheCleanupExecutorPendingTasks Cassandra cassandra.node.threadPool.compactionExecutor.activeTasks db.threadpool.internalCompactionExecutorActiveTasks Cassandra cassandra.node.threadPool.compactionExecutor.completedTasks db.threadpool.internalCompactionExecutorCompletedTasks Cassandra cassandra.node.threadPool.compactionExecutor.currentlyBlockedTasks db.threadpool.internalCompactionExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.compactionExecutor.pendingTasks db.threadpool.internalCompactionExecutorPendingTasks Cassandra cassandra.node.threadPool.counterMutationStage.activeTasks db.threadpool.requestCounterMutationStageActiveTasks Cassandra cassandra.node.threadPool.counterMutationStage.completedTasks db.threadpool.requestCounterMutationStageCompletedTasks Cassandra cassandra.node.threadPool.counterMutationStage.currentlyBlockedTasks db.threadpool.requestCounterMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.counterMutationStage.pendingTasks db.threadpool.requestCounterMutationStagePendingTasks Cassandra cassandra.node.threadPool.gossipStage.activeTasks db.threadpool.internalGossipStageActiveTasks Cassandra cassandra.node.threadPool.gossipStage.completedTasks db.threadpool.internalGossipStageCompletedTasks Cassandra cassandra.node.threadPool.gossipStage.currentlyBlockedTasks db.threadpool.internalGossipStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.gossipStage.pendingTasks db.threadpool.internalGossipStagePendingTasks Cassandra cassandra.node.threadPool.hintsDispatcher.activeTasks db.threadpool.internalHintsDispatcherActiveTasks Cassandra cassandra.node.threadPool.hintsDispatcher.completedTasks db.threadpool.internalHintsDispatcherCompletedTasks Cassandra cassandra.node.threadPool.hintsDispatcher.currentlyBlockedTasks db.threadpool.internalHintsDispatcherCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.hintsDispatcher.pendingTasks db.threadpool.internalHintsDispatcherPendingTasks Cassandra cassandra.node.threadPool.internalResponseStage.activeTasks db.threadpool.internalInternalResponseStageActiveTasks Cassandra cassandra.node.threadPool.internalResponseStage.completedTasks db.threadpool.internalInternalResponseStageCompletedTasks Cassandra cassandra.node.threadPool.internalResponseStage.pCurrentlyBlockedTasks db.threadpool.internalInternalResponseStagePCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.internalResponseStage.pendingTasks db.threadpool.internalInternalResponseStagePendingTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.activeTasks db.threadpool.internalMemtableFlushWriterActiveTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.completedTasks db.threadpool.internalMemtableFlushWriterCompletedTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.currentlyBlockedTasks db.threadpool.internalMemtableFlushWriterCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.pendingTasks db.threadpool.internalMemtableFlushWriterPendingTasks Cassandra cassandra.node.threadPool.memtablePostFlush.activeTasks db.threadpool.internalMemtablePostFlushActiveTasks Cassandra cassandra.node.threadPool.memtablePostFlush.completedTasks db.threadpool.internalMemtablePostFlushCompletedTasks Cassandra cassandra.node.threadPool.memtablePostFlush.currentlyBlockedTasks db.threadpool.internalMemtablePostFlushCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtablePostFlush.pendingTasks db.threadpool.internalMemtablePostFlushPendingTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.activeTasks db.threadpool.internalMemtableReclaimMemoryActiveTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.completedTasks db.threadpool.internalMemtableReclaimMemoryCompletedTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.currentlyBlockedTasks db.threadpool.internalMemtableReclaimMemoryCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.pendingTasks db.threadpool.internalMemtableReclaimMemoryPendingTasks Cassandra cassandra.node.threadPool.migrationStage.activeTasks db.threadpool.internalMigrationStageActiveTasks Cassandra cassandra.node.threadPool.migrationStage.completedTasks db.threadpool.internalMigrationStageCompletedTasks Cassandra cassandra.node.threadPool.migrationStage.currentlyBlockedTasks db.threadpool.internalMigrationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.migrationStage.pendingTasks db.threadpool.internalMigrationStagePendingTasks Cassandra cassandra.node.threadPool.miscStage.activeTasks db.threadpool.internalMiscStageActiveTasks Cassandra cassandra.node.threadPool.miscStage.completedTasks db.threadpool.internalMiscStageCompletedTasks Cassandra cassandra.node.threadPool.miscStage.currentlyBlockedTasks db.threadpool.internalMiscStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.miscStage.pendingTasks db.threadpool.internalMiscStagePendingTasks Cassandra cassandra.node.threadPool.mutationStage.activeTasks db.threadpool.requestMutationStageActiveTasks Cassandra cassandra.node.threadPool.mutationStage.completedTasks db.threadpool.requestMutationStageCompletedTasks Cassandra cassandra.node.threadPool.mutationStage.currentlyBlockedTasks db.threadpool.requestMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.mutationStage.pendingTasks db.threadpool.requestMutationStagePendingTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.activeTasks db.threadpool.internalPendingRangeCalculatorActiveTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.completedTasks db.threadpool.internalPendingRangeCalculatorCompletedTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.currentlyBlockedTasks db.threadpool.internalPendingRangeCalculatorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.pendingTasks db.threadpool.internalPendingRangeCalculatorPendingTasks Cassandra cassandra.node.threadPool.readRepairStage.activeTasks db.threadpool.requestReadRepairStageActiveTasks Cassandra cassandra.node.threadPool.readRepairStage.completedTasks db.threadpool.requestReadRepairStageCompletedTasks Cassandra cassandra.node.threadPool.readRepairStage.currentlyBlockedTasks db.threadpool.requestReadRepairStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.readRepairStage.pendingTasks db.threadpool.requestReadRepairStagePendingTasks Cassandra cassandra.node.threadPool.readStage.activeTasks db.threadpool.requestReadStageActiveTasks Cassandra cassandra.node.threadPool.readStage.completedTasks db.threadpool.requestReadStageCompletedTasks Cassandra cassandra.node.threadPool.readStage.currentlyBlockedTasks db.threadpool.requestReadStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.readStage.pendingTasks db.threadpool.requestReadStagePendingTasks Cassandra cassandra.node.threadPool.requestResponseStage.activeTasks db.threadpool.requestRequestResponseStageActiveTasks Cassandra cassandra.node.threadPool.requestResponseStage.completedTasks db.threadpool.requestRequestResponseStageCompletedTasks Cassandra cassandra.node.threadPool.requestResponseStage.currentlyBlockedTasks db.threadpool.requestRequestResponseStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.requestResponseStage.pendingTasks db.threadpool.requestRequestResponseStagePendingTasks Cassandra cassandra.node.threadPool.sampler.activeTasks db.threadpool.internalSamplerActiveTasks Cassandra cassandra.node.threadPool.sampler.completedTasks db.threadpool.internalSamplerCompletedTasks Cassandra cassandra.node.threadPool.sampler.currentlyBlockedTasks db.threadpool.internalSamplerCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.sampler.pendingTasks db.threadpool.internalSamplerPendingTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.activeTasks db.threadpool.internalSecondaryIndexManagementActiveTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.completedTasks db.threadpool.internalSecondaryIndexManagementCompletedTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.currentlyBlockedTasks db.threadpool.internalSecondaryIndexManagementCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.pendingTasks db.threadpool.internalSecondaryIndexManagementPendingTasks Cassandra cassandra.node.threadPool.validationExecutor.activeTasks db.threadpool.internalValidationExecutorActiveTasks Cassandra cassandra.node.threadPool.validationExecutor.completedTasks db.threadpool.internalValidationExecutorCompletedTasks Cassandra cassandra.node.threadPool.validationExecutor.currentlyBlockedTasks db.threadpool.internalValidationExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.validationExecutor.pendingTasks db.threadpool.internalValidationExecutorPendingTasks Cassandra cassandra.node.threadPool.viewMutationStage.activeTasks db.threadpool.requestViewMutationStageActiveTasks Cassandra cassandra.node.threadPool.viewMutationStage.completedTasks db.threadpool.requestViewMutationStageCompletedTasks Cassandra cassandra.node.threadPool.viewMutationStage.currentlyBlockedTasks db.threadpool.requestViewMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.viewMutationStage.pendingTasks db.threadpool.requestViewMutationStagePendingTasks Cassandra cassandra.node.totalHintsInProgress db.totalHintsInProgress Cassandra cassandra.node.totalHintsPerSecond db.totalHintsPerSecond Cassandra cassandra.columnFamily.allMemtablesOffHeapSizeBytes db.allMemtablesOffHeapSizeBytes Cassandra cassandra.columnFamily.allMemtablesOnHeapSizeBytes db.allMemtablesOnHeapSizeBytes Cassandra cassandra.columnFamily.bloomFilterFalseRatio db.bloomFilterFalseRatio Cassandra cassandra.columnFamily.liveDiskSpaceUsedBytes db.liveDiskSpaceUsedBytes Cassandra cassandra.columnFamily.liveSsTableCount db.liveSSTableCount Cassandra cassandra.columnFamily.maxRowSize db.maxRowSize Cassandra cassandra.columnFamily.meanRowSize db.meanRowSize Cassandra cassandra.columnFamily.memtableLiveDataSize db.memtableLiveDataSize Cassandra cassandra.columnFamily.minRowSize db.minRowSize Cassandra cassandra.columnFamily.pendingCompactions db.pendingCompactions Cassandra cassandra.columnFamily.query.readLatency50ThPercentileMilliseconds query.readLatency50thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency75ThPercentileMilliseconds query.readLatency75thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency95ThPercentileMilliseconds query.readLatency95thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency98ThPercentileMilliseconds query.readLatency98thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency999ThPercentileMilliseconds query.readLatency999thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency99ThPercentileMilliseconds query.readLatency99thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readRequestsPerSecond query.readRequestsPerSecond Cassandra cassandra.columnFamily.query.writeLatency50ThPercentileMilliseconds query.writeLatency50thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency75ThPercentileMilliseconds query.writeLatency75thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency95ThPercentileMilliseconds query.writeLatency95thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency98ThPercentileMilliseconds query.writeLatency98thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency999ThPercentileMilliseconds query.writeLatency999thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency99ThPercentileMilliseconds query.writeLatency99thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeRequestsPerSecond query.writeRequestsPerSecond Cassandra cassandra.columnFamily.speculativeRetries db.speculativeRetries Cassandra cassandra.columnFamily.ssTablesPerRead50ThPercentileMilliseconds db.SSTablesPerRead50thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead75ThPercentileMilliseconds db.SSTablesPerRead75thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead95ThPercentileMilliseconds db.SSTablesPerRead95thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead98ThPercentileMilliseconds db.SSTablesPerRead98thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead999ThPercentileMilliseconds db.SSTablesPerRead999thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead99ThPercentileMilliseconds db.SSTablesPerRead99thPercentileMilliseconds Cassandra cassandra.columnFamily.tombstoneScannedHistogram50ThPercentile db.tombstoneScannedHistogram50thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram75ThPercentile db.tombstoneScannedHistogram75thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram95ThPercentile db.tombstoneScannedHistogram95thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram98ThPercentile db.tombstoneScannedHistogram98thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram999ThPercentile db.tombstoneScannedHistogram999thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram99ThPercentile db.tombstoneScannedHistogram99thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogramCount db.tombstoneScannedHistogramCount Consul consul.datacenter.catalog.criticalNodes catalog.criticalNodes Consul consul.datacenter.catalog.passingNodes catalog.passingNodes Consul consul.datacenter.catalog.registeredNodes catalog.registeredNodes Consul consul.datacenter.catalog.upNodes catalog.upNodes Consul consul.datacenter.catalog.warningNodes catalog.warningNodes Consul consul.datacenter.cluster.flaps cluster.flaps Consul consul.datacenter.cluster.suspects cluster.suspects Consul consul.datacenter.raft.commitTime raft.commitTimes Consul consul.datacenter.raft.commitTimeAvgInMilliseconds raft.commitTimeAvgInMilliseconds Consul consul.datacenter.raft.commitTimeMaxInMilliseconds raft.commitTimeMaxInMilliseconds Consul consul.datacenter.raft.completedLeaderElections raft.completedLeaderElections Consul consul.datacenter.raft.initiatedLeaderElections raft.initiatedLeaderElections Consul consul.datacenter.raft.lastContactAvgInMilliseconds raft.lastContactAvgInMilliseconds Consul consul.datacenter.raft.lastContactMaxInMilliseconds raft.lastContactMaxInMilliseconds Consul consul.datacenter.raft.lastContacts raft.lastContacts Consul consul.datacenter.raft.logDispatchAvgInMilliseconds raft.logDispatchAvgInMilliseconds Consul consul.datacenter.raft.logDispatches raft.logDispatches Consul consul.datacenter.raft.logDispatchMaxInMilliseconds raft.logDispatchMaxInMilliseconds Consul consul.datacenter.raft.txns raft.txns Consul consul.agent.aclCacheHitPerSecond agent.aclCacheHit Consul consul.agent.aclCacheMissPerSecond agent.aclCacheMiss Consul consul.agent.client.rpcFailed client.rpcFailed Consul consul.agent.client.rpcLoad client.rpcLoad Consul consul.agent.kvStores agent.kvStoress Consul consul.agent.kvStoresAvgInMilliseconds agent.kvStoresAvgInMilliseconds Consul consul.agent.kvStoresMaxInMilliseconds agent.kvStoresMaxInMilliseconds Consul consul.agent.net.agent.maxLatencyInMilliseconds net.agent.maxLatencyInMilliseconds Consul consul.agent.net.medianLatencyInMilliseconds net.agent.medianLatencyInMilliseconds Consul consul.agent.net.minLatencyInMilliseconds net.agent.minLatencyInMilliseconds Consul consul.agent.net.p25LatencyInMilliseconds net.agent.p25LatencyInMilliseconds Consul consul.agent.net.p75LatencyInMilliseconds net.agent.p75LatencyInMilliseconds Consul consul.agent.net.p90LatencyInMilliseconds net.agent.p90LatencyInMilliseconds Consul consul.agent.net.p95LatencyInMilliseconds net.agent.p95LatencyInMilliseconds Consul consul.agent.net.p99LatencyInMilliseconds net.agent.p99LatencyInMilliseconds Consul consul.agent.peers agent.peers Consul consul.agent.runtime.allocations runtime.allocations Consul consul.agent.runtime.allocationsInBytes runtime.allocationsInBytes Consul consul.agent.runtime.frees runtime.frees Consul consul.agent.runtime.gcCycles runtime.gcCycles Consul consul.agent.runtime.gcPauseInMilliseconds runtime.gcPauseInMilliseconds Consul consul.agent.runtime.goroutines runtime.goroutines Consul consul.agent.runtime.heapObjects runtime.heapObjects Consul consul.agent.runtime.virtualAddressSpaceInBytes runtime.virtualAddressSpaceInBytes Consul consul.agent.staleQueries agent.staleQueries Consul consul.agent.txnAvgInMilliseconds agent.txnAvgInMilliseconds Consul consul.agent.txnMaxInMilliseconds agent.txnMaxInMilliseconds Consul consul.agent.txns agent.txns Couchbase couchbase.bucket.activeItemsEnteringDiskQueuePerSecond bucket.activeItemsEnteringDiskQueuePerSecond Couchbase couchbase.bucket.activeItemsInMemory bucket.activeItemsInMemory Couchbase couchbase.bucket.activeResidentItemsRatio bucket.activeResidentItemsRatio Couchbase couchbase.bucket.averageDiskCommitTimeInMilliseconds bucket.averageDiskCommitTimeInMilliseconds Couchbase couchbase.bucket.averageDiskUpdateTimeInMilliseconds bucket.averageDiskUpdateTimeInMilliseconds Couchbase couchbase.bucket.cacheMisses bucket.cacheMisses Couchbase couchbase.bucket.cacheMissRatio bucket.cacheMissRatio Couchbase couchbase.bucket.casHits bucket.casHits Couchbase couchbase.bucket.casMisses bucket.casMisses Couchbase couchbase.bucket.couchDocsFragmentationPercent bucket.couchDocsFragmentationPercent Couchbase couchbase.bucket.currentConnections bucket.currentConnections Couchbase couchbase.bucket.dataUsedInBytes bucket.dataUsedInBytes Couchbase couchbase.bucket.decrementHitsPerSecond bucket.decrementHitsPerSecond Couchbase couchbase.bucket.decrementMissesPerSecond bucket.decrementMissesPerSecond Couchbase couchbase.bucket.deleteHitsPerSecond bucket.deleteHitsPerSecond Couchbase couchbase.bucket.deleteMissesPerSecond bucket.deleteMissesPerSecond Couchbase couchbase.bucket.diskCreateOperationsPerSecond bucket.diskCreateOperationsPerSecond Couchbase couchbase.bucket.diskFetchesPerSecond bucket.diskFetchesPerSecond Couchbase couchbase.bucket.diskReadsPerSecond bucket.diskReadsPerSecond Couchbase couchbase.bucket.diskUpdateOperationsPerSecond bucket.diskUpdateOperationsPerSecond Couchbase couchbase.bucket.diskUsedInBytes bucket.diskUsedInBytes Couchbase couchbase.bucket.diskWriteQueue bucket.diskWriteQueue Couchbase couchbase.bucket.drainedItemsInQueue bucket.drainedItemsInQueue Couchbase couchbase.bucket.drainedItemsOnDiskQueue bucket.drainedItemsOnDiskQueue Couchbase couchbase.bucket.drainedPendingItemsInQueue bucket.drainedPendingItemsInQueue Couchbase couchbase.bucket.ejectionsPerSecond bucket.ejectionsPerSecond Couchbase couchbase.bucket.evictionsPerSecond bucket.evictionsPerSecond Couchbase couchbase.bucket.getHitsPerSecond bucket.getHitsPerSecond Couchbase couchbase.bucket.getMissesPerSecond bucket.getMissesPerSecond Couchbase couchbase.bucket.hitRatio bucket.hitRatio Couchbase couchbase.bucket.incrementHitsPerSecond bucket.incrementHitsPerSecond Couchbase couchbase.bucket.incrementMissesPerSecond bucket.incrementMissesPerSecond Couchbase couchbase.bucket.itemCount bucket.itemCount Couchbase couchbase.bucket.itemsBeingWritten bucket.itemsBeingWritten Couchbase couchbase.bucket.itemsEjectedFromMemoryToDisk bucket.itemsEjectedFromMemoryToDisk Couchbase couchbase.bucket.itemsOnDiskQueue bucket.itemsOnDiskQueue Couchbase couchbase.bucket.itemsQueuedForStorage bucket.itemsQueuedForStorage Couchbase couchbase.bucket.maximumMemoryUsage bucket.maximumMemoryUsage Couchbase couchbase.bucket.memoryHighWaterMarkInBytes bucket.memoryHighWaterMarkInBytes Couchbase couchbase.bucket.memoryLowWaterMarkInBytes bucket.memoryLowWaterMarkInBytes Couchbase couchbase.bucket.memoryUsedInBytes bucket.memoryUsedInBytes Couchbase couchbase.bucket.metadataInRamInBytes bucket.metadataInRAMInBytes Couchbase couchbase.bucket.missesPerSecond bucket.missesPerSecond Couchbase couchbase.bucket.outOfMemoryErrorsPerSecond bucket.outOfMemoryErrorsPerSecond Couchbase couchbase.bucket.overheadInBytes bucket.overheadInBytes Couchbase couchbase.bucket.pendingItemsInDiskQueue bucket.pendingItemsInDiskQueue Couchbase couchbase.bucket.pendingResidentItemsRatio bucket.pendingResidentItemsRatio Couchbase couchbase.bucket.quotaUtilization bucket.quotaUtilization Couchbase couchbase.bucket.readOperationsPerSecond bucket.readOperationsPerSecond Couchbase couchbase.bucket.readRatePerSecond bucket.readRatePerSecond Couchbase couchbase.bucket.recoverableOutOfMemoryCount bucket.recoverableOutOfMemoryCount Couchbase couchbase.bucket.replicaIndex bucket.replicaIndex Couchbase couchbase.bucket.replicaNumber bucket.replicaNumber Couchbase couchbase.bucket.replicaResidentItemsRatio bucket.replicaResidentItemsRatio Couchbase couchbase.bucket.residentItemsRatio bucket.residentItemsRatio Couchbase couchbase.bucket.temporaryOutOfMemoryErrorsPerSecond bucket.temporaryOutOfMemoryErrorsPerSecond Couchbase couchbase.bucket.threadsNumber bucket.threadsNumber Couchbase couchbase.bucket.totalItems bucket.totalItems Couchbase couchbase.bucket.totalOperationsPerSecond bucket.totalOperationsPerSecond Couchbase couchbase.bucket.viewFragmentationPercent bucket.viewFragmentationPercent Couchbase couchbase.bucket.writeOperationsPerSecond bucket.writeOperationsPerSecond Couchbase couchbase.bucket.writeRatePerSecond bucket.writeRatePerSecond Couchbase couchbase.cluster.autoFailoverCount cluster.autoFailoverCount Couchbase couchbase.cluster.autoFailoverEnabled cluster.autoFailoverEnabled Couchbase couchbase.cluster.databaseFragmentationThreshold cluster.databaseFragmentationThreshold Couchbase couchbase.cluster.diskFreeInBytes cluster.diskFreeInBytes Couchbase couchbase.cluster.diskQuotaTotalInBytes cluster.diskQuotaTotalInBytes Couchbase couchbase.cluster.diskTotalInBytes cluster.diskTotalInBytes Couchbase couchbase.cluster.diskUsedByDataInBytes cluster.diskUsedByDataInBytes Couchbase couchbase.cluster.diskUsedInBytes cluster.diskUsedInBytes Couchbase couchbase.cluster.indexFragmentationThreshold cluster.indexFragmentationThreshold Couchbase couchbase.cluster.maximumBucketCount cluster.maximumBucketCount Couchbase couchbase.cluster.memoryQuotaTotalInBytes cluster.memoryQuotaTotalInBytes Couchbase couchbase.cluster.memoryQuotaTotalPerNodeInBytes cluster.memoryQuotaTotalPerNodeInBytes Couchbase couchbase.cluster.memoryQuotaUsedInBytes cluster.memoryQuotaUsedInBytes Couchbase couchbase.cluster.memoryQuotaUsedPerNodeInBytes cluster.memoryQuotaUsedPerNodeInBytes Couchbase couchbase.cluster.memoryTotalInBytes cluster.memoryTotalInBytes Couchbase couchbase.cluster.memoryUsedByDataInBytes cluster.memoryUsedByDataInBytes Couchbase couchbase.cluster.memoryUsedInBytes cluster.memoryUsedInBytes Couchbase couchbase.cluster.viewFragmentationThreshold cluster.viewFragmentationThreshold Couchbase couchbase.node.backgroundFetches node.backgroundFetches Couchbase couchbase.node.cmdGet node.cmdGet Couchbase couchbase.node.couchDocsActualDiskSizeInBytes node.couchDocsActualDiskSizeInBytes Couchbase couchbase.node.couchDocsDataSizeInBytes node.couchDocsDataSizeInBytes Couchbase couchbase.node.couchSpatialDataSizeInBytes node.couchSpatialDataSizeInBytes Couchbase couchbase.node.couchSpatialDiskSizeInBytes node.couchSpatialDiskSizeInBytes Couchbase couchbase.node.couchViewsActualDiskSizeInBytes node.couchViewsActualDiskSizeInBytes Couchbase couchbase.node.couchViewsDataSizeInBytes node.couchViewsDataSizeInBytes Couchbase couchbase.node.cpuUtilization node.cpuUtilization Couchbase couchbase.node.currentItems node.currentItems Couchbase couchbase.node.currentItemsTotal node.currentItemsTotal Couchbase couchbase.node.getHits node.getHits Couchbase couchbase.node.memoryFreeInBytes node.memoryFreeInBytes Couchbase couchbase.node.memoryTotalInBytes node.memoryTotalInBytes Couchbase couchbase.node.memoryUsedInBytes node.memoryUsedInBytes Couchbase couchbase.node.ops node.ops Couchbase couchbase.node.swapTotalInBytes node.swapTotalInBytes Couchbase couchbase.node.swapUsedInBytes node.swapUsedInBytes Couchbase couchbase.node.uptimeInMilliseconds node.uptimeInMilliseconds Couchbase couchbase.node.vbucketActiveNonResidentItems node.vbucketActiveNonResidentItems Couchbase couchbase.node.vbucketInMemoryItems node.vbucketInMemoryItems Couchbase couchbase.queryengine.activeRequests queryengine.activeRequests Couchbase couchbase.queryengine.averageRequestTimeInMilliseconds queryengine.averageRequestTimeInMilliseconds Couchbase couchbase.queryengine.completedLimit queryengine.completedLimit Couchbase couchbase.queryengine.completedRequests queryengine.completedRequests Couchbase couchbase.queryengine.completedThresholdInMilliseconds queryengine.completedThresholdInMilliseconds Couchbase couchbase.queryengine.cores queryengine.cores Couchbase couchbase.queryengine.garbageCollectionNumber queryengine.garbageCollectionNumber Couchbase couchbase.queryengine.garbageCollectionPaused queryengine.garbageCollectionPaused Couchbase couchbase.queryengine.garbageCollectionTimePausedInMilliseconds queryengine.garbageCollectionTimePausedInMilliseconds Couchbase couchbase.queryengine.medianRequestTimeInMilliseconds queryengine.medianRequestTimeInMilliseconds Couchbase couchbase.queryengine.preparedStatementUtilization queryengine.preparedStatementUtilization Couchbase couchbase.queryengine.requestsLast15MinutesPerSecond queryengine.requestsLast15MinutesPerSecond Couchbase couchbase.queryengine.requestsLast1MinutesPerSecond queryengine.requestsLast1MinutesPerSecond Couchbase couchbase.queryengine.requestsLast5MinutesPerSecond queryengine.requestsLast5MinutesPerSecond Couchbase couchbase.queryengine.requestTime80thPercentileInMilliseconds queryengine.requestTime80thPercentileInMilliseconds Couchbase couchbase.queryengine.requestTime95thPercentileInMilliseconds queryengine.requestTime95thPercentileInMilliseconds Couchbase couchbase.queryengine.requestTime99thPercentileInMilliseconds queryengine.requestTime99thPercentileInMilliseconds Couchbase couchbase.queryengine.systemCpuUtilization queryengine.systemCPUUtilization Couchbase couchbase.queryengine.systemMemoryInBytes queryengine.systemMemoryInBytes Couchbase couchbase.queryengine.totalMemoryInBytes queryengine.totalMemoryInBytes Couchbase couchbase.queryengine.totalThreads queryengine.totalThreads Couchbase couchbase.queryengine.uptimeInMilliseconds queryengine.uptimeInMilliseconds Couchbase couchbase.queryengine.usedMemoryInBytes queryengine.usedMemoryInBytes Couchbase couchbase.queryengine.userCpuUtilization queryengine.userCPUUtilization Docker docker.container.cpuKernelPercent cpuKernelPercent Docker docker.container.cpuLimitCores cpuLimitCores Docker docker.container.cpuPercent cpuPercent Docker docker.container.cpuThrottlePeriods cpuThrottlePeriods Docker docker.container.cpuThrottleTimeMs cpuThrottleTimeMs Docker docker.container.cpuUsedCores cpuUsedCores Docker docker.container.cpuUsedCoresPercent cpuUsedCoresPercent Docker docker.container.cpuUserPercent cpuUserPercent Docker docker.container.ioReadBytesPerSecond ioReadBytesPerSecond Docker docker.container.ioReadCountPerSecond ioReadCountPerSecond Docker docker.container.ioTotalBytes ioTotalBytes Docker docker.container.ioTotalReadBytes ioTotalReadBytes Docker docker.container.ioTotalReadCount ioTotalReadCount Docker docker.container.ioTotalWriteBytes ioTotalWriteBytes Docker docker.container.ioTotalWriteCount ioTotalWriteCount Docker docker.container.ioWriteBytesPerSecond ioWriteBytesPerSecond Docker docker.container.ioWriteCountPerSecond ioWriteCountPerSecond Docker docker.container.memoryCacheBytes memoryCacheBytes Docker docker.container.memoryResidentSizeBytes memoryResidentSizeBytes Docker docker.container.memorySizeLimitBytes memorySizeLimitBytes Docker docker.container.memoryUsageBytes memoryUsageBytes Docker docker.container.memoryUsageLimitPercent memoryUsageLimitPercent Docker docker.container.networkRxBytes networkRxBytes Docker docker.container.networkRxBytesPerSecond networkRxBytesPerSecond Docker docker.container.networkRxDropped networkRxDropped Docker docker.container.networkRxDroppedPerSecond networkRxDroppedPerSecond Docker docker.container.networkRxErrors networkRxErrors Docker docker.container.networkRxErrorsPerSecond networkRxErrorsPerSecond Docker docker.container.networkRxPackets networkRxPackets Docker docker.container.networkRxPacketsPerSecond networkRxPacketsPerSecond Docker docker.container.networkTxBytes networkTxBytes Docker docker.container.networkTxBytesPerSecond networkTxBytesPerSecond Docker docker.container.networkTxDropped networkTxDropped Docker docker.container.networkTxDroppedPerSecond networkTxDroppedPerSecond Docker docker.container.networkTxErrors networkTxErrors Docker docker.container.networkTxErrorsPerSecond networkTxErrorsPerSecond Docker docker.container.networkTxPackets networkTxPackets Docker docker.container.networkTxPacketsPerSecond networkTxPacketsPerSecond Docker docker.container.pids pids Docker docker.container.processCount processCount Docker docker.container.processCountLimit processCountLimit Docker docker.container.restartCount restartCount Docker docker.container.threadCount threadCount Docker docker.container.threadCountLimit threadCountLimit ElasticSearch elasticsearch.cluster.dataNodes cluster.dataNodes ElasticSearch elasticsearch.cluster.nodes cluster.nodes ElasticSearch elasticsearch.cluster.shards.active shards.active ElasticSearch elasticsearch.cluster.shards.initializing shards.initializing ElasticSearch elasticsearch.cluster.shards.primaryActive shards.primaryActive ElasticSearch elasticsearch.cluster.shards.relocating shards.relocating ElasticSearch elasticsearch.cluster.shards.unassigned shards.unassigned ElasticSearch elasticsearch.cluster.tempData temp-data ElasticSearch elasticsearch.index.docs index.docs ElasticSearch elasticsearch.index.docsDeleted index.docsDeleted ElasticSearch elasticsearch.index.primaryShards index.primaryShards ElasticSearch elasticsearch.index.primaryStoreSizeInBytes index.primaryStoreSizeInBytes ElasticSearch elasticsearch.index.replicaShards index.replicaShards ElasticSearch elasticsearch.index.rollup.docsCount primaries.docsnumber ElasticSearch elasticsearch.index.rollup.docsDeleted primaries.docsDeleted ElasticSearch elasticsearch.index.rollup.flushTotal primaries.flushesTotal ElasticSearch elasticsearch.index.rollup.flushTotalTimeInMilliseconds primaries.flushTotalTimeInMilliseconds ElasticSearch elasticsearch.index.rollup.get.documentsExist primaries.get.documentsExist ElasticSearch elasticsearch.index.rollup.get.documentsExistInMilliseconds primaries.get.documentsExistInMilliseconds ElasticSearch elasticsearch.index.rollup.get.documentsMissing primaries.get.documentsMissing ElasticSearch elasticsearch.index.rollup.get.documentsMissingInMilliseconds primaries.get.documentsMissingInMilliseconds ElasticSearch elasticsearch.index.rollup.get.requests primaries.get.requests ElasticSearch elasticsearch.index.rollup.get.requestsCurrent primaries.get.requestsCurrent ElasticSearch elasticsearch.index.rollup.get.requestsInMilliseconds primaries.get.requestsInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyDeleted primaries.index.docsCurrentlyDeleted ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyDeletedInMilliseconds primaries.index.docsCurrentlyDeletedInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyIndexing primaries.index.docsCurrentlyIndexing ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyIndexingInMilliseconds primaries.index.docsCurrentlyIndexingInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsDeleted primaries.index.docsDeleted ElasticSearch elasticsearch.index.rollup.index.docsTotal primaries.index.docsTotal ElasticSearch elasticsearch.index.rollup.indexRefreshesTotal primaries.indexRefreshesTotal ElasticSearch elasticsearch.index.rollup.indexRefreshesTotalInMilliseconds primaries.indexRefreshesTotalInMilliseconds ElasticSearch elasticsearch.index.rollup.merges.current primaries.merges.current ElasticSearch elasticsearch.index.rollup.merges.docsSegmentsCurrentlyMerged primaries.merges.docsSegmentsCurrentlyMerged ElasticSearch elasticsearch.index.rollup.merges.docsTotal primaries.merges.docsTotal ElasticSearch elasticsearch.index.rollup.merges.segmentsCurrentlyMergedInBytes primaries.merges.segmentsCurrentlyMergedInBytes ElasticSearch elasticsearch.index.rollup.merges.segmentsTotal primaries.merges.segmentsTotal ElasticSearch elasticsearch.index.rollup.merges.segmentsTotalInBytes primaries.merges.segmentsTotalInBytes ElasticSearch elasticsearch.index.rollup.merges.segmentsTotalInMilliseconds primaries.merges.segmentsTotalInMilliseconds ElasticSearch elasticsearch.index.rollup.queriesInMilliseconds primaries.queriesInMilliseconds ElasticSearch elasticsearch.index.rollup.queriesTotal primaries.queriesTotal ElasticSearch elasticsearch.index.rollup.queryActive primaries.queryActive ElasticSearch elasticsearch.index.rollup.queryFetches primaries.queryFetches ElasticSearch elasticsearch.index.rollup.queryFetchesInMilliseconds primaries.queryFetchesInMilliseconds ElasticSearch elasticsearch.index.rollup.queryFetchesTotal primaries.queryFetchesTotal ElasticSearch elasticsearch.index.rollup.sizeInBytes primaries.sizeInBytes ElasticSearch elasticsearch.index.storeSizeInBytes index.storeSizeInBytes ElasticSearch elasticsearch.node.activeSearches activeSearches ElasticSearch elasticsearch.node.activeSearchesInMilliseconds activeSearchesInMilliseconds ElasticSearch elasticsearch.node.breakers.estimatedSizeFieldDataCircuitBreakerInBytes breakers.estimatedSizeFieldDataCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.estimatedSizeParentCircuitBreakerInBytes breakers.estimatedSizeParentCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.estimatedSizeRequestCircuitBreakerInBytes breakers.estimatedSizeRequestCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.fieldDataCircuitBreakerTripped breakers.fieldDataCircuitBreakerTripped ElasticSearch elasticsearch.node.breakers.parentCircuitBreakerTripped breakers.parentCircuitBreakerTripped ElasticSearch elasticsearch.node.breakers.requestCircuitBreakerTripped breakers.requestCircuitBreakerTripped ElasticSearch elasticsearch.node.flush.indexRefreshesTotal flush.indexRefreshesTotal ElasticSearch elasticsearch.node.flush.indexRefreshesTotalInMilliseconds flush.indexRefreshesTotalInMilliseconds ElasticSearch elasticsearch.node.fs.bytesAvailableJvmInBytes fs.bytesAvailableJVMInBytes ElasticSearch elasticsearch.node.fs.dataRead fs.bytesReadsInBytes ElasticSearch elasticsearch.node.fs.dataWritten fs.writesInBytes ElasticSearch elasticsearch.node.fs.ioOperations fs.iOOperations ElasticSearch elasticsearch.node.fs.readOperations fs.reads ElasticSearch elasticsearch.node.fs.totalSizeInBytes fs.totalSizeInBytes ElasticSearch elasticsearch.node.fs.unallocatedBytes fs.unallocatedBytesInBYtes ElasticSearch elasticsearch.node.fs.writeOperations fs.writeOperations ElasticSearch elasticsearch.node.get.currentRequestsRunning get.currentRequestsRunning ElasticSearch elasticsearch.node.get.requestsDocumentExists get.requestsDocumentExists ElasticSearch elasticsearch.node.get.requestsDocumentExistsInMilliseconds get.requestsDocumentExistsInMilliseconds ElasticSearch elasticsearch.node.get.requestsDocumentMissing get.requestsDocumentMissing ElasticSearch elasticsearch.node.get.requestsDocumentMissingInMilliseconds get.requestsDocumentMissingInMilliseconds ElasticSearch elasticsearch.node.get.timeGetRequestsInMilliseconds get.timeGetRequestsInMilliseconds ElasticSearch elasticsearch.node.get.totalGetRequests get.totalGetRequests ElasticSearch elasticsearch.node.http.currentOpenConnections http.currentOpenConnections ElasticSearch elasticsearch.node.http.openedConnections http.openedConnections ElasticSearch elasticsearch.node.index.indexingOperationsFailed indices.indexingOperationsFailed ElasticSearch elasticsearch.node.index.indexingWaitedThrottlingInMilliseconds indices.indexingWaitedThrottlingInMilliseconds ElasticSearch elasticsearch.node.index.memoryQueryCacheInBytes indices.memoryQueryCacheInBytes ElasticSearch elasticsearch.node.index.numberIndices indices.numberIndices ElasticSearch elasticsearch.node.index.queryCacheEvictions indices.queryCacheEvictions ElasticSearch elasticsearch.node.index.queryCacheHits indices.queryCacheHits ElasticSearch elasticsearch.node.index.queryCacheMisses indices.queryCacheMisses ElasticSearch elasticsearch.node.index.recoveryOngoingShardSource indices.recoveryOngoingShardSource ElasticSearch elasticsearch.node.index.recoveryOngoingShardTarget indices.recoveryOngoingShardTarget ElasticSearch elasticsearch.node.index.recoveryWaitedThrottlingInMilliseconds indices.recoveryWaitedThrottlingInMilliseconds ElasticSearch elasticsearch.node.index.requestCacheEvictions indices.requestCacheEvictions ElasticSearch elasticsearch.node.index.requestCacheHits indices.requestCacheHits ElasticSearch elasticsearch.node.index.requestCacheMemoryInBytes indices.requestCacheMemoryInBytes ElasticSearch elasticsearch.node.index.requestCacheMisses indices.requestCacheMisses ElasticSearch elasticsearch.node.index.segmentsIndexShard indices.segmentsIndexShard ElasticSearch elasticsearch.node.index.segmentsMemoryUsedDocValuesInBytes indices.segmentsMemoryUsedDocValuesInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedFixedBitSetInBytes indices.segmentsMemoryUsedFixedBitSetInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedIndexSegmentsInBytes indices.segmentsMemoryUsedIndexSegmentsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedIndexWriterInBytes indices.segmentsMemoryUsedIndexWriterInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedNormsInBytes indices.segmentsMemoryUsedNormsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedSegmentVersionMapInBytes indices.segmentsMemoryUsedSegmentVersionMapInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedStoredFieldsInBytes indices.segmentsMemoryUsedStoredFieldsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedTermsInBytes indices.segmentsMemoryUsedTermsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedTermVectorsInBytes indices.segmentsMemoryUsedTermVectorsInBytes ElasticSearch elasticsearch.node.index.translogOperations indices.translogOperations ElasticSearch elasticsearch.node.index.translogOperationsInBytes indices.translogOperationsInBytes ElasticSearch elasticsearch.node.indexing.docsCurrentlyDeleted indexing.docsCurrentlyDeleted ElasticSearch elasticsearch.node.indexing.documentsCurrentlyIndexing indexing.documentsCurrentlyIndexing ElasticSearch elasticsearch.node.indexing.documentsIndexed indexing.documentsIndexed ElasticSearch elasticsearch.node.indexing.timeDeletingDocumentsInMilliseconds indexing.timeDeletingDocumentsInMilliseconds ElasticSearch elasticsearch.node.indexing.timeIndexingDocumentsInMilliseconds indexing.timeIndexingDocumentsInMilliseconds ElasticSearch elasticsearch.node.indexing.totalDocumentsDeleted indexing.totalDocumentsDeleted ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsOldGenerationObjects jvm.gc.majorCollectionsOldGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsOldGenerationObjectsInMilliseconds jvm.gc.majorCollectionsOldGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsYoungGenerationObjects jvm.gc.majorCollectionsYoungGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsYoungGenerationObjectsInMilliseconds jvm.gc.majorCollectionsYoungGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.gc.minorCollectionsYoungGenerationObjects jvm.gc.minorCollectionsYoungGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.minorCollectionsYoungGenerationObjectsInMilliseconds jvm.gc.minorCollectionsYoungGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.mem.heapCommittedInBytes jvm.mem.heapCommittedInBytes ElasticSearch elasticsearch.node.jvm.mem.heapMaxInBytes jvm.mem.heapMaxInBytes ElasticSearch elasticsearch.node.jvm.mem.heapUsed jvm.mem.heapUsed ElasticSearch elasticsearch.node.jvm.mem.heapUsedInBytes jvm.mem.heapUsedInBytes ElasticSearch elasticsearch.node.jvm.mem.maxOldGenerationHeapInBytes jvm.mem.maxOldGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.maxSurvivorSpaceInBytes jvm.mem.maxSurvivorSpaceInBYtes ElasticSearch elasticsearch.node.jvm.mem.maxYoungGenerationHeapInBytes jvm.mem.maxYoungGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.nonHeapCommittedInBytes jvm.mem.nonHeapCommittedInBytes ElasticSearch elasticsearch.node.jvm.mem.nonHeapUsedInBytes jvm.mem.nonHeapUsedInBytes ElasticSearch elasticsearch.node.jvm.mem.usedOldGenerationHeapInBytes jvm.mem.usedOldGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.usedSurvivorSpaceInBytes jvm.mem.usedSurvivorSpaceInBytes ElasticSearch elasticsearch.node.jvm.mem.usedYoungGenerationHeapInBytes jvm.mem.usedYoungGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.threadsActive jvm.ThreadsActive ElasticSearch elasticsearch.node.jvm.threadsPeak jvm.ThreadsPeak ElasticSearch elasticsearch.node.merges.currentActive merges.currentActive ElasticSearch elasticsearch.node.merges.docsSegmentMerges merges.docsSegmentMerges ElasticSearch elasticsearch.node.merges.docsSegmentsMerging merges.docsSegmentsMerging ElasticSearch elasticsearch.node.merges.mergedSegmentsInBytes merges.mergedSegmentsInBytes ElasticSearch elasticsearch.node.merges.segmentMerges merges.segmentMerges ElasticSearch elasticsearch.node.merges.sizeSegmentsMergingInBytes merges.sizeSegmentsMergingInBytes ElasticSearch elasticsearch.node.merges.totalSegmentMergingInMilliseconds merges.totalSegmentMergingInMilliseconds ElasticSearch elasticsearch.node.openFd openFD ElasticSearch elasticsearch.node.queriesTotal queriesTotal ElasticSearch elasticsearch.node.refresh.total refresh.total ElasticSearch elasticsearch.node.refresh.totalInMilliseconds refresh.totalInMilliseconds ElasticSearch elasticsearch.node.searchFetchCurrentlyRunning searchFetchCurrentlyRunning ElasticSearch elasticsearch.node.searchFetches searchFetches ElasticSearch elasticsearch.node.sizeStoreInBytes sizeStoreInBytes ElasticSearch elasticsearch.node.threadpool.activeFetchShardStarted threadpool.activeFetchShardStarted ElasticSearch elasticsearch.node.threadpool.bulkActive threadpool.bulkActive ElasticSearch elasticsearch.node.threadpool.bulkQueue threadpool.bulkQueue ElasticSearch elasticsearch.node.threadpool.bulkRejected threadpool.bulkRejected ElasticSearch elasticsearch.node.threadpool.bulkThreads threadpool.bulkThreads ElasticSearch elasticsearch.node.threadpool.fetchShardStartedQueue threadpool.fetchShardStartedQueue ElasticSearch elasticsearch.node.threadpool.fetchShardStartedRejected threadpool.fetchShardStartedRejected ElasticSearch elasticsearch.node.threadpool.fetchShardStartedThreads threadpool.fetchShardStartedThreads ElasticSearch elasticsearch.node.threadpool.fetchShardStoreActive threadpool.fetchShardStoreActive ElasticSearch elasticsearch.node.threadpool.fetchShardStoreQueue threadpool.fetchShardStoreQueue ElasticSearch elasticsearch.node.threadpool.fetchShardStoreRejected threadpool.fetchShardStoreRejected ElasticSearch elasticsearch.node.threadpool.fetchShardStoreThreads threadpool.fetchShardStoreThreads ElasticSearch elasticsearch.node.threadpool.flushActive threadpool.flushActive ElasticSearch elasticsearch.node.threadpool.flushQueue threadpool.flushQueue ElasticSearch elasticsearch.node.threadpool.flushRejected threadpool.flushRejected ElasticSearch elasticsearch.node.threadpool.flushThreads threadpool.flushThreads ElasticSearch elasticsearch.node.threadpool.forceMergeActive threadpool.forceMergeActive ElasticSearch elasticsearch.node.threadpool.forceMergeQueue threadpool.forceMergeQueue ElasticSearch elasticsearch.node.threadpool.forceMergeRejected threadpool.forceMergeRejected ElasticSearch elasticsearch.node.threadpool.forceMergeThreads threadpool.forceMergeThreads ElasticSearch elasticsearch.node.threadpool.genericActive threadpool.genericActive ElasticSearch elasticsearch.node.threadpool.genericQueue threadpool.genericQueue ElasticSearch elasticsearch.node.threadpool.genericRejected threadpool.genericRejected ElasticSearch elasticsearch.node.threadpool.genericThreads threadpool.genericThreads ElasticSearch elasticsearch.node.threadpool.getActive threadpool.getActive ElasticSearch elasticsearch.node.threadpool.getQueue threadpool.getQueue ElasticSearch elasticsearch.node.threadpool.getRejected threadpool.getRejected ElasticSearch elasticsearch.node.threadpool.getThreads threadpool.getThreads ElasticSearch elasticsearch.node.threadpool.indexActive threadpool.indexActive ElasticSearch elasticsearch.node.threadpool.indexQueue threadpool.indexQueue ElasticSearch elasticsearch.node.threadpool.indexRejected threadpool.indexRejected ElasticSearch elasticsearch.node.threadpool.indexThreads threadpool.indexThreads ElasticSearch elasticsearch.node.threadpool.listenerActive threadpool.listenerActive ElasticSearch elasticsearch.node.threadpool.listenerQueue threadpool.listenerQueue ElasticSearch elasticsearch.node.threadpool.listenerRejected threadpool.listenerRejected ElasticSearch elasticsearch.node.threadpool.listenerThreads threadpool.listenerThreads ElasticSearch elasticsearch.node.threadpool.managementActive threadpool.managementActive ElasticSearch elasticsearch.node.threadpool.managementQueue threadpool.managementQueue ElasticSearch elasticsearch.node.threadpool.managementRejected threadpool.managementRejected ElasticSearch elasticsearch.node.threadpool.managementThreads threadpool.managementThreads ElasticSearch elasticsearch.node.threadpool.refreshActive threadpool.refreshActive ElasticSearch elasticsearch.node.threadpool.refreshQueue threadpool.refreshQueue ElasticSearch elasticsearch.node.threadpool.refreshRejected threadpool.refreshRejected ElasticSearch elasticsearch.node.threadpool.refreshThreads threadpool.refreshThreads ElasticSearch elasticsearch.node.threadpool.searchActive threadpool.searchActive ElasticSearch elasticsearch.node.threadpool.searchQueue threadpool.searchQueue ElasticSearch elasticsearch.node.threadpool.searchRejected threadpool.searchRejected ElasticSearch elasticsearch.node.threadpool.searchThreads threadpool.searchThreads ElasticSearch elasticsearch.node.threadpool.snapshotActive threadpool.snapshotActive ElasticSearch elasticsearch.node.threadpool.snapshotQueue threadpool.snapshotQueue ElasticSearch elasticsearch.node.threadpool.snapshotRejected threadpool.snapshotRejected ElasticSearch elasticsearch.node.threadpool.snapshotThreads threadpool.snapshotThreads ElasticSearch elasticsearch.node.transport.connectionsOpened transport.connectionsOpened ElasticSearch elasticsearch.node.transport.packetsReceived transport.packetsReceived ElasticSearch elasticsearch.node.transport.packetsReceivedInBytes transport.packetsReceivedInBytes ElasticSearch elasticsearch.node.transport.packetsSent transport.packetsSent ElasticSearch elasticsearch.node.transport.packetsSentInBytes transport.packetsSentInBytes F5 f5.node.availabilityState node.availabilityState F5 f5.node.connections node.connections F5 f5.node.connectionsPerSecond node.connectionsPerSecond F5 f5.node.enabled node.enabled F5 f5.node.inDataInBytesPerSecond node.inDataInBytesPerSecond F5 f5.node.monitorStatus node.monitorStatus F5 f5.node.outDataInBytesPerSecond node.outDataInBytesPerSecond F5 f5.node.packetsReceivedPerSecond node.packetsReceivedPerSecond F5 f5.node.packetsSentPerSecond node.packetsSentPerSecond F5 f5.node.requestsPerSecond node.requestsPerSecond F5 f5.node.sessions node.sessions F5 f5.node.sessionStatus node.sessionStatus F5 f5.poolMember.availabilityState member.availabilityState F5 f5.poolMember.connections member.connections F5 f5.poolMember.enabled member.enabled F5 f5.poolMember.inDataInBytesPerSecond member.inDataInBytesPerSecond F5 f5.poolMember.monitorStatus member.monitorStatus F5 f5.poolMember.outDataInBytesPerSecond member.outDataInBytesPerSecond F5 f5.poolMember.packetsReceivedPerSecond member.packetsReceivedPerSecond F5 f5.poolMember.packetsSentPerSecond member.packetsSentPerSecond F5 f5.poolMember.requestsPerSecond member.requestsPerSecond F5 f5.poolMember.sessions member.sessions F5 f5.poolMember.sessionStatus member.sessionStatus F5 f5.pool.activeMembers pool.activeMembers F5 f5.pool.availabilityState pool.availabilityState F5 f5.pool.connections pool.connections F5 f5.pool.connqAgeEdm pool.connqAgeEdm F5 f5.pool.connqAgeEma pool.connqAgeEma F5 f5.pool.connqAgeHead pool.connqAgeHead F5 f5.pool.connqAgeMax pool.connqAgeMax F5 f5.pool.connqAllAgeEdm pool.connqAllAgeEdm F5 f5.pool.connqAllAgeEma pool.connqAllAgeEma F5 f5.pool.connqAllAgeHead pool.connqAllAgeHead F5 f5.pool.connqAllAgeMax pool.connqAllAgeMax F5 f5.pool.connqAllDepth pool.connqAllDepth F5 f5.pool.connqDepth pool.connqDepth F5 f5.pool.currentConnections pool.currentConnections F5 f5.pool.enabled pool.enabled F5 f5.pool.inDataInBytesPerSecond pool.inDataInBytesPerSecond F5 f5.pool.minActiveMembers pool.minActiveMembers F5 f5.pool.outDataInBytesPerSecond pool.outDataInBytesPerSecond F5 f5.pool.packetsReceivedPerSecond pool.packetsReceivedPerSecond F5 f5.pool.packetsSentPerSecond pool.packetsSentPerSecond F5 f5.pool.requestsPerSecond pool.requestsPerSecond F5 f5.pool.sessions pool.sessions F5 f5.system.cpuIdleTicksPerSecond system.cpuIdleTicksPerSecond F5 f5.system.cpuIdleUtilization system.cpuIdleUtilization F5 f5.system.cpuInterruptRequestUtilization system.cpuInterruptRequestUtilization F5 f5.system.cpuIoWaitUtilization system.cpuIOWaitUtilization F5 f5.system.cpuNiceLevelUtilization system.cpuNiceLevelUtilization F5 f5.system.cpuSoftInterruptRequestUtilization system.cpuSoftInterruptRequestUtilization F5 f5.system.cpuStolenUtilization system.cpuStolenUtilization F5 f5.system.cpuSystemTicksPerSecond system.cpuSystemTicksPerSecond F5 f5.system.cpuSystemUtilization system.cpuSystemUtilization F5 f5.system.cpuUserTicksPerSecond system.cpuUserTicksPerSecond F5 f5.system.cpuUserUtilization system.cpuUserUtilization F5 f5.system.memoryFreeInBytes system.memoryFreeInBytes F5 f5.system.memoryTotalInBytes system.memoryTotalInBytes F5 f5.system.memoryUsedInBytes system.memoryUsedInBytes F5 f5.system.otherMemoryFreeInBytes system.otherMemoryFreeInBytes F5 f5.system.otherMemoryTotalInBytes system.otherMemoryTotalInBytes F5 f5.system.otherMemoryUsedInBytes system.otherMemoryUsedInBytes F5 f5.system.swapFreeInBytes system.swapFreeInBytes F5 f5.system.swapTotalInBytes system.swapTotalInBytes F5 f5.system.swapUsedInBytes system.swapUsedInBytes F5 f5.system.tmmMemoryFreeInBytes system.tmmMemoryFreeInBytes F5 f5.system.tmmMemoryTotalInBytes system.tmmMemoryTotalInBytes F5 f5.system.tmmMemoryUsedInBytes system.tmmMemoryUsedInBytes F5 f5.virtualserver.availabilityState virtualserver.availabilityState F5 f5.virtualserver.clientsideConnectionsPerSecond virtualserver.clientsideConnectionsPerSecond F5 f5.virtualserver.connections virtualserver.connections F5 f5.virtualserver.csMaxConnDur virtualserver.csMaxConnDur F5 f5.virtualserver.csMeanConnDur virtualserver.csMeanConnDur F5 f5.virtualserver.csMinConnDur virtualserver.csMinConnDur F5 f5.virtualserver.enabled virtualserver.enabled F5 f5.virtualserver.ephemeralBytesInPerSecond virtualserver.ephemeralBytesInPerSecond F5 f5.virtualserver.ephemeralBytesOutPerSecond virtualserver.ephemeralBytesOutPerSecond F5 f5.virtualserver.ephemeralConnectionsPerSecond virtualserver.ephemeralConnectionsPerSecond F5 f5.virtualserver.ephemeralCurrentConnections virtualserver.ephemeralCurrentConnections F5 f5.virtualserver.ephemeralEvictedConnectionsPerSecond virtualserver.ephemeralEvictedConnectionsPerSecond F5 f5.virtualserver.ephemeralMaxConnections virtualserver.ephemeralMaxConnections F5 f5.virtualserver.ephemeralPacketsReceivedPerSecond virtualserver.ephemeralPacketsReceivedPerSecond F5 f5.virtualserver.ephemeralPacketsSentPerSecond virtualserver.ephemeralPacketsSentPerSecond F5 f5.virtualserver.ephemeralSlowKilledPerSecond virtualserver.ephemeralSlowKilledPerSecond F5 f5.virtualserver.evictedConnsPerSecond virtualserver.evictedConnsPerSecond F5 f5.virtualserver.inDataInBytesPerSecond virtualserver.inDataInBytesPerSecond F5 f5.virtualserver.outDataInBytesPerSecond virtualserver.outDataInBytesPerSecond F5 f5.virtualserver.packetsReceivedPerSecond virtualserver.packetsReceivedPerSecond F5 f5.virtualserver.packetsSentPerSecond virtualserver.packetsSentPerSecond F5 f5.virtualserver.requestsPerSecond virtualserver.requestsPerSecond F5 f5.virtualserver.slowKilledPerSecond virtualserver.slowKilledPerSecond F5 f5.virtualserver.usageRatio virtualserver.usageRatio HAProxy haproxy.backend.activeServers backend.activeServers HAProxy haproxy.backend.averageConnectTimeInSeconds backend.averageConnectTimeInSeconds HAProxy haproxy.backend.averageQueueTimeInSeconds backend.averageQueueTimeInSeconds HAProxy haproxy.backend.averageResponseTimeInSeconds backend.averageResponseTimeInSeconds HAProxy haproxy.backend.averageTotalSessionTimeInSeconds backend.averageTotalSessionTimeInSeconds HAProxy haproxy.backend.backupServers backend.backupServers HAProxy haproxy.backend.bytesInPerSecond backend.bytesInPerSecond HAProxy haproxy.backend.bytesOutPerSecond backend.bytesOutPerSecond HAProxy haproxy.backend.bytesThatBypassedCompressorPerSecond backend.bytesThatBypassedCompressorPerSecond HAProxy haproxy.backend.connectingRequestErrorsPerSecond backend.connectingRequestErrorsPerSecond HAProxy haproxy.backend.connectionRetriesPerSecond backend.connectionRetriesPerSecond HAProxy haproxy.backend.currentQueuedRequestsWithoutServer backend.currentQueuedRequestsWithoutServer HAProxy haproxy.backend.currentSessions backend.currentSessions HAProxy haproxy.backend.dataTransfersAbortedByClientPerSecond backend.dataTransfersAbortedByClientPerSecond HAProxy haproxy.backend.dataTransfersAbortedByServerPerSecond backend.dataTransfersAbortedByServerPerSecond HAProxy haproxy.backend.downtimeInSeconds backend.downtimeInSeconds HAProxy haproxy.backend.http100ResponsesPerSecond backend.http100ResponsesPerSecond HAProxy haproxy.backend.http200ResponsesPerSecond backend.http200ResponsesPerSecond HAProxy haproxy.backend.http300ResponsesPerSecond backend.http300ResponsesPerSecond HAProxy haproxy.backend.http400ResponsesPerSecond backend.http400ResponsesPerSecond HAProxy haproxy.backend.http500ResponsesPerSecond backend.http500ResponsesPerSecond HAProxy haproxy.backend.httpOtherResponsesPerSecond backend.httpOtherResponsesPerSecond HAProxy haproxy.backend.httpRequestsPerSecond backend.httpRequestsPerSecond HAProxy haproxy.backend.httpResponseBytesEmittedByCompressorPerSecond backend.httpResponseBytesEmittedByCompressorPerSecond HAProxy haproxy.backend.httpResponseBytesFedToCompressorPerSecond backend.httpResponseBytesFedToCompressorPerSecond HAProxy haproxy.backend.httpResponsesCompressedPerSecond backend.httpResponsesCompressedPerSecond HAProxy haproxy.backend.interceptedRequestsPerSecond backend.interceptedRequestsPerSecond HAProxy haproxy.backend.maxQueuedRequestsWithoutServer backend.maxQueuedRequestsWithoutServer HAProxy haproxy.backend.maxSessions backend.maxSessions HAProxy haproxy.backend.maxSessionsPerSecond backend.maxSessionsPerSecond HAProxy haproxy.backend.requestRedispatchPerSecond backend.requestRedispatchPerSecond HAProxy haproxy.backend.requestsDenied.securityConcernsPerSecond backend.requestsDenied.securityConcernsPerSecond HAProxy haproxy.backend.responseErrorsPerSecond backend.responseErrorsPerSecond HAProxy haproxy.backend.responsesDenied.securityConcernsPerSecond backend.responsesDenied.securityConcernsPerSecond HAProxy haproxy.backend.serverSelectedPerSecond backend.serverSelectedPerSecond HAProxy haproxy.backend.sessionsPerSecond backend.sessionsPerSecond HAProxy haproxy.backend.timeSinceLastSessionAssignedInSeconds backend.timeSinceLastSessionAssignedInSeconds HAProxy haproxy.backend.timeSinceLastUpDownTransitionInSeconds backend.timeSinceLastUpDownTransitionInSeconds HAProxy haproxy.backend.totalWeight backend.totalWeight HAProxy haproxy.backend.type backend.type HAProxy haproxy.backend.upToDownTransitionsPerSecond backend.upToDownTransitionsPerSecond HAProxy haproxy.frontend.bytesInPerSecond frontend.bytesInPerSecond HAProxy haproxy.frontend.bytesOutPerSecond frontend.bytesOutPerSecond HAProxy haproxy.frontend.connectionsPerSecond frontend.connectionsPerSecond HAProxy haproxy.frontend.currentSessions frontend.currentSessions HAProxy haproxy.frontend.http100ResponsesPerSecond frontend.http100ResponsesPerSecond HAProxy haproxy.frontend.http200ResponsesPerSecond frontend.http200ResponsesPerSecond HAProxy haproxy.frontend.http300ResponsesPerSecond frontend.http300ResponsesPerSecond HAProxy haproxy.frontend.http400ResponsesPerSecond frontend.http400ResponsesPerSecond HAProxy haproxy.frontend.http500ResponsesPerSecond frontend.http500ResponsesPerSecond HAProxy haproxy.frontend.httpOtherResponsesPerSecond frontend.httpOtherResponsesPerSecond HAProxy haproxy.frontend.httpRequests.maxPerSecond frontend.httpRequests.maxPerSecond HAProxy haproxy.frontend.httpRequestsPerSecond frontend.httpRequestsPerSecond HAProxy haproxy.frontend.interceptedRequestsPerSecond frontend.interceptedRequestsPerSecond HAProxy haproxy.frontend.maxConnectionsPerSecond frontend.maxConnectionsPerSecond HAProxy haproxy.frontend.maxSessions frontend.maxSessions HAProxy haproxy.frontend.maxSessionsPerSecond frontend.maxSessionsPerSecond HAProxy haproxy.frontend.requestErrorsPerSecond frontend.requestErrorsPerSecond HAProxy haproxy.frontend.requestsDenied.securityConcernsPerSecond frontend.requestsDenied.securityConcernsPerSecond HAProxy haproxy.frontend.requestsDenied.tcpRequestConnectionRulesPerSecond frontend.requestsDenied.tcpRequestConnectionRulesPerSecond HAProxy haproxy.frontend.requestsDenied.tcpRequestSessionRulesPerSecond frontend.requestsDenied.tcpRequestSessionRulesPerSecond HAProxy haproxy.frontend.responsesDenied.securityConcernsPerSecond frontend.responsesDenied.securityConcernsPerSecond HAProxy haproxy.frontend.sessionsPerSecond frontend.sessionsPerSecond HAProxy haproxy.server.averageConnectTimeInSeconds server.averageConnectTimeInSeconds HAProxy haproxy.server.averageQueueTimeInSeconds server.averageQueueTimeInSeconds HAProxy haproxy.server.averageResponseTimeInSeconds server.averageResponseTimeInSeconds HAProxy haproxy.server.averageTotalSessionTimeInSeconds server.averageTotalSessionTimeInSeconds HAProxy haproxy.server.bytesInPerSecond server.bytesInPerSecond HAProxy haproxy.server.bytesOutPerSecond server.bytesOutPerSecond HAProxy haproxy.server.connectingRequestErrorsPerSecond server.connectingRequestErrorsPerSecond HAProxy haproxy.server.connectionRetriesPerSecond server.connectionRetriesPerSecond HAProxy haproxy.server.currentQueuedRequestsWithoutServer server.currentQueuedRequestsWithoutServer HAProxy haproxy.server.currentSessions server.currentSessions HAProxy haproxy.server.dataTransfersAbortedByClientPerSecond server.dataTransfersAbortedByClientPerSecond HAProxy haproxy.server.dataTransfersAbortedByServerPerSecond server.dataTransfersAbortedByServerPerSecond HAProxy haproxy.server.downtimeInSeconds server.downtimeInSeconds HAProxy haproxy.server.failedChecksPerSecond server.failedChecksPerSecond HAProxy haproxy.server.healthCheckDurationInMilliseconds server.healthCheckDurationInMilliseconds HAProxy haproxy.server.http100ResponsesPerSecond server.http100ResponsesPerSecond HAProxy haproxy.server.http200ResponsesPerSecond server.http200ResponsesPerSecond HAProxy haproxy.server.http300ResponsesPerSecond server.http300ResponsesPerSecond HAProxy haproxy.server.http400ResponsesPerSecond server.http400ResponsesPerSecond HAProxy haproxy.server.http500ResponsesPerSecond server.http500ResponsesPerSecond HAProxy haproxy.server.httpOtherResponsesPerSecond server.httpOtherResponsesPerSecond HAProxy haproxy.server.isActive server.isActive HAProxy haproxy.server.isBackup server.isBackup HAProxy haproxy.server.maxQueuedRequestsWithoutServer server.maxQueuedRequestsWithoutServer HAProxy haproxy.server.maxSessions server.maxSessions HAProxy haproxy.server.maxSessionsPerSecond server.maxSessionsPerSecond HAProxy haproxy.server.requestRedispatchPerSecond server.requestRedispatchPerSecond HAProxy haproxy.server.requestsDenied.securityConcernsPerSecond server.requestsDenied.securityConcernsPerSecond HAProxy haproxy.server.responseErrorsPerSecond server.responseErrorsPerSecond HAProxy haproxy.server.responsesDenied.securityConcernsPerSecond server.responsesDenied.securityConcernsPerSecond HAProxy haproxy.server.serverSelectedPerSecond server.serverSelectedPerSecond HAProxy haproxy.server.serverWeight server.serverWeight HAProxy haproxy.server.sessionsPerSecond server.sessionsPerSecond HAProxy haproxy.server.throttlePercentage server.throttlePercentage HAProxy haproxy.server.timeSinceLastSessionAssignedInSeconds server.timeSinceLastSessionAssignedInSeconds HAProxy haproxy.server.timeSinceLastUpDownTransitionInSeconds server.timeSinceLastUpDownTransitionInSeconds HAProxy haproxy.server.type server.type HAProxy haproxy.server.upToDownTransitionsPerSecond server.upToDownTransitionsPerSecond Kafka kafka.broker.bytesWrittenToTopicPerSecond broker.bytesWrittenToTopicPerSecond Kafka kafka.broker.consumer.requestsExpiredPerSecond consumer.requestsExpiredPerSecond Kafka kafka.broker.follower.requestExpirationPerSecond follower.requestExpirationPerSecond Kafka kafka.broker.ioInPerSecond broker.IOInPerSecond Kafka kafka.broker.ioOutPerSecond broker.IOOutPerSecond Kafka kafka.broker.logFlushPerSecond broker.logFlushPerSecond Kafka kafka.broker.messagesInPerSecond broker.messagesInPerSecond Kafka kafka.broker.net.bytesRejectedPerSecond net.bytesRejectedPerSecond Kafka kafka.broker.replication.isrExpandsPerSecond replication.isrExpandsPerSecond Kafka kafka.broker.replication.isrShrinksPerSecond replication.isrShrinksPerSecond Kafka kafka.broker.replication.leaderElectionPerSecond replication.leaderElectionPerSecond Kafka kafka.broker.replication.uncleanLeaderElectionPerSecond replication.uncleanLeaderElectionPerSecond Kafka kafka.broker.replication.unreplicatedPartitions replication.unreplicatedPartitions Kafka kafka.broker.request.avgTimeFetch request.avgTimeFetch Kafka kafka.broker.request.avgTimeMetadata request.avgTimeMetadata Kafka kafka.broker.request.avgTimeMetadata99Percentile request.avgTimeMetadata99Percentile Kafka kafka.broker.request.avgTimeOffset request.avgTimeOffset Kafka kafka.broker.request.avgTimeOffset99Percentile request.avgTimeOffset99Percentile Kafka kafka.broker.request.avgTimeProduceRequest request.avgTimeProduceRequest Kafka kafka.broker.request.avgTimeUpdateMetadata request.avgTimeUpdateMetadata Kafka kafka.broker.request.avgTimeUpdateMetadata99Percentile request.avgTimeUpdateMetadata99Percentile Kafka kafka.broker.request.clientFetchesFailedPerSecond request.clientFetchesFailedPerSecond Kafka kafka.broker.request.fetchConsumerRequestsPerSecond request.fetchConsumerRequestsPerSecond Kafka kafka.broker.request.fetchFollowerRequestsPerSecond request.fetchFollowerRequestsPerSecond Kafka kafka.broker.request.fetchTime99Percentile request.fetchTime99Percentile Kafka kafka.broker.request.handlerIdle request.handlerIdle Kafka kafka.broker.request.listGroupsRequestsPerSecond request.listGroupsRequestsPerSecond Kafka kafka.broker.request.metadataRequestsPerSecond request.metadataRequestsPerSecond Kafka kafka.broker.request.offsetCommitRequestsPerSecond request.offsetCommitRequestsPerSecond Kafka kafka.broker.request.produceRequestsFailedPerSecond request.produceRequestsFailedPerSecond Kafka kafka.broker.request.produceRequestsPerSecond request.produceRequestsPerSecond Kafka kafka.broker.request.produceTime99Percentile request.produceTime99Percentile Kafka kafka.broker.topic.diskSize topic.diskSize Kafka kafka.topic.bytesInPerSec topic.BytesInPerSec Kafka kafka.topic.bytesOutPerSec topic.BytesOutPerSec Kafka kafka.topic.messagesInPerSec topic.MessagesInPerSec Kafka kafka.topic.partitionsWithNonPreferredLeader topic.partitionsWithNonPreferredLeader Kafka kafka.topic.respondsToMetadataRequests topic.respondsToMetadataRequests Kafka kafka.topic.retentionBytesOrTime topic.retentionBytesOrTime Kafka kafka.topic.underReplicatedPartitions topic.underReplicatedPartitions Kafka kafka.producer.ageMetadataUsedInMilliseconds producer.ageMetadataUsedInMilliseconds Kafka kafka.producer.availableBufferInBytes producer.availableBufferInBytes Kafka kafka.producer.avgBytesSentPerRequestInBytes producer.avgBytesSentPerRequestInBytes Kafka kafka.producer.avgCompressionRateRecordBatches producer.avgCompressionRateRecordBatches Kafka kafka.producer.avgRecordAccumulatorsInMilliseconds producer.avgRecordAccumulatorsInMilliseconds Kafka kafka.producer.avgRecordSizeInBytes producer.avgRecordSizeInBytes Kafka kafka.producer.avgRecordsSentPerSecond producer.avgRecordsSentPerSecond Kafka kafka.producer.avgRecordsSentPerTopicPerSecond producer.avgRecordsSentPerTopicPerSecond Kafka kafka.producer.avgRequestLatency producer.avgRequestLatencyPerSecond Kafka kafka.producer.avgThrottleTime producer.avgThrottleTime Kafka kafka.producer.bufferMemoryAvailableInBytes producer.bufferMemoryAvailableInBytes Kafka kafka.producer.bufferpoolWaitTime producer.bufferpoolWaitTime Kafka kafka.producer.bytesOutPerSecond producer.bytesOutPerSecond Kafka kafka.producer.compressionRateRecordBatches producer.compressionRateRecordBatches Kafka kafka.producer.ioWaitTime producer.ioWaitTime Kafka kafka.producer.maxBytesSentPerRequestInBytes producer.maxBytesSentPerRequestInBytes Kafka kafka.producer.maxRecordSizeInBytes producer.maxRecordSizeInBytes Kafka kafka.producer.maxRequestLatencyInMilliseconds producer.maxRequestLatencyInMilliseconds Kafka kafka.producer.maxThrottleTime producer.maxThrottleTime Kafka kafka.producer.requestPerSecond producer.requestPerSecond Kafka kafka.producer.requestsWaitingResponse producer.requestsWaitingResponse Kafka kafka.producer.responsePerSecond producer.responsePerSecond Kafka kafka.producer.threadsWaiting producer.threadsWaiting Kafka kafka.consumer.avgFetchSizeInBytes consumer.avgFetchSizeInBytes Kafka kafka.consumer.avgRecordConsumedPerTopic consumer.avgRecordConsumedPerTopic Kafka kafka.consumer.avgRecordConsumedPerTopicPerSecond consumer.avgRecordConsumedPerTopicPerSecond Kafka kafka.consumer.bytesInPerSecond consumer.bytesInPerSecond Kafka kafka.consumer.fetchPerSecond consumer.fetchPerSecond Kafka kafka.consumer.hwm consumer.hwm Kafka kafka.consumer.lag consumer.lag Kafka kafka.consumer.maxFetchSizeInBytes consumer.maxFetchSizeInBytes Kafka kafka.consumer.maxLag consumer.maxLag Kafka kafka.consumer.messageConsumptionPerSecond consumer.messageConsumptionPerSecond Kafka kafka.consumer.offset consumer.offset Kafka kafka.consumer.totalLag consumer.totalLag Kafka kafka.consumerGroup.maxLag consumerGroup.maxLag Kafka kafka.consumerGroup.totalLag consumerGroup.totalLag Kubernetes k8s.apiserver.goGoroutines goGoroutines Kubernetes k8s.apiserver.goThreads goThreads Kubernetes k8s.apiserver.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.apiserver.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.controllermanager.goGoroutines goGoroutines Kubernetes k8s.controllermanager.goThreads goThreads Kubernetes k8s.controllermanager.leaderElectionMasterStatus leaderElectionMasterStatus Kubernetes k8s.controllermanager.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.controllermanager.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.etcd.goGoroutines goGoroutines Kubernetes k8s.etcd.goThreads goThreads Kubernetes k8s.etcd.mvccDbTotalSizeInBytes etcdMvccDbTotalSizeInBytes Kubernetes k8s.etcd.networkClientGrpcReceivedBytesRate etcdNetworkClientGrpcReceivedBytesRate Kubernetes k8s.etcd.networkClientGrpcSentBytesRate etcdNetworkClientGrpcSentBytesRate Kubernetes k8s.etcd.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.etcd.process.maxFds processMaxFds Kubernetes k8s.etcd.process.openFds processOpenFds Kubernetes k8s.etcd.process.processFdsUtilization processFdsUtilization Kubernetes k8s.etcd.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.etcd.serverHasLeader etcdServerHasLeader Kubernetes k8s.etcd.serverLeaderChangesSeenDelta etcdServerLeaderChangesSeenDelta Kubernetes k8s.etcd.serverProposalsAppliedDelta etcdServerProposalsAppliedDelta Kubernetes k8s.etcd.serverProposalsAppliedRate etcdServerProposalsAppliedRate Kubernetes k8s.etcd.serverProposalsCommittedDelta etcdServerProposalsCommittedDelta Kubernetes k8s.etcd.serverProposalsCommittedRate etcdServerProposalsCommittedRate Kubernetes k8s.etcd.serverProposalsFailedDelta etcdServerProposalsFailedDelta Kubernetes k8s.etcd.serverProposalsFailedRate etcdServerProposalsFailedRate Kubernetes k8s.etcd.serverProposalsPending etcdServerProposalsPending Kubernetes k8s.scheduler.goGoroutines goGoroutines Kubernetes k8s.scheduler.goThreads goThreads Kubernetes k8s.scheduler.leaderElectionMasterStatus leaderElectionMasterStatus Kubernetes k8s.scheduler.podPreemptionVictims schedulerPodPreemptionVictims Kubernetes k8s.scheduler.preemptionAttemptsDelta schedulerPreemptionAttemptsDelta Kubernetes k8s.scheduler.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.scheduler.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.container.cpuCfsPeriodsDelta containerCpuCfsPeriodsDelta Kubernetes k8s.container.cpuCfsPeriodsTotal containerCpuCfsPeriodsTotal Kubernetes k8s.container.cpuCfsThrottledPeriodsDelta containerCpuCfsThrottledPeriodsDelta Kubernetes k8s.container.cpuCfsThrottledPeriodsTotal containerCpuCfsThrottledPeriodsTotal Kubernetes k8s.container.cpuCfsThrottledSecondsDelta containerCpuCfsThrottledSecondsDelta Kubernetes k8s.container.cpuCfsThrottledSecondsTotal containerCpuCfsThrottledSecondsTotal Kubernetes k8s.container.cpuCoresUtilization cpuCoresUtilization Kubernetes k8s.container.cpuLimitCores cpuLimitCores Kubernetes k8s.container.cpuRequestedCores cpuRequestedCores Kubernetes k8s.container.cpuUsedCores cpuUsedCores Kubernetes k8s.container.fsAvailableBytes fsAvailableBytes Kubernetes k8s.container.fsCapacityBytes fsCapacityBytes Kubernetes k8s.container.fsInodes fsInodes Kubernetes k8s.container.fsInodesFree fsInodesFree Kubernetes k8s.container.fsInodesUsed fsInodesUsed Kubernetes k8s.container.fsUsedBytes fsUsedBytes Kubernetes k8s.container.fsUsedPercent fsUsedPercent Kubernetes k8s.container.isReady isReady Kubernetes k8s.container.memoryLimitBytes memoryLimitBytes Kubernetes k8s.container.memoryMappedFileBytes containerMemoryMappedFileBytes Kubernetes k8s.container.memoryRequestedBytes memoryRequestedBytes Kubernetes k8s.container.memoryUsedBytes memoryUsedBytes Kubernetes k8s.container.memoryUtilization memoryUtilization Kubernetes k8s.container.memoryWorkingSetBytes memoryWorkingSetBytes Kubernetes k8s.container.requestedCpuCoresUtilization requestedCpuCoresUtilization Kubernetes k8s.container.requestedMemoryUtilization requestedMemoryUtilization Kubernetes k8s.container.restartCount restartCount Kubernetes k8s.daemonset.createdAt createdAt Kubernetes k8s.daemonset.metadataGeneration metadataGeneration Kubernetes k8s.daemonset.podsAvailable podsAvailable Kubernetes k8s.daemonset.podsDesired podsDesired Kubernetes k8s.daemonset.podsMisscheduled podsMisscheduled Kubernetes k8s.daemonset.podsReady podsReady Kubernetes k8s.daemonset.podsScheduled podsScheduled Kubernetes k8s.daemonset.podsUnavailable podsUnavailable Kubernetes k8s.daemonset.podsUpdatedScheduled podsUpdatedScheduled Kubernetes k8s.deployment.createdAt createdAt Kubernetes k8s.deployment.podsAvailable podsAvailable Kubernetes k8s.deployment.podsDesired podsDesired Kubernetes k8s.deployment.podsMaxUnavailable podsMaxUnavailable Kubernetes k8s.deployment.podsTotal podsTotal Kubernetes k8s.deployment.podsUnavailable podsUnavailable Kubernetes k8s.deployment.podsUpdated podsUpdated Kubernetes k8s.endpoint.addressAvailable addressAvailable Kubernetes k8s.endpoint.addressNotReady addressNotReady Kubernetes k8s.endpoint.createdAt createdAt Kubernetes k8s.namespace.createdAt createdAt Kubernetes k8s.node.allocatableAttachableVolumes* allocatableAttachableVolumes* Kubernetes k8s.node.allocatableCpuCores allocatableCpuCores Kubernetes k8s.node.allocatableCpuCoresUtilization allocatableCpuCoresUtilization Kubernetes k8s.node.allocatableEphemeralStorageBytes allocatableEphemeralStorageBytes Kubernetes k8s.node.allocatableHugepages* allocatableHugepages* Kubernetes k8s.node.allocatableMemoryBytes allocatableMemoryBytes Kubernetes k8s.node.allocatableMemoryUtilization allocatableMemoryUtilization Kubernetes k8s.node.allocatablePods allocatablePods Kubernetes k8s.node.capacityAttachableVolumes* capacityAttachableVolumes* Kubernetes k8s.node.capacityCpuCores capacityCpuCores Kubernetes k8s.node.capacityEphemeralStorageBytes capacityEphemeralStorageBytes Kubernetes k8s.node.capacityHugepages* capacityHugepages* Kubernetes k8s.node.capacityMemoryBytes capacityMemoryBytes Kubernetes k8s.node.capacityPods capacityPods Kubernetes k8s.node.cpuUsedCoreMilliseconds cpuUsedCoreMilliseconds Kubernetes k8s.node.cpuUsedCores cpuUsedCores Kubernetes k8s.node.fsAvailableBytes fsAvailableBytes Kubernetes k8s.node.fsCapacityBytes fsCapacityBytes Kubernetes k8s.node.fsCapacityUtilization fsCapacityUtilization Kubernetes k8s.node.fsInodes fsInodes Kubernetes k8s.node.fsInodesFree fsInodesFree Kubernetes k8s.node.fsInodesUsed fsInodesUsed Kubernetes k8s.node.fsUsedBytes fsUsedBytes Kubernetes k8s.node.memoryAvailableBytes memoryAvailableBytes Kubernetes k8s.node.memoryMajorPageFaultsPerSecond memoryMajorPageFaultsPerSecond Kubernetes k8s.node.memoryPageFaults memoryPageFaults Kubernetes k8s.node.memoryRssBytes memoryRssBytes Kubernetes k8s.node.memoryUsedBytes memoryUsedBytes Kubernetes k8s.node.memoryWorkingSetBytes memoryWorkingSetBytes Kubernetes k8s.node.netErrorsPerSecond net.errorsPerSecond Kubernetes k8s.node.netRxBytesPerSecond net.rxBytesPerSecond Kubernetes k8s.node.netTxBytesPerSecond net.txBytesPerSecond Kubernetes k8s.node.runtimeAvailableBytes runtimeAvailableBytes Kubernetes k8s.node.runtimeCapacityBytes runtimeCapacityBytes Kubernetes k8s.node.runtimeInodes runtimeInodes Kubernetes k8s.node.runtimeInodesFree runtimeInodesFree Kubernetes k8s.node.runtimeInodesUsed runtimeInodesUsed Kubernetes k8s.node.runtimeUsedBytes runtimeUsedBytes Kubernetes k8s.pod.createdAt createdAt Kubernetes k8s.pod.isReady isReady Kubernetes k8s.pod.isScheduled isScheduled Kubernetes k8s.pod.netErrorsPerSecond net.errorsPerSecond Kubernetes k8s.pod.netRxBytesPerSecond net.rxBytesPerSecond Kubernetes k8s.pod.netTxBytesPerSecond net.txBytesPerSecond Kubernetes k8s.pod.startTime startTime Kubernetes k8s.replicaset.createdAt createdAt Kubernetes k8s.replicaset.observedGeneration observedGeneration Kubernetes k8s.replicaset.podsDesired podsDesired Kubernetes k8s.replicaset.podsFullyLabeled podsFullyLabeled Kubernetes k8s.replicaset.podsMissing podsMissing Kubernetes k8s.replicaset.podsReady podsReady Kubernetes k8s.replicaset.podsTotal podsTotal Kubernetes k8s.service.createdAt createdAt Kubernetes k8s.statefulset.createdAt createdAt Kubernetes k8s.statefulset.currentRevision currentRevision Kubernetes k8s.statefulset.metadataGeneration metadataGeneration Kubernetes k8s.statefulset.observedGeneration observedGeneration Kubernetes k8s.statefulset.podsCurrent podsCurrent Kubernetes k8s.statefulset.podsDesired podsDesired Kubernetes k8s.statefulset.podsReady podsReady Kubernetes k8s.statefulset.podsTotal podsTotal Kubernetes k8s.statefulset.podsUpdated podsUpdated Kubernetes k8s.statefulset.updateRevision updateRevision Kubernetes k8s.volume.fsAvailableBytes fsAvailableBytes Kubernetes k8s.volume.fsCapacityBytes fsCapacityBytes Kubernetes k8s.volume.fsInodes fsInodes Kubernetes k8s.volume.fsInodesFree fsInodesFree Kubernetes k8s.volume.fsInodesUsed fsInodesUsed Kubernetes k8s.volume.fsUsedBytes fsUsedBytes Kubernetes k8s.volume.fsUsedPercent fsUsedPercent Memcached memcached.server.activeSlabs activeSlabs Memcached memcached.server.avgItemSizeInBytes avgItemSizeInBytes Memcached memcached.server.bytesReadServerPerSecond bytesReadServerPerSecond Memcached memcached.server.bytesUsedServerInBytes bytesUsedServerInBytes Memcached memcached.server.bytesWrittenServerPerSecond bytesWrittenServerPerSecond Memcached memcached.server.casHitRatePerSecond casHitRatePerSecond Memcached memcached.server.casMissRatePerSecond casMissRatePerSecond Memcached memcached.server.casWrongRatePerSecond casWrongRatePerSecond Memcached memcached.server.cmdFlushRatePerSecond cmdFlushRatePerSecond Memcached memcached.server.cmdGetRatePerSecond cmdGetRatePerSecond Memcached memcached.server.cmdSetRatePerSecond cmdSetRatePerSecond Memcached memcached.server.connectionRateServerPerSecond connectionRateServerPerSecond Memcached memcached.server.connectionStructuresAllocated connectionStructuresAllocated Memcached memcached.server.currentItemsStoredServer currentItemsStoredServer Memcached memcached.server.deleteCmdNoneRemovedPerSecond deleteCmdNoneRemovedPerSecond Memcached memcached.server.deleteCmdRemovedPerSecond deleteCmdRemovedPerSecond Memcached memcached.server.evictionsPerSecond evictionsPerSecond Memcached memcached.server.getHitPercent getHitPercent Memcached memcached.server.getHitPerSecond getHitPerSecond Memcached memcached.server.getMissPerSecond getMissPerSecond Memcached memcached.server.itemsStoredPerSecond itemsStoredPerSecond Memcached memcached.server.limitBytesStorage limitBytesStorage Memcached memcached.server.limitMaxBytes limitMaxBytes Memcached memcached.server.maxConnectionLimitPerSecond serverMaxConnectionLimitPerSecond Memcached memcached.server.memAllocatedSlabsInBytes memAllocatedSlabsInBytes Memcached memcached.server.openConnectionsServer openConnectionsServer Memcached memcached.server.pointerSize pointerSize Memcached memcached.server.rusageSystem usageRate Memcached memcached.server.rusageUser executionTime Memcached memcached.server.storingItemsPercentMemory storingItemsPercentMemory Memcached memcached.server.threads threads Memcached memcached.server.uptimeInMilliseconds uptimeInMilliseconds Memcached memcached.slab.activeItemsBumpedPerSecond activeItemsBumpedPerSecond Memcached memcached.slab.casBadValPerSecond casBadValPerSecond Memcached memcached.slab.casModifiedSlabPerSecond casModifiedSlabPerSecond Memcached memcached.slab.chunkSizeInBytes chunkSizeInBytes Memcached memcached.slab.chunksPerPage chunksPerPage Memcached memcached.slab.cmdSetRateSlabPerSecond cmdSetRateSlabPerSecond Memcached memcached.slab.decrsModifySlabPerSecond decrsModifySlabPerSecond Memcached memcached.slab.deleteRateSlabPerSecond deleteRateSlabPerSecond Memcached memcached.slab.entriesReclaimedPerSecond entriesReclaimedPerSecond Memcached memcached.slab.evictionsBeforeExpirationPerSecond evictionsBeforeExpirationPerSecond Memcached memcached.slab.evictionsBeforeExplicitExpirationPerSecond evictionsBeforeExplicitExpirationPerSecond Memcached memcached.slab.expiredItemsReclaimedPerSecond expiredItemsReclaimedPerSecond Memcached memcached.slab.freedChunks freedChunks Memcached memcached.slab.freedChunksEnd freedChunksEnd Memcached memcached.slab.getHitRateSlabPerSecond getHitRateSlabPerSecond Memcached memcached.slab.incrsModifySlabPerSecond incrsModifySlabPerSecond Memcached memcached.slab.itemsCold itemsCold Memcached memcached.slab.itemsColdPerSecond itemsColdPerSecond Memcached memcached.slab.itemsDirectReclaimedPerSecond itemsDirectReclaimedPerSecond Memcached memcached.slab.itemsFreedCrawlerPerSecond itemsFreedCrawlerPerSecond Memcached memcached.slab.itemsHot itemsHot Memcached memcached.slab.itemsOldestInMilliseconds itemsOldestInMilliseconds Memcached memcached.slab.itemsRefcountLockedPerSecond itemsRefcountLockedPerSecond Memcached memcached.slab.itemsSlabClass itemsSlabClass Memcached memcached.slab.itemsTimeSinceEvictionInMilliseconds itemsTimeSinceEvictionInMilliseconds Memcached memcached.slab.itemsWarm itemsWarm Memcached memcached.slab.itemsWarmPerSecond itemsWarmPerSecond Memcached memcached.slab.memRequestedSlabInBytesPerSecond memRequestedSlabInBytesPerSecond Memcached memcached.slab.outOfMemoryPerSecond outOfMemoryPerSecond Memcached memcached.slab.selfHealedSlabPerSecond selfHealedSlabPerSecond Memcached memcached.slab.totalChunksSlab totalChunksSlab Memcached memcached.slab.totalPagesSlab totalPagesSlab Memcached memcached.slab.touchHitSlabPerSecond touchHitSlabPerSecond Memcached memcached.slab.usedChunksItems usedChunksItems Memcached memcached.slab.usedChunksPerSecond usedChunksPerSecond Memcached memcached.slab.validItemsEvictedPerSecond validItemsEvictedPerSecond MongoDB mongo.index.accesses collection.indexAccesses MongoDB mongo.index.sizeInBytes collection.indexSizeInBytes MongoDB mongo.collection.avgObjSizeInBytes collection.avgObjSizeInBytes MongoDB mongo.collection.capped collection.capped MongoDB mongo.collection.count collection.count MongoDB mongo.collection.max collection.max MongoDB mongo.collection.maxSizeInBytes collection.maxSizeInBytes MongoDB mongo.collection.nindexes collection.nindexes MongoDB mongo.collection.sizeInBytes collection.sizeInBytes MongoDB mongo.collection.storageSizeInBytes collection.storageSizeInBytes MongoDB mongo.configServer.asserts.messagesPerSecond asserts.messagesPerSecond MongoDB mongo.configServer.asserts.regularPerSecond asserts.regularPerSecond MongoDB mongo.configServer.asserts.rolloversPerSecond asserts.rolloversPerSecond MongoDB mongo.configServer.asserts.userPerSecond asserts.userPerSecond MongoDB mongo.configServer.asserts.warningPerSecond asserts.warningPerSecond MongoDB mongo.configServer.commands.countFailedPerSecond commands.countFailedPerSecond MongoDB mongo.configServer.commands.countPerSecond commands.countPerSecond MongoDB mongo.configServer.commands.createIndexesFailedPerSecond commands.createIndexesFailedPerSecond MongoDB mongo.configServer.commands.createIndexesPerSecond commands.createIndexesPerSecond MongoDB mongo.configServer.commands.deleteFailedPerSecond commands.deleteFailedPerSecond MongoDB mongo.configServer.commands.deletePerSecond commands.deletePerSecond MongoDB mongo.configServer.commands.evalFailedPerSecond commands.evalFailedPerSecond MongoDB mongo.configServer.commands.evalPerSecond commands.evalPerSecond MongoDB mongo.configServer.commands.findAndModifyFailedPerSecond commands.findAndModifyFailedPerSecond MongoDB mongo.configServer.commands.findAndModifyPerSecond commands.findAndModifyPerSecond MongoDB mongo.configServer.commands.insertFailedPerSecond commands.insertFailedPerSecond MongoDB mongo.configServer.commands.insertPerSecond commands.insertPerSecond MongoDB mongo.configServer.commands.updateFailedPerSecond commands.updateFailedPerSecond MongoDB mongo.configServer.commands.updatePerSecond commands.updatePerSecond MongoDB mongo.configServer.connections.available connections.available MongoDB mongo.configServer.connections.current connections.current MongoDB mongo.configServer.connections.totalCreated connections.totalCreated MongoDB mongo.configServer.cursor.openNoTimeout cursor.openNoTimeout MongoDB mongo.configServer.cursor.openPinned cursor.openPinned MongoDB mongo.configServer.cursor.openTotal cursor.openTotal MongoDB mongo.configServer.cursor.timedOutPerSecond cursor.timedOutPerSecond MongoDB mongo.configServer.document.deletedPerSecond document.deletedPerSecond MongoDB mongo.configServer.document.insertedPerSecond document.insertedPerSecond MongoDB mongo.configServer.document.returnedPerSecond document.returnedPerSecond MongoDB mongo.configServer.document.updatedPerSecond document.updatedPerSecond MongoDB mongo.configServer.dur.commits dur.commits MongoDB mongo.configServer.dur.commitsInWriteLock dur.commitsInWriteLock MongoDB mongo.configServer.dur.compression dur.compression MongoDB mongo.configServer.dur.earlyCommits dur.earlyCommits MongoDB mongo.configServer.dur.preparingInMilliseconds dur.preparingInMilliseconds MongoDB mongo.configServer.dur.remappingInMilliseconds dur.remappingInMilliseconds MongoDB mongo.configServer.dur.timeCollectedCommitsInMilliseconds dur.timeCollectedCommitsInMilliseconds MongoDB mongo.configServer.dur.writingDataFilesInMilliseconds dur.writingDataFilesInMilliseconds MongoDB mongo.configServer.dur.writingJournalInMilliseconds dur.writingJournalInMilliseconds MongoDB mongo.configServer.flush.averageInMilliseconds flush.averageInMilliseconds MongoDB mongo.configServer.flush.flushesDisk flush.flushesDisk MongoDB mongo.configServer.flush.lastInMilliseconds flush.lastInMilliseconds MongoDB mongo.configServer.flush.totalInMilliseconds flush.totalInMilliseconds MongoDB mongo.configServer.getlasterror.wtimeMillisPerSecond getlasterror.wtimeMillisPerSecond MongoDB mongo.configServer.getlasterror.wtimeoutsPerSecond getlasterror.wtimeoutsPerSecond MongoDB mongo.configServer.globallock.activeClientsReaders globallock.activeClientsReaders MongoDB mongo.configServer.globallock.activeClientsTotal globallock.activeClientsTotal MongoDB mongo.configServer.globallock.activeClientsWriters globallock.activeClientsWriters MongoDB mongo.configServer.globallock.currentQueueReaders globallock.currentQueueReaders MongoDB mongo.configServer.globallock.currentQueueTotal globallock.currentQueueTotal MongoDB mongo.configServer.globallock.currentQueueWriters globallock.currentQueueWriters MongoDB mongo.configServer.globallock.totalTime globallock.totaltime MongoDB mongo.configServer.locks.collectionAcquireExclusive locks.collectionAcquireExclusive MongoDB mongo.configServer.locks.collectionAcquireIntentExclusive locks.collectionAcquireIntentExclusive MongoDB mongo.configServer.locks.collectionAcquireIntentShared locks.collectionAcquireIntentShared MongoDB mongo.configServer.locks.collectionAcquireWaitCountExclusive locks.collectionAcquireWaitCountExclusive MongoDB mongo.configServer.locks.collectionTimeAcquiringMicrosExclusive locks.collectionTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.databaseAcquireExclusive locks.databaseAcquireExclusive MongoDB mongo.configServer.locks.databaseAcquireIntentExclusive locks.databaseAcquireIntentExclusive MongoDB mongo.configServer.locks.databaseAcquireIntentShared locks.databaseAcquireIntentShared MongoDB mongo.configServer.locks.databaseAcquireShared locks.databaseAcquireShared MongoDB mongo.configServer.locks.databaseAcquireWaitExclusive locks.databaseAcquireWaitExclusive MongoDB mongo.configServer.locks.databaseAcquireWaitIntentExclusive locks.databaseAcquireWaitIntentExclusive MongoDB mongo.configServer.locks.databaseAcquireWaitIntentShared locks.databaseAcquireWaitIntentShared MongoDB mongo.configServer.locks.databaseAcquireWaitShared locks.databaseAcquireWaitShared MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosExclusive locks.databaseTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosIntentExclusive locks.databaseTimeAcquiringMicrosIntentExclusive MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosIntentShared locks.databaseTimeAcquiringMicrosIntentShared MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosShared locks.databaseTimeAcquiringMicrosShared MongoDB mongo.configServer.locks.globalAcquireExclusive locks.globalAcquireExclusive MongoDB mongo.configServer.locks.globalAcquireIntentExclusive locks.globalAcquireIntentExclusive MongoDB mongo.configServer.locks.globalAcquireIntentShared locks.globalAcquireIntentShared MongoDB mongo.configServer.locks.globalAcquireShared locks.globalAcquireShared MongoDB mongo.configServer.locks.globalAcquireWaitExclusive locks.globalAcquireWaitExclusive MongoDB mongo.configServer.locks.globalAcquireWaitIntentExclusive locks.globalAcquireWaitIntentExclusive MongoDB mongo.configServer.locks.globalAcquireWaitIntentShared locks.globalAcquireWaitIntentShared MongoDB mongo.configServer.locks.globalAcquireWaitShared locks.globalAcquireWaitShared MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosExclusive locks.globalTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosIntentExclusive locks.globalTimeAcquiringMicrosIntentExclusive MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosIntentShared locks.globalTimeAcquiringMicrosIntentShared MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosShared locks.globalTimeAcquiringMicrosShared MongoDB mongo.configServer.locks.metadataAcquireExclusive locks.metadataAcquireExclusive MongoDB mongo.configServer.locks.oplogAcquireExclusive locks.oplogAcquireExclusive MongoDB mongo.configServer.locks.oplogAcquireIntentExclusive locks.oplogAcquireIntentExclusive MongoDB mongo.configServer.locks.oplogAcquireIntentShared locks.oplogAcquireIntentShared MongoDB mongo",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 358.85834,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": "New Relic Integrations Metrics The following table contains the metrics we collect for our <em>infrastructure</em> integrations. Integration Dimensional Metric Name (new) Sample Metric Name (previous) Agent host.cpuIdlePercent cpuIdlePercent Agent host.cpuIoWaitPercent cpuIOWaitPercent Agent host.cpuPercent"
      },
      "id": "603e8a8a64441f69a34e8841"
    },
    {
      "sections": [
        "Default infrastructure monitoring data",
        "Important",
        "Infrastructure events",
        "Supported Linux storage systems",
        "Supported Windows storage systems",
        "Query infrastructure data",
        "Manage data",
        "Add custom attributes",
        "Common Amazon EC2 attributes",
        "awsRegion",
        "awsAvailabilityZone",
        "ec2InstanceType",
        "ec2InstanceId",
        "ec2AmiId",
        "ec2SubnetId",
        "ec2VpcId",
        "Other Amazon EC2 attributes"
      ],
      "title": "Default infrastructure monitoring data ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "01647189a48892103f4dc6abe07ce29d5fc13f0d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/default-infrastructure-monitoring-data/",
      "published_at": "2021-06-14T21:14:34Z",
      "updated_at": "2021-03-30T08:36:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of April 12, 2021, we are upgrading Insights to an improved web and mobile experience! All of your Insights URLs will be redirected automatically to the corresponding dashboards in New Relic One. For more details about this migration and how you can easily plan for this transition, see our Explorers Hub post. New Relic's infrastructure monitoring agent collects and displays data using six primary events, each with associated attributes that represent assorted metrics and metadata. Understanding infrastructure data can help you: Better understand our infrastructure monitoring UI. Manage your infrastructure data. Create better host filter sets. Run better queries of your data. Set up better monitoring solutions using custom attributes. Infrastructure events The following are events reported by default by the infrastructure agent and some infrastructure integrations. The attributes attached to these events are the metadata and metrics used to create our infrastructure UI visualizations. You can also create custom queries and charts of this data. If you're using integrations, see that integration's doc for more on reported data. For common AWS attributes, see AWS data. Select an event name in the following table to see its attributes. Event Description SystemSample SystemSample contains data describing the current overall state of the entire server, including CPU, memory, disk, and network. We take a snapshot of this data every 5 seconds and package it into a SystemSample event, which is then sent to New Relic. This data appears in the Hosts UI page. ProcessSample ProcessSample gathers detailed resource usage information from programs running on a single system. We take a snapshot of this data every 20 seconds for every active process and package it into a ProcessSample event, which is then sent to New Relic. This data appears on the Processes UI page. Important Process metrics are not sent to New Relic by default for accounts created after July 20, 2020. Enable process metrics to get this data into the Infrastructure monitoring UI. StorageSample StorageSample represents a single storage device associated with a server. Each sample gathers descriptive information about the device, the type of file system it uses, and its current usage and capacity. We take a snapshot of this data every 20 seconds for each mounted file system and package it into a StorageSample event, which is then sent to New Relic. This data appears on the Storage UI page. Important If your server uses disks with file systems other than the supported file systems in the following table, StorageSample events will not be generated for those disks. Supported Linux storage systems Supported Linux storage file systems: xfs vxfs btrfs ext ext2 ext3 ext4 hfs Supported Windows storage systems Supported Windows storage file systems: NTFS ReFS (version 1.0.976 and higher) NetworkSample NetworkSample captures the descriptive and state information for each network device associated with a server. It includes the device's interface and address information, as well as current usage data. We take a snapshot of this data every 10 seconds for each attached network interface and package it into a NetworkSample event, which is then sent to New Relic. This data appears on the Network UI page. ContainerSample ContainerSample collects the descriptive and state information for each Docker container. It includes the container's ID, name, image, image name, as well metrics about CPU, memory and networking. We take a snapshot of this data every 15 seconds for each container and package it into a ContainerSample event, which is then sent to New Relic. This data appears on the Containers UI page. For more information, see Docker monitoring. InfrastructureEvent InfrastructureEvent describes changes (deltas) that occur in a system's live state. When an inventory or system state is added, removed, or changed, New Relic will produce an InfrastructureEvent that logs that activity. This data appears on the Events UI page. To learn about infrastructure integration data, see the documentation for a specific integration. If an AWS integration is enabled, your infrastructure events may also have AWS attributes attached. Query infrastructure data You can query your infrastructure data to troubleshoot a problem or create a chart, or to understand what data is available. For example, to see what data is attached to ProcessSample, you would run this NRQL query: SELECT * FROM ProcessSample Copy You can also query infrastructure using dimensional metrics. Manage data For tips on managing data ingest and reporting, see Manage infrastructure data. Add custom attributes You can create custom attributes in the infrastructure agent's YAML file. Use this metadata to: Create infrastructure filter sets Populate the Group by menu Annotate your infrastructure data Common Amazon EC2 attributes If you connect your Amazon Elastic Compute Cloud (EC2) account to our infrastructure monitoring, we report data from your Amazon EC2 instances. Amazon EC2-related attributes are common attributes that can be used in any event. These attributes are drawn from the EC2 API. No CloudWatch information is collected. These attributes and their values are subject to change if Amazon changes the data they expose. awsRegion The region (determined by Amazon Web Services) where the AWS server exists. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. awsAvailabilityZone The availability zone (determined by Amazon Web Services) where the AWS server exists. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2InstanceType The Amazon Web Services instance type, displayed in AWS-specific codes. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2InstanceId The Amazon Web Services instance's unique identifying number for the server. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2AmiId The Amazon Machine Image (AMI) identification number of the image used by Amazon Web Services to bootstrap the Amazon EC2 instance. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2SubnetId The networking sub-net identifier on which the server is connected. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2VpcId The Virtual Private Cloud identifier (if any) for this server. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. Other Amazon EC2 attributes If Amazon Web Services changes the metadata they make available to New Relic, other attributes and values collected also may be available.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.37016,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Default <em>infrastructure</em> monitoring <em>data</em> ",
        "sections": "Default <em>infrastructure</em> monitoring <em>data</em>",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": ". <em>Manage</em> <em>your</em> <em>infrastructure</em> <em>data</em>. Create better host filter sets. Run better queries of <em>your</em> <em>data</em>. Set up better monitoring solutions using custom attributes. <em>Infrastructure</em> events The following are events reported by default by the <em>infrastructure</em> agent and some <em>infrastructure</em> integrations"
      },
      "id": "6043edcd28ccbcfa8a2c6086"
    },
    {
      "sections": [
        "Manage infrastructure data reporting"
      ],
      "title": "Manage infrastructure data reporting",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "7cd87ba8f7686e9233f4171021607d499bf6bc72",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/manage-infrastructure-data-reporting/",
      "published_at": "2021-06-14T21:15:46Z",
      "updated_at": "2021-03-16T07:33:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the infrastructure agent or on-host integrations that report data via the infrastructure agent, there are several ways to configure data reporting. Here are two common options for managing data reporting: Enable/disable process metrics Select specific attributes to report For other agent configuration options, see Configuration. For our infrastructure integrations, you can also change the frequency of data reporting: For on-host integrations: use a specific integration's interval configuration setting. For cloud integrations (AWS, Azure, Google Cloud): edit the polling frequency. For more about New Relic data management in general, see Manage data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.4204,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>infrastructure</em> <em>data</em> reporting",
        "sections": "<em>Manage</em> <em>infrastructure</em> <em>data</em> reporting",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": " configuration options, see Configuration. For our <em>infrastructure</em> integrations, you can also change the frequency of <em>data</em> reporting: For on-host integrations: use a specific integration&#x27;s interval configuration setting. For cloud integrations (AWS, Azure, Google Cloud): edit the polling frequency. For more about New Relic <em>data</em> management in general, see <em>Manage</em> <em>data</em>."
      },
      "id": "603e775a196a67f470a83de4"
    }
  ],
  "/docs/infrastructure/manage-your-data/data-instrumentation/default-infrastructure-monitoring-data": [
    {
      "sections": [
        "On-host integrations metrics",
        "New Relic Integrations Metrics"
      ],
      "title": "On-host integrations metrics",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "fe96c0c4950380504b1a33c3ad861bcb17507cba",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/host-integrations-metrics/",
      "published_at": "2021-06-15T01:04:56Z",
      "updated_at": "2021-06-15T01:04:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Integrations Metrics The following table contains the metrics we collect for our infrastructure integrations. Integration Dimensional Metric Name (new) Sample Metric Name (previous) Agent host.cpuIdlePercent cpuIdlePercent Agent host.cpuIoWaitPercent cpuIOWaitPercent Agent host.cpuPercent cpuPercent Agent host.cpuStealPercent cpuStealPercent Agent host.cpuSystemPercent cpuSystemPercent Agent host.cpuUserPercent cpuUserPercent Agent host.disk.avgQueueLen avgQueueLen Agent host.disk.avgReadQueueLen avgReadQueueLen Agent host.disk.avgWriteQueueLen avgWriteQueueLen Agent host.disk.currentQueueLen currentQueueLen Agent host.disk.freeBytes diskFreeBytes Agent host.disk.freePercent diskFreePercent Agent host.disk.inodesFree inodesFree Agent host.disk.inodesTotal inodesTotal Agent host.disk.inodesUsed inodesUsed Agent host.disk.inodesUsedPercent inodesUsedPercent Agent host.disk.readBytesPerSecond readBytesPerSecond Agent host.disk.readIoPerSecond readIoPerSecond Agent host.disk.readUtilizationPercent readUtilizationPercent Agent host.disk.readWriteBytesPerSecond readWriteBytesPerSecond Agent host.disk.totalBytes diskTotalBytes Agent host.disk.totalUtilizationPercent totalUtilizationPercent Agent host.disk.usedBytes diskUsedBytes Agent host.disk.usedPercent diskUsedPercent Agent host.disk.writeBytesPerSecond writeBytesPerSecond Agent host.disk.writeIoPerSecond writeIoPerSecond Agent host.disk.writeUtilizationPercent writeUtilizationPercent Agent host.diskFreeBytes diskFreeBytes Agent host.diskFreePercent diskFreePercent Agent host.diskReadsPerSecond diskReadsPerSecond Agent host.diskReadUtilizationPercent diskReadUtilizationPercent Agent host.diskTotalBytes diskTotalBytes Agent host.diskUsedBytes diskUsedBytes Agent host.diskUsedPercent diskUsedPercent Agent host.diskUtilizationPercent diskUtilizationPercent Agent host.diskWritesPerSecond diskWritesPerSecond Agent host.diskWriteUtilizationPercent diskWriteUtilizationPercent Agent host.loadAverageFifteenMinute loadAverageFifteenMinute Agent host.loadAverageFiveMinute loadAverageFiveMinute Agent host.loadAverageOneMinute loadAverageOneMinute Agent host.memoryFreeBytes memoryFreeBytes Agent host.memoryFreePercent memoryFreePercent Agent host.memoryTotalBytes memoryTotalBytes Agent host.memoryUsedBytes memoryUsedBytes Agent host.memoryUsedPercent memoryUsedPercent Agent host.net.receiveBytesPerSecond receiveBytesPerSecond Agent host.net.receiveDroppedPerSecond receiveDroppedPerSecond Agent host.net.receiveErrorsPerSecond receiveErrorsPerSecond Agent host.net.receivePacketsPerSecond receivePacketsPerSecond Agent host.net.transmitBytesPerSecond transmitBytesPerSecond Agent host.net.transmitDroppedPerSecond transmitDroppedPerSecond Agent host.net.transmitErrorsPerSecond transmitErrorsPerSecond Agent host.net.transmitPacketsPerSecond transmitPacketsPerSecond Agent host.process.cpuPercent cpuPercent Agent host.process.cpuSystemPercent cpuSystemPercent Agent host.process.cpuUserPercent cpuUserPercent Agent host.process.fileDescriptorCount fileDescriptorCount Agent host.process.ioReadBytesPerSecond ioReadBytesPerSecond Agent host.process.ioReadCountPerSecond ioReadCountPerSecond Agent host.process.ioTotalReadBytes ioTotalReadBytes Agent host.process.ioTotalReadCount ioTotalReadCount Agent host.process.ioTotalWriteBytes ioTotalWriteBytes Agent host.process.ioTotalWriteCount ioTotalWriteCount Agent host.process.ioWriteBytesPerSecond ioWriteBytesPerSecond Agent host.process.ioWriteCountPerSecond ioWriteCountPerSecond Agent host.process.memoryResidentSizeBytes memoryResidentSizeBytes Agent host.process.memoryVirtualSizeBytes memoryVirtualSizeBytes Agent host.process.threadCount threadCount Agent host.swapFreeBytes swapFreeBytes Agent host.swapTotalBytes swapTotalBytes Agent host.swapUsedBytes swapUsedBytes Apache apache.server.busyWorkers server.busyWorkers Apache apache.server.idleWorkers server.idleWorkers Apache apache.server.net.bytesPerSecond net.bytesPerSecond Apache apache.server.net.requestsPerSecond net.requestsPerSecond Apache apache.server.scoreboard.closingWorkers server.scoreboard.closingWorkers Apache apache.server.scoreboard.dnsLookupWorkers server.scoreboard.dnsLookupWorkers Apache apache.server.scoreboard.finishingWorkers server.scoreboard.finishingWorkers Apache apache.server.scoreboard.idleCleanupWorkers server.scoreboard.idleCleanupWorkers Apache apache.server.scoreboard.keepAliveWorkers server.scoreboard.keepAliveWorkers Apache apache.server.scoreboard.loggingWorkers server.scoreboard.loggingWorkers Apache apache.server.scoreboard.readingWorkers server.scoreboard.readingWorkers Apache apache.server.scoreboard.startingWorkers server.scoreboard.startingWorkers Apache apache.server.scoreboard.totalWorkers server.scoreboard.totalWorkers Apache apache.server.scoreboard.writingWorkers server.scoreboard.writingWorkers Cassandra cassandra.node.allMemtablesOffHeapSizeBytes db.allMemtablesOffHeapSizeBytes Cassandra cassandra.node.allMemtablesOnHeapSizeBytes db.allMemtablesOnHeapSizeBytes Cassandra cassandra.node.client.connectedNativeClients client.connectedNativeClients Cassandra cassandra.node.commitLogCompletedTasksPerSecond db.commitLogCompletedTasksPerSecond Cassandra cassandra.node.commitLogPendingTasks db.commitLogPendindTasks Cassandra cassandra.node.commitLogTotalSizeBytes db.commitLogTotalSizeBytes Cassandra cassandra.node.droppedBatchRemoveMessagesPerSecond db.droppedBatchRemoveMessagesPerSecond Cassandra cassandra.node.droppedBatchStoreMessagesPerSecond db.droppedBatchStoreMessagesPerSecond Cassandra cassandra.node.droppedCounterMutationMessagesPerSecond db.droppedCounterMutationMessagesPerSecond Cassandra cassandra.node.droppedHintMessagesPerSecond db.droppedHintMessagesPerSecond Cassandra cassandra.node.droppedMutationMessagesPerSecond db.droppedMutationMessagesPerSecond Cassandra cassandra.node.droppedPagedRangeMessagesPerSecond db.droppedPagedRangeMessagesPerSecond Cassandra cassandra.node.droppedRangeSliceMessagesPerSecond db.droppedRangeSliceMessagesPerSecond Cassandra cassandra.node.droppedReadMessagesPerSecond db.droppedReadMessagesPerSecond Cassandra cassandra.node.droppedReadRepairMessagesPerSecond db.droppedReadRepairMessagesPerSecond Cassandra cassandra.node.droppedRequestResponseMessagesPerSecond db.droppedRequestResponseMessagesPerSecond Cassandra cassandra.node.droppedTraceMessagesPerSecond db.droppedTraceMessagesPerSecond Cassandra cassandra.node.keyCacheCapacityBytes db.keyCacheCapacityBytes Cassandra cassandra.node.keyCacheHitRate db.keyCacheHitRate Cassandra cassandra.node.keyCacheHitsPerSecond db.keyCacheHitsPerSecond Cassandra cassandra.node.keyCacheRequestsPerSecond db.keyCacheRequestsPerSecond Cassandra cassandra.node.keyCacheSizeBytes db.keyCacheSizeBytes Cassandra cassandra.node.liveSsTableCount db.liveSSTableCount Cassandra cassandra.node.loadBytes db.loadBytes Cassandra cassandra.node.query.casReadRequestsPerSecond query.CASReadRequestsPerSecond Cassandra cassandra.node.query.casWriteRequestsPerSecond query.CASWriteRequestsPerSecond Cassandra cassandra.node.query.rangeSliceRequestsPerSecond query.rangeSliceRequestsPerSecond Cassandra cassandra.node.query.rangeSliceTimeoutsPerSecond query.rangeSliceTimeoutsPerSecond Cassandra cassandra.node.query.rangeSliceUnavailablesPerSecond query.rangeSliceUnavailablesPerSecond Cassandra cassandra.node.query.readLatency50ThPercentileMilliseconds query.readLatency50thPercentileMilliseconds Cassandra cassandra.node.query.readLatency75ThPercentileMilliseconds query.readLatency75thPercentileMilliseconds Cassandra cassandra.node.query.readLatency95ThPercentileMilliseconds query.readLatency95thPercentileMilliseconds Cassandra cassandra.node.query.readLatency98ThPercentileMilliseconds query.readLatency98thPercentileMilliseconds Cassandra cassandra.node.query.readLatency999ThPercentileMilliseconds query.readLatency999thPercentileMilliseconds Cassandra cassandra.node.query.readLatency99ThPercentileMilliseconds query.readLatency99thPercentileMilliseconds Cassandra cassandra.node.query.readRequestsPerSecond query.readRequestsPerSecond Cassandra cassandra.node.query.readTimeoutsPerSecond query.readTimeoutsPerSecond Cassandra cassandra.node.query.readUnavailablesPerSecond query.readUnavailablesPerSecond Cassandra cassandra.node.query.viewWriteRequestsPerSecond query.viewWriteRequestsPerSecond Cassandra cassandra.node.query.writeLatency50ThPercentileMilliseconds query.writeLatency50thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency75ThPercentileMilliseconds query.writeLatency75thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency95ThPercentileMilliseconds query.writeLatency95thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency98ThPercentileMilliseconds query.writeLatency98thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency999ThPercentileMilliseconds query.writeLatency999thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency99ThPercentileMilliseconds query.writeLatency99thPercentileMilliseconds Cassandra cassandra.node.query.writeRequestsPerSecond query.writeRequestsPerSecond Cassandra cassandra.node.query.writeTimeoutsPerSecond query.writeTimeoutsPerSecond Cassandra cassandra.node.query.writeUnavailablesPerSecond query.writeUnavailablesPerSecond Cassandra cassandra.node.rowCacheCapacityBytes db.rowCacheCapacityBytes Cassandra cassandra.node.rowCacheHitRate db.rowCacheHitRate Cassandra cassandra.node.rowCacheHitsPerSecond db.rowCacheHitsPerSecond Cassandra cassandra.node.rowCacheRequestsPerSecond db.rowCacheRequestsPerSecond Cassandra cassandra.node.rowCacheSizeBytes db.rowCacheSizeBytes Cassandra cassandra.node.storage.exceptionCount storage.exceptionCount Cassandra cassandra.node.threadPool.antiEntropyStage.activeTasks db.threadpool.internalAntiEntropyStageActiveTasks Cassandra cassandra.node.threadPool.antiEntropyStage.completedTasks db.threadpool.internalAntiEntropyStageCompletedTasks Cassandra cassandra.node.threadPool.antiEntropyStage.currentlyBlockedTasks db.threadpool.internalAntiEntropyStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.antiEntropyStage.pendingTasks db.threadpool.internalAntiEntropyStagePendingTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.activeTasks db.threadpool.internalCacheCleanupExecutorActiveTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.completedTasks db.threadpool.internalCacheCleanupExecutorCompletedTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.currentlyBlockedTasks db.threadpool.internalCacheCleanupExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.pendingTasks db.threadpool.internalCacheCleanupExecutorPendingTasks Cassandra cassandra.node.threadPool.compactionExecutor.activeTasks db.threadpool.internalCompactionExecutorActiveTasks Cassandra cassandra.node.threadPool.compactionExecutor.completedTasks db.threadpool.internalCompactionExecutorCompletedTasks Cassandra cassandra.node.threadPool.compactionExecutor.currentlyBlockedTasks db.threadpool.internalCompactionExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.compactionExecutor.pendingTasks db.threadpool.internalCompactionExecutorPendingTasks Cassandra cassandra.node.threadPool.counterMutationStage.activeTasks db.threadpool.requestCounterMutationStageActiveTasks Cassandra cassandra.node.threadPool.counterMutationStage.completedTasks db.threadpool.requestCounterMutationStageCompletedTasks Cassandra cassandra.node.threadPool.counterMutationStage.currentlyBlockedTasks db.threadpool.requestCounterMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.counterMutationStage.pendingTasks db.threadpool.requestCounterMutationStagePendingTasks Cassandra cassandra.node.threadPool.gossipStage.activeTasks db.threadpool.internalGossipStageActiveTasks Cassandra cassandra.node.threadPool.gossipStage.completedTasks db.threadpool.internalGossipStageCompletedTasks Cassandra cassandra.node.threadPool.gossipStage.currentlyBlockedTasks db.threadpool.internalGossipStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.gossipStage.pendingTasks db.threadpool.internalGossipStagePendingTasks Cassandra cassandra.node.threadPool.hintsDispatcher.activeTasks db.threadpool.internalHintsDispatcherActiveTasks Cassandra cassandra.node.threadPool.hintsDispatcher.completedTasks db.threadpool.internalHintsDispatcherCompletedTasks Cassandra cassandra.node.threadPool.hintsDispatcher.currentlyBlockedTasks db.threadpool.internalHintsDispatcherCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.hintsDispatcher.pendingTasks db.threadpool.internalHintsDispatcherPendingTasks Cassandra cassandra.node.threadPool.internalResponseStage.activeTasks db.threadpool.internalInternalResponseStageActiveTasks Cassandra cassandra.node.threadPool.internalResponseStage.completedTasks db.threadpool.internalInternalResponseStageCompletedTasks Cassandra cassandra.node.threadPool.internalResponseStage.pCurrentlyBlockedTasks db.threadpool.internalInternalResponseStagePCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.internalResponseStage.pendingTasks db.threadpool.internalInternalResponseStagePendingTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.activeTasks db.threadpool.internalMemtableFlushWriterActiveTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.completedTasks db.threadpool.internalMemtableFlushWriterCompletedTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.currentlyBlockedTasks db.threadpool.internalMemtableFlushWriterCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.pendingTasks db.threadpool.internalMemtableFlushWriterPendingTasks Cassandra cassandra.node.threadPool.memtablePostFlush.activeTasks db.threadpool.internalMemtablePostFlushActiveTasks Cassandra cassandra.node.threadPool.memtablePostFlush.completedTasks db.threadpool.internalMemtablePostFlushCompletedTasks Cassandra cassandra.node.threadPool.memtablePostFlush.currentlyBlockedTasks db.threadpool.internalMemtablePostFlushCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtablePostFlush.pendingTasks db.threadpool.internalMemtablePostFlushPendingTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.activeTasks db.threadpool.internalMemtableReclaimMemoryActiveTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.completedTasks db.threadpool.internalMemtableReclaimMemoryCompletedTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.currentlyBlockedTasks db.threadpool.internalMemtableReclaimMemoryCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.pendingTasks db.threadpool.internalMemtableReclaimMemoryPendingTasks Cassandra cassandra.node.threadPool.migrationStage.activeTasks db.threadpool.internalMigrationStageActiveTasks Cassandra cassandra.node.threadPool.migrationStage.completedTasks db.threadpool.internalMigrationStageCompletedTasks Cassandra cassandra.node.threadPool.migrationStage.currentlyBlockedTasks db.threadpool.internalMigrationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.migrationStage.pendingTasks db.threadpool.internalMigrationStagePendingTasks Cassandra cassandra.node.threadPool.miscStage.activeTasks db.threadpool.internalMiscStageActiveTasks Cassandra cassandra.node.threadPool.miscStage.completedTasks db.threadpool.internalMiscStageCompletedTasks Cassandra cassandra.node.threadPool.miscStage.currentlyBlockedTasks db.threadpool.internalMiscStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.miscStage.pendingTasks db.threadpool.internalMiscStagePendingTasks Cassandra cassandra.node.threadPool.mutationStage.activeTasks db.threadpool.requestMutationStageActiveTasks Cassandra cassandra.node.threadPool.mutationStage.completedTasks db.threadpool.requestMutationStageCompletedTasks Cassandra cassandra.node.threadPool.mutationStage.currentlyBlockedTasks db.threadpool.requestMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.mutationStage.pendingTasks db.threadpool.requestMutationStagePendingTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.activeTasks db.threadpool.internalPendingRangeCalculatorActiveTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.completedTasks db.threadpool.internalPendingRangeCalculatorCompletedTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.currentlyBlockedTasks db.threadpool.internalPendingRangeCalculatorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.pendingTasks db.threadpool.internalPendingRangeCalculatorPendingTasks Cassandra cassandra.node.threadPool.readRepairStage.activeTasks db.threadpool.requestReadRepairStageActiveTasks Cassandra cassandra.node.threadPool.readRepairStage.completedTasks db.threadpool.requestReadRepairStageCompletedTasks Cassandra cassandra.node.threadPool.readRepairStage.currentlyBlockedTasks db.threadpool.requestReadRepairStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.readRepairStage.pendingTasks db.threadpool.requestReadRepairStagePendingTasks Cassandra cassandra.node.threadPool.readStage.activeTasks db.threadpool.requestReadStageActiveTasks Cassandra cassandra.node.threadPool.readStage.completedTasks db.threadpool.requestReadStageCompletedTasks Cassandra cassandra.node.threadPool.readStage.currentlyBlockedTasks db.threadpool.requestReadStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.readStage.pendingTasks db.threadpool.requestReadStagePendingTasks Cassandra cassandra.node.threadPool.requestResponseStage.activeTasks db.threadpool.requestRequestResponseStageActiveTasks Cassandra cassandra.node.threadPool.requestResponseStage.completedTasks db.threadpool.requestRequestResponseStageCompletedTasks Cassandra cassandra.node.threadPool.requestResponseStage.currentlyBlockedTasks db.threadpool.requestRequestResponseStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.requestResponseStage.pendingTasks db.threadpool.requestRequestResponseStagePendingTasks Cassandra cassandra.node.threadPool.sampler.activeTasks db.threadpool.internalSamplerActiveTasks Cassandra cassandra.node.threadPool.sampler.completedTasks db.threadpool.internalSamplerCompletedTasks Cassandra cassandra.node.threadPool.sampler.currentlyBlockedTasks db.threadpool.internalSamplerCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.sampler.pendingTasks db.threadpool.internalSamplerPendingTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.activeTasks db.threadpool.internalSecondaryIndexManagementActiveTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.completedTasks db.threadpool.internalSecondaryIndexManagementCompletedTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.currentlyBlockedTasks db.threadpool.internalSecondaryIndexManagementCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.pendingTasks db.threadpool.internalSecondaryIndexManagementPendingTasks Cassandra cassandra.node.threadPool.validationExecutor.activeTasks db.threadpool.internalValidationExecutorActiveTasks Cassandra cassandra.node.threadPool.validationExecutor.completedTasks db.threadpool.internalValidationExecutorCompletedTasks Cassandra cassandra.node.threadPool.validationExecutor.currentlyBlockedTasks db.threadpool.internalValidationExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.validationExecutor.pendingTasks db.threadpool.internalValidationExecutorPendingTasks Cassandra cassandra.node.threadPool.viewMutationStage.activeTasks db.threadpool.requestViewMutationStageActiveTasks Cassandra cassandra.node.threadPool.viewMutationStage.completedTasks db.threadpool.requestViewMutationStageCompletedTasks Cassandra cassandra.node.threadPool.viewMutationStage.currentlyBlockedTasks db.threadpool.requestViewMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.viewMutationStage.pendingTasks db.threadpool.requestViewMutationStagePendingTasks Cassandra cassandra.node.totalHintsInProgress db.totalHintsInProgress Cassandra cassandra.node.totalHintsPerSecond db.totalHintsPerSecond Cassandra cassandra.columnFamily.allMemtablesOffHeapSizeBytes db.allMemtablesOffHeapSizeBytes Cassandra cassandra.columnFamily.allMemtablesOnHeapSizeBytes db.allMemtablesOnHeapSizeBytes Cassandra cassandra.columnFamily.bloomFilterFalseRatio db.bloomFilterFalseRatio Cassandra cassandra.columnFamily.liveDiskSpaceUsedBytes db.liveDiskSpaceUsedBytes Cassandra cassandra.columnFamily.liveSsTableCount db.liveSSTableCount Cassandra cassandra.columnFamily.maxRowSize db.maxRowSize Cassandra cassandra.columnFamily.meanRowSize db.meanRowSize Cassandra cassandra.columnFamily.memtableLiveDataSize db.memtableLiveDataSize Cassandra cassandra.columnFamily.minRowSize db.minRowSize Cassandra cassandra.columnFamily.pendingCompactions db.pendingCompactions Cassandra cassandra.columnFamily.query.readLatency50ThPercentileMilliseconds query.readLatency50thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency75ThPercentileMilliseconds query.readLatency75thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency95ThPercentileMilliseconds query.readLatency95thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency98ThPercentileMilliseconds query.readLatency98thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency999ThPercentileMilliseconds query.readLatency999thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency99ThPercentileMilliseconds query.readLatency99thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readRequestsPerSecond query.readRequestsPerSecond Cassandra cassandra.columnFamily.query.writeLatency50ThPercentileMilliseconds query.writeLatency50thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency75ThPercentileMilliseconds query.writeLatency75thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency95ThPercentileMilliseconds query.writeLatency95thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency98ThPercentileMilliseconds query.writeLatency98thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency999ThPercentileMilliseconds query.writeLatency999thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency99ThPercentileMilliseconds query.writeLatency99thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeRequestsPerSecond query.writeRequestsPerSecond Cassandra cassandra.columnFamily.speculativeRetries db.speculativeRetries Cassandra cassandra.columnFamily.ssTablesPerRead50ThPercentileMilliseconds db.SSTablesPerRead50thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead75ThPercentileMilliseconds db.SSTablesPerRead75thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead95ThPercentileMilliseconds db.SSTablesPerRead95thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead98ThPercentileMilliseconds db.SSTablesPerRead98thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead999ThPercentileMilliseconds db.SSTablesPerRead999thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead99ThPercentileMilliseconds db.SSTablesPerRead99thPercentileMilliseconds Cassandra cassandra.columnFamily.tombstoneScannedHistogram50ThPercentile db.tombstoneScannedHistogram50thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram75ThPercentile db.tombstoneScannedHistogram75thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram95ThPercentile db.tombstoneScannedHistogram95thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram98ThPercentile db.tombstoneScannedHistogram98thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram999ThPercentile db.tombstoneScannedHistogram999thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram99ThPercentile db.tombstoneScannedHistogram99thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogramCount db.tombstoneScannedHistogramCount Consul consul.datacenter.catalog.criticalNodes catalog.criticalNodes Consul consul.datacenter.catalog.passingNodes catalog.passingNodes Consul consul.datacenter.catalog.registeredNodes catalog.registeredNodes Consul consul.datacenter.catalog.upNodes catalog.upNodes Consul consul.datacenter.catalog.warningNodes catalog.warningNodes Consul consul.datacenter.cluster.flaps cluster.flaps Consul consul.datacenter.cluster.suspects cluster.suspects Consul consul.datacenter.raft.commitTime raft.commitTimes Consul consul.datacenter.raft.commitTimeAvgInMilliseconds raft.commitTimeAvgInMilliseconds Consul consul.datacenter.raft.commitTimeMaxInMilliseconds raft.commitTimeMaxInMilliseconds Consul consul.datacenter.raft.completedLeaderElections raft.completedLeaderElections Consul consul.datacenter.raft.initiatedLeaderElections raft.initiatedLeaderElections Consul consul.datacenter.raft.lastContactAvgInMilliseconds raft.lastContactAvgInMilliseconds Consul consul.datacenter.raft.lastContactMaxInMilliseconds raft.lastContactMaxInMilliseconds Consul consul.datacenter.raft.lastContacts raft.lastContacts Consul consul.datacenter.raft.logDispatchAvgInMilliseconds raft.logDispatchAvgInMilliseconds Consul consul.datacenter.raft.logDispatches raft.logDispatches Consul consul.datacenter.raft.logDispatchMaxInMilliseconds raft.logDispatchMaxInMilliseconds Consul consul.datacenter.raft.txns raft.txns Consul consul.agent.aclCacheHitPerSecond agent.aclCacheHit Consul consul.agent.aclCacheMissPerSecond agent.aclCacheMiss Consul consul.agent.client.rpcFailed client.rpcFailed Consul consul.agent.client.rpcLoad client.rpcLoad Consul consul.agent.kvStores agent.kvStoress Consul consul.agent.kvStoresAvgInMilliseconds agent.kvStoresAvgInMilliseconds Consul consul.agent.kvStoresMaxInMilliseconds agent.kvStoresMaxInMilliseconds Consul consul.agent.net.agent.maxLatencyInMilliseconds net.agent.maxLatencyInMilliseconds Consul consul.agent.net.medianLatencyInMilliseconds net.agent.medianLatencyInMilliseconds Consul consul.agent.net.minLatencyInMilliseconds net.agent.minLatencyInMilliseconds Consul consul.agent.net.p25LatencyInMilliseconds net.agent.p25LatencyInMilliseconds Consul consul.agent.net.p75LatencyInMilliseconds net.agent.p75LatencyInMilliseconds Consul consul.agent.net.p90LatencyInMilliseconds net.agent.p90LatencyInMilliseconds Consul consul.agent.net.p95LatencyInMilliseconds net.agent.p95LatencyInMilliseconds Consul consul.agent.net.p99LatencyInMilliseconds net.agent.p99LatencyInMilliseconds Consul consul.agent.peers agent.peers Consul consul.agent.runtime.allocations runtime.allocations Consul consul.agent.runtime.allocationsInBytes runtime.allocationsInBytes Consul consul.agent.runtime.frees runtime.frees Consul consul.agent.runtime.gcCycles runtime.gcCycles Consul consul.agent.runtime.gcPauseInMilliseconds runtime.gcPauseInMilliseconds Consul consul.agent.runtime.goroutines runtime.goroutines Consul consul.agent.runtime.heapObjects runtime.heapObjects Consul consul.agent.runtime.virtualAddressSpaceInBytes runtime.virtualAddressSpaceInBytes Consul consul.agent.staleQueries agent.staleQueries Consul consul.agent.txnAvgInMilliseconds agent.txnAvgInMilliseconds Consul consul.agent.txnMaxInMilliseconds agent.txnMaxInMilliseconds Consul consul.agent.txns agent.txns Couchbase couchbase.bucket.activeItemsEnteringDiskQueuePerSecond bucket.activeItemsEnteringDiskQueuePerSecond Couchbase couchbase.bucket.activeItemsInMemory bucket.activeItemsInMemory Couchbase couchbase.bucket.activeResidentItemsRatio bucket.activeResidentItemsRatio Couchbase couchbase.bucket.averageDiskCommitTimeInMilliseconds bucket.averageDiskCommitTimeInMilliseconds Couchbase couchbase.bucket.averageDiskUpdateTimeInMilliseconds bucket.averageDiskUpdateTimeInMilliseconds Couchbase couchbase.bucket.cacheMisses bucket.cacheMisses Couchbase couchbase.bucket.cacheMissRatio bucket.cacheMissRatio Couchbase couchbase.bucket.casHits bucket.casHits Couchbase couchbase.bucket.casMisses bucket.casMisses Couchbase couchbase.bucket.couchDocsFragmentationPercent bucket.couchDocsFragmentationPercent Couchbase couchbase.bucket.currentConnections bucket.currentConnections Couchbase couchbase.bucket.dataUsedInBytes bucket.dataUsedInBytes Couchbase couchbase.bucket.decrementHitsPerSecond bucket.decrementHitsPerSecond Couchbase couchbase.bucket.decrementMissesPerSecond bucket.decrementMissesPerSecond Couchbase couchbase.bucket.deleteHitsPerSecond bucket.deleteHitsPerSecond Couchbase couchbase.bucket.deleteMissesPerSecond bucket.deleteMissesPerSecond Couchbase couchbase.bucket.diskCreateOperationsPerSecond bucket.diskCreateOperationsPerSecond Couchbase couchbase.bucket.diskFetchesPerSecond bucket.diskFetchesPerSecond Couchbase couchbase.bucket.diskReadsPerSecond bucket.diskReadsPerSecond Couchbase couchbase.bucket.diskUpdateOperationsPerSecond bucket.diskUpdateOperationsPerSecond Couchbase couchbase.bucket.diskUsedInBytes bucket.diskUsedInBytes Couchbase couchbase.bucket.diskWriteQueue bucket.diskWriteQueue Couchbase couchbase.bucket.drainedItemsInQueue bucket.drainedItemsInQueue Couchbase couchbase.bucket.drainedItemsOnDiskQueue bucket.drainedItemsOnDiskQueue Couchbase couchbase.bucket.drainedPendingItemsInQueue bucket.drainedPendingItemsInQueue Couchbase couchbase.bucket.ejectionsPerSecond bucket.ejectionsPerSecond Couchbase couchbase.bucket.evictionsPerSecond bucket.evictionsPerSecond Couchbase couchbase.bucket.getHitsPerSecond bucket.getHitsPerSecond Couchbase couchbase.bucket.getMissesPerSecond bucket.getMissesPerSecond Couchbase couchbase.bucket.hitRatio bucket.hitRatio Couchbase couchbase.bucket.incrementHitsPerSecond bucket.incrementHitsPerSecond Couchbase couchbase.bucket.incrementMissesPerSecond bucket.incrementMissesPerSecond Couchbase couchbase.bucket.itemCount bucket.itemCount Couchbase couchbase.bucket.itemsBeingWritten bucket.itemsBeingWritten Couchbase couchbase.bucket.itemsEjectedFromMemoryToDisk bucket.itemsEjectedFromMemoryToDisk Couchbase couchbase.bucket.itemsOnDiskQueue bucket.itemsOnDiskQueue Couchbase couchbase.bucket.itemsQueuedForStorage bucket.itemsQueuedForStorage Couchbase couchbase.bucket.maximumMemoryUsage bucket.maximumMemoryUsage Couchbase couchbase.bucket.memoryHighWaterMarkInBytes bucket.memoryHighWaterMarkInBytes Couchbase couchbase.bucket.memoryLowWaterMarkInBytes bucket.memoryLowWaterMarkInBytes Couchbase couchbase.bucket.memoryUsedInBytes bucket.memoryUsedInBytes Couchbase couchbase.bucket.metadataInRamInBytes bucket.metadataInRAMInBytes Couchbase couchbase.bucket.missesPerSecond bucket.missesPerSecond Couchbase couchbase.bucket.outOfMemoryErrorsPerSecond bucket.outOfMemoryErrorsPerSecond Couchbase couchbase.bucket.overheadInBytes bucket.overheadInBytes Couchbase couchbase.bucket.pendingItemsInDiskQueue bucket.pendingItemsInDiskQueue Couchbase couchbase.bucket.pendingResidentItemsRatio bucket.pendingResidentItemsRatio Couchbase couchbase.bucket.quotaUtilization bucket.quotaUtilization Couchbase couchbase.bucket.readOperationsPerSecond bucket.readOperationsPerSecond Couchbase couchbase.bucket.readRatePerSecond bucket.readRatePerSecond Couchbase couchbase.bucket.recoverableOutOfMemoryCount bucket.recoverableOutOfMemoryCount Couchbase couchbase.bucket.replicaIndex bucket.replicaIndex Couchbase couchbase.bucket.replicaNumber bucket.replicaNumber Couchbase couchbase.bucket.replicaResidentItemsRatio bucket.replicaResidentItemsRatio Couchbase couchbase.bucket.residentItemsRatio bucket.residentItemsRatio Couchbase couchbase.bucket.temporaryOutOfMemoryErrorsPerSecond bucket.temporaryOutOfMemoryErrorsPerSecond Couchbase couchbase.bucket.threadsNumber bucket.threadsNumber Couchbase couchbase.bucket.totalItems bucket.totalItems Couchbase couchbase.bucket.totalOperationsPerSecond bucket.totalOperationsPerSecond Couchbase couchbase.bucket.viewFragmentationPercent bucket.viewFragmentationPercent Couchbase couchbase.bucket.writeOperationsPerSecond bucket.writeOperationsPerSecond Couchbase couchbase.bucket.writeRatePerSecond bucket.writeRatePerSecond Couchbase couchbase.cluster.autoFailoverCount cluster.autoFailoverCount Couchbase couchbase.cluster.autoFailoverEnabled cluster.autoFailoverEnabled Couchbase couchbase.cluster.databaseFragmentationThreshold cluster.databaseFragmentationThreshold Couchbase couchbase.cluster.diskFreeInBytes cluster.diskFreeInBytes Couchbase couchbase.cluster.diskQuotaTotalInBytes cluster.diskQuotaTotalInBytes Couchbase couchbase.cluster.diskTotalInBytes cluster.diskTotalInBytes Couchbase couchbase.cluster.diskUsedByDataInBytes cluster.diskUsedByDataInBytes Couchbase couchbase.cluster.diskUsedInBytes cluster.diskUsedInBytes Couchbase couchbase.cluster.indexFragmentationThreshold cluster.indexFragmentationThreshold Couchbase couchbase.cluster.maximumBucketCount cluster.maximumBucketCount Couchbase couchbase.cluster.memoryQuotaTotalInBytes cluster.memoryQuotaTotalInBytes Couchbase couchbase.cluster.memoryQuotaTotalPerNodeInBytes cluster.memoryQuotaTotalPerNodeInBytes Couchbase couchbase.cluster.memoryQuotaUsedInBytes cluster.memoryQuotaUsedInBytes Couchbase couchbase.cluster.memoryQuotaUsedPerNodeInBytes cluster.memoryQuotaUsedPerNodeInBytes Couchbase couchbase.cluster.memoryTotalInBytes cluster.memoryTotalInBytes Couchbase couchbase.cluster.memoryUsedByDataInBytes cluster.memoryUsedByDataInBytes Couchbase couchbase.cluster.memoryUsedInBytes cluster.memoryUsedInBytes Couchbase couchbase.cluster.viewFragmentationThreshold cluster.viewFragmentationThreshold Couchbase couchbase.node.backgroundFetches node.backgroundFetches Couchbase couchbase.node.cmdGet node.cmdGet Couchbase couchbase.node.couchDocsActualDiskSizeInBytes node.couchDocsActualDiskSizeInBytes Couchbase couchbase.node.couchDocsDataSizeInBytes node.couchDocsDataSizeInBytes Couchbase couchbase.node.couchSpatialDataSizeInBytes node.couchSpatialDataSizeInBytes Couchbase couchbase.node.couchSpatialDiskSizeInBytes node.couchSpatialDiskSizeInBytes Couchbase couchbase.node.couchViewsActualDiskSizeInBytes node.couchViewsActualDiskSizeInBytes Couchbase couchbase.node.couchViewsDataSizeInBytes node.couchViewsDataSizeInBytes Couchbase couchbase.node.cpuUtilization node.cpuUtilization Couchbase couchbase.node.currentItems node.currentItems Couchbase couchbase.node.currentItemsTotal node.currentItemsTotal Couchbase couchbase.node.getHits node.getHits Couchbase couchbase.node.memoryFreeInBytes node.memoryFreeInBytes Couchbase couchbase.node.memoryTotalInBytes node.memoryTotalInBytes Couchbase couchbase.node.memoryUsedInBytes node.memoryUsedInBytes Couchbase couchbase.node.ops node.ops Couchbase couchbase.node.swapTotalInBytes node.swapTotalInBytes Couchbase couchbase.node.swapUsedInBytes node.swapUsedInBytes Couchbase couchbase.node.uptimeInMilliseconds node.uptimeInMilliseconds Couchbase couchbase.node.vbucketActiveNonResidentItems node.vbucketActiveNonResidentItems Couchbase couchbase.node.vbucketInMemoryItems node.vbucketInMemoryItems Couchbase couchbase.queryengine.activeRequests queryengine.activeRequests Couchbase couchbase.queryengine.averageRequestTimeInMilliseconds queryengine.averageRequestTimeInMilliseconds Couchbase couchbase.queryengine.completedLimit queryengine.completedLimit Couchbase couchbase.queryengine.completedRequests queryengine.completedRequests Couchbase couchbase.queryengine.completedThresholdInMilliseconds queryengine.completedThresholdInMilliseconds Couchbase couchbase.queryengine.cores queryengine.cores Couchbase couchbase.queryengine.garbageCollectionNumber queryengine.garbageCollectionNumber Couchbase couchbase.queryengine.garbageCollectionPaused queryengine.garbageCollectionPaused Couchbase couchbase.queryengine.garbageCollectionTimePausedInMilliseconds queryengine.garbageCollectionTimePausedInMilliseconds Couchbase couchbase.queryengine.medianRequestTimeInMilliseconds queryengine.medianRequestTimeInMilliseconds Couchbase couchbase.queryengine.preparedStatementUtilization queryengine.preparedStatementUtilization Couchbase couchbase.queryengine.requestsLast15MinutesPerSecond queryengine.requestsLast15MinutesPerSecond Couchbase couchbase.queryengine.requestsLast1MinutesPerSecond queryengine.requestsLast1MinutesPerSecond Couchbase couchbase.queryengine.requestsLast5MinutesPerSecond queryengine.requestsLast5MinutesPerSecond Couchbase couchbase.queryengine.requestTime80thPercentileInMilliseconds queryengine.requestTime80thPercentileInMilliseconds Couchbase couchbase.queryengine.requestTime95thPercentileInMilliseconds queryengine.requestTime95thPercentileInMilliseconds Couchbase couchbase.queryengine.requestTime99thPercentileInMilliseconds queryengine.requestTime99thPercentileInMilliseconds Couchbase couchbase.queryengine.systemCpuUtilization queryengine.systemCPUUtilization Couchbase couchbase.queryengine.systemMemoryInBytes queryengine.systemMemoryInBytes Couchbase couchbase.queryengine.totalMemoryInBytes queryengine.totalMemoryInBytes Couchbase couchbase.queryengine.totalThreads queryengine.totalThreads Couchbase couchbase.queryengine.uptimeInMilliseconds queryengine.uptimeInMilliseconds Couchbase couchbase.queryengine.usedMemoryInBytes queryengine.usedMemoryInBytes Couchbase couchbase.queryengine.userCpuUtilization queryengine.userCPUUtilization Docker docker.container.cpuKernelPercent cpuKernelPercent Docker docker.container.cpuLimitCores cpuLimitCores Docker docker.container.cpuPercent cpuPercent Docker docker.container.cpuThrottlePeriods cpuThrottlePeriods Docker docker.container.cpuThrottleTimeMs cpuThrottleTimeMs Docker docker.container.cpuUsedCores cpuUsedCores Docker docker.container.cpuUsedCoresPercent cpuUsedCoresPercent Docker docker.container.cpuUserPercent cpuUserPercent Docker docker.container.ioReadBytesPerSecond ioReadBytesPerSecond Docker docker.container.ioReadCountPerSecond ioReadCountPerSecond Docker docker.container.ioTotalBytes ioTotalBytes Docker docker.container.ioTotalReadBytes ioTotalReadBytes Docker docker.container.ioTotalReadCount ioTotalReadCount Docker docker.container.ioTotalWriteBytes ioTotalWriteBytes Docker docker.container.ioTotalWriteCount ioTotalWriteCount Docker docker.container.ioWriteBytesPerSecond ioWriteBytesPerSecond Docker docker.container.ioWriteCountPerSecond ioWriteCountPerSecond Docker docker.container.memoryCacheBytes memoryCacheBytes Docker docker.container.memoryResidentSizeBytes memoryResidentSizeBytes Docker docker.container.memorySizeLimitBytes memorySizeLimitBytes Docker docker.container.memoryUsageBytes memoryUsageBytes Docker docker.container.memoryUsageLimitPercent memoryUsageLimitPercent Docker docker.container.networkRxBytes networkRxBytes Docker docker.container.networkRxBytesPerSecond networkRxBytesPerSecond Docker docker.container.networkRxDropped networkRxDropped Docker docker.container.networkRxDroppedPerSecond networkRxDroppedPerSecond Docker docker.container.networkRxErrors networkRxErrors Docker docker.container.networkRxErrorsPerSecond networkRxErrorsPerSecond Docker docker.container.networkRxPackets networkRxPackets Docker docker.container.networkRxPacketsPerSecond networkRxPacketsPerSecond Docker docker.container.networkTxBytes networkTxBytes Docker docker.container.networkTxBytesPerSecond networkTxBytesPerSecond Docker docker.container.networkTxDropped networkTxDropped Docker docker.container.networkTxDroppedPerSecond networkTxDroppedPerSecond Docker docker.container.networkTxErrors networkTxErrors Docker docker.container.networkTxErrorsPerSecond networkTxErrorsPerSecond Docker docker.container.networkTxPackets networkTxPackets Docker docker.container.networkTxPacketsPerSecond networkTxPacketsPerSecond Docker docker.container.pids pids Docker docker.container.processCount processCount Docker docker.container.processCountLimit processCountLimit Docker docker.container.restartCount restartCount Docker docker.container.threadCount threadCount Docker docker.container.threadCountLimit threadCountLimit ElasticSearch elasticsearch.cluster.dataNodes cluster.dataNodes ElasticSearch elasticsearch.cluster.nodes cluster.nodes ElasticSearch elasticsearch.cluster.shards.active shards.active ElasticSearch elasticsearch.cluster.shards.initializing shards.initializing ElasticSearch elasticsearch.cluster.shards.primaryActive shards.primaryActive ElasticSearch elasticsearch.cluster.shards.relocating shards.relocating ElasticSearch elasticsearch.cluster.shards.unassigned shards.unassigned ElasticSearch elasticsearch.cluster.tempData temp-data ElasticSearch elasticsearch.index.docs index.docs ElasticSearch elasticsearch.index.docsDeleted index.docsDeleted ElasticSearch elasticsearch.index.primaryShards index.primaryShards ElasticSearch elasticsearch.index.primaryStoreSizeInBytes index.primaryStoreSizeInBytes ElasticSearch elasticsearch.index.replicaShards index.replicaShards ElasticSearch elasticsearch.index.rollup.docsCount primaries.docsnumber ElasticSearch elasticsearch.index.rollup.docsDeleted primaries.docsDeleted ElasticSearch elasticsearch.index.rollup.flushTotal primaries.flushesTotal ElasticSearch elasticsearch.index.rollup.flushTotalTimeInMilliseconds primaries.flushTotalTimeInMilliseconds ElasticSearch elasticsearch.index.rollup.get.documentsExist primaries.get.documentsExist ElasticSearch elasticsearch.index.rollup.get.documentsExistInMilliseconds primaries.get.documentsExistInMilliseconds ElasticSearch elasticsearch.index.rollup.get.documentsMissing primaries.get.documentsMissing ElasticSearch elasticsearch.index.rollup.get.documentsMissingInMilliseconds primaries.get.documentsMissingInMilliseconds ElasticSearch elasticsearch.index.rollup.get.requests primaries.get.requests ElasticSearch elasticsearch.index.rollup.get.requestsCurrent primaries.get.requestsCurrent ElasticSearch elasticsearch.index.rollup.get.requestsInMilliseconds primaries.get.requestsInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyDeleted primaries.index.docsCurrentlyDeleted ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyDeletedInMilliseconds primaries.index.docsCurrentlyDeletedInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyIndexing primaries.index.docsCurrentlyIndexing ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyIndexingInMilliseconds primaries.index.docsCurrentlyIndexingInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsDeleted primaries.index.docsDeleted ElasticSearch elasticsearch.index.rollup.index.docsTotal primaries.index.docsTotal ElasticSearch elasticsearch.index.rollup.indexRefreshesTotal primaries.indexRefreshesTotal ElasticSearch elasticsearch.index.rollup.indexRefreshesTotalInMilliseconds primaries.indexRefreshesTotalInMilliseconds ElasticSearch elasticsearch.index.rollup.merges.current primaries.merges.current ElasticSearch elasticsearch.index.rollup.merges.docsSegmentsCurrentlyMerged primaries.merges.docsSegmentsCurrentlyMerged ElasticSearch elasticsearch.index.rollup.merges.docsTotal primaries.merges.docsTotal ElasticSearch elasticsearch.index.rollup.merges.segmentsCurrentlyMergedInBytes primaries.merges.segmentsCurrentlyMergedInBytes ElasticSearch elasticsearch.index.rollup.merges.segmentsTotal primaries.merges.segmentsTotal ElasticSearch elasticsearch.index.rollup.merges.segmentsTotalInBytes primaries.merges.segmentsTotalInBytes ElasticSearch elasticsearch.index.rollup.merges.segmentsTotalInMilliseconds primaries.merges.segmentsTotalInMilliseconds ElasticSearch elasticsearch.index.rollup.queriesInMilliseconds primaries.queriesInMilliseconds ElasticSearch elasticsearch.index.rollup.queriesTotal primaries.queriesTotal ElasticSearch elasticsearch.index.rollup.queryActive primaries.queryActive ElasticSearch elasticsearch.index.rollup.queryFetches primaries.queryFetches ElasticSearch elasticsearch.index.rollup.queryFetchesInMilliseconds primaries.queryFetchesInMilliseconds ElasticSearch elasticsearch.index.rollup.queryFetchesTotal primaries.queryFetchesTotal ElasticSearch elasticsearch.index.rollup.sizeInBytes primaries.sizeInBytes ElasticSearch elasticsearch.index.storeSizeInBytes index.storeSizeInBytes ElasticSearch elasticsearch.node.activeSearches activeSearches ElasticSearch elasticsearch.node.activeSearchesInMilliseconds activeSearchesInMilliseconds ElasticSearch elasticsearch.node.breakers.estimatedSizeFieldDataCircuitBreakerInBytes breakers.estimatedSizeFieldDataCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.estimatedSizeParentCircuitBreakerInBytes breakers.estimatedSizeParentCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.estimatedSizeRequestCircuitBreakerInBytes breakers.estimatedSizeRequestCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.fieldDataCircuitBreakerTripped breakers.fieldDataCircuitBreakerTripped ElasticSearch elasticsearch.node.breakers.parentCircuitBreakerTripped breakers.parentCircuitBreakerTripped ElasticSearch elasticsearch.node.breakers.requestCircuitBreakerTripped breakers.requestCircuitBreakerTripped ElasticSearch elasticsearch.node.flush.indexRefreshesTotal flush.indexRefreshesTotal ElasticSearch elasticsearch.node.flush.indexRefreshesTotalInMilliseconds flush.indexRefreshesTotalInMilliseconds ElasticSearch elasticsearch.node.fs.bytesAvailableJvmInBytes fs.bytesAvailableJVMInBytes ElasticSearch elasticsearch.node.fs.dataRead fs.bytesReadsInBytes ElasticSearch elasticsearch.node.fs.dataWritten fs.writesInBytes ElasticSearch elasticsearch.node.fs.ioOperations fs.iOOperations ElasticSearch elasticsearch.node.fs.readOperations fs.reads ElasticSearch elasticsearch.node.fs.totalSizeInBytes fs.totalSizeInBytes ElasticSearch elasticsearch.node.fs.unallocatedBytes fs.unallocatedBytesInBYtes ElasticSearch elasticsearch.node.fs.writeOperations fs.writeOperations ElasticSearch elasticsearch.node.get.currentRequestsRunning get.currentRequestsRunning ElasticSearch elasticsearch.node.get.requestsDocumentExists get.requestsDocumentExists ElasticSearch elasticsearch.node.get.requestsDocumentExistsInMilliseconds get.requestsDocumentExistsInMilliseconds ElasticSearch elasticsearch.node.get.requestsDocumentMissing get.requestsDocumentMissing ElasticSearch elasticsearch.node.get.requestsDocumentMissingInMilliseconds get.requestsDocumentMissingInMilliseconds ElasticSearch elasticsearch.node.get.timeGetRequestsInMilliseconds get.timeGetRequestsInMilliseconds ElasticSearch elasticsearch.node.get.totalGetRequests get.totalGetRequests ElasticSearch elasticsearch.node.http.currentOpenConnections http.currentOpenConnections ElasticSearch elasticsearch.node.http.openedConnections http.openedConnections ElasticSearch elasticsearch.node.index.indexingOperationsFailed indices.indexingOperationsFailed ElasticSearch elasticsearch.node.index.indexingWaitedThrottlingInMilliseconds indices.indexingWaitedThrottlingInMilliseconds ElasticSearch elasticsearch.node.index.memoryQueryCacheInBytes indices.memoryQueryCacheInBytes ElasticSearch elasticsearch.node.index.numberIndices indices.numberIndices ElasticSearch elasticsearch.node.index.queryCacheEvictions indices.queryCacheEvictions ElasticSearch elasticsearch.node.index.queryCacheHits indices.queryCacheHits ElasticSearch elasticsearch.node.index.queryCacheMisses indices.queryCacheMisses ElasticSearch elasticsearch.node.index.recoveryOngoingShardSource indices.recoveryOngoingShardSource ElasticSearch elasticsearch.node.index.recoveryOngoingShardTarget indices.recoveryOngoingShardTarget ElasticSearch elasticsearch.node.index.recoveryWaitedThrottlingInMilliseconds indices.recoveryWaitedThrottlingInMilliseconds ElasticSearch elasticsearch.node.index.requestCacheEvictions indices.requestCacheEvictions ElasticSearch elasticsearch.node.index.requestCacheHits indices.requestCacheHits ElasticSearch elasticsearch.node.index.requestCacheMemoryInBytes indices.requestCacheMemoryInBytes ElasticSearch elasticsearch.node.index.requestCacheMisses indices.requestCacheMisses ElasticSearch elasticsearch.node.index.segmentsIndexShard indices.segmentsIndexShard ElasticSearch elasticsearch.node.index.segmentsMemoryUsedDocValuesInBytes indices.segmentsMemoryUsedDocValuesInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedFixedBitSetInBytes indices.segmentsMemoryUsedFixedBitSetInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedIndexSegmentsInBytes indices.segmentsMemoryUsedIndexSegmentsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedIndexWriterInBytes indices.segmentsMemoryUsedIndexWriterInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedNormsInBytes indices.segmentsMemoryUsedNormsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedSegmentVersionMapInBytes indices.segmentsMemoryUsedSegmentVersionMapInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedStoredFieldsInBytes indices.segmentsMemoryUsedStoredFieldsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedTermsInBytes indices.segmentsMemoryUsedTermsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedTermVectorsInBytes indices.segmentsMemoryUsedTermVectorsInBytes ElasticSearch elasticsearch.node.index.translogOperations indices.translogOperations ElasticSearch elasticsearch.node.index.translogOperationsInBytes indices.translogOperationsInBytes ElasticSearch elasticsearch.node.indexing.docsCurrentlyDeleted indexing.docsCurrentlyDeleted ElasticSearch elasticsearch.node.indexing.documentsCurrentlyIndexing indexing.documentsCurrentlyIndexing ElasticSearch elasticsearch.node.indexing.documentsIndexed indexing.documentsIndexed ElasticSearch elasticsearch.node.indexing.timeDeletingDocumentsInMilliseconds indexing.timeDeletingDocumentsInMilliseconds ElasticSearch elasticsearch.node.indexing.timeIndexingDocumentsInMilliseconds indexing.timeIndexingDocumentsInMilliseconds ElasticSearch elasticsearch.node.indexing.totalDocumentsDeleted indexing.totalDocumentsDeleted ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsOldGenerationObjects jvm.gc.majorCollectionsOldGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsOldGenerationObjectsInMilliseconds jvm.gc.majorCollectionsOldGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsYoungGenerationObjects jvm.gc.majorCollectionsYoungGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsYoungGenerationObjectsInMilliseconds jvm.gc.majorCollectionsYoungGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.gc.minorCollectionsYoungGenerationObjects jvm.gc.minorCollectionsYoungGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.minorCollectionsYoungGenerationObjectsInMilliseconds jvm.gc.minorCollectionsYoungGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.mem.heapCommittedInBytes jvm.mem.heapCommittedInBytes ElasticSearch elasticsearch.node.jvm.mem.heapMaxInBytes jvm.mem.heapMaxInBytes ElasticSearch elasticsearch.node.jvm.mem.heapUsed jvm.mem.heapUsed ElasticSearch elasticsearch.node.jvm.mem.heapUsedInBytes jvm.mem.heapUsedInBytes ElasticSearch elasticsearch.node.jvm.mem.maxOldGenerationHeapInBytes jvm.mem.maxOldGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.maxSurvivorSpaceInBytes jvm.mem.maxSurvivorSpaceInBYtes ElasticSearch elasticsearch.node.jvm.mem.maxYoungGenerationHeapInBytes jvm.mem.maxYoungGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.nonHeapCommittedInBytes jvm.mem.nonHeapCommittedInBytes ElasticSearch elasticsearch.node.jvm.mem.nonHeapUsedInBytes jvm.mem.nonHeapUsedInBytes ElasticSearch elasticsearch.node.jvm.mem.usedOldGenerationHeapInBytes jvm.mem.usedOldGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.usedSurvivorSpaceInBytes jvm.mem.usedSurvivorSpaceInBytes ElasticSearch elasticsearch.node.jvm.mem.usedYoungGenerationHeapInBytes jvm.mem.usedYoungGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.threadsActive jvm.ThreadsActive ElasticSearch elasticsearch.node.jvm.threadsPeak jvm.ThreadsPeak ElasticSearch elasticsearch.node.merges.currentActive merges.currentActive ElasticSearch elasticsearch.node.merges.docsSegmentMerges merges.docsSegmentMerges ElasticSearch elasticsearch.node.merges.docsSegmentsMerging merges.docsSegmentsMerging ElasticSearch elasticsearch.node.merges.mergedSegmentsInBytes merges.mergedSegmentsInBytes ElasticSearch elasticsearch.node.merges.segmentMerges merges.segmentMerges ElasticSearch elasticsearch.node.merges.sizeSegmentsMergingInBytes merges.sizeSegmentsMergingInBytes ElasticSearch elasticsearch.node.merges.totalSegmentMergingInMilliseconds merges.totalSegmentMergingInMilliseconds ElasticSearch elasticsearch.node.openFd openFD ElasticSearch elasticsearch.node.queriesTotal queriesTotal ElasticSearch elasticsearch.node.refresh.total refresh.total ElasticSearch elasticsearch.node.refresh.totalInMilliseconds refresh.totalInMilliseconds ElasticSearch elasticsearch.node.searchFetchCurrentlyRunning searchFetchCurrentlyRunning ElasticSearch elasticsearch.node.searchFetches searchFetches ElasticSearch elasticsearch.node.sizeStoreInBytes sizeStoreInBytes ElasticSearch elasticsearch.node.threadpool.activeFetchShardStarted threadpool.activeFetchShardStarted ElasticSearch elasticsearch.node.threadpool.bulkActive threadpool.bulkActive ElasticSearch elasticsearch.node.threadpool.bulkQueue threadpool.bulkQueue ElasticSearch elasticsearch.node.threadpool.bulkRejected threadpool.bulkRejected ElasticSearch elasticsearch.node.threadpool.bulkThreads threadpool.bulkThreads ElasticSearch elasticsearch.node.threadpool.fetchShardStartedQueue threadpool.fetchShardStartedQueue ElasticSearch elasticsearch.node.threadpool.fetchShardStartedRejected threadpool.fetchShardStartedRejected ElasticSearch elasticsearch.node.threadpool.fetchShardStartedThreads threadpool.fetchShardStartedThreads ElasticSearch elasticsearch.node.threadpool.fetchShardStoreActive threadpool.fetchShardStoreActive ElasticSearch elasticsearch.node.threadpool.fetchShardStoreQueue threadpool.fetchShardStoreQueue ElasticSearch elasticsearch.node.threadpool.fetchShardStoreRejected threadpool.fetchShardStoreRejected ElasticSearch elasticsearch.node.threadpool.fetchShardStoreThreads threadpool.fetchShardStoreThreads ElasticSearch elasticsearch.node.threadpool.flushActive threadpool.flushActive ElasticSearch elasticsearch.node.threadpool.flushQueue threadpool.flushQueue ElasticSearch elasticsearch.node.threadpool.flushRejected threadpool.flushRejected ElasticSearch elasticsearch.node.threadpool.flushThreads threadpool.flushThreads ElasticSearch elasticsearch.node.threadpool.forceMergeActive threadpool.forceMergeActive ElasticSearch elasticsearch.node.threadpool.forceMergeQueue threadpool.forceMergeQueue ElasticSearch elasticsearch.node.threadpool.forceMergeRejected threadpool.forceMergeRejected ElasticSearch elasticsearch.node.threadpool.forceMergeThreads threadpool.forceMergeThreads ElasticSearch elasticsearch.node.threadpool.genericActive threadpool.genericActive ElasticSearch elasticsearch.node.threadpool.genericQueue threadpool.genericQueue ElasticSearch elasticsearch.node.threadpool.genericRejected threadpool.genericRejected ElasticSearch elasticsearch.node.threadpool.genericThreads threadpool.genericThreads ElasticSearch elasticsearch.node.threadpool.getActive threadpool.getActive ElasticSearch elasticsearch.node.threadpool.getQueue threadpool.getQueue ElasticSearch elasticsearch.node.threadpool.getRejected threadpool.getRejected ElasticSearch elasticsearch.node.threadpool.getThreads threadpool.getThreads ElasticSearch elasticsearch.node.threadpool.indexActive threadpool.indexActive ElasticSearch elasticsearch.node.threadpool.indexQueue threadpool.indexQueue ElasticSearch elasticsearch.node.threadpool.indexRejected threadpool.indexRejected ElasticSearch elasticsearch.node.threadpool.indexThreads threadpool.indexThreads ElasticSearch elasticsearch.node.threadpool.listenerActive threadpool.listenerActive ElasticSearch elasticsearch.node.threadpool.listenerQueue threadpool.listenerQueue ElasticSearch elasticsearch.node.threadpool.listenerRejected threadpool.listenerRejected ElasticSearch elasticsearch.node.threadpool.listenerThreads threadpool.listenerThreads ElasticSearch elasticsearch.node.threadpool.managementActive threadpool.managementActive ElasticSearch elasticsearch.node.threadpool.managementQueue threadpool.managementQueue ElasticSearch elasticsearch.node.threadpool.managementRejected threadpool.managementRejected ElasticSearch elasticsearch.node.threadpool.managementThreads threadpool.managementThreads ElasticSearch elasticsearch.node.threadpool.refreshActive threadpool.refreshActive ElasticSearch elasticsearch.node.threadpool.refreshQueue threadpool.refreshQueue ElasticSearch elasticsearch.node.threadpool.refreshRejected threadpool.refreshRejected ElasticSearch elasticsearch.node.threadpool.refreshThreads threadpool.refreshThreads ElasticSearch elasticsearch.node.threadpool.searchActive threadpool.searchActive ElasticSearch elasticsearch.node.threadpool.searchQueue threadpool.searchQueue ElasticSearch elasticsearch.node.threadpool.searchRejected threadpool.searchRejected ElasticSearch elasticsearch.node.threadpool.searchThreads threadpool.searchThreads ElasticSearch elasticsearch.node.threadpool.snapshotActive threadpool.snapshotActive ElasticSearch elasticsearch.node.threadpool.snapshotQueue threadpool.snapshotQueue ElasticSearch elasticsearch.node.threadpool.snapshotRejected threadpool.snapshotRejected ElasticSearch elasticsearch.node.threadpool.snapshotThreads threadpool.snapshotThreads ElasticSearch elasticsearch.node.transport.connectionsOpened transport.connectionsOpened ElasticSearch elasticsearch.node.transport.packetsReceived transport.packetsReceived ElasticSearch elasticsearch.node.transport.packetsReceivedInBytes transport.packetsReceivedInBytes ElasticSearch elasticsearch.node.transport.packetsSent transport.packetsSent ElasticSearch elasticsearch.node.transport.packetsSentInBytes transport.packetsSentInBytes F5 f5.node.availabilityState node.availabilityState F5 f5.node.connections node.connections F5 f5.node.connectionsPerSecond node.connectionsPerSecond F5 f5.node.enabled node.enabled F5 f5.node.inDataInBytesPerSecond node.inDataInBytesPerSecond F5 f5.node.monitorStatus node.monitorStatus F5 f5.node.outDataInBytesPerSecond node.outDataInBytesPerSecond F5 f5.node.packetsReceivedPerSecond node.packetsReceivedPerSecond F5 f5.node.packetsSentPerSecond node.packetsSentPerSecond F5 f5.node.requestsPerSecond node.requestsPerSecond F5 f5.node.sessions node.sessions F5 f5.node.sessionStatus node.sessionStatus F5 f5.poolMember.availabilityState member.availabilityState F5 f5.poolMember.connections member.connections F5 f5.poolMember.enabled member.enabled F5 f5.poolMember.inDataInBytesPerSecond member.inDataInBytesPerSecond F5 f5.poolMember.monitorStatus member.monitorStatus F5 f5.poolMember.outDataInBytesPerSecond member.outDataInBytesPerSecond F5 f5.poolMember.packetsReceivedPerSecond member.packetsReceivedPerSecond F5 f5.poolMember.packetsSentPerSecond member.packetsSentPerSecond F5 f5.poolMember.requestsPerSecond member.requestsPerSecond F5 f5.poolMember.sessions member.sessions F5 f5.poolMember.sessionStatus member.sessionStatus F5 f5.pool.activeMembers pool.activeMembers F5 f5.pool.availabilityState pool.availabilityState F5 f5.pool.connections pool.connections F5 f5.pool.connqAgeEdm pool.connqAgeEdm F5 f5.pool.connqAgeEma pool.connqAgeEma F5 f5.pool.connqAgeHead pool.connqAgeHead F5 f5.pool.connqAgeMax pool.connqAgeMax F5 f5.pool.connqAllAgeEdm pool.connqAllAgeEdm F5 f5.pool.connqAllAgeEma pool.connqAllAgeEma F5 f5.pool.connqAllAgeHead pool.connqAllAgeHead F5 f5.pool.connqAllAgeMax pool.connqAllAgeMax F5 f5.pool.connqAllDepth pool.connqAllDepth F5 f5.pool.connqDepth pool.connqDepth F5 f5.pool.currentConnections pool.currentConnections F5 f5.pool.enabled pool.enabled F5 f5.pool.inDataInBytesPerSecond pool.inDataInBytesPerSecond F5 f5.pool.minActiveMembers pool.minActiveMembers F5 f5.pool.outDataInBytesPerSecond pool.outDataInBytesPerSecond F5 f5.pool.packetsReceivedPerSecond pool.packetsReceivedPerSecond F5 f5.pool.packetsSentPerSecond pool.packetsSentPerSecond F5 f5.pool.requestsPerSecond pool.requestsPerSecond F5 f5.pool.sessions pool.sessions F5 f5.system.cpuIdleTicksPerSecond system.cpuIdleTicksPerSecond F5 f5.system.cpuIdleUtilization system.cpuIdleUtilization F5 f5.system.cpuInterruptRequestUtilization system.cpuInterruptRequestUtilization F5 f5.system.cpuIoWaitUtilization system.cpuIOWaitUtilization F5 f5.system.cpuNiceLevelUtilization system.cpuNiceLevelUtilization F5 f5.system.cpuSoftInterruptRequestUtilization system.cpuSoftInterruptRequestUtilization F5 f5.system.cpuStolenUtilization system.cpuStolenUtilization F5 f5.system.cpuSystemTicksPerSecond system.cpuSystemTicksPerSecond F5 f5.system.cpuSystemUtilization system.cpuSystemUtilization F5 f5.system.cpuUserTicksPerSecond system.cpuUserTicksPerSecond F5 f5.system.cpuUserUtilization system.cpuUserUtilization F5 f5.system.memoryFreeInBytes system.memoryFreeInBytes F5 f5.system.memoryTotalInBytes system.memoryTotalInBytes F5 f5.system.memoryUsedInBytes system.memoryUsedInBytes F5 f5.system.otherMemoryFreeInBytes system.otherMemoryFreeInBytes F5 f5.system.otherMemoryTotalInBytes system.otherMemoryTotalInBytes F5 f5.system.otherMemoryUsedInBytes system.otherMemoryUsedInBytes F5 f5.system.swapFreeInBytes system.swapFreeInBytes F5 f5.system.swapTotalInBytes system.swapTotalInBytes F5 f5.system.swapUsedInBytes system.swapUsedInBytes F5 f5.system.tmmMemoryFreeInBytes system.tmmMemoryFreeInBytes F5 f5.system.tmmMemoryTotalInBytes system.tmmMemoryTotalInBytes F5 f5.system.tmmMemoryUsedInBytes system.tmmMemoryUsedInBytes F5 f5.virtualserver.availabilityState virtualserver.availabilityState F5 f5.virtualserver.clientsideConnectionsPerSecond virtualserver.clientsideConnectionsPerSecond F5 f5.virtualserver.connections virtualserver.connections F5 f5.virtualserver.csMaxConnDur virtualserver.csMaxConnDur F5 f5.virtualserver.csMeanConnDur virtualserver.csMeanConnDur F5 f5.virtualserver.csMinConnDur virtualserver.csMinConnDur F5 f5.virtualserver.enabled virtualserver.enabled F5 f5.virtualserver.ephemeralBytesInPerSecond virtualserver.ephemeralBytesInPerSecond F5 f5.virtualserver.ephemeralBytesOutPerSecond virtualserver.ephemeralBytesOutPerSecond F5 f5.virtualserver.ephemeralConnectionsPerSecond virtualserver.ephemeralConnectionsPerSecond F5 f5.virtualserver.ephemeralCurrentConnections virtualserver.ephemeralCurrentConnections F5 f5.virtualserver.ephemeralEvictedConnectionsPerSecond virtualserver.ephemeralEvictedConnectionsPerSecond F5 f5.virtualserver.ephemeralMaxConnections virtualserver.ephemeralMaxConnections F5 f5.virtualserver.ephemeralPacketsReceivedPerSecond virtualserver.ephemeralPacketsReceivedPerSecond F5 f5.virtualserver.ephemeralPacketsSentPerSecond virtualserver.ephemeralPacketsSentPerSecond F5 f5.virtualserver.ephemeralSlowKilledPerSecond virtualserver.ephemeralSlowKilledPerSecond F5 f5.virtualserver.evictedConnsPerSecond virtualserver.evictedConnsPerSecond F5 f5.virtualserver.inDataInBytesPerSecond virtualserver.inDataInBytesPerSecond F5 f5.virtualserver.outDataInBytesPerSecond virtualserver.outDataInBytesPerSecond F5 f5.virtualserver.packetsReceivedPerSecond virtualserver.packetsReceivedPerSecond F5 f5.virtualserver.packetsSentPerSecond virtualserver.packetsSentPerSecond F5 f5.virtualserver.requestsPerSecond virtualserver.requestsPerSecond F5 f5.virtualserver.slowKilledPerSecond virtualserver.slowKilledPerSecond F5 f5.virtualserver.usageRatio virtualserver.usageRatio HAProxy haproxy.backend.activeServers backend.activeServers HAProxy haproxy.backend.averageConnectTimeInSeconds backend.averageConnectTimeInSeconds HAProxy haproxy.backend.averageQueueTimeInSeconds backend.averageQueueTimeInSeconds HAProxy haproxy.backend.averageResponseTimeInSeconds backend.averageResponseTimeInSeconds HAProxy haproxy.backend.averageTotalSessionTimeInSeconds backend.averageTotalSessionTimeInSeconds HAProxy haproxy.backend.backupServers backend.backupServers HAProxy haproxy.backend.bytesInPerSecond backend.bytesInPerSecond HAProxy haproxy.backend.bytesOutPerSecond backend.bytesOutPerSecond HAProxy haproxy.backend.bytesThatBypassedCompressorPerSecond backend.bytesThatBypassedCompressorPerSecond HAProxy haproxy.backend.connectingRequestErrorsPerSecond backend.connectingRequestErrorsPerSecond HAProxy haproxy.backend.connectionRetriesPerSecond backend.connectionRetriesPerSecond HAProxy haproxy.backend.currentQueuedRequestsWithoutServer backend.currentQueuedRequestsWithoutServer HAProxy haproxy.backend.currentSessions backend.currentSessions HAProxy haproxy.backend.dataTransfersAbortedByClientPerSecond backend.dataTransfersAbortedByClientPerSecond HAProxy haproxy.backend.dataTransfersAbortedByServerPerSecond backend.dataTransfersAbortedByServerPerSecond HAProxy haproxy.backend.downtimeInSeconds backend.downtimeInSeconds HAProxy haproxy.backend.http100ResponsesPerSecond backend.http100ResponsesPerSecond HAProxy haproxy.backend.http200ResponsesPerSecond backend.http200ResponsesPerSecond HAProxy haproxy.backend.http300ResponsesPerSecond backend.http300ResponsesPerSecond HAProxy haproxy.backend.http400ResponsesPerSecond backend.http400ResponsesPerSecond HAProxy haproxy.backend.http500ResponsesPerSecond backend.http500ResponsesPerSecond HAProxy haproxy.backend.httpOtherResponsesPerSecond backend.httpOtherResponsesPerSecond HAProxy haproxy.backend.httpRequestsPerSecond backend.httpRequestsPerSecond HAProxy haproxy.backend.httpResponseBytesEmittedByCompressorPerSecond backend.httpResponseBytesEmittedByCompressorPerSecond HAProxy haproxy.backend.httpResponseBytesFedToCompressorPerSecond backend.httpResponseBytesFedToCompressorPerSecond HAProxy haproxy.backend.httpResponsesCompressedPerSecond backend.httpResponsesCompressedPerSecond HAProxy haproxy.backend.interceptedRequestsPerSecond backend.interceptedRequestsPerSecond HAProxy haproxy.backend.maxQueuedRequestsWithoutServer backend.maxQueuedRequestsWithoutServer HAProxy haproxy.backend.maxSessions backend.maxSessions HAProxy haproxy.backend.maxSessionsPerSecond backend.maxSessionsPerSecond HAProxy haproxy.backend.requestRedispatchPerSecond backend.requestRedispatchPerSecond HAProxy haproxy.backend.requestsDenied.securityConcernsPerSecond backend.requestsDenied.securityConcernsPerSecond HAProxy haproxy.backend.responseErrorsPerSecond backend.responseErrorsPerSecond HAProxy haproxy.backend.responsesDenied.securityConcernsPerSecond backend.responsesDenied.securityConcernsPerSecond HAProxy haproxy.backend.serverSelectedPerSecond backend.serverSelectedPerSecond HAProxy haproxy.backend.sessionsPerSecond backend.sessionsPerSecond HAProxy haproxy.backend.timeSinceLastSessionAssignedInSeconds backend.timeSinceLastSessionAssignedInSeconds HAProxy haproxy.backend.timeSinceLastUpDownTransitionInSeconds backend.timeSinceLastUpDownTransitionInSeconds HAProxy haproxy.backend.totalWeight backend.totalWeight HAProxy haproxy.backend.type backend.type HAProxy haproxy.backend.upToDownTransitionsPerSecond backend.upToDownTransitionsPerSecond HAProxy haproxy.frontend.bytesInPerSecond frontend.bytesInPerSecond HAProxy haproxy.frontend.bytesOutPerSecond frontend.bytesOutPerSecond HAProxy haproxy.frontend.connectionsPerSecond frontend.connectionsPerSecond HAProxy haproxy.frontend.currentSessions frontend.currentSessions HAProxy haproxy.frontend.http100ResponsesPerSecond frontend.http100ResponsesPerSecond HAProxy haproxy.frontend.http200ResponsesPerSecond frontend.http200ResponsesPerSecond HAProxy haproxy.frontend.http300ResponsesPerSecond frontend.http300ResponsesPerSecond HAProxy haproxy.frontend.http400ResponsesPerSecond frontend.http400ResponsesPerSecond HAProxy haproxy.frontend.http500ResponsesPerSecond frontend.http500ResponsesPerSecond HAProxy haproxy.frontend.httpOtherResponsesPerSecond frontend.httpOtherResponsesPerSecond HAProxy haproxy.frontend.httpRequests.maxPerSecond frontend.httpRequests.maxPerSecond HAProxy haproxy.frontend.httpRequestsPerSecond frontend.httpRequestsPerSecond HAProxy haproxy.frontend.interceptedRequestsPerSecond frontend.interceptedRequestsPerSecond HAProxy haproxy.frontend.maxConnectionsPerSecond frontend.maxConnectionsPerSecond HAProxy haproxy.frontend.maxSessions frontend.maxSessions HAProxy haproxy.frontend.maxSessionsPerSecond frontend.maxSessionsPerSecond HAProxy haproxy.frontend.requestErrorsPerSecond frontend.requestErrorsPerSecond HAProxy haproxy.frontend.requestsDenied.securityConcernsPerSecond frontend.requestsDenied.securityConcernsPerSecond HAProxy haproxy.frontend.requestsDenied.tcpRequestConnectionRulesPerSecond frontend.requestsDenied.tcpRequestConnectionRulesPerSecond HAProxy haproxy.frontend.requestsDenied.tcpRequestSessionRulesPerSecond frontend.requestsDenied.tcpRequestSessionRulesPerSecond HAProxy haproxy.frontend.responsesDenied.securityConcernsPerSecond frontend.responsesDenied.securityConcernsPerSecond HAProxy haproxy.frontend.sessionsPerSecond frontend.sessionsPerSecond HAProxy haproxy.server.averageConnectTimeInSeconds server.averageConnectTimeInSeconds HAProxy haproxy.server.averageQueueTimeInSeconds server.averageQueueTimeInSeconds HAProxy haproxy.server.averageResponseTimeInSeconds server.averageResponseTimeInSeconds HAProxy haproxy.server.averageTotalSessionTimeInSeconds server.averageTotalSessionTimeInSeconds HAProxy haproxy.server.bytesInPerSecond server.bytesInPerSecond HAProxy haproxy.server.bytesOutPerSecond server.bytesOutPerSecond HAProxy haproxy.server.connectingRequestErrorsPerSecond server.connectingRequestErrorsPerSecond HAProxy haproxy.server.connectionRetriesPerSecond server.connectionRetriesPerSecond HAProxy haproxy.server.currentQueuedRequestsWithoutServer server.currentQueuedRequestsWithoutServer HAProxy haproxy.server.currentSessions server.currentSessions HAProxy haproxy.server.dataTransfersAbortedByClientPerSecond server.dataTransfersAbortedByClientPerSecond HAProxy haproxy.server.dataTransfersAbortedByServerPerSecond server.dataTransfersAbortedByServerPerSecond HAProxy haproxy.server.downtimeInSeconds server.downtimeInSeconds HAProxy haproxy.server.failedChecksPerSecond server.failedChecksPerSecond HAProxy haproxy.server.healthCheckDurationInMilliseconds server.healthCheckDurationInMilliseconds HAProxy haproxy.server.http100ResponsesPerSecond server.http100ResponsesPerSecond HAProxy haproxy.server.http200ResponsesPerSecond server.http200ResponsesPerSecond HAProxy haproxy.server.http300ResponsesPerSecond server.http300ResponsesPerSecond HAProxy haproxy.server.http400ResponsesPerSecond server.http400ResponsesPerSecond HAProxy haproxy.server.http500ResponsesPerSecond server.http500ResponsesPerSecond HAProxy haproxy.server.httpOtherResponsesPerSecond server.httpOtherResponsesPerSecond HAProxy haproxy.server.isActive server.isActive HAProxy haproxy.server.isBackup server.isBackup HAProxy haproxy.server.maxQueuedRequestsWithoutServer server.maxQueuedRequestsWithoutServer HAProxy haproxy.server.maxSessions server.maxSessions HAProxy haproxy.server.maxSessionsPerSecond server.maxSessionsPerSecond HAProxy haproxy.server.requestRedispatchPerSecond server.requestRedispatchPerSecond HAProxy haproxy.server.requestsDenied.securityConcernsPerSecond server.requestsDenied.securityConcernsPerSecond HAProxy haproxy.server.responseErrorsPerSecond server.responseErrorsPerSecond HAProxy haproxy.server.responsesDenied.securityConcernsPerSecond server.responsesDenied.securityConcernsPerSecond HAProxy haproxy.server.serverSelectedPerSecond server.serverSelectedPerSecond HAProxy haproxy.server.serverWeight server.serverWeight HAProxy haproxy.server.sessionsPerSecond server.sessionsPerSecond HAProxy haproxy.server.throttlePercentage server.throttlePercentage HAProxy haproxy.server.timeSinceLastSessionAssignedInSeconds server.timeSinceLastSessionAssignedInSeconds HAProxy haproxy.server.timeSinceLastUpDownTransitionInSeconds server.timeSinceLastUpDownTransitionInSeconds HAProxy haproxy.server.type server.type HAProxy haproxy.server.upToDownTransitionsPerSecond server.upToDownTransitionsPerSecond Kafka kafka.broker.bytesWrittenToTopicPerSecond broker.bytesWrittenToTopicPerSecond Kafka kafka.broker.consumer.requestsExpiredPerSecond consumer.requestsExpiredPerSecond Kafka kafka.broker.follower.requestExpirationPerSecond follower.requestExpirationPerSecond Kafka kafka.broker.ioInPerSecond broker.IOInPerSecond Kafka kafka.broker.ioOutPerSecond broker.IOOutPerSecond Kafka kafka.broker.logFlushPerSecond broker.logFlushPerSecond Kafka kafka.broker.messagesInPerSecond broker.messagesInPerSecond Kafka kafka.broker.net.bytesRejectedPerSecond net.bytesRejectedPerSecond Kafka kafka.broker.replication.isrExpandsPerSecond replication.isrExpandsPerSecond Kafka kafka.broker.replication.isrShrinksPerSecond replication.isrShrinksPerSecond Kafka kafka.broker.replication.leaderElectionPerSecond replication.leaderElectionPerSecond Kafka kafka.broker.replication.uncleanLeaderElectionPerSecond replication.uncleanLeaderElectionPerSecond Kafka kafka.broker.replication.unreplicatedPartitions replication.unreplicatedPartitions Kafka kafka.broker.request.avgTimeFetch request.avgTimeFetch Kafka kafka.broker.request.avgTimeMetadata request.avgTimeMetadata Kafka kafka.broker.request.avgTimeMetadata99Percentile request.avgTimeMetadata99Percentile Kafka kafka.broker.request.avgTimeOffset request.avgTimeOffset Kafka kafka.broker.request.avgTimeOffset99Percentile request.avgTimeOffset99Percentile Kafka kafka.broker.request.avgTimeProduceRequest request.avgTimeProduceRequest Kafka kafka.broker.request.avgTimeUpdateMetadata request.avgTimeUpdateMetadata Kafka kafka.broker.request.avgTimeUpdateMetadata99Percentile request.avgTimeUpdateMetadata99Percentile Kafka kafka.broker.request.clientFetchesFailedPerSecond request.clientFetchesFailedPerSecond Kafka kafka.broker.request.fetchConsumerRequestsPerSecond request.fetchConsumerRequestsPerSecond Kafka kafka.broker.request.fetchFollowerRequestsPerSecond request.fetchFollowerRequestsPerSecond Kafka kafka.broker.request.fetchTime99Percentile request.fetchTime99Percentile Kafka kafka.broker.request.handlerIdle request.handlerIdle Kafka kafka.broker.request.listGroupsRequestsPerSecond request.listGroupsRequestsPerSecond Kafka kafka.broker.request.metadataRequestsPerSecond request.metadataRequestsPerSecond Kafka kafka.broker.request.offsetCommitRequestsPerSecond request.offsetCommitRequestsPerSecond Kafka kafka.broker.request.produceRequestsFailedPerSecond request.produceRequestsFailedPerSecond Kafka kafka.broker.request.produceRequestsPerSecond request.produceRequestsPerSecond Kafka kafka.broker.request.produceTime99Percentile request.produceTime99Percentile Kafka kafka.broker.topic.diskSize topic.diskSize Kafka kafka.topic.bytesInPerSec topic.BytesInPerSec Kafka kafka.topic.bytesOutPerSec topic.BytesOutPerSec Kafka kafka.topic.messagesInPerSec topic.MessagesInPerSec Kafka kafka.topic.partitionsWithNonPreferredLeader topic.partitionsWithNonPreferredLeader Kafka kafka.topic.respondsToMetadataRequests topic.respondsToMetadataRequests Kafka kafka.topic.retentionBytesOrTime topic.retentionBytesOrTime Kafka kafka.topic.underReplicatedPartitions topic.underReplicatedPartitions Kafka kafka.producer.ageMetadataUsedInMilliseconds producer.ageMetadataUsedInMilliseconds Kafka kafka.producer.availableBufferInBytes producer.availableBufferInBytes Kafka kafka.producer.avgBytesSentPerRequestInBytes producer.avgBytesSentPerRequestInBytes Kafka kafka.producer.avgCompressionRateRecordBatches producer.avgCompressionRateRecordBatches Kafka kafka.producer.avgRecordAccumulatorsInMilliseconds producer.avgRecordAccumulatorsInMilliseconds Kafka kafka.producer.avgRecordSizeInBytes producer.avgRecordSizeInBytes Kafka kafka.producer.avgRecordsSentPerSecond producer.avgRecordsSentPerSecond Kafka kafka.producer.avgRecordsSentPerTopicPerSecond producer.avgRecordsSentPerTopicPerSecond Kafka kafka.producer.avgRequestLatency producer.avgRequestLatencyPerSecond Kafka kafka.producer.avgThrottleTime producer.avgThrottleTime Kafka kafka.producer.bufferMemoryAvailableInBytes producer.bufferMemoryAvailableInBytes Kafka kafka.producer.bufferpoolWaitTime producer.bufferpoolWaitTime Kafka kafka.producer.bytesOutPerSecond producer.bytesOutPerSecond Kafka kafka.producer.compressionRateRecordBatches producer.compressionRateRecordBatches Kafka kafka.producer.ioWaitTime producer.ioWaitTime Kafka kafka.producer.maxBytesSentPerRequestInBytes producer.maxBytesSentPerRequestInBytes Kafka kafka.producer.maxRecordSizeInBytes producer.maxRecordSizeInBytes Kafka kafka.producer.maxRequestLatencyInMilliseconds producer.maxRequestLatencyInMilliseconds Kafka kafka.producer.maxThrottleTime producer.maxThrottleTime Kafka kafka.producer.requestPerSecond producer.requestPerSecond Kafka kafka.producer.requestsWaitingResponse producer.requestsWaitingResponse Kafka kafka.producer.responsePerSecond producer.responsePerSecond Kafka kafka.producer.threadsWaiting producer.threadsWaiting Kafka kafka.consumer.avgFetchSizeInBytes consumer.avgFetchSizeInBytes Kafka kafka.consumer.avgRecordConsumedPerTopic consumer.avgRecordConsumedPerTopic Kafka kafka.consumer.avgRecordConsumedPerTopicPerSecond consumer.avgRecordConsumedPerTopicPerSecond Kafka kafka.consumer.bytesInPerSecond consumer.bytesInPerSecond Kafka kafka.consumer.fetchPerSecond consumer.fetchPerSecond Kafka kafka.consumer.hwm consumer.hwm Kafka kafka.consumer.lag consumer.lag Kafka kafka.consumer.maxFetchSizeInBytes consumer.maxFetchSizeInBytes Kafka kafka.consumer.maxLag consumer.maxLag Kafka kafka.consumer.messageConsumptionPerSecond consumer.messageConsumptionPerSecond Kafka kafka.consumer.offset consumer.offset Kafka kafka.consumer.totalLag consumer.totalLag Kafka kafka.consumerGroup.maxLag consumerGroup.maxLag Kafka kafka.consumerGroup.totalLag consumerGroup.totalLag Kubernetes k8s.apiserver.goGoroutines goGoroutines Kubernetes k8s.apiserver.goThreads goThreads Kubernetes k8s.apiserver.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.apiserver.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.controllermanager.goGoroutines goGoroutines Kubernetes k8s.controllermanager.goThreads goThreads Kubernetes k8s.controllermanager.leaderElectionMasterStatus leaderElectionMasterStatus Kubernetes k8s.controllermanager.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.controllermanager.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.etcd.goGoroutines goGoroutines Kubernetes k8s.etcd.goThreads goThreads Kubernetes k8s.etcd.mvccDbTotalSizeInBytes etcdMvccDbTotalSizeInBytes Kubernetes k8s.etcd.networkClientGrpcReceivedBytesRate etcdNetworkClientGrpcReceivedBytesRate Kubernetes k8s.etcd.networkClientGrpcSentBytesRate etcdNetworkClientGrpcSentBytesRate Kubernetes k8s.etcd.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.etcd.process.maxFds processMaxFds Kubernetes k8s.etcd.process.openFds processOpenFds Kubernetes k8s.etcd.process.processFdsUtilization processFdsUtilization Kubernetes k8s.etcd.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.etcd.serverHasLeader etcdServerHasLeader Kubernetes k8s.etcd.serverLeaderChangesSeenDelta etcdServerLeaderChangesSeenDelta Kubernetes k8s.etcd.serverProposalsAppliedDelta etcdServerProposalsAppliedDelta Kubernetes k8s.etcd.serverProposalsAppliedRate etcdServerProposalsAppliedRate Kubernetes k8s.etcd.serverProposalsCommittedDelta etcdServerProposalsCommittedDelta Kubernetes k8s.etcd.serverProposalsCommittedRate etcdServerProposalsCommittedRate Kubernetes k8s.etcd.serverProposalsFailedDelta etcdServerProposalsFailedDelta Kubernetes k8s.etcd.serverProposalsFailedRate etcdServerProposalsFailedRate Kubernetes k8s.etcd.serverProposalsPending etcdServerProposalsPending Kubernetes k8s.scheduler.goGoroutines goGoroutines Kubernetes k8s.scheduler.goThreads goThreads Kubernetes k8s.scheduler.leaderElectionMasterStatus leaderElectionMasterStatus Kubernetes k8s.scheduler.podPreemptionVictims schedulerPodPreemptionVictims Kubernetes k8s.scheduler.preemptionAttemptsDelta schedulerPreemptionAttemptsDelta Kubernetes k8s.scheduler.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.scheduler.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.container.cpuCfsPeriodsDelta containerCpuCfsPeriodsDelta Kubernetes k8s.container.cpuCfsPeriodsTotal containerCpuCfsPeriodsTotal Kubernetes k8s.container.cpuCfsThrottledPeriodsDelta containerCpuCfsThrottledPeriodsDelta Kubernetes k8s.container.cpuCfsThrottledPeriodsTotal containerCpuCfsThrottledPeriodsTotal Kubernetes k8s.container.cpuCfsThrottledSecondsDelta containerCpuCfsThrottledSecondsDelta Kubernetes k8s.container.cpuCfsThrottledSecondsTotal containerCpuCfsThrottledSecondsTotal Kubernetes k8s.container.cpuCoresUtilization cpuCoresUtilization Kubernetes k8s.container.cpuLimitCores cpuLimitCores Kubernetes k8s.container.cpuRequestedCores cpuRequestedCores Kubernetes k8s.container.cpuUsedCores cpuUsedCores Kubernetes k8s.container.fsAvailableBytes fsAvailableBytes Kubernetes k8s.container.fsCapacityBytes fsCapacityBytes Kubernetes k8s.container.fsInodes fsInodes Kubernetes k8s.container.fsInodesFree fsInodesFree Kubernetes k8s.container.fsInodesUsed fsInodesUsed Kubernetes k8s.container.fsUsedBytes fsUsedBytes Kubernetes k8s.container.fsUsedPercent fsUsedPercent Kubernetes k8s.container.isReady isReady Kubernetes k8s.container.memoryLimitBytes memoryLimitBytes Kubernetes k8s.container.memoryMappedFileBytes containerMemoryMappedFileBytes Kubernetes k8s.container.memoryRequestedBytes memoryRequestedBytes Kubernetes k8s.container.memoryUsedBytes memoryUsedBytes Kubernetes k8s.container.memoryUtilization memoryUtilization Kubernetes k8s.container.memoryWorkingSetBytes memoryWorkingSetBytes Kubernetes k8s.container.requestedCpuCoresUtilization requestedCpuCoresUtilization Kubernetes k8s.container.requestedMemoryUtilization requestedMemoryUtilization Kubernetes k8s.container.restartCount restartCount Kubernetes k8s.daemonset.createdAt createdAt Kubernetes k8s.daemonset.metadataGeneration metadataGeneration Kubernetes k8s.daemonset.podsAvailable podsAvailable Kubernetes k8s.daemonset.podsDesired podsDesired Kubernetes k8s.daemonset.podsMisscheduled podsMisscheduled Kubernetes k8s.daemonset.podsReady podsReady Kubernetes k8s.daemonset.podsScheduled podsScheduled Kubernetes k8s.daemonset.podsUnavailable podsUnavailable Kubernetes k8s.daemonset.podsUpdatedScheduled podsUpdatedScheduled Kubernetes k8s.deployment.createdAt createdAt Kubernetes k8s.deployment.podsAvailable podsAvailable Kubernetes k8s.deployment.podsDesired podsDesired Kubernetes k8s.deployment.podsMaxUnavailable podsMaxUnavailable Kubernetes k8s.deployment.podsTotal podsTotal Kubernetes k8s.deployment.podsUnavailable podsUnavailable Kubernetes k8s.deployment.podsUpdated podsUpdated Kubernetes k8s.endpoint.addressAvailable addressAvailable Kubernetes k8s.endpoint.addressNotReady addressNotReady Kubernetes k8s.endpoint.createdAt createdAt Kubernetes k8s.namespace.createdAt createdAt Kubernetes k8s.node.allocatableAttachableVolumes* allocatableAttachableVolumes* Kubernetes k8s.node.allocatableCpuCores allocatableCpuCores Kubernetes k8s.node.allocatableCpuCoresUtilization allocatableCpuCoresUtilization Kubernetes k8s.node.allocatableEphemeralStorageBytes allocatableEphemeralStorageBytes Kubernetes k8s.node.allocatableHugepages* allocatableHugepages* Kubernetes k8s.node.allocatableMemoryBytes allocatableMemoryBytes Kubernetes k8s.node.allocatableMemoryUtilization allocatableMemoryUtilization Kubernetes k8s.node.allocatablePods allocatablePods Kubernetes k8s.node.capacityAttachableVolumes* capacityAttachableVolumes* Kubernetes k8s.node.capacityCpuCores capacityCpuCores Kubernetes k8s.node.capacityEphemeralStorageBytes capacityEphemeralStorageBytes Kubernetes k8s.node.capacityHugepages* capacityHugepages* Kubernetes k8s.node.capacityMemoryBytes capacityMemoryBytes Kubernetes k8s.node.capacityPods capacityPods Kubernetes k8s.node.cpuUsedCoreMilliseconds cpuUsedCoreMilliseconds Kubernetes k8s.node.cpuUsedCores cpuUsedCores Kubernetes k8s.node.fsAvailableBytes fsAvailableBytes Kubernetes k8s.node.fsCapacityBytes fsCapacityBytes Kubernetes k8s.node.fsCapacityUtilization fsCapacityUtilization Kubernetes k8s.node.fsInodes fsInodes Kubernetes k8s.node.fsInodesFree fsInodesFree Kubernetes k8s.node.fsInodesUsed fsInodesUsed Kubernetes k8s.node.fsUsedBytes fsUsedBytes Kubernetes k8s.node.memoryAvailableBytes memoryAvailableBytes Kubernetes k8s.node.memoryMajorPageFaultsPerSecond memoryMajorPageFaultsPerSecond Kubernetes k8s.node.memoryPageFaults memoryPageFaults Kubernetes k8s.node.memoryRssBytes memoryRssBytes Kubernetes k8s.node.memoryUsedBytes memoryUsedBytes Kubernetes k8s.node.memoryWorkingSetBytes memoryWorkingSetBytes Kubernetes k8s.node.netErrorsPerSecond net.errorsPerSecond Kubernetes k8s.node.netRxBytesPerSecond net.rxBytesPerSecond Kubernetes k8s.node.netTxBytesPerSecond net.txBytesPerSecond Kubernetes k8s.node.runtimeAvailableBytes runtimeAvailableBytes Kubernetes k8s.node.runtimeCapacityBytes runtimeCapacityBytes Kubernetes k8s.node.runtimeInodes runtimeInodes Kubernetes k8s.node.runtimeInodesFree runtimeInodesFree Kubernetes k8s.node.runtimeInodesUsed runtimeInodesUsed Kubernetes k8s.node.runtimeUsedBytes runtimeUsedBytes Kubernetes k8s.pod.createdAt createdAt Kubernetes k8s.pod.isReady isReady Kubernetes k8s.pod.isScheduled isScheduled Kubernetes k8s.pod.netErrorsPerSecond net.errorsPerSecond Kubernetes k8s.pod.netRxBytesPerSecond net.rxBytesPerSecond Kubernetes k8s.pod.netTxBytesPerSecond net.txBytesPerSecond Kubernetes k8s.pod.startTime startTime Kubernetes k8s.replicaset.createdAt createdAt Kubernetes k8s.replicaset.observedGeneration observedGeneration Kubernetes k8s.replicaset.podsDesired podsDesired Kubernetes k8s.replicaset.podsFullyLabeled podsFullyLabeled Kubernetes k8s.replicaset.podsMissing podsMissing Kubernetes k8s.replicaset.podsReady podsReady Kubernetes k8s.replicaset.podsTotal podsTotal Kubernetes k8s.service.createdAt createdAt Kubernetes k8s.statefulset.createdAt createdAt Kubernetes k8s.statefulset.currentRevision currentRevision Kubernetes k8s.statefulset.metadataGeneration metadataGeneration Kubernetes k8s.statefulset.observedGeneration observedGeneration Kubernetes k8s.statefulset.podsCurrent podsCurrent Kubernetes k8s.statefulset.podsDesired podsDesired Kubernetes k8s.statefulset.podsReady podsReady Kubernetes k8s.statefulset.podsTotal podsTotal Kubernetes k8s.statefulset.podsUpdated podsUpdated Kubernetes k8s.statefulset.updateRevision updateRevision Kubernetes k8s.volume.fsAvailableBytes fsAvailableBytes Kubernetes k8s.volume.fsCapacityBytes fsCapacityBytes Kubernetes k8s.volume.fsInodes fsInodes Kubernetes k8s.volume.fsInodesFree fsInodesFree Kubernetes k8s.volume.fsInodesUsed fsInodesUsed Kubernetes k8s.volume.fsUsedBytes fsUsedBytes Kubernetes k8s.volume.fsUsedPercent fsUsedPercent Memcached memcached.server.activeSlabs activeSlabs Memcached memcached.server.avgItemSizeInBytes avgItemSizeInBytes Memcached memcached.server.bytesReadServerPerSecond bytesReadServerPerSecond Memcached memcached.server.bytesUsedServerInBytes bytesUsedServerInBytes Memcached memcached.server.bytesWrittenServerPerSecond bytesWrittenServerPerSecond Memcached memcached.server.casHitRatePerSecond casHitRatePerSecond Memcached memcached.server.casMissRatePerSecond casMissRatePerSecond Memcached memcached.server.casWrongRatePerSecond casWrongRatePerSecond Memcached memcached.server.cmdFlushRatePerSecond cmdFlushRatePerSecond Memcached memcached.server.cmdGetRatePerSecond cmdGetRatePerSecond Memcached memcached.server.cmdSetRatePerSecond cmdSetRatePerSecond Memcached memcached.server.connectionRateServerPerSecond connectionRateServerPerSecond Memcached memcached.server.connectionStructuresAllocated connectionStructuresAllocated Memcached memcached.server.currentItemsStoredServer currentItemsStoredServer Memcached memcached.server.deleteCmdNoneRemovedPerSecond deleteCmdNoneRemovedPerSecond Memcached memcached.server.deleteCmdRemovedPerSecond deleteCmdRemovedPerSecond Memcached memcached.server.evictionsPerSecond evictionsPerSecond Memcached memcached.server.getHitPercent getHitPercent Memcached memcached.server.getHitPerSecond getHitPerSecond Memcached memcached.server.getMissPerSecond getMissPerSecond Memcached memcached.server.itemsStoredPerSecond itemsStoredPerSecond Memcached memcached.server.limitBytesStorage limitBytesStorage Memcached memcached.server.limitMaxBytes limitMaxBytes Memcached memcached.server.maxConnectionLimitPerSecond serverMaxConnectionLimitPerSecond Memcached memcached.server.memAllocatedSlabsInBytes memAllocatedSlabsInBytes Memcached memcached.server.openConnectionsServer openConnectionsServer Memcached memcached.server.pointerSize pointerSize Memcached memcached.server.rusageSystem usageRate Memcached memcached.server.rusageUser executionTime Memcached memcached.server.storingItemsPercentMemory storingItemsPercentMemory Memcached memcached.server.threads threads Memcached memcached.server.uptimeInMilliseconds uptimeInMilliseconds Memcached memcached.slab.activeItemsBumpedPerSecond activeItemsBumpedPerSecond Memcached memcached.slab.casBadValPerSecond casBadValPerSecond Memcached memcached.slab.casModifiedSlabPerSecond casModifiedSlabPerSecond Memcached memcached.slab.chunkSizeInBytes chunkSizeInBytes Memcached memcached.slab.chunksPerPage chunksPerPage Memcached memcached.slab.cmdSetRateSlabPerSecond cmdSetRateSlabPerSecond Memcached memcached.slab.decrsModifySlabPerSecond decrsModifySlabPerSecond Memcached memcached.slab.deleteRateSlabPerSecond deleteRateSlabPerSecond Memcached memcached.slab.entriesReclaimedPerSecond entriesReclaimedPerSecond Memcached memcached.slab.evictionsBeforeExpirationPerSecond evictionsBeforeExpirationPerSecond Memcached memcached.slab.evictionsBeforeExplicitExpirationPerSecond evictionsBeforeExplicitExpirationPerSecond Memcached memcached.slab.expiredItemsReclaimedPerSecond expiredItemsReclaimedPerSecond Memcached memcached.slab.freedChunks freedChunks Memcached memcached.slab.freedChunksEnd freedChunksEnd Memcached memcached.slab.getHitRateSlabPerSecond getHitRateSlabPerSecond Memcached memcached.slab.incrsModifySlabPerSecond incrsModifySlabPerSecond Memcached memcached.slab.itemsCold itemsCold Memcached memcached.slab.itemsColdPerSecond itemsColdPerSecond Memcached memcached.slab.itemsDirectReclaimedPerSecond itemsDirectReclaimedPerSecond Memcached memcached.slab.itemsFreedCrawlerPerSecond itemsFreedCrawlerPerSecond Memcached memcached.slab.itemsHot itemsHot Memcached memcached.slab.itemsOldestInMilliseconds itemsOldestInMilliseconds Memcached memcached.slab.itemsRefcountLockedPerSecond itemsRefcountLockedPerSecond Memcached memcached.slab.itemsSlabClass itemsSlabClass Memcached memcached.slab.itemsTimeSinceEvictionInMilliseconds itemsTimeSinceEvictionInMilliseconds Memcached memcached.slab.itemsWarm itemsWarm Memcached memcached.slab.itemsWarmPerSecond itemsWarmPerSecond Memcached memcached.slab.memRequestedSlabInBytesPerSecond memRequestedSlabInBytesPerSecond Memcached memcached.slab.outOfMemoryPerSecond outOfMemoryPerSecond Memcached memcached.slab.selfHealedSlabPerSecond selfHealedSlabPerSecond Memcached memcached.slab.totalChunksSlab totalChunksSlab Memcached memcached.slab.totalPagesSlab totalPagesSlab Memcached memcached.slab.touchHitSlabPerSecond touchHitSlabPerSecond Memcached memcached.slab.usedChunksItems usedChunksItems Memcached memcached.slab.usedChunksPerSecond usedChunksPerSecond Memcached memcached.slab.validItemsEvictedPerSecond validItemsEvictedPerSecond MongoDB mongo.index.accesses collection.indexAccesses MongoDB mongo.index.sizeInBytes collection.indexSizeInBytes MongoDB mongo.collection.avgObjSizeInBytes collection.avgObjSizeInBytes MongoDB mongo.collection.capped collection.capped MongoDB mongo.collection.count collection.count MongoDB mongo.collection.max collection.max MongoDB mongo.collection.maxSizeInBytes collection.maxSizeInBytes MongoDB mongo.collection.nindexes collection.nindexes MongoDB mongo.collection.sizeInBytes collection.sizeInBytes MongoDB mongo.collection.storageSizeInBytes collection.storageSizeInBytes MongoDB mongo.configServer.asserts.messagesPerSecond asserts.messagesPerSecond MongoDB mongo.configServer.asserts.regularPerSecond asserts.regularPerSecond MongoDB mongo.configServer.asserts.rolloversPerSecond asserts.rolloversPerSecond MongoDB mongo.configServer.asserts.userPerSecond asserts.userPerSecond MongoDB mongo.configServer.asserts.warningPerSecond asserts.warningPerSecond MongoDB mongo.configServer.commands.countFailedPerSecond commands.countFailedPerSecond MongoDB mongo.configServer.commands.countPerSecond commands.countPerSecond MongoDB mongo.configServer.commands.createIndexesFailedPerSecond commands.createIndexesFailedPerSecond MongoDB mongo.configServer.commands.createIndexesPerSecond commands.createIndexesPerSecond MongoDB mongo.configServer.commands.deleteFailedPerSecond commands.deleteFailedPerSecond MongoDB mongo.configServer.commands.deletePerSecond commands.deletePerSecond MongoDB mongo.configServer.commands.evalFailedPerSecond commands.evalFailedPerSecond MongoDB mongo.configServer.commands.evalPerSecond commands.evalPerSecond MongoDB mongo.configServer.commands.findAndModifyFailedPerSecond commands.findAndModifyFailedPerSecond MongoDB mongo.configServer.commands.findAndModifyPerSecond commands.findAndModifyPerSecond MongoDB mongo.configServer.commands.insertFailedPerSecond commands.insertFailedPerSecond MongoDB mongo.configServer.commands.insertPerSecond commands.insertPerSecond MongoDB mongo.configServer.commands.updateFailedPerSecond commands.updateFailedPerSecond MongoDB mongo.configServer.commands.updatePerSecond commands.updatePerSecond MongoDB mongo.configServer.connections.available connections.available MongoDB mongo.configServer.connections.current connections.current MongoDB mongo.configServer.connections.totalCreated connections.totalCreated MongoDB mongo.configServer.cursor.openNoTimeout cursor.openNoTimeout MongoDB mongo.configServer.cursor.openPinned cursor.openPinned MongoDB mongo.configServer.cursor.openTotal cursor.openTotal MongoDB mongo.configServer.cursor.timedOutPerSecond cursor.timedOutPerSecond MongoDB mongo.configServer.document.deletedPerSecond document.deletedPerSecond MongoDB mongo.configServer.document.insertedPerSecond document.insertedPerSecond MongoDB mongo.configServer.document.returnedPerSecond document.returnedPerSecond MongoDB mongo.configServer.document.updatedPerSecond document.updatedPerSecond MongoDB mongo.configServer.dur.commits dur.commits MongoDB mongo.configServer.dur.commitsInWriteLock dur.commitsInWriteLock MongoDB mongo.configServer.dur.compression dur.compression MongoDB mongo.configServer.dur.earlyCommits dur.earlyCommits MongoDB mongo.configServer.dur.preparingInMilliseconds dur.preparingInMilliseconds MongoDB mongo.configServer.dur.remappingInMilliseconds dur.remappingInMilliseconds MongoDB mongo.configServer.dur.timeCollectedCommitsInMilliseconds dur.timeCollectedCommitsInMilliseconds MongoDB mongo.configServer.dur.writingDataFilesInMilliseconds dur.writingDataFilesInMilliseconds MongoDB mongo.configServer.dur.writingJournalInMilliseconds dur.writingJournalInMilliseconds MongoDB mongo.configServer.flush.averageInMilliseconds flush.averageInMilliseconds MongoDB mongo.configServer.flush.flushesDisk flush.flushesDisk MongoDB mongo.configServer.flush.lastInMilliseconds flush.lastInMilliseconds MongoDB mongo.configServer.flush.totalInMilliseconds flush.totalInMilliseconds MongoDB mongo.configServer.getlasterror.wtimeMillisPerSecond getlasterror.wtimeMillisPerSecond MongoDB mongo.configServer.getlasterror.wtimeoutsPerSecond getlasterror.wtimeoutsPerSecond MongoDB mongo.configServer.globallock.activeClientsReaders globallock.activeClientsReaders MongoDB mongo.configServer.globallock.activeClientsTotal globallock.activeClientsTotal MongoDB mongo.configServer.globallock.activeClientsWriters globallock.activeClientsWriters MongoDB mongo.configServer.globallock.currentQueueReaders globallock.currentQueueReaders MongoDB mongo.configServer.globallock.currentQueueTotal globallock.currentQueueTotal MongoDB mongo.configServer.globallock.currentQueueWriters globallock.currentQueueWriters MongoDB mongo.configServer.globallock.totalTime globallock.totaltime MongoDB mongo.configServer.locks.collectionAcquireExclusive locks.collectionAcquireExclusive MongoDB mongo.configServer.locks.collectionAcquireIntentExclusive locks.collectionAcquireIntentExclusive MongoDB mongo.configServer.locks.collectionAcquireIntentShared locks.collectionAcquireIntentShared MongoDB mongo.configServer.locks.collectionAcquireWaitCountExclusive locks.collectionAcquireWaitCountExclusive MongoDB mongo.configServer.locks.collectionTimeAcquiringMicrosExclusive locks.collectionTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.databaseAcquireExclusive locks.databaseAcquireExclusive MongoDB mongo.configServer.locks.databaseAcquireIntentExclusive locks.databaseAcquireIntentExclusive MongoDB mongo.configServer.locks.databaseAcquireIntentShared locks.databaseAcquireIntentShared MongoDB mongo.configServer.locks.databaseAcquireShared locks.databaseAcquireShared MongoDB mongo.configServer.locks.databaseAcquireWaitExclusive locks.databaseAcquireWaitExclusive MongoDB mongo.configServer.locks.databaseAcquireWaitIntentExclusive locks.databaseAcquireWaitIntentExclusive MongoDB mongo.configServer.locks.databaseAcquireWaitIntentShared locks.databaseAcquireWaitIntentShared MongoDB mongo.configServer.locks.databaseAcquireWaitShared locks.databaseAcquireWaitShared MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosExclusive locks.databaseTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosIntentExclusive locks.databaseTimeAcquiringMicrosIntentExclusive MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosIntentShared locks.databaseTimeAcquiringMicrosIntentShared MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosShared locks.databaseTimeAcquiringMicrosShared MongoDB mongo.configServer.locks.globalAcquireExclusive locks.globalAcquireExclusive MongoDB mongo.configServer.locks.globalAcquireIntentExclusive locks.globalAcquireIntentExclusive MongoDB mongo.configServer.locks.globalAcquireIntentShared locks.globalAcquireIntentShared MongoDB mongo.configServer.locks.globalAcquireShared locks.globalAcquireShared MongoDB mongo.configServer.locks.globalAcquireWaitExclusive locks.globalAcquireWaitExclusive MongoDB mongo.configServer.locks.globalAcquireWaitIntentExclusive locks.globalAcquireWaitIntentExclusive MongoDB mongo.configServer.locks.globalAcquireWaitIntentShared locks.globalAcquireWaitIntentShared MongoDB mongo.configServer.locks.globalAcquireWaitShared locks.globalAcquireWaitShared MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosExclusive locks.globalTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosIntentExclusive locks.globalTimeAcquiringMicrosIntentExclusive MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosIntentShared locks.globalTimeAcquiringMicrosIntentShared MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosShared locks.globalTimeAcquiringMicrosShared MongoDB mongo.configServer.locks.metadataAcquireExclusive locks.metadataAcquireExclusive MongoDB mongo.configServer.locks.oplogAcquireExclusive locks.oplogAcquireExclusive MongoDB mongo.configServer.locks.oplogAcquireIntentExclusive locks.oplogAcquireIntentExclusive MongoDB mongo.configServer.locks.oplogAcquireIntentShared locks.oplogAcquireIntentShared MongoDB mongo",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 358.8581,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": "New Relic Integrations Metrics The following table contains the metrics we collect for our <em>infrastructure</em> integrations. Integration Dimensional Metric Name (new) Sample Metric Name (previous) Agent host.cpuIdlePercent cpuIdlePercent Agent host.cpuIoWaitPercent cpuIOWaitPercent Agent host.cpuPercent"
      },
      "id": "603e8a8a64441f69a34e8841"
    },
    {
      "sections": [
        "APM data in infrastructure monitoring",
        "How to integrate APM and infrastructure data",
        "View APM charts",
        "Filter by application data",
        "Tip",
        "Switch between infrastructure and APM",
        "APM data in Inventory and Events",
        "View host data in APM",
        "Troubleshoot missing APM data"
      ],
      "title": "APM data in infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "ac221ae748f8f2eb5a0ab7373853c5ea78974e41",
      "image": "https://docs.newrelic.com/static/4ab30e9528ae8a5121a1691143f80d44/ff42b/Infrastructure-APM-application-data-chart.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/apm-data-infrastructure-monitoring/",
      "published_at": "2021-06-14T21:14:34Z",
      "updated_at": "2021-03-16T07:33:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The integration of APM and infrastructure data lets you see your APM data and infrastructure data side by side so you can find the root cause of problems more quickly. Let's look at how the APM-Infrastructure integration works and how to make use of the shared data. The main ways to find and use APM data in infrastructure monitoring are: View APM charts on Infrastructure monitoring UI pages Filter hosts by application data Switch between Infrastructure and APM Examine APM data in Inventory and Events pages Infrastructure data appears in APM in the host table on the APM Summary page. How to integrate APM and infrastructure data For APM and infrastructure data to be integrated, all of the following must be true: The APM agent and the infrastructure agent must be installed on the same host. Both agents must use the same New Relic license key. They must use the same hostname. If the integration is not working, see Troubleshooting the APM-Infrastructure integration. View APM charts When your APM and infrastructure data is linked, you have access to APM data charts on these Infrastructure monitoring UI pages: Hosts, Network, Storage, and Processes. To switch to different charts: select the dropdown beside a chart's name and choose a new chart. Application-related charts will be near the top. one.newrelic.com > Infrastructure > Hosts: If your APM and Infrastructure data is linked, the charts in Infrastructure monitoring can be changed to show your application data. Filter by application data When your APM and infrastructure data is linked, you can filter displayed host data using Applications: From the host filter, select Applications. Select the application you want to filter on. Tip On the Hosts page, you can also filter by selecting items in the Applications column. Switch between infrastructure and APM When your APM and infrastructure accounts are linked, you can switch over from infrastructure to APM and vice versa for the same selected time range. You can switch from infrastructure to APM from these locations: From the host filter Applications menu On the Hosts page, when selecting applications in the Applications table column. You can switch from APM to infrastructure from the host table on the APM Summary page. APM data in Inventory and Events When your APM and infrastructure data is linked, you can view and filter on application data on the Infrastructure monitoring UI's Inventory page and the Events page. View host data in APM When your APM and infrastructure data is linked, you have more available host data in APM. The APM Summary page contains a table with data about your app's hosts and instances, including: Apdex Response time Throughput Error rate CPU usage Memory You can toggle between a table view or breakout metric details for the individual hosts by selecting View table or Break out each metric by host. For more information on host data on the APM Summary page, see host details. Troubleshoot missing APM data APM/Infrastructure integration should happen automatically if you have both the APM agent and the infrastructure agent installed on the same host(s) and they use the same New Relic license key and have the same hostname set. If you do not see APM data in infrastructure monitoring, see Troubleshooting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.4204,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM <em>data</em> in <em>infrastructure</em> monitoring",
        "sections": "APM <em>data</em> in <em>infrastructure</em> monitoring",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": "The integration of APM and <em>infrastructure</em> <em>data</em> lets you see <em>your</em> APM <em>data</em> and <em>infrastructure</em> <em>data</em> side by side so you can find the root cause of problems more quickly. Let&#x27;s look at how the APM-<em>Infrastructure</em> integration works and how to make use of the shared <em>data</em>. The main ways to find and use"
      },
      "id": "603e88b2e7b9d246932a07f6"
    },
    {
      "sections": [
        "Manage infrastructure data reporting"
      ],
      "title": "Manage infrastructure data reporting",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "7cd87ba8f7686e9233f4171021607d499bf6bc72",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/manage-infrastructure-data-reporting/",
      "published_at": "2021-06-14T21:15:46Z",
      "updated_at": "2021-03-16T07:33:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the infrastructure agent or on-host integrations that report data via the infrastructure agent, there are several ways to configure data reporting. Here are two common options for managing data reporting: Enable/disable process metrics Select specific attributes to report For other agent configuration options, see Configuration. For our infrastructure integrations, you can also change the frequency of data reporting: For on-host integrations: use a specific integration's interval configuration setting. For cloud integrations (AWS, Azure, Google Cloud): edit the polling frequency. For more about New Relic data management in general, see Manage data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.4204,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>infrastructure</em> <em>data</em> reporting",
        "sections": "<em>Manage</em> <em>infrastructure</em> <em>data</em> reporting",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": " configuration options, see Configuration. For our <em>infrastructure</em> integrations, you can also change the frequency of <em>data</em> reporting: For on-host integrations: use a specific integration&#x27;s interval configuration setting. For cloud integrations (AWS, Azure, Google Cloud): edit the polling frequency. For more about New Relic <em>data</em> management in general, see <em>Manage</em> <em>data</em>."
      },
      "id": "603e775a196a67f470a83de4"
    }
  ],
  "/docs/infrastructure/manage-your-data/data-instrumentation/host-integrations-metrics": [
    {
      "sections": [
        "Default infrastructure monitoring data",
        "Important",
        "Infrastructure events",
        "Supported Linux storage systems",
        "Supported Windows storage systems",
        "Query infrastructure data",
        "Manage data",
        "Add custom attributes",
        "Common Amazon EC2 attributes",
        "awsRegion",
        "awsAvailabilityZone",
        "ec2InstanceType",
        "ec2InstanceId",
        "ec2AmiId",
        "ec2SubnetId",
        "ec2VpcId",
        "Other Amazon EC2 attributes"
      ],
      "title": "Default infrastructure monitoring data ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "01647189a48892103f4dc6abe07ce29d5fc13f0d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/default-infrastructure-monitoring-data/",
      "published_at": "2021-06-14T21:14:34Z",
      "updated_at": "2021-03-30T08:36:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of April 12, 2021, we are upgrading Insights to an improved web and mobile experience! All of your Insights URLs will be redirected automatically to the corresponding dashboards in New Relic One. For more details about this migration and how you can easily plan for this transition, see our Explorers Hub post. New Relic's infrastructure monitoring agent collects and displays data using six primary events, each with associated attributes that represent assorted metrics and metadata. Understanding infrastructure data can help you: Better understand our infrastructure monitoring UI. Manage your infrastructure data. Create better host filter sets. Run better queries of your data. Set up better monitoring solutions using custom attributes. Infrastructure events The following are events reported by default by the infrastructure agent and some infrastructure integrations. The attributes attached to these events are the metadata and metrics used to create our infrastructure UI visualizations. You can also create custom queries and charts of this data. If you're using integrations, see that integration's doc for more on reported data. For common AWS attributes, see AWS data. Select an event name in the following table to see its attributes. Event Description SystemSample SystemSample contains data describing the current overall state of the entire server, including CPU, memory, disk, and network. We take a snapshot of this data every 5 seconds and package it into a SystemSample event, which is then sent to New Relic. This data appears in the Hosts UI page. ProcessSample ProcessSample gathers detailed resource usage information from programs running on a single system. We take a snapshot of this data every 20 seconds for every active process and package it into a ProcessSample event, which is then sent to New Relic. This data appears on the Processes UI page. Important Process metrics are not sent to New Relic by default for accounts created after July 20, 2020. Enable process metrics to get this data into the Infrastructure monitoring UI. StorageSample StorageSample represents a single storage device associated with a server. Each sample gathers descriptive information about the device, the type of file system it uses, and its current usage and capacity. We take a snapshot of this data every 20 seconds for each mounted file system and package it into a StorageSample event, which is then sent to New Relic. This data appears on the Storage UI page. Important If your server uses disks with file systems other than the supported file systems in the following table, StorageSample events will not be generated for those disks. Supported Linux storage systems Supported Linux storage file systems: xfs vxfs btrfs ext ext2 ext3 ext4 hfs Supported Windows storage systems Supported Windows storage file systems: NTFS ReFS (version 1.0.976 and higher) NetworkSample NetworkSample captures the descriptive and state information for each network device associated with a server. It includes the device's interface and address information, as well as current usage data. We take a snapshot of this data every 10 seconds for each attached network interface and package it into a NetworkSample event, which is then sent to New Relic. This data appears on the Network UI page. ContainerSample ContainerSample collects the descriptive and state information for each Docker container. It includes the container's ID, name, image, image name, as well metrics about CPU, memory and networking. We take a snapshot of this data every 15 seconds for each container and package it into a ContainerSample event, which is then sent to New Relic. This data appears on the Containers UI page. For more information, see Docker monitoring. InfrastructureEvent InfrastructureEvent describes changes (deltas) that occur in a system's live state. When an inventory or system state is added, removed, or changed, New Relic will produce an InfrastructureEvent that logs that activity. This data appears on the Events UI page. To learn about infrastructure integration data, see the documentation for a specific integration. If an AWS integration is enabled, your infrastructure events may also have AWS attributes attached. Query infrastructure data You can query your infrastructure data to troubleshoot a problem or create a chart, or to understand what data is available. For example, to see what data is attached to ProcessSample, you would run this NRQL query: SELECT * FROM ProcessSample Copy You can also query infrastructure using dimensional metrics. Manage data For tips on managing data ingest and reporting, see Manage infrastructure data. Add custom attributes You can create custom attributes in the infrastructure agent's YAML file. Use this metadata to: Create infrastructure filter sets Populate the Group by menu Annotate your infrastructure data Common Amazon EC2 attributes If you connect your Amazon Elastic Compute Cloud (EC2) account to our infrastructure monitoring, we report data from your Amazon EC2 instances. Amazon EC2-related attributes are common attributes that can be used in any event. These attributes are drawn from the EC2 API. No CloudWatch information is collected. These attributes and their values are subject to change if Amazon changes the data they expose. awsRegion The region (determined by Amazon Web Services) where the AWS server exists. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. awsAvailabilityZone The availability zone (determined by Amazon Web Services) where the AWS server exists. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2InstanceType The Amazon Web Services instance type, displayed in AWS-specific codes. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2InstanceId The Amazon Web Services instance's unique identifying number for the server. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2AmiId The Amazon Machine Image (AMI) identification number of the image used by Amazon Web Services to bootstrap the Amazon EC2 instance. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2SubnetId The networking sub-net identifier on which the server is connected. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2VpcId The Virtual Private Cloud identifier (if any) for this server. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. Other Amazon EC2 attributes If Amazon Web Services changes the metadata they make available to New Relic, other attributes and values collected also may be available.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.37016,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Default <em>infrastructure</em> monitoring <em>data</em> ",
        "sections": "Default <em>infrastructure</em> monitoring <em>data</em>",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": ". <em>Manage</em> <em>your</em> <em>infrastructure</em> <em>data</em>. Create better host filter sets. Run better queries of <em>your</em> <em>data</em>. Set up better monitoring solutions using custom attributes. <em>Infrastructure</em> events The following are events reported by default by the <em>infrastructure</em> agent and some <em>infrastructure</em> integrations"
      },
      "id": "6043edcd28ccbcfa8a2c6086"
    },
    {
      "sections": [
        "APM data in infrastructure monitoring",
        "How to integrate APM and infrastructure data",
        "View APM charts",
        "Filter by application data",
        "Tip",
        "Switch between infrastructure and APM",
        "APM data in Inventory and Events",
        "View host data in APM",
        "Troubleshoot missing APM data"
      ],
      "title": "APM data in infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "ac221ae748f8f2eb5a0ab7373853c5ea78974e41",
      "image": "https://docs.newrelic.com/static/4ab30e9528ae8a5121a1691143f80d44/ff42b/Infrastructure-APM-application-data-chart.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/apm-data-infrastructure-monitoring/",
      "published_at": "2021-06-14T21:14:34Z",
      "updated_at": "2021-03-16T07:33:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The integration of APM and infrastructure data lets you see your APM data and infrastructure data side by side so you can find the root cause of problems more quickly. Let's look at how the APM-Infrastructure integration works and how to make use of the shared data. The main ways to find and use APM data in infrastructure monitoring are: View APM charts on Infrastructure monitoring UI pages Filter hosts by application data Switch between Infrastructure and APM Examine APM data in Inventory and Events pages Infrastructure data appears in APM in the host table on the APM Summary page. How to integrate APM and infrastructure data For APM and infrastructure data to be integrated, all of the following must be true: The APM agent and the infrastructure agent must be installed on the same host. Both agents must use the same New Relic license key. They must use the same hostname. If the integration is not working, see Troubleshooting the APM-Infrastructure integration. View APM charts When your APM and infrastructure data is linked, you have access to APM data charts on these Infrastructure monitoring UI pages: Hosts, Network, Storage, and Processes. To switch to different charts: select the dropdown beside a chart's name and choose a new chart. Application-related charts will be near the top. one.newrelic.com > Infrastructure > Hosts: If your APM and Infrastructure data is linked, the charts in Infrastructure monitoring can be changed to show your application data. Filter by application data When your APM and infrastructure data is linked, you can filter displayed host data using Applications: From the host filter, select Applications. Select the application you want to filter on. Tip On the Hosts page, you can also filter by selecting items in the Applications column. Switch between infrastructure and APM When your APM and infrastructure accounts are linked, you can switch over from infrastructure to APM and vice versa for the same selected time range. You can switch from infrastructure to APM from these locations: From the host filter Applications menu On the Hosts page, when selecting applications in the Applications table column. You can switch from APM to infrastructure from the host table on the APM Summary page. APM data in Inventory and Events When your APM and infrastructure data is linked, you can view and filter on application data on the Infrastructure monitoring UI's Inventory page and the Events page. View host data in APM When your APM and infrastructure data is linked, you have more available host data in APM. The APM Summary page contains a table with data about your app's hosts and instances, including: Apdex Response time Throughput Error rate CPU usage Memory You can toggle between a table view or breakout metric details for the individual hosts by selecting View table or Break out each metric by host. For more information on host data on the APM Summary page, see host details. Troubleshoot missing APM data APM/Infrastructure integration should happen automatically if you have both the APM agent and the infrastructure agent installed on the same host(s) and they use the same New Relic license key and have the same hostname set. If you do not see APM data in infrastructure monitoring, see Troubleshooting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.4204,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM <em>data</em> in <em>infrastructure</em> monitoring",
        "sections": "APM <em>data</em> in <em>infrastructure</em> monitoring",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": "The integration of APM and <em>infrastructure</em> <em>data</em> lets you see <em>your</em> APM <em>data</em> and <em>infrastructure</em> <em>data</em> side by side so you can find the root cause of problems more quickly. Let&#x27;s look at how the APM-<em>Infrastructure</em> integration works and how to make use of the shared <em>data</em>. The main ways to find and use"
      },
      "id": "603e88b2e7b9d246932a07f6"
    },
    {
      "sections": [
        "Manage infrastructure data reporting"
      ],
      "title": "Manage infrastructure data reporting",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "7cd87ba8f7686e9233f4171021607d499bf6bc72",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/manage-infrastructure-data-reporting/",
      "published_at": "2021-06-14T21:15:46Z",
      "updated_at": "2021-03-16T07:33:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the infrastructure agent or on-host integrations that report data via the infrastructure agent, there are several ways to configure data reporting. Here are two common options for managing data reporting: Enable/disable process metrics Select specific attributes to report For other agent configuration options, see Configuration. For our infrastructure integrations, you can also change the frequency of data reporting: For on-host integrations: use a specific integration's interval configuration setting. For cloud integrations (AWS, Azure, Google Cloud): edit the polling frequency. For more about New Relic data management in general, see Manage data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.4204,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>infrastructure</em> <em>data</em> reporting",
        "sections": "<em>Manage</em> <em>infrastructure</em> <em>data</em> reporting",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": " configuration options, see Configuration. For our <em>infrastructure</em> integrations, you can also change the frequency of <em>data</em> reporting: For on-host integrations: use a specific integration&#x27;s interval configuration setting. For cloud integrations (AWS, Azure, Google Cloud): edit the polling frequency. For more about New Relic <em>data</em> management in general, see <em>Manage</em> <em>data</em>."
      },
      "id": "603e775a196a67f470a83de4"
    }
  ],
  "/docs/infrastructure/manage-your-data/data-instrumentation/manage-infrastructure-data-reporting": [
    {
      "sections": [
        "On-host integrations metrics",
        "New Relic Integrations Metrics"
      ],
      "title": "On-host integrations metrics",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "fe96c0c4950380504b1a33c3ad861bcb17507cba",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/host-integrations-metrics/",
      "published_at": "2021-06-15T01:04:56Z",
      "updated_at": "2021-06-15T01:04:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Integrations Metrics The following table contains the metrics we collect for our infrastructure integrations. Integration Dimensional Metric Name (new) Sample Metric Name (previous) Agent host.cpuIdlePercent cpuIdlePercent Agent host.cpuIoWaitPercent cpuIOWaitPercent Agent host.cpuPercent cpuPercent Agent host.cpuStealPercent cpuStealPercent Agent host.cpuSystemPercent cpuSystemPercent Agent host.cpuUserPercent cpuUserPercent Agent host.disk.avgQueueLen avgQueueLen Agent host.disk.avgReadQueueLen avgReadQueueLen Agent host.disk.avgWriteQueueLen avgWriteQueueLen Agent host.disk.currentQueueLen currentQueueLen Agent host.disk.freeBytes diskFreeBytes Agent host.disk.freePercent diskFreePercent Agent host.disk.inodesFree inodesFree Agent host.disk.inodesTotal inodesTotal Agent host.disk.inodesUsed inodesUsed Agent host.disk.inodesUsedPercent inodesUsedPercent Agent host.disk.readBytesPerSecond readBytesPerSecond Agent host.disk.readIoPerSecond readIoPerSecond Agent host.disk.readUtilizationPercent readUtilizationPercent Agent host.disk.readWriteBytesPerSecond readWriteBytesPerSecond Agent host.disk.totalBytes diskTotalBytes Agent host.disk.totalUtilizationPercent totalUtilizationPercent Agent host.disk.usedBytes diskUsedBytes Agent host.disk.usedPercent diskUsedPercent Agent host.disk.writeBytesPerSecond writeBytesPerSecond Agent host.disk.writeIoPerSecond writeIoPerSecond Agent host.disk.writeUtilizationPercent writeUtilizationPercent Agent host.diskFreeBytes diskFreeBytes Agent host.diskFreePercent diskFreePercent Agent host.diskReadsPerSecond diskReadsPerSecond Agent host.diskReadUtilizationPercent diskReadUtilizationPercent Agent host.diskTotalBytes diskTotalBytes Agent host.diskUsedBytes diskUsedBytes Agent host.diskUsedPercent diskUsedPercent Agent host.diskUtilizationPercent diskUtilizationPercent Agent host.diskWritesPerSecond diskWritesPerSecond Agent host.diskWriteUtilizationPercent diskWriteUtilizationPercent Agent host.loadAverageFifteenMinute loadAverageFifteenMinute Agent host.loadAverageFiveMinute loadAverageFiveMinute Agent host.loadAverageOneMinute loadAverageOneMinute Agent host.memoryFreeBytes memoryFreeBytes Agent host.memoryFreePercent memoryFreePercent Agent host.memoryTotalBytes memoryTotalBytes Agent host.memoryUsedBytes memoryUsedBytes Agent host.memoryUsedPercent memoryUsedPercent Agent host.net.receiveBytesPerSecond receiveBytesPerSecond Agent host.net.receiveDroppedPerSecond receiveDroppedPerSecond Agent host.net.receiveErrorsPerSecond receiveErrorsPerSecond Agent host.net.receivePacketsPerSecond receivePacketsPerSecond Agent host.net.transmitBytesPerSecond transmitBytesPerSecond Agent host.net.transmitDroppedPerSecond transmitDroppedPerSecond Agent host.net.transmitErrorsPerSecond transmitErrorsPerSecond Agent host.net.transmitPacketsPerSecond transmitPacketsPerSecond Agent host.process.cpuPercent cpuPercent Agent host.process.cpuSystemPercent cpuSystemPercent Agent host.process.cpuUserPercent cpuUserPercent Agent host.process.fileDescriptorCount fileDescriptorCount Agent host.process.ioReadBytesPerSecond ioReadBytesPerSecond Agent host.process.ioReadCountPerSecond ioReadCountPerSecond Agent host.process.ioTotalReadBytes ioTotalReadBytes Agent host.process.ioTotalReadCount ioTotalReadCount Agent host.process.ioTotalWriteBytes ioTotalWriteBytes Agent host.process.ioTotalWriteCount ioTotalWriteCount Agent host.process.ioWriteBytesPerSecond ioWriteBytesPerSecond Agent host.process.ioWriteCountPerSecond ioWriteCountPerSecond Agent host.process.memoryResidentSizeBytes memoryResidentSizeBytes Agent host.process.memoryVirtualSizeBytes memoryVirtualSizeBytes Agent host.process.threadCount threadCount Agent host.swapFreeBytes swapFreeBytes Agent host.swapTotalBytes swapTotalBytes Agent host.swapUsedBytes swapUsedBytes Apache apache.server.busyWorkers server.busyWorkers Apache apache.server.idleWorkers server.idleWorkers Apache apache.server.net.bytesPerSecond net.bytesPerSecond Apache apache.server.net.requestsPerSecond net.requestsPerSecond Apache apache.server.scoreboard.closingWorkers server.scoreboard.closingWorkers Apache apache.server.scoreboard.dnsLookupWorkers server.scoreboard.dnsLookupWorkers Apache apache.server.scoreboard.finishingWorkers server.scoreboard.finishingWorkers Apache apache.server.scoreboard.idleCleanupWorkers server.scoreboard.idleCleanupWorkers Apache apache.server.scoreboard.keepAliveWorkers server.scoreboard.keepAliveWorkers Apache apache.server.scoreboard.loggingWorkers server.scoreboard.loggingWorkers Apache apache.server.scoreboard.readingWorkers server.scoreboard.readingWorkers Apache apache.server.scoreboard.startingWorkers server.scoreboard.startingWorkers Apache apache.server.scoreboard.totalWorkers server.scoreboard.totalWorkers Apache apache.server.scoreboard.writingWorkers server.scoreboard.writingWorkers Cassandra cassandra.node.allMemtablesOffHeapSizeBytes db.allMemtablesOffHeapSizeBytes Cassandra cassandra.node.allMemtablesOnHeapSizeBytes db.allMemtablesOnHeapSizeBytes Cassandra cassandra.node.client.connectedNativeClients client.connectedNativeClients Cassandra cassandra.node.commitLogCompletedTasksPerSecond db.commitLogCompletedTasksPerSecond Cassandra cassandra.node.commitLogPendingTasks db.commitLogPendindTasks Cassandra cassandra.node.commitLogTotalSizeBytes db.commitLogTotalSizeBytes Cassandra cassandra.node.droppedBatchRemoveMessagesPerSecond db.droppedBatchRemoveMessagesPerSecond Cassandra cassandra.node.droppedBatchStoreMessagesPerSecond db.droppedBatchStoreMessagesPerSecond Cassandra cassandra.node.droppedCounterMutationMessagesPerSecond db.droppedCounterMutationMessagesPerSecond Cassandra cassandra.node.droppedHintMessagesPerSecond db.droppedHintMessagesPerSecond Cassandra cassandra.node.droppedMutationMessagesPerSecond db.droppedMutationMessagesPerSecond Cassandra cassandra.node.droppedPagedRangeMessagesPerSecond db.droppedPagedRangeMessagesPerSecond Cassandra cassandra.node.droppedRangeSliceMessagesPerSecond db.droppedRangeSliceMessagesPerSecond Cassandra cassandra.node.droppedReadMessagesPerSecond db.droppedReadMessagesPerSecond Cassandra cassandra.node.droppedReadRepairMessagesPerSecond db.droppedReadRepairMessagesPerSecond Cassandra cassandra.node.droppedRequestResponseMessagesPerSecond db.droppedRequestResponseMessagesPerSecond Cassandra cassandra.node.droppedTraceMessagesPerSecond db.droppedTraceMessagesPerSecond Cassandra cassandra.node.keyCacheCapacityBytes db.keyCacheCapacityBytes Cassandra cassandra.node.keyCacheHitRate db.keyCacheHitRate Cassandra cassandra.node.keyCacheHitsPerSecond db.keyCacheHitsPerSecond Cassandra cassandra.node.keyCacheRequestsPerSecond db.keyCacheRequestsPerSecond Cassandra cassandra.node.keyCacheSizeBytes db.keyCacheSizeBytes Cassandra cassandra.node.liveSsTableCount db.liveSSTableCount Cassandra cassandra.node.loadBytes db.loadBytes Cassandra cassandra.node.query.casReadRequestsPerSecond query.CASReadRequestsPerSecond Cassandra cassandra.node.query.casWriteRequestsPerSecond query.CASWriteRequestsPerSecond Cassandra cassandra.node.query.rangeSliceRequestsPerSecond query.rangeSliceRequestsPerSecond Cassandra cassandra.node.query.rangeSliceTimeoutsPerSecond query.rangeSliceTimeoutsPerSecond Cassandra cassandra.node.query.rangeSliceUnavailablesPerSecond query.rangeSliceUnavailablesPerSecond Cassandra cassandra.node.query.readLatency50ThPercentileMilliseconds query.readLatency50thPercentileMilliseconds Cassandra cassandra.node.query.readLatency75ThPercentileMilliseconds query.readLatency75thPercentileMilliseconds Cassandra cassandra.node.query.readLatency95ThPercentileMilliseconds query.readLatency95thPercentileMilliseconds Cassandra cassandra.node.query.readLatency98ThPercentileMilliseconds query.readLatency98thPercentileMilliseconds Cassandra cassandra.node.query.readLatency999ThPercentileMilliseconds query.readLatency999thPercentileMilliseconds Cassandra cassandra.node.query.readLatency99ThPercentileMilliseconds query.readLatency99thPercentileMilliseconds Cassandra cassandra.node.query.readRequestsPerSecond query.readRequestsPerSecond Cassandra cassandra.node.query.readTimeoutsPerSecond query.readTimeoutsPerSecond Cassandra cassandra.node.query.readUnavailablesPerSecond query.readUnavailablesPerSecond Cassandra cassandra.node.query.viewWriteRequestsPerSecond query.viewWriteRequestsPerSecond Cassandra cassandra.node.query.writeLatency50ThPercentileMilliseconds query.writeLatency50thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency75ThPercentileMilliseconds query.writeLatency75thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency95ThPercentileMilliseconds query.writeLatency95thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency98ThPercentileMilliseconds query.writeLatency98thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency999ThPercentileMilliseconds query.writeLatency999thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency99ThPercentileMilliseconds query.writeLatency99thPercentileMilliseconds Cassandra cassandra.node.query.writeRequestsPerSecond query.writeRequestsPerSecond Cassandra cassandra.node.query.writeTimeoutsPerSecond query.writeTimeoutsPerSecond Cassandra cassandra.node.query.writeUnavailablesPerSecond query.writeUnavailablesPerSecond Cassandra cassandra.node.rowCacheCapacityBytes db.rowCacheCapacityBytes Cassandra cassandra.node.rowCacheHitRate db.rowCacheHitRate Cassandra cassandra.node.rowCacheHitsPerSecond db.rowCacheHitsPerSecond Cassandra cassandra.node.rowCacheRequestsPerSecond db.rowCacheRequestsPerSecond Cassandra cassandra.node.rowCacheSizeBytes db.rowCacheSizeBytes Cassandra cassandra.node.storage.exceptionCount storage.exceptionCount Cassandra cassandra.node.threadPool.antiEntropyStage.activeTasks db.threadpool.internalAntiEntropyStageActiveTasks Cassandra cassandra.node.threadPool.antiEntropyStage.completedTasks db.threadpool.internalAntiEntropyStageCompletedTasks Cassandra cassandra.node.threadPool.antiEntropyStage.currentlyBlockedTasks db.threadpool.internalAntiEntropyStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.antiEntropyStage.pendingTasks db.threadpool.internalAntiEntropyStagePendingTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.activeTasks db.threadpool.internalCacheCleanupExecutorActiveTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.completedTasks db.threadpool.internalCacheCleanupExecutorCompletedTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.currentlyBlockedTasks db.threadpool.internalCacheCleanupExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.pendingTasks db.threadpool.internalCacheCleanupExecutorPendingTasks Cassandra cassandra.node.threadPool.compactionExecutor.activeTasks db.threadpool.internalCompactionExecutorActiveTasks Cassandra cassandra.node.threadPool.compactionExecutor.completedTasks db.threadpool.internalCompactionExecutorCompletedTasks Cassandra cassandra.node.threadPool.compactionExecutor.currentlyBlockedTasks db.threadpool.internalCompactionExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.compactionExecutor.pendingTasks db.threadpool.internalCompactionExecutorPendingTasks Cassandra cassandra.node.threadPool.counterMutationStage.activeTasks db.threadpool.requestCounterMutationStageActiveTasks Cassandra cassandra.node.threadPool.counterMutationStage.completedTasks db.threadpool.requestCounterMutationStageCompletedTasks Cassandra cassandra.node.threadPool.counterMutationStage.currentlyBlockedTasks db.threadpool.requestCounterMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.counterMutationStage.pendingTasks db.threadpool.requestCounterMutationStagePendingTasks Cassandra cassandra.node.threadPool.gossipStage.activeTasks db.threadpool.internalGossipStageActiveTasks Cassandra cassandra.node.threadPool.gossipStage.completedTasks db.threadpool.internalGossipStageCompletedTasks Cassandra cassandra.node.threadPool.gossipStage.currentlyBlockedTasks db.threadpool.internalGossipStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.gossipStage.pendingTasks db.threadpool.internalGossipStagePendingTasks Cassandra cassandra.node.threadPool.hintsDispatcher.activeTasks db.threadpool.internalHintsDispatcherActiveTasks Cassandra cassandra.node.threadPool.hintsDispatcher.completedTasks db.threadpool.internalHintsDispatcherCompletedTasks Cassandra cassandra.node.threadPool.hintsDispatcher.currentlyBlockedTasks db.threadpool.internalHintsDispatcherCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.hintsDispatcher.pendingTasks db.threadpool.internalHintsDispatcherPendingTasks Cassandra cassandra.node.threadPool.internalResponseStage.activeTasks db.threadpool.internalInternalResponseStageActiveTasks Cassandra cassandra.node.threadPool.internalResponseStage.completedTasks db.threadpool.internalInternalResponseStageCompletedTasks Cassandra cassandra.node.threadPool.internalResponseStage.pCurrentlyBlockedTasks db.threadpool.internalInternalResponseStagePCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.internalResponseStage.pendingTasks db.threadpool.internalInternalResponseStagePendingTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.activeTasks db.threadpool.internalMemtableFlushWriterActiveTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.completedTasks db.threadpool.internalMemtableFlushWriterCompletedTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.currentlyBlockedTasks db.threadpool.internalMemtableFlushWriterCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.pendingTasks db.threadpool.internalMemtableFlushWriterPendingTasks Cassandra cassandra.node.threadPool.memtablePostFlush.activeTasks db.threadpool.internalMemtablePostFlushActiveTasks Cassandra cassandra.node.threadPool.memtablePostFlush.completedTasks db.threadpool.internalMemtablePostFlushCompletedTasks Cassandra cassandra.node.threadPool.memtablePostFlush.currentlyBlockedTasks db.threadpool.internalMemtablePostFlushCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtablePostFlush.pendingTasks db.threadpool.internalMemtablePostFlushPendingTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.activeTasks db.threadpool.internalMemtableReclaimMemoryActiveTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.completedTasks db.threadpool.internalMemtableReclaimMemoryCompletedTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.currentlyBlockedTasks db.threadpool.internalMemtableReclaimMemoryCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.pendingTasks db.threadpool.internalMemtableReclaimMemoryPendingTasks Cassandra cassandra.node.threadPool.migrationStage.activeTasks db.threadpool.internalMigrationStageActiveTasks Cassandra cassandra.node.threadPool.migrationStage.completedTasks db.threadpool.internalMigrationStageCompletedTasks Cassandra cassandra.node.threadPool.migrationStage.currentlyBlockedTasks db.threadpool.internalMigrationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.migrationStage.pendingTasks db.threadpool.internalMigrationStagePendingTasks Cassandra cassandra.node.threadPool.miscStage.activeTasks db.threadpool.internalMiscStageActiveTasks Cassandra cassandra.node.threadPool.miscStage.completedTasks db.threadpool.internalMiscStageCompletedTasks Cassandra cassandra.node.threadPool.miscStage.currentlyBlockedTasks db.threadpool.internalMiscStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.miscStage.pendingTasks db.threadpool.internalMiscStagePendingTasks Cassandra cassandra.node.threadPool.mutationStage.activeTasks db.threadpool.requestMutationStageActiveTasks Cassandra cassandra.node.threadPool.mutationStage.completedTasks db.threadpool.requestMutationStageCompletedTasks Cassandra cassandra.node.threadPool.mutationStage.currentlyBlockedTasks db.threadpool.requestMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.mutationStage.pendingTasks db.threadpool.requestMutationStagePendingTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.activeTasks db.threadpool.internalPendingRangeCalculatorActiveTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.completedTasks db.threadpool.internalPendingRangeCalculatorCompletedTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.currentlyBlockedTasks db.threadpool.internalPendingRangeCalculatorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.pendingTasks db.threadpool.internalPendingRangeCalculatorPendingTasks Cassandra cassandra.node.threadPool.readRepairStage.activeTasks db.threadpool.requestReadRepairStageActiveTasks Cassandra cassandra.node.threadPool.readRepairStage.completedTasks db.threadpool.requestReadRepairStageCompletedTasks Cassandra cassandra.node.threadPool.readRepairStage.currentlyBlockedTasks db.threadpool.requestReadRepairStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.readRepairStage.pendingTasks db.threadpool.requestReadRepairStagePendingTasks Cassandra cassandra.node.threadPool.readStage.activeTasks db.threadpool.requestReadStageActiveTasks Cassandra cassandra.node.threadPool.readStage.completedTasks db.threadpool.requestReadStageCompletedTasks Cassandra cassandra.node.threadPool.readStage.currentlyBlockedTasks db.threadpool.requestReadStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.readStage.pendingTasks db.threadpool.requestReadStagePendingTasks Cassandra cassandra.node.threadPool.requestResponseStage.activeTasks db.threadpool.requestRequestResponseStageActiveTasks Cassandra cassandra.node.threadPool.requestResponseStage.completedTasks db.threadpool.requestRequestResponseStageCompletedTasks Cassandra cassandra.node.threadPool.requestResponseStage.currentlyBlockedTasks db.threadpool.requestRequestResponseStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.requestResponseStage.pendingTasks db.threadpool.requestRequestResponseStagePendingTasks Cassandra cassandra.node.threadPool.sampler.activeTasks db.threadpool.internalSamplerActiveTasks Cassandra cassandra.node.threadPool.sampler.completedTasks db.threadpool.internalSamplerCompletedTasks Cassandra cassandra.node.threadPool.sampler.currentlyBlockedTasks db.threadpool.internalSamplerCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.sampler.pendingTasks db.threadpool.internalSamplerPendingTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.activeTasks db.threadpool.internalSecondaryIndexManagementActiveTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.completedTasks db.threadpool.internalSecondaryIndexManagementCompletedTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.currentlyBlockedTasks db.threadpool.internalSecondaryIndexManagementCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.pendingTasks db.threadpool.internalSecondaryIndexManagementPendingTasks Cassandra cassandra.node.threadPool.validationExecutor.activeTasks db.threadpool.internalValidationExecutorActiveTasks Cassandra cassandra.node.threadPool.validationExecutor.completedTasks db.threadpool.internalValidationExecutorCompletedTasks Cassandra cassandra.node.threadPool.validationExecutor.currentlyBlockedTasks db.threadpool.internalValidationExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.validationExecutor.pendingTasks db.threadpool.internalValidationExecutorPendingTasks Cassandra cassandra.node.threadPool.viewMutationStage.activeTasks db.threadpool.requestViewMutationStageActiveTasks Cassandra cassandra.node.threadPool.viewMutationStage.completedTasks db.threadpool.requestViewMutationStageCompletedTasks Cassandra cassandra.node.threadPool.viewMutationStage.currentlyBlockedTasks db.threadpool.requestViewMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.viewMutationStage.pendingTasks db.threadpool.requestViewMutationStagePendingTasks Cassandra cassandra.node.totalHintsInProgress db.totalHintsInProgress Cassandra cassandra.node.totalHintsPerSecond db.totalHintsPerSecond Cassandra cassandra.columnFamily.allMemtablesOffHeapSizeBytes db.allMemtablesOffHeapSizeBytes Cassandra cassandra.columnFamily.allMemtablesOnHeapSizeBytes db.allMemtablesOnHeapSizeBytes Cassandra cassandra.columnFamily.bloomFilterFalseRatio db.bloomFilterFalseRatio Cassandra cassandra.columnFamily.liveDiskSpaceUsedBytes db.liveDiskSpaceUsedBytes Cassandra cassandra.columnFamily.liveSsTableCount db.liveSSTableCount Cassandra cassandra.columnFamily.maxRowSize db.maxRowSize Cassandra cassandra.columnFamily.meanRowSize db.meanRowSize Cassandra cassandra.columnFamily.memtableLiveDataSize db.memtableLiveDataSize Cassandra cassandra.columnFamily.minRowSize db.minRowSize Cassandra cassandra.columnFamily.pendingCompactions db.pendingCompactions Cassandra cassandra.columnFamily.query.readLatency50ThPercentileMilliseconds query.readLatency50thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency75ThPercentileMilliseconds query.readLatency75thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency95ThPercentileMilliseconds query.readLatency95thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency98ThPercentileMilliseconds query.readLatency98thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency999ThPercentileMilliseconds query.readLatency999thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency99ThPercentileMilliseconds query.readLatency99thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readRequestsPerSecond query.readRequestsPerSecond Cassandra cassandra.columnFamily.query.writeLatency50ThPercentileMilliseconds query.writeLatency50thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency75ThPercentileMilliseconds query.writeLatency75thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency95ThPercentileMilliseconds query.writeLatency95thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency98ThPercentileMilliseconds query.writeLatency98thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency999ThPercentileMilliseconds query.writeLatency999thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency99ThPercentileMilliseconds query.writeLatency99thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeRequestsPerSecond query.writeRequestsPerSecond Cassandra cassandra.columnFamily.speculativeRetries db.speculativeRetries Cassandra cassandra.columnFamily.ssTablesPerRead50ThPercentileMilliseconds db.SSTablesPerRead50thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead75ThPercentileMilliseconds db.SSTablesPerRead75thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead95ThPercentileMilliseconds db.SSTablesPerRead95thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead98ThPercentileMilliseconds db.SSTablesPerRead98thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead999ThPercentileMilliseconds db.SSTablesPerRead999thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead99ThPercentileMilliseconds db.SSTablesPerRead99thPercentileMilliseconds Cassandra cassandra.columnFamily.tombstoneScannedHistogram50ThPercentile db.tombstoneScannedHistogram50thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram75ThPercentile db.tombstoneScannedHistogram75thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram95ThPercentile db.tombstoneScannedHistogram95thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram98ThPercentile db.tombstoneScannedHistogram98thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram999ThPercentile db.tombstoneScannedHistogram999thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram99ThPercentile db.tombstoneScannedHistogram99thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogramCount db.tombstoneScannedHistogramCount Consul consul.datacenter.catalog.criticalNodes catalog.criticalNodes Consul consul.datacenter.catalog.passingNodes catalog.passingNodes Consul consul.datacenter.catalog.registeredNodes catalog.registeredNodes Consul consul.datacenter.catalog.upNodes catalog.upNodes Consul consul.datacenter.catalog.warningNodes catalog.warningNodes Consul consul.datacenter.cluster.flaps cluster.flaps Consul consul.datacenter.cluster.suspects cluster.suspects Consul consul.datacenter.raft.commitTime raft.commitTimes Consul consul.datacenter.raft.commitTimeAvgInMilliseconds raft.commitTimeAvgInMilliseconds Consul consul.datacenter.raft.commitTimeMaxInMilliseconds raft.commitTimeMaxInMilliseconds Consul consul.datacenter.raft.completedLeaderElections raft.completedLeaderElections Consul consul.datacenter.raft.initiatedLeaderElections raft.initiatedLeaderElections Consul consul.datacenter.raft.lastContactAvgInMilliseconds raft.lastContactAvgInMilliseconds Consul consul.datacenter.raft.lastContactMaxInMilliseconds raft.lastContactMaxInMilliseconds Consul consul.datacenter.raft.lastContacts raft.lastContacts Consul consul.datacenter.raft.logDispatchAvgInMilliseconds raft.logDispatchAvgInMilliseconds Consul consul.datacenter.raft.logDispatches raft.logDispatches Consul consul.datacenter.raft.logDispatchMaxInMilliseconds raft.logDispatchMaxInMilliseconds Consul consul.datacenter.raft.txns raft.txns Consul consul.agent.aclCacheHitPerSecond agent.aclCacheHit Consul consul.agent.aclCacheMissPerSecond agent.aclCacheMiss Consul consul.agent.client.rpcFailed client.rpcFailed Consul consul.agent.client.rpcLoad client.rpcLoad Consul consul.agent.kvStores agent.kvStoress Consul consul.agent.kvStoresAvgInMilliseconds agent.kvStoresAvgInMilliseconds Consul consul.agent.kvStoresMaxInMilliseconds agent.kvStoresMaxInMilliseconds Consul consul.agent.net.agent.maxLatencyInMilliseconds net.agent.maxLatencyInMilliseconds Consul consul.agent.net.medianLatencyInMilliseconds net.agent.medianLatencyInMilliseconds Consul consul.agent.net.minLatencyInMilliseconds net.agent.minLatencyInMilliseconds Consul consul.agent.net.p25LatencyInMilliseconds net.agent.p25LatencyInMilliseconds Consul consul.agent.net.p75LatencyInMilliseconds net.agent.p75LatencyInMilliseconds Consul consul.agent.net.p90LatencyInMilliseconds net.agent.p90LatencyInMilliseconds Consul consul.agent.net.p95LatencyInMilliseconds net.agent.p95LatencyInMilliseconds Consul consul.agent.net.p99LatencyInMilliseconds net.agent.p99LatencyInMilliseconds Consul consul.agent.peers agent.peers Consul consul.agent.runtime.allocations runtime.allocations Consul consul.agent.runtime.allocationsInBytes runtime.allocationsInBytes Consul consul.agent.runtime.frees runtime.frees Consul consul.agent.runtime.gcCycles runtime.gcCycles Consul consul.agent.runtime.gcPauseInMilliseconds runtime.gcPauseInMilliseconds Consul consul.agent.runtime.goroutines runtime.goroutines Consul consul.agent.runtime.heapObjects runtime.heapObjects Consul consul.agent.runtime.virtualAddressSpaceInBytes runtime.virtualAddressSpaceInBytes Consul consul.agent.staleQueries agent.staleQueries Consul consul.agent.txnAvgInMilliseconds agent.txnAvgInMilliseconds Consul consul.agent.txnMaxInMilliseconds agent.txnMaxInMilliseconds Consul consul.agent.txns agent.txns Couchbase couchbase.bucket.activeItemsEnteringDiskQueuePerSecond bucket.activeItemsEnteringDiskQueuePerSecond Couchbase couchbase.bucket.activeItemsInMemory bucket.activeItemsInMemory Couchbase couchbase.bucket.activeResidentItemsRatio bucket.activeResidentItemsRatio Couchbase couchbase.bucket.averageDiskCommitTimeInMilliseconds bucket.averageDiskCommitTimeInMilliseconds Couchbase couchbase.bucket.averageDiskUpdateTimeInMilliseconds bucket.averageDiskUpdateTimeInMilliseconds Couchbase couchbase.bucket.cacheMisses bucket.cacheMisses Couchbase couchbase.bucket.cacheMissRatio bucket.cacheMissRatio Couchbase couchbase.bucket.casHits bucket.casHits Couchbase couchbase.bucket.casMisses bucket.casMisses Couchbase couchbase.bucket.couchDocsFragmentationPercent bucket.couchDocsFragmentationPercent Couchbase couchbase.bucket.currentConnections bucket.currentConnections Couchbase couchbase.bucket.dataUsedInBytes bucket.dataUsedInBytes Couchbase couchbase.bucket.decrementHitsPerSecond bucket.decrementHitsPerSecond Couchbase couchbase.bucket.decrementMissesPerSecond bucket.decrementMissesPerSecond Couchbase couchbase.bucket.deleteHitsPerSecond bucket.deleteHitsPerSecond Couchbase couchbase.bucket.deleteMissesPerSecond bucket.deleteMissesPerSecond Couchbase couchbase.bucket.diskCreateOperationsPerSecond bucket.diskCreateOperationsPerSecond Couchbase couchbase.bucket.diskFetchesPerSecond bucket.diskFetchesPerSecond Couchbase couchbase.bucket.diskReadsPerSecond bucket.diskReadsPerSecond Couchbase couchbase.bucket.diskUpdateOperationsPerSecond bucket.diskUpdateOperationsPerSecond Couchbase couchbase.bucket.diskUsedInBytes bucket.diskUsedInBytes Couchbase couchbase.bucket.diskWriteQueue bucket.diskWriteQueue Couchbase couchbase.bucket.drainedItemsInQueue bucket.drainedItemsInQueue Couchbase couchbase.bucket.drainedItemsOnDiskQueue bucket.drainedItemsOnDiskQueue Couchbase couchbase.bucket.drainedPendingItemsInQueue bucket.drainedPendingItemsInQueue Couchbase couchbase.bucket.ejectionsPerSecond bucket.ejectionsPerSecond Couchbase couchbase.bucket.evictionsPerSecond bucket.evictionsPerSecond Couchbase couchbase.bucket.getHitsPerSecond bucket.getHitsPerSecond Couchbase couchbase.bucket.getMissesPerSecond bucket.getMissesPerSecond Couchbase couchbase.bucket.hitRatio bucket.hitRatio Couchbase couchbase.bucket.incrementHitsPerSecond bucket.incrementHitsPerSecond Couchbase couchbase.bucket.incrementMissesPerSecond bucket.incrementMissesPerSecond Couchbase couchbase.bucket.itemCount bucket.itemCount Couchbase couchbase.bucket.itemsBeingWritten bucket.itemsBeingWritten Couchbase couchbase.bucket.itemsEjectedFromMemoryToDisk bucket.itemsEjectedFromMemoryToDisk Couchbase couchbase.bucket.itemsOnDiskQueue bucket.itemsOnDiskQueue Couchbase couchbase.bucket.itemsQueuedForStorage bucket.itemsQueuedForStorage Couchbase couchbase.bucket.maximumMemoryUsage bucket.maximumMemoryUsage Couchbase couchbase.bucket.memoryHighWaterMarkInBytes bucket.memoryHighWaterMarkInBytes Couchbase couchbase.bucket.memoryLowWaterMarkInBytes bucket.memoryLowWaterMarkInBytes Couchbase couchbase.bucket.memoryUsedInBytes bucket.memoryUsedInBytes Couchbase couchbase.bucket.metadataInRamInBytes bucket.metadataInRAMInBytes Couchbase couchbase.bucket.missesPerSecond bucket.missesPerSecond Couchbase couchbase.bucket.outOfMemoryErrorsPerSecond bucket.outOfMemoryErrorsPerSecond Couchbase couchbase.bucket.overheadInBytes bucket.overheadInBytes Couchbase couchbase.bucket.pendingItemsInDiskQueue bucket.pendingItemsInDiskQueue Couchbase couchbase.bucket.pendingResidentItemsRatio bucket.pendingResidentItemsRatio Couchbase couchbase.bucket.quotaUtilization bucket.quotaUtilization Couchbase couchbase.bucket.readOperationsPerSecond bucket.readOperationsPerSecond Couchbase couchbase.bucket.readRatePerSecond bucket.readRatePerSecond Couchbase couchbase.bucket.recoverableOutOfMemoryCount bucket.recoverableOutOfMemoryCount Couchbase couchbase.bucket.replicaIndex bucket.replicaIndex Couchbase couchbase.bucket.replicaNumber bucket.replicaNumber Couchbase couchbase.bucket.replicaResidentItemsRatio bucket.replicaResidentItemsRatio Couchbase couchbase.bucket.residentItemsRatio bucket.residentItemsRatio Couchbase couchbase.bucket.temporaryOutOfMemoryErrorsPerSecond bucket.temporaryOutOfMemoryErrorsPerSecond Couchbase couchbase.bucket.threadsNumber bucket.threadsNumber Couchbase couchbase.bucket.totalItems bucket.totalItems Couchbase couchbase.bucket.totalOperationsPerSecond bucket.totalOperationsPerSecond Couchbase couchbase.bucket.viewFragmentationPercent bucket.viewFragmentationPercent Couchbase couchbase.bucket.writeOperationsPerSecond bucket.writeOperationsPerSecond Couchbase couchbase.bucket.writeRatePerSecond bucket.writeRatePerSecond Couchbase couchbase.cluster.autoFailoverCount cluster.autoFailoverCount Couchbase couchbase.cluster.autoFailoverEnabled cluster.autoFailoverEnabled Couchbase couchbase.cluster.databaseFragmentationThreshold cluster.databaseFragmentationThreshold Couchbase couchbase.cluster.diskFreeInBytes cluster.diskFreeInBytes Couchbase couchbase.cluster.diskQuotaTotalInBytes cluster.diskQuotaTotalInBytes Couchbase couchbase.cluster.diskTotalInBytes cluster.diskTotalInBytes Couchbase couchbase.cluster.diskUsedByDataInBytes cluster.diskUsedByDataInBytes Couchbase couchbase.cluster.diskUsedInBytes cluster.diskUsedInBytes Couchbase couchbase.cluster.indexFragmentationThreshold cluster.indexFragmentationThreshold Couchbase couchbase.cluster.maximumBucketCount cluster.maximumBucketCount Couchbase couchbase.cluster.memoryQuotaTotalInBytes cluster.memoryQuotaTotalInBytes Couchbase couchbase.cluster.memoryQuotaTotalPerNodeInBytes cluster.memoryQuotaTotalPerNodeInBytes Couchbase couchbase.cluster.memoryQuotaUsedInBytes cluster.memoryQuotaUsedInBytes Couchbase couchbase.cluster.memoryQuotaUsedPerNodeInBytes cluster.memoryQuotaUsedPerNodeInBytes Couchbase couchbase.cluster.memoryTotalInBytes cluster.memoryTotalInBytes Couchbase couchbase.cluster.memoryUsedByDataInBytes cluster.memoryUsedByDataInBytes Couchbase couchbase.cluster.memoryUsedInBytes cluster.memoryUsedInBytes Couchbase couchbase.cluster.viewFragmentationThreshold cluster.viewFragmentationThreshold Couchbase couchbase.node.backgroundFetches node.backgroundFetches Couchbase couchbase.node.cmdGet node.cmdGet Couchbase couchbase.node.couchDocsActualDiskSizeInBytes node.couchDocsActualDiskSizeInBytes Couchbase couchbase.node.couchDocsDataSizeInBytes node.couchDocsDataSizeInBytes Couchbase couchbase.node.couchSpatialDataSizeInBytes node.couchSpatialDataSizeInBytes Couchbase couchbase.node.couchSpatialDiskSizeInBytes node.couchSpatialDiskSizeInBytes Couchbase couchbase.node.couchViewsActualDiskSizeInBytes node.couchViewsActualDiskSizeInBytes Couchbase couchbase.node.couchViewsDataSizeInBytes node.couchViewsDataSizeInBytes Couchbase couchbase.node.cpuUtilization node.cpuUtilization Couchbase couchbase.node.currentItems node.currentItems Couchbase couchbase.node.currentItemsTotal node.currentItemsTotal Couchbase couchbase.node.getHits node.getHits Couchbase couchbase.node.memoryFreeInBytes node.memoryFreeInBytes Couchbase couchbase.node.memoryTotalInBytes node.memoryTotalInBytes Couchbase couchbase.node.memoryUsedInBytes node.memoryUsedInBytes Couchbase couchbase.node.ops node.ops Couchbase couchbase.node.swapTotalInBytes node.swapTotalInBytes Couchbase couchbase.node.swapUsedInBytes node.swapUsedInBytes Couchbase couchbase.node.uptimeInMilliseconds node.uptimeInMilliseconds Couchbase couchbase.node.vbucketActiveNonResidentItems node.vbucketActiveNonResidentItems Couchbase couchbase.node.vbucketInMemoryItems node.vbucketInMemoryItems Couchbase couchbase.queryengine.activeRequests queryengine.activeRequests Couchbase couchbase.queryengine.averageRequestTimeInMilliseconds queryengine.averageRequestTimeInMilliseconds Couchbase couchbase.queryengine.completedLimit queryengine.completedLimit Couchbase couchbase.queryengine.completedRequests queryengine.completedRequests Couchbase couchbase.queryengine.completedThresholdInMilliseconds queryengine.completedThresholdInMilliseconds Couchbase couchbase.queryengine.cores queryengine.cores Couchbase couchbase.queryengine.garbageCollectionNumber queryengine.garbageCollectionNumber Couchbase couchbase.queryengine.garbageCollectionPaused queryengine.garbageCollectionPaused Couchbase couchbase.queryengine.garbageCollectionTimePausedInMilliseconds queryengine.garbageCollectionTimePausedInMilliseconds Couchbase couchbase.queryengine.medianRequestTimeInMilliseconds queryengine.medianRequestTimeInMilliseconds Couchbase couchbase.queryengine.preparedStatementUtilization queryengine.preparedStatementUtilization Couchbase couchbase.queryengine.requestsLast15MinutesPerSecond queryengine.requestsLast15MinutesPerSecond Couchbase couchbase.queryengine.requestsLast1MinutesPerSecond queryengine.requestsLast1MinutesPerSecond Couchbase couchbase.queryengine.requestsLast5MinutesPerSecond queryengine.requestsLast5MinutesPerSecond Couchbase couchbase.queryengine.requestTime80thPercentileInMilliseconds queryengine.requestTime80thPercentileInMilliseconds Couchbase couchbase.queryengine.requestTime95thPercentileInMilliseconds queryengine.requestTime95thPercentileInMilliseconds Couchbase couchbase.queryengine.requestTime99thPercentileInMilliseconds queryengine.requestTime99thPercentileInMilliseconds Couchbase couchbase.queryengine.systemCpuUtilization queryengine.systemCPUUtilization Couchbase couchbase.queryengine.systemMemoryInBytes queryengine.systemMemoryInBytes Couchbase couchbase.queryengine.totalMemoryInBytes queryengine.totalMemoryInBytes Couchbase couchbase.queryengine.totalThreads queryengine.totalThreads Couchbase couchbase.queryengine.uptimeInMilliseconds queryengine.uptimeInMilliseconds Couchbase couchbase.queryengine.usedMemoryInBytes queryengine.usedMemoryInBytes Couchbase couchbase.queryengine.userCpuUtilization queryengine.userCPUUtilization Docker docker.container.cpuKernelPercent cpuKernelPercent Docker docker.container.cpuLimitCores cpuLimitCores Docker docker.container.cpuPercent cpuPercent Docker docker.container.cpuThrottlePeriods cpuThrottlePeriods Docker docker.container.cpuThrottleTimeMs cpuThrottleTimeMs Docker docker.container.cpuUsedCores cpuUsedCores Docker docker.container.cpuUsedCoresPercent cpuUsedCoresPercent Docker docker.container.cpuUserPercent cpuUserPercent Docker docker.container.ioReadBytesPerSecond ioReadBytesPerSecond Docker docker.container.ioReadCountPerSecond ioReadCountPerSecond Docker docker.container.ioTotalBytes ioTotalBytes Docker docker.container.ioTotalReadBytes ioTotalReadBytes Docker docker.container.ioTotalReadCount ioTotalReadCount Docker docker.container.ioTotalWriteBytes ioTotalWriteBytes Docker docker.container.ioTotalWriteCount ioTotalWriteCount Docker docker.container.ioWriteBytesPerSecond ioWriteBytesPerSecond Docker docker.container.ioWriteCountPerSecond ioWriteCountPerSecond Docker docker.container.memoryCacheBytes memoryCacheBytes Docker docker.container.memoryResidentSizeBytes memoryResidentSizeBytes Docker docker.container.memorySizeLimitBytes memorySizeLimitBytes Docker docker.container.memoryUsageBytes memoryUsageBytes Docker docker.container.memoryUsageLimitPercent memoryUsageLimitPercent Docker docker.container.networkRxBytes networkRxBytes Docker docker.container.networkRxBytesPerSecond networkRxBytesPerSecond Docker docker.container.networkRxDropped networkRxDropped Docker docker.container.networkRxDroppedPerSecond networkRxDroppedPerSecond Docker docker.container.networkRxErrors networkRxErrors Docker docker.container.networkRxErrorsPerSecond networkRxErrorsPerSecond Docker docker.container.networkRxPackets networkRxPackets Docker docker.container.networkRxPacketsPerSecond networkRxPacketsPerSecond Docker docker.container.networkTxBytes networkTxBytes Docker docker.container.networkTxBytesPerSecond networkTxBytesPerSecond Docker docker.container.networkTxDropped networkTxDropped Docker docker.container.networkTxDroppedPerSecond networkTxDroppedPerSecond Docker docker.container.networkTxErrors networkTxErrors Docker docker.container.networkTxErrorsPerSecond networkTxErrorsPerSecond Docker docker.container.networkTxPackets networkTxPackets Docker docker.container.networkTxPacketsPerSecond networkTxPacketsPerSecond Docker docker.container.pids pids Docker docker.container.processCount processCount Docker docker.container.processCountLimit processCountLimit Docker docker.container.restartCount restartCount Docker docker.container.threadCount threadCount Docker docker.container.threadCountLimit threadCountLimit ElasticSearch elasticsearch.cluster.dataNodes cluster.dataNodes ElasticSearch elasticsearch.cluster.nodes cluster.nodes ElasticSearch elasticsearch.cluster.shards.active shards.active ElasticSearch elasticsearch.cluster.shards.initializing shards.initializing ElasticSearch elasticsearch.cluster.shards.primaryActive shards.primaryActive ElasticSearch elasticsearch.cluster.shards.relocating shards.relocating ElasticSearch elasticsearch.cluster.shards.unassigned shards.unassigned ElasticSearch elasticsearch.cluster.tempData temp-data ElasticSearch elasticsearch.index.docs index.docs ElasticSearch elasticsearch.index.docsDeleted index.docsDeleted ElasticSearch elasticsearch.index.primaryShards index.primaryShards ElasticSearch elasticsearch.index.primaryStoreSizeInBytes index.primaryStoreSizeInBytes ElasticSearch elasticsearch.index.replicaShards index.replicaShards ElasticSearch elasticsearch.index.rollup.docsCount primaries.docsnumber ElasticSearch elasticsearch.index.rollup.docsDeleted primaries.docsDeleted ElasticSearch elasticsearch.index.rollup.flushTotal primaries.flushesTotal ElasticSearch elasticsearch.index.rollup.flushTotalTimeInMilliseconds primaries.flushTotalTimeInMilliseconds ElasticSearch elasticsearch.index.rollup.get.documentsExist primaries.get.documentsExist ElasticSearch elasticsearch.index.rollup.get.documentsExistInMilliseconds primaries.get.documentsExistInMilliseconds ElasticSearch elasticsearch.index.rollup.get.documentsMissing primaries.get.documentsMissing ElasticSearch elasticsearch.index.rollup.get.documentsMissingInMilliseconds primaries.get.documentsMissingInMilliseconds ElasticSearch elasticsearch.index.rollup.get.requests primaries.get.requests ElasticSearch elasticsearch.index.rollup.get.requestsCurrent primaries.get.requestsCurrent ElasticSearch elasticsearch.index.rollup.get.requestsInMilliseconds primaries.get.requestsInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyDeleted primaries.index.docsCurrentlyDeleted ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyDeletedInMilliseconds primaries.index.docsCurrentlyDeletedInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyIndexing primaries.index.docsCurrentlyIndexing ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyIndexingInMilliseconds primaries.index.docsCurrentlyIndexingInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsDeleted primaries.index.docsDeleted ElasticSearch elasticsearch.index.rollup.index.docsTotal primaries.index.docsTotal ElasticSearch elasticsearch.index.rollup.indexRefreshesTotal primaries.indexRefreshesTotal ElasticSearch elasticsearch.index.rollup.indexRefreshesTotalInMilliseconds primaries.indexRefreshesTotalInMilliseconds ElasticSearch elasticsearch.index.rollup.merges.current primaries.merges.current ElasticSearch elasticsearch.index.rollup.merges.docsSegmentsCurrentlyMerged primaries.merges.docsSegmentsCurrentlyMerged ElasticSearch elasticsearch.index.rollup.merges.docsTotal primaries.merges.docsTotal ElasticSearch elasticsearch.index.rollup.merges.segmentsCurrentlyMergedInBytes primaries.merges.segmentsCurrentlyMergedInBytes ElasticSearch elasticsearch.index.rollup.merges.segmentsTotal primaries.merges.segmentsTotal ElasticSearch elasticsearch.index.rollup.merges.segmentsTotalInBytes primaries.merges.segmentsTotalInBytes ElasticSearch elasticsearch.index.rollup.merges.segmentsTotalInMilliseconds primaries.merges.segmentsTotalInMilliseconds ElasticSearch elasticsearch.index.rollup.queriesInMilliseconds primaries.queriesInMilliseconds ElasticSearch elasticsearch.index.rollup.queriesTotal primaries.queriesTotal ElasticSearch elasticsearch.index.rollup.queryActive primaries.queryActive ElasticSearch elasticsearch.index.rollup.queryFetches primaries.queryFetches ElasticSearch elasticsearch.index.rollup.queryFetchesInMilliseconds primaries.queryFetchesInMilliseconds ElasticSearch elasticsearch.index.rollup.queryFetchesTotal primaries.queryFetchesTotal ElasticSearch elasticsearch.index.rollup.sizeInBytes primaries.sizeInBytes ElasticSearch elasticsearch.index.storeSizeInBytes index.storeSizeInBytes ElasticSearch elasticsearch.node.activeSearches activeSearches ElasticSearch elasticsearch.node.activeSearchesInMilliseconds activeSearchesInMilliseconds ElasticSearch elasticsearch.node.breakers.estimatedSizeFieldDataCircuitBreakerInBytes breakers.estimatedSizeFieldDataCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.estimatedSizeParentCircuitBreakerInBytes breakers.estimatedSizeParentCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.estimatedSizeRequestCircuitBreakerInBytes breakers.estimatedSizeRequestCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.fieldDataCircuitBreakerTripped breakers.fieldDataCircuitBreakerTripped ElasticSearch elasticsearch.node.breakers.parentCircuitBreakerTripped breakers.parentCircuitBreakerTripped ElasticSearch elasticsearch.node.breakers.requestCircuitBreakerTripped breakers.requestCircuitBreakerTripped ElasticSearch elasticsearch.node.flush.indexRefreshesTotal flush.indexRefreshesTotal ElasticSearch elasticsearch.node.flush.indexRefreshesTotalInMilliseconds flush.indexRefreshesTotalInMilliseconds ElasticSearch elasticsearch.node.fs.bytesAvailableJvmInBytes fs.bytesAvailableJVMInBytes ElasticSearch elasticsearch.node.fs.dataRead fs.bytesReadsInBytes ElasticSearch elasticsearch.node.fs.dataWritten fs.writesInBytes ElasticSearch elasticsearch.node.fs.ioOperations fs.iOOperations ElasticSearch elasticsearch.node.fs.readOperations fs.reads ElasticSearch elasticsearch.node.fs.totalSizeInBytes fs.totalSizeInBytes ElasticSearch elasticsearch.node.fs.unallocatedBytes fs.unallocatedBytesInBYtes ElasticSearch elasticsearch.node.fs.writeOperations fs.writeOperations ElasticSearch elasticsearch.node.get.currentRequestsRunning get.currentRequestsRunning ElasticSearch elasticsearch.node.get.requestsDocumentExists get.requestsDocumentExists ElasticSearch elasticsearch.node.get.requestsDocumentExistsInMilliseconds get.requestsDocumentExistsInMilliseconds ElasticSearch elasticsearch.node.get.requestsDocumentMissing get.requestsDocumentMissing ElasticSearch elasticsearch.node.get.requestsDocumentMissingInMilliseconds get.requestsDocumentMissingInMilliseconds ElasticSearch elasticsearch.node.get.timeGetRequestsInMilliseconds get.timeGetRequestsInMilliseconds ElasticSearch elasticsearch.node.get.totalGetRequests get.totalGetRequests ElasticSearch elasticsearch.node.http.currentOpenConnections http.currentOpenConnections ElasticSearch elasticsearch.node.http.openedConnections http.openedConnections ElasticSearch elasticsearch.node.index.indexingOperationsFailed indices.indexingOperationsFailed ElasticSearch elasticsearch.node.index.indexingWaitedThrottlingInMilliseconds indices.indexingWaitedThrottlingInMilliseconds ElasticSearch elasticsearch.node.index.memoryQueryCacheInBytes indices.memoryQueryCacheInBytes ElasticSearch elasticsearch.node.index.numberIndices indices.numberIndices ElasticSearch elasticsearch.node.index.queryCacheEvictions indices.queryCacheEvictions ElasticSearch elasticsearch.node.index.queryCacheHits indices.queryCacheHits ElasticSearch elasticsearch.node.index.queryCacheMisses indices.queryCacheMisses ElasticSearch elasticsearch.node.index.recoveryOngoingShardSource indices.recoveryOngoingShardSource ElasticSearch elasticsearch.node.index.recoveryOngoingShardTarget indices.recoveryOngoingShardTarget ElasticSearch elasticsearch.node.index.recoveryWaitedThrottlingInMilliseconds indices.recoveryWaitedThrottlingInMilliseconds ElasticSearch elasticsearch.node.index.requestCacheEvictions indices.requestCacheEvictions ElasticSearch elasticsearch.node.index.requestCacheHits indices.requestCacheHits ElasticSearch elasticsearch.node.index.requestCacheMemoryInBytes indices.requestCacheMemoryInBytes ElasticSearch elasticsearch.node.index.requestCacheMisses indices.requestCacheMisses ElasticSearch elasticsearch.node.index.segmentsIndexShard indices.segmentsIndexShard ElasticSearch elasticsearch.node.index.segmentsMemoryUsedDocValuesInBytes indices.segmentsMemoryUsedDocValuesInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedFixedBitSetInBytes indices.segmentsMemoryUsedFixedBitSetInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedIndexSegmentsInBytes indices.segmentsMemoryUsedIndexSegmentsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedIndexWriterInBytes indices.segmentsMemoryUsedIndexWriterInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedNormsInBytes indices.segmentsMemoryUsedNormsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedSegmentVersionMapInBytes indices.segmentsMemoryUsedSegmentVersionMapInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedStoredFieldsInBytes indices.segmentsMemoryUsedStoredFieldsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedTermsInBytes indices.segmentsMemoryUsedTermsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedTermVectorsInBytes indices.segmentsMemoryUsedTermVectorsInBytes ElasticSearch elasticsearch.node.index.translogOperations indices.translogOperations ElasticSearch elasticsearch.node.index.translogOperationsInBytes indices.translogOperationsInBytes ElasticSearch elasticsearch.node.indexing.docsCurrentlyDeleted indexing.docsCurrentlyDeleted ElasticSearch elasticsearch.node.indexing.documentsCurrentlyIndexing indexing.documentsCurrentlyIndexing ElasticSearch elasticsearch.node.indexing.documentsIndexed indexing.documentsIndexed ElasticSearch elasticsearch.node.indexing.timeDeletingDocumentsInMilliseconds indexing.timeDeletingDocumentsInMilliseconds ElasticSearch elasticsearch.node.indexing.timeIndexingDocumentsInMilliseconds indexing.timeIndexingDocumentsInMilliseconds ElasticSearch elasticsearch.node.indexing.totalDocumentsDeleted indexing.totalDocumentsDeleted ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsOldGenerationObjects jvm.gc.majorCollectionsOldGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsOldGenerationObjectsInMilliseconds jvm.gc.majorCollectionsOldGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsYoungGenerationObjects jvm.gc.majorCollectionsYoungGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsYoungGenerationObjectsInMilliseconds jvm.gc.majorCollectionsYoungGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.gc.minorCollectionsYoungGenerationObjects jvm.gc.minorCollectionsYoungGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.minorCollectionsYoungGenerationObjectsInMilliseconds jvm.gc.minorCollectionsYoungGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.mem.heapCommittedInBytes jvm.mem.heapCommittedInBytes ElasticSearch elasticsearch.node.jvm.mem.heapMaxInBytes jvm.mem.heapMaxInBytes ElasticSearch elasticsearch.node.jvm.mem.heapUsed jvm.mem.heapUsed ElasticSearch elasticsearch.node.jvm.mem.heapUsedInBytes jvm.mem.heapUsedInBytes ElasticSearch elasticsearch.node.jvm.mem.maxOldGenerationHeapInBytes jvm.mem.maxOldGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.maxSurvivorSpaceInBytes jvm.mem.maxSurvivorSpaceInBYtes ElasticSearch elasticsearch.node.jvm.mem.maxYoungGenerationHeapInBytes jvm.mem.maxYoungGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.nonHeapCommittedInBytes jvm.mem.nonHeapCommittedInBytes ElasticSearch elasticsearch.node.jvm.mem.nonHeapUsedInBytes jvm.mem.nonHeapUsedInBytes ElasticSearch elasticsearch.node.jvm.mem.usedOldGenerationHeapInBytes jvm.mem.usedOldGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.usedSurvivorSpaceInBytes jvm.mem.usedSurvivorSpaceInBytes ElasticSearch elasticsearch.node.jvm.mem.usedYoungGenerationHeapInBytes jvm.mem.usedYoungGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.threadsActive jvm.ThreadsActive ElasticSearch elasticsearch.node.jvm.threadsPeak jvm.ThreadsPeak ElasticSearch elasticsearch.node.merges.currentActive merges.currentActive ElasticSearch elasticsearch.node.merges.docsSegmentMerges merges.docsSegmentMerges ElasticSearch elasticsearch.node.merges.docsSegmentsMerging merges.docsSegmentsMerging ElasticSearch elasticsearch.node.merges.mergedSegmentsInBytes merges.mergedSegmentsInBytes ElasticSearch elasticsearch.node.merges.segmentMerges merges.segmentMerges ElasticSearch elasticsearch.node.merges.sizeSegmentsMergingInBytes merges.sizeSegmentsMergingInBytes ElasticSearch elasticsearch.node.merges.totalSegmentMergingInMilliseconds merges.totalSegmentMergingInMilliseconds ElasticSearch elasticsearch.node.openFd openFD ElasticSearch elasticsearch.node.queriesTotal queriesTotal ElasticSearch elasticsearch.node.refresh.total refresh.total ElasticSearch elasticsearch.node.refresh.totalInMilliseconds refresh.totalInMilliseconds ElasticSearch elasticsearch.node.searchFetchCurrentlyRunning searchFetchCurrentlyRunning ElasticSearch elasticsearch.node.searchFetches searchFetches ElasticSearch elasticsearch.node.sizeStoreInBytes sizeStoreInBytes ElasticSearch elasticsearch.node.threadpool.activeFetchShardStarted threadpool.activeFetchShardStarted ElasticSearch elasticsearch.node.threadpool.bulkActive threadpool.bulkActive ElasticSearch elasticsearch.node.threadpool.bulkQueue threadpool.bulkQueue ElasticSearch elasticsearch.node.threadpool.bulkRejected threadpool.bulkRejected ElasticSearch elasticsearch.node.threadpool.bulkThreads threadpool.bulkThreads ElasticSearch elasticsearch.node.threadpool.fetchShardStartedQueue threadpool.fetchShardStartedQueue ElasticSearch elasticsearch.node.threadpool.fetchShardStartedRejected threadpool.fetchShardStartedRejected ElasticSearch elasticsearch.node.threadpool.fetchShardStartedThreads threadpool.fetchShardStartedThreads ElasticSearch elasticsearch.node.threadpool.fetchShardStoreActive threadpool.fetchShardStoreActive ElasticSearch elasticsearch.node.threadpool.fetchShardStoreQueue threadpool.fetchShardStoreQueue ElasticSearch elasticsearch.node.threadpool.fetchShardStoreRejected threadpool.fetchShardStoreRejected ElasticSearch elasticsearch.node.threadpool.fetchShardStoreThreads threadpool.fetchShardStoreThreads ElasticSearch elasticsearch.node.threadpool.flushActive threadpool.flushActive ElasticSearch elasticsearch.node.threadpool.flushQueue threadpool.flushQueue ElasticSearch elasticsearch.node.threadpool.flushRejected threadpool.flushRejected ElasticSearch elasticsearch.node.threadpool.flushThreads threadpool.flushThreads ElasticSearch elasticsearch.node.threadpool.forceMergeActive threadpool.forceMergeActive ElasticSearch elasticsearch.node.threadpool.forceMergeQueue threadpool.forceMergeQueue ElasticSearch elasticsearch.node.threadpool.forceMergeRejected threadpool.forceMergeRejected ElasticSearch elasticsearch.node.threadpool.forceMergeThreads threadpool.forceMergeThreads ElasticSearch elasticsearch.node.threadpool.genericActive threadpool.genericActive ElasticSearch elasticsearch.node.threadpool.genericQueue threadpool.genericQueue ElasticSearch elasticsearch.node.threadpool.genericRejected threadpool.genericRejected ElasticSearch elasticsearch.node.threadpool.genericThreads threadpool.genericThreads ElasticSearch elasticsearch.node.threadpool.getActive threadpool.getActive ElasticSearch elasticsearch.node.threadpool.getQueue threadpool.getQueue ElasticSearch elasticsearch.node.threadpool.getRejected threadpool.getRejected ElasticSearch elasticsearch.node.threadpool.getThreads threadpool.getThreads ElasticSearch elasticsearch.node.threadpool.indexActive threadpool.indexActive ElasticSearch elasticsearch.node.threadpool.indexQueue threadpool.indexQueue ElasticSearch elasticsearch.node.threadpool.indexRejected threadpool.indexRejected ElasticSearch elasticsearch.node.threadpool.indexThreads threadpool.indexThreads ElasticSearch elasticsearch.node.threadpool.listenerActive threadpool.listenerActive ElasticSearch elasticsearch.node.threadpool.listenerQueue threadpool.listenerQueue ElasticSearch elasticsearch.node.threadpool.listenerRejected threadpool.listenerRejected ElasticSearch elasticsearch.node.threadpool.listenerThreads threadpool.listenerThreads ElasticSearch elasticsearch.node.threadpool.managementActive threadpool.managementActive ElasticSearch elasticsearch.node.threadpool.managementQueue threadpool.managementQueue ElasticSearch elasticsearch.node.threadpool.managementRejected threadpool.managementRejected ElasticSearch elasticsearch.node.threadpool.managementThreads threadpool.managementThreads ElasticSearch elasticsearch.node.threadpool.refreshActive threadpool.refreshActive ElasticSearch elasticsearch.node.threadpool.refreshQueue threadpool.refreshQueue ElasticSearch elasticsearch.node.threadpool.refreshRejected threadpool.refreshRejected ElasticSearch elasticsearch.node.threadpool.refreshThreads threadpool.refreshThreads ElasticSearch elasticsearch.node.threadpool.searchActive threadpool.searchActive ElasticSearch elasticsearch.node.threadpool.searchQueue threadpool.searchQueue ElasticSearch elasticsearch.node.threadpool.searchRejected threadpool.searchRejected ElasticSearch elasticsearch.node.threadpool.searchThreads threadpool.searchThreads ElasticSearch elasticsearch.node.threadpool.snapshotActive threadpool.snapshotActive ElasticSearch elasticsearch.node.threadpool.snapshotQueue threadpool.snapshotQueue ElasticSearch elasticsearch.node.threadpool.snapshotRejected threadpool.snapshotRejected ElasticSearch elasticsearch.node.threadpool.snapshotThreads threadpool.snapshotThreads ElasticSearch elasticsearch.node.transport.connectionsOpened transport.connectionsOpened ElasticSearch elasticsearch.node.transport.packetsReceived transport.packetsReceived ElasticSearch elasticsearch.node.transport.packetsReceivedInBytes transport.packetsReceivedInBytes ElasticSearch elasticsearch.node.transport.packetsSent transport.packetsSent ElasticSearch elasticsearch.node.transport.packetsSentInBytes transport.packetsSentInBytes F5 f5.node.availabilityState node.availabilityState F5 f5.node.connections node.connections F5 f5.node.connectionsPerSecond node.connectionsPerSecond F5 f5.node.enabled node.enabled F5 f5.node.inDataInBytesPerSecond node.inDataInBytesPerSecond F5 f5.node.monitorStatus node.monitorStatus F5 f5.node.outDataInBytesPerSecond node.outDataInBytesPerSecond F5 f5.node.packetsReceivedPerSecond node.packetsReceivedPerSecond F5 f5.node.packetsSentPerSecond node.packetsSentPerSecond F5 f5.node.requestsPerSecond node.requestsPerSecond F5 f5.node.sessions node.sessions F5 f5.node.sessionStatus node.sessionStatus F5 f5.poolMember.availabilityState member.availabilityState F5 f5.poolMember.connections member.connections F5 f5.poolMember.enabled member.enabled F5 f5.poolMember.inDataInBytesPerSecond member.inDataInBytesPerSecond F5 f5.poolMember.monitorStatus member.monitorStatus F5 f5.poolMember.outDataInBytesPerSecond member.outDataInBytesPerSecond F5 f5.poolMember.packetsReceivedPerSecond member.packetsReceivedPerSecond F5 f5.poolMember.packetsSentPerSecond member.packetsSentPerSecond F5 f5.poolMember.requestsPerSecond member.requestsPerSecond F5 f5.poolMember.sessions member.sessions F5 f5.poolMember.sessionStatus member.sessionStatus F5 f5.pool.activeMembers pool.activeMembers F5 f5.pool.availabilityState pool.availabilityState F5 f5.pool.connections pool.connections F5 f5.pool.connqAgeEdm pool.connqAgeEdm F5 f5.pool.connqAgeEma pool.connqAgeEma F5 f5.pool.connqAgeHead pool.connqAgeHead F5 f5.pool.connqAgeMax pool.connqAgeMax F5 f5.pool.connqAllAgeEdm pool.connqAllAgeEdm F5 f5.pool.connqAllAgeEma pool.connqAllAgeEma F5 f5.pool.connqAllAgeHead pool.connqAllAgeHead F5 f5.pool.connqAllAgeMax pool.connqAllAgeMax F5 f5.pool.connqAllDepth pool.connqAllDepth F5 f5.pool.connqDepth pool.connqDepth F5 f5.pool.currentConnections pool.currentConnections F5 f5.pool.enabled pool.enabled F5 f5.pool.inDataInBytesPerSecond pool.inDataInBytesPerSecond F5 f5.pool.minActiveMembers pool.minActiveMembers F5 f5.pool.outDataInBytesPerSecond pool.outDataInBytesPerSecond F5 f5.pool.packetsReceivedPerSecond pool.packetsReceivedPerSecond F5 f5.pool.packetsSentPerSecond pool.packetsSentPerSecond F5 f5.pool.requestsPerSecond pool.requestsPerSecond F5 f5.pool.sessions pool.sessions F5 f5.system.cpuIdleTicksPerSecond system.cpuIdleTicksPerSecond F5 f5.system.cpuIdleUtilization system.cpuIdleUtilization F5 f5.system.cpuInterruptRequestUtilization system.cpuInterruptRequestUtilization F5 f5.system.cpuIoWaitUtilization system.cpuIOWaitUtilization F5 f5.system.cpuNiceLevelUtilization system.cpuNiceLevelUtilization F5 f5.system.cpuSoftInterruptRequestUtilization system.cpuSoftInterruptRequestUtilization F5 f5.system.cpuStolenUtilization system.cpuStolenUtilization F5 f5.system.cpuSystemTicksPerSecond system.cpuSystemTicksPerSecond F5 f5.system.cpuSystemUtilization system.cpuSystemUtilization F5 f5.system.cpuUserTicksPerSecond system.cpuUserTicksPerSecond F5 f5.system.cpuUserUtilization system.cpuUserUtilization F5 f5.system.memoryFreeInBytes system.memoryFreeInBytes F5 f5.system.memoryTotalInBytes system.memoryTotalInBytes F5 f5.system.memoryUsedInBytes system.memoryUsedInBytes F5 f5.system.otherMemoryFreeInBytes system.otherMemoryFreeInBytes F5 f5.system.otherMemoryTotalInBytes system.otherMemoryTotalInBytes F5 f5.system.otherMemoryUsedInBytes system.otherMemoryUsedInBytes F5 f5.system.swapFreeInBytes system.swapFreeInBytes F5 f5.system.swapTotalInBytes system.swapTotalInBytes F5 f5.system.swapUsedInBytes system.swapUsedInBytes F5 f5.system.tmmMemoryFreeInBytes system.tmmMemoryFreeInBytes F5 f5.system.tmmMemoryTotalInBytes system.tmmMemoryTotalInBytes F5 f5.system.tmmMemoryUsedInBytes system.tmmMemoryUsedInBytes F5 f5.virtualserver.availabilityState virtualserver.availabilityState F5 f5.virtualserver.clientsideConnectionsPerSecond virtualserver.clientsideConnectionsPerSecond F5 f5.virtualserver.connections virtualserver.connections F5 f5.virtualserver.csMaxConnDur virtualserver.csMaxConnDur F5 f5.virtualserver.csMeanConnDur virtualserver.csMeanConnDur F5 f5.virtualserver.csMinConnDur virtualserver.csMinConnDur F5 f5.virtualserver.enabled virtualserver.enabled F5 f5.virtualserver.ephemeralBytesInPerSecond virtualserver.ephemeralBytesInPerSecond F5 f5.virtualserver.ephemeralBytesOutPerSecond virtualserver.ephemeralBytesOutPerSecond F5 f5.virtualserver.ephemeralConnectionsPerSecond virtualserver.ephemeralConnectionsPerSecond F5 f5.virtualserver.ephemeralCurrentConnections virtualserver.ephemeralCurrentConnections F5 f5.virtualserver.ephemeralEvictedConnectionsPerSecond virtualserver.ephemeralEvictedConnectionsPerSecond F5 f5.virtualserver.ephemeralMaxConnections virtualserver.ephemeralMaxConnections F5 f5.virtualserver.ephemeralPacketsReceivedPerSecond virtualserver.ephemeralPacketsReceivedPerSecond F5 f5.virtualserver.ephemeralPacketsSentPerSecond virtualserver.ephemeralPacketsSentPerSecond F5 f5.virtualserver.ephemeralSlowKilledPerSecond virtualserver.ephemeralSlowKilledPerSecond F5 f5.virtualserver.evictedConnsPerSecond virtualserver.evictedConnsPerSecond F5 f5.virtualserver.inDataInBytesPerSecond virtualserver.inDataInBytesPerSecond F5 f5.virtualserver.outDataInBytesPerSecond virtualserver.outDataInBytesPerSecond F5 f5.virtualserver.packetsReceivedPerSecond virtualserver.packetsReceivedPerSecond F5 f5.virtualserver.packetsSentPerSecond virtualserver.packetsSentPerSecond F5 f5.virtualserver.requestsPerSecond virtualserver.requestsPerSecond F5 f5.virtualserver.slowKilledPerSecond virtualserver.slowKilledPerSecond F5 f5.virtualserver.usageRatio virtualserver.usageRatio HAProxy haproxy.backend.activeServers backend.activeServers HAProxy haproxy.backend.averageConnectTimeInSeconds backend.averageConnectTimeInSeconds HAProxy haproxy.backend.averageQueueTimeInSeconds backend.averageQueueTimeInSeconds HAProxy haproxy.backend.averageResponseTimeInSeconds backend.averageResponseTimeInSeconds HAProxy haproxy.backend.averageTotalSessionTimeInSeconds backend.averageTotalSessionTimeInSeconds HAProxy haproxy.backend.backupServers backend.backupServers HAProxy haproxy.backend.bytesInPerSecond backend.bytesInPerSecond HAProxy haproxy.backend.bytesOutPerSecond backend.bytesOutPerSecond HAProxy haproxy.backend.bytesThatBypassedCompressorPerSecond backend.bytesThatBypassedCompressorPerSecond HAProxy haproxy.backend.connectingRequestErrorsPerSecond backend.connectingRequestErrorsPerSecond HAProxy haproxy.backend.connectionRetriesPerSecond backend.connectionRetriesPerSecond HAProxy haproxy.backend.currentQueuedRequestsWithoutServer backend.currentQueuedRequestsWithoutServer HAProxy haproxy.backend.currentSessions backend.currentSessions HAProxy haproxy.backend.dataTransfersAbortedByClientPerSecond backend.dataTransfersAbortedByClientPerSecond HAProxy haproxy.backend.dataTransfersAbortedByServerPerSecond backend.dataTransfersAbortedByServerPerSecond HAProxy haproxy.backend.downtimeInSeconds backend.downtimeInSeconds HAProxy haproxy.backend.http100ResponsesPerSecond backend.http100ResponsesPerSecond HAProxy haproxy.backend.http200ResponsesPerSecond backend.http200ResponsesPerSecond HAProxy haproxy.backend.http300ResponsesPerSecond backend.http300ResponsesPerSecond HAProxy haproxy.backend.http400ResponsesPerSecond backend.http400ResponsesPerSecond HAProxy haproxy.backend.http500ResponsesPerSecond backend.http500ResponsesPerSecond HAProxy haproxy.backend.httpOtherResponsesPerSecond backend.httpOtherResponsesPerSecond HAProxy haproxy.backend.httpRequestsPerSecond backend.httpRequestsPerSecond HAProxy haproxy.backend.httpResponseBytesEmittedByCompressorPerSecond backend.httpResponseBytesEmittedByCompressorPerSecond HAProxy haproxy.backend.httpResponseBytesFedToCompressorPerSecond backend.httpResponseBytesFedToCompressorPerSecond HAProxy haproxy.backend.httpResponsesCompressedPerSecond backend.httpResponsesCompressedPerSecond HAProxy haproxy.backend.interceptedRequestsPerSecond backend.interceptedRequestsPerSecond HAProxy haproxy.backend.maxQueuedRequestsWithoutServer backend.maxQueuedRequestsWithoutServer HAProxy haproxy.backend.maxSessions backend.maxSessions HAProxy haproxy.backend.maxSessionsPerSecond backend.maxSessionsPerSecond HAProxy haproxy.backend.requestRedispatchPerSecond backend.requestRedispatchPerSecond HAProxy haproxy.backend.requestsDenied.securityConcernsPerSecond backend.requestsDenied.securityConcernsPerSecond HAProxy haproxy.backend.responseErrorsPerSecond backend.responseErrorsPerSecond HAProxy haproxy.backend.responsesDenied.securityConcernsPerSecond backend.responsesDenied.securityConcernsPerSecond HAProxy haproxy.backend.serverSelectedPerSecond backend.serverSelectedPerSecond HAProxy haproxy.backend.sessionsPerSecond backend.sessionsPerSecond HAProxy haproxy.backend.timeSinceLastSessionAssignedInSeconds backend.timeSinceLastSessionAssignedInSeconds HAProxy haproxy.backend.timeSinceLastUpDownTransitionInSeconds backend.timeSinceLastUpDownTransitionInSeconds HAProxy haproxy.backend.totalWeight backend.totalWeight HAProxy haproxy.backend.type backend.type HAProxy haproxy.backend.upToDownTransitionsPerSecond backend.upToDownTransitionsPerSecond HAProxy haproxy.frontend.bytesInPerSecond frontend.bytesInPerSecond HAProxy haproxy.frontend.bytesOutPerSecond frontend.bytesOutPerSecond HAProxy haproxy.frontend.connectionsPerSecond frontend.connectionsPerSecond HAProxy haproxy.frontend.currentSessions frontend.currentSessions HAProxy haproxy.frontend.http100ResponsesPerSecond frontend.http100ResponsesPerSecond HAProxy haproxy.frontend.http200ResponsesPerSecond frontend.http200ResponsesPerSecond HAProxy haproxy.frontend.http300ResponsesPerSecond frontend.http300ResponsesPerSecond HAProxy haproxy.frontend.http400ResponsesPerSecond frontend.http400ResponsesPerSecond HAProxy haproxy.frontend.http500ResponsesPerSecond frontend.http500ResponsesPerSecond HAProxy haproxy.frontend.httpOtherResponsesPerSecond frontend.httpOtherResponsesPerSecond HAProxy haproxy.frontend.httpRequests.maxPerSecond frontend.httpRequests.maxPerSecond HAProxy haproxy.frontend.httpRequestsPerSecond frontend.httpRequestsPerSecond HAProxy haproxy.frontend.interceptedRequestsPerSecond frontend.interceptedRequestsPerSecond HAProxy haproxy.frontend.maxConnectionsPerSecond frontend.maxConnectionsPerSecond HAProxy haproxy.frontend.maxSessions frontend.maxSessions HAProxy haproxy.frontend.maxSessionsPerSecond frontend.maxSessionsPerSecond HAProxy haproxy.frontend.requestErrorsPerSecond frontend.requestErrorsPerSecond HAProxy haproxy.frontend.requestsDenied.securityConcernsPerSecond frontend.requestsDenied.securityConcernsPerSecond HAProxy haproxy.frontend.requestsDenied.tcpRequestConnectionRulesPerSecond frontend.requestsDenied.tcpRequestConnectionRulesPerSecond HAProxy haproxy.frontend.requestsDenied.tcpRequestSessionRulesPerSecond frontend.requestsDenied.tcpRequestSessionRulesPerSecond HAProxy haproxy.frontend.responsesDenied.securityConcernsPerSecond frontend.responsesDenied.securityConcernsPerSecond HAProxy haproxy.frontend.sessionsPerSecond frontend.sessionsPerSecond HAProxy haproxy.server.averageConnectTimeInSeconds server.averageConnectTimeInSeconds HAProxy haproxy.server.averageQueueTimeInSeconds server.averageQueueTimeInSeconds HAProxy haproxy.server.averageResponseTimeInSeconds server.averageResponseTimeInSeconds HAProxy haproxy.server.averageTotalSessionTimeInSeconds server.averageTotalSessionTimeInSeconds HAProxy haproxy.server.bytesInPerSecond server.bytesInPerSecond HAProxy haproxy.server.bytesOutPerSecond server.bytesOutPerSecond HAProxy haproxy.server.connectingRequestErrorsPerSecond server.connectingRequestErrorsPerSecond HAProxy haproxy.server.connectionRetriesPerSecond server.connectionRetriesPerSecond HAProxy haproxy.server.currentQueuedRequestsWithoutServer server.currentQueuedRequestsWithoutServer HAProxy haproxy.server.currentSessions server.currentSessions HAProxy haproxy.server.dataTransfersAbortedByClientPerSecond server.dataTransfersAbortedByClientPerSecond HAProxy haproxy.server.dataTransfersAbortedByServerPerSecond server.dataTransfersAbortedByServerPerSecond HAProxy haproxy.server.downtimeInSeconds server.downtimeInSeconds HAProxy haproxy.server.failedChecksPerSecond server.failedChecksPerSecond HAProxy haproxy.server.healthCheckDurationInMilliseconds server.healthCheckDurationInMilliseconds HAProxy haproxy.server.http100ResponsesPerSecond server.http100ResponsesPerSecond HAProxy haproxy.server.http200ResponsesPerSecond server.http200ResponsesPerSecond HAProxy haproxy.server.http300ResponsesPerSecond server.http300ResponsesPerSecond HAProxy haproxy.server.http400ResponsesPerSecond server.http400ResponsesPerSecond HAProxy haproxy.server.http500ResponsesPerSecond server.http500ResponsesPerSecond HAProxy haproxy.server.httpOtherResponsesPerSecond server.httpOtherResponsesPerSecond HAProxy haproxy.server.isActive server.isActive HAProxy haproxy.server.isBackup server.isBackup HAProxy haproxy.server.maxQueuedRequestsWithoutServer server.maxQueuedRequestsWithoutServer HAProxy haproxy.server.maxSessions server.maxSessions HAProxy haproxy.server.maxSessionsPerSecond server.maxSessionsPerSecond HAProxy haproxy.server.requestRedispatchPerSecond server.requestRedispatchPerSecond HAProxy haproxy.server.requestsDenied.securityConcernsPerSecond server.requestsDenied.securityConcernsPerSecond HAProxy haproxy.server.responseErrorsPerSecond server.responseErrorsPerSecond HAProxy haproxy.server.responsesDenied.securityConcernsPerSecond server.responsesDenied.securityConcernsPerSecond HAProxy haproxy.server.serverSelectedPerSecond server.serverSelectedPerSecond HAProxy haproxy.server.serverWeight server.serverWeight HAProxy haproxy.server.sessionsPerSecond server.sessionsPerSecond HAProxy haproxy.server.throttlePercentage server.throttlePercentage HAProxy haproxy.server.timeSinceLastSessionAssignedInSeconds server.timeSinceLastSessionAssignedInSeconds HAProxy haproxy.server.timeSinceLastUpDownTransitionInSeconds server.timeSinceLastUpDownTransitionInSeconds HAProxy haproxy.server.type server.type HAProxy haproxy.server.upToDownTransitionsPerSecond server.upToDownTransitionsPerSecond Kafka kafka.broker.bytesWrittenToTopicPerSecond broker.bytesWrittenToTopicPerSecond Kafka kafka.broker.consumer.requestsExpiredPerSecond consumer.requestsExpiredPerSecond Kafka kafka.broker.follower.requestExpirationPerSecond follower.requestExpirationPerSecond Kafka kafka.broker.ioInPerSecond broker.IOInPerSecond Kafka kafka.broker.ioOutPerSecond broker.IOOutPerSecond Kafka kafka.broker.logFlushPerSecond broker.logFlushPerSecond Kafka kafka.broker.messagesInPerSecond broker.messagesInPerSecond Kafka kafka.broker.net.bytesRejectedPerSecond net.bytesRejectedPerSecond Kafka kafka.broker.replication.isrExpandsPerSecond replication.isrExpandsPerSecond Kafka kafka.broker.replication.isrShrinksPerSecond replication.isrShrinksPerSecond Kafka kafka.broker.replication.leaderElectionPerSecond replication.leaderElectionPerSecond Kafka kafka.broker.replication.uncleanLeaderElectionPerSecond replication.uncleanLeaderElectionPerSecond Kafka kafka.broker.replication.unreplicatedPartitions replication.unreplicatedPartitions Kafka kafka.broker.request.avgTimeFetch request.avgTimeFetch Kafka kafka.broker.request.avgTimeMetadata request.avgTimeMetadata Kafka kafka.broker.request.avgTimeMetadata99Percentile request.avgTimeMetadata99Percentile Kafka kafka.broker.request.avgTimeOffset request.avgTimeOffset Kafka kafka.broker.request.avgTimeOffset99Percentile request.avgTimeOffset99Percentile Kafka kafka.broker.request.avgTimeProduceRequest request.avgTimeProduceRequest Kafka kafka.broker.request.avgTimeUpdateMetadata request.avgTimeUpdateMetadata Kafka kafka.broker.request.avgTimeUpdateMetadata99Percentile request.avgTimeUpdateMetadata99Percentile Kafka kafka.broker.request.clientFetchesFailedPerSecond request.clientFetchesFailedPerSecond Kafka kafka.broker.request.fetchConsumerRequestsPerSecond request.fetchConsumerRequestsPerSecond Kafka kafka.broker.request.fetchFollowerRequestsPerSecond request.fetchFollowerRequestsPerSecond Kafka kafka.broker.request.fetchTime99Percentile request.fetchTime99Percentile Kafka kafka.broker.request.handlerIdle request.handlerIdle Kafka kafka.broker.request.listGroupsRequestsPerSecond request.listGroupsRequestsPerSecond Kafka kafka.broker.request.metadataRequestsPerSecond request.metadataRequestsPerSecond Kafka kafka.broker.request.offsetCommitRequestsPerSecond request.offsetCommitRequestsPerSecond Kafka kafka.broker.request.produceRequestsFailedPerSecond request.produceRequestsFailedPerSecond Kafka kafka.broker.request.produceRequestsPerSecond request.produceRequestsPerSecond Kafka kafka.broker.request.produceTime99Percentile request.produceTime99Percentile Kafka kafka.broker.topic.diskSize topic.diskSize Kafka kafka.topic.bytesInPerSec topic.BytesInPerSec Kafka kafka.topic.bytesOutPerSec topic.BytesOutPerSec Kafka kafka.topic.messagesInPerSec topic.MessagesInPerSec Kafka kafka.topic.partitionsWithNonPreferredLeader topic.partitionsWithNonPreferredLeader Kafka kafka.topic.respondsToMetadataRequests topic.respondsToMetadataRequests Kafka kafka.topic.retentionBytesOrTime topic.retentionBytesOrTime Kafka kafka.topic.underReplicatedPartitions topic.underReplicatedPartitions Kafka kafka.producer.ageMetadataUsedInMilliseconds producer.ageMetadataUsedInMilliseconds Kafka kafka.producer.availableBufferInBytes producer.availableBufferInBytes Kafka kafka.producer.avgBytesSentPerRequestInBytes producer.avgBytesSentPerRequestInBytes Kafka kafka.producer.avgCompressionRateRecordBatches producer.avgCompressionRateRecordBatches Kafka kafka.producer.avgRecordAccumulatorsInMilliseconds producer.avgRecordAccumulatorsInMilliseconds Kafka kafka.producer.avgRecordSizeInBytes producer.avgRecordSizeInBytes Kafka kafka.producer.avgRecordsSentPerSecond producer.avgRecordsSentPerSecond Kafka kafka.producer.avgRecordsSentPerTopicPerSecond producer.avgRecordsSentPerTopicPerSecond Kafka kafka.producer.avgRequestLatency producer.avgRequestLatencyPerSecond Kafka kafka.producer.avgThrottleTime producer.avgThrottleTime Kafka kafka.producer.bufferMemoryAvailableInBytes producer.bufferMemoryAvailableInBytes Kafka kafka.producer.bufferpoolWaitTime producer.bufferpoolWaitTime Kafka kafka.producer.bytesOutPerSecond producer.bytesOutPerSecond Kafka kafka.producer.compressionRateRecordBatches producer.compressionRateRecordBatches Kafka kafka.producer.ioWaitTime producer.ioWaitTime Kafka kafka.producer.maxBytesSentPerRequestInBytes producer.maxBytesSentPerRequestInBytes Kafka kafka.producer.maxRecordSizeInBytes producer.maxRecordSizeInBytes Kafka kafka.producer.maxRequestLatencyInMilliseconds producer.maxRequestLatencyInMilliseconds Kafka kafka.producer.maxThrottleTime producer.maxThrottleTime Kafka kafka.producer.requestPerSecond producer.requestPerSecond Kafka kafka.producer.requestsWaitingResponse producer.requestsWaitingResponse Kafka kafka.producer.responsePerSecond producer.responsePerSecond Kafka kafka.producer.threadsWaiting producer.threadsWaiting Kafka kafka.consumer.avgFetchSizeInBytes consumer.avgFetchSizeInBytes Kafka kafka.consumer.avgRecordConsumedPerTopic consumer.avgRecordConsumedPerTopic Kafka kafka.consumer.avgRecordConsumedPerTopicPerSecond consumer.avgRecordConsumedPerTopicPerSecond Kafka kafka.consumer.bytesInPerSecond consumer.bytesInPerSecond Kafka kafka.consumer.fetchPerSecond consumer.fetchPerSecond Kafka kafka.consumer.hwm consumer.hwm Kafka kafka.consumer.lag consumer.lag Kafka kafka.consumer.maxFetchSizeInBytes consumer.maxFetchSizeInBytes Kafka kafka.consumer.maxLag consumer.maxLag Kafka kafka.consumer.messageConsumptionPerSecond consumer.messageConsumptionPerSecond Kafka kafka.consumer.offset consumer.offset Kafka kafka.consumer.totalLag consumer.totalLag Kafka kafka.consumerGroup.maxLag consumerGroup.maxLag Kafka kafka.consumerGroup.totalLag consumerGroup.totalLag Kubernetes k8s.apiserver.goGoroutines goGoroutines Kubernetes k8s.apiserver.goThreads goThreads Kubernetes k8s.apiserver.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.apiserver.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.controllermanager.goGoroutines goGoroutines Kubernetes k8s.controllermanager.goThreads goThreads Kubernetes k8s.controllermanager.leaderElectionMasterStatus leaderElectionMasterStatus Kubernetes k8s.controllermanager.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.controllermanager.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.etcd.goGoroutines goGoroutines Kubernetes k8s.etcd.goThreads goThreads Kubernetes k8s.etcd.mvccDbTotalSizeInBytes etcdMvccDbTotalSizeInBytes Kubernetes k8s.etcd.networkClientGrpcReceivedBytesRate etcdNetworkClientGrpcReceivedBytesRate Kubernetes k8s.etcd.networkClientGrpcSentBytesRate etcdNetworkClientGrpcSentBytesRate Kubernetes k8s.etcd.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.etcd.process.maxFds processMaxFds Kubernetes k8s.etcd.process.openFds processOpenFds Kubernetes k8s.etcd.process.processFdsUtilization processFdsUtilization Kubernetes k8s.etcd.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.etcd.serverHasLeader etcdServerHasLeader Kubernetes k8s.etcd.serverLeaderChangesSeenDelta etcdServerLeaderChangesSeenDelta Kubernetes k8s.etcd.serverProposalsAppliedDelta etcdServerProposalsAppliedDelta Kubernetes k8s.etcd.serverProposalsAppliedRate etcdServerProposalsAppliedRate Kubernetes k8s.etcd.serverProposalsCommittedDelta etcdServerProposalsCommittedDelta Kubernetes k8s.etcd.serverProposalsCommittedRate etcdServerProposalsCommittedRate Kubernetes k8s.etcd.serverProposalsFailedDelta etcdServerProposalsFailedDelta Kubernetes k8s.etcd.serverProposalsFailedRate etcdServerProposalsFailedRate Kubernetes k8s.etcd.serverProposalsPending etcdServerProposalsPending Kubernetes k8s.scheduler.goGoroutines goGoroutines Kubernetes k8s.scheduler.goThreads goThreads Kubernetes k8s.scheduler.leaderElectionMasterStatus leaderElectionMasterStatus Kubernetes k8s.scheduler.podPreemptionVictims schedulerPodPreemptionVictims Kubernetes k8s.scheduler.preemptionAttemptsDelta schedulerPreemptionAttemptsDelta Kubernetes k8s.scheduler.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.scheduler.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.container.cpuCfsPeriodsDelta containerCpuCfsPeriodsDelta Kubernetes k8s.container.cpuCfsPeriodsTotal containerCpuCfsPeriodsTotal Kubernetes k8s.container.cpuCfsThrottledPeriodsDelta containerCpuCfsThrottledPeriodsDelta Kubernetes k8s.container.cpuCfsThrottledPeriodsTotal containerCpuCfsThrottledPeriodsTotal Kubernetes k8s.container.cpuCfsThrottledSecondsDelta containerCpuCfsThrottledSecondsDelta Kubernetes k8s.container.cpuCfsThrottledSecondsTotal containerCpuCfsThrottledSecondsTotal Kubernetes k8s.container.cpuCoresUtilization cpuCoresUtilization Kubernetes k8s.container.cpuLimitCores cpuLimitCores Kubernetes k8s.container.cpuRequestedCores cpuRequestedCores Kubernetes k8s.container.cpuUsedCores cpuUsedCores Kubernetes k8s.container.fsAvailableBytes fsAvailableBytes Kubernetes k8s.container.fsCapacityBytes fsCapacityBytes Kubernetes k8s.container.fsInodes fsInodes Kubernetes k8s.container.fsInodesFree fsInodesFree Kubernetes k8s.container.fsInodesUsed fsInodesUsed Kubernetes k8s.container.fsUsedBytes fsUsedBytes Kubernetes k8s.container.fsUsedPercent fsUsedPercent Kubernetes k8s.container.isReady isReady Kubernetes k8s.container.memoryLimitBytes memoryLimitBytes Kubernetes k8s.container.memoryMappedFileBytes containerMemoryMappedFileBytes Kubernetes k8s.container.memoryRequestedBytes memoryRequestedBytes Kubernetes k8s.container.memoryUsedBytes memoryUsedBytes Kubernetes k8s.container.memoryUtilization memoryUtilization Kubernetes k8s.container.memoryWorkingSetBytes memoryWorkingSetBytes Kubernetes k8s.container.requestedCpuCoresUtilization requestedCpuCoresUtilization Kubernetes k8s.container.requestedMemoryUtilization requestedMemoryUtilization Kubernetes k8s.container.restartCount restartCount Kubernetes k8s.daemonset.createdAt createdAt Kubernetes k8s.daemonset.metadataGeneration metadataGeneration Kubernetes k8s.daemonset.podsAvailable podsAvailable Kubernetes k8s.daemonset.podsDesired podsDesired Kubernetes k8s.daemonset.podsMisscheduled podsMisscheduled Kubernetes k8s.daemonset.podsReady podsReady Kubernetes k8s.daemonset.podsScheduled podsScheduled Kubernetes k8s.daemonset.podsUnavailable podsUnavailable Kubernetes k8s.daemonset.podsUpdatedScheduled podsUpdatedScheduled Kubernetes k8s.deployment.createdAt createdAt Kubernetes k8s.deployment.podsAvailable podsAvailable Kubernetes k8s.deployment.podsDesired podsDesired Kubernetes k8s.deployment.podsMaxUnavailable podsMaxUnavailable Kubernetes k8s.deployment.podsTotal podsTotal Kubernetes k8s.deployment.podsUnavailable podsUnavailable Kubernetes k8s.deployment.podsUpdated podsUpdated Kubernetes k8s.endpoint.addressAvailable addressAvailable Kubernetes k8s.endpoint.addressNotReady addressNotReady Kubernetes k8s.endpoint.createdAt createdAt Kubernetes k8s.namespace.createdAt createdAt Kubernetes k8s.node.allocatableAttachableVolumes* allocatableAttachableVolumes* Kubernetes k8s.node.allocatableCpuCores allocatableCpuCores Kubernetes k8s.node.allocatableCpuCoresUtilization allocatableCpuCoresUtilization Kubernetes k8s.node.allocatableEphemeralStorageBytes allocatableEphemeralStorageBytes Kubernetes k8s.node.allocatableHugepages* allocatableHugepages* Kubernetes k8s.node.allocatableMemoryBytes allocatableMemoryBytes Kubernetes k8s.node.allocatableMemoryUtilization allocatableMemoryUtilization Kubernetes k8s.node.allocatablePods allocatablePods Kubernetes k8s.node.capacityAttachableVolumes* capacityAttachableVolumes* Kubernetes k8s.node.capacityCpuCores capacityCpuCores Kubernetes k8s.node.capacityEphemeralStorageBytes capacityEphemeralStorageBytes Kubernetes k8s.node.capacityHugepages* capacityHugepages* Kubernetes k8s.node.capacityMemoryBytes capacityMemoryBytes Kubernetes k8s.node.capacityPods capacityPods Kubernetes k8s.node.cpuUsedCoreMilliseconds cpuUsedCoreMilliseconds Kubernetes k8s.node.cpuUsedCores cpuUsedCores Kubernetes k8s.node.fsAvailableBytes fsAvailableBytes Kubernetes k8s.node.fsCapacityBytes fsCapacityBytes Kubernetes k8s.node.fsCapacityUtilization fsCapacityUtilization Kubernetes k8s.node.fsInodes fsInodes Kubernetes k8s.node.fsInodesFree fsInodesFree Kubernetes k8s.node.fsInodesUsed fsInodesUsed Kubernetes k8s.node.fsUsedBytes fsUsedBytes Kubernetes k8s.node.memoryAvailableBytes memoryAvailableBytes Kubernetes k8s.node.memoryMajorPageFaultsPerSecond memoryMajorPageFaultsPerSecond Kubernetes k8s.node.memoryPageFaults memoryPageFaults Kubernetes k8s.node.memoryRssBytes memoryRssBytes Kubernetes k8s.node.memoryUsedBytes memoryUsedBytes Kubernetes k8s.node.memoryWorkingSetBytes memoryWorkingSetBytes Kubernetes k8s.node.netErrorsPerSecond net.errorsPerSecond Kubernetes k8s.node.netRxBytesPerSecond net.rxBytesPerSecond Kubernetes k8s.node.netTxBytesPerSecond net.txBytesPerSecond Kubernetes k8s.node.runtimeAvailableBytes runtimeAvailableBytes Kubernetes k8s.node.runtimeCapacityBytes runtimeCapacityBytes Kubernetes k8s.node.runtimeInodes runtimeInodes Kubernetes k8s.node.runtimeInodesFree runtimeInodesFree Kubernetes k8s.node.runtimeInodesUsed runtimeInodesUsed Kubernetes k8s.node.runtimeUsedBytes runtimeUsedBytes Kubernetes k8s.pod.createdAt createdAt Kubernetes k8s.pod.isReady isReady Kubernetes k8s.pod.isScheduled isScheduled Kubernetes k8s.pod.netErrorsPerSecond net.errorsPerSecond Kubernetes k8s.pod.netRxBytesPerSecond net.rxBytesPerSecond Kubernetes k8s.pod.netTxBytesPerSecond net.txBytesPerSecond Kubernetes k8s.pod.startTime startTime Kubernetes k8s.replicaset.createdAt createdAt Kubernetes k8s.replicaset.observedGeneration observedGeneration Kubernetes k8s.replicaset.podsDesired podsDesired Kubernetes k8s.replicaset.podsFullyLabeled podsFullyLabeled Kubernetes k8s.replicaset.podsMissing podsMissing Kubernetes k8s.replicaset.podsReady podsReady Kubernetes k8s.replicaset.podsTotal podsTotal Kubernetes k8s.service.createdAt createdAt Kubernetes k8s.statefulset.createdAt createdAt Kubernetes k8s.statefulset.currentRevision currentRevision Kubernetes k8s.statefulset.metadataGeneration metadataGeneration Kubernetes k8s.statefulset.observedGeneration observedGeneration Kubernetes k8s.statefulset.podsCurrent podsCurrent Kubernetes k8s.statefulset.podsDesired podsDesired Kubernetes k8s.statefulset.podsReady podsReady Kubernetes k8s.statefulset.podsTotal podsTotal Kubernetes k8s.statefulset.podsUpdated podsUpdated Kubernetes k8s.statefulset.updateRevision updateRevision Kubernetes k8s.volume.fsAvailableBytes fsAvailableBytes Kubernetes k8s.volume.fsCapacityBytes fsCapacityBytes Kubernetes k8s.volume.fsInodes fsInodes Kubernetes k8s.volume.fsInodesFree fsInodesFree Kubernetes k8s.volume.fsInodesUsed fsInodesUsed Kubernetes k8s.volume.fsUsedBytes fsUsedBytes Kubernetes k8s.volume.fsUsedPercent fsUsedPercent Memcached memcached.server.activeSlabs activeSlabs Memcached memcached.server.avgItemSizeInBytes avgItemSizeInBytes Memcached memcached.server.bytesReadServerPerSecond bytesReadServerPerSecond Memcached memcached.server.bytesUsedServerInBytes bytesUsedServerInBytes Memcached memcached.server.bytesWrittenServerPerSecond bytesWrittenServerPerSecond Memcached memcached.server.casHitRatePerSecond casHitRatePerSecond Memcached memcached.server.casMissRatePerSecond casMissRatePerSecond Memcached memcached.server.casWrongRatePerSecond casWrongRatePerSecond Memcached memcached.server.cmdFlushRatePerSecond cmdFlushRatePerSecond Memcached memcached.server.cmdGetRatePerSecond cmdGetRatePerSecond Memcached memcached.server.cmdSetRatePerSecond cmdSetRatePerSecond Memcached memcached.server.connectionRateServerPerSecond connectionRateServerPerSecond Memcached memcached.server.connectionStructuresAllocated connectionStructuresAllocated Memcached memcached.server.currentItemsStoredServer currentItemsStoredServer Memcached memcached.server.deleteCmdNoneRemovedPerSecond deleteCmdNoneRemovedPerSecond Memcached memcached.server.deleteCmdRemovedPerSecond deleteCmdRemovedPerSecond Memcached memcached.server.evictionsPerSecond evictionsPerSecond Memcached memcached.server.getHitPercent getHitPercent Memcached memcached.server.getHitPerSecond getHitPerSecond Memcached memcached.server.getMissPerSecond getMissPerSecond Memcached memcached.server.itemsStoredPerSecond itemsStoredPerSecond Memcached memcached.server.limitBytesStorage limitBytesStorage Memcached memcached.server.limitMaxBytes limitMaxBytes Memcached memcached.server.maxConnectionLimitPerSecond serverMaxConnectionLimitPerSecond Memcached memcached.server.memAllocatedSlabsInBytes memAllocatedSlabsInBytes Memcached memcached.server.openConnectionsServer openConnectionsServer Memcached memcached.server.pointerSize pointerSize Memcached memcached.server.rusageSystem usageRate Memcached memcached.server.rusageUser executionTime Memcached memcached.server.storingItemsPercentMemory storingItemsPercentMemory Memcached memcached.server.threads threads Memcached memcached.server.uptimeInMilliseconds uptimeInMilliseconds Memcached memcached.slab.activeItemsBumpedPerSecond activeItemsBumpedPerSecond Memcached memcached.slab.casBadValPerSecond casBadValPerSecond Memcached memcached.slab.casModifiedSlabPerSecond casModifiedSlabPerSecond Memcached memcached.slab.chunkSizeInBytes chunkSizeInBytes Memcached memcached.slab.chunksPerPage chunksPerPage Memcached memcached.slab.cmdSetRateSlabPerSecond cmdSetRateSlabPerSecond Memcached memcached.slab.decrsModifySlabPerSecond decrsModifySlabPerSecond Memcached memcached.slab.deleteRateSlabPerSecond deleteRateSlabPerSecond Memcached memcached.slab.entriesReclaimedPerSecond entriesReclaimedPerSecond Memcached memcached.slab.evictionsBeforeExpirationPerSecond evictionsBeforeExpirationPerSecond Memcached memcached.slab.evictionsBeforeExplicitExpirationPerSecond evictionsBeforeExplicitExpirationPerSecond Memcached memcached.slab.expiredItemsReclaimedPerSecond expiredItemsReclaimedPerSecond Memcached memcached.slab.freedChunks freedChunks Memcached memcached.slab.freedChunksEnd freedChunksEnd Memcached memcached.slab.getHitRateSlabPerSecond getHitRateSlabPerSecond Memcached memcached.slab.incrsModifySlabPerSecond incrsModifySlabPerSecond Memcached memcached.slab.itemsCold itemsCold Memcached memcached.slab.itemsColdPerSecond itemsColdPerSecond Memcached memcached.slab.itemsDirectReclaimedPerSecond itemsDirectReclaimedPerSecond Memcached memcached.slab.itemsFreedCrawlerPerSecond itemsFreedCrawlerPerSecond Memcached memcached.slab.itemsHot itemsHot Memcached memcached.slab.itemsOldestInMilliseconds itemsOldestInMilliseconds Memcached memcached.slab.itemsRefcountLockedPerSecond itemsRefcountLockedPerSecond Memcached memcached.slab.itemsSlabClass itemsSlabClass Memcached memcached.slab.itemsTimeSinceEvictionInMilliseconds itemsTimeSinceEvictionInMilliseconds Memcached memcached.slab.itemsWarm itemsWarm Memcached memcached.slab.itemsWarmPerSecond itemsWarmPerSecond Memcached memcached.slab.memRequestedSlabInBytesPerSecond memRequestedSlabInBytesPerSecond Memcached memcached.slab.outOfMemoryPerSecond outOfMemoryPerSecond Memcached memcached.slab.selfHealedSlabPerSecond selfHealedSlabPerSecond Memcached memcached.slab.totalChunksSlab totalChunksSlab Memcached memcached.slab.totalPagesSlab totalPagesSlab Memcached memcached.slab.touchHitSlabPerSecond touchHitSlabPerSecond Memcached memcached.slab.usedChunksItems usedChunksItems Memcached memcached.slab.usedChunksPerSecond usedChunksPerSecond Memcached memcached.slab.validItemsEvictedPerSecond validItemsEvictedPerSecond MongoDB mongo.index.accesses collection.indexAccesses MongoDB mongo.index.sizeInBytes collection.indexSizeInBytes MongoDB mongo.collection.avgObjSizeInBytes collection.avgObjSizeInBytes MongoDB mongo.collection.capped collection.capped MongoDB mongo.collection.count collection.count MongoDB mongo.collection.max collection.max MongoDB mongo.collection.maxSizeInBytes collection.maxSizeInBytes MongoDB mongo.collection.nindexes collection.nindexes MongoDB mongo.collection.sizeInBytes collection.sizeInBytes MongoDB mongo.collection.storageSizeInBytes collection.storageSizeInBytes MongoDB mongo.configServer.asserts.messagesPerSecond asserts.messagesPerSecond MongoDB mongo.configServer.asserts.regularPerSecond asserts.regularPerSecond MongoDB mongo.configServer.asserts.rolloversPerSecond asserts.rolloversPerSecond MongoDB mongo.configServer.asserts.userPerSecond asserts.userPerSecond MongoDB mongo.configServer.asserts.warningPerSecond asserts.warningPerSecond MongoDB mongo.configServer.commands.countFailedPerSecond commands.countFailedPerSecond MongoDB mongo.configServer.commands.countPerSecond commands.countPerSecond MongoDB mongo.configServer.commands.createIndexesFailedPerSecond commands.createIndexesFailedPerSecond MongoDB mongo.configServer.commands.createIndexesPerSecond commands.createIndexesPerSecond MongoDB mongo.configServer.commands.deleteFailedPerSecond commands.deleteFailedPerSecond MongoDB mongo.configServer.commands.deletePerSecond commands.deletePerSecond MongoDB mongo.configServer.commands.evalFailedPerSecond commands.evalFailedPerSecond MongoDB mongo.configServer.commands.evalPerSecond commands.evalPerSecond MongoDB mongo.configServer.commands.findAndModifyFailedPerSecond commands.findAndModifyFailedPerSecond MongoDB mongo.configServer.commands.findAndModifyPerSecond commands.findAndModifyPerSecond MongoDB mongo.configServer.commands.insertFailedPerSecond commands.insertFailedPerSecond MongoDB mongo.configServer.commands.insertPerSecond commands.insertPerSecond MongoDB mongo.configServer.commands.updateFailedPerSecond commands.updateFailedPerSecond MongoDB mongo.configServer.commands.updatePerSecond commands.updatePerSecond MongoDB mongo.configServer.connections.available connections.available MongoDB mongo.configServer.connections.current connections.current MongoDB mongo.configServer.connections.totalCreated connections.totalCreated MongoDB mongo.configServer.cursor.openNoTimeout cursor.openNoTimeout MongoDB mongo.configServer.cursor.openPinned cursor.openPinned MongoDB mongo.configServer.cursor.openTotal cursor.openTotal MongoDB mongo.configServer.cursor.timedOutPerSecond cursor.timedOutPerSecond MongoDB mongo.configServer.document.deletedPerSecond document.deletedPerSecond MongoDB mongo.configServer.document.insertedPerSecond document.insertedPerSecond MongoDB mongo.configServer.document.returnedPerSecond document.returnedPerSecond MongoDB mongo.configServer.document.updatedPerSecond document.updatedPerSecond MongoDB mongo.configServer.dur.commits dur.commits MongoDB mongo.configServer.dur.commitsInWriteLock dur.commitsInWriteLock MongoDB mongo.configServer.dur.compression dur.compression MongoDB mongo.configServer.dur.earlyCommits dur.earlyCommits MongoDB mongo.configServer.dur.preparingInMilliseconds dur.preparingInMilliseconds MongoDB mongo.configServer.dur.remappingInMilliseconds dur.remappingInMilliseconds MongoDB mongo.configServer.dur.timeCollectedCommitsInMilliseconds dur.timeCollectedCommitsInMilliseconds MongoDB mongo.configServer.dur.writingDataFilesInMilliseconds dur.writingDataFilesInMilliseconds MongoDB mongo.configServer.dur.writingJournalInMilliseconds dur.writingJournalInMilliseconds MongoDB mongo.configServer.flush.averageInMilliseconds flush.averageInMilliseconds MongoDB mongo.configServer.flush.flushesDisk flush.flushesDisk MongoDB mongo.configServer.flush.lastInMilliseconds flush.lastInMilliseconds MongoDB mongo.configServer.flush.totalInMilliseconds flush.totalInMilliseconds MongoDB mongo.configServer.getlasterror.wtimeMillisPerSecond getlasterror.wtimeMillisPerSecond MongoDB mongo.configServer.getlasterror.wtimeoutsPerSecond getlasterror.wtimeoutsPerSecond MongoDB mongo.configServer.globallock.activeClientsReaders globallock.activeClientsReaders MongoDB mongo.configServer.globallock.activeClientsTotal globallock.activeClientsTotal MongoDB mongo.configServer.globallock.activeClientsWriters globallock.activeClientsWriters MongoDB mongo.configServer.globallock.currentQueueReaders globallock.currentQueueReaders MongoDB mongo.configServer.globallock.currentQueueTotal globallock.currentQueueTotal MongoDB mongo.configServer.globallock.currentQueueWriters globallock.currentQueueWriters MongoDB mongo.configServer.globallock.totalTime globallock.totaltime MongoDB mongo.configServer.locks.collectionAcquireExclusive locks.collectionAcquireExclusive MongoDB mongo.configServer.locks.collectionAcquireIntentExclusive locks.collectionAcquireIntentExclusive MongoDB mongo.configServer.locks.collectionAcquireIntentShared locks.collectionAcquireIntentShared MongoDB mongo.configServer.locks.collectionAcquireWaitCountExclusive locks.collectionAcquireWaitCountExclusive MongoDB mongo.configServer.locks.collectionTimeAcquiringMicrosExclusive locks.collectionTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.databaseAcquireExclusive locks.databaseAcquireExclusive MongoDB mongo.configServer.locks.databaseAcquireIntentExclusive locks.databaseAcquireIntentExclusive MongoDB mongo.configServer.locks.databaseAcquireIntentShared locks.databaseAcquireIntentShared MongoDB mongo.configServer.locks.databaseAcquireShared locks.databaseAcquireShared MongoDB mongo.configServer.locks.databaseAcquireWaitExclusive locks.databaseAcquireWaitExclusive MongoDB mongo.configServer.locks.databaseAcquireWaitIntentExclusive locks.databaseAcquireWaitIntentExclusive MongoDB mongo.configServer.locks.databaseAcquireWaitIntentShared locks.databaseAcquireWaitIntentShared MongoDB mongo.configServer.locks.databaseAcquireWaitShared locks.databaseAcquireWaitShared MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosExclusive locks.databaseTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosIntentExclusive locks.databaseTimeAcquiringMicrosIntentExclusive MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosIntentShared locks.databaseTimeAcquiringMicrosIntentShared MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosShared locks.databaseTimeAcquiringMicrosShared MongoDB mongo.configServer.locks.globalAcquireExclusive locks.globalAcquireExclusive MongoDB mongo.configServer.locks.globalAcquireIntentExclusive locks.globalAcquireIntentExclusive MongoDB mongo.configServer.locks.globalAcquireIntentShared locks.globalAcquireIntentShared MongoDB mongo.configServer.locks.globalAcquireShared locks.globalAcquireShared MongoDB mongo.configServer.locks.globalAcquireWaitExclusive locks.globalAcquireWaitExclusive MongoDB mongo.configServer.locks.globalAcquireWaitIntentExclusive locks.globalAcquireWaitIntentExclusive MongoDB mongo.configServer.locks.globalAcquireWaitIntentShared locks.globalAcquireWaitIntentShared MongoDB mongo.configServer.locks.globalAcquireWaitShared locks.globalAcquireWaitShared MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosExclusive locks.globalTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosIntentExclusive locks.globalTimeAcquiringMicrosIntentExclusive MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosIntentShared locks.globalTimeAcquiringMicrosIntentShared MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosShared locks.globalTimeAcquiringMicrosShared MongoDB mongo.configServer.locks.metadataAcquireExclusive locks.metadataAcquireExclusive MongoDB mongo.configServer.locks.oplogAcquireExclusive locks.oplogAcquireExclusive MongoDB mongo.configServer.locks.oplogAcquireIntentExclusive locks.oplogAcquireIntentExclusive MongoDB mongo.configServer.locks.oplogAcquireIntentShared locks.oplogAcquireIntentShared MongoDB mongo",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 358.85785,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": "New Relic Integrations Metrics The following table contains the metrics we collect for our <em>infrastructure</em> integrations. Integration Dimensional Metric Name (new) Sample Metric Name (previous) Agent host.cpuIdlePercent cpuIdlePercent Agent host.cpuIoWaitPercent cpuIOWaitPercent Agent host.cpuPercent"
      },
      "id": "603e8a8a64441f69a34e8841"
    },
    {
      "sections": [
        "Default infrastructure monitoring data",
        "Important",
        "Infrastructure events",
        "Supported Linux storage systems",
        "Supported Windows storage systems",
        "Query infrastructure data",
        "Manage data",
        "Add custom attributes",
        "Common Amazon EC2 attributes",
        "awsRegion",
        "awsAvailabilityZone",
        "ec2InstanceType",
        "ec2InstanceId",
        "ec2AmiId",
        "ec2SubnetId",
        "ec2VpcId",
        "Other Amazon EC2 attributes"
      ],
      "title": "Default infrastructure monitoring data ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "01647189a48892103f4dc6abe07ce29d5fc13f0d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/default-infrastructure-monitoring-data/",
      "published_at": "2021-06-14T21:14:34Z",
      "updated_at": "2021-03-30T08:36:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of April 12, 2021, we are upgrading Insights to an improved web and mobile experience! All of your Insights URLs will be redirected automatically to the corresponding dashboards in New Relic One. For more details about this migration and how you can easily plan for this transition, see our Explorers Hub post. New Relic's infrastructure monitoring agent collects and displays data using six primary events, each with associated attributes that represent assorted metrics and metadata. Understanding infrastructure data can help you: Better understand our infrastructure monitoring UI. Manage your infrastructure data. Create better host filter sets. Run better queries of your data. Set up better monitoring solutions using custom attributes. Infrastructure events The following are events reported by default by the infrastructure agent and some infrastructure integrations. The attributes attached to these events are the metadata and metrics used to create our infrastructure UI visualizations. You can also create custom queries and charts of this data. If you're using integrations, see that integration's doc for more on reported data. For common AWS attributes, see AWS data. Select an event name in the following table to see its attributes. Event Description SystemSample SystemSample contains data describing the current overall state of the entire server, including CPU, memory, disk, and network. We take a snapshot of this data every 5 seconds and package it into a SystemSample event, which is then sent to New Relic. This data appears in the Hosts UI page. ProcessSample ProcessSample gathers detailed resource usage information from programs running on a single system. We take a snapshot of this data every 20 seconds for every active process and package it into a ProcessSample event, which is then sent to New Relic. This data appears on the Processes UI page. Important Process metrics are not sent to New Relic by default for accounts created after July 20, 2020. Enable process metrics to get this data into the Infrastructure monitoring UI. StorageSample StorageSample represents a single storage device associated with a server. Each sample gathers descriptive information about the device, the type of file system it uses, and its current usage and capacity. We take a snapshot of this data every 20 seconds for each mounted file system and package it into a StorageSample event, which is then sent to New Relic. This data appears on the Storage UI page. Important If your server uses disks with file systems other than the supported file systems in the following table, StorageSample events will not be generated for those disks. Supported Linux storage systems Supported Linux storage file systems: xfs vxfs btrfs ext ext2 ext3 ext4 hfs Supported Windows storage systems Supported Windows storage file systems: NTFS ReFS (version 1.0.976 and higher) NetworkSample NetworkSample captures the descriptive and state information for each network device associated with a server. It includes the device's interface and address information, as well as current usage data. We take a snapshot of this data every 10 seconds for each attached network interface and package it into a NetworkSample event, which is then sent to New Relic. This data appears on the Network UI page. ContainerSample ContainerSample collects the descriptive and state information for each Docker container. It includes the container's ID, name, image, image name, as well metrics about CPU, memory and networking. We take a snapshot of this data every 15 seconds for each container and package it into a ContainerSample event, which is then sent to New Relic. This data appears on the Containers UI page. For more information, see Docker monitoring. InfrastructureEvent InfrastructureEvent describes changes (deltas) that occur in a system's live state. When an inventory or system state is added, removed, or changed, New Relic will produce an InfrastructureEvent that logs that activity. This data appears on the Events UI page. To learn about infrastructure integration data, see the documentation for a specific integration. If an AWS integration is enabled, your infrastructure events may also have AWS attributes attached. Query infrastructure data You can query your infrastructure data to troubleshoot a problem or create a chart, or to understand what data is available. For example, to see what data is attached to ProcessSample, you would run this NRQL query: SELECT * FROM ProcessSample Copy You can also query infrastructure using dimensional metrics. Manage data For tips on managing data ingest and reporting, see Manage infrastructure data. Add custom attributes You can create custom attributes in the infrastructure agent's YAML file. Use this metadata to: Create infrastructure filter sets Populate the Group by menu Annotate your infrastructure data Common Amazon EC2 attributes If you connect your Amazon Elastic Compute Cloud (EC2) account to our infrastructure monitoring, we report data from your Amazon EC2 instances. Amazon EC2-related attributes are common attributes that can be used in any event. These attributes are drawn from the EC2 API. No CloudWatch information is collected. These attributes and their values are subject to change if Amazon changes the data they expose. awsRegion The region (determined by Amazon Web Services) where the AWS server exists. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. awsAvailabilityZone The availability zone (determined by Amazon Web Services) where the AWS server exists. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2InstanceType The Amazon Web Services instance type, displayed in AWS-specific codes. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2InstanceId The Amazon Web Services instance's unique identifying number for the server. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2AmiId The Amazon Machine Image (AMI) identification number of the image used by Amazon Web Services to bootstrap the Amazon EC2 instance. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2SubnetId The networking sub-net identifier on which the server is connected. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2VpcId The Virtual Private Cloud identifier (if any) for this server. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. Other Amazon EC2 attributes If Amazon Web Services changes the metadata they make available to New Relic, other attributes and values collected also may be available.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.37016,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Default <em>infrastructure</em> monitoring <em>data</em> ",
        "sections": "Default <em>infrastructure</em> monitoring <em>data</em>",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": ". <em>Manage</em> <em>your</em> <em>infrastructure</em> <em>data</em>. Create better host filter sets. Run better queries of <em>your</em> <em>data</em>. Set up better monitoring solutions using custom attributes. <em>Infrastructure</em> events The following are events reported by default by the <em>infrastructure</em> agent and some <em>infrastructure</em> integrations"
      },
      "id": "6043edcd28ccbcfa8a2c6086"
    },
    {
      "sections": [
        "APM data in infrastructure monitoring",
        "How to integrate APM and infrastructure data",
        "View APM charts",
        "Filter by application data",
        "Tip",
        "Switch between infrastructure and APM",
        "APM data in Inventory and Events",
        "View host data in APM",
        "Troubleshoot missing APM data"
      ],
      "title": "APM data in infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "ac221ae748f8f2eb5a0ab7373853c5ea78974e41",
      "image": "https://docs.newrelic.com/static/4ab30e9528ae8a5121a1691143f80d44/ff42b/Infrastructure-APM-application-data-chart.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/apm-data-infrastructure-monitoring/",
      "published_at": "2021-06-14T21:14:34Z",
      "updated_at": "2021-03-16T07:33:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The integration of APM and infrastructure data lets you see your APM data and infrastructure data side by side so you can find the root cause of problems more quickly. Let's look at how the APM-Infrastructure integration works and how to make use of the shared data. The main ways to find and use APM data in infrastructure monitoring are: View APM charts on Infrastructure monitoring UI pages Filter hosts by application data Switch between Infrastructure and APM Examine APM data in Inventory and Events pages Infrastructure data appears in APM in the host table on the APM Summary page. How to integrate APM and infrastructure data For APM and infrastructure data to be integrated, all of the following must be true: The APM agent and the infrastructure agent must be installed on the same host. Both agents must use the same New Relic license key. They must use the same hostname. If the integration is not working, see Troubleshooting the APM-Infrastructure integration. View APM charts When your APM and infrastructure data is linked, you have access to APM data charts on these Infrastructure monitoring UI pages: Hosts, Network, Storage, and Processes. To switch to different charts: select the dropdown beside a chart's name and choose a new chart. Application-related charts will be near the top. one.newrelic.com > Infrastructure > Hosts: If your APM and Infrastructure data is linked, the charts in Infrastructure monitoring can be changed to show your application data. Filter by application data When your APM and infrastructure data is linked, you can filter displayed host data using Applications: From the host filter, select Applications. Select the application you want to filter on. Tip On the Hosts page, you can also filter by selecting items in the Applications column. Switch between infrastructure and APM When your APM and infrastructure accounts are linked, you can switch over from infrastructure to APM and vice versa for the same selected time range. You can switch from infrastructure to APM from these locations: From the host filter Applications menu On the Hosts page, when selecting applications in the Applications table column. You can switch from APM to infrastructure from the host table on the APM Summary page. APM data in Inventory and Events When your APM and infrastructure data is linked, you can view and filter on application data on the Infrastructure monitoring UI's Inventory page and the Events page. View host data in APM When your APM and infrastructure data is linked, you have more available host data in APM. The APM Summary page contains a table with data about your app's hosts and instances, including: Apdex Response time Throughput Error rate CPU usage Memory You can toggle between a table view or breakout metric details for the individual hosts by selecting View table or Break out each metric by host. For more information on host data on the APM Summary page, see host details. Troubleshoot missing APM data APM/Infrastructure integration should happen automatically if you have both the APM agent and the infrastructure agent installed on the same host(s) and they use the same New Relic license key and have the same hostname set. If you do not see APM data in infrastructure monitoring, see Troubleshooting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.4204,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM <em>data</em> in <em>infrastructure</em> monitoring",
        "sections": "APM <em>data</em> in <em>infrastructure</em> monitoring",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": "The integration of APM and <em>infrastructure</em> <em>data</em> lets you see <em>your</em> APM <em>data</em> and <em>infrastructure</em> <em>data</em> side by side so you can find the root cause of problems more quickly. Let&#x27;s look at how the APM-<em>Infrastructure</em> integration works and how to make use of the shared <em>data</em>. The main ways to find and use"
      },
      "id": "603e88b2e7b9d246932a07f6"
    }
  ],
  "/docs/infrastructure/new-relic-infrastructure/filter-group/filter-sets-organize-your-infrastructure-hosts": [
    {
      "sections": [
        "Group infrastructure results by specific attributes",
        "Group charts by specific attributes",
        "Combine filter sets and grouping",
        "Increased CPU usage on a single host"
      ],
      "title": "Group infrastructure results by specific attributes",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Filter and group"
      ],
      "external_id": "8436b1d0391cd7caa2a79c4080528697ff7a012d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/filter-group/group-infrastructure-results-specific-attributes/",
      "published_at": "2021-06-14T21:00:34Z",
      "updated_at": "2021-03-11T10:49:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In our infrastructure monitoring tool, you can use the Group by feature to group chart results by specific attributes. For example, on the Hosts page, you might display the AWS regions with the highest CPU usage grouped by awsRegion. Group by is available near the top of some infrastructure monitoring UI pages. Group charts by specific attributes On some infrastructure pages you can use Group by to group page results and charts by a specific attribute, such as host name, entity ID, or AWS region. The attributes available to group by will depend on your system setup. These may include: Default infrastructure attributes Custom attributes APM-related attributes To group infrastructure results by a specific attribute: On pages that have this feature, select Group by (located beside the time picker). From the dropdown, select an attribute to group by. Combine filter sets and grouping Grouping applies to any filter sets you have selected. By combining filter sets with Group by, you can find detailed system information quickly. Increased CPU usage on a single host On the Filter sets sidebar, you see alert threshold violations as Critical icon or Warning icon on one of your filter sets. To view only the hosts related to the filter set on your Hosts page, click the filter set name. To determine which of the hosts is causing the problem, select Group by, then select the hostname attribute. Review the charts which now show the hosts, by name, with the highest CPU usage.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 207.13792,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Group</em> <em>infrastructure</em> results by specific attributes",
        "sections": "<em>Group</em> <em>infrastructure</em> results by specific attributes",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": " monitoring UI pages. <em>Group</em> charts by specific attributes On some <em>infrastructure</em> pages you can use <em>Group</em> by to <em>group</em> page results and charts by a specific attribute, such as host name, entity ID, or AWS region. The attributes available to <em>group</em> by will depend on <em>your</em> system setup. These may include: Default"
      },
      "id": "6043edcd64441fd920378ecf"
    },
    {
      "sections": [
        "On-host integrations metrics",
        "New Relic Integrations Metrics"
      ],
      "title": "On-host integrations metrics",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "fe96c0c4950380504b1a33c3ad861bcb17507cba",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/host-integrations-metrics/",
      "published_at": "2021-06-15T01:04:56Z",
      "updated_at": "2021-06-15T01:04:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Integrations Metrics The following table contains the metrics we collect for our infrastructure integrations. Integration Dimensional Metric Name (new) Sample Metric Name (previous) Agent host.cpuIdlePercent cpuIdlePercent Agent host.cpuIoWaitPercent cpuIOWaitPercent Agent host.cpuPercent cpuPercent Agent host.cpuStealPercent cpuStealPercent Agent host.cpuSystemPercent cpuSystemPercent Agent host.cpuUserPercent cpuUserPercent Agent host.disk.avgQueueLen avgQueueLen Agent host.disk.avgReadQueueLen avgReadQueueLen Agent host.disk.avgWriteQueueLen avgWriteQueueLen Agent host.disk.currentQueueLen currentQueueLen Agent host.disk.freeBytes diskFreeBytes Agent host.disk.freePercent diskFreePercent Agent host.disk.inodesFree inodesFree Agent host.disk.inodesTotal inodesTotal Agent host.disk.inodesUsed inodesUsed Agent host.disk.inodesUsedPercent inodesUsedPercent Agent host.disk.readBytesPerSecond readBytesPerSecond Agent host.disk.readIoPerSecond readIoPerSecond Agent host.disk.readUtilizationPercent readUtilizationPercent Agent host.disk.readWriteBytesPerSecond readWriteBytesPerSecond Agent host.disk.totalBytes diskTotalBytes Agent host.disk.totalUtilizationPercent totalUtilizationPercent Agent host.disk.usedBytes diskUsedBytes Agent host.disk.usedPercent diskUsedPercent Agent host.disk.writeBytesPerSecond writeBytesPerSecond Agent host.disk.writeIoPerSecond writeIoPerSecond Agent host.disk.writeUtilizationPercent writeUtilizationPercent Agent host.diskFreeBytes diskFreeBytes Agent host.diskFreePercent diskFreePercent Agent host.diskReadsPerSecond diskReadsPerSecond Agent host.diskReadUtilizationPercent diskReadUtilizationPercent Agent host.diskTotalBytes diskTotalBytes Agent host.diskUsedBytes diskUsedBytes Agent host.diskUsedPercent diskUsedPercent Agent host.diskUtilizationPercent diskUtilizationPercent Agent host.diskWritesPerSecond diskWritesPerSecond Agent host.diskWriteUtilizationPercent diskWriteUtilizationPercent Agent host.loadAverageFifteenMinute loadAverageFifteenMinute Agent host.loadAverageFiveMinute loadAverageFiveMinute Agent host.loadAverageOneMinute loadAverageOneMinute Agent host.memoryFreeBytes memoryFreeBytes Agent host.memoryFreePercent memoryFreePercent Agent host.memoryTotalBytes memoryTotalBytes Agent host.memoryUsedBytes memoryUsedBytes Agent host.memoryUsedPercent memoryUsedPercent Agent host.net.receiveBytesPerSecond receiveBytesPerSecond Agent host.net.receiveDroppedPerSecond receiveDroppedPerSecond Agent host.net.receiveErrorsPerSecond receiveErrorsPerSecond Agent host.net.receivePacketsPerSecond receivePacketsPerSecond Agent host.net.transmitBytesPerSecond transmitBytesPerSecond Agent host.net.transmitDroppedPerSecond transmitDroppedPerSecond Agent host.net.transmitErrorsPerSecond transmitErrorsPerSecond Agent host.net.transmitPacketsPerSecond transmitPacketsPerSecond Agent host.process.cpuPercent cpuPercent Agent host.process.cpuSystemPercent cpuSystemPercent Agent host.process.cpuUserPercent cpuUserPercent Agent host.process.fileDescriptorCount fileDescriptorCount Agent host.process.ioReadBytesPerSecond ioReadBytesPerSecond Agent host.process.ioReadCountPerSecond ioReadCountPerSecond Agent host.process.ioTotalReadBytes ioTotalReadBytes Agent host.process.ioTotalReadCount ioTotalReadCount Agent host.process.ioTotalWriteBytes ioTotalWriteBytes Agent host.process.ioTotalWriteCount ioTotalWriteCount Agent host.process.ioWriteBytesPerSecond ioWriteBytesPerSecond Agent host.process.ioWriteCountPerSecond ioWriteCountPerSecond Agent host.process.memoryResidentSizeBytes memoryResidentSizeBytes Agent host.process.memoryVirtualSizeBytes memoryVirtualSizeBytes Agent host.process.threadCount threadCount Agent host.swapFreeBytes swapFreeBytes Agent host.swapTotalBytes swapTotalBytes Agent host.swapUsedBytes swapUsedBytes Apache apache.server.busyWorkers server.busyWorkers Apache apache.server.idleWorkers server.idleWorkers Apache apache.server.net.bytesPerSecond net.bytesPerSecond Apache apache.server.net.requestsPerSecond net.requestsPerSecond Apache apache.server.scoreboard.closingWorkers server.scoreboard.closingWorkers Apache apache.server.scoreboard.dnsLookupWorkers server.scoreboard.dnsLookupWorkers Apache apache.server.scoreboard.finishingWorkers server.scoreboard.finishingWorkers Apache apache.server.scoreboard.idleCleanupWorkers server.scoreboard.idleCleanupWorkers Apache apache.server.scoreboard.keepAliveWorkers server.scoreboard.keepAliveWorkers Apache apache.server.scoreboard.loggingWorkers server.scoreboard.loggingWorkers Apache apache.server.scoreboard.readingWorkers server.scoreboard.readingWorkers Apache apache.server.scoreboard.startingWorkers server.scoreboard.startingWorkers Apache apache.server.scoreboard.totalWorkers server.scoreboard.totalWorkers Apache apache.server.scoreboard.writingWorkers server.scoreboard.writingWorkers Cassandra cassandra.node.allMemtablesOffHeapSizeBytes db.allMemtablesOffHeapSizeBytes Cassandra cassandra.node.allMemtablesOnHeapSizeBytes db.allMemtablesOnHeapSizeBytes Cassandra cassandra.node.client.connectedNativeClients client.connectedNativeClients Cassandra cassandra.node.commitLogCompletedTasksPerSecond db.commitLogCompletedTasksPerSecond Cassandra cassandra.node.commitLogPendingTasks db.commitLogPendindTasks Cassandra cassandra.node.commitLogTotalSizeBytes db.commitLogTotalSizeBytes Cassandra cassandra.node.droppedBatchRemoveMessagesPerSecond db.droppedBatchRemoveMessagesPerSecond Cassandra cassandra.node.droppedBatchStoreMessagesPerSecond db.droppedBatchStoreMessagesPerSecond Cassandra cassandra.node.droppedCounterMutationMessagesPerSecond db.droppedCounterMutationMessagesPerSecond Cassandra cassandra.node.droppedHintMessagesPerSecond db.droppedHintMessagesPerSecond Cassandra cassandra.node.droppedMutationMessagesPerSecond db.droppedMutationMessagesPerSecond Cassandra cassandra.node.droppedPagedRangeMessagesPerSecond db.droppedPagedRangeMessagesPerSecond Cassandra cassandra.node.droppedRangeSliceMessagesPerSecond db.droppedRangeSliceMessagesPerSecond Cassandra cassandra.node.droppedReadMessagesPerSecond db.droppedReadMessagesPerSecond Cassandra cassandra.node.droppedReadRepairMessagesPerSecond db.droppedReadRepairMessagesPerSecond Cassandra cassandra.node.droppedRequestResponseMessagesPerSecond db.droppedRequestResponseMessagesPerSecond Cassandra cassandra.node.droppedTraceMessagesPerSecond db.droppedTraceMessagesPerSecond Cassandra cassandra.node.keyCacheCapacityBytes db.keyCacheCapacityBytes Cassandra cassandra.node.keyCacheHitRate db.keyCacheHitRate Cassandra cassandra.node.keyCacheHitsPerSecond db.keyCacheHitsPerSecond Cassandra cassandra.node.keyCacheRequestsPerSecond db.keyCacheRequestsPerSecond Cassandra cassandra.node.keyCacheSizeBytes db.keyCacheSizeBytes Cassandra cassandra.node.liveSsTableCount db.liveSSTableCount Cassandra cassandra.node.loadBytes db.loadBytes Cassandra cassandra.node.query.casReadRequestsPerSecond query.CASReadRequestsPerSecond Cassandra cassandra.node.query.casWriteRequestsPerSecond query.CASWriteRequestsPerSecond Cassandra cassandra.node.query.rangeSliceRequestsPerSecond query.rangeSliceRequestsPerSecond Cassandra cassandra.node.query.rangeSliceTimeoutsPerSecond query.rangeSliceTimeoutsPerSecond Cassandra cassandra.node.query.rangeSliceUnavailablesPerSecond query.rangeSliceUnavailablesPerSecond Cassandra cassandra.node.query.readLatency50ThPercentileMilliseconds query.readLatency50thPercentileMilliseconds Cassandra cassandra.node.query.readLatency75ThPercentileMilliseconds query.readLatency75thPercentileMilliseconds Cassandra cassandra.node.query.readLatency95ThPercentileMilliseconds query.readLatency95thPercentileMilliseconds Cassandra cassandra.node.query.readLatency98ThPercentileMilliseconds query.readLatency98thPercentileMilliseconds Cassandra cassandra.node.query.readLatency999ThPercentileMilliseconds query.readLatency999thPercentileMilliseconds Cassandra cassandra.node.query.readLatency99ThPercentileMilliseconds query.readLatency99thPercentileMilliseconds Cassandra cassandra.node.query.readRequestsPerSecond query.readRequestsPerSecond Cassandra cassandra.node.query.readTimeoutsPerSecond query.readTimeoutsPerSecond Cassandra cassandra.node.query.readUnavailablesPerSecond query.readUnavailablesPerSecond Cassandra cassandra.node.query.viewWriteRequestsPerSecond query.viewWriteRequestsPerSecond Cassandra cassandra.node.query.writeLatency50ThPercentileMilliseconds query.writeLatency50thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency75ThPercentileMilliseconds query.writeLatency75thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency95ThPercentileMilliseconds query.writeLatency95thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency98ThPercentileMilliseconds query.writeLatency98thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency999ThPercentileMilliseconds query.writeLatency999thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency99ThPercentileMilliseconds query.writeLatency99thPercentileMilliseconds Cassandra cassandra.node.query.writeRequestsPerSecond query.writeRequestsPerSecond Cassandra cassandra.node.query.writeTimeoutsPerSecond query.writeTimeoutsPerSecond Cassandra cassandra.node.query.writeUnavailablesPerSecond query.writeUnavailablesPerSecond Cassandra cassandra.node.rowCacheCapacityBytes db.rowCacheCapacityBytes Cassandra cassandra.node.rowCacheHitRate db.rowCacheHitRate Cassandra cassandra.node.rowCacheHitsPerSecond db.rowCacheHitsPerSecond Cassandra cassandra.node.rowCacheRequestsPerSecond db.rowCacheRequestsPerSecond Cassandra cassandra.node.rowCacheSizeBytes db.rowCacheSizeBytes Cassandra cassandra.node.storage.exceptionCount storage.exceptionCount Cassandra cassandra.node.threadPool.antiEntropyStage.activeTasks db.threadpool.internalAntiEntropyStageActiveTasks Cassandra cassandra.node.threadPool.antiEntropyStage.completedTasks db.threadpool.internalAntiEntropyStageCompletedTasks Cassandra cassandra.node.threadPool.antiEntropyStage.currentlyBlockedTasks db.threadpool.internalAntiEntropyStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.antiEntropyStage.pendingTasks db.threadpool.internalAntiEntropyStagePendingTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.activeTasks db.threadpool.internalCacheCleanupExecutorActiveTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.completedTasks db.threadpool.internalCacheCleanupExecutorCompletedTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.currentlyBlockedTasks db.threadpool.internalCacheCleanupExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.pendingTasks db.threadpool.internalCacheCleanupExecutorPendingTasks Cassandra cassandra.node.threadPool.compactionExecutor.activeTasks db.threadpool.internalCompactionExecutorActiveTasks Cassandra cassandra.node.threadPool.compactionExecutor.completedTasks db.threadpool.internalCompactionExecutorCompletedTasks Cassandra cassandra.node.threadPool.compactionExecutor.currentlyBlockedTasks db.threadpool.internalCompactionExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.compactionExecutor.pendingTasks db.threadpool.internalCompactionExecutorPendingTasks Cassandra cassandra.node.threadPool.counterMutationStage.activeTasks db.threadpool.requestCounterMutationStageActiveTasks Cassandra cassandra.node.threadPool.counterMutationStage.completedTasks db.threadpool.requestCounterMutationStageCompletedTasks Cassandra cassandra.node.threadPool.counterMutationStage.currentlyBlockedTasks db.threadpool.requestCounterMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.counterMutationStage.pendingTasks db.threadpool.requestCounterMutationStagePendingTasks Cassandra cassandra.node.threadPool.gossipStage.activeTasks db.threadpool.internalGossipStageActiveTasks Cassandra cassandra.node.threadPool.gossipStage.completedTasks db.threadpool.internalGossipStageCompletedTasks Cassandra cassandra.node.threadPool.gossipStage.currentlyBlockedTasks db.threadpool.internalGossipStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.gossipStage.pendingTasks db.threadpool.internalGossipStagePendingTasks Cassandra cassandra.node.threadPool.hintsDispatcher.activeTasks db.threadpool.internalHintsDispatcherActiveTasks Cassandra cassandra.node.threadPool.hintsDispatcher.completedTasks db.threadpool.internalHintsDispatcherCompletedTasks Cassandra cassandra.node.threadPool.hintsDispatcher.currentlyBlockedTasks db.threadpool.internalHintsDispatcherCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.hintsDispatcher.pendingTasks db.threadpool.internalHintsDispatcherPendingTasks Cassandra cassandra.node.threadPool.internalResponseStage.activeTasks db.threadpool.internalInternalResponseStageActiveTasks Cassandra cassandra.node.threadPool.internalResponseStage.completedTasks db.threadpool.internalInternalResponseStageCompletedTasks Cassandra cassandra.node.threadPool.internalResponseStage.pCurrentlyBlockedTasks db.threadpool.internalInternalResponseStagePCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.internalResponseStage.pendingTasks db.threadpool.internalInternalResponseStagePendingTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.activeTasks db.threadpool.internalMemtableFlushWriterActiveTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.completedTasks db.threadpool.internalMemtableFlushWriterCompletedTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.currentlyBlockedTasks db.threadpool.internalMemtableFlushWriterCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.pendingTasks db.threadpool.internalMemtableFlushWriterPendingTasks Cassandra cassandra.node.threadPool.memtablePostFlush.activeTasks db.threadpool.internalMemtablePostFlushActiveTasks Cassandra cassandra.node.threadPool.memtablePostFlush.completedTasks db.threadpool.internalMemtablePostFlushCompletedTasks Cassandra cassandra.node.threadPool.memtablePostFlush.currentlyBlockedTasks db.threadpool.internalMemtablePostFlushCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtablePostFlush.pendingTasks db.threadpool.internalMemtablePostFlushPendingTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.activeTasks db.threadpool.internalMemtableReclaimMemoryActiveTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.completedTasks db.threadpool.internalMemtableReclaimMemoryCompletedTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.currentlyBlockedTasks db.threadpool.internalMemtableReclaimMemoryCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.pendingTasks db.threadpool.internalMemtableReclaimMemoryPendingTasks Cassandra cassandra.node.threadPool.migrationStage.activeTasks db.threadpool.internalMigrationStageActiveTasks Cassandra cassandra.node.threadPool.migrationStage.completedTasks db.threadpool.internalMigrationStageCompletedTasks Cassandra cassandra.node.threadPool.migrationStage.currentlyBlockedTasks db.threadpool.internalMigrationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.migrationStage.pendingTasks db.threadpool.internalMigrationStagePendingTasks Cassandra cassandra.node.threadPool.miscStage.activeTasks db.threadpool.internalMiscStageActiveTasks Cassandra cassandra.node.threadPool.miscStage.completedTasks db.threadpool.internalMiscStageCompletedTasks Cassandra cassandra.node.threadPool.miscStage.currentlyBlockedTasks db.threadpool.internalMiscStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.miscStage.pendingTasks db.threadpool.internalMiscStagePendingTasks Cassandra cassandra.node.threadPool.mutationStage.activeTasks db.threadpool.requestMutationStageActiveTasks Cassandra cassandra.node.threadPool.mutationStage.completedTasks db.threadpool.requestMutationStageCompletedTasks Cassandra cassandra.node.threadPool.mutationStage.currentlyBlockedTasks db.threadpool.requestMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.mutationStage.pendingTasks db.threadpool.requestMutationStagePendingTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.activeTasks db.threadpool.internalPendingRangeCalculatorActiveTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.completedTasks db.threadpool.internalPendingRangeCalculatorCompletedTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.currentlyBlockedTasks db.threadpool.internalPendingRangeCalculatorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.pendingTasks db.threadpool.internalPendingRangeCalculatorPendingTasks Cassandra cassandra.node.threadPool.readRepairStage.activeTasks db.threadpool.requestReadRepairStageActiveTasks Cassandra cassandra.node.threadPool.readRepairStage.completedTasks db.threadpool.requestReadRepairStageCompletedTasks Cassandra cassandra.node.threadPool.readRepairStage.currentlyBlockedTasks db.threadpool.requestReadRepairStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.readRepairStage.pendingTasks db.threadpool.requestReadRepairStagePendingTasks Cassandra cassandra.node.threadPool.readStage.activeTasks db.threadpool.requestReadStageActiveTasks Cassandra cassandra.node.threadPool.readStage.completedTasks db.threadpool.requestReadStageCompletedTasks Cassandra cassandra.node.threadPool.readStage.currentlyBlockedTasks db.threadpool.requestReadStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.readStage.pendingTasks db.threadpool.requestReadStagePendingTasks Cassandra cassandra.node.threadPool.requestResponseStage.activeTasks db.threadpool.requestRequestResponseStageActiveTasks Cassandra cassandra.node.threadPool.requestResponseStage.completedTasks db.threadpool.requestRequestResponseStageCompletedTasks Cassandra cassandra.node.threadPool.requestResponseStage.currentlyBlockedTasks db.threadpool.requestRequestResponseStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.requestResponseStage.pendingTasks db.threadpool.requestRequestResponseStagePendingTasks Cassandra cassandra.node.threadPool.sampler.activeTasks db.threadpool.internalSamplerActiveTasks Cassandra cassandra.node.threadPool.sampler.completedTasks db.threadpool.internalSamplerCompletedTasks Cassandra cassandra.node.threadPool.sampler.currentlyBlockedTasks db.threadpool.internalSamplerCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.sampler.pendingTasks db.threadpool.internalSamplerPendingTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.activeTasks db.threadpool.internalSecondaryIndexManagementActiveTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.completedTasks db.threadpool.internalSecondaryIndexManagementCompletedTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.currentlyBlockedTasks db.threadpool.internalSecondaryIndexManagementCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.pendingTasks db.threadpool.internalSecondaryIndexManagementPendingTasks Cassandra cassandra.node.threadPool.validationExecutor.activeTasks db.threadpool.internalValidationExecutorActiveTasks Cassandra cassandra.node.threadPool.validationExecutor.completedTasks db.threadpool.internalValidationExecutorCompletedTasks Cassandra cassandra.node.threadPool.validationExecutor.currentlyBlockedTasks db.threadpool.internalValidationExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.validationExecutor.pendingTasks db.threadpool.internalValidationExecutorPendingTasks Cassandra cassandra.node.threadPool.viewMutationStage.activeTasks db.threadpool.requestViewMutationStageActiveTasks Cassandra cassandra.node.threadPool.viewMutationStage.completedTasks db.threadpool.requestViewMutationStageCompletedTasks Cassandra cassandra.node.threadPool.viewMutationStage.currentlyBlockedTasks db.threadpool.requestViewMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.viewMutationStage.pendingTasks db.threadpool.requestViewMutationStagePendingTasks Cassandra cassandra.node.totalHintsInProgress db.totalHintsInProgress Cassandra cassandra.node.totalHintsPerSecond db.totalHintsPerSecond Cassandra cassandra.columnFamily.allMemtablesOffHeapSizeBytes db.allMemtablesOffHeapSizeBytes Cassandra cassandra.columnFamily.allMemtablesOnHeapSizeBytes db.allMemtablesOnHeapSizeBytes Cassandra cassandra.columnFamily.bloomFilterFalseRatio db.bloomFilterFalseRatio Cassandra cassandra.columnFamily.liveDiskSpaceUsedBytes db.liveDiskSpaceUsedBytes Cassandra cassandra.columnFamily.liveSsTableCount db.liveSSTableCount Cassandra cassandra.columnFamily.maxRowSize db.maxRowSize Cassandra cassandra.columnFamily.meanRowSize db.meanRowSize Cassandra cassandra.columnFamily.memtableLiveDataSize db.memtableLiveDataSize Cassandra cassandra.columnFamily.minRowSize db.minRowSize Cassandra cassandra.columnFamily.pendingCompactions db.pendingCompactions Cassandra cassandra.columnFamily.query.readLatency50ThPercentileMilliseconds query.readLatency50thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency75ThPercentileMilliseconds query.readLatency75thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency95ThPercentileMilliseconds query.readLatency95thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency98ThPercentileMilliseconds query.readLatency98thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency999ThPercentileMilliseconds query.readLatency999thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency99ThPercentileMilliseconds query.readLatency99thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readRequestsPerSecond query.readRequestsPerSecond Cassandra cassandra.columnFamily.query.writeLatency50ThPercentileMilliseconds query.writeLatency50thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency75ThPercentileMilliseconds query.writeLatency75thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency95ThPercentileMilliseconds query.writeLatency95thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency98ThPercentileMilliseconds query.writeLatency98thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency999ThPercentileMilliseconds query.writeLatency999thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency99ThPercentileMilliseconds query.writeLatency99thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeRequestsPerSecond query.writeRequestsPerSecond Cassandra cassandra.columnFamily.speculativeRetries db.speculativeRetries Cassandra cassandra.columnFamily.ssTablesPerRead50ThPercentileMilliseconds db.SSTablesPerRead50thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead75ThPercentileMilliseconds db.SSTablesPerRead75thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead95ThPercentileMilliseconds db.SSTablesPerRead95thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead98ThPercentileMilliseconds db.SSTablesPerRead98thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead999ThPercentileMilliseconds db.SSTablesPerRead999thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead99ThPercentileMilliseconds db.SSTablesPerRead99thPercentileMilliseconds Cassandra cassandra.columnFamily.tombstoneScannedHistogram50ThPercentile db.tombstoneScannedHistogram50thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram75ThPercentile db.tombstoneScannedHistogram75thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram95ThPercentile db.tombstoneScannedHistogram95thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram98ThPercentile db.tombstoneScannedHistogram98thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram999ThPercentile db.tombstoneScannedHistogram999thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram99ThPercentile db.tombstoneScannedHistogram99thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogramCount db.tombstoneScannedHistogramCount Consul consul.datacenter.catalog.criticalNodes catalog.criticalNodes Consul consul.datacenter.catalog.passingNodes catalog.passingNodes Consul consul.datacenter.catalog.registeredNodes catalog.registeredNodes Consul consul.datacenter.catalog.upNodes catalog.upNodes Consul consul.datacenter.catalog.warningNodes catalog.warningNodes Consul consul.datacenter.cluster.flaps cluster.flaps Consul consul.datacenter.cluster.suspects cluster.suspects Consul consul.datacenter.raft.commitTime raft.commitTimes Consul consul.datacenter.raft.commitTimeAvgInMilliseconds raft.commitTimeAvgInMilliseconds Consul consul.datacenter.raft.commitTimeMaxInMilliseconds raft.commitTimeMaxInMilliseconds Consul consul.datacenter.raft.completedLeaderElections raft.completedLeaderElections Consul consul.datacenter.raft.initiatedLeaderElections raft.initiatedLeaderElections Consul consul.datacenter.raft.lastContactAvgInMilliseconds raft.lastContactAvgInMilliseconds Consul consul.datacenter.raft.lastContactMaxInMilliseconds raft.lastContactMaxInMilliseconds Consul consul.datacenter.raft.lastContacts raft.lastContacts Consul consul.datacenter.raft.logDispatchAvgInMilliseconds raft.logDispatchAvgInMilliseconds Consul consul.datacenter.raft.logDispatches raft.logDispatches Consul consul.datacenter.raft.logDispatchMaxInMilliseconds raft.logDispatchMaxInMilliseconds Consul consul.datacenter.raft.txns raft.txns Consul consul.agent.aclCacheHitPerSecond agent.aclCacheHit Consul consul.agent.aclCacheMissPerSecond agent.aclCacheMiss Consul consul.agent.client.rpcFailed client.rpcFailed Consul consul.agent.client.rpcLoad client.rpcLoad Consul consul.agent.kvStores agent.kvStoress Consul consul.agent.kvStoresAvgInMilliseconds agent.kvStoresAvgInMilliseconds Consul consul.agent.kvStoresMaxInMilliseconds agent.kvStoresMaxInMilliseconds Consul consul.agent.net.agent.maxLatencyInMilliseconds net.agent.maxLatencyInMilliseconds Consul consul.agent.net.medianLatencyInMilliseconds net.agent.medianLatencyInMilliseconds Consul consul.agent.net.minLatencyInMilliseconds net.agent.minLatencyInMilliseconds Consul consul.agent.net.p25LatencyInMilliseconds net.agent.p25LatencyInMilliseconds Consul consul.agent.net.p75LatencyInMilliseconds net.agent.p75LatencyInMilliseconds Consul consul.agent.net.p90LatencyInMilliseconds net.agent.p90LatencyInMilliseconds Consul consul.agent.net.p95LatencyInMilliseconds net.agent.p95LatencyInMilliseconds Consul consul.agent.net.p99LatencyInMilliseconds net.agent.p99LatencyInMilliseconds Consul consul.agent.peers agent.peers Consul consul.agent.runtime.allocations runtime.allocations Consul consul.agent.runtime.allocationsInBytes runtime.allocationsInBytes Consul consul.agent.runtime.frees runtime.frees Consul consul.agent.runtime.gcCycles runtime.gcCycles Consul consul.agent.runtime.gcPauseInMilliseconds runtime.gcPauseInMilliseconds Consul consul.agent.runtime.goroutines runtime.goroutines Consul consul.agent.runtime.heapObjects runtime.heapObjects Consul consul.agent.runtime.virtualAddressSpaceInBytes runtime.virtualAddressSpaceInBytes Consul consul.agent.staleQueries agent.staleQueries Consul consul.agent.txnAvgInMilliseconds agent.txnAvgInMilliseconds Consul consul.agent.txnMaxInMilliseconds agent.txnMaxInMilliseconds Consul consul.agent.txns agent.txns Couchbase couchbase.bucket.activeItemsEnteringDiskQueuePerSecond bucket.activeItemsEnteringDiskQueuePerSecond Couchbase couchbase.bucket.activeItemsInMemory bucket.activeItemsInMemory Couchbase couchbase.bucket.activeResidentItemsRatio bucket.activeResidentItemsRatio Couchbase couchbase.bucket.averageDiskCommitTimeInMilliseconds bucket.averageDiskCommitTimeInMilliseconds Couchbase couchbase.bucket.averageDiskUpdateTimeInMilliseconds bucket.averageDiskUpdateTimeInMilliseconds Couchbase couchbase.bucket.cacheMisses bucket.cacheMisses Couchbase couchbase.bucket.cacheMissRatio bucket.cacheMissRatio Couchbase couchbase.bucket.casHits bucket.casHits Couchbase couchbase.bucket.casMisses bucket.casMisses Couchbase couchbase.bucket.couchDocsFragmentationPercent bucket.couchDocsFragmentationPercent Couchbase couchbase.bucket.currentConnections bucket.currentConnections Couchbase couchbase.bucket.dataUsedInBytes bucket.dataUsedInBytes Couchbase couchbase.bucket.decrementHitsPerSecond bucket.decrementHitsPerSecond Couchbase couchbase.bucket.decrementMissesPerSecond bucket.decrementMissesPerSecond Couchbase couchbase.bucket.deleteHitsPerSecond bucket.deleteHitsPerSecond Couchbase couchbase.bucket.deleteMissesPerSecond bucket.deleteMissesPerSecond Couchbase couchbase.bucket.diskCreateOperationsPerSecond bucket.diskCreateOperationsPerSecond Couchbase couchbase.bucket.diskFetchesPerSecond bucket.diskFetchesPerSecond Couchbase couchbase.bucket.diskReadsPerSecond bucket.diskReadsPerSecond Couchbase couchbase.bucket.diskUpdateOperationsPerSecond bucket.diskUpdateOperationsPerSecond Couchbase couchbase.bucket.diskUsedInBytes bucket.diskUsedInBytes Couchbase couchbase.bucket.diskWriteQueue bucket.diskWriteQueue Couchbase couchbase.bucket.drainedItemsInQueue bucket.drainedItemsInQueue Couchbase couchbase.bucket.drainedItemsOnDiskQueue bucket.drainedItemsOnDiskQueue Couchbase couchbase.bucket.drainedPendingItemsInQueue bucket.drainedPendingItemsInQueue Couchbase couchbase.bucket.ejectionsPerSecond bucket.ejectionsPerSecond Couchbase couchbase.bucket.evictionsPerSecond bucket.evictionsPerSecond Couchbase couchbase.bucket.getHitsPerSecond bucket.getHitsPerSecond Couchbase couchbase.bucket.getMissesPerSecond bucket.getMissesPerSecond Couchbase couchbase.bucket.hitRatio bucket.hitRatio Couchbase couchbase.bucket.incrementHitsPerSecond bucket.incrementHitsPerSecond Couchbase couchbase.bucket.incrementMissesPerSecond bucket.incrementMissesPerSecond Couchbase couchbase.bucket.itemCount bucket.itemCount Couchbase couchbase.bucket.itemsBeingWritten bucket.itemsBeingWritten Couchbase couchbase.bucket.itemsEjectedFromMemoryToDisk bucket.itemsEjectedFromMemoryToDisk Couchbase couchbase.bucket.itemsOnDiskQueue bucket.itemsOnDiskQueue Couchbase couchbase.bucket.itemsQueuedForStorage bucket.itemsQueuedForStorage Couchbase couchbase.bucket.maximumMemoryUsage bucket.maximumMemoryUsage Couchbase couchbase.bucket.memoryHighWaterMarkInBytes bucket.memoryHighWaterMarkInBytes Couchbase couchbase.bucket.memoryLowWaterMarkInBytes bucket.memoryLowWaterMarkInBytes Couchbase couchbase.bucket.memoryUsedInBytes bucket.memoryUsedInBytes Couchbase couchbase.bucket.metadataInRamInBytes bucket.metadataInRAMInBytes Couchbase couchbase.bucket.missesPerSecond bucket.missesPerSecond Couchbase couchbase.bucket.outOfMemoryErrorsPerSecond bucket.outOfMemoryErrorsPerSecond Couchbase couchbase.bucket.overheadInBytes bucket.overheadInBytes Couchbase couchbase.bucket.pendingItemsInDiskQueue bucket.pendingItemsInDiskQueue Couchbase couchbase.bucket.pendingResidentItemsRatio bucket.pendingResidentItemsRatio Couchbase couchbase.bucket.quotaUtilization bucket.quotaUtilization Couchbase couchbase.bucket.readOperationsPerSecond bucket.readOperationsPerSecond Couchbase couchbase.bucket.readRatePerSecond bucket.readRatePerSecond Couchbase couchbase.bucket.recoverableOutOfMemoryCount bucket.recoverableOutOfMemoryCount Couchbase couchbase.bucket.replicaIndex bucket.replicaIndex Couchbase couchbase.bucket.replicaNumber bucket.replicaNumber Couchbase couchbase.bucket.replicaResidentItemsRatio bucket.replicaResidentItemsRatio Couchbase couchbase.bucket.residentItemsRatio bucket.residentItemsRatio Couchbase couchbase.bucket.temporaryOutOfMemoryErrorsPerSecond bucket.temporaryOutOfMemoryErrorsPerSecond Couchbase couchbase.bucket.threadsNumber bucket.threadsNumber Couchbase couchbase.bucket.totalItems bucket.totalItems Couchbase couchbase.bucket.totalOperationsPerSecond bucket.totalOperationsPerSecond Couchbase couchbase.bucket.viewFragmentationPercent bucket.viewFragmentationPercent Couchbase couchbase.bucket.writeOperationsPerSecond bucket.writeOperationsPerSecond Couchbase couchbase.bucket.writeRatePerSecond bucket.writeRatePerSecond Couchbase couchbase.cluster.autoFailoverCount cluster.autoFailoverCount Couchbase couchbase.cluster.autoFailoverEnabled cluster.autoFailoverEnabled Couchbase couchbase.cluster.databaseFragmentationThreshold cluster.databaseFragmentationThreshold Couchbase couchbase.cluster.diskFreeInBytes cluster.diskFreeInBytes Couchbase couchbase.cluster.diskQuotaTotalInBytes cluster.diskQuotaTotalInBytes Couchbase couchbase.cluster.diskTotalInBytes cluster.diskTotalInBytes Couchbase couchbase.cluster.diskUsedByDataInBytes cluster.diskUsedByDataInBytes Couchbase couchbase.cluster.diskUsedInBytes cluster.diskUsedInBytes Couchbase couchbase.cluster.indexFragmentationThreshold cluster.indexFragmentationThreshold Couchbase couchbase.cluster.maximumBucketCount cluster.maximumBucketCount Couchbase couchbase.cluster.memoryQuotaTotalInBytes cluster.memoryQuotaTotalInBytes Couchbase couchbase.cluster.memoryQuotaTotalPerNodeInBytes cluster.memoryQuotaTotalPerNodeInBytes Couchbase couchbase.cluster.memoryQuotaUsedInBytes cluster.memoryQuotaUsedInBytes Couchbase couchbase.cluster.memoryQuotaUsedPerNodeInBytes cluster.memoryQuotaUsedPerNodeInBytes Couchbase couchbase.cluster.memoryTotalInBytes cluster.memoryTotalInBytes Couchbase couchbase.cluster.memoryUsedByDataInBytes cluster.memoryUsedByDataInBytes Couchbase couchbase.cluster.memoryUsedInBytes cluster.memoryUsedInBytes Couchbase couchbase.cluster.viewFragmentationThreshold cluster.viewFragmentationThreshold Couchbase couchbase.node.backgroundFetches node.backgroundFetches Couchbase couchbase.node.cmdGet node.cmdGet Couchbase couchbase.node.couchDocsActualDiskSizeInBytes node.couchDocsActualDiskSizeInBytes Couchbase couchbase.node.couchDocsDataSizeInBytes node.couchDocsDataSizeInBytes Couchbase couchbase.node.couchSpatialDataSizeInBytes node.couchSpatialDataSizeInBytes Couchbase couchbase.node.couchSpatialDiskSizeInBytes node.couchSpatialDiskSizeInBytes Couchbase couchbase.node.couchViewsActualDiskSizeInBytes node.couchViewsActualDiskSizeInBytes Couchbase couchbase.node.couchViewsDataSizeInBytes node.couchViewsDataSizeInBytes Couchbase couchbase.node.cpuUtilization node.cpuUtilization Couchbase couchbase.node.currentItems node.currentItems Couchbase couchbase.node.currentItemsTotal node.currentItemsTotal Couchbase couchbase.node.getHits node.getHits Couchbase couchbase.node.memoryFreeInBytes node.memoryFreeInBytes Couchbase couchbase.node.memoryTotalInBytes node.memoryTotalInBytes Couchbase couchbase.node.memoryUsedInBytes node.memoryUsedInBytes Couchbase couchbase.node.ops node.ops Couchbase couchbase.node.swapTotalInBytes node.swapTotalInBytes Couchbase couchbase.node.swapUsedInBytes node.swapUsedInBytes Couchbase couchbase.node.uptimeInMilliseconds node.uptimeInMilliseconds Couchbase couchbase.node.vbucketActiveNonResidentItems node.vbucketActiveNonResidentItems Couchbase couchbase.node.vbucketInMemoryItems node.vbucketInMemoryItems Couchbase couchbase.queryengine.activeRequests queryengine.activeRequests Couchbase couchbase.queryengine.averageRequestTimeInMilliseconds queryengine.averageRequestTimeInMilliseconds Couchbase couchbase.queryengine.completedLimit queryengine.completedLimit Couchbase couchbase.queryengine.completedRequests queryengine.completedRequests Couchbase couchbase.queryengine.completedThresholdInMilliseconds queryengine.completedThresholdInMilliseconds Couchbase couchbase.queryengine.cores queryengine.cores Couchbase couchbase.queryengine.garbageCollectionNumber queryengine.garbageCollectionNumber Couchbase couchbase.queryengine.garbageCollectionPaused queryengine.garbageCollectionPaused Couchbase couchbase.queryengine.garbageCollectionTimePausedInMilliseconds queryengine.garbageCollectionTimePausedInMilliseconds Couchbase couchbase.queryengine.medianRequestTimeInMilliseconds queryengine.medianRequestTimeInMilliseconds Couchbase couchbase.queryengine.preparedStatementUtilization queryengine.preparedStatementUtilization Couchbase couchbase.queryengine.requestsLast15MinutesPerSecond queryengine.requestsLast15MinutesPerSecond Couchbase couchbase.queryengine.requestsLast1MinutesPerSecond queryengine.requestsLast1MinutesPerSecond Couchbase couchbase.queryengine.requestsLast5MinutesPerSecond queryengine.requestsLast5MinutesPerSecond Couchbase couchbase.queryengine.requestTime80thPercentileInMilliseconds queryengine.requestTime80thPercentileInMilliseconds Couchbase couchbase.queryengine.requestTime95thPercentileInMilliseconds queryengine.requestTime95thPercentileInMilliseconds Couchbase couchbase.queryengine.requestTime99thPercentileInMilliseconds queryengine.requestTime99thPercentileInMilliseconds Couchbase couchbase.queryengine.systemCpuUtilization queryengine.systemCPUUtilization Couchbase couchbase.queryengine.systemMemoryInBytes queryengine.systemMemoryInBytes Couchbase couchbase.queryengine.totalMemoryInBytes queryengine.totalMemoryInBytes Couchbase couchbase.queryengine.totalThreads queryengine.totalThreads Couchbase couchbase.queryengine.uptimeInMilliseconds queryengine.uptimeInMilliseconds Couchbase couchbase.queryengine.usedMemoryInBytes queryengine.usedMemoryInBytes Couchbase couchbase.queryengine.userCpuUtilization queryengine.userCPUUtilization Docker docker.container.cpuKernelPercent cpuKernelPercent Docker docker.container.cpuLimitCores cpuLimitCores Docker docker.container.cpuPercent cpuPercent Docker docker.container.cpuThrottlePeriods cpuThrottlePeriods Docker docker.container.cpuThrottleTimeMs cpuThrottleTimeMs Docker docker.container.cpuUsedCores cpuUsedCores Docker docker.container.cpuUsedCoresPercent cpuUsedCoresPercent Docker docker.container.cpuUserPercent cpuUserPercent Docker docker.container.ioReadBytesPerSecond ioReadBytesPerSecond Docker docker.container.ioReadCountPerSecond ioReadCountPerSecond Docker docker.container.ioTotalBytes ioTotalBytes Docker docker.container.ioTotalReadBytes ioTotalReadBytes Docker docker.container.ioTotalReadCount ioTotalReadCount Docker docker.container.ioTotalWriteBytes ioTotalWriteBytes Docker docker.container.ioTotalWriteCount ioTotalWriteCount Docker docker.container.ioWriteBytesPerSecond ioWriteBytesPerSecond Docker docker.container.ioWriteCountPerSecond ioWriteCountPerSecond Docker docker.container.memoryCacheBytes memoryCacheBytes Docker docker.container.memoryResidentSizeBytes memoryResidentSizeBytes Docker docker.container.memorySizeLimitBytes memorySizeLimitBytes Docker docker.container.memoryUsageBytes memoryUsageBytes Docker docker.container.memoryUsageLimitPercent memoryUsageLimitPercent Docker docker.container.networkRxBytes networkRxBytes Docker docker.container.networkRxBytesPerSecond networkRxBytesPerSecond Docker docker.container.networkRxDropped networkRxDropped Docker docker.container.networkRxDroppedPerSecond networkRxDroppedPerSecond Docker docker.container.networkRxErrors networkRxErrors Docker docker.container.networkRxErrorsPerSecond networkRxErrorsPerSecond Docker docker.container.networkRxPackets networkRxPackets Docker docker.container.networkRxPacketsPerSecond networkRxPacketsPerSecond Docker docker.container.networkTxBytes networkTxBytes Docker docker.container.networkTxBytesPerSecond networkTxBytesPerSecond Docker docker.container.networkTxDropped networkTxDropped Docker docker.container.networkTxDroppedPerSecond networkTxDroppedPerSecond Docker docker.container.networkTxErrors networkTxErrors Docker docker.container.networkTxErrorsPerSecond networkTxErrorsPerSecond Docker docker.container.networkTxPackets networkTxPackets Docker docker.container.networkTxPacketsPerSecond networkTxPacketsPerSecond Docker docker.container.pids pids Docker docker.container.processCount processCount Docker docker.container.processCountLimit processCountLimit Docker docker.container.restartCount restartCount Docker docker.container.threadCount threadCount Docker docker.container.threadCountLimit threadCountLimit ElasticSearch elasticsearch.cluster.dataNodes cluster.dataNodes ElasticSearch elasticsearch.cluster.nodes cluster.nodes ElasticSearch elasticsearch.cluster.shards.active shards.active ElasticSearch elasticsearch.cluster.shards.initializing shards.initializing ElasticSearch elasticsearch.cluster.shards.primaryActive shards.primaryActive ElasticSearch elasticsearch.cluster.shards.relocating shards.relocating ElasticSearch elasticsearch.cluster.shards.unassigned shards.unassigned ElasticSearch elasticsearch.cluster.tempData temp-data ElasticSearch elasticsearch.index.docs index.docs ElasticSearch elasticsearch.index.docsDeleted index.docsDeleted ElasticSearch elasticsearch.index.primaryShards index.primaryShards ElasticSearch elasticsearch.index.primaryStoreSizeInBytes index.primaryStoreSizeInBytes ElasticSearch elasticsearch.index.replicaShards index.replicaShards ElasticSearch elasticsearch.index.rollup.docsCount primaries.docsnumber ElasticSearch elasticsearch.index.rollup.docsDeleted primaries.docsDeleted ElasticSearch elasticsearch.index.rollup.flushTotal primaries.flushesTotal ElasticSearch elasticsearch.index.rollup.flushTotalTimeInMilliseconds primaries.flushTotalTimeInMilliseconds ElasticSearch elasticsearch.index.rollup.get.documentsExist primaries.get.documentsExist ElasticSearch elasticsearch.index.rollup.get.documentsExistInMilliseconds primaries.get.documentsExistInMilliseconds ElasticSearch elasticsearch.index.rollup.get.documentsMissing primaries.get.documentsMissing ElasticSearch elasticsearch.index.rollup.get.documentsMissingInMilliseconds primaries.get.documentsMissingInMilliseconds ElasticSearch elasticsearch.index.rollup.get.requests primaries.get.requests ElasticSearch elasticsearch.index.rollup.get.requestsCurrent primaries.get.requestsCurrent ElasticSearch elasticsearch.index.rollup.get.requestsInMilliseconds primaries.get.requestsInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyDeleted primaries.index.docsCurrentlyDeleted ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyDeletedInMilliseconds primaries.index.docsCurrentlyDeletedInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyIndexing primaries.index.docsCurrentlyIndexing ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyIndexingInMilliseconds primaries.index.docsCurrentlyIndexingInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsDeleted primaries.index.docsDeleted ElasticSearch elasticsearch.index.rollup.index.docsTotal primaries.index.docsTotal ElasticSearch elasticsearch.index.rollup.indexRefreshesTotal primaries.indexRefreshesTotal ElasticSearch elasticsearch.index.rollup.indexRefreshesTotalInMilliseconds primaries.indexRefreshesTotalInMilliseconds ElasticSearch elasticsearch.index.rollup.merges.current primaries.merges.current ElasticSearch elasticsearch.index.rollup.merges.docsSegmentsCurrentlyMerged primaries.merges.docsSegmentsCurrentlyMerged ElasticSearch elasticsearch.index.rollup.merges.docsTotal primaries.merges.docsTotal ElasticSearch elasticsearch.index.rollup.merges.segmentsCurrentlyMergedInBytes primaries.merges.segmentsCurrentlyMergedInBytes ElasticSearch elasticsearch.index.rollup.merges.segmentsTotal primaries.merges.segmentsTotal ElasticSearch elasticsearch.index.rollup.merges.segmentsTotalInBytes primaries.merges.segmentsTotalInBytes ElasticSearch elasticsearch.index.rollup.merges.segmentsTotalInMilliseconds primaries.merges.segmentsTotalInMilliseconds ElasticSearch elasticsearch.index.rollup.queriesInMilliseconds primaries.queriesInMilliseconds ElasticSearch elasticsearch.index.rollup.queriesTotal primaries.queriesTotal ElasticSearch elasticsearch.index.rollup.queryActive primaries.queryActive ElasticSearch elasticsearch.index.rollup.queryFetches primaries.queryFetches ElasticSearch elasticsearch.index.rollup.queryFetchesInMilliseconds primaries.queryFetchesInMilliseconds ElasticSearch elasticsearch.index.rollup.queryFetchesTotal primaries.queryFetchesTotal ElasticSearch elasticsearch.index.rollup.sizeInBytes primaries.sizeInBytes ElasticSearch elasticsearch.index.storeSizeInBytes index.storeSizeInBytes ElasticSearch elasticsearch.node.activeSearches activeSearches ElasticSearch elasticsearch.node.activeSearchesInMilliseconds activeSearchesInMilliseconds ElasticSearch elasticsearch.node.breakers.estimatedSizeFieldDataCircuitBreakerInBytes breakers.estimatedSizeFieldDataCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.estimatedSizeParentCircuitBreakerInBytes breakers.estimatedSizeParentCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.estimatedSizeRequestCircuitBreakerInBytes breakers.estimatedSizeRequestCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.fieldDataCircuitBreakerTripped breakers.fieldDataCircuitBreakerTripped ElasticSearch elasticsearch.node.breakers.parentCircuitBreakerTripped breakers.parentCircuitBreakerTripped ElasticSearch elasticsearch.node.breakers.requestCircuitBreakerTripped breakers.requestCircuitBreakerTripped ElasticSearch elasticsearch.node.flush.indexRefreshesTotal flush.indexRefreshesTotal ElasticSearch elasticsearch.node.flush.indexRefreshesTotalInMilliseconds flush.indexRefreshesTotalInMilliseconds ElasticSearch elasticsearch.node.fs.bytesAvailableJvmInBytes fs.bytesAvailableJVMInBytes ElasticSearch elasticsearch.node.fs.dataRead fs.bytesReadsInBytes ElasticSearch elasticsearch.node.fs.dataWritten fs.writesInBytes ElasticSearch elasticsearch.node.fs.ioOperations fs.iOOperations ElasticSearch elasticsearch.node.fs.readOperations fs.reads ElasticSearch elasticsearch.node.fs.totalSizeInBytes fs.totalSizeInBytes ElasticSearch elasticsearch.node.fs.unallocatedBytes fs.unallocatedBytesInBYtes ElasticSearch elasticsearch.node.fs.writeOperations fs.writeOperations ElasticSearch elasticsearch.node.get.currentRequestsRunning get.currentRequestsRunning ElasticSearch elasticsearch.node.get.requestsDocumentExists get.requestsDocumentExists ElasticSearch elasticsearch.node.get.requestsDocumentExistsInMilliseconds get.requestsDocumentExistsInMilliseconds ElasticSearch elasticsearch.node.get.requestsDocumentMissing get.requestsDocumentMissing ElasticSearch elasticsearch.node.get.requestsDocumentMissingInMilliseconds get.requestsDocumentMissingInMilliseconds ElasticSearch elasticsearch.node.get.timeGetRequestsInMilliseconds get.timeGetRequestsInMilliseconds ElasticSearch elasticsearch.node.get.totalGetRequests get.totalGetRequests ElasticSearch elasticsearch.node.http.currentOpenConnections http.currentOpenConnections ElasticSearch elasticsearch.node.http.openedConnections http.openedConnections ElasticSearch elasticsearch.node.index.indexingOperationsFailed indices.indexingOperationsFailed ElasticSearch elasticsearch.node.index.indexingWaitedThrottlingInMilliseconds indices.indexingWaitedThrottlingInMilliseconds ElasticSearch elasticsearch.node.index.memoryQueryCacheInBytes indices.memoryQueryCacheInBytes ElasticSearch elasticsearch.node.index.numberIndices indices.numberIndices ElasticSearch elasticsearch.node.index.queryCacheEvictions indices.queryCacheEvictions ElasticSearch elasticsearch.node.index.queryCacheHits indices.queryCacheHits ElasticSearch elasticsearch.node.index.queryCacheMisses indices.queryCacheMisses ElasticSearch elasticsearch.node.index.recoveryOngoingShardSource indices.recoveryOngoingShardSource ElasticSearch elasticsearch.node.index.recoveryOngoingShardTarget indices.recoveryOngoingShardTarget ElasticSearch elasticsearch.node.index.recoveryWaitedThrottlingInMilliseconds indices.recoveryWaitedThrottlingInMilliseconds ElasticSearch elasticsearch.node.index.requestCacheEvictions indices.requestCacheEvictions ElasticSearch elasticsearch.node.index.requestCacheHits indices.requestCacheHits ElasticSearch elasticsearch.node.index.requestCacheMemoryInBytes indices.requestCacheMemoryInBytes ElasticSearch elasticsearch.node.index.requestCacheMisses indices.requestCacheMisses ElasticSearch elasticsearch.node.index.segmentsIndexShard indices.segmentsIndexShard ElasticSearch elasticsearch.node.index.segmentsMemoryUsedDocValuesInBytes indices.segmentsMemoryUsedDocValuesInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedFixedBitSetInBytes indices.segmentsMemoryUsedFixedBitSetInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedIndexSegmentsInBytes indices.segmentsMemoryUsedIndexSegmentsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedIndexWriterInBytes indices.segmentsMemoryUsedIndexWriterInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedNormsInBytes indices.segmentsMemoryUsedNormsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedSegmentVersionMapInBytes indices.segmentsMemoryUsedSegmentVersionMapInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedStoredFieldsInBytes indices.segmentsMemoryUsedStoredFieldsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedTermsInBytes indices.segmentsMemoryUsedTermsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedTermVectorsInBytes indices.segmentsMemoryUsedTermVectorsInBytes ElasticSearch elasticsearch.node.index.translogOperations indices.translogOperations ElasticSearch elasticsearch.node.index.translogOperationsInBytes indices.translogOperationsInBytes ElasticSearch elasticsearch.node.indexing.docsCurrentlyDeleted indexing.docsCurrentlyDeleted ElasticSearch elasticsearch.node.indexing.documentsCurrentlyIndexing indexing.documentsCurrentlyIndexing ElasticSearch elasticsearch.node.indexing.documentsIndexed indexing.documentsIndexed ElasticSearch elasticsearch.node.indexing.timeDeletingDocumentsInMilliseconds indexing.timeDeletingDocumentsInMilliseconds ElasticSearch elasticsearch.node.indexing.timeIndexingDocumentsInMilliseconds indexing.timeIndexingDocumentsInMilliseconds ElasticSearch elasticsearch.node.indexing.totalDocumentsDeleted indexing.totalDocumentsDeleted ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsOldGenerationObjects jvm.gc.majorCollectionsOldGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsOldGenerationObjectsInMilliseconds jvm.gc.majorCollectionsOldGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsYoungGenerationObjects jvm.gc.majorCollectionsYoungGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsYoungGenerationObjectsInMilliseconds jvm.gc.majorCollectionsYoungGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.gc.minorCollectionsYoungGenerationObjects jvm.gc.minorCollectionsYoungGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.minorCollectionsYoungGenerationObjectsInMilliseconds jvm.gc.minorCollectionsYoungGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.mem.heapCommittedInBytes jvm.mem.heapCommittedInBytes ElasticSearch elasticsearch.node.jvm.mem.heapMaxInBytes jvm.mem.heapMaxInBytes ElasticSearch elasticsearch.node.jvm.mem.heapUsed jvm.mem.heapUsed ElasticSearch elasticsearch.node.jvm.mem.heapUsedInBytes jvm.mem.heapUsedInBytes ElasticSearch elasticsearch.node.jvm.mem.maxOldGenerationHeapInBytes jvm.mem.maxOldGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.maxSurvivorSpaceInBytes jvm.mem.maxSurvivorSpaceInBYtes ElasticSearch elasticsearch.node.jvm.mem.maxYoungGenerationHeapInBytes jvm.mem.maxYoungGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.nonHeapCommittedInBytes jvm.mem.nonHeapCommittedInBytes ElasticSearch elasticsearch.node.jvm.mem.nonHeapUsedInBytes jvm.mem.nonHeapUsedInBytes ElasticSearch elasticsearch.node.jvm.mem.usedOldGenerationHeapInBytes jvm.mem.usedOldGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.usedSurvivorSpaceInBytes jvm.mem.usedSurvivorSpaceInBytes ElasticSearch elasticsearch.node.jvm.mem.usedYoungGenerationHeapInBytes jvm.mem.usedYoungGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.threadsActive jvm.ThreadsActive ElasticSearch elasticsearch.node.jvm.threadsPeak jvm.ThreadsPeak ElasticSearch elasticsearch.node.merges.currentActive merges.currentActive ElasticSearch elasticsearch.node.merges.docsSegmentMerges merges.docsSegmentMerges ElasticSearch elasticsearch.node.merges.docsSegmentsMerging merges.docsSegmentsMerging ElasticSearch elasticsearch.node.merges.mergedSegmentsInBytes merges.mergedSegmentsInBytes ElasticSearch elasticsearch.node.merges.segmentMerges merges.segmentMerges ElasticSearch elasticsearch.node.merges.sizeSegmentsMergingInBytes merges.sizeSegmentsMergingInBytes ElasticSearch elasticsearch.node.merges.totalSegmentMergingInMilliseconds merges.totalSegmentMergingInMilliseconds ElasticSearch elasticsearch.node.openFd openFD ElasticSearch elasticsearch.node.queriesTotal queriesTotal ElasticSearch elasticsearch.node.refresh.total refresh.total ElasticSearch elasticsearch.node.refresh.totalInMilliseconds refresh.totalInMilliseconds ElasticSearch elasticsearch.node.searchFetchCurrentlyRunning searchFetchCurrentlyRunning ElasticSearch elasticsearch.node.searchFetches searchFetches ElasticSearch elasticsearch.node.sizeStoreInBytes sizeStoreInBytes ElasticSearch elasticsearch.node.threadpool.activeFetchShardStarted threadpool.activeFetchShardStarted ElasticSearch elasticsearch.node.threadpool.bulkActive threadpool.bulkActive ElasticSearch elasticsearch.node.threadpool.bulkQueue threadpool.bulkQueue ElasticSearch elasticsearch.node.threadpool.bulkRejected threadpool.bulkRejected ElasticSearch elasticsearch.node.threadpool.bulkThreads threadpool.bulkThreads ElasticSearch elasticsearch.node.threadpool.fetchShardStartedQueue threadpool.fetchShardStartedQueue ElasticSearch elasticsearch.node.threadpool.fetchShardStartedRejected threadpool.fetchShardStartedRejected ElasticSearch elasticsearch.node.threadpool.fetchShardStartedThreads threadpool.fetchShardStartedThreads ElasticSearch elasticsearch.node.threadpool.fetchShardStoreActive threadpool.fetchShardStoreActive ElasticSearch elasticsearch.node.threadpool.fetchShardStoreQueue threadpool.fetchShardStoreQueue ElasticSearch elasticsearch.node.threadpool.fetchShardStoreRejected threadpool.fetchShardStoreRejected ElasticSearch elasticsearch.node.threadpool.fetchShardStoreThreads threadpool.fetchShardStoreThreads ElasticSearch elasticsearch.node.threadpool.flushActive threadpool.flushActive ElasticSearch elasticsearch.node.threadpool.flushQueue threadpool.flushQueue ElasticSearch elasticsearch.node.threadpool.flushRejected threadpool.flushRejected ElasticSearch elasticsearch.node.threadpool.flushThreads threadpool.flushThreads ElasticSearch elasticsearch.node.threadpool.forceMergeActive threadpool.forceMergeActive ElasticSearch elasticsearch.node.threadpool.forceMergeQueue threadpool.forceMergeQueue ElasticSearch elasticsearch.node.threadpool.forceMergeRejected threadpool.forceMergeRejected ElasticSearch elasticsearch.node.threadpool.forceMergeThreads threadpool.forceMergeThreads ElasticSearch elasticsearch.node.threadpool.genericActive threadpool.genericActive ElasticSearch elasticsearch.node.threadpool.genericQueue threadpool.genericQueue ElasticSearch elasticsearch.node.threadpool.genericRejected threadpool.genericRejected ElasticSearch elasticsearch.node.threadpool.genericThreads threadpool.genericThreads ElasticSearch elasticsearch.node.threadpool.getActive threadpool.getActive ElasticSearch elasticsearch.node.threadpool.getQueue threadpool.getQueue ElasticSearch elasticsearch.node.threadpool.getRejected threadpool.getRejected ElasticSearch elasticsearch.node.threadpool.getThreads threadpool.getThreads ElasticSearch elasticsearch.node.threadpool.indexActive threadpool.indexActive ElasticSearch elasticsearch.node.threadpool.indexQueue threadpool.indexQueue ElasticSearch elasticsearch.node.threadpool.indexRejected threadpool.indexRejected ElasticSearch elasticsearch.node.threadpool.indexThreads threadpool.indexThreads ElasticSearch elasticsearch.node.threadpool.listenerActive threadpool.listenerActive ElasticSearch elasticsearch.node.threadpool.listenerQueue threadpool.listenerQueue ElasticSearch elasticsearch.node.threadpool.listenerRejected threadpool.listenerRejected ElasticSearch elasticsearch.node.threadpool.listenerThreads threadpool.listenerThreads ElasticSearch elasticsearch.node.threadpool.managementActive threadpool.managementActive ElasticSearch elasticsearch.node.threadpool.managementQueue threadpool.managementQueue ElasticSearch elasticsearch.node.threadpool.managementRejected threadpool.managementRejected ElasticSearch elasticsearch.node.threadpool.managementThreads threadpool.managementThreads ElasticSearch elasticsearch.node.threadpool.refreshActive threadpool.refreshActive ElasticSearch elasticsearch.node.threadpool.refreshQueue threadpool.refreshQueue ElasticSearch elasticsearch.node.threadpool.refreshRejected threadpool.refreshRejected ElasticSearch elasticsearch.node.threadpool.refreshThreads threadpool.refreshThreads ElasticSearch elasticsearch.node.threadpool.searchActive threadpool.searchActive ElasticSearch elasticsearch.node.threadpool.searchQueue threadpool.searchQueue ElasticSearch elasticsearch.node.threadpool.searchRejected threadpool.searchRejected ElasticSearch elasticsearch.node.threadpool.searchThreads threadpool.searchThreads ElasticSearch elasticsearch.node.threadpool.snapshotActive threadpool.snapshotActive ElasticSearch elasticsearch.node.threadpool.snapshotQueue threadpool.snapshotQueue ElasticSearch elasticsearch.node.threadpool.snapshotRejected threadpool.snapshotRejected ElasticSearch elasticsearch.node.threadpool.snapshotThreads threadpool.snapshotThreads ElasticSearch elasticsearch.node.transport.connectionsOpened transport.connectionsOpened ElasticSearch elasticsearch.node.transport.packetsReceived transport.packetsReceived ElasticSearch elasticsearch.node.transport.packetsReceivedInBytes transport.packetsReceivedInBytes ElasticSearch elasticsearch.node.transport.packetsSent transport.packetsSent ElasticSearch elasticsearch.node.transport.packetsSentInBytes transport.packetsSentInBytes F5 f5.node.availabilityState node.availabilityState F5 f5.node.connections node.connections F5 f5.node.connectionsPerSecond node.connectionsPerSecond F5 f5.node.enabled node.enabled F5 f5.node.inDataInBytesPerSecond node.inDataInBytesPerSecond F5 f5.node.monitorStatus node.monitorStatus F5 f5.node.outDataInBytesPerSecond node.outDataInBytesPerSecond F5 f5.node.packetsReceivedPerSecond node.packetsReceivedPerSecond F5 f5.node.packetsSentPerSecond node.packetsSentPerSecond F5 f5.node.requestsPerSecond node.requestsPerSecond F5 f5.node.sessions node.sessions F5 f5.node.sessionStatus node.sessionStatus F5 f5.poolMember.availabilityState member.availabilityState F5 f5.poolMember.connections member.connections F5 f5.poolMember.enabled member.enabled F5 f5.poolMember.inDataInBytesPerSecond member.inDataInBytesPerSecond F5 f5.poolMember.monitorStatus member.monitorStatus F5 f5.poolMember.outDataInBytesPerSecond member.outDataInBytesPerSecond F5 f5.poolMember.packetsReceivedPerSecond member.packetsReceivedPerSecond F5 f5.poolMember.packetsSentPerSecond member.packetsSentPerSecond F5 f5.poolMember.requestsPerSecond member.requestsPerSecond F5 f5.poolMember.sessions member.sessions F5 f5.poolMember.sessionStatus member.sessionStatus F5 f5.pool.activeMembers pool.activeMembers F5 f5.pool.availabilityState pool.availabilityState F5 f5.pool.connections pool.connections F5 f5.pool.connqAgeEdm pool.connqAgeEdm F5 f5.pool.connqAgeEma pool.connqAgeEma F5 f5.pool.connqAgeHead pool.connqAgeHead F5 f5.pool.connqAgeMax pool.connqAgeMax F5 f5.pool.connqAllAgeEdm pool.connqAllAgeEdm F5 f5.pool.connqAllAgeEma pool.connqAllAgeEma F5 f5.pool.connqAllAgeHead pool.connqAllAgeHead F5 f5.pool.connqAllAgeMax pool.connqAllAgeMax F5 f5.pool.connqAllDepth pool.connqAllDepth F5 f5.pool.connqDepth pool.connqDepth F5 f5.pool.currentConnections pool.currentConnections F5 f5.pool.enabled pool.enabled F5 f5.pool.inDataInBytesPerSecond pool.inDataInBytesPerSecond F5 f5.pool.minActiveMembers pool.minActiveMembers F5 f5.pool.outDataInBytesPerSecond pool.outDataInBytesPerSecond F5 f5.pool.packetsReceivedPerSecond pool.packetsReceivedPerSecond F5 f5.pool.packetsSentPerSecond pool.packetsSentPerSecond F5 f5.pool.requestsPerSecond pool.requestsPerSecond F5 f5.pool.sessions pool.sessions F5 f5.system.cpuIdleTicksPerSecond system.cpuIdleTicksPerSecond F5 f5.system.cpuIdleUtilization system.cpuIdleUtilization F5 f5.system.cpuInterruptRequestUtilization system.cpuInterruptRequestUtilization F5 f5.system.cpuIoWaitUtilization system.cpuIOWaitUtilization F5 f5.system.cpuNiceLevelUtilization system.cpuNiceLevelUtilization F5 f5.system.cpuSoftInterruptRequestUtilization system.cpuSoftInterruptRequestUtilization F5 f5.system.cpuStolenUtilization system.cpuStolenUtilization F5 f5.system.cpuSystemTicksPerSecond system.cpuSystemTicksPerSecond F5 f5.system.cpuSystemUtilization system.cpuSystemUtilization F5 f5.system.cpuUserTicksPerSecond system.cpuUserTicksPerSecond F5 f5.system.cpuUserUtilization system.cpuUserUtilization F5 f5.system.memoryFreeInBytes system.memoryFreeInBytes F5 f5.system.memoryTotalInBytes system.memoryTotalInBytes F5 f5.system.memoryUsedInBytes system.memoryUsedInBytes F5 f5.system.otherMemoryFreeInBytes system.otherMemoryFreeInBytes F5 f5.system.otherMemoryTotalInBytes system.otherMemoryTotalInBytes F5 f5.system.otherMemoryUsedInBytes system.otherMemoryUsedInBytes F5 f5.system.swapFreeInBytes system.swapFreeInBytes F5 f5.system.swapTotalInBytes system.swapTotalInBytes F5 f5.system.swapUsedInBytes system.swapUsedInBytes F5 f5.system.tmmMemoryFreeInBytes system.tmmMemoryFreeInBytes F5 f5.system.tmmMemoryTotalInBytes system.tmmMemoryTotalInBytes F5 f5.system.tmmMemoryUsedInBytes system.tmmMemoryUsedInBytes F5 f5.virtualserver.availabilityState virtualserver.availabilityState F5 f5.virtualserver.clientsideConnectionsPerSecond virtualserver.clientsideConnectionsPerSecond F5 f5.virtualserver.connections virtualserver.connections F5 f5.virtualserver.csMaxConnDur virtualserver.csMaxConnDur F5 f5.virtualserver.csMeanConnDur virtualserver.csMeanConnDur F5 f5.virtualserver.csMinConnDur virtualserver.csMinConnDur F5 f5.virtualserver.enabled virtualserver.enabled F5 f5.virtualserver.ephemeralBytesInPerSecond virtualserver.ephemeralBytesInPerSecond F5 f5.virtualserver.ephemeralBytesOutPerSecond virtualserver.ephemeralBytesOutPerSecond F5 f5.virtualserver.ephemeralConnectionsPerSecond virtualserver.ephemeralConnectionsPerSecond F5 f5.virtualserver.ephemeralCurrentConnections virtualserver.ephemeralCurrentConnections F5 f5.virtualserver.ephemeralEvictedConnectionsPerSecond virtualserver.ephemeralEvictedConnectionsPerSecond F5 f5.virtualserver.ephemeralMaxConnections virtualserver.ephemeralMaxConnections F5 f5.virtualserver.ephemeralPacketsReceivedPerSecond virtualserver.ephemeralPacketsReceivedPerSecond F5 f5.virtualserver.ephemeralPacketsSentPerSecond virtualserver.ephemeralPacketsSentPerSecond F5 f5.virtualserver.ephemeralSlowKilledPerSecond virtualserver.ephemeralSlowKilledPerSecond F5 f5.virtualserver.evictedConnsPerSecond virtualserver.evictedConnsPerSecond F5 f5.virtualserver.inDataInBytesPerSecond virtualserver.inDataInBytesPerSecond F5 f5.virtualserver.outDataInBytesPerSecond virtualserver.outDataInBytesPerSecond F5 f5.virtualserver.packetsReceivedPerSecond virtualserver.packetsReceivedPerSecond F5 f5.virtualserver.packetsSentPerSecond virtualserver.packetsSentPerSecond F5 f5.virtualserver.requestsPerSecond virtualserver.requestsPerSecond F5 f5.virtualserver.slowKilledPerSecond virtualserver.slowKilledPerSecond F5 f5.virtualserver.usageRatio virtualserver.usageRatio HAProxy haproxy.backend.activeServers backend.activeServers HAProxy haproxy.backend.averageConnectTimeInSeconds backend.averageConnectTimeInSeconds HAProxy haproxy.backend.averageQueueTimeInSeconds backend.averageQueueTimeInSeconds HAProxy haproxy.backend.averageResponseTimeInSeconds backend.averageResponseTimeInSeconds HAProxy haproxy.backend.averageTotalSessionTimeInSeconds backend.averageTotalSessionTimeInSeconds HAProxy haproxy.backend.backupServers backend.backupServers HAProxy haproxy.backend.bytesInPerSecond backend.bytesInPerSecond HAProxy haproxy.backend.bytesOutPerSecond backend.bytesOutPerSecond HAProxy haproxy.backend.bytesThatBypassedCompressorPerSecond backend.bytesThatBypassedCompressorPerSecond HAProxy haproxy.backend.connectingRequestErrorsPerSecond backend.connectingRequestErrorsPerSecond HAProxy haproxy.backend.connectionRetriesPerSecond backend.connectionRetriesPerSecond HAProxy haproxy.backend.currentQueuedRequestsWithoutServer backend.currentQueuedRequestsWithoutServer HAProxy haproxy.backend.currentSessions backend.currentSessions HAProxy haproxy.backend.dataTransfersAbortedByClientPerSecond backend.dataTransfersAbortedByClientPerSecond HAProxy haproxy.backend.dataTransfersAbortedByServerPerSecond backend.dataTransfersAbortedByServerPerSecond HAProxy haproxy.backend.downtimeInSeconds backend.downtimeInSeconds HAProxy haproxy.backend.http100ResponsesPerSecond backend.http100ResponsesPerSecond HAProxy haproxy.backend.http200ResponsesPerSecond backend.http200ResponsesPerSecond HAProxy haproxy.backend.http300ResponsesPerSecond backend.http300ResponsesPerSecond HAProxy haproxy.backend.http400ResponsesPerSecond backend.http400ResponsesPerSecond HAProxy haproxy.backend.http500ResponsesPerSecond backend.http500ResponsesPerSecond HAProxy haproxy.backend.httpOtherResponsesPerSecond backend.httpOtherResponsesPerSecond HAProxy haproxy.backend.httpRequestsPerSecond backend.httpRequestsPerSecond HAProxy haproxy.backend.httpResponseBytesEmittedByCompressorPerSecond backend.httpResponseBytesEmittedByCompressorPerSecond HAProxy haproxy.backend.httpResponseBytesFedToCompressorPerSecond backend.httpResponseBytesFedToCompressorPerSecond HAProxy haproxy.backend.httpResponsesCompressedPerSecond backend.httpResponsesCompressedPerSecond HAProxy haproxy.backend.interceptedRequestsPerSecond backend.interceptedRequestsPerSecond HAProxy haproxy.backend.maxQueuedRequestsWithoutServer backend.maxQueuedRequestsWithoutServer HAProxy haproxy.backend.maxSessions backend.maxSessions HAProxy haproxy.backend.maxSessionsPerSecond backend.maxSessionsPerSecond HAProxy haproxy.backend.requestRedispatchPerSecond backend.requestRedispatchPerSecond HAProxy haproxy.backend.requestsDenied.securityConcernsPerSecond backend.requestsDenied.securityConcernsPerSecond HAProxy haproxy.backend.responseErrorsPerSecond backend.responseErrorsPerSecond HAProxy haproxy.backend.responsesDenied.securityConcernsPerSecond backend.responsesDenied.securityConcernsPerSecond HAProxy haproxy.backend.serverSelectedPerSecond backend.serverSelectedPerSecond HAProxy haproxy.backend.sessionsPerSecond backend.sessionsPerSecond HAProxy haproxy.backend.timeSinceLastSessionAssignedInSeconds backend.timeSinceLastSessionAssignedInSeconds HAProxy haproxy.backend.timeSinceLastUpDownTransitionInSeconds backend.timeSinceLastUpDownTransitionInSeconds HAProxy haproxy.backend.totalWeight backend.totalWeight HAProxy haproxy.backend.type backend.type HAProxy haproxy.backend.upToDownTransitionsPerSecond backend.upToDownTransitionsPerSecond HAProxy haproxy.frontend.bytesInPerSecond frontend.bytesInPerSecond HAProxy haproxy.frontend.bytesOutPerSecond frontend.bytesOutPerSecond HAProxy haproxy.frontend.connectionsPerSecond frontend.connectionsPerSecond HAProxy haproxy.frontend.currentSessions frontend.currentSessions HAProxy haproxy.frontend.http100ResponsesPerSecond frontend.http100ResponsesPerSecond HAProxy haproxy.frontend.http200ResponsesPerSecond frontend.http200ResponsesPerSecond HAProxy haproxy.frontend.http300ResponsesPerSecond frontend.http300ResponsesPerSecond HAProxy haproxy.frontend.http400ResponsesPerSecond frontend.http400ResponsesPerSecond HAProxy haproxy.frontend.http500ResponsesPerSecond frontend.http500ResponsesPerSecond HAProxy haproxy.frontend.httpOtherResponsesPerSecond frontend.httpOtherResponsesPerSecond HAProxy haproxy.frontend.httpRequests.maxPerSecond frontend.httpRequests.maxPerSecond HAProxy haproxy.frontend.httpRequestsPerSecond frontend.httpRequestsPerSecond HAProxy haproxy.frontend.interceptedRequestsPerSecond frontend.interceptedRequestsPerSecond HAProxy haproxy.frontend.maxConnectionsPerSecond frontend.maxConnectionsPerSecond HAProxy haproxy.frontend.maxSessions frontend.maxSessions HAProxy haproxy.frontend.maxSessionsPerSecond frontend.maxSessionsPerSecond HAProxy haproxy.frontend.requestErrorsPerSecond frontend.requestErrorsPerSecond HAProxy haproxy.frontend.requestsDenied.securityConcernsPerSecond frontend.requestsDenied.securityConcernsPerSecond HAProxy haproxy.frontend.requestsDenied.tcpRequestConnectionRulesPerSecond frontend.requestsDenied.tcpRequestConnectionRulesPerSecond HAProxy haproxy.frontend.requestsDenied.tcpRequestSessionRulesPerSecond frontend.requestsDenied.tcpRequestSessionRulesPerSecond HAProxy haproxy.frontend.responsesDenied.securityConcernsPerSecond frontend.responsesDenied.securityConcernsPerSecond HAProxy haproxy.frontend.sessionsPerSecond frontend.sessionsPerSecond HAProxy haproxy.server.averageConnectTimeInSeconds server.averageConnectTimeInSeconds HAProxy haproxy.server.averageQueueTimeInSeconds server.averageQueueTimeInSeconds HAProxy haproxy.server.averageResponseTimeInSeconds server.averageResponseTimeInSeconds HAProxy haproxy.server.averageTotalSessionTimeInSeconds server.averageTotalSessionTimeInSeconds HAProxy haproxy.server.bytesInPerSecond server.bytesInPerSecond HAProxy haproxy.server.bytesOutPerSecond server.bytesOutPerSecond HAProxy haproxy.server.connectingRequestErrorsPerSecond server.connectingRequestErrorsPerSecond HAProxy haproxy.server.connectionRetriesPerSecond server.connectionRetriesPerSecond HAProxy haproxy.server.currentQueuedRequestsWithoutServer server.currentQueuedRequestsWithoutServer HAProxy haproxy.server.currentSessions server.currentSessions HAProxy haproxy.server.dataTransfersAbortedByClientPerSecond server.dataTransfersAbortedByClientPerSecond HAProxy haproxy.server.dataTransfersAbortedByServerPerSecond server.dataTransfersAbortedByServerPerSecond HAProxy haproxy.server.downtimeInSeconds server.downtimeInSeconds HAProxy haproxy.server.failedChecksPerSecond server.failedChecksPerSecond HAProxy haproxy.server.healthCheckDurationInMilliseconds server.healthCheckDurationInMilliseconds HAProxy haproxy.server.http100ResponsesPerSecond server.http100ResponsesPerSecond HAProxy haproxy.server.http200ResponsesPerSecond server.http200ResponsesPerSecond HAProxy haproxy.server.http300ResponsesPerSecond server.http300ResponsesPerSecond HAProxy haproxy.server.http400ResponsesPerSecond server.http400ResponsesPerSecond HAProxy haproxy.server.http500ResponsesPerSecond server.http500ResponsesPerSecond HAProxy haproxy.server.httpOtherResponsesPerSecond server.httpOtherResponsesPerSecond HAProxy haproxy.server.isActive server.isActive HAProxy haproxy.server.isBackup server.isBackup HAProxy haproxy.server.maxQueuedRequestsWithoutServer server.maxQueuedRequestsWithoutServer HAProxy haproxy.server.maxSessions server.maxSessions HAProxy haproxy.server.maxSessionsPerSecond server.maxSessionsPerSecond HAProxy haproxy.server.requestRedispatchPerSecond server.requestRedispatchPerSecond HAProxy haproxy.server.requestsDenied.securityConcernsPerSecond server.requestsDenied.securityConcernsPerSecond HAProxy haproxy.server.responseErrorsPerSecond server.responseErrorsPerSecond HAProxy haproxy.server.responsesDenied.securityConcernsPerSecond server.responsesDenied.securityConcernsPerSecond HAProxy haproxy.server.serverSelectedPerSecond server.serverSelectedPerSecond HAProxy haproxy.server.serverWeight server.serverWeight HAProxy haproxy.server.sessionsPerSecond server.sessionsPerSecond HAProxy haproxy.server.throttlePercentage server.throttlePercentage HAProxy haproxy.server.timeSinceLastSessionAssignedInSeconds server.timeSinceLastSessionAssignedInSeconds HAProxy haproxy.server.timeSinceLastUpDownTransitionInSeconds server.timeSinceLastUpDownTransitionInSeconds HAProxy haproxy.server.type server.type HAProxy haproxy.server.upToDownTransitionsPerSecond server.upToDownTransitionsPerSecond Kafka kafka.broker.bytesWrittenToTopicPerSecond broker.bytesWrittenToTopicPerSecond Kafka kafka.broker.consumer.requestsExpiredPerSecond consumer.requestsExpiredPerSecond Kafka kafka.broker.follower.requestExpirationPerSecond follower.requestExpirationPerSecond Kafka kafka.broker.ioInPerSecond broker.IOInPerSecond Kafka kafka.broker.ioOutPerSecond broker.IOOutPerSecond Kafka kafka.broker.logFlushPerSecond broker.logFlushPerSecond Kafka kafka.broker.messagesInPerSecond broker.messagesInPerSecond Kafka kafka.broker.net.bytesRejectedPerSecond net.bytesRejectedPerSecond Kafka kafka.broker.replication.isrExpandsPerSecond replication.isrExpandsPerSecond Kafka kafka.broker.replication.isrShrinksPerSecond replication.isrShrinksPerSecond Kafka kafka.broker.replication.leaderElectionPerSecond replication.leaderElectionPerSecond Kafka kafka.broker.replication.uncleanLeaderElectionPerSecond replication.uncleanLeaderElectionPerSecond Kafka kafka.broker.replication.unreplicatedPartitions replication.unreplicatedPartitions Kafka kafka.broker.request.avgTimeFetch request.avgTimeFetch Kafka kafka.broker.request.avgTimeMetadata request.avgTimeMetadata Kafka kafka.broker.request.avgTimeMetadata99Percentile request.avgTimeMetadata99Percentile Kafka kafka.broker.request.avgTimeOffset request.avgTimeOffset Kafka kafka.broker.request.avgTimeOffset99Percentile request.avgTimeOffset99Percentile Kafka kafka.broker.request.avgTimeProduceRequest request.avgTimeProduceRequest Kafka kafka.broker.request.avgTimeUpdateMetadata request.avgTimeUpdateMetadata Kafka kafka.broker.request.avgTimeUpdateMetadata99Percentile request.avgTimeUpdateMetadata99Percentile Kafka kafka.broker.request.clientFetchesFailedPerSecond request.clientFetchesFailedPerSecond Kafka kafka.broker.request.fetchConsumerRequestsPerSecond request.fetchConsumerRequestsPerSecond Kafka kafka.broker.request.fetchFollowerRequestsPerSecond request.fetchFollowerRequestsPerSecond Kafka kafka.broker.request.fetchTime99Percentile request.fetchTime99Percentile Kafka kafka.broker.request.handlerIdle request.handlerIdle Kafka kafka.broker.request.listGroupsRequestsPerSecond request.listGroupsRequestsPerSecond Kafka kafka.broker.request.metadataRequestsPerSecond request.metadataRequestsPerSecond Kafka kafka.broker.request.offsetCommitRequestsPerSecond request.offsetCommitRequestsPerSecond Kafka kafka.broker.request.produceRequestsFailedPerSecond request.produceRequestsFailedPerSecond Kafka kafka.broker.request.produceRequestsPerSecond request.produceRequestsPerSecond Kafka kafka.broker.request.produceTime99Percentile request.produceTime99Percentile Kafka kafka.broker.topic.diskSize topic.diskSize Kafka kafka.topic.bytesInPerSec topic.BytesInPerSec Kafka kafka.topic.bytesOutPerSec topic.BytesOutPerSec Kafka kafka.topic.messagesInPerSec topic.MessagesInPerSec Kafka kafka.topic.partitionsWithNonPreferredLeader topic.partitionsWithNonPreferredLeader Kafka kafka.topic.respondsToMetadataRequests topic.respondsToMetadataRequests Kafka kafka.topic.retentionBytesOrTime topic.retentionBytesOrTime Kafka kafka.topic.underReplicatedPartitions topic.underReplicatedPartitions Kafka kafka.producer.ageMetadataUsedInMilliseconds producer.ageMetadataUsedInMilliseconds Kafka kafka.producer.availableBufferInBytes producer.availableBufferInBytes Kafka kafka.producer.avgBytesSentPerRequestInBytes producer.avgBytesSentPerRequestInBytes Kafka kafka.producer.avgCompressionRateRecordBatches producer.avgCompressionRateRecordBatches Kafka kafka.producer.avgRecordAccumulatorsInMilliseconds producer.avgRecordAccumulatorsInMilliseconds Kafka kafka.producer.avgRecordSizeInBytes producer.avgRecordSizeInBytes Kafka kafka.producer.avgRecordsSentPerSecond producer.avgRecordsSentPerSecond Kafka kafka.producer.avgRecordsSentPerTopicPerSecond producer.avgRecordsSentPerTopicPerSecond Kafka kafka.producer.avgRequestLatency producer.avgRequestLatencyPerSecond Kafka kafka.producer.avgThrottleTime producer.avgThrottleTime Kafka kafka.producer.bufferMemoryAvailableInBytes producer.bufferMemoryAvailableInBytes Kafka kafka.producer.bufferpoolWaitTime producer.bufferpoolWaitTime Kafka kafka.producer.bytesOutPerSecond producer.bytesOutPerSecond Kafka kafka.producer.compressionRateRecordBatches producer.compressionRateRecordBatches Kafka kafka.producer.ioWaitTime producer.ioWaitTime Kafka kafka.producer.maxBytesSentPerRequestInBytes producer.maxBytesSentPerRequestInBytes Kafka kafka.producer.maxRecordSizeInBytes producer.maxRecordSizeInBytes Kafka kafka.producer.maxRequestLatencyInMilliseconds producer.maxRequestLatencyInMilliseconds Kafka kafka.producer.maxThrottleTime producer.maxThrottleTime Kafka kafka.producer.requestPerSecond producer.requestPerSecond Kafka kafka.producer.requestsWaitingResponse producer.requestsWaitingResponse Kafka kafka.producer.responsePerSecond producer.responsePerSecond Kafka kafka.producer.threadsWaiting producer.threadsWaiting Kafka kafka.consumer.avgFetchSizeInBytes consumer.avgFetchSizeInBytes Kafka kafka.consumer.avgRecordConsumedPerTopic consumer.avgRecordConsumedPerTopic Kafka kafka.consumer.avgRecordConsumedPerTopicPerSecond consumer.avgRecordConsumedPerTopicPerSecond Kafka kafka.consumer.bytesInPerSecond consumer.bytesInPerSecond Kafka kafka.consumer.fetchPerSecond consumer.fetchPerSecond Kafka kafka.consumer.hwm consumer.hwm Kafka kafka.consumer.lag consumer.lag Kafka kafka.consumer.maxFetchSizeInBytes consumer.maxFetchSizeInBytes Kafka kafka.consumer.maxLag consumer.maxLag Kafka kafka.consumer.messageConsumptionPerSecond consumer.messageConsumptionPerSecond Kafka kafka.consumer.offset consumer.offset Kafka kafka.consumer.totalLag consumer.totalLag Kafka kafka.consumerGroup.maxLag consumerGroup.maxLag Kafka kafka.consumerGroup.totalLag consumerGroup.totalLag Kubernetes k8s.apiserver.goGoroutines goGoroutines Kubernetes k8s.apiserver.goThreads goThreads Kubernetes k8s.apiserver.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.apiserver.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.controllermanager.goGoroutines goGoroutines Kubernetes k8s.controllermanager.goThreads goThreads Kubernetes k8s.controllermanager.leaderElectionMasterStatus leaderElectionMasterStatus Kubernetes k8s.controllermanager.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.controllermanager.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.etcd.goGoroutines goGoroutines Kubernetes k8s.etcd.goThreads goThreads Kubernetes k8s.etcd.mvccDbTotalSizeInBytes etcdMvccDbTotalSizeInBytes Kubernetes k8s.etcd.networkClientGrpcReceivedBytesRate etcdNetworkClientGrpcReceivedBytesRate Kubernetes k8s.etcd.networkClientGrpcSentBytesRate etcdNetworkClientGrpcSentBytesRate Kubernetes k8s.etcd.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.etcd.process.maxFds processMaxFds Kubernetes k8s.etcd.process.openFds processOpenFds Kubernetes k8s.etcd.process.processFdsUtilization processFdsUtilization Kubernetes k8s.etcd.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.etcd.serverHasLeader etcdServerHasLeader Kubernetes k8s.etcd.serverLeaderChangesSeenDelta etcdServerLeaderChangesSeenDelta Kubernetes k8s.etcd.serverProposalsAppliedDelta etcdServerProposalsAppliedDelta Kubernetes k8s.etcd.serverProposalsAppliedRate etcdServerProposalsAppliedRate Kubernetes k8s.etcd.serverProposalsCommittedDelta etcdServerProposalsCommittedDelta Kubernetes k8s.etcd.serverProposalsCommittedRate etcdServerProposalsCommittedRate Kubernetes k8s.etcd.serverProposalsFailedDelta etcdServerProposalsFailedDelta Kubernetes k8s.etcd.serverProposalsFailedRate etcdServerProposalsFailedRate Kubernetes k8s.etcd.serverProposalsPending etcdServerProposalsPending Kubernetes k8s.scheduler.goGoroutines goGoroutines Kubernetes k8s.scheduler.goThreads goThreads Kubernetes k8s.scheduler.leaderElectionMasterStatus leaderElectionMasterStatus Kubernetes k8s.scheduler.podPreemptionVictims schedulerPodPreemptionVictims Kubernetes k8s.scheduler.preemptionAttemptsDelta schedulerPreemptionAttemptsDelta Kubernetes k8s.scheduler.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.scheduler.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.container.cpuCfsPeriodsDelta containerCpuCfsPeriodsDelta Kubernetes k8s.container.cpuCfsPeriodsTotal containerCpuCfsPeriodsTotal Kubernetes k8s.container.cpuCfsThrottledPeriodsDelta containerCpuCfsThrottledPeriodsDelta Kubernetes k8s.container.cpuCfsThrottledPeriodsTotal containerCpuCfsThrottledPeriodsTotal Kubernetes k8s.container.cpuCfsThrottledSecondsDelta containerCpuCfsThrottledSecondsDelta Kubernetes k8s.container.cpuCfsThrottledSecondsTotal containerCpuCfsThrottledSecondsTotal Kubernetes k8s.container.cpuCoresUtilization cpuCoresUtilization Kubernetes k8s.container.cpuLimitCores cpuLimitCores Kubernetes k8s.container.cpuRequestedCores cpuRequestedCores Kubernetes k8s.container.cpuUsedCores cpuUsedCores Kubernetes k8s.container.fsAvailableBytes fsAvailableBytes Kubernetes k8s.container.fsCapacityBytes fsCapacityBytes Kubernetes k8s.container.fsInodes fsInodes Kubernetes k8s.container.fsInodesFree fsInodesFree Kubernetes k8s.container.fsInodesUsed fsInodesUsed Kubernetes k8s.container.fsUsedBytes fsUsedBytes Kubernetes k8s.container.fsUsedPercent fsUsedPercent Kubernetes k8s.container.isReady isReady Kubernetes k8s.container.memoryLimitBytes memoryLimitBytes Kubernetes k8s.container.memoryMappedFileBytes containerMemoryMappedFileBytes Kubernetes k8s.container.memoryRequestedBytes memoryRequestedBytes Kubernetes k8s.container.memoryUsedBytes memoryUsedBytes Kubernetes k8s.container.memoryUtilization memoryUtilization Kubernetes k8s.container.memoryWorkingSetBytes memoryWorkingSetBytes Kubernetes k8s.container.requestedCpuCoresUtilization requestedCpuCoresUtilization Kubernetes k8s.container.requestedMemoryUtilization requestedMemoryUtilization Kubernetes k8s.container.restartCount restartCount Kubernetes k8s.daemonset.createdAt createdAt Kubernetes k8s.daemonset.metadataGeneration metadataGeneration Kubernetes k8s.daemonset.podsAvailable podsAvailable Kubernetes k8s.daemonset.podsDesired podsDesired Kubernetes k8s.daemonset.podsMisscheduled podsMisscheduled Kubernetes k8s.daemonset.podsReady podsReady Kubernetes k8s.daemonset.podsScheduled podsScheduled Kubernetes k8s.daemonset.podsUnavailable podsUnavailable Kubernetes k8s.daemonset.podsUpdatedScheduled podsUpdatedScheduled Kubernetes k8s.deployment.createdAt createdAt Kubernetes k8s.deployment.podsAvailable podsAvailable Kubernetes k8s.deployment.podsDesired podsDesired Kubernetes k8s.deployment.podsMaxUnavailable podsMaxUnavailable Kubernetes k8s.deployment.podsTotal podsTotal Kubernetes k8s.deployment.podsUnavailable podsUnavailable Kubernetes k8s.deployment.podsUpdated podsUpdated Kubernetes k8s.endpoint.addressAvailable addressAvailable Kubernetes k8s.endpoint.addressNotReady addressNotReady Kubernetes k8s.endpoint.createdAt createdAt Kubernetes k8s.namespace.createdAt createdAt Kubernetes k8s.node.allocatableAttachableVolumes* allocatableAttachableVolumes* Kubernetes k8s.node.allocatableCpuCores allocatableCpuCores Kubernetes k8s.node.allocatableCpuCoresUtilization allocatableCpuCoresUtilization Kubernetes k8s.node.allocatableEphemeralStorageBytes allocatableEphemeralStorageBytes Kubernetes k8s.node.allocatableHugepages* allocatableHugepages* Kubernetes k8s.node.allocatableMemoryBytes allocatableMemoryBytes Kubernetes k8s.node.allocatableMemoryUtilization allocatableMemoryUtilization Kubernetes k8s.node.allocatablePods allocatablePods Kubernetes k8s.node.capacityAttachableVolumes* capacityAttachableVolumes* Kubernetes k8s.node.capacityCpuCores capacityCpuCores Kubernetes k8s.node.capacityEphemeralStorageBytes capacityEphemeralStorageBytes Kubernetes k8s.node.capacityHugepages* capacityHugepages* Kubernetes k8s.node.capacityMemoryBytes capacityMemoryBytes Kubernetes k8s.node.capacityPods capacityPods Kubernetes k8s.node.cpuUsedCoreMilliseconds cpuUsedCoreMilliseconds Kubernetes k8s.node.cpuUsedCores cpuUsedCores Kubernetes k8s.node.fsAvailableBytes fsAvailableBytes Kubernetes k8s.node.fsCapacityBytes fsCapacityBytes Kubernetes k8s.node.fsCapacityUtilization fsCapacityUtilization Kubernetes k8s.node.fsInodes fsInodes Kubernetes k8s.node.fsInodesFree fsInodesFree Kubernetes k8s.node.fsInodesUsed fsInodesUsed Kubernetes k8s.node.fsUsedBytes fsUsedBytes Kubernetes k8s.node.memoryAvailableBytes memoryAvailableBytes Kubernetes k8s.node.memoryMajorPageFaultsPerSecond memoryMajorPageFaultsPerSecond Kubernetes k8s.node.memoryPageFaults memoryPageFaults Kubernetes k8s.node.memoryRssBytes memoryRssBytes Kubernetes k8s.node.memoryUsedBytes memoryUsedBytes Kubernetes k8s.node.memoryWorkingSetBytes memoryWorkingSetBytes Kubernetes k8s.node.netErrorsPerSecond net.errorsPerSecond Kubernetes k8s.node.netRxBytesPerSecond net.rxBytesPerSecond Kubernetes k8s.node.netTxBytesPerSecond net.txBytesPerSecond Kubernetes k8s.node.runtimeAvailableBytes runtimeAvailableBytes Kubernetes k8s.node.runtimeCapacityBytes runtimeCapacityBytes Kubernetes k8s.node.runtimeInodes runtimeInodes Kubernetes k8s.node.runtimeInodesFree runtimeInodesFree Kubernetes k8s.node.runtimeInodesUsed runtimeInodesUsed Kubernetes k8s.node.runtimeUsedBytes runtimeUsedBytes Kubernetes k8s.pod.createdAt createdAt Kubernetes k8s.pod.isReady isReady Kubernetes k8s.pod.isScheduled isScheduled Kubernetes k8s.pod.netErrorsPerSecond net.errorsPerSecond Kubernetes k8s.pod.netRxBytesPerSecond net.rxBytesPerSecond Kubernetes k8s.pod.netTxBytesPerSecond net.txBytesPerSecond Kubernetes k8s.pod.startTime startTime Kubernetes k8s.replicaset.createdAt createdAt Kubernetes k8s.replicaset.observedGeneration observedGeneration Kubernetes k8s.replicaset.podsDesired podsDesired Kubernetes k8s.replicaset.podsFullyLabeled podsFullyLabeled Kubernetes k8s.replicaset.podsMissing podsMissing Kubernetes k8s.replicaset.podsReady podsReady Kubernetes k8s.replicaset.podsTotal podsTotal Kubernetes k8s.service.createdAt createdAt Kubernetes k8s.statefulset.createdAt createdAt Kubernetes k8s.statefulset.currentRevision currentRevision Kubernetes k8s.statefulset.metadataGeneration metadataGeneration Kubernetes k8s.statefulset.observedGeneration observedGeneration Kubernetes k8s.statefulset.podsCurrent podsCurrent Kubernetes k8s.statefulset.podsDesired podsDesired Kubernetes k8s.statefulset.podsReady podsReady Kubernetes k8s.statefulset.podsTotal podsTotal Kubernetes k8s.statefulset.podsUpdated podsUpdated Kubernetes k8s.statefulset.updateRevision updateRevision Kubernetes k8s.volume.fsAvailableBytes fsAvailableBytes Kubernetes k8s.volume.fsCapacityBytes fsCapacityBytes Kubernetes k8s.volume.fsInodes fsInodes Kubernetes k8s.volume.fsInodesFree fsInodesFree Kubernetes k8s.volume.fsInodesUsed fsInodesUsed Kubernetes k8s.volume.fsUsedBytes fsUsedBytes Kubernetes k8s.volume.fsUsedPercent fsUsedPercent Memcached memcached.server.activeSlabs activeSlabs Memcached memcached.server.avgItemSizeInBytes avgItemSizeInBytes Memcached memcached.server.bytesReadServerPerSecond bytesReadServerPerSecond Memcached memcached.server.bytesUsedServerInBytes bytesUsedServerInBytes Memcached memcached.server.bytesWrittenServerPerSecond bytesWrittenServerPerSecond Memcached memcached.server.casHitRatePerSecond casHitRatePerSecond Memcached memcached.server.casMissRatePerSecond casMissRatePerSecond Memcached memcached.server.casWrongRatePerSecond casWrongRatePerSecond Memcached memcached.server.cmdFlushRatePerSecond cmdFlushRatePerSecond Memcached memcached.server.cmdGetRatePerSecond cmdGetRatePerSecond Memcached memcached.server.cmdSetRatePerSecond cmdSetRatePerSecond Memcached memcached.server.connectionRateServerPerSecond connectionRateServerPerSecond Memcached memcached.server.connectionStructuresAllocated connectionStructuresAllocated Memcached memcached.server.currentItemsStoredServer currentItemsStoredServer Memcached memcached.server.deleteCmdNoneRemovedPerSecond deleteCmdNoneRemovedPerSecond Memcached memcached.server.deleteCmdRemovedPerSecond deleteCmdRemovedPerSecond Memcached memcached.server.evictionsPerSecond evictionsPerSecond Memcached memcached.server.getHitPercent getHitPercent Memcached memcached.server.getHitPerSecond getHitPerSecond Memcached memcached.server.getMissPerSecond getMissPerSecond Memcached memcached.server.itemsStoredPerSecond itemsStoredPerSecond Memcached memcached.server.limitBytesStorage limitBytesStorage Memcached memcached.server.limitMaxBytes limitMaxBytes Memcached memcached.server.maxConnectionLimitPerSecond serverMaxConnectionLimitPerSecond Memcached memcached.server.memAllocatedSlabsInBytes memAllocatedSlabsInBytes Memcached memcached.server.openConnectionsServer openConnectionsServer Memcached memcached.server.pointerSize pointerSize Memcached memcached.server.rusageSystem usageRate Memcached memcached.server.rusageUser executionTime Memcached memcached.server.storingItemsPercentMemory storingItemsPercentMemory Memcached memcached.server.threads threads Memcached memcached.server.uptimeInMilliseconds uptimeInMilliseconds Memcached memcached.slab.activeItemsBumpedPerSecond activeItemsBumpedPerSecond Memcached memcached.slab.casBadValPerSecond casBadValPerSecond Memcached memcached.slab.casModifiedSlabPerSecond casModifiedSlabPerSecond Memcached memcached.slab.chunkSizeInBytes chunkSizeInBytes Memcached memcached.slab.chunksPerPage chunksPerPage Memcached memcached.slab.cmdSetRateSlabPerSecond cmdSetRateSlabPerSecond Memcached memcached.slab.decrsModifySlabPerSecond decrsModifySlabPerSecond Memcached memcached.slab.deleteRateSlabPerSecond deleteRateSlabPerSecond Memcached memcached.slab.entriesReclaimedPerSecond entriesReclaimedPerSecond Memcached memcached.slab.evictionsBeforeExpirationPerSecond evictionsBeforeExpirationPerSecond Memcached memcached.slab.evictionsBeforeExplicitExpirationPerSecond evictionsBeforeExplicitExpirationPerSecond Memcached memcached.slab.expiredItemsReclaimedPerSecond expiredItemsReclaimedPerSecond Memcached memcached.slab.freedChunks freedChunks Memcached memcached.slab.freedChunksEnd freedChunksEnd Memcached memcached.slab.getHitRateSlabPerSecond getHitRateSlabPerSecond Memcached memcached.slab.incrsModifySlabPerSecond incrsModifySlabPerSecond Memcached memcached.slab.itemsCold itemsCold Memcached memcached.slab.itemsColdPerSecond itemsColdPerSecond Memcached memcached.slab.itemsDirectReclaimedPerSecond itemsDirectReclaimedPerSecond Memcached memcached.slab.itemsFreedCrawlerPerSecond itemsFreedCrawlerPerSecond Memcached memcached.slab.itemsHot itemsHot Memcached memcached.slab.itemsOldestInMilliseconds itemsOldestInMilliseconds Memcached memcached.slab.itemsRefcountLockedPerSecond itemsRefcountLockedPerSecond Memcached memcached.slab.itemsSlabClass itemsSlabClass Memcached memcached.slab.itemsTimeSinceEvictionInMilliseconds itemsTimeSinceEvictionInMilliseconds Memcached memcached.slab.itemsWarm itemsWarm Memcached memcached.slab.itemsWarmPerSecond itemsWarmPerSecond Memcached memcached.slab.memRequestedSlabInBytesPerSecond memRequestedSlabInBytesPerSecond Memcached memcached.slab.outOfMemoryPerSecond outOfMemoryPerSecond Memcached memcached.slab.selfHealedSlabPerSecond selfHealedSlabPerSecond Memcached memcached.slab.totalChunksSlab totalChunksSlab Memcached memcached.slab.totalPagesSlab totalPagesSlab Memcached memcached.slab.touchHitSlabPerSecond touchHitSlabPerSecond Memcached memcached.slab.usedChunksItems usedChunksItems Memcached memcached.slab.usedChunksPerSecond usedChunksPerSecond Memcached memcached.slab.validItemsEvictedPerSecond validItemsEvictedPerSecond MongoDB mongo.index.accesses collection.indexAccesses MongoDB mongo.index.sizeInBytes collection.indexSizeInBytes MongoDB mongo.collection.avgObjSizeInBytes collection.avgObjSizeInBytes MongoDB mongo.collection.capped collection.capped MongoDB mongo.collection.count collection.count MongoDB mongo.collection.max collection.max MongoDB mongo.collection.maxSizeInBytes collection.maxSizeInBytes MongoDB mongo.collection.nindexes collection.nindexes MongoDB mongo.collection.sizeInBytes collection.sizeInBytes MongoDB mongo.collection.storageSizeInBytes collection.storageSizeInBytes MongoDB mongo.configServer.asserts.messagesPerSecond asserts.messagesPerSecond MongoDB mongo.configServer.asserts.regularPerSecond asserts.regularPerSecond MongoDB mongo.configServer.asserts.rolloversPerSecond asserts.rolloversPerSecond MongoDB mongo.configServer.asserts.userPerSecond asserts.userPerSecond MongoDB mongo.configServer.asserts.warningPerSecond asserts.warningPerSecond MongoDB mongo.configServer.commands.countFailedPerSecond commands.countFailedPerSecond MongoDB mongo.configServer.commands.countPerSecond commands.countPerSecond MongoDB mongo.configServer.commands.createIndexesFailedPerSecond commands.createIndexesFailedPerSecond MongoDB mongo.configServer.commands.createIndexesPerSecond commands.createIndexesPerSecond MongoDB mongo.configServer.commands.deleteFailedPerSecond commands.deleteFailedPerSecond MongoDB mongo.configServer.commands.deletePerSecond commands.deletePerSecond MongoDB mongo.configServer.commands.evalFailedPerSecond commands.evalFailedPerSecond MongoDB mongo.configServer.commands.evalPerSecond commands.evalPerSecond MongoDB mongo.configServer.commands.findAndModifyFailedPerSecond commands.findAndModifyFailedPerSecond MongoDB mongo.configServer.commands.findAndModifyPerSecond commands.findAndModifyPerSecond MongoDB mongo.configServer.commands.insertFailedPerSecond commands.insertFailedPerSecond MongoDB mongo.configServer.commands.insertPerSecond commands.insertPerSecond MongoDB mongo.configServer.commands.updateFailedPerSecond commands.updateFailedPerSecond MongoDB mongo.configServer.commands.updatePerSecond commands.updatePerSecond MongoDB mongo.configServer.connections.available connections.available MongoDB mongo.configServer.connections.current connections.current MongoDB mongo.configServer.connections.totalCreated connections.totalCreated MongoDB mongo.configServer.cursor.openNoTimeout cursor.openNoTimeout MongoDB mongo.configServer.cursor.openPinned cursor.openPinned MongoDB mongo.configServer.cursor.openTotal cursor.openTotal MongoDB mongo.configServer.cursor.timedOutPerSecond cursor.timedOutPerSecond MongoDB mongo.configServer.document.deletedPerSecond document.deletedPerSecond MongoDB mongo.configServer.document.insertedPerSecond document.insertedPerSecond MongoDB mongo.configServer.document.returnedPerSecond document.returnedPerSecond MongoDB mongo.configServer.document.updatedPerSecond document.updatedPerSecond MongoDB mongo.configServer.dur.commits dur.commits MongoDB mongo.configServer.dur.commitsInWriteLock dur.commitsInWriteLock MongoDB mongo.configServer.dur.compression dur.compression MongoDB mongo.configServer.dur.earlyCommits dur.earlyCommits MongoDB mongo.configServer.dur.preparingInMilliseconds dur.preparingInMilliseconds MongoDB mongo.configServer.dur.remappingInMilliseconds dur.remappingInMilliseconds MongoDB mongo.configServer.dur.timeCollectedCommitsInMilliseconds dur.timeCollectedCommitsInMilliseconds MongoDB mongo.configServer.dur.writingDataFilesInMilliseconds dur.writingDataFilesInMilliseconds MongoDB mongo.configServer.dur.writingJournalInMilliseconds dur.writingJournalInMilliseconds MongoDB mongo.configServer.flush.averageInMilliseconds flush.averageInMilliseconds MongoDB mongo.configServer.flush.flushesDisk flush.flushesDisk MongoDB mongo.configServer.flush.lastInMilliseconds flush.lastInMilliseconds MongoDB mongo.configServer.flush.totalInMilliseconds flush.totalInMilliseconds MongoDB mongo.configServer.getlasterror.wtimeMillisPerSecond getlasterror.wtimeMillisPerSecond MongoDB mongo.configServer.getlasterror.wtimeoutsPerSecond getlasterror.wtimeoutsPerSecond MongoDB mongo.configServer.globallock.activeClientsReaders globallock.activeClientsReaders MongoDB mongo.configServer.globallock.activeClientsTotal globallock.activeClientsTotal MongoDB mongo.configServer.globallock.activeClientsWriters globallock.activeClientsWriters MongoDB mongo.configServer.globallock.currentQueueReaders globallock.currentQueueReaders MongoDB mongo.configServer.globallock.currentQueueTotal globallock.currentQueueTotal MongoDB mongo.configServer.globallock.currentQueueWriters globallock.currentQueueWriters MongoDB mongo.configServer.globallock.totalTime globallock.totaltime MongoDB mongo.configServer.locks.collectionAcquireExclusive locks.collectionAcquireExclusive MongoDB mongo.configServer.locks.collectionAcquireIntentExclusive locks.collectionAcquireIntentExclusive MongoDB mongo.configServer.locks.collectionAcquireIntentShared locks.collectionAcquireIntentShared MongoDB mongo.configServer.locks.collectionAcquireWaitCountExclusive locks.collectionAcquireWaitCountExclusive MongoDB mongo.configServer.locks.collectionTimeAcquiringMicrosExclusive locks.collectionTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.databaseAcquireExclusive locks.databaseAcquireExclusive MongoDB mongo.configServer.locks.databaseAcquireIntentExclusive locks.databaseAcquireIntentExclusive MongoDB mongo.configServer.locks.databaseAcquireIntentShared locks.databaseAcquireIntentShared MongoDB mongo.configServer.locks.databaseAcquireShared locks.databaseAcquireShared MongoDB mongo.configServer.locks.databaseAcquireWaitExclusive locks.databaseAcquireWaitExclusive MongoDB mongo.configServer.locks.databaseAcquireWaitIntentExclusive locks.databaseAcquireWaitIntentExclusive MongoDB mongo.configServer.locks.databaseAcquireWaitIntentShared locks.databaseAcquireWaitIntentShared MongoDB mongo.configServer.locks.databaseAcquireWaitShared locks.databaseAcquireWaitShared MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosExclusive locks.databaseTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosIntentExclusive locks.databaseTimeAcquiringMicrosIntentExclusive MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosIntentShared locks.databaseTimeAcquiringMicrosIntentShared MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosShared locks.databaseTimeAcquiringMicrosShared MongoDB mongo.configServer.locks.globalAcquireExclusive locks.globalAcquireExclusive MongoDB mongo.configServer.locks.globalAcquireIntentExclusive locks.globalAcquireIntentExclusive MongoDB mongo.configServer.locks.globalAcquireIntentShared locks.globalAcquireIntentShared MongoDB mongo.configServer.locks.globalAcquireShared locks.globalAcquireShared MongoDB mongo.configServer.locks.globalAcquireWaitExclusive locks.globalAcquireWaitExclusive MongoDB mongo.configServer.locks.globalAcquireWaitIntentExclusive locks.globalAcquireWaitIntentExclusive MongoDB mongo.configServer.locks.globalAcquireWaitIntentShared locks.globalAcquireWaitIntentShared MongoDB mongo.configServer.locks.globalAcquireWaitShared locks.globalAcquireWaitShared MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosExclusive locks.globalTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosIntentExclusive locks.globalTimeAcquiringMicrosIntentExclusive MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosIntentShared locks.globalTimeAcquiringMicrosIntentShared MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosShared locks.globalTimeAcquiringMicrosShared MongoDB mongo.configServer.locks.metadataAcquireExclusive locks.metadataAcquireExclusive MongoDB mongo.configServer.locks.oplogAcquireExclusive locks.oplogAcquireExclusive MongoDB mongo.configServer.locks.oplogAcquireIntentExclusive locks.oplogAcquireIntentExclusive MongoDB mongo.configServer.locks.oplogAcquireIntentShared locks.oplogAcquireIntentShared MongoDB mongo",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.66895,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": "New Relic Integrations Metrics The following table contains the metrics we collect for our <em>infrastructure</em> integrations. Integration Dimensional Metric Name (new) Sample Metric Name (previous) Agent host.cpuIdlePercent cpuIdlePercent Agent host.cpuIoWaitPercent cpuIOWaitPercent Agent host.cpuPercent"
      },
      "id": "603e8a8a64441f69a34e8841"
    },
    {
      "sections": [
        "Default infrastructure monitoring data",
        "Important",
        "Infrastructure events",
        "Supported Linux storage systems",
        "Supported Windows storage systems",
        "Query infrastructure data",
        "Manage data",
        "Add custom attributes",
        "Common Amazon EC2 attributes",
        "awsRegion",
        "awsAvailabilityZone",
        "ec2InstanceType",
        "ec2InstanceId",
        "ec2AmiId",
        "ec2SubnetId",
        "ec2VpcId",
        "Other Amazon EC2 attributes"
      ],
      "title": "Default infrastructure monitoring data ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "01647189a48892103f4dc6abe07ce29d5fc13f0d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/default-infrastructure-monitoring-data/",
      "published_at": "2021-06-14T21:14:34Z",
      "updated_at": "2021-03-30T08:36:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of April 12, 2021, we are upgrading Insights to an improved web and mobile experience! All of your Insights URLs will be redirected automatically to the corresponding dashboards in New Relic One. For more details about this migration and how you can easily plan for this transition, see our Explorers Hub post. New Relic's infrastructure monitoring agent collects and displays data using six primary events, each with associated attributes that represent assorted metrics and metadata. Understanding infrastructure data can help you: Better understand our infrastructure monitoring UI. Manage your infrastructure data. Create better host filter sets. Run better queries of your data. Set up better monitoring solutions using custom attributes. Infrastructure events The following are events reported by default by the infrastructure agent and some infrastructure integrations. The attributes attached to these events are the metadata and metrics used to create our infrastructure UI visualizations. You can also create custom queries and charts of this data. If you're using integrations, see that integration's doc for more on reported data. For common AWS attributes, see AWS data. Select an event name in the following table to see its attributes. Event Description SystemSample SystemSample contains data describing the current overall state of the entire server, including CPU, memory, disk, and network. We take a snapshot of this data every 5 seconds and package it into a SystemSample event, which is then sent to New Relic. This data appears in the Hosts UI page. ProcessSample ProcessSample gathers detailed resource usage information from programs running on a single system. We take a snapshot of this data every 20 seconds for every active process and package it into a ProcessSample event, which is then sent to New Relic. This data appears on the Processes UI page. Important Process metrics are not sent to New Relic by default for accounts created after July 20, 2020. Enable process metrics to get this data into the Infrastructure monitoring UI. StorageSample StorageSample represents a single storage device associated with a server. Each sample gathers descriptive information about the device, the type of file system it uses, and its current usage and capacity. We take a snapshot of this data every 20 seconds for each mounted file system and package it into a StorageSample event, which is then sent to New Relic. This data appears on the Storage UI page. Important If your server uses disks with file systems other than the supported file systems in the following table, StorageSample events will not be generated for those disks. Supported Linux storage systems Supported Linux storage file systems: xfs vxfs btrfs ext ext2 ext3 ext4 hfs Supported Windows storage systems Supported Windows storage file systems: NTFS ReFS (version 1.0.976 and higher) NetworkSample NetworkSample captures the descriptive and state information for each network device associated with a server. It includes the device's interface and address information, as well as current usage data. We take a snapshot of this data every 10 seconds for each attached network interface and package it into a NetworkSample event, which is then sent to New Relic. This data appears on the Network UI page. ContainerSample ContainerSample collects the descriptive and state information for each Docker container. It includes the container's ID, name, image, image name, as well metrics about CPU, memory and networking. We take a snapshot of this data every 15 seconds for each container and package it into a ContainerSample event, which is then sent to New Relic. This data appears on the Containers UI page. For more information, see Docker monitoring. InfrastructureEvent InfrastructureEvent describes changes (deltas) that occur in a system's live state. When an inventory or system state is added, removed, or changed, New Relic will produce an InfrastructureEvent that logs that activity. This data appears on the Events UI page. To learn about infrastructure integration data, see the documentation for a specific integration. If an AWS integration is enabled, your infrastructure events may also have AWS attributes attached. Query infrastructure data You can query your infrastructure data to troubleshoot a problem or create a chart, or to understand what data is available. For example, to see what data is attached to ProcessSample, you would run this NRQL query: SELECT * FROM ProcessSample Copy You can also query infrastructure using dimensional metrics. Manage data For tips on managing data ingest and reporting, see Manage infrastructure data. Add custom attributes You can create custom attributes in the infrastructure agent's YAML file. Use this metadata to: Create infrastructure filter sets Populate the Group by menu Annotate your infrastructure data Common Amazon EC2 attributes If you connect your Amazon Elastic Compute Cloud (EC2) account to our infrastructure monitoring, we report data from your Amazon EC2 instances. Amazon EC2-related attributes are common attributes that can be used in any event. These attributes are drawn from the EC2 API. No CloudWatch information is collected. These attributes and their values are subject to change if Amazon changes the data they expose. awsRegion The region (determined by Amazon Web Services) where the AWS server exists. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. awsAvailabilityZone The availability zone (determined by Amazon Web Services) where the AWS server exists. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2InstanceType The Amazon Web Services instance type, displayed in AWS-specific codes. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2InstanceId The Amazon Web Services instance's unique identifying number for the server. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2AmiId The Amazon Machine Image (AMI) identification number of the image used by Amazon Web Services to bootstrap the Amazon EC2 instance. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2SubnetId The networking sub-net identifier on which the server is connected. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2VpcId The Virtual Private Cloud identifier (if any) for this server. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. Other Amazon EC2 attributes If Amazon Web Services changes the metadata they make available to New Relic, other attributes and values collected also may be available.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 110.989006,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Default <em>infrastructure</em> monitoring <em>data</em> ",
        "sections": "Default <em>infrastructure</em> monitoring <em>data</em>",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": ". <em>Manage</em> <em>your</em> <em>infrastructure</em> <em>data</em>. Create better host <em>filter</em> sets. Run better queries of <em>your</em> <em>data</em>. Set up better monitoring solutions using custom attributes. <em>Infrastructure</em> events The following are events reported by default by the <em>infrastructure</em> agent and some <em>infrastructure</em> integrations"
      },
      "id": "6043edcd28ccbcfa8a2c6086"
    }
  ],
  "/docs/infrastructure/new-relic-infrastructure/filter-group/group-infrastructure-results-specific-attributes": [
    {
      "sections": [
        "Filter sets: Organize your hosts",
        "Benefits of filter sets",
        "Create filter sets",
        "Edit filter sets",
        "Delete filter sets",
        "Combine filter sets with grouping",
        "Copy filters from filter set to alerts",
        "Important",
        "Filter set logic",
        "Inclusion and exclusion",
        "Recommended: Select values by matching a string",
        "Tip",
        "Select values individually",
        "And/Or"
      ],
      "title": "Filter sets: Organize your hosts",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Filter and group"
      ],
      "external_id": "ae70ce239865f3cb006e2ed47fc9bf3fc0598d81",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/filter-group/filter-sets-organize-your-infrastructure-hosts/",
      "published_at": "2021-06-14T21:15:46Z",
      "updated_at": "2021-03-11T08:50:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With New Relic infrastructure monitoring, you can combine filters into a filter set to organize hosts based on criteria that matter the most to you. Read on to learn about the benefits, use, and logic of filter sets. Benefits of filter sets You can create filter sets using available attributes or tags. For example, you can organize your infrastructure into categories such as: Regions Operating system versions Hosts associated with Docker containers Test environments You can share filter sets with other people in your account, and you can quickly identify infrastructure problems by checking the color-coded health status of each host in the filter set. Create filter sets The default infrastructure filter set is All hosts, and it serves as a template for you to create filter sets. To create a filter set: Go to one.newrelic.com > Infrastructure and click Hosts, Inventory, or Events. If All hosts is not displayed in the left sidebar, open that filter set by selecting Saved filter sets > All hosts. In All hosts, click Filter hosts. In the list, click an item to see a list of values. Click Include or Exclude (see Filter set logic). Click values individually or enter text to match multiple values. Continue adding filters until you have the filter set you want. To name your filter, click the icon, type a name, and click Save. Edit filter sets To change an existing filter set: Go to one.newrelic.com > Infrastructure and click Hosts, Inventory, or Events. In the sidebar, click Saved filter sets to open a list. Locate the filter set by scrolling or by entering a search term. Click the filter set to open it. In the sidebar, click an option to update your filter set, and then save. Delete filter sets You can delete any saved filter set except the default All hosts. Go to one.newrelic.com > Infrastructure > Settings > Filter sets. Click to delete the filter set. Combine filter sets with grouping On some pages you can use Group by to group chart results by specific attributes. For example, on the Hosts page, you can group by awsRegion to display the AWS regions with the highest CPU usage. Grouping applies to the selected filter sets. By combining filter sets with grouping, you can find detailed system information quickly. For an example of using these tools to troubleshoot a problem, see Combining filter sets and grouping. Copy filters from filter set to alerts When you create an alert condition, you can build filters individually, or you can copy all the filters from a filter set into a new alert condition. This is a quick shortcut to populate a new alert condition with some filters. Important When you copy filter set filters to a new alert condition, these filters are no longer tied to the filter set. If you make changes to the filter set, the alert filters are not affected. To copy filter set filters to a new alert condition: Go to one.newrelic.com > Infrastructure and click Hosts, Inventory, or Events. In the sidebar, click Saved filter sets to open a list. Locate the filter set by scrolling or by entering a search term. Click the filter set to open it. Mouse over any chart and click > Create alert. Enter an alert condition name. Make adjustments to filters as necessary. Complete the remaining alert fields (see Create alert conditions). Filter set logic When you create a filter set, you generate a list of attributes and/or tags that narrow the results. This section explains how filter sets apply various rules to the list. Inclusion and exclusion As part of building a filter set, you designate whether a filter should include or exclude entities that match certain values. The way the inclusion or exclusion works depends on how you select values: Recommended: Select values by matching a string You can generate a list of values by entering a string that you want values to match. This is useful for matching multiple values. Tip String matching efficiently generates a list of values, and this approach scales as you add new entities. Here is the logic filter sets use with string matching: Comparator Logic Include If you click Include and then enter a string that you want values to match, the filter uses the comparator LIKE, which means the results include any entities that are like the string. For example, you could filter by the term East-, and all entities that contain that term are returned. Exclude If you click Exclude and then enter a string that you want values to match, the filter uses the comparator NOT LIKE, which means the results exclude any entities that are like the string. For example, you could filter by the term West-, and all entities that do not contain that term are returned. Select values individually You can click through the list of attributes/tags to identify individual values. Tip This approach does not scale well if you add new entities. Here is the logic filter sets use with individual value selection: Comparator Logic Include If you click Include and then click specific values, the filter uses the comparator IN, which means the filter looks for entities that exactly match one or more values in your list of selections. Exclude If you click Exclude and then click specific values, the filter set uses the comparator NOT IN, which means the filter returns all entities that do not exactly match one or more values in your list of selections. And/Or Filter sets use the logical operators AND and OR behind the scenes to join the data. Here are the rules for AND and OR: When you click values from multiple attributes or tags, they are joined by AND. When you click values from within an attribute or tags, they are joined by OR. The filter results display hosts for which both of the following are true: Hosts containing any one of the selected infrastructure agent versions Hosts in any one of the selected AWS availability zones",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 207.12244,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Filter</em> sets: Organize <em>your</em> hosts",
        "sections": "<em>Filter</em> sets: Organize <em>your</em> hosts",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": " or tags. For example, you can organize <em>your</em> <em>infrastructure</em> into categories such as: Regions Operating system versions Hosts associated with Docker containers Test environments You can share <em>filter</em> sets with other people in <em>your</em> account, and you can quickly identify <em>infrastructure</em> problems by checking"
      },
      "id": "6043ed8ee7b9d289955799cb"
    },
    {
      "sections": [
        "On-host integrations metrics",
        "New Relic Integrations Metrics"
      ],
      "title": "On-host integrations metrics",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "fe96c0c4950380504b1a33c3ad861bcb17507cba",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/host-integrations-metrics/",
      "published_at": "2021-06-15T01:04:56Z",
      "updated_at": "2021-06-15T01:04:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Integrations Metrics The following table contains the metrics we collect for our infrastructure integrations. Integration Dimensional Metric Name (new) Sample Metric Name (previous) Agent host.cpuIdlePercent cpuIdlePercent Agent host.cpuIoWaitPercent cpuIOWaitPercent Agent host.cpuPercent cpuPercent Agent host.cpuStealPercent cpuStealPercent Agent host.cpuSystemPercent cpuSystemPercent Agent host.cpuUserPercent cpuUserPercent Agent host.disk.avgQueueLen avgQueueLen Agent host.disk.avgReadQueueLen avgReadQueueLen Agent host.disk.avgWriteQueueLen avgWriteQueueLen Agent host.disk.currentQueueLen currentQueueLen Agent host.disk.freeBytes diskFreeBytes Agent host.disk.freePercent diskFreePercent Agent host.disk.inodesFree inodesFree Agent host.disk.inodesTotal inodesTotal Agent host.disk.inodesUsed inodesUsed Agent host.disk.inodesUsedPercent inodesUsedPercent Agent host.disk.readBytesPerSecond readBytesPerSecond Agent host.disk.readIoPerSecond readIoPerSecond Agent host.disk.readUtilizationPercent readUtilizationPercent Agent host.disk.readWriteBytesPerSecond readWriteBytesPerSecond Agent host.disk.totalBytes diskTotalBytes Agent host.disk.totalUtilizationPercent totalUtilizationPercent Agent host.disk.usedBytes diskUsedBytes Agent host.disk.usedPercent diskUsedPercent Agent host.disk.writeBytesPerSecond writeBytesPerSecond Agent host.disk.writeIoPerSecond writeIoPerSecond Agent host.disk.writeUtilizationPercent writeUtilizationPercent Agent host.diskFreeBytes diskFreeBytes Agent host.diskFreePercent diskFreePercent Agent host.diskReadsPerSecond diskReadsPerSecond Agent host.diskReadUtilizationPercent diskReadUtilizationPercent Agent host.diskTotalBytes diskTotalBytes Agent host.diskUsedBytes diskUsedBytes Agent host.diskUsedPercent diskUsedPercent Agent host.diskUtilizationPercent diskUtilizationPercent Agent host.diskWritesPerSecond diskWritesPerSecond Agent host.diskWriteUtilizationPercent diskWriteUtilizationPercent Agent host.loadAverageFifteenMinute loadAverageFifteenMinute Agent host.loadAverageFiveMinute loadAverageFiveMinute Agent host.loadAverageOneMinute loadAverageOneMinute Agent host.memoryFreeBytes memoryFreeBytes Agent host.memoryFreePercent memoryFreePercent Agent host.memoryTotalBytes memoryTotalBytes Agent host.memoryUsedBytes memoryUsedBytes Agent host.memoryUsedPercent memoryUsedPercent Agent host.net.receiveBytesPerSecond receiveBytesPerSecond Agent host.net.receiveDroppedPerSecond receiveDroppedPerSecond Agent host.net.receiveErrorsPerSecond receiveErrorsPerSecond Agent host.net.receivePacketsPerSecond receivePacketsPerSecond Agent host.net.transmitBytesPerSecond transmitBytesPerSecond Agent host.net.transmitDroppedPerSecond transmitDroppedPerSecond Agent host.net.transmitErrorsPerSecond transmitErrorsPerSecond Agent host.net.transmitPacketsPerSecond transmitPacketsPerSecond Agent host.process.cpuPercent cpuPercent Agent host.process.cpuSystemPercent cpuSystemPercent Agent host.process.cpuUserPercent cpuUserPercent Agent host.process.fileDescriptorCount fileDescriptorCount Agent host.process.ioReadBytesPerSecond ioReadBytesPerSecond Agent host.process.ioReadCountPerSecond ioReadCountPerSecond Agent host.process.ioTotalReadBytes ioTotalReadBytes Agent host.process.ioTotalReadCount ioTotalReadCount Agent host.process.ioTotalWriteBytes ioTotalWriteBytes Agent host.process.ioTotalWriteCount ioTotalWriteCount Agent host.process.ioWriteBytesPerSecond ioWriteBytesPerSecond Agent host.process.ioWriteCountPerSecond ioWriteCountPerSecond Agent host.process.memoryResidentSizeBytes memoryResidentSizeBytes Agent host.process.memoryVirtualSizeBytes memoryVirtualSizeBytes Agent host.process.threadCount threadCount Agent host.swapFreeBytes swapFreeBytes Agent host.swapTotalBytes swapTotalBytes Agent host.swapUsedBytes swapUsedBytes Apache apache.server.busyWorkers server.busyWorkers Apache apache.server.idleWorkers server.idleWorkers Apache apache.server.net.bytesPerSecond net.bytesPerSecond Apache apache.server.net.requestsPerSecond net.requestsPerSecond Apache apache.server.scoreboard.closingWorkers server.scoreboard.closingWorkers Apache apache.server.scoreboard.dnsLookupWorkers server.scoreboard.dnsLookupWorkers Apache apache.server.scoreboard.finishingWorkers server.scoreboard.finishingWorkers Apache apache.server.scoreboard.idleCleanupWorkers server.scoreboard.idleCleanupWorkers Apache apache.server.scoreboard.keepAliveWorkers server.scoreboard.keepAliveWorkers Apache apache.server.scoreboard.loggingWorkers server.scoreboard.loggingWorkers Apache apache.server.scoreboard.readingWorkers server.scoreboard.readingWorkers Apache apache.server.scoreboard.startingWorkers server.scoreboard.startingWorkers Apache apache.server.scoreboard.totalWorkers server.scoreboard.totalWorkers Apache apache.server.scoreboard.writingWorkers server.scoreboard.writingWorkers Cassandra cassandra.node.allMemtablesOffHeapSizeBytes db.allMemtablesOffHeapSizeBytes Cassandra cassandra.node.allMemtablesOnHeapSizeBytes db.allMemtablesOnHeapSizeBytes Cassandra cassandra.node.client.connectedNativeClients client.connectedNativeClients Cassandra cassandra.node.commitLogCompletedTasksPerSecond db.commitLogCompletedTasksPerSecond Cassandra cassandra.node.commitLogPendingTasks db.commitLogPendindTasks Cassandra cassandra.node.commitLogTotalSizeBytes db.commitLogTotalSizeBytes Cassandra cassandra.node.droppedBatchRemoveMessagesPerSecond db.droppedBatchRemoveMessagesPerSecond Cassandra cassandra.node.droppedBatchStoreMessagesPerSecond db.droppedBatchStoreMessagesPerSecond Cassandra cassandra.node.droppedCounterMutationMessagesPerSecond db.droppedCounterMutationMessagesPerSecond Cassandra cassandra.node.droppedHintMessagesPerSecond db.droppedHintMessagesPerSecond Cassandra cassandra.node.droppedMutationMessagesPerSecond db.droppedMutationMessagesPerSecond Cassandra cassandra.node.droppedPagedRangeMessagesPerSecond db.droppedPagedRangeMessagesPerSecond Cassandra cassandra.node.droppedRangeSliceMessagesPerSecond db.droppedRangeSliceMessagesPerSecond Cassandra cassandra.node.droppedReadMessagesPerSecond db.droppedReadMessagesPerSecond Cassandra cassandra.node.droppedReadRepairMessagesPerSecond db.droppedReadRepairMessagesPerSecond Cassandra cassandra.node.droppedRequestResponseMessagesPerSecond db.droppedRequestResponseMessagesPerSecond Cassandra cassandra.node.droppedTraceMessagesPerSecond db.droppedTraceMessagesPerSecond Cassandra cassandra.node.keyCacheCapacityBytes db.keyCacheCapacityBytes Cassandra cassandra.node.keyCacheHitRate db.keyCacheHitRate Cassandra cassandra.node.keyCacheHitsPerSecond db.keyCacheHitsPerSecond Cassandra cassandra.node.keyCacheRequestsPerSecond db.keyCacheRequestsPerSecond Cassandra cassandra.node.keyCacheSizeBytes db.keyCacheSizeBytes Cassandra cassandra.node.liveSsTableCount db.liveSSTableCount Cassandra cassandra.node.loadBytes db.loadBytes Cassandra cassandra.node.query.casReadRequestsPerSecond query.CASReadRequestsPerSecond Cassandra cassandra.node.query.casWriteRequestsPerSecond query.CASWriteRequestsPerSecond Cassandra cassandra.node.query.rangeSliceRequestsPerSecond query.rangeSliceRequestsPerSecond Cassandra cassandra.node.query.rangeSliceTimeoutsPerSecond query.rangeSliceTimeoutsPerSecond Cassandra cassandra.node.query.rangeSliceUnavailablesPerSecond query.rangeSliceUnavailablesPerSecond Cassandra cassandra.node.query.readLatency50ThPercentileMilliseconds query.readLatency50thPercentileMilliseconds Cassandra cassandra.node.query.readLatency75ThPercentileMilliseconds query.readLatency75thPercentileMilliseconds Cassandra cassandra.node.query.readLatency95ThPercentileMilliseconds query.readLatency95thPercentileMilliseconds Cassandra cassandra.node.query.readLatency98ThPercentileMilliseconds query.readLatency98thPercentileMilliseconds Cassandra cassandra.node.query.readLatency999ThPercentileMilliseconds query.readLatency999thPercentileMilliseconds Cassandra cassandra.node.query.readLatency99ThPercentileMilliseconds query.readLatency99thPercentileMilliseconds Cassandra cassandra.node.query.readRequestsPerSecond query.readRequestsPerSecond Cassandra cassandra.node.query.readTimeoutsPerSecond query.readTimeoutsPerSecond Cassandra cassandra.node.query.readUnavailablesPerSecond query.readUnavailablesPerSecond Cassandra cassandra.node.query.viewWriteRequestsPerSecond query.viewWriteRequestsPerSecond Cassandra cassandra.node.query.writeLatency50ThPercentileMilliseconds query.writeLatency50thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency75ThPercentileMilliseconds query.writeLatency75thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency95ThPercentileMilliseconds query.writeLatency95thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency98ThPercentileMilliseconds query.writeLatency98thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency999ThPercentileMilliseconds query.writeLatency999thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency99ThPercentileMilliseconds query.writeLatency99thPercentileMilliseconds Cassandra cassandra.node.query.writeRequestsPerSecond query.writeRequestsPerSecond Cassandra cassandra.node.query.writeTimeoutsPerSecond query.writeTimeoutsPerSecond Cassandra cassandra.node.query.writeUnavailablesPerSecond query.writeUnavailablesPerSecond Cassandra cassandra.node.rowCacheCapacityBytes db.rowCacheCapacityBytes Cassandra cassandra.node.rowCacheHitRate db.rowCacheHitRate Cassandra cassandra.node.rowCacheHitsPerSecond db.rowCacheHitsPerSecond Cassandra cassandra.node.rowCacheRequestsPerSecond db.rowCacheRequestsPerSecond Cassandra cassandra.node.rowCacheSizeBytes db.rowCacheSizeBytes Cassandra cassandra.node.storage.exceptionCount storage.exceptionCount Cassandra cassandra.node.threadPool.antiEntropyStage.activeTasks db.threadpool.internalAntiEntropyStageActiveTasks Cassandra cassandra.node.threadPool.antiEntropyStage.completedTasks db.threadpool.internalAntiEntropyStageCompletedTasks Cassandra cassandra.node.threadPool.antiEntropyStage.currentlyBlockedTasks db.threadpool.internalAntiEntropyStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.antiEntropyStage.pendingTasks db.threadpool.internalAntiEntropyStagePendingTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.activeTasks db.threadpool.internalCacheCleanupExecutorActiveTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.completedTasks db.threadpool.internalCacheCleanupExecutorCompletedTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.currentlyBlockedTasks db.threadpool.internalCacheCleanupExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.pendingTasks db.threadpool.internalCacheCleanupExecutorPendingTasks Cassandra cassandra.node.threadPool.compactionExecutor.activeTasks db.threadpool.internalCompactionExecutorActiveTasks Cassandra cassandra.node.threadPool.compactionExecutor.completedTasks db.threadpool.internalCompactionExecutorCompletedTasks Cassandra cassandra.node.threadPool.compactionExecutor.currentlyBlockedTasks db.threadpool.internalCompactionExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.compactionExecutor.pendingTasks db.threadpool.internalCompactionExecutorPendingTasks Cassandra cassandra.node.threadPool.counterMutationStage.activeTasks db.threadpool.requestCounterMutationStageActiveTasks Cassandra cassandra.node.threadPool.counterMutationStage.completedTasks db.threadpool.requestCounterMutationStageCompletedTasks Cassandra cassandra.node.threadPool.counterMutationStage.currentlyBlockedTasks db.threadpool.requestCounterMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.counterMutationStage.pendingTasks db.threadpool.requestCounterMutationStagePendingTasks Cassandra cassandra.node.threadPool.gossipStage.activeTasks db.threadpool.internalGossipStageActiveTasks Cassandra cassandra.node.threadPool.gossipStage.completedTasks db.threadpool.internalGossipStageCompletedTasks Cassandra cassandra.node.threadPool.gossipStage.currentlyBlockedTasks db.threadpool.internalGossipStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.gossipStage.pendingTasks db.threadpool.internalGossipStagePendingTasks Cassandra cassandra.node.threadPool.hintsDispatcher.activeTasks db.threadpool.internalHintsDispatcherActiveTasks Cassandra cassandra.node.threadPool.hintsDispatcher.completedTasks db.threadpool.internalHintsDispatcherCompletedTasks Cassandra cassandra.node.threadPool.hintsDispatcher.currentlyBlockedTasks db.threadpool.internalHintsDispatcherCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.hintsDispatcher.pendingTasks db.threadpool.internalHintsDispatcherPendingTasks Cassandra cassandra.node.threadPool.internalResponseStage.activeTasks db.threadpool.internalInternalResponseStageActiveTasks Cassandra cassandra.node.threadPool.internalResponseStage.completedTasks db.threadpool.internalInternalResponseStageCompletedTasks Cassandra cassandra.node.threadPool.internalResponseStage.pCurrentlyBlockedTasks db.threadpool.internalInternalResponseStagePCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.internalResponseStage.pendingTasks db.threadpool.internalInternalResponseStagePendingTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.activeTasks db.threadpool.internalMemtableFlushWriterActiveTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.completedTasks db.threadpool.internalMemtableFlushWriterCompletedTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.currentlyBlockedTasks db.threadpool.internalMemtableFlushWriterCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.pendingTasks db.threadpool.internalMemtableFlushWriterPendingTasks Cassandra cassandra.node.threadPool.memtablePostFlush.activeTasks db.threadpool.internalMemtablePostFlushActiveTasks Cassandra cassandra.node.threadPool.memtablePostFlush.completedTasks db.threadpool.internalMemtablePostFlushCompletedTasks Cassandra cassandra.node.threadPool.memtablePostFlush.currentlyBlockedTasks db.threadpool.internalMemtablePostFlushCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtablePostFlush.pendingTasks db.threadpool.internalMemtablePostFlushPendingTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.activeTasks db.threadpool.internalMemtableReclaimMemoryActiveTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.completedTasks db.threadpool.internalMemtableReclaimMemoryCompletedTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.currentlyBlockedTasks db.threadpool.internalMemtableReclaimMemoryCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.pendingTasks db.threadpool.internalMemtableReclaimMemoryPendingTasks Cassandra cassandra.node.threadPool.migrationStage.activeTasks db.threadpool.internalMigrationStageActiveTasks Cassandra cassandra.node.threadPool.migrationStage.completedTasks db.threadpool.internalMigrationStageCompletedTasks Cassandra cassandra.node.threadPool.migrationStage.currentlyBlockedTasks db.threadpool.internalMigrationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.migrationStage.pendingTasks db.threadpool.internalMigrationStagePendingTasks Cassandra cassandra.node.threadPool.miscStage.activeTasks db.threadpool.internalMiscStageActiveTasks Cassandra cassandra.node.threadPool.miscStage.completedTasks db.threadpool.internalMiscStageCompletedTasks Cassandra cassandra.node.threadPool.miscStage.currentlyBlockedTasks db.threadpool.internalMiscStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.miscStage.pendingTasks db.threadpool.internalMiscStagePendingTasks Cassandra cassandra.node.threadPool.mutationStage.activeTasks db.threadpool.requestMutationStageActiveTasks Cassandra cassandra.node.threadPool.mutationStage.completedTasks db.threadpool.requestMutationStageCompletedTasks Cassandra cassandra.node.threadPool.mutationStage.currentlyBlockedTasks db.threadpool.requestMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.mutationStage.pendingTasks db.threadpool.requestMutationStagePendingTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.activeTasks db.threadpool.internalPendingRangeCalculatorActiveTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.completedTasks db.threadpool.internalPendingRangeCalculatorCompletedTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.currentlyBlockedTasks db.threadpool.internalPendingRangeCalculatorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.pendingTasks db.threadpool.internalPendingRangeCalculatorPendingTasks Cassandra cassandra.node.threadPool.readRepairStage.activeTasks db.threadpool.requestReadRepairStageActiveTasks Cassandra cassandra.node.threadPool.readRepairStage.completedTasks db.threadpool.requestReadRepairStageCompletedTasks Cassandra cassandra.node.threadPool.readRepairStage.currentlyBlockedTasks db.threadpool.requestReadRepairStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.readRepairStage.pendingTasks db.threadpool.requestReadRepairStagePendingTasks Cassandra cassandra.node.threadPool.readStage.activeTasks db.threadpool.requestReadStageActiveTasks Cassandra cassandra.node.threadPool.readStage.completedTasks db.threadpool.requestReadStageCompletedTasks Cassandra cassandra.node.threadPool.readStage.currentlyBlockedTasks db.threadpool.requestReadStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.readStage.pendingTasks db.threadpool.requestReadStagePendingTasks Cassandra cassandra.node.threadPool.requestResponseStage.activeTasks db.threadpool.requestRequestResponseStageActiveTasks Cassandra cassandra.node.threadPool.requestResponseStage.completedTasks db.threadpool.requestRequestResponseStageCompletedTasks Cassandra cassandra.node.threadPool.requestResponseStage.currentlyBlockedTasks db.threadpool.requestRequestResponseStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.requestResponseStage.pendingTasks db.threadpool.requestRequestResponseStagePendingTasks Cassandra cassandra.node.threadPool.sampler.activeTasks db.threadpool.internalSamplerActiveTasks Cassandra cassandra.node.threadPool.sampler.completedTasks db.threadpool.internalSamplerCompletedTasks Cassandra cassandra.node.threadPool.sampler.currentlyBlockedTasks db.threadpool.internalSamplerCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.sampler.pendingTasks db.threadpool.internalSamplerPendingTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.activeTasks db.threadpool.internalSecondaryIndexManagementActiveTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.completedTasks db.threadpool.internalSecondaryIndexManagementCompletedTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.currentlyBlockedTasks db.threadpool.internalSecondaryIndexManagementCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.pendingTasks db.threadpool.internalSecondaryIndexManagementPendingTasks Cassandra cassandra.node.threadPool.validationExecutor.activeTasks db.threadpool.internalValidationExecutorActiveTasks Cassandra cassandra.node.threadPool.validationExecutor.completedTasks db.threadpool.internalValidationExecutorCompletedTasks Cassandra cassandra.node.threadPool.validationExecutor.currentlyBlockedTasks db.threadpool.internalValidationExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.validationExecutor.pendingTasks db.threadpool.internalValidationExecutorPendingTasks Cassandra cassandra.node.threadPool.viewMutationStage.activeTasks db.threadpool.requestViewMutationStageActiveTasks Cassandra cassandra.node.threadPool.viewMutationStage.completedTasks db.threadpool.requestViewMutationStageCompletedTasks Cassandra cassandra.node.threadPool.viewMutationStage.currentlyBlockedTasks db.threadpool.requestViewMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.viewMutationStage.pendingTasks db.threadpool.requestViewMutationStagePendingTasks Cassandra cassandra.node.totalHintsInProgress db.totalHintsInProgress Cassandra cassandra.node.totalHintsPerSecond db.totalHintsPerSecond Cassandra cassandra.columnFamily.allMemtablesOffHeapSizeBytes db.allMemtablesOffHeapSizeBytes Cassandra cassandra.columnFamily.allMemtablesOnHeapSizeBytes db.allMemtablesOnHeapSizeBytes Cassandra cassandra.columnFamily.bloomFilterFalseRatio db.bloomFilterFalseRatio Cassandra cassandra.columnFamily.liveDiskSpaceUsedBytes db.liveDiskSpaceUsedBytes Cassandra cassandra.columnFamily.liveSsTableCount db.liveSSTableCount Cassandra cassandra.columnFamily.maxRowSize db.maxRowSize Cassandra cassandra.columnFamily.meanRowSize db.meanRowSize Cassandra cassandra.columnFamily.memtableLiveDataSize db.memtableLiveDataSize Cassandra cassandra.columnFamily.minRowSize db.minRowSize Cassandra cassandra.columnFamily.pendingCompactions db.pendingCompactions Cassandra cassandra.columnFamily.query.readLatency50ThPercentileMilliseconds query.readLatency50thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency75ThPercentileMilliseconds query.readLatency75thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency95ThPercentileMilliseconds query.readLatency95thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency98ThPercentileMilliseconds query.readLatency98thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency999ThPercentileMilliseconds query.readLatency999thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency99ThPercentileMilliseconds query.readLatency99thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readRequestsPerSecond query.readRequestsPerSecond Cassandra cassandra.columnFamily.query.writeLatency50ThPercentileMilliseconds query.writeLatency50thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency75ThPercentileMilliseconds query.writeLatency75thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency95ThPercentileMilliseconds query.writeLatency95thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency98ThPercentileMilliseconds query.writeLatency98thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency999ThPercentileMilliseconds query.writeLatency999thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency99ThPercentileMilliseconds query.writeLatency99thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeRequestsPerSecond query.writeRequestsPerSecond Cassandra cassandra.columnFamily.speculativeRetries db.speculativeRetries Cassandra cassandra.columnFamily.ssTablesPerRead50ThPercentileMilliseconds db.SSTablesPerRead50thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead75ThPercentileMilliseconds db.SSTablesPerRead75thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead95ThPercentileMilliseconds db.SSTablesPerRead95thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead98ThPercentileMilliseconds db.SSTablesPerRead98thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead999ThPercentileMilliseconds db.SSTablesPerRead999thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead99ThPercentileMilliseconds db.SSTablesPerRead99thPercentileMilliseconds Cassandra cassandra.columnFamily.tombstoneScannedHistogram50ThPercentile db.tombstoneScannedHistogram50thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram75ThPercentile db.tombstoneScannedHistogram75thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram95ThPercentile db.tombstoneScannedHistogram95thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram98ThPercentile db.tombstoneScannedHistogram98thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram999ThPercentile db.tombstoneScannedHistogram999thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram99ThPercentile db.tombstoneScannedHistogram99thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogramCount db.tombstoneScannedHistogramCount Consul consul.datacenter.catalog.criticalNodes catalog.criticalNodes Consul consul.datacenter.catalog.passingNodes catalog.passingNodes Consul consul.datacenter.catalog.registeredNodes catalog.registeredNodes Consul consul.datacenter.catalog.upNodes catalog.upNodes Consul consul.datacenter.catalog.warningNodes catalog.warningNodes Consul consul.datacenter.cluster.flaps cluster.flaps Consul consul.datacenter.cluster.suspects cluster.suspects Consul consul.datacenter.raft.commitTime raft.commitTimes Consul consul.datacenter.raft.commitTimeAvgInMilliseconds raft.commitTimeAvgInMilliseconds Consul consul.datacenter.raft.commitTimeMaxInMilliseconds raft.commitTimeMaxInMilliseconds Consul consul.datacenter.raft.completedLeaderElections raft.completedLeaderElections Consul consul.datacenter.raft.initiatedLeaderElections raft.initiatedLeaderElections Consul consul.datacenter.raft.lastContactAvgInMilliseconds raft.lastContactAvgInMilliseconds Consul consul.datacenter.raft.lastContactMaxInMilliseconds raft.lastContactMaxInMilliseconds Consul consul.datacenter.raft.lastContacts raft.lastContacts Consul consul.datacenter.raft.logDispatchAvgInMilliseconds raft.logDispatchAvgInMilliseconds Consul consul.datacenter.raft.logDispatches raft.logDispatches Consul consul.datacenter.raft.logDispatchMaxInMilliseconds raft.logDispatchMaxInMilliseconds Consul consul.datacenter.raft.txns raft.txns Consul consul.agent.aclCacheHitPerSecond agent.aclCacheHit Consul consul.agent.aclCacheMissPerSecond agent.aclCacheMiss Consul consul.agent.client.rpcFailed client.rpcFailed Consul consul.agent.client.rpcLoad client.rpcLoad Consul consul.agent.kvStores agent.kvStoress Consul consul.agent.kvStoresAvgInMilliseconds agent.kvStoresAvgInMilliseconds Consul consul.agent.kvStoresMaxInMilliseconds agent.kvStoresMaxInMilliseconds Consul consul.agent.net.agent.maxLatencyInMilliseconds net.agent.maxLatencyInMilliseconds Consul consul.agent.net.medianLatencyInMilliseconds net.agent.medianLatencyInMilliseconds Consul consul.agent.net.minLatencyInMilliseconds net.agent.minLatencyInMilliseconds Consul consul.agent.net.p25LatencyInMilliseconds net.agent.p25LatencyInMilliseconds Consul consul.agent.net.p75LatencyInMilliseconds net.agent.p75LatencyInMilliseconds Consul consul.agent.net.p90LatencyInMilliseconds net.agent.p90LatencyInMilliseconds Consul consul.agent.net.p95LatencyInMilliseconds net.agent.p95LatencyInMilliseconds Consul consul.agent.net.p99LatencyInMilliseconds net.agent.p99LatencyInMilliseconds Consul consul.agent.peers agent.peers Consul consul.agent.runtime.allocations runtime.allocations Consul consul.agent.runtime.allocationsInBytes runtime.allocationsInBytes Consul consul.agent.runtime.frees runtime.frees Consul consul.agent.runtime.gcCycles runtime.gcCycles Consul consul.agent.runtime.gcPauseInMilliseconds runtime.gcPauseInMilliseconds Consul consul.agent.runtime.goroutines runtime.goroutines Consul consul.agent.runtime.heapObjects runtime.heapObjects Consul consul.agent.runtime.virtualAddressSpaceInBytes runtime.virtualAddressSpaceInBytes Consul consul.agent.staleQueries agent.staleQueries Consul consul.agent.txnAvgInMilliseconds agent.txnAvgInMilliseconds Consul consul.agent.txnMaxInMilliseconds agent.txnMaxInMilliseconds Consul consul.agent.txns agent.txns Couchbase couchbase.bucket.activeItemsEnteringDiskQueuePerSecond bucket.activeItemsEnteringDiskQueuePerSecond Couchbase couchbase.bucket.activeItemsInMemory bucket.activeItemsInMemory Couchbase couchbase.bucket.activeResidentItemsRatio bucket.activeResidentItemsRatio Couchbase couchbase.bucket.averageDiskCommitTimeInMilliseconds bucket.averageDiskCommitTimeInMilliseconds Couchbase couchbase.bucket.averageDiskUpdateTimeInMilliseconds bucket.averageDiskUpdateTimeInMilliseconds Couchbase couchbase.bucket.cacheMisses bucket.cacheMisses Couchbase couchbase.bucket.cacheMissRatio bucket.cacheMissRatio Couchbase couchbase.bucket.casHits bucket.casHits Couchbase couchbase.bucket.casMisses bucket.casMisses Couchbase couchbase.bucket.couchDocsFragmentationPercent bucket.couchDocsFragmentationPercent Couchbase couchbase.bucket.currentConnections bucket.currentConnections Couchbase couchbase.bucket.dataUsedInBytes bucket.dataUsedInBytes Couchbase couchbase.bucket.decrementHitsPerSecond bucket.decrementHitsPerSecond Couchbase couchbase.bucket.decrementMissesPerSecond bucket.decrementMissesPerSecond Couchbase couchbase.bucket.deleteHitsPerSecond bucket.deleteHitsPerSecond Couchbase couchbase.bucket.deleteMissesPerSecond bucket.deleteMissesPerSecond Couchbase couchbase.bucket.diskCreateOperationsPerSecond bucket.diskCreateOperationsPerSecond Couchbase couchbase.bucket.diskFetchesPerSecond bucket.diskFetchesPerSecond Couchbase couchbase.bucket.diskReadsPerSecond bucket.diskReadsPerSecond Couchbase couchbase.bucket.diskUpdateOperationsPerSecond bucket.diskUpdateOperationsPerSecond Couchbase couchbase.bucket.diskUsedInBytes bucket.diskUsedInBytes Couchbase couchbase.bucket.diskWriteQueue bucket.diskWriteQueue Couchbase couchbase.bucket.drainedItemsInQueue bucket.drainedItemsInQueue Couchbase couchbase.bucket.drainedItemsOnDiskQueue bucket.drainedItemsOnDiskQueue Couchbase couchbase.bucket.drainedPendingItemsInQueue bucket.drainedPendingItemsInQueue Couchbase couchbase.bucket.ejectionsPerSecond bucket.ejectionsPerSecond Couchbase couchbase.bucket.evictionsPerSecond bucket.evictionsPerSecond Couchbase couchbase.bucket.getHitsPerSecond bucket.getHitsPerSecond Couchbase couchbase.bucket.getMissesPerSecond bucket.getMissesPerSecond Couchbase couchbase.bucket.hitRatio bucket.hitRatio Couchbase couchbase.bucket.incrementHitsPerSecond bucket.incrementHitsPerSecond Couchbase couchbase.bucket.incrementMissesPerSecond bucket.incrementMissesPerSecond Couchbase couchbase.bucket.itemCount bucket.itemCount Couchbase couchbase.bucket.itemsBeingWritten bucket.itemsBeingWritten Couchbase couchbase.bucket.itemsEjectedFromMemoryToDisk bucket.itemsEjectedFromMemoryToDisk Couchbase couchbase.bucket.itemsOnDiskQueue bucket.itemsOnDiskQueue Couchbase couchbase.bucket.itemsQueuedForStorage bucket.itemsQueuedForStorage Couchbase couchbase.bucket.maximumMemoryUsage bucket.maximumMemoryUsage Couchbase couchbase.bucket.memoryHighWaterMarkInBytes bucket.memoryHighWaterMarkInBytes Couchbase couchbase.bucket.memoryLowWaterMarkInBytes bucket.memoryLowWaterMarkInBytes Couchbase couchbase.bucket.memoryUsedInBytes bucket.memoryUsedInBytes Couchbase couchbase.bucket.metadataInRamInBytes bucket.metadataInRAMInBytes Couchbase couchbase.bucket.missesPerSecond bucket.missesPerSecond Couchbase couchbase.bucket.outOfMemoryErrorsPerSecond bucket.outOfMemoryErrorsPerSecond Couchbase couchbase.bucket.overheadInBytes bucket.overheadInBytes Couchbase couchbase.bucket.pendingItemsInDiskQueue bucket.pendingItemsInDiskQueue Couchbase couchbase.bucket.pendingResidentItemsRatio bucket.pendingResidentItemsRatio Couchbase couchbase.bucket.quotaUtilization bucket.quotaUtilization Couchbase couchbase.bucket.readOperationsPerSecond bucket.readOperationsPerSecond Couchbase couchbase.bucket.readRatePerSecond bucket.readRatePerSecond Couchbase couchbase.bucket.recoverableOutOfMemoryCount bucket.recoverableOutOfMemoryCount Couchbase couchbase.bucket.replicaIndex bucket.replicaIndex Couchbase couchbase.bucket.replicaNumber bucket.replicaNumber Couchbase couchbase.bucket.replicaResidentItemsRatio bucket.replicaResidentItemsRatio Couchbase couchbase.bucket.residentItemsRatio bucket.residentItemsRatio Couchbase couchbase.bucket.temporaryOutOfMemoryErrorsPerSecond bucket.temporaryOutOfMemoryErrorsPerSecond Couchbase couchbase.bucket.threadsNumber bucket.threadsNumber Couchbase couchbase.bucket.totalItems bucket.totalItems Couchbase couchbase.bucket.totalOperationsPerSecond bucket.totalOperationsPerSecond Couchbase couchbase.bucket.viewFragmentationPercent bucket.viewFragmentationPercent Couchbase couchbase.bucket.writeOperationsPerSecond bucket.writeOperationsPerSecond Couchbase couchbase.bucket.writeRatePerSecond bucket.writeRatePerSecond Couchbase couchbase.cluster.autoFailoverCount cluster.autoFailoverCount Couchbase couchbase.cluster.autoFailoverEnabled cluster.autoFailoverEnabled Couchbase couchbase.cluster.databaseFragmentationThreshold cluster.databaseFragmentationThreshold Couchbase couchbase.cluster.diskFreeInBytes cluster.diskFreeInBytes Couchbase couchbase.cluster.diskQuotaTotalInBytes cluster.diskQuotaTotalInBytes Couchbase couchbase.cluster.diskTotalInBytes cluster.diskTotalInBytes Couchbase couchbase.cluster.diskUsedByDataInBytes cluster.diskUsedByDataInBytes Couchbase couchbase.cluster.diskUsedInBytes cluster.diskUsedInBytes Couchbase couchbase.cluster.indexFragmentationThreshold cluster.indexFragmentationThreshold Couchbase couchbase.cluster.maximumBucketCount cluster.maximumBucketCount Couchbase couchbase.cluster.memoryQuotaTotalInBytes cluster.memoryQuotaTotalInBytes Couchbase couchbase.cluster.memoryQuotaTotalPerNodeInBytes cluster.memoryQuotaTotalPerNodeInBytes Couchbase couchbase.cluster.memoryQuotaUsedInBytes cluster.memoryQuotaUsedInBytes Couchbase couchbase.cluster.memoryQuotaUsedPerNodeInBytes cluster.memoryQuotaUsedPerNodeInBytes Couchbase couchbase.cluster.memoryTotalInBytes cluster.memoryTotalInBytes Couchbase couchbase.cluster.memoryUsedByDataInBytes cluster.memoryUsedByDataInBytes Couchbase couchbase.cluster.memoryUsedInBytes cluster.memoryUsedInBytes Couchbase couchbase.cluster.viewFragmentationThreshold cluster.viewFragmentationThreshold Couchbase couchbase.node.backgroundFetches node.backgroundFetches Couchbase couchbase.node.cmdGet node.cmdGet Couchbase couchbase.node.couchDocsActualDiskSizeInBytes node.couchDocsActualDiskSizeInBytes Couchbase couchbase.node.couchDocsDataSizeInBytes node.couchDocsDataSizeInBytes Couchbase couchbase.node.couchSpatialDataSizeInBytes node.couchSpatialDataSizeInBytes Couchbase couchbase.node.couchSpatialDiskSizeInBytes node.couchSpatialDiskSizeInBytes Couchbase couchbase.node.couchViewsActualDiskSizeInBytes node.couchViewsActualDiskSizeInBytes Couchbase couchbase.node.couchViewsDataSizeInBytes node.couchViewsDataSizeInBytes Couchbase couchbase.node.cpuUtilization node.cpuUtilization Couchbase couchbase.node.currentItems node.currentItems Couchbase couchbase.node.currentItemsTotal node.currentItemsTotal Couchbase couchbase.node.getHits node.getHits Couchbase couchbase.node.memoryFreeInBytes node.memoryFreeInBytes Couchbase couchbase.node.memoryTotalInBytes node.memoryTotalInBytes Couchbase couchbase.node.memoryUsedInBytes node.memoryUsedInBytes Couchbase couchbase.node.ops node.ops Couchbase couchbase.node.swapTotalInBytes node.swapTotalInBytes Couchbase couchbase.node.swapUsedInBytes node.swapUsedInBytes Couchbase couchbase.node.uptimeInMilliseconds node.uptimeInMilliseconds Couchbase couchbase.node.vbucketActiveNonResidentItems node.vbucketActiveNonResidentItems Couchbase couchbase.node.vbucketInMemoryItems node.vbucketInMemoryItems Couchbase couchbase.queryengine.activeRequests queryengine.activeRequests Couchbase couchbase.queryengine.averageRequestTimeInMilliseconds queryengine.averageRequestTimeInMilliseconds Couchbase couchbase.queryengine.completedLimit queryengine.completedLimit Couchbase couchbase.queryengine.completedRequests queryengine.completedRequests Couchbase couchbase.queryengine.completedThresholdInMilliseconds queryengine.completedThresholdInMilliseconds Couchbase couchbase.queryengine.cores queryengine.cores Couchbase couchbase.queryengine.garbageCollectionNumber queryengine.garbageCollectionNumber Couchbase couchbase.queryengine.garbageCollectionPaused queryengine.garbageCollectionPaused Couchbase couchbase.queryengine.garbageCollectionTimePausedInMilliseconds queryengine.garbageCollectionTimePausedInMilliseconds Couchbase couchbase.queryengine.medianRequestTimeInMilliseconds queryengine.medianRequestTimeInMilliseconds Couchbase couchbase.queryengine.preparedStatementUtilization queryengine.preparedStatementUtilization Couchbase couchbase.queryengine.requestsLast15MinutesPerSecond queryengine.requestsLast15MinutesPerSecond Couchbase couchbase.queryengine.requestsLast1MinutesPerSecond queryengine.requestsLast1MinutesPerSecond Couchbase couchbase.queryengine.requestsLast5MinutesPerSecond queryengine.requestsLast5MinutesPerSecond Couchbase couchbase.queryengine.requestTime80thPercentileInMilliseconds queryengine.requestTime80thPercentileInMilliseconds Couchbase couchbase.queryengine.requestTime95thPercentileInMilliseconds queryengine.requestTime95thPercentileInMilliseconds Couchbase couchbase.queryengine.requestTime99thPercentileInMilliseconds queryengine.requestTime99thPercentileInMilliseconds Couchbase couchbase.queryengine.systemCpuUtilization queryengine.systemCPUUtilization Couchbase couchbase.queryengine.systemMemoryInBytes queryengine.systemMemoryInBytes Couchbase couchbase.queryengine.totalMemoryInBytes queryengine.totalMemoryInBytes Couchbase couchbase.queryengine.totalThreads queryengine.totalThreads Couchbase couchbase.queryengine.uptimeInMilliseconds queryengine.uptimeInMilliseconds Couchbase couchbase.queryengine.usedMemoryInBytes queryengine.usedMemoryInBytes Couchbase couchbase.queryengine.userCpuUtilization queryengine.userCPUUtilization Docker docker.container.cpuKernelPercent cpuKernelPercent Docker docker.container.cpuLimitCores cpuLimitCores Docker docker.container.cpuPercent cpuPercent Docker docker.container.cpuThrottlePeriods cpuThrottlePeriods Docker docker.container.cpuThrottleTimeMs cpuThrottleTimeMs Docker docker.container.cpuUsedCores cpuUsedCores Docker docker.container.cpuUsedCoresPercent cpuUsedCoresPercent Docker docker.container.cpuUserPercent cpuUserPercent Docker docker.container.ioReadBytesPerSecond ioReadBytesPerSecond Docker docker.container.ioReadCountPerSecond ioReadCountPerSecond Docker docker.container.ioTotalBytes ioTotalBytes Docker docker.container.ioTotalReadBytes ioTotalReadBytes Docker docker.container.ioTotalReadCount ioTotalReadCount Docker docker.container.ioTotalWriteBytes ioTotalWriteBytes Docker docker.container.ioTotalWriteCount ioTotalWriteCount Docker docker.container.ioWriteBytesPerSecond ioWriteBytesPerSecond Docker docker.container.ioWriteCountPerSecond ioWriteCountPerSecond Docker docker.container.memoryCacheBytes memoryCacheBytes Docker docker.container.memoryResidentSizeBytes memoryResidentSizeBytes Docker docker.container.memorySizeLimitBytes memorySizeLimitBytes Docker docker.container.memoryUsageBytes memoryUsageBytes Docker docker.container.memoryUsageLimitPercent memoryUsageLimitPercent Docker docker.container.networkRxBytes networkRxBytes Docker docker.container.networkRxBytesPerSecond networkRxBytesPerSecond Docker docker.container.networkRxDropped networkRxDropped Docker docker.container.networkRxDroppedPerSecond networkRxDroppedPerSecond Docker docker.container.networkRxErrors networkRxErrors Docker docker.container.networkRxErrorsPerSecond networkRxErrorsPerSecond Docker docker.container.networkRxPackets networkRxPackets Docker docker.container.networkRxPacketsPerSecond networkRxPacketsPerSecond Docker docker.container.networkTxBytes networkTxBytes Docker docker.container.networkTxBytesPerSecond networkTxBytesPerSecond Docker docker.container.networkTxDropped networkTxDropped Docker docker.container.networkTxDroppedPerSecond networkTxDroppedPerSecond Docker docker.container.networkTxErrors networkTxErrors Docker docker.container.networkTxErrorsPerSecond networkTxErrorsPerSecond Docker docker.container.networkTxPackets networkTxPackets Docker docker.container.networkTxPacketsPerSecond networkTxPacketsPerSecond Docker docker.container.pids pids Docker docker.container.processCount processCount Docker docker.container.processCountLimit processCountLimit Docker docker.container.restartCount restartCount Docker docker.container.threadCount threadCount Docker docker.container.threadCountLimit threadCountLimit ElasticSearch elasticsearch.cluster.dataNodes cluster.dataNodes ElasticSearch elasticsearch.cluster.nodes cluster.nodes ElasticSearch elasticsearch.cluster.shards.active shards.active ElasticSearch elasticsearch.cluster.shards.initializing shards.initializing ElasticSearch elasticsearch.cluster.shards.primaryActive shards.primaryActive ElasticSearch elasticsearch.cluster.shards.relocating shards.relocating ElasticSearch elasticsearch.cluster.shards.unassigned shards.unassigned ElasticSearch elasticsearch.cluster.tempData temp-data ElasticSearch elasticsearch.index.docs index.docs ElasticSearch elasticsearch.index.docsDeleted index.docsDeleted ElasticSearch elasticsearch.index.primaryShards index.primaryShards ElasticSearch elasticsearch.index.primaryStoreSizeInBytes index.primaryStoreSizeInBytes ElasticSearch elasticsearch.index.replicaShards index.replicaShards ElasticSearch elasticsearch.index.rollup.docsCount primaries.docsnumber ElasticSearch elasticsearch.index.rollup.docsDeleted primaries.docsDeleted ElasticSearch elasticsearch.index.rollup.flushTotal primaries.flushesTotal ElasticSearch elasticsearch.index.rollup.flushTotalTimeInMilliseconds primaries.flushTotalTimeInMilliseconds ElasticSearch elasticsearch.index.rollup.get.documentsExist primaries.get.documentsExist ElasticSearch elasticsearch.index.rollup.get.documentsExistInMilliseconds primaries.get.documentsExistInMilliseconds ElasticSearch elasticsearch.index.rollup.get.documentsMissing primaries.get.documentsMissing ElasticSearch elasticsearch.index.rollup.get.documentsMissingInMilliseconds primaries.get.documentsMissingInMilliseconds ElasticSearch elasticsearch.index.rollup.get.requests primaries.get.requests ElasticSearch elasticsearch.index.rollup.get.requestsCurrent primaries.get.requestsCurrent ElasticSearch elasticsearch.index.rollup.get.requestsInMilliseconds primaries.get.requestsInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyDeleted primaries.index.docsCurrentlyDeleted ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyDeletedInMilliseconds primaries.index.docsCurrentlyDeletedInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyIndexing primaries.index.docsCurrentlyIndexing ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyIndexingInMilliseconds primaries.index.docsCurrentlyIndexingInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsDeleted primaries.index.docsDeleted ElasticSearch elasticsearch.index.rollup.index.docsTotal primaries.index.docsTotal ElasticSearch elasticsearch.index.rollup.indexRefreshesTotal primaries.indexRefreshesTotal ElasticSearch elasticsearch.index.rollup.indexRefreshesTotalInMilliseconds primaries.indexRefreshesTotalInMilliseconds ElasticSearch elasticsearch.index.rollup.merges.current primaries.merges.current ElasticSearch elasticsearch.index.rollup.merges.docsSegmentsCurrentlyMerged primaries.merges.docsSegmentsCurrentlyMerged ElasticSearch elasticsearch.index.rollup.merges.docsTotal primaries.merges.docsTotal ElasticSearch elasticsearch.index.rollup.merges.segmentsCurrentlyMergedInBytes primaries.merges.segmentsCurrentlyMergedInBytes ElasticSearch elasticsearch.index.rollup.merges.segmentsTotal primaries.merges.segmentsTotal ElasticSearch elasticsearch.index.rollup.merges.segmentsTotalInBytes primaries.merges.segmentsTotalInBytes ElasticSearch elasticsearch.index.rollup.merges.segmentsTotalInMilliseconds primaries.merges.segmentsTotalInMilliseconds ElasticSearch elasticsearch.index.rollup.queriesInMilliseconds primaries.queriesInMilliseconds ElasticSearch elasticsearch.index.rollup.queriesTotal primaries.queriesTotal ElasticSearch elasticsearch.index.rollup.queryActive primaries.queryActive ElasticSearch elasticsearch.index.rollup.queryFetches primaries.queryFetches ElasticSearch elasticsearch.index.rollup.queryFetchesInMilliseconds primaries.queryFetchesInMilliseconds ElasticSearch elasticsearch.index.rollup.queryFetchesTotal primaries.queryFetchesTotal ElasticSearch elasticsearch.index.rollup.sizeInBytes primaries.sizeInBytes ElasticSearch elasticsearch.index.storeSizeInBytes index.storeSizeInBytes ElasticSearch elasticsearch.node.activeSearches activeSearches ElasticSearch elasticsearch.node.activeSearchesInMilliseconds activeSearchesInMilliseconds ElasticSearch elasticsearch.node.breakers.estimatedSizeFieldDataCircuitBreakerInBytes breakers.estimatedSizeFieldDataCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.estimatedSizeParentCircuitBreakerInBytes breakers.estimatedSizeParentCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.estimatedSizeRequestCircuitBreakerInBytes breakers.estimatedSizeRequestCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.fieldDataCircuitBreakerTripped breakers.fieldDataCircuitBreakerTripped ElasticSearch elasticsearch.node.breakers.parentCircuitBreakerTripped breakers.parentCircuitBreakerTripped ElasticSearch elasticsearch.node.breakers.requestCircuitBreakerTripped breakers.requestCircuitBreakerTripped ElasticSearch elasticsearch.node.flush.indexRefreshesTotal flush.indexRefreshesTotal ElasticSearch elasticsearch.node.flush.indexRefreshesTotalInMilliseconds flush.indexRefreshesTotalInMilliseconds ElasticSearch elasticsearch.node.fs.bytesAvailableJvmInBytes fs.bytesAvailableJVMInBytes ElasticSearch elasticsearch.node.fs.dataRead fs.bytesReadsInBytes ElasticSearch elasticsearch.node.fs.dataWritten fs.writesInBytes ElasticSearch elasticsearch.node.fs.ioOperations fs.iOOperations ElasticSearch elasticsearch.node.fs.readOperations fs.reads ElasticSearch elasticsearch.node.fs.totalSizeInBytes fs.totalSizeInBytes ElasticSearch elasticsearch.node.fs.unallocatedBytes fs.unallocatedBytesInBYtes ElasticSearch elasticsearch.node.fs.writeOperations fs.writeOperations ElasticSearch elasticsearch.node.get.currentRequestsRunning get.currentRequestsRunning ElasticSearch elasticsearch.node.get.requestsDocumentExists get.requestsDocumentExists ElasticSearch elasticsearch.node.get.requestsDocumentExistsInMilliseconds get.requestsDocumentExistsInMilliseconds ElasticSearch elasticsearch.node.get.requestsDocumentMissing get.requestsDocumentMissing ElasticSearch elasticsearch.node.get.requestsDocumentMissingInMilliseconds get.requestsDocumentMissingInMilliseconds ElasticSearch elasticsearch.node.get.timeGetRequestsInMilliseconds get.timeGetRequestsInMilliseconds ElasticSearch elasticsearch.node.get.totalGetRequests get.totalGetRequests ElasticSearch elasticsearch.node.http.currentOpenConnections http.currentOpenConnections ElasticSearch elasticsearch.node.http.openedConnections http.openedConnections ElasticSearch elasticsearch.node.index.indexingOperationsFailed indices.indexingOperationsFailed ElasticSearch elasticsearch.node.index.indexingWaitedThrottlingInMilliseconds indices.indexingWaitedThrottlingInMilliseconds ElasticSearch elasticsearch.node.index.memoryQueryCacheInBytes indices.memoryQueryCacheInBytes ElasticSearch elasticsearch.node.index.numberIndices indices.numberIndices ElasticSearch elasticsearch.node.index.queryCacheEvictions indices.queryCacheEvictions ElasticSearch elasticsearch.node.index.queryCacheHits indices.queryCacheHits ElasticSearch elasticsearch.node.index.queryCacheMisses indices.queryCacheMisses ElasticSearch elasticsearch.node.index.recoveryOngoingShardSource indices.recoveryOngoingShardSource ElasticSearch elasticsearch.node.index.recoveryOngoingShardTarget indices.recoveryOngoingShardTarget ElasticSearch elasticsearch.node.index.recoveryWaitedThrottlingInMilliseconds indices.recoveryWaitedThrottlingInMilliseconds ElasticSearch elasticsearch.node.index.requestCacheEvictions indices.requestCacheEvictions ElasticSearch elasticsearch.node.index.requestCacheHits indices.requestCacheHits ElasticSearch elasticsearch.node.index.requestCacheMemoryInBytes indices.requestCacheMemoryInBytes ElasticSearch elasticsearch.node.index.requestCacheMisses indices.requestCacheMisses ElasticSearch elasticsearch.node.index.segmentsIndexShard indices.segmentsIndexShard ElasticSearch elasticsearch.node.index.segmentsMemoryUsedDocValuesInBytes indices.segmentsMemoryUsedDocValuesInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedFixedBitSetInBytes indices.segmentsMemoryUsedFixedBitSetInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedIndexSegmentsInBytes indices.segmentsMemoryUsedIndexSegmentsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedIndexWriterInBytes indices.segmentsMemoryUsedIndexWriterInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedNormsInBytes indices.segmentsMemoryUsedNormsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedSegmentVersionMapInBytes indices.segmentsMemoryUsedSegmentVersionMapInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedStoredFieldsInBytes indices.segmentsMemoryUsedStoredFieldsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedTermsInBytes indices.segmentsMemoryUsedTermsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedTermVectorsInBytes indices.segmentsMemoryUsedTermVectorsInBytes ElasticSearch elasticsearch.node.index.translogOperations indices.translogOperations ElasticSearch elasticsearch.node.index.translogOperationsInBytes indices.translogOperationsInBytes ElasticSearch elasticsearch.node.indexing.docsCurrentlyDeleted indexing.docsCurrentlyDeleted ElasticSearch elasticsearch.node.indexing.documentsCurrentlyIndexing indexing.documentsCurrentlyIndexing ElasticSearch elasticsearch.node.indexing.documentsIndexed indexing.documentsIndexed ElasticSearch elasticsearch.node.indexing.timeDeletingDocumentsInMilliseconds indexing.timeDeletingDocumentsInMilliseconds ElasticSearch elasticsearch.node.indexing.timeIndexingDocumentsInMilliseconds indexing.timeIndexingDocumentsInMilliseconds ElasticSearch elasticsearch.node.indexing.totalDocumentsDeleted indexing.totalDocumentsDeleted ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsOldGenerationObjects jvm.gc.majorCollectionsOldGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsOldGenerationObjectsInMilliseconds jvm.gc.majorCollectionsOldGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsYoungGenerationObjects jvm.gc.majorCollectionsYoungGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsYoungGenerationObjectsInMilliseconds jvm.gc.majorCollectionsYoungGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.gc.minorCollectionsYoungGenerationObjects jvm.gc.minorCollectionsYoungGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.minorCollectionsYoungGenerationObjectsInMilliseconds jvm.gc.minorCollectionsYoungGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.mem.heapCommittedInBytes jvm.mem.heapCommittedInBytes ElasticSearch elasticsearch.node.jvm.mem.heapMaxInBytes jvm.mem.heapMaxInBytes ElasticSearch elasticsearch.node.jvm.mem.heapUsed jvm.mem.heapUsed ElasticSearch elasticsearch.node.jvm.mem.heapUsedInBytes jvm.mem.heapUsedInBytes ElasticSearch elasticsearch.node.jvm.mem.maxOldGenerationHeapInBytes jvm.mem.maxOldGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.maxSurvivorSpaceInBytes jvm.mem.maxSurvivorSpaceInBYtes ElasticSearch elasticsearch.node.jvm.mem.maxYoungGenerationHeapInBytes jvm.mem.maxYoungGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.nonHeapCommittedInBytes jvm.mem.nonHeapCommittedInBytes ElasticSearch elasticsearch.node.jvm.mem.nonHeapUsedInBytes jvm.mem.nonHeapUsedInBytes ElasticSearch elasticsearch.node.jvm.mem.usedOldGenerationHeapInBytes jvm.mem.usedOldGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.usedSurvivorSpaceInBytes jvm.mem.usedSurvivorSpaceInBytes ElasticSearch elasticsearch.node.jvm.mem.usedYoungGenerationHeapInBytes jvm.mem.usedYoungGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.threadsActive jvm.ThreadsActive ElasticSearch elasticsearch.node.jvm.threadsPeak jvm.ThreadsPeak ElasticSearch elasticsearch.node.merges.currentActive merges.currentActive ElasticSearch elasticsearch.node.merges.docsSegmentMerges merges.docsSegmentMerges ElasticSearch elasticsearch.node.merges.docsSegmentsMerging merges.docsSegmentsMerging ElasticSearch elasticsearch.node.merges.mergedSegmentsInBytes merges.mergedSegmentsInBytes ElasticSearch elasticsearch.node.merges.segmentMerges merges.segmentMerges ElasticSearch elasticsearch.node.merges.sizeSegmentsMergingInBytes merges.sizeSegmentsMergingInBytes ElasticSearch elasticsearch.node.merges.totalSegmentMergingInMilliseconds merges.totalSegmentMergingInMilliseconds ElasticSearch elasticsearch.node.openFd openFD ElasticSearch elasticsearch.node.queriesTotal queriesTotal ElasticSearch elasticsearch.node.refresh.total refresh.total ElasticSearch elasticsearch.node.refresh.totalInMilliseconds refresh.totalInMilliseconds ElasticSearch elasticsearch.node.searchFetchCurrentlyRunning searchFetchCurrentlyRunning ElasticSearch elasticsearch.node.searchFetches searchFetches ElasticSearch elasticsearch.node.sizeStoreInBytes sizeStoreInBytes ElasticSearch elasticsearch.node.threadpool.activeFetchShardStarted threadpool.activeFetchShardStarted ElasticSearch elasticsearch.node.threadpool.bulkActive threadpool.bulkActive ElasticSearch elasticsearch.node.threadpool.bulkQueue threadpool.bulkQueue ElasticSearch elasticsearch.node.threadpool.bulkRejected threadpool.bulkRejected ElasticSearch elasticsearch.node.threadpool.bulkThreads threadpool.bulkThreads ElasticSearch elasticsearch.node.threadpool.fetchShardStartedQueue threadpool.fetchShardStartedQueue ElasticSearch elasticsearch.node.threadpool.fetchShardStartedRejected threadpool.fetchShardStartedRejected ElasticSearch elasticsearch.node.threadpool.fetchShardStartedThreads threadpool.fetchShardStartedThreads ElasticSearch elasticsearch.node.threadpool.fetchShardStoreActive threadpool.fetchShardStoreActive ElasticSearch elasticsearch.node.threadpool.fetchShardStoreQueue threadpool.fetchShardStoreQueue ElasticSearch elasticsearch.node.threadpool.fetchShardStoreRejected threadpool.fetchShardStoreRejected ElasticSearch elasticsearch.node.threadpool.fetchShardStoreThreads threadpool.fetchShardStoreThreads ElasticSearch elasticsearch.node.threadpool.flushActive threadpool.flushActive ElasticSearch elasticsearch.node.threadpool.flushQueue threadpool.flushQueue ElasticSearch elasticsearch.node.threadpool.flushRejected threadpool.flushRejected ElasticSearch elasticsearch.node.threadpool.flushThreads threadpool.flushThreads ElasticSearch elasticsearch.node.threadpool.forceMergeActive threadpool.forceMergeActive ElasticSearch elasticsearch.node.threadpool.forceMergeQueue threadpool.forceMergeQueue ElasticSearch elasticsearch.node.threadpool.forceMergeRejected threadpool.forceMergeRejected ElasticSearch elasticsearch.node.threadpool.forceMergeThreads threadpool.forceMergeThreads ElasticSearch elasticsearch.node.threadpool.genericActive threadpool.genericActive ElasticSearch elasticsearch.node.threadpool.genericQueue threadpool.genericQueue ElasticSearch elasticsearch.node.threadpool.genericRejected threadpool.genericRejected ElasticSearch elasticsearch.node.threadpool.genericThreads threadpool.genericThreads ElasticSearch elasticsearch.node.threadpool.getActive threadpool.getActive ElasticSearch elasticsearch.node.threadpool.getQueue threadpool.getQueue ElasticSearch elasticsearch.node.threadpool.getRejected threadpool.getRejected ElasticSearch elasticsearch.node.threadpool.getThreads threadpool.getThreads ElasticSearch elasticsearch.node.threadpool.indexActive threadpool.indexActive ElasticSearch elasticsearch.node.threadpool.indexQueue threadpool.indexQueue ElasticSearch elasticsearch.node.threadpool.indexRejected threadpool.indexRejected ElasticSearch elasticsearch.node.threadpool.indexThreads threadpool.indexThreads ElasticSearch elasticsearch.node.threadpool.listenerActive threadpool.listenerActive ElasticSearch elasticsearch.node.threadpool.listenerQueue threadpool.listenerQueue ElasticSearch elasticsearch.node.threadpool.listenerRejected threadpool.listenerRejected ElasticSearch elasticsearch.node.threadpool.listenerThreads threadpool.listenerThreads ElasticSearch elasticsearch.node.threadpool.managementActive threadpool.managementActive ElasticSearch elasticsearch.node.threadpool.managementQueue threadpool.managementQueue ElasticSearch elasticsearch.node.threadpool.managementRejected threadpool.managementRejected ElasticSearch elasticsearch.node.threadpool.managementThreads threadpool.managementThreads ElasticSearch elasticsearch.node.threadpool.refreshActive threadpool.refreshActive ElasticSearch elasticsearch.node.threadpool.refreshQueue threadpool.refreshQueue ElasticSearch elasticsearch.node.threadpool.refreshRejected threadpool.refreshRejected ElasticSearch elasticsearch.node.threadpool.refreshThreads threadpool.refreshThreads ElasticSearch elasticsearch.node.threadpool.searchActive threadpool.searchActive ElasticSearch elasticsearch.node.threadpool.searchQueue threadpool.searchQueue ElasticSearch elasticsearch.node.threadpool.searchRejected threadpool.searchRejected ElasticSearch elasticsearch.node.threadpool.searchThreads threadpool.searchThreads ElasticSearch elasticsearch.node.threadpool.snapshotActive threadpool.snapshotActive ElasticSearch elasticsearch.node.threadpool.snapshotQueue threadpool.snapshotQueue ElasticSearch elasticsearch.node.threadpool.snapshotRejected threadpool.snapshotRejected ElasticSearch elasticsearch.node.threadpool.snapshotThreads threadpool.snapshotThreads ElasticSearch elasticsearch.node.transport.connectionsOpened transport.connectionsOpened ElasticSearch elasticsearch.node.transport.packetsReceived transport.packetsReceived ElasticSearch elasticsearch.node.transport.packetsReceivedInBytes transport.packetsReceivedInBytes ElasticSearch elasticsearch.node.transport.packetsSent transport.packetsSent ElasticSearch elasticsearch.node.transport.packetsSentInBytes transport.packetsSentInBytes F5 f5.node.availabilityState node.availabilityState F5 f5.node.connections node.connections F5 f5.node.connectionsPerSecond node.connectionsPerSecond F5 f5.node.enabled node.enabled F5 f5.node.inDataInBytesPerSecond node.inDataInBytesPerSecond F5 f5.node.monitorStatus node.monitorStatus F5 f5.node.outDataInBytesPerSecond node.outDataInBytesPerSecond F5 f5.node.packetsReceivedPerSecond node.packetsReceivedPerSecond F5 f5.node.packetsSentPerSecond node.packetsSentPerSecond F5 f5.node.requestsPerSecond node.requestsPerSecond F5 f5.node.sessions node.sessions F5 f5.node.sessionStatus node.sessionStatus F5 f5.poolMember.availabilityState member.availabilityState F5 f5.poolMember.connections member.connections F5 f5.poolMember.enabled member.enabled F5 f5.poolMember.inDataInBytesPerSecond member.inDataInBytesPerSecond F5 f5.poolMember.monitorStatus member.monitorStatus F5 f5.poolMember.outDataInBytesPerSecond member.outDataInBytesPerSecond F5 f5.poolMember.packetsReceivedPerSecond member.packetsReceivedPerSecond F5 f5.poolMember.packetsSentPerSecond member.packetsSentPerSecond F5 f5.poolMember.requestsPerSecond member.requestsPerSecond F5 f5.poolMember.sessions member.sessions F5 f5.poolMember.sessionStatus member.sessionStatus F5 f5.pool.activeMembers pool.activeMembers F5 f5.pool.availabilityState pool.availabilityState F5 f5.pool.connections pool.connections F5 f5.pool.connqAgeEdm pool.connqAgeEdm F5 f5.pool.connqAgeEma pool.connqAgeEma F5 f5.pool.connqAgeHead pool.connqAgeHead F5 f5.pool.connqAgeMax pool.connqAgeMax F5 f5.pool.connqAllAgeEdm pool.connqAllAgeEdm F5 f5.pool.connqAllAgeEma pool.connqAllAgeEma F5 f5.pool.connqAllAgeHead pool.connqAllAgeHead F5 f5.pool.connqAllAgeMax pool.connqAllAgeMax F5 f5.pool.connqAllDepth pool.connqAllDepth F5 f5.pool.connqDepth pool.connqDepth F5 f5.pool.currentConnections pool.currentConnections F5 f5.pool.enabled pool.enabled F5 f5.pool.inDataInBytesPerSecond pool.inDataInBytesPerSecond F5 f5.pool.minActiveMembers pool.minActiveMembers F5 f5.pool.outDataInBytesPerSecond pool.outDataInBytesPerSecond F5 f5.pool.packetsReceivedPerSecond pool.packetsReceivedPerSecond F5 f5.pool.packetsSentPerSecond pool.packetsSentPerSecond F5 f5.pool.requestsPerSecond pool.requestsPerSecond F5 f5.pool.sessions pool.sessions F5 f5.system.cpuIdleTicksPerSecond system.cpuIdleTicksPerSecond F5 f5.system.cpuIdleUtilization system.cpuIdleUtilization F5 f5.system.cpuInterruptRequestUtilization system.cpuInterruptRequestUtilization F5 f5.system.cpuIoWaitUtilization system.cpuIOWaitUtilization F5 f5.system.cpuNiceLevelUtilization system.cpuNiceLevelUtilization F5 f5.system.cpuSoftInterruptRequestUtilization system.cpuSoftInterruptRequestUtilization F5 f5.system.cpuStolenUtilization system.cpuStolenUtilization F5 f5.system.cpuSystemTicksPerSecond system.cpuSystemTicksPerSecond F5 f5.system.cpuSystemUtilization system.cpuSystemUtilization F5 f5.system.cpuUserTicksPerSecond system.cpuUserTicksPerSecond F5 f5.system.cpuUserUtilization system.cpuUserUtilization F5 f5.system.memoryFreeInBytes system.memoryFreeInBytes F5 f5.system.memoryTotalInBytes system.memoryTotalInBytes F5 f5.system.memoryUsedInBytes system.memoryUsedInBytes F5 f5.system.otherMemoryFreeInBytes system.otherMemoryFreeInBytes F5 f5.system.otherMemoryTotalInBytes system.otherMemoryTotalInBytes F5 f5.system.otherMemoryUsedInBytes system.otherMemoryUsedInBytes F5 f5.system.swapFreeInBytes system.swapFreeInBytes F5 f5.system.swapTotalInBytes system.swapTotalInBytes F5 f5.system.swapUsedInBytes system.swapUsedInBytes F5 f5.system.tmmMemoryFreeInBytes system.tmmMemoryFreeInBytes F5 f5.system.tmmMemoryTotalInBytes system.tmmMemoryTotalInBytes F5 f5.system.tmmMemoryUsedInBytes system.tmmMemoryUsedInBytes F5 f5.virtualserver.availabilityState virtualserver.availabilityState F5 f5.virtualserver.clientsideConnectionsPerSecond virtualserver.clientsideConnectionsPerSecond F5 f5.virtualserver.connections virtualserver.connections F5 f5.virtualserver.csMaxConnDur virtualserver.csMaxConnDur F5 f5.virtualserver.csMeanConnDur virtualserver.csMeanConnDur F5 f5.virtualserver.csMinConnDur virtualserver.csMinConnDur F5 f5.virtualserver.enabled virtualserver.enabled F5 f5.virtualserver.ephemeralBytesInPerSecond virtualserver.ephemeralBytesInPerSecond F5 f5.virtualserver.ephemeralBytesOutPerSecond virtualserver.ephemeralBytesOutPerSecond F5 f5.virtualserver.ephemeralConnectionsPerSecond virtualserver.ephemeralConnectionsPerSecond F5 f5.virtualserver.ephemeralCurrentConnections virtualserver.ephemeralCurrentConnections F5 f5.virtualserver.ephemeralEvictedConnectionsPerSecond virtualserver.ephemeralEvictedConnectionsPerSecond F5 f5.virtualserver.ephemeralMaxConnections virtualserver.ephemeralMaxConnections F5 f5.virtualserver.ephemeralPacketsReceivedPerSecond virtualserver.ephemeralPacketsReceivedPerSecond F5 f5.virtualserver.ephemeralPacketsSentPerSecond virtualserver.ephemeralPacketsSentPerSecond F5 f5.virtualserver.ephemeralSlowKilledPerSecond virtualserver.ephemeralSlowKilledPerSecond F5 f5.virtualserver.evictedConnsPerSecond virtualserver.evictedConnsPerSecond F5 f5.virtualserver.inDataInBytesPerSecond virtualserver.inDataInBytesPerSecond F5 f5.virtualserver.outDataInBytesPerSecond virtualserver.outDataInBytesPerSecond F5 f5.virtualserver.packetsReceivedPerSecond virtualserver.packetsReceivedPerSecond F5 f5.virtualserver.packetsSentPerSecond virtualserver.packetsSentPerSecond F5 f5.virtualserver.requestsPerSecond virtualserver.requestsPerSecond F5 f5.virtualserver.slowKilledPerSecond virtualserver.slowKilledPerSecond F5 f5.virtualserver.usageRatio virtualserver.usageRatio HAProxy haproxy.backend.activeServers backend.activeServers HAProxy haproxy.backend.averageConnectTimeInSeconds backend.averageConnectTimeInSeconds HAProxy haproxy.backend.averageQueueTimeInSeconds backend.averageQueueTimeInSeconds HAProxy haproxy.backend.averageResponseTimeInSeconds backend.averageResponseTimeInSeconds HAProxy haproxy.backend.averageTotalSessionTimeInSeconds backend.averageTotalSessionTimeInSeconds HAProxy haproxy.backend.backupServers backend.backupServers HAProxy haproxy.backend.bytesInPerSecond backend.bytesInPerSecond HAProxy haproxy.backend.bytesOutPerSecond backend.bytesOutPerSecond HAProxy haproxy.backend.bytesThatBypassedCompressorPerSecond backend.bytesThatBypassedCompressorPerSecond HAProxy haproxy.backend.connectingRequestErrorsPerSecond backend.connectingRequestErrorsPerSecond HAProxy haproxy.backend.connectionRetriesPerSecond backend.connectionRetriesPerSecond HAProxy haproxy.backend.currentQueuedRequestsWithoutServer backend.currentQueuedRequestsWithoutServer HAProxy haproxy.backend.currentSessions backend.currentSessions HAProxy haproxy.backend.dataTransfersAbortedByClientPerSecond backend.dataTransfersAbortedByClientPerSecond HAProxy haproxy.backend.dataTransfersAbortedByServerPerSecond backend.dataTransfersAbortedByServerPerSecond HAProxy haproxy.backend.downtimeInSeconds backend.downtimeInSeconds HAProxy haproxy.backend.http100ResponsesPerSecond backend.http100ResponsesPerSecond HAProxy haproxy.backend.http200ResponsesPerSecond backend.http200ResponsesPerSecond HAProxy haproxy.backend.http300ResponsesPerSecond backend.http300ResponsesPerSecond HAProxy haproxy.backend.http400ResponsesPerSecond backend.http400ResponsesPerSecond HAProxy haproxy.backend.http500ResponsesPerSecond backend.http500ResponsesPerSecond HAProxy haproxy.backend.httpOtherResponsesPerSecond backend.httpOtherResponsesPerSecond HAProxy haproxy.backend.httpRequestsPerSecond backend.httpRequestsPerSecond HAProxy haproxy.backend.httpResponseBytesEmittedByCompressorPerSecond backend.httpResponseBytesEmittedByCompressorPerSecond HAProxy haproxy.backend.httpResponseBytesFedToCompressorPerSecond backend.httpResponseBytesFedToCompressorPerSecond HAProxy haproxy.backend.httpResponsesCompressedPerSecond backend.httpResponsesCompressedPerSecond HAProxy haproxy.backend.interceptedRequestsPerSecond backend.interceptedRequestsPerSecond HAProxy haproxy.backend.maxQueuedRequestsWithoutServer backend.maxQueuedRequestsWithoutServer HAProxy haproxy.backend.maxSessions backend.maxSessions HAProxy haproxy.backend.maxSessionsPerSecond backend.maxSessionsPerSecond HAProxy haproxy.backend.requestRedispatchPerSecond backend.requestRedispatchPerSecond HAProxy haproxy.backend.requestsDenied.securityConcernsPerSecond backend.requestsDenied.securityConcernsPerSecond HAProxy haproxy.backend.responseErrorsPerSecond backend.responseErrorsPerSecond HAProxy haproxy.backend.responsesDenied.securityConcernsPerSecond backend.responsesDenied.securityConcernsPerSecond HAProxy haproxy.backend.serverSelectedPerSecond backend.serverSelectedPerSecond HAProxy haproxy.backend.sessionsPerSecond backend.sessionsPerSecond HAProxy haproxy.backend.timeSinceLastSessionAssignedInSeconds backend.timeSinceLastSessionAssignedInSeconds HAProxy haproxy.backend.timeSinceLastUpDownTransitionInSeconds backend.timeSinceLastUpDownTransitionInSeconds HAProxy haproxy.backend.totalWeight backend.totalWeight HAProxy haproxy.backend.type backend.type HAProxy haproxy.backend.upToDownTransitionsPerSecond backend.upToDownTransitionsPerSecond HAProxy haproxy.frontend.bytesInPerSecond frontend.bytesInPerSecond HAProxy haproxy.frontend.bytesOutPerSecond frontend.bytesOutPerSecond HAProxy haproxy.frontend.connectionsPerSecond frontend.connectionsPerSecond HAProxy haproxy.frontend.currentSessions frontend.currentSessions HAProxy haproxy.frontend.http100ResponsesPerSecond frontend.http100ResponsesPerSecond HAProxy haproxy.frontend.http200ResponsesPerSecond frontend.http200ResponsesPerSecond HAProxy haproxy.frontend.http300ResponsesPerSecond frontend.http300ResponsesPerSecond HAProxy haproxy.frontend.http400ResponsesPerSecond frontend.http400ResponsesPerSecond HAProxy haproxy.frontend.http500ResponsesPerSecond frontend.http500ResponsesPerSecond HAProxy haproxy.frontend.httpOtherResponsesPerSecond frontend.httpOtherResponsesPerSecond HAProxy haproxy.frontend.httpRequests.maxPerSecond frontend.httpRequests.maxPerSecond HAProxy haproxy.frontend.httpRequestsPerSecond frontend.httpRequestsPerSecond HAProxy haproxy.frontend.interceptedRequestsPerSecond frontend.interceptedRequestsPerSecond HAProxy haproxy.frontend.maxConnectionsPerSecond frontend.maxConnectionsPerSecond HAProxy haproxy.frontend.maxSessions frontend.maxSessions HAProxy haproxy.frontend.maxSessionsPerSecond frontend.maxSessionsPerSecond HAProxy haproxy.frontend.requestErrorsPerSecond frontend.requestErrorsPerSecond HAProxy haproxy.frontend.requestsDenied.securityConcernsPerSecond frontend.requestsDenied.securityConcernsPerSecond HAProxy haproxy.frontend.requestsDenied.tcpRequestConnectionRulesPerSecond frontend.requestsDenied.tcpRequestConnectionRulesPerSecond HAProxy haproxy.frontend.requestsDenied.tcpRequestSessionRulesPerSecond frontend.requestsDenied.tcpRequestSessionRulesPerSecond HAProxy haproxy.frontend.responsesDenied.securityConcernsPerSecond frontend.responsesDenied.securityConcernsPerSecond HAProxy haproxy.frontend.sessionsPerSecond frontend.sessionsPerSecond HAProxy haproxy.server.averageConnectTimeInSeconds server.averageConnectTimeInSeconds HAProxy haproxy.server.averageQueueTimeInSeconds server.averageQueueTimeInSeconds HAProxy haproxy.server.averageResponseTimeInSeconds server.averageResponseTimeInSeconds HAProxy haproxy.server.averageTotalSessionTimeInSeconds server.averageTotalSessionTimeInSeconds HAProxy haproxy.server.bytesInPerSecond server.bytesInPerSecond HAProxy haproxy.server.bytesOutPerSecond server.bytesOutPerSecond HAProxy haproxy.server.connectingRequestErrorsPerSecond server.connectingRequestErrorsPerSecond HAProxy haproxy.server.connectionRetriesPerSecond server.connectionRetriesPerSecond HAProxy haproxy.server.currentQueuedRequestsWithoutServer server.currentQueuedRequestsWithoutServer HAProxy haproxy.server.currentSessions server.currentSessions HAProxy haproxy.server.dataTransfersAbortedByClientPerSecond server.dataTransfersAbortedByClientPerSecond HAProxy haproxy.server.dataTransfersAbortedByServerPerSecond server.dataTransfersAbortedByServerPerSecond HAProxy haproxy.server.downtimeInSeconds server.downtimeInSeconds HAProxy haproxy.server.failedChecksPerSecond server.failedChecksPerSecond HAProxy haproxy.server.healthCheckDurationInMilliseconds server.healthCheckDurationInMilliseconds HAProxy haproxy.server.http100ResponsesPerSecond server.http100ResponsesPerSecond HAProxy haproxy.server.http200ResponsesPerSecond server.http200ResponsesPerSecond HAProxy haproxy.server.http300ResponsesPerSecond server.http300ResponsesPerSecond HAProxy haproxy.server.http400ResponsesPerSecond server.http400ResponsesPerSecond HAProxy haproxy.server.http500ResponsesPerSecond server.http500ResponsesPerSecond HAProxy haproxy.server.httpOtherResponsesPerSecond server.httpOtherResponsesPerSecond HAProxy haproxy.server.isActive server.isActive HAProxy haproxy.server.isBackup server.isBackup HAProxy haproxy.server.maxQueuedRequestsWithoutServer server.maxQueuedRequestsWithoutServer HAProxy haproxy.server.maxSessions server.maxSessions HAProxy haproxy.server.maxSessionsPerSecond server.maxSessionsPerSecond HAProxy haproxy.server.requestRedispatchPerSecond server.requestRedispatchPerSecond HAProxy haproxy.server.requestsDenied.securityConcernsPerSecond server.requestsDenied.securityConcernsPerSecond HAProxy haproxy.server.responseErrorsPerSecond server.responseErrorsPerSecond HAProxy haproxy.server.responsesDenied.securityConcernsPerSecond server.responsesDenied.securityConcernsPerSecond HAProxy haproxy.server.serverSelectedPerSecond server.serverSelectedPerSecond HAProxy haproxy.server.serverWeight server.serverWeight HAProxy haproxy.server.sessionsPerSecond server.sessionsPerSecond HAProxy haproxy.server.throttlePercentage server.throttlePercentage HAProxy haproxy.server.timeSinceLastSessionAssignedInSeconds server.timeSinceLastSessionAssignedInSeconds HAProxy haproxy.server.timeSinceLastUpDownTransitionInSeconds server.timeSinceLastUpDownTransitionInSeconds HAProxy haproxy.server.type server.type HAProxy haproxy.server.upToDownTransitionsPerSecond server.upToDownTransitionsPerSecond Kafka kafka.broker.bytesWrittenToTopicPerSecond broker.bytesWrittenToTopicPerSecond Kafka kafka.broker.consumer.requestsExpiredPerSecond consumer.requestsExpiredPerSecond Kafka kafka.broker.follower.requestExpirationPerSecond follower.requestExpirationPerSecond Kafka kafka.broker.ioInPerSecond broker.IOInPerSecond Kafka kafka.broker.ioOutPerSecond broker.IOOutPerSecond Kafka kafka.broker.logFlushPerSecond broker.logFlushPerSecond Kafka kafka.broker.messagesInPerSecond broker.messagesInPerSecond Kafka kafka.broker.net.bytesRejectedPerSecond net.bytesRejectedPerSecond Kafka kafka.broker.replication.isrExpandsPerSecond replication.isrExpandsPerSecond Kafka kafka.broker.replication.isrShrinksPerSecond replication.isrShrinksPerSecond Kafka kafka.broker.replication.leaderElectionPerSecond replication.leaderElectionPerSecond Kafka kafka.broker.replication.uncleanLeaderElectionPerSecond replication.uncleanLeaderElectionPerSecond Kafka kafka.broker.replication.unreplicatedPartitions replication.unreplicatedPartitions Kafka kafka.broker.request.avgTimeFetch request.avgTimeFetch Kafka kafka.broker.request.avgTimeMetadata request.avgTimeMetadata Kafka kafka.broker.request.avgTimeMetadata99Percentile request.avgTimeMetadata99Percentile Kafka kafka.broker.request.avgTimeOffset request.avgTimeOffset Kafka kafka.broker.request.avgTimeOffset99Percentile request.avgTimeOffset99Percentile Kafka kafka.broker.request.avgTimeProduceRequest request.avgTimeProduceRequest Kafka kafka.broker.request.avgTimeUpdateMetadata request.avgTimeUpdateMetadata Kafka kafka.broker.request.avgTimeUpdateMetadata99Percentile request.avgTimeUpdateMetadata99Percentile Kafka kafka.broker.request.clientFetchesFailedPerSecond request.clientFetchesFailedPerSecond Kafka kafka.broker.request.fetchConsumerRequestsPerSecond request.fetchConsumerRequestsPerSecond Kafka kafka.broker.request.fetchFollowerRequestsPerSecond request.fetchFollowerRequestsPerSecond Kafka kafka.broker.request.fetchTime99Percentile request.fetchTime99Percentile Kafka kafka.broker.request.handlerIdle request.handlerIdle Kafka kafka.broker.request.listGroupsRequestsPerSecond request.listGroupsRequestsPerSecond Kafka kafka.broker.request.metadataRequestsPerSecond request.metadataRequestsPerSecond Kafka kafka.broker.request.offsetCommitRequestsPerSecond request.offsetCommitRequestsPerSecond Kafka kafka.broker.request.produceRequestsFailedPerSecond request.produceRequestsFailedPerSecond Kafka kafka.broker.request.produceRequestsPerSecond request.produceRequestsPerSecond Kafka kafka.broker.request.produceTime99Percentile request.produceTime99Percentile Kafka kafka.broker.topic.diskSize topic.diskSize Kafka kafka.topic.bytesInPerSec topic.BytesInPerSec Kafka kafka.topic.bytesOutPerSec topic.BytesOutPerSec Kafka kafka.topic.messagesInPerSec topic.MessagesInPerSec Kafka kafka.topic.partitionsWithNonPreferredLeader topic.partitionsWithNonPreferredLeader Kafka kafka.topic.respondsToMetadataRequests topic.respondsToMetadataRequests Kafka kafka.topic.retentionBytesOrTime topic.retentionBytesOrTime Kafka kafka.topic.underReplicatedPartitions topic.underReplicatedPartitions Kafka kafka.producer.ageMetadataUsedInMilliseconds producer.ageMetadataUsedInMilliseconds Kafka kafka.producer.availableBufferInBytes producer.availableBufferInBytes Kafka kafka.producer.avgBytesSentPerRequestInBytes producer.avgBytesSentPerRequestInBytes Kafka kafka.producer.avgCompressionRateRecordBatches producer.avgCompressionRateRecordBatches Kafka kafka.producer.avgRecordAccumulatorsInMilliseconds producer.avgRecordAccumulatorsInMilliseconds Kafka kafka.producer.avgRecordSizeInBytes producer.avgRecordSizeInBytes Kafka kafka.producer.avgRecordsSentPerSecond producer.avgRecordsSentPerSecond Kafka kafka.producer.avgRecordsSentPerTopicPerSecond producer.avgRecordsSentPerTopicPerSecond Kafka kafka.producer.avgRequestLatency producer.avgRequestLatencyPerSecond Kafka kafka.producer.avgThrottleTime producer.avgThrottleTime Kafka kafka.producer.bufferMemoryAvailableInBytes producer.bufferMemoryAvailableInBytes Kafka kafka.producer.bufferpoolWaitTime producer.bufferpoolWaitTime Kafka kafka.producer.bytesOutPerSecond producer.bytesOutPerSecond Kafka kafka.producer.compressionRateRecordBatches producer.compressionRateRecordBatches Kafka kafka.producer.ioWaitTime producer.ioWaitTime Kafka kafka.producer.maxBytesSentPerRequestInBytes producer.maxBytesSentPerRequestInBytes Kafka kafka.producer.maxRecordSizeInBytes producer.maxRecordSizeInBytes Kafka kafka.producer.maxRequestLatencyInMilliseconds producer.maxRequestLatencyInMilliseconds Kafka kafka.producer.maxThrottleTime producer.maxThrottleTime Kafka kafka.producer.requestPerSecond producer.requestPerSecond Kafka kafka.producer.requestsWaitingResponse producer.requestsWaitingResponse Kafka kafka.producer.responsePerSecond producer.responsePerSecond Kafka kafka.producer.threadsWaiting producer.threadsWaiting Kafka kafka.consumer.avgFetchSizeInBytes consumer.avgFetchSizeInBytes Kafka kafka.consumer.avgRecordConsumedPerTopic consumer.avgRecordConsumedPerTopic Kafka kafka.consumer.avgRecordConsumedPerTopicPerSecond consumer.avgRecordConsumedPerTopicPerSecond Kafka kafka.consumer.bytesInPerSecond consumer.bytesInPerSecond Kafka kafka.consumer.fetchPerSecond consumer.fetchPerSecond Kafka kafka.consumer.hwm consumer.hwm Kafka kafka.consumer.lag consumer.lag Kafka kafka.consumer.maxFetchSizeInBytes consumer.maxFetchSizeInBytes Kafka kafka.consumer.maxLag consumer.maxLag Kafka kafka.consumer.messageConsumptionPerSecond consumer.messageConsumptionPerSecond Kafka kafka.consumer.offset consumer.offset Kafka kafka.consumer.totalLag consumer.totalLag Kafka kafka.consumerGroup.maxLag consumerGroup.maxLag Kafka kafka.consumerGroup.totalLag consumerGroup.totalLag Kubernetes k8s.apiserver.goGoroutines goGoroutines Kubernetes k8s.apiserver.goThreads goThreads Kubernetes k8s.apiserver.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.apiserver.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.controllermanager.goGoroutines goGoroutines Kubernetes k8s.controllermanager.goThreads goThreads Kubernetes k8s.controllermanager.leaderElectionMasterStatus leaderElectionMasterStatus Kubernetes k8s.controllermanager.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.controllermanager.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.etcd.goGoroutines goGoroutines Kubernetes k8s.etcd.goThreads goThreads Kubernetes k8s.etcd.mvccDbTotalSizeInBytes etcdMvccDbTotalSizeInBytes Kubernetes k8s.etcd.networkClientGrpcReceivedBytesRate etcdNetworkClientGrpcReceivedBytesRate Kubernetes k8s.etcd.networkClientGrpcSentBytesRate etcdNetworkClientGrpcSentBytesRate Kubernetes k8s.etcd.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.etcd.process.maxFds processMaxFds Kubernetes k8s.etcd.process.openFds processOpenFds Kubernetes k8s.etcd.process.processFdsUtilization processFdsUtilization Kubernetes k8s.etcd.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.etcd.serverHasLeader etcdServerHasLeader Kubernetes k8s.etcd.serverLeaderChangesSeenDelta etcdServerLeaderChangesSeenDelta Kubernetes k8s.etcd.serverProposalsAppliedDelta etcdServerProposalsAppliedDelta Kubernetes k8s.etcd.serverProposalsAppliedRate etcdServerProposalsAppliedRate Kubernetes k8s.etcd.serverProposalsCommittedDelta etcdServerProposalsCommittedDelta Kubernetes k8s.etcd.serverProposalsCommittedRate etcdServerProposalsCommittedRate Kubernetes k8s.etcd.serverProposalsFailedDelta etcdServerProposalsFailedDelta Kubernetes k8s.etcd.serverProposalsFailedRate etcdServerProposalsFailedRate Kubernetes k8s.etcd.serverProposalsPending etcdServerProposalsPending Kubernetes k8s.scheduler.goGoroutines goGoroutines Kubernetes k8s.scheduler.goThreads goThreads Kubernetes k8s.scheduler.leaderElectionMasterStatus leaderElectionMasterStatus Kubernetes k8s.scheduler.podPreemptionVictims schedulerPodPreemptionVictims Kubernetes k8s.scheduler.preemptionAttemptsDelta schedulerPreemptionAttemptsDelta Kubernetes k8s.scheduler.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.scheduler.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.container.cpuCfsPeriodsDelta containerCpuCfsPeriodsDelta Kubernetes k8s.container.cpuCfsPeriodsTotal containerCpuCfsPeriodsTotal Kubernetes k8s.container.cpuCfsThrottledPeriodsDelta containerCpuCfsThrottledPeriodsDelta Kubernetes k8s.container.cpuCfsThrottledPeriodsTotal containerCpuCfsThrottledPeriodsTotal Kubernetes k8s.container.cpuCfsThrottledSecondsDelta containerCpuCfsThrottledSecondsDelta Kubernetes k8s.container.cpuCfsThrottledSecondsTotal containerCpuCfsThrottledSecondsTotal Kubernetes k8s.container.cpuCoresUtilization cpuCoresUtilization Kubernetes k8s.container.cpuLimitCores cpuLimitCores Kubernetes k8s.container.cpuRequestedCores cpuRequestedCores Kubernetes k8s.container.cpuUsedCores cpuUsedCores Kubernetes k8s.container.fsAvailableBytes fsAvailableBytes Kubernetes k8s.container.fsCapacityBytes fsCapacityBytes Kubernetes k8s.container.fsInodes fsInodes Kubernetes k8s.container.fsInodesFree fsInodesFree Kubernetes k8s.container.fsInodesUsed fsInodesUsed Kubernetes k8s.container.fsUsedBytes fsUsedBytes Kubernetes k8s.container.fsUsedPercent fsUsedPercent Kubernetes k8s.container.isReady isReady Kubernetes k8s.container.memoryLimitBytes memoryLimitBytes Kubernetes k8s.container.memoryMappedFileBytes containerMemoryMappedFileBytes Kubernetes k8s.container.memoryRequestedBytes memoryRequestedBytes Kubernetes k8s.container.memoryUsedBytes memoryUsedBytes Kubernetes k8s.container.memoryUtilization memoryUtilization Kubernetes k8s.container.memoryWorkingSetBytes memoryWorkingSetBytes Kubernetes k8s.container.requestedCpuCoresUtilization requestedCpuCoresUtilization Kubernetes k8s.container.requestedMemoryUtilization requestedMemoryUtilization Kubernetes k8s.container.restartCount restartCount Kubernetes k8s.daemonset.createdAt createdAt Kubernetes k8s.daemonset.metadataGeneration metadataGeneration Kubernetes k8s.daemonset.podsAvailable podsAvailable Kubernetes k8s.daemonset.podsDesired podsDesired Kubernetes k8s.daemonset.podsMisscheduled podsMisscheduled Kubernetes k8s.daemonset.podsReady podsReady Kubernetes k8s.daemonset.podsScheduled podsScheduled Kubernetes k8s.daemonset.podsUnavailable podsUnavailable Kubernetes k8s.daemonset.podsUpdatedScheduled podsUpdatedScheduled Kubernetes k8s.deployment.createdAt createdAt Kubernetes k8s.deployment.podsAvailable podsAvailable Kubernetes k8s.deployment.podsDesired podsDesired Kubernetes k8s.deployment.podsMaxUnavailable podsMaxUnavailable Kubernetes k8s.deployment.podsTotal podsTotal Kubernetes k8s.deployment.podsUnavailable podsUnavailable Kubernetes k8s.deployment.podsUpdated podsUpdated Kubernetes k8s.endpoint.addressAvailable addressAvailable Kubernetes k8s.endpoint.addressNotReady addressNotReady Kubernetes k8s.endpoint.createdAt createdAt Kubernetes k8s.namespace.createdAt createdAt Kubernetes k8s.node.allocatableAttachableVolumes* allocatableAttachableVolumes* Kubernetes k8s.node.allocatableCpuCores allocatableCpuCores Kubernetes k8s.node.allocatableCpuCoresUtilization allocatableCpuCoresUtilization Kubernetes k8s.node.allocatableEphemeralStorageBytes allocatableEphemeralStorageBytes Kubernetes k8s.node.allocatableHugepages* allocatableHugepages* Kubernetes k8s.node.allocatableMemoryBytes allocatableMemoryBytes Kubernetes k8s.node.allocatableMemoryUtilization allocatableMemoryUtilization Kubernetes k8s.node.allocatablePods allocatablePods Kubernetes k8s.node.capacityAttachableVolumes* capacityAttachableVolumes* Kubernetes k8s.node.capacityCpuCores capacityCpuCores Kubernetes k8s.node.capacityEphemeralStorageBytes capacityEphemeralStorageBytes Kubernetes k8s.node.capacityHugepages* capacityHugepages* Kubernetes k8s.node.capacityMemoryBytes capacityMemoryBytes Kubernetes k8s.node.capacityPods capacityPods Kubernetes k8s.node.cpuUsedCoreMilliseconds cpuUsedCoreMilliseconds Kubernetes k8s.node.cpuUsedCores cpuUsedCores Kubernetes k8s.node.fsAvailableBytes fsAvailableBytes Kubernetes k8s.node.fsCapacityBytes fsCapacityBytes Kubernetes k8s.node.fsCapacityUtilization fsCapacityUtilization Kubernetes k8s.node.fsInodes fsInodes Kubernetes k8s.node.fsInodesFree fsInodesFree Kubernetes k8s.node.fsInodesUsed fsInodesUsed Kubernetes k8s.node.fsUsedBytes fsUsedBytes Kubernetes k8s.node.memoryAvailableBytes memoryAvailableBytes Kubernetes k8s.node.memoryMajorPageFaultsPerSecond memoryMajorPageFaultsPerSecond Kubernetes k8s.node.memoryPageFaults memoryPageFaults Kubernetes k8s.node.memoryRssBytes memoryRssBytes Kubernetes k8s.node.memoryUsedBytes memoryUsedBytes Kubernetes k8s.node.memoryWorkingSetBytes memoryWorkingSetBytes Kubernetes k8s.node.netErrorsPerSecond net.errorsPerSecond Kubernetes k8s.node.netRxBytesPerSecond net.rxBytesPerSecond Kubernetes k8s.node.netTxBytesPerSecond net.txBytesPerSecond Kubernetes k8s.node.runtimeAvailableBytes runtimeAvailableBytes Kubernetes k8s.node.runtimeCapacityBytes runtimeCapacityBytes Kubernetes k8s.node.runtimeInodes runtimeInodes Kubernetes k8s.node.runtimeInodesFree runtimeInodesFree Kubernetes k8s.node.runtimeInodesUsed runtimeInodesUsed Kubernetes k8s.node.runtimeUsedBytes runtimeUsedBytes Kubernetes k8s.pod.createdAt createdAt Kubernetes k8s.pod.isReady isReady Kubernetes k8s.pod.isScheduled isScheduled Kubernetes k8s.pod.netErrorsPerSecond net.errorsPerSecond Kubernetes k8s.pod.netRxBytesPerSecond net.rxBytesPerSecond Kubernetes k8s.pod.netTxBytesPerSecond net.txBytesPerSecond Kubernetes k8s.pod.startTime startTime Kubernetes k8s.replicaset.createdAt createdAt Kubernetes k8s.replicaset.observedGeneration observedGeneration Kubernetes k8s.replicaset.podsDesired podsDesired Kubernetes k8s.replicaset.podsFullyLabeled podsFullyLabeled Kubernetes k8s.replicaset.podsMissing podsMissing Kubernetes k8s.replicaset.podsReady podsReady Kubernetes k8s.replicaset.podsTotal podsTotal Kubernetes k8s.service.createdAt createdAt Kubernetes k8s.statefulset.createdAt createdAt Kubernetes k8s.statefulset.currentRevision currentRevision Kubernetes k8s.statefulset.metadataGeneration metadataGeneration Kubernetes k8s.statefulset.observedGeneration observedGeneration Kubernetes k8s.statefulset.podsCurrent podsCurrent Kubernetes k8s.statefulset.podsDesired podsDesired Kubernetes k8s.statefulset.podsReady podsReady Kubernetes k8s.statefulset.podsTotal podsTotal Kubernetes k8s.statefulset.podsUpdated podsUpdated Kubernetes k8s.statefulset.updateRevision updateRevision Kubernetes k8s.volume.fsAvailableBytes fsAvailableBytes Kubernetes k8s.volume.fsCapacityBytes fsCapacityBytes Kubernetes k8s.volume.fsInodes fsInodes Kubernetes k8s.volume.fsInodesFree fsInodesFree Kubernetes k8s.volume.fsInodesUsed fsInodesUsed Kubernetes k8s.volume.fsUsedBytes fsUsedBytes Kubernetes k8s.volume.fsUsedPercent fsUsedPercent Memcached memcached.server.activeSlabs activeSlabs Memcached memcached.server.avgItemSizeInBytes avgItemSizeInBytes Memcached memcached.server.bytesReadServerPerSecond bytesReadServerPerSecond Memcached memcached.server.bytesUsedServerInBytes bytesUsedServerInBytes Memcached memcached.server.bytesWrittenServerPerSecond bytesWrittenServerPerSecond Memcached memcached.server.casHitRatePerSecond casHitRatePerSecond Memcached memcached.server.casMissRatePerSecond casMissRatePerSecond Memcached memcached.server.casWrongRatePerSecond casWrongRatePerSecond Memcached memcached.server.cmdFlushRatePerSecond cmdFlushRatePerSecond Memcached memcached.server.cmdGetRatePerSecond cmdGetRatePerSecond Memcached memcached.server.cmdSetRatePerSecond cmdSetRatePerSecond Memcached memcached.server.connectionRateServerPerSecond connectionRateServerPerSecond Memcached memcached.server.connectionStructuresAllocated connectionStructuresAllocated Memcached memcached.server.currentItemsStoredServer currentItemsStoredServer Memcached memcached.server.deleteCmdNoneRemovedPerSecond deleteCmdNoneRemovedPerSecond Memcached memcached.server.deleteCmdRemovedPerSecond deleteCmdRemovedPerSecond Memcached memcached.server.evictionsPerSecond evictionsPerSecond Memcached memcached.server.getHitPercent getHitPercent Memcached memcached.server.getHitPerSecond getHitPerSecond Memcached memcached.server.getMissPerSecond getMissPerSecond Memcached memcached.server.itemsStoredPerSecond itemsStoredPerSecond Memcached memcached.server.limitBytesStorage limitBytesStorage Memcached memcached.server.limitMaxBytes limitMaxBytes Memcached memcached.server.maxConnectionLimitPerSecond serverMaxConnectionLimitPerSecond Memcached memcached.server.memAllocatedSlabsInBytes memAllocatedSlabsInBytes Memcached memcached.server.openConnectionsServer openConnectionsServer Memcached memcached.server.pointerSize pointerSize Memcached memcached.server.rusageSystem usageRate Memcached memcached.server.rusageUser executionTime Memcached memcached.server.storingItemsPercentMemory storingItemsPercentMemory Memcached memcached.server.threads threads Memcached memcached.server.uptimeInMilliseconds uptimeInMilliseconds Memcached memcached.slab.activeItemsBumpedPerSecond activeItemsBumpedPerSecond Memcached memcached.slab.casBadValPerSecond casBadValPerSecond Memcached memcached.slab.casModifiedSlabPerSecond casModifiedSlabPerSecond Memcached memcached.slab.chunkSizeInBytes chunkSizeInBytes Memcached memcached.slab.chunksPerPage chunksPerPage Memcached memcached.slab.cmdSetRateSlabPerSecond cmdSetRateSlabPerSecond Memcached memcached.slab.decrsModifySlabPerSecond decrsModifySlabPerSecond Memcached memcached.slab.deleteRateSlabPerSecond deleteRateSlabPerSecond Memcached memcached.slab.entriesReclaimedPerSecond entriesReclaimedPerSecond Memcached memcached.slab.evictionsBeforeExpirationPerSecond evictionsBeforeExpirationPerSecond Memcached memcached.slab.evictionsBeforeExplicitExpirationPerSecond evictionsBeforeExplicitExpirationPerSecond Memcached memcached.slab.expiredItemsReclaimedPerSecond expiredItemsReclaimedPerSecond Memcached memcached.slab.freedChunks freedChunks Memcached memcached.slab.freedChunksEnd freedChunksEnd Memcached memcached.slab.getHitRateSlabPerSecond getHitRateSlabPerSecond Memcached memcached.slab.incrsModifySlabPerSecond incrsModifySlabPerSecond Memcached memcached.slab.itemsCold itemsCold Memcached memcached.slab.itemsColdPerSecond itemsColdPerSecond Memcached memcached.slab.itemsDirectReclaimedPerSecond itemsDirectReclaimedPerSecond Memcached memcached.slab.itemsFreedCrawlerPerSecond itemsFreedCrawlerPerSecond Memcached memcached.slab.itemsHot itemsHot Memcached memcached.slab.itemsOldestInMilliseconds itemsOldestInMilliseconds Memcached memcached.slab.itemsRefcountLockedPerSecond itemsRefcountLockedPerSecond Memcached memcached.slab.itemsSlabClass itemsSlabClass Memcached memcached.slab.itemsTimeSinceEvictionInMilliseconds itemsTimeSinceEvictionInMilliseconds Memcached memcached.slab.itemsWarm itemsWarm Memcached memcached.slab.itemsWarmPerSecond itemsWarmPerSecond Memcached memcached.slab.memRequestedSlabInBytesPerSecond memRequestedSlabInBytesPerSecond Memcached memcached.slab.outOfMemoryPerSecond outOfMemoryPerSecond Memcached memcached.slab.selfHealedSlabPerSecond selfHealedSlabPerSecond Memcached memcached.slab.totalChunksSlab totalChunksSlab Memcached memcached.slab.totalPagesSlab totalPagesSlab Memcached memcached.slab.touchHitSlabPerSecond touchHitSlabPerSecond Memcached memcached.slab.usedChunksItems usedChunksItems Memcached memcached.slab.usedChunksPerSecond usedChunksPerSecond Memcached memcached.slab.validItemsEvictedPerSecond validItemsEvictedPerSecond MongoDB mongo.index.accesses collection.indexAccesses MongoDB mongo.index.sizeInBytes collection.indexSizeInBytes MongoDB mongo.collection.avgObjSizeInBytes collection.avgObjSizeInBytes MongoDB mongo.collection.capped collection.capped MongoDB mongo.collection.count collection.count MongoDB mongo.collection.max collection.max MongoDB mongo.collection.maxSizeInBytes collection.maxSizeInBytes MongoDB mongo.collection.nindexes collection.nindexes MongoDB mongo.collection.sizeInBytes collection.sizeInBytes MongoDB mongo.collection.storageSizeInBytes collection.storageSizeInBytes MongoDB mongo.configServer.asserts.messagesPerSecond asserts.messagesPerSecond MongoDB mongo.configServer.asserts.regularPerSecond asserts.regularPerSecond MongoDB mongo.configServer.asserts.rolloversPerSecond asserts.rolloversPerSecond MongoDB mongo.configServer.asserts.userPerSecond asserts.userPerSecond MongoDB mongo.configServer.asserts.warningPerSecond asserts.warningPerSecond MongoDB mongo.configServer.commands.countFailedPerSecond commands.countFailedPerSecond MongoDB mongo.configServer.commands.countPerSecond commands.countPerSecond MongoDB mongo.configServer.commands.createIndexesFailedPerSecond commands.createIndexesFailedPerSecond MongoDB mongo.configServer.commands.createIndexesPerSecond commands.createIndexesPerSecond MongoDB mongo.configServer.commands.deleteFailedPerSecond commands.deleteFailedPerSecond MongoDB mongo.configServer.commands.deletePerSecond commands.deletePerSecond MongoDB mongo.configServer.commands.evalFailedPerSecond commands.evalFailedPerSecond MongoDB mongo.configServer.commands.evalPerSecond commands.evalPerSecond MongoDB mongo.configServer.commands.findAndModifyFailedPerSecond commands.findAndModifyFailedPerSecond MongoDB mongo.configServer.commands.findAndModifyPerSecond commands.findAndModifyPerSecond MongoDB mongo.configServer.commands.insertFailedPerSecond commands.insertFailedPerSecond MongoDB mongo.configServer.commands.insertPerSecond commands.insertPerSecond MongoDB mongo.configServer.commands.updateFailedPerSecond commands.updateFailedPerSecond MongoDB mongo.configServer.commands.updatePerSecond commands.updatePerSecond MongoDB mongo.configServer.connections.available connections.available MongoDB mongo.configServer.connections.current connections.current MongoDB mongo.configServer.connections.totalCreated connections.totalCreated MongoDB mongo.configServer.cursor.openNoTimeout cursor.openNoTimeout MongoDB mongo.configServer.cursor.openPinned cursor.openPinned MongoDB mongo.configServer.cursor.openTotal cursor.openTotal MongoDB mongo.configServer.cursor.timedOutPerSecond cursor.timedOutPerSecond MongoDB mongo.configServer.document.deletedPerSecond document.deletedPerSecond MongoDB mongo.configServer.document.insertedPerSecond document.insertedPerSecond MongoDB mongo.configServer.document.returnedPerSecond document.returnedPerSecond MongoDB mongo.configServer.document.updatedPerSecond document.updatedPerSecond MongoDB mongo.configServer.dur.commits dur.commits MongoDB mongo.configServer.dur.commitsInWriteLock dur.commitsInWriteLock MongoDB mongo.configServer.dur.compression dur.compression MongoDB mongo.configServer.dur.earlyCommits dur.earlyCommits MongoDB mongo.configServer.dur.preparingInMilliseconds dur.preparingInMilliseconds MongoDB mongo.configServer.dur.remappingInMilliseconds dur.remappingInMilliseconds MongoDB mongo.configServer.dur.timeCollectedCommitsInMilliseconds dur.timeCollectedCommitsInMilliseconds MongoDB mongo.configServer.dur.writingDataFilesInMilliseconds dur.writingDataFilesInMilliseconds MongoDB mongo.configServer.dur.writingJournalInMilliseconds dur.writingJournalInMilliseconds MongoDB mongo.configServer.flush.averageInMilliseconds flush.averageInMilliseconds MongoDB mongo.configServer.flush.flushesDisk flush.flushesDisk MongoDB mongo.configServer.flush.lastInMilliseconds flush.lastInMilliseconds MongoDB mongo.configServer.flush.totalInMilliseconds flush.totalInMilliseconds MongoDB mongo.configServer.getlasterror.wtimeMillisPerSecond getlasterror.wtimeMillisPerSecond MongoDB mongo.configServer.getlasterror.wtimeoutsPerSecond getlasterror.wtimeoutsPerSecond MongoDB mongo.configServer.globallock.activeClientsReaders globallock.activeClientsReaders MongoDB mongo.configServer.globallock.activeClientsTotal globallock.activeClientsTotal MongoDB mongo.configServer.globallock.activeClientsWriters globallock.activeClientsWriters MongoDB mongo.configServer.globallock.currentQueueReaders globallock.currentQueueReaders MongoDB mongo.configServer.globallock.currentQueueTotal globallock.currentQueueTotal MongoDB mongo.configServer.globallock.currentQueueWriters globallock.currentQueueWriters MongoDB mongo.configServer.globallock.totalTime globallock.totaltime MongoDB mongo.configServer.locks.collectionAcquireExclusive locks.collectionAcquireExclusive MongoDB mongo.configServer.locks.collectionAcquireIntentExclusive locks.collectionAcquireIntentExclusive MongoDB mongo.configServer.locks.collectionAcquireIntentShared locks.collectionAcquireIntentShared MongoDB mongo.configServer.locks.collectionAcquireWaitCountExclusive locks.collectionAcquireWaitCountExclusive MongoDB mongo.configServer.locks.collectionTimeAcquiringMicrosExclusive locks.collectionTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.databaseAcquireExclusive locks.databaseAcquireExclusive MongoDB mongo.configServer.locks.databaseAcquireIntentExclusive locks.databaseAcquireIntentExclusive MongoDB mongo.configServer.locks.databaseAcquireIntentShared locks.databaseAcquireIntentShared MongoDB mongo.configServer.locks.databaseAcquireShared locks.databaseAcquireShared MongoDB mongo.configServer.locks.databaseAcquireWaitExclusive locks.databaseAcquireWaitExclusive MongoDB mongo.configServer.locks.databaseAcquireWaitIntentExclusive locks.databaseAcquireWaitIntentExclusive MongoDB mongo.configServer.locks.databaseAcquireWaitIntentShared locks.databaseAcquireWaitIntentShared MongoDB mongo.configServer.locks.databaseAcquireWaitShared locks.databaseAcquireWaitShared MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosExclusive locks.databaseTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosIntentExclusive locks.databaseTimeAcquiringMicrosIntentExclusive MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosIntentShared locks.databaseTimeAcquiringMicrosIntentShared MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosShared locks.databaseTimeAcquiringMicrosShared MongoDB mongo.configServer.locks.globalAcquireExclusive locks.globalAcquireExclusive MongoDB mongo.configServer.locks.globalAcquireIntentExclusive locks.globalAcquireIntentExclusive MongoDB mongo.configServer.locks.globalAcquireIntentShared locks.globalAcquireIntentShared MongoDB mongo.configServer.locks.globalAcquireShared locks.globalAcquireShared MongoDB mongo.configServer.locks.globalAcquireWaitExclusive locks.globalAcquireWaitExclusive MongoDB mongo.configServer.locks.globalAcquireWaitIntentExclusive locks.globalAcquireWaitIntentExclusive MongoDB mongo.configServer.locks.globalAcquireWaitIntentShared locks.globalAcquireWaitIntentShared MongoDB mongo.configServer.locks.globalAcquireWaitShared locks.globalAcquireWaitShared MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosExclusive locks.globalTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosIntentExclusive locks.globalTimeAcquiringMicrosIntentExclusive MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosIntentShared locks.globalTimeAcquiringMicrosIntentShared MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosShared locks.globalTimeAcquiringMicrosShared MongoDB mongo.configServer.locks.metadataAcquireExclusive locks.metadataAcquireExclusive MongoDB mongo.configServer.locks.oplogAcquireExclusive locks.oplogAcquireExclusive MongoDB mongo.configServer.locks.oplogAcquireIntentExclusive locks.oplogAcquireIntentExclusive MongoDB mongo.configServer.locks.oplogAcquireIntentShared locks.oplogAcquireIntentShared MongoDB mongo",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.66881,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": "New Relic Integrations Metrics The following table contains the metrics we collect for our <em>infrastructure</em> integrations. Integration Dimensional Metric Name (new) Sample Metric Name (previous) Agent host.cpuIdlePercent cpuIdlePercent Agent host.cpuIoWaitPercent cpuIOWaitPercent Agent host.cpuPercent"
      },
      "id": "603e8a8a64441f69a34e8841"
    },
    {
      "sections": [
        "Default infrastructure monitoring data",
        "Important",
        "Infrastructure events",
        "Supported Linux storage systems",
        "Supported Windows storage systems",
        "Query infrastructure data",
        "Manage data",
        "Add custom attributes",
        "Common Amazon EC2 attributes",
        "awsRegion",
        "awsAvailabilityZone",
        "ec2InstanceType",
        "ec2InstanceId",
        "ec2AmiId",
        "ec2SubnetId",
        "ec2VpcId",
        "Other Amazon EC2 attributes"
      ],
      "title": "Default infrastructure monitoring data ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "01647189a48892103f4dc6abe07ce29d5fc13f0d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/default-infrastructure-monitoring-data/",
      "published_at": "2021-06-14T21:14:34Z",
      "updated_at": "2021-03-30T08:36:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of April 12, 2021, we are upgrading Insights to an improved web and mobile experience! All of your Insights URLs will be redirected automatically to the corresponding dashboards in New Relic One. For more details about this migration and how you can easily plan for this transition, see our Explorers Hub post. New Relic's infrastructure monitoring agent collects and displays data using six primary events, each with associated attributes that represent assorted metrics and metadata. Understanding infrastructure data can help you: Better understand our infrastructure monitoring UI. Manage your infrastructure data. Create better host filter sets. Run better queries of your data. Set up better monitoring solutions using custom attributes. Infrastructure events The following are events reported by default by the infrastructure agent and some infrastructure integrations. The attributes attached to these events are the metadata and metrics used to create our infrastructure UI visualizations. You can also create custom queries and charts of this data. If you're using integrations, see that integration's doc for more on reported data. For common AWS attributes, see AWS data. Select an event name in the following table to see its attributes. Event Description SystemSample SystemSample contains data describing the current overall state of the entire server, including CPU, memory, disk, and network. We take a snapshot of this data every 5 seconds and package it into a SystemSample event, which is then sent to New Relic. This data appears in the Hosts UI page. ProcessSample ProcessSample gathers detailed resource usage information from programs running on a single system. We take a snapshot of this data every 20 seconds for every active process and package it into a ProcessSample event, which is then sent to New Relic. This data appears on the Processes UI page. Important Process metrics are not sent to New Relic by default for accounts created after July 20, 2020. Enable process metrics to get this data into the Infrastructure monitoring UI. StorageSample StorageSample represents a single storage device associated with a server. Each sample gathers descriptive information about the device, the type of file system it uses, and its current usage and capacity. We take a snapshot of this data every 20 seconds for each mounted file system and package it into a StorageSample event, which is then sent to New Relic. This data appears on the Storage UI page. Important If your server uses disks with file systems other than the supported file systems in the following table, StorageSample events will not be generated for those disks. Supported Linux storage systems Supported Linux storage file systems: xfs vxfs btrfs ext ext2 ext3 ext4 hfs Supported Windows storage systems Supported Windows storage file systems: NTFS ReFS (version 1.0.976 and higher) NetworkSample NetworkSample captures the descriptive and state information for each network device associated with a server. It includes the device's interface and address information, as well as current usage data. We take a snapshot of this data every 10 seconds for each attached network interface and package it into a NetworkSample event, which is then sent to New Relic. This data appears on the Network UI page. ContainerSample ContainerSample collects the descriptive and state information for each Docker container. It includes the container's ID, name, image, image name, as well metrics about CPU, memory and networking. We take a snapshot of this data every 15 seconds for each container and package it into a ContainerSample event, which is then sent to New Relic. This data appears on the Containers UI page. For more information, see Docker monitoring. InfrastructureEvent InfrastructureEvent describes changes (deltas) that occur in a system's live state. When an inventory or system state is added, removed, or changed, New Relic will produce an InfrastructureEvent that logs that activity. This data appears on the Events UI page. To learn about infrastructure integration data, see the documentation for a specific integration. If an AWS integration is enabled, your infrastructure events may also have AWS attributes attached. Query infrastructure data You can query your infrastructure data to troubleshoot a problem or create a chart, or to understand what data is available. For example, to see what data is attached to ProcessSample, you would run this NRQL query: SELECT * FROM ProcessSample Copy You can also query infrastructure using dimensional metrics. Manage data For tips on managing data ingest and reporting, see Manage infrastructure data. Add custom attributes You can create custom attributes in the infrastructure agent's YAML file. Use this metadata to: Create infrastructure filter sets Populate the Group by menu Annotate your infrastructure data Common Amazon EC2 attributes If you connect your Amazon Elastic Compute Cloud (EC2) account to our infrastructure monitoring, we report data from your Amazon EC2 instances. Amazon EC2-related attributes are common attributes that can be used in any event. These attributes are drawn from the EC2 API. No CloudWatch information is collected. These attributes and their values are subject to change if Amazon changes the data they expose. awsRegion The region (determined by Amazon Web Services) where the AWS server exists. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. awsAvailabilityZone The availability zone (determined by Amazon Web Services) where the AWS server exists. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2InstanceType The Amazon Web Services instance type, displayed in AWS-specific codes. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2InstanceId The Amazon Web Services instance's unique identifying number for the server. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2AmiId The Amazon Machine Image (AMI) identification number of the image used by Amazon Web Services to bootstrap the Amazon EC2 instance. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2SubnetId The networking sub-net identifier on which the server is connected. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2VpcId The Virtual Private Cloud identifier (if any) for this server. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. Other Amazon EC2 attributes If Amazon Web Services changes the metadata they make available to New Relic, other attributes and values collected also may be available.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 110.989,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Default <em>infrastructure</em> monitoring <em>data</em> ",
        "sections": "Default <em>infrastructure</em> monitoring <em>data</em>",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": ". <em>Manage</em> <em>your</em> <em>infrastructure</em> <em>data</em>. Create better host <em>filter</em> sets. Run better queries of <em>your</em> <em>data</em>. Set up better monitoring solutions using custom attributes. <em>Infrastructure</em> events The following are events reported by default by the <em>infrastructure</em> agent and some <em>infrastructure</em> integrations"
      },
      "id": "6043edcd28ccbcfa8a2c6086"
    }
  ],
  "/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/alert-infrastructure-processes": [
    {
      "sections": [
        "REST API calls for infrastructure alerts",
        "Requirements",
        "Tip",
        "Using infrastructure API calls",
        "GET infrastructure conditions",
        "GET a list of infrastructure conditions",
        "Example GET a list of conditions",
        "GET a specific infrastructure condition",
        "Example GET a specific condition",
        "Create (POST) an infrastructure condition",
        "Important",
        "Update (PUT) an infrastructure condition",
        "Example update (PUT) a condition",
        "Remove (DELETE) an infrastructure condition",
        "Types of conditions",
        "Process running conditions API data",
        "Example condition types",
        "Metric conditions API data",
        "Example",
        "Host not reporting condition",
        "Definitions",
        "value",
        "duration_minutes",
        "time_function"
      ],
      "title": "REST API calls for infrastructure alerts",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "c35aa43cdb6645473d02886a49d6f9aeb37e577f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/rest-api-calls-new-relic-infrastructure-alerts/",
      "published_at": "2021-06-15T02:33:21Z",
      "updated_at": "2021-04-06T06:04:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the infrastructure REST API to add, update, delete, and list alerting conditions. You can also manage individual alerting conditions using the infrastructure monitoring UI. REST API calls for infrastructure alerts are not available in the API Explorer. Why use the API Examples Consistency Define the same set of conditions for every cluster without having to set up identical conditions in the Infrastructure monitoring UI each time. Manage multiple conditions quickly, without having to update them one by one using the UI. Flexibility Create conditions for an arbitrary group of hosts. Disable or delete conditions for hosts taken offline anytime. Create a condition with exclusionary filtering (for instance, environment NOT LIKE x). For more on this, see this post on exclusion filtering. For AWS Cloud integrations, select attributes that haven't been sent up by AWS yet. Create compound alert conditions by using the where_clause, which allows you to specify the limits on a secondary or tertiary metric. Exceed the 500-facet limitation on NRQL alert conditions. Reliability Audit when a condition was last updated. Requirements In order to use the Infrastructure REST API, you need: An API key The alerting condition's related policy_id from New Relic, available via GET list of conditions or via the Alerts REST API The condition id, available via GET list of conditions, or via the condition's URL in the Infrastructure monitoring UI Tip If your account hosts data in the EU data center, make sure you are using the proper API endpoints for EU region accounts. Using infrastructure API calls Here are some basic cURL commands and their responses for Infrastructure alert conditions. Depending on the type of condition, the DATA information you provide in the call will vary for POST (add) and PUT (update) calls. Definitions of each attribute used in the data blocks can be found in the Definitions section. GET infrastructure conditions You can either GET a list of infrastructure conditions or GET a specific infrastructure condition. Here are a few tips for listing infrastructure conditions. For pagination, use limit (records per page) and offset (how many records to skip) parameters. Default is 50 records per page, and offset starts at 0 (skip no records). To scope the results to a specific policy, use policy_id. Tip If you want to use the GET response as a template for your PUT or POST input, be sure to remove the created_at_epoch_millis, updated_at_epoch_millis and id information. GET a list of infrastructure conditions curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions?policy_id=111111\" Copy Example GET a list of conditions Response showing 2 of the 3 conditions for the example policy (formatted for readability and truncated): HTTP/1.1 200 OK Content-Length: 622 Content-Type: application/json { \"data\":[ { \"type\":\"infra_process_running\", \"name\":\"Java is running\", \"enabled\":true, \"where_clause\":\"(`hostname` LIKE '%cassandra%')\", \"id\":13890, \"created_at_epoch_millis\":1490996713872, \"updated_at_epoch_millis\":1490996713872, \"policy_id\":111111, \"comparison\":\"equal\", \"critical_threshold\":{ \"value\":0, \"duration_minutes\":6 }, \"process_where_clause\":\"(`commandName` = 'java')\" }, { \"created_at_epoch_millis\": 1501704525462, \"critical_threshold\": { \"duration_minutes\": 5 }, \"enabled\": true, \"filter\": { \"and\": [ { \"like\": { \"fullHostname\": \"Production_1\" } } ] }, \"id\": 448036, \"name\": \"PROD - Host Machine's Agent Not Responding ....\", \"policy_id\": 98485, \"type\": \"infra_host_not_reporting\", \"updated_at_epoch_millis\": 1504879191220 } . . . ], \"meta\":{ \"limit\":50, \"offset\":0, \"total\":3 }, \"links\":{} } Copy To get a list of the 10 Infrastructure conditions beyond the 50 limit: curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions?policy_id=111111&offset=50&list=10\" Copy GET a specific infrastructure condition To get information about a single Infrastructure condition: curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions/condition-id\" Copy Example GET a specific condition Response (formatted for readability): HTTP/1.1 200 OK Content-Length: 246 Content-Type: application/json { \"data\":{ \"type\":\"infra_host_not_reporting\", \"name\":\"demo condition\", \"enabled\":false, \"id\":13887, \"created_at_epoch_millis\":1490981583580, \"updated_at_epoch_millis\":1490981583580, \"policy_id\":23635, \"critical_threshold\":{ \"duration_minutes\":100 } } } Copy Create (POST) an infrastructure condition Important Do not include an \"id\": when adding a new condition (POST). It will be generated when the condition is created. To add an infrastructure condition, use this basic cURL command: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{\"data\":{DATA object details}}' Copy Include details in the DATA object (-d \\ section) for the type of infrastructure condition you are adding: Process running conditions API data Metric conditions API data Host not reporting conditions API data Update (PUT) an infrastructure condition You only need to include the fields that need to be changed when updating an infrastructure condition. The API keeps the existing values for any missing fields. Important If you want to change the condition type, do not use PUT. Instead, delete the existing condition, then add (POST) a new condition with the new condition type and all fields. To update an infrastructure condition, use this basic cURL command. To indicate which condition is to be updated, be sure to include the \"id\": . Example update (PUT) a condition curl -X PUT 'https://infra-api.newrelic.com/v2/alerts/conditions/condition-id' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{\"data\":{DATA object details}}' Copy Include details in the DATA object (-d \\ section) for the type of infrastructure condition you are updating: Process running conditions API data Metric conditions API data Host not reporting conditions API data Remove (DELETE) an infrastructure condition To delete an infrastructure condition, use this basic cURL command: curl -v -X DELETE --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions/condition_id\" Copy Types of conditions Process running conditions API data A process running condition alerts you when the number of processes is above, below, or equal to the threshold you define. To add (POST) or update (PUT) a process running condition, use your API key, and refer to the definitions to customize your values in the API call. Example condition types For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_process_running\", \"name\":\"Java is running\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"comparison\":\"equal\", \"critical_threshold\":{ \"value\":0, \"duration_minutes\":6 }, \"process_where_clause\":\"(commandName = '\\''java'\\'')\" } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause and process_where_clause Metric conditions API data A metric condition alerts you when the metric of your choice is above, below, or equal to the threshold you define. This includes: System metrics Process metrics Network metrics Storage metrics Cloud integration metrics To add (POST) or update (PUT) a metric condition, use your API key, and refer to the definitions to customize your values in the API call. If you are adding or updating a cloud integration alert condition: For the event_type field, enter the event type generated by your selected cloud integration service (for example, ComputeSample for the AWS EC2 integration). If you are setting up an alert condition on a cloud integration service that requires a provider value (for example, AWS RDS uses DatastoreSample with a provider value of RdsDbInstance or RdsDbCluster), you will need to add the \"integration_provider\" field and use the value that is appropriate for the service your alert condition is targeting (for example, \"integration_provider\":\"RdsDbInstance\"). For the select_value field, build the metric name by using the following syntax, where provider is a standard prefix string: provider.metric.aggregation_type Copy metric: Use the metric name as described in the New Relic documentation for your integration. aggregation_type: Use Sum, Average, Minimum, or Maximum. Refer to the original documentation by the integration's cloud provider to see which statistic aggregations are available for each metric. Example For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_metric\", \"name\":\"Disk Space Condition\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"event_type\":\"StorageSample\", \"select_value\":\"diskFreePercent\", \"comparison\":\"below\", \"critical_threshold\":{ \"value\":10, \"duration_minutes\":1, \"time_function\":\"any\" }, \"warning_threshold\":{ \"value\":30, \"duration_minutes\":2, \"time_function\":\"any\" } } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause Host not reporting condition A host not reporting condition alerts you when a host stops reporting. To add (POST) or update (PUT) a host not reporting condition, use your API key, and refer to the definitions to customize your values in the API call. Example For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_host_not_reporting\", \"name\":\"Cassandra Host Reporting Condition\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"critical_threshold\":{ \"duration_minutes\":12 } } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause Definitions When formatting your cURL commands, use these values as needed. These are listed in alphabetical order, not the order they appear in your API calls. Field Definition comparison (enum) Condition type: infra_metric, infra_process_running The value used to define the threshold; for example, \"[\"above\", \"below\", \"equal\"]. critical_threshold and warning_threshold Condition type: all This object identifies the threshold value before opening a violation. The critical_threshold is required. The warning_threshold is optional and may only be used with infra_metric conditions. The keys of this object depend on the condition type. Condition type: infra_metric format: \"critical_threshold\":{ \"value\":<number>, \"duration_minutes\":<integer>, \"time_function\":\"any\" or \"all\" }, Copy Condition type: infra_process_running format: \"critical_threshold\":{ \"value\":<integer>, \"duration_minutes\":<integer>, }, Copy Condition type: infra_host_not_reporting format: \"critical_threshold\":{ \"duration_minutes\":<integer>, }, Copy value The numeric value that must be breached for the condition to open a violation duration_minutes The number of minutes the value must be passed or met for the condition to open a violation time_function Indicates if the condition needs to be sustained for a certain period of time to create a violation, or if it only needs to break the threshold once within a certain period of time. If you're setting up a for at least x minutes threshold, use all; for an at least once in x minutes threshold, use any. enabled (boolean) Condition type: all Whether the condition is turned on or off; true or false. event_type (string) Condition type: infra_metric The metric event; for example, system metrics, process metrics, storage metrics, or network metrics. This automatically populates for infrastructure integrations; for example, StorageSample or SystemSample. filter (string) Condition type: all If the condition was made in the UI, filter appears instead of where_clause; for example: {and: [{is: {ec2InstanceType: \"m3.medium\"}}]} Copy Recommendation: Use where_clause when creating a new condition. id (integer) Condition type: all The condition ID located in the URL. GET: This value appears in the GET response. PUT: Include this value in the DATA section. POST: Do not include this in the DATA section. DELETE: Include this value in the -X DELETE call. integration_provider (string) Condition type: infra_metric For alerts on integrations, use integration_provider instead of event_type. To see valid values: From the New Relic documentation for your cloud service, check the Find and use data section. Example: In the AWS RDS monitoring integration documentation, you can see that the DatastoreSample event type can be used with an integration_provider value of either RdsDbInstance for DB instances, or RdsDbCluster for Aurora DB clusters. name (string) Condition type: all The infrastructure alerting condition's name; for example: \"[test] process running\" Copy policy_id (integer) Condition type: all The unique ID for the alert policy's account ID associated with the condition; for example, 1234567890. This is not the policy's global ID. process_where_clause (string) Condition type: infra_process_running Any filters applied to processes, specifically in process running alert conditions. This parameter is mandatory for those types of alert conditions. For example: \"commandName = '\\''java'\\''\" Copy runbook_url (string) Condition type: all The runbook URL to display in notifications. select_value (string) Condition type: infra_metric The attribute name to identify the metric being targeted; for example, \"cpuPercent\", \"diskFreePercent\", \"memoryResidentSizeBytes\", or \"memoryFreeBytes/memoryTotalBytes*100\". This automatically populates for Infrastructure Integrations; for example, diskFreePercent. type (enum) Condition type: all The type of infrastructure alert condition: \"infra_process_running\", \"infra_metric\", or \"infra_host_not_reporting\". violation_close_timer (integer) Condition type: all The Violation time limit setting, expressed as hours. Possible values are 0, 1, 2, 4, 8,12, 24, 48, 72. This determines how much time will pass before a violation is automatically closed. Setting the time limit to 0 prevents a violation from being force-closed. For new conditions, if a value is not provided, the following default values are used: Host Not Responding (HNR) conditions: 0 (disabled) All other conditions: 24 When updating existing conditions, if a value is provided, it overrides the existing value, but does not affect already opened violations. where_clause (string) Condition type: all If applicable, this identifies any infrastructure host filters used; for example: \"(`hostname` LIKE '\\''%cassandra%'\\'')\", Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.25702,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>infrastructure</em> <em>alerts</em>",
        "sections": "REST API calls for <em>infrastructure</em> <em>alerts</em>",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "Use the <em>infrastructure</em> REST API to add, update, delete, and list alerting <em>conditions</em>. You can also manage individual alerting <em>conditions</em> using the <em>infrastructure</em> monitoring UI. REST API calls for <em>infrastructure</em> <em>alerts</em> are not available in the API Explorer. Why use the API Examples Consistency"
      },
      "id": "6043fa6c196a678ae2960f31"
    },
    {
      "sections": [
        "Create infrastructure \"host not reporting\" condition",
        "Features",
        "Create \"host not reporting\" condition",
        "Investigate the problem",
        "Intentional outages"
      ],
      "title": "Create infrastructure \"host not reporting\" condition",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "0a74e7e65e3eeb5268eac310c11802ca2e78a614",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-alerts/infrastructure-alert-conditions/create-infrastructure-host-not-reporting-condition/",
      "published_at": "2021-06-15T06:58:45Z",
      "updated_at": "2021-03-16T08:30:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use Infrastructure monitoring's Host not reporting condition to notify you when we've stopped receiving data from an infrastructure agent. This feature allows you to dynamically alert on groups of hosts, configure the time window from five to 60 minutes, and take full advantage of alerts notifications. Features You can define conditions based on the sets of hosts most important to you, and configure thresholds appropriate for each filter set. The Host not reporting event triggers when data from the infrastructure agent doesn't reach our collector within the time frame you specify. This feature's flexibility allows you to easily customize what to monitor and when to notify selected individuals or teams. In addition, the email notification includes links to help you quickly troubleshoot the situation. Host not reporting condition Features What to monitor You can use filter sets to select which hosts you want to be monitored with the alert condition. The condition will also automatically apply to any hosts you add in the future that match these filters. How to notify Conditions are contained in policies. You can select an existing policy or create a new policy with email notifications from the Infrastructure monitoring UI. If you want to create a new policy with other types of notification channels, use the UI. When to notify Email addresses (identified in the policy) will be notified automatically about threshold violations for any host matching the filters you have applied, depending on the policy's incident preferences. Where to troubleshoot The link at the top of the email notification will take you to the infrastructure Events page centered on the time when the host disconnected. Additional links in the email will take you to additional detail. Create \"host not reporting\" condition To define the Host not reporting condition criteria: Follow standard procedures to create an infrastructure condition. Select Host not reporting as the Alert type. Define the Critical threshold for triggering the notification: minimum 5 minutes, maximum 60 minutes. Enable 'Don't trigger alerts for hosts that perform a clean shutdown' option, if you want to prevent false alerts when you have hosts set to shut down via command line. Currently this feature is supported on all Windows systems and Linux systems using systemd. Depending on the policy's incident preferences, it will define which notification channels to use when the defined Critical threshold for the condition passes. To avoid \"false positives,\" the host must stop reporting for the entire time period before a violation is opened. Example: You create a condition to open a violation when any of the filtered set of hosts stop reporting data for seven minutes. If any host stops reporting for five minutes, then resumes reporting, the condition does not open a violation. If any host stops reporting for seven minutes, even if the others are fine, the condition does open a violation. Investigate the problem To further investigate why a host is not reporting data: Review the details in the email notification. Use the link from the email notification to monitor ongoing changes in your environment from Infrastructure monitoring's Events page. For example, use the Events page to help determine if a host disconnected right after a root user made a configuration change to the host. Optional: Use the email notification's Acknowledge link to verify you are aware of and taking ownership of the alerting incident. Use the email links to examine additional details in the Incident details page. Intentional outages We can distinguish between unexpected situations and planned situations with the option Don't trigger alerts for hosts that perform a clean shutdown. Use this option for situations such as: Host has been taken offline intentionally. Host has planned downtime for maintenance. Host has been shut down or decommissioned. Autoscaling hosts or shutting down instances in a cloud console. We rely on Linux and Windows shutdown signals to flag a clean shutdown. We've confirmed that these scenarios are detected by the agent: AWS Auto-scaling event with EC2 instances that use systemd (Amazon Linux, CentOs/RedHat 7 and newer, Ubuntu 16 and newer, Suse 12 and newer, Debian 9 and newer) User-initiated shutdown of Windows systems User-initiated shutdown of Linux systems that use systemd (Amazon Linux, CentOs/RedHat 7 and newer, Ubuntu 16 and newer, Suse 12 and newer, Debian 9 and newer) We know that these scenarios are not detected by the agent: User-initiated shutdown of Linux systems that don't use systemd (CentOs/RedHat 6 and earlier, Ubuntu 14, Debian 8). This includes other modern Linux systems that still use Upstart or SysV init systems. AWS Auto-scaling event with EC2 instances that don't use systemd (CentOs/RedHat 6 and earlier, Ubuntu 14, Debian 8). This includes other more modern Linux systems that still use Upstart or SysV init systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.89491,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create <em>infrastructure</em> &quot;host not reporting&quot; <em>condition</em>",
        "sections": "Create <em>infrastructure</em> &quot;host not reporting&quot; <em>condition</em>",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "Use <em>Infrastructure</em> monitoring&#x27;s Host not reporting condition to notify you when we&#x27;ve stopped receiving data from an <em>infrastructure</em> agent. This feature allows you to dynamically <em>alert</em> on groups of hosts, configure the time window from five to 60 minutes, and take full advantage of <em>alerts</em>"
      },
      "id": "603ea06c196a67cd47a83dc1"
    },
    {
      "sections": [
        "Infrastructure alerting examples",
        "Examples: Infrastructure pages",
        "Examples: Threshold options",
        "Integrations providers",
        "CPU, disk, load average, memory, swap",
        "Byte size"
      ],
      "title": "Infrastructure alerting examples",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "1ec5f86b745413b2a8d6a5b676ecbe622c674ab1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/infrastructure-alerting-examples/",
      "published_at": "2021-06-14T21:16:54Z",
      "updated_at": "2021-03-16T07:35:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Alert type field in infrastructure monitoring's Settings > Alerts page shows what options you can select to create infrastructure alert conditions. You can also create alert conditions from any infrastructure chart by selecting the ellipses icon and then Create alert. Examples: Infrastructure pages Here are some examples of how to create alert conditions within the context of the Infrastructure monitoring UI page you are currently viewing. To create an alerts condition from any chart, select the ellipses icon and then Create alert. New Relic will automatically select the appropriate Alert type. Example Problem and solution High CPU usage Problem: Your Ops team monitors a filtered set of host clusters in your eastern region and notices that the CPU usage is constantly high. Solution: Use the CPU chart on Infrastructure monitoring's Hosts page to create an alert condition for system metrics. Virtual memory capacity Problem: Your night shift needs to be alerted when virtual memory for a set of background workers reaches an average of 10G for at least two minutes. Solution: Use the Top memory consumers chart on Infrastructure monitoring's Processes page to create an alert condition for process metrics. Limited bandwidth Problem: You want to monitor performance based on the average number of errors received or transmitted. Solution: Use the Top bandwidth chart on Infrastructure monitoring's Network page to create an alert condition for network metrics. I/O read and write operations Problem: You are testing a new set of hosts in your staging environment, and you want to be notified when their read or write capacity rises above your test threshold level. Solution: Use the Top I/O operations chart on Infrastructure monitoring's Storage page to create an alert condition for storage metrics. Host not reporting Problem: You want to be notified when we have stopped receiving data from an infrastructure agent. Solution: From the Hosts, Processes, Network, or Storage pages, create a host not reporting alert condition. Processes not running as expected Problem: You want to be notified if any of the processes on your hosts stop reporting. OR A process you expected to start on a host (such as a new program) is not actually running. Solution: From the Processes page (or from the Hosts, Network, or Storage pages), create a process running alert condition. Examples: Threshold options Use the thresholds dropdown for the selected Alert type to further define how you want to be alerted. Here are some examples of the options available. Integrations providers With infrastructure integrations, you can create an alert condition from your Integrations page. Depending on the type of provider selected (CloudFront, DynamoDB, EBS, etc.), options will vary from the Define thresholds dropdown; for example, bytes, errors, requests, CPU, connections, memory, records, latency, etc. CPU, disk, load average, memory, swap The System metrics thresholds dropdown allows you to select various criteria for CPU, disk, load average, memory, and swap metrics. Byte size The Network metrics thresholds provide flexibility with your business needs. Depending on the size of your network, you can easily set the threshold in bytes, KB, MB, GB, or TB.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.88722,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>alerting</em> examples",
        "sections": "<em>Infrastructure</em> <em>alerting</em> examples",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "The <em>Alert</em> type field in <em>infrastructure</em> monitoring&#x27;s Settings &gt; <em>Alerts</em> page shows what options you can select to create <em>infrastructure</em> <em>alert</em> <em>conditions</em>. You can also create <em>alert</em> <em>conditions</em> from any <em>infrastructure</em> chart by selecting the ellipses icon and then Create <em>alert</em>. Examples: <em>Infrastructure</em>"
      },
      "id": "603eb52a28ccbc9027eba7bb"
    }
  ],
  "/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/infrastructure-alerting-examples": [
    {
      "sections": [
        "REST API calls for infrastructure alerts",
        "Requirements",
        "Tip",
        "Using infrastructure API calls",
        "GET infrastructure conditions",
        "GET a list of infrastructure conditions",
        "Example GET a list of conditions",
        "GET a specific infrastructure condition",
        "Example GET a specific condition",
        "Create (POST) an infrastructure condition",
        "Important",
        "Update (PUT) an infrastructure condition",
        "Example update (PUT) a condition",
        "Remove (DELETE) an infrastructure condition",
        "Types of conditions",
        "Process running conditions API data",
        "Example condition types",
        "Metric conditions API data",
        "Example",
        "Host not reporting condition",
        "Definitions",
        "value",
        "duration_minutes",
        "time_function"
      ],
      "title": "REST API calls for infrastructure alerts",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "c35aa43cdb6645473d02886a49d6f9aeb37e577f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/rest-api-calls-new-relic-infrastructure-alerts/",
      "published_at": "2021-06-15T02:33:21Z",
      "updated_at": "2021-04-06T06:04:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the infrastructure REST API to add, update, delete, and list alerting conditions. You can also manage individual alerting conditions using the infrastructure monitoring UI. REST API calls for infrastructure alerts are not available in the API Explorer. Why use the API Examples Consistency Define the same set of conditions for every cluster without having to set up identical conditions in the Infrastructure monitoring UI each time. Manage multiple conditions quickly, without having to update them one by one using the UI. Flexibility Create conditions for an arbitrary group of hosts. Disable or delete conditions for hosts taken offline anytime. Create a condition with exclusionary filtering (for instance, environment NOT LIKE x). For more on this, see this post on exclusion filtering. For AWS Cloud integrations, select attributes that haven't been sent up by AWS yet. Create compound alert conditions by using the where_clause, which allows you to specify the limits on a secondary or tertiary metric. Exceed the 500-facet limitation on NRQL alert conditions. Reliability Audit when a condition was last updated. Requirements In order to use the Infrastructure REST API, you need: An API key The alerting condition's related policy_id from New Relic, available via GET list of conditions or via the Alerts REST API The condition id, available via GET list of conditions, or via the condition's URL in the Infrastructure monitoring UI Tip If your account hosts data in the EU data center, make sure you are using the proper API endpoints for EU region accounts. Using infrastructure API calls Here are some basic cURL commands and their responses for Infrastructure alert conditions. Depending on the type of condition, the DATA information you provide in the call will vary for POST (add) and PUT (update) calls. Definitions of each attribute used in the data blocks can be found in the Definitions section. GET infrastructure conditions You can either GET a list of infrastructure conditions or GET a specific infrastructure condition. Here are a few tips for listing infrastructure conditions. For pagination, use limit (records per page) and offset (how many records to skip) parameters. Default is 50 records per page, and offset starts at 0 (skip no records). To scope the results to a specific policy, use policy_id. Tip If you want to use the GET response as a template for your PUT or POST input, be sure to remove the created_at_epoch_millis, updated_at_epoch_millis and id information. GET a list of infrastructure conditions curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions?policy_id=111111\" Copy Example GET a list of conditions Response showing 2 of the 3 conditions for the example policy (formatted for readability and truncated): HTTP/1.1 200 OK Content-Length: 622 Content-Type: application/json { \"data\":[ { \"type\":\"infra_process_running\", \"name\":\"Java is running\", \"enabled\":true, \"where_clause\":\"(`hostname` LIKE '%cassandra%')\", \"id\":13890, \"created_at_epoch_millis\":1490996713872, \"updated_at_epoch_millis\":1490996713872, \"policy_id\":111111, \"comparison\":\"equal\", \"critical_threshold\":{ \"value\":0, \"duration_minutes\":6 }, \"process_where_clause\":\"(`commandName` = 'java')\" }, { \"created_at_epoch_millis\": 1501704525462, \"critical_threshold\": { \"duration_minutes\": 5 }, \"enabled\": true, \"filter\": { \"and\": [ { \"like\": { \"fullHostname\": \"Production_1\" } } ] }, \"id\": 448036, \"name\": \"PROD - Host Machine's Agent Not Responding ....\", \"policy_id\": 98485, \"type\": \"infra_host_not_reporting\", \"updated_at_epoch_millis\": 1504879191220 } . . . ], \"meta\":{ \"limit\":50, \"offset\":0, \"total\":3 }, \"links\":{} } Copy To get a list of the 10 Infrastructure conditions beyond the 50 limit: curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions?policy_id=111111&offset=50&list=10\" Copy GET a specific infrastructure condition To get information about a single Infrastructure condition: curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions/condition-id\" Copy Example GET a specific condition Response (formatted for readability): HTTP/1.1 200 OK Content-Length: 246 Content-Type: application/json { \"data\":{ \"type\":\"infra_host_not_reporting\", \"name\":\"demo condition\", \"enabled\":false, \"id\":13887, \"created_at_epoch_millis\":1490981583580, \"updated_at_epoch_millis\":1490981583580, \"policy_id\":23635, \"critical_threshold\":{ \"duration_minutes\":100 } } } Copy Create (POST) an infrastructure condition Important Do not include an \"id\": when adding a new condition (POST). It will be generated when the condition is created. To add an infrastructure condition, use this basic cURL command: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{\"data\":{DATA object details}}' Copy Include details in the DATA object (-d \\ section) for the type of infrastructure condition you are adding: Process running conditions API data Metric conditions API data Host not reporting conditions API data Update (PUT) an infrastructure condition You only need to include the fields that need to be changed when updating an infrastructure condition. The API keeps the existing values for any missing fields. Important If you want to change the condition type, do not use PUT. Instead, delete the existing condition, then add (POST) a new condition with the new condition type and all fields. To update an infrastructure condition, use this basic cURL command. To indicate which condition is to be updated, be sure to include the \"id\": . Example update (PUT) a condition curl -X PUT 'https://infra-api.newrelic.com/v2/alerts/conditions/condition-id' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{\"data\":{DATA object details}}' Copy Include details in the DATA object (-d \\ section) for the type of infrastructure condition you are updating: Process running conditions API data Metric conditions API data Host not reporting conditions API data Remove (DELETE) an infrastructure condition To delete an infrastructure condition, use this basic cURL command: curl -v -X DELETE --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions/condition_id\" Copy Types of conditions Process running conditions API data A process running condition alerts you when the number of processes is above, below, or equal to the threshold you define. To add (POST) or update (PUT) a process running condition, use your API key, and refer to the definitions to customize your values in the API call. Example condition types For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_process_running\", \"name\":\"Java is running\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"comparison\":\"equal\", \"critical_threshold\":{ \"value\":0, \"duration_minutes\":6 }, \"process_where_clause\":\"(commandName = '\\''java'\\'')\" } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause and process_where_clause Metric conditions API data A metric condition alerts you when the metric of your choice is above, below, or equal to the threshold you define. This includes: System metrics Process metrics Network metrics Storage metrics Cloud integration metrics To add (POST) or update (PUT) a metric condition, use your API key, and refer to the definitions to customize your values in the API call. If you are adding or updating a cloud integration alert condition: For the event_type field, enter the event type generated by your selected cloud integration service (for example, ComputeSample for the AWS EC2 integration). If you are setting up an alert condition on a cloud integration service that requires a provider value (for example, AWS RDS uses DatastoreSample with a provider value of RdsDbInstance or RdsDbCluster), you will need to add the \"integration_provider\" field and use the value that is appropriate for the service your alert condition is targeting (for example, \"integration_provider\":\"RdsDbInstance\"). For the select_value field, build the metric name by using the following syntax, where provider is a standard prefix string: provider.metric.aggregation_type Copy metric: Use the metric name as described in the New Relic documentation for your integration. aggregation_type: Use Sum, Average, Minimum, or Maximum. Refer to the original documentation by the integration's cloud provider to see which statistic aggregations are available for each metric. Example For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_metric\", \"name\":\"Disk Space Condition\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"event_type\":\"StorageSample\", \"select_value\":\"diskFreePercent\", \"comparison\":\"below\", \"critical_threshold\":{ \"value\":10, \"duration_minutes\":1, \"time_function\":\"any\" }, \"warning_threshold\":{ \"value\":30, \"duration_minutes\":2, \"time_function\":\"any\" } } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause Host not reporting condition A host not reporting condition alerts you when a host stops reporting. To add (POST) or update (PUT) a host not reporting condition, use your API key, and refer to the definitions to customize your values in the API call. Example For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_host_not_reporting\", \"name\":\"Cassandra Host Reporting Condition\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"critical_threshold\":{ \"duration_minutes\":12 } } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause Definitions When formatting your cURL commands, use these values as needed. These are listed in alphabetical order, not the order they appear in your API calls. Field Definition comparison (enum) Condition type: infra_metric, infra_process_running The value used to define the threshold; for example, \"[\"above\", \"below\", \"equal\"]. critical_threshold and warning_threshold Condition type: all This object identifies the threshold value before opening a violation. The critical_threshold is required. The warning_threshold is optional and may only be used with infra_metric conditions. The keys of this object depend on the condition type. Condition type: infra_metric format: \"critical_threshold\":{ \"value\":<number>, \"duration_minutes\":<integer>, \"time_function\":\"any\" or \"all\" }, Copy Condition type: infra_process_running format: \"critical_threshold\":{ \"value\":<integer>, \"duration_minutes\":<integer>, }, Copy Condition type: infra_host_not_reporting format: \"critical_threshold\":{ \"duration_minutes\":<integer>, }, Copy value The numeric value that must be breached for the condition to open a violation duration_minutes The number of minutes the value must be passed or met for the condition to open a violation time_function Indicates if the condition needs to be sustained for a certain period of time to create a violation, or if it only needs to break the threshold once within a certain period of time. If you're setting up a for at least x minutes threshold, use all; for an at least once in x minutes threshold, use any. enabled (boolean) Condition type: all Whether the condition is turned on or off; true or false. event_type (string) Condition type: infra_metric The metric event; for example, system metrics, process metrics, storage metrics, or network metrics. This automatically populates for infrastructure integrations; for example, StorageSample or SystemSample. filter (string) Condition type: all If the condition was made in the UI, filter appears instead of where_clause; for example: {and: [{is: {ec2InstanceType: \"m3.medium\"}}]} Copy Recommendation: Use where_clause when creating a new condition. id (integer) Condition type: all The condition ID located in the URL. GET: This value appears in the GET response. PUT: Include this value in the DATA section. POST: Do not include this in the DATA section. DELETE: Include this value in the -X DELETE call. integration_provider (string) Condition type: infra_metric For alerts on integrations, use integration_provider instead of event_type. To see valid values: From the New Relic documentation for your cloud service, check the Find and use data section. Example: In the AWS RDS monitoring integration documentation, you can see that the DatastoreSample event type can be used with an integration_provider value of either RdsDbInstance for DB instances, or RdsDbCluster for Aurora DB clusters. name (string) Condition type: all The infrastructure alerting condition's name; for example: \"[test] process running\" Copy policy_id (integer) Condition type: all The unique ID for the alert policy's account ID associated with the condition; for example, 1234567890. This is not the policy's global ID. process_where_clause (string) Condition type: infra_process_running Any filters applied to processes, specifically in process running alert conditions. This parameter is mandatory for those types of alert conditions. For example: \"commandName = '\\''java'\\''\" Copy runbook_url (string) Condition type: all The runbook URL to display in notifications. select_value (string) Condition type: infra_metric The attribute name to identify the metric being targeted; for example, \"cpuPercent\", \"diskFreePercent\", \"memoryResidentSizeBytes\", or \"memoryFreeBytes/memoryTotalBytes*100\". This automatically populates for Infrastructure Integrations; for example, diskFreePercent. type (enum) Condition type: all The type of infrastructure alert condition: \"infra_process_running\", \"infra_metric\", or \"infra_host_not_reporting\". violation_close_timer (integer) Condition type: all The Violation time limit setting, expressed as hours. Possible values are 0, 1, 2, 4, 8,12, 24, 48, 72. This determines how much time will pass before a violation is automatically closed. Setting the time limit to 0 prevents a violation from being force-closed. For new conditions, if a value is not provided, the following default values are used: Host Not Responding (HNR) conditions: 0 (disabled) All other conditions: 24 When updating existing conditions, if a value is provided, it overrides the existing value, but does not affect already opened violations. where_clause (string) Condition type: all If applicable, this identifies any infrastructure host filters used; for example: \"(`hostname` LIKE '\\''%cassandra%'\\'')\", Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.25702,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>infrastructure</em> <em>alerts</em>",
        "sections": "REST API calls for <em>infrastructure</em> <em>alerts</em>",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "Use the <em>infrastructure</em> REST API to add, update, delete, and list alerting <em>conditions</em>. You can also manage individual alerting <em>conditions</em> using the <em>infrastructure</em> monitoring UI. REST API calls for <em>infrastructure</em> <em>alerts</em> are not available in the API Explorer. Why use the API Examples Consistency"
      },
      "id": "6043fa6c196a678ae2960f31"
    },
    {
      "sections": [
        "Alert on infrastructure processes",
        "Important",
        "Examples",
        "Ensure enough processes are running to satisfy load",
        "Ensure that critical services run constantly",
        "Monitor startup for critical processes that require special attention",
        "Make sure a job doesn't take too long",
        "Validate that services started successfully",
        "Watch for runaway processes or configuration problems",
        "Create an infrastructure process running condition"
      ],
      "title": "Alert on infrastructure processes",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "5fcbe11b9beb16723ff2521fca981f19a4c716ce",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/alert-infrastructure-processes/",
      "published_at": "2021-06-15T02:33:23Z",
      "updated_at": "2021-03-16T08:35:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use New Relic infrastructure's Process running alert condition to be notified when a set of processes on your filtered hosts stop running for a configurable number of minutes. This is useful, for example, when: Any of the processes on the hosts stop reporting A process you expected to start on a host (such as a new program) is not actually running This feature's flexibility allows you to easily filter what hosts and processes to monitor and when to notify selected individuals or teams. In addition, the email notification includes links to help you quickly troubleshoot the situation. Important By default, the infrastructure agent doesn't send data about the operating system's processes. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Examples By applying filters to the hosts and processes that are important to your business, you can define alerting thresholds to decide when violations open and New Relic sends an email notification to you depending on the policy's incident preferences. These examples illustrate how to use infrastructure monitoring's Process running condition to monitor your processes. Ensure enough processes are running to satisfy load Problem: Some load balancers and application servers work by running many worker processes in parallel. Here, for example, you may want an alert violation when fewer than eight processes are running for a service like gunicorn. Solution: Depending on the situation, use any of these Process running thresholds options as needed: More than the defined number of processes are running Exactly the defined number of processes are running Fewer than the defined number of processes are running Ensure that critical services run constantly Problem: A service, such as a database or application server, is expected to be running constantly on certain hosts, and you need to know when it has stopped. Solution: Use the No processes are running (default) threshold. Monitor startup for critical processes that require special attention Problem: You have processes requiring special attention due to security or potential performance impact. Solution: Use the At least one process is running threshold with condition filters set to a username and specific executable so that New Relic can open a violation when the process is running. Make sure a job doesn't take too long Problem: You have a job that runs periodically, and you want to open a violation when it has been running longer than an expected number of minutes. Solution: Use the At least one process is running threshold. Validate that services started successfully Problem: When provisioning new hosts, you want to open a violation if a required service fails to successfully start up. Solution: Use the No processes are running (default) threshold. Watch for runaway processes or configuration problems Problem: Sometimes problems with processes can be solved with changes to your configuration. For example, you have more than one Chef process running, and you may need to address an issue with how that service is configured. Solution: Depending on the situation, use any of these Process running thresholds options as needed: More than the defined number of processes are running Exactly the defined number of processes are running Fewer than the defined number of processes are running Create an infrastructure process running condition To define the Process running alert criteria: Follow standard procedures to create an infrastructure alert condition. Select Process running as the Alert type. Filter what hosts and processes you want the alert condition to apply to. Define the Critical threshold for triggering the alert notification: minimum 1 minute, default 5 minutes, maximum 60 minutes. If you create the alert condition directly with infrastructure monitoring, New Relic will send an email notification when the defined threshold for the alert condition passes depending on the policy's incident preferences. Your alert policy defines which personnel or teams and which notification channels we use.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.8956,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alert</em> on <em>infrastructure</em> processes",
        "sections": "<em>Alert</em> on <em>infrastructure</em> processes",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "Use New Relic <em>infrastructure</em>&#x27;s Process running <em>alert</em> condition to be notified when a set of processes on your filtered hosts stop running for a configurable number of minutes. This is useful, for example, when: Any of the processes on the hosts stop reporting A process you expected to start"
      },
      "id": "603eb49128ccbca939eba74a"
    },
    {
      "sections": [
        "Create infrastructure \"host not reporting\" condition",
        "Features",
        "Create \"host not reporting\" condition",
        "Investigate the problem",
        "Intentional outages"
      ],
      "title": "Create infrastructure \"host not reporting\" condition",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "0a74e7e65e3eeb5268eac310c11802ca2e78a614",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-alerts/infrastructure-alert-conditions/create-infrastructure-host-not-reporting-condition/",
      "published_at": "2021-06-15T06:58:45Z",
      "updated_at": "2021-03-16T08:30:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use Infrastructure monitoring's Host not reporting condition to notify you when we've stopped receiving data from an infrastructure agent. This feature allows you to dynamically alert on groups of hosts, configure the time window from five to 60 minutes, and take full advantage of alerts notifications. Features You can define conditions based on the sets of hosts most important to you, and configure thresholds appropriate for each filter set. The Host not reporting event triggers when data from the infrastructure agent doesn't reach our collector within the time frame you specify. This feature's flexibility allows you to easily customize what to monitor and when to notify selected individuals or teams. In addition, the email notification includes links to help you quickly troubleshoot the situation. Host not reporting condition Features What to monitor You can use filter sets to select which hosts you want to be monitored with the alert condition. The condition will also automatically apply to any hosts you add in the future that match these filters. How to notify Conditions are contained in policies. You can select an existing policy or create a new policy with email notifications from the Infrastructure monitoring UI. If you want to create a new policy with other types of notification channels, use the UI. When to notify Email addresses (identified in the policy) will be notified automatically about threshold violations for any host matching the filters you have applied, depending on the policy's incident preferences. Where to troubleshoot The link at the top of the email notification will take you to the infrastructure Events page centered on the time when the host disconnected. Additional links in the email will take you to additional detail. Create \"host not reporting\" condition To define the Host not reporting condition criteria: Follow standard procedures to create an infrastructure condition. Select Host not reporting as the Alert type. Define the Critical threshold for triggering the notification: minimum 5 minutes, maximum 60 minutes. Enable 'Don't trigger alerts for hosts that perform a clean shutdown' option, if you want to prevent false alerts when you have hosts set to shut down via command line. Currently this feature is supported on all Windows systems and Linux systems using systemd. Depending on the policy's incident preferences, it will define which notification channels to use when the defined Critical threshold for the condition passes. To avoid \"false positives,\" the host must stop reporting for the entire time period before a violation is opened. Example: You create a condition to open a violation when any of the filtered set of hosts stop reporting data for seven minutes. If any host stops reporting for five minutes, then resumes reporting, the condition does not open a violation. If any host stops reporting for seven minutes, even if the others are fine, the condition does open a violation. Investigate the problem To further investigate why a host is not reporting data: Review the details in the email notification. Use the link from the email notification to monitor ongoing changes in your environment from Infrastructure monitoring's Events page. For example, use the Events page to help determine if a host disconnected right after a root user made a configuration change to the host. Optional: Use the email notification's Acknowledge link to verify you are aware of and taking ownership of the alerting incident. Use the email links to examine additional details in the Incident details page. Intentional outages We can distinguish between unexpected situations and planned situations with the option Don't trigger alerts for hosts that perform a clean shutdown. Use this option for situations such as: Host has been taken offline intentionally. Host has planned downtime for maintenance. Host has been shut down or decommissioned. Autoscaling hosts or shutting down instances in a cloud console. We rely on Linux and Windows shutdown signals to flag a clean shutdown. We've confirmed that these scenarios are detected by the agent: AWS Auto-scaling event with EC2 instances that use systemd (Amazon Linux, CentOs/RedHat 7 and newer, Ubuntu 16 and newer, Suse 12 and newer, Debian 9 and newer) User-initiated shutdown of Windows systems User-initiated shutdown of Linux systems that use systemd (Amazon Linux, CentOs/RedHat 7 and newer, Ubuntu 16 and newer, Suse 12 and newer, Debian 9 and newer) We know that these scenarios are not detected by the agent: User-initiated shutdown of Linux systems that don't use systemd (CentOs/RedHat 6 and earlier, Ubuntu 14, Debian 8). This includes other modern Linux systems that still use Upstart or SysV init systems. AWS Auto-scaling event with EC2 instances that don't use systemd (CentOs/RedHat 6 and earlier, Ubuntu 14, Debian 8). This includes other more modern Linux systems that still use Upstart or SysV init systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.89491,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create <em>infrastructure</em> &quot;host not reporting&quot; <em>condition</em>",
        "sections": "Create <em>infrastructure</em> &quot;host not reporting&quot; <em>condition</em>",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "Use <em>Infrastructure</em> monitoring&#x27;s Host not reporting condition to notify you when we&#x27;ve stopped receiving data from an <em>infrastructure</em> agent. This feature allows you to dynamically <em>alert</em> on groups of hosts, configure the time window from five to 60 minutes, and take full advantage of <em>alerts</em>"
      },
      "id": "603ea06c196a67cd47a83dc1"
    }
  ],
  "/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/infrastructure-alerts-add-edit-or-view-host-alert-information": [
    {
      "sections": [
        "REST API calls for infrastructure alerts",
        "Requirements",
        "Tip",
        "Using infrastructure API calls",
        "GET infrastructure conditions",
        "GET a list of infrastructure conditions",
        "Example GET a list of conditions",
        "GET a specific infrastructure condition",
        "Example GET a specific condition",
        "Create (POST) an infrastructure condition",
        "Important",
        "Update (PUT) an infrastructure condition",
        "Example update (PUT) a condition",
        "Remove (DELETE) an infrastructure condition",
        "Types of conditions",
        "Process running conditions API data",
        "Example condition types",
        "Metric conditions API data",
        "Example",
        "Host not reporting condition",
        "Definitions",
        "value",
        "duration_minutes",
        "time_function"
      ],
      "title": "REST API calls for infrastructure alerts",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "c35aa43cdb6645473d02886a49d6f9aeb37e577f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/rest-api-calls-new-relic-infrastructure-alerts/",
      "published_at": "2021-06-15T02:33:21Z",
      "updated_at": "2021-04-06T06:04:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the infrastructure REST API to add, update, delete, and list alerting conditions. You can also manage individual alerting conditions using the infrastructure monitoring UI. REST API calls for infrastructure alerts are not available in the API Explorer. Why use the API Examples Consistency Define the same set of conditions for every cluster without having to set up identical conditions in the Infrastructure monitoring UI each time. Manage multiple conditions quickly, without having to update them one by one using the UI. Flexibility Create conditions for an arbitrary group of hosts. Disable or delete conditions for hosts taken offline anytime. Create a condition with exclusionary filtering (for instance, environment NOT LIKE x). For more on this, see this post on exclusion filtering. For AWS Cloud integrations, select attributes that haven't been sent up by AWS yet. Create compound alert conditions by using the where_clause, which allows you to specify the limits on a secondary or tertiary metric. Exceed the 500-facet limitation on NRQL alert conditions. Reliability Audit when a condition was last updated. Requirements In order to use the Infrastructure REST API, you need: An API key The alerting condition's related policy_id from New Relic, available via GET list of conditions or via the Alerts REST API The condition id, available via GET list of conditions, or via the condition's URL in the Infrastructure monitoring UI Tip If your account hosts data in the EU data center, make sure you are using the proper API endpoints for EU region accounts. Using infrastructure API calls Here are some basic cURL commands and their responses for Infrastructure alert conditions. Depending on the type of condition, the DATA information you provide in the call will vary for POST (add) and PUT (update) calls. Definitions of each attribute used in the data blocks can be found in the Definitions section. GET infrastructure conditions You can either GET a list of infrastructure conditions or GET a specific infrastructure condition. Here are a few tips for listing infrastructure conditions. For pagination, use limit (records per page) and offset (how many records to skip) parameters. Default is 50 records per page, and offset starts at 0 (skip no records). To scope the results to a specific policy, use policy_id. Tip If you want to use the GET response as a template for your PUT or POST input, be sure to remove the created_at_epoch_millis, updated_at_epoch_millis and id information. GET a list of infrastructure conditions curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions?policy_id=111111\" Copy Example GET a list of conditions Response showing 2 of the 3 conditions for the example policy (formatted for readability and truncated): HTTP/1.1 200 OK Content-Length: 622 Content-Type: application/json { \"data\":[ { \"type\":\"infra_process_running\", \"name\":\"Java is running\", \"enabled\":true, \"where_clause\":\"(`hostname` LIKE '%cassandra%')\", \"id\":13890, \"created_at_epoch_millis\":1490996713872, \"updated_at_epoch_millis\":1490996713872, \"policy_id\":111111, \"comparison\":\"equal\", \"critical_threshold\":{ \"value\":0, \"duration_minutes\":6 }, \"process_where_clause\":\"(`commandName` = 'java')\" }, { \"created_at_epoch_millis\": 1501704525462, \"critical_threshold\": { \"duration_minutes\": 5 }, \"enabled\": true, \"filter\": { \"and\": [ { \"like\": { \"fullHostname\": \"Production_1\" } } ] }, \"id\": 448036, \"name\": \"PROD - Host Machine's Agent Not Responding ....\", \"policy_id\": 98485, \"type\": \"infra_host_not_reporting\", \"updated_at_epoch_millis\": 1504879191220 } . . . ], \"meta\":{ \"limit\":50, \"offset\":0, \"total\":3 }, \"links\":{} } Copy To get a list of the 10 Infrastructure conditions beyond the 50 limit: curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions?policy_id=111111&offset=50&list=10\" Copy GET a specific infrastructure condition To get information about a single Infrastructure condition: curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions/condition-id\" Copy Example GET a specific condition Response (formatted for readability): HTTP/1.1 200 OK Content-Length: 246 Content-Type: application/json { \"data\":{ \"type\":\"infra_host_not_reporting\", \"name\":\"demo condition\", \"enabled\":false, \"id\":13887, \"created_at_epoch_millis\":1490981583580, \"updated_at_epoch_millis\":1490981583580, \"policy_id\":23635, \"critical_threshold\":{ \"duration_minutes\":100 } } } Copy Create (POST) an infrastructure condition Important Do not include an \"id\": when adding a new condition (POST). It will be generated when the condition is created. To add an infrastructure condition, use this basic cURL command: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{\"data\":{DATA object details}}' Copy Include details in the DATA object (-d \\ section) for the type of infrastructure condition you are adding: Process running conditions API data Metric conditions API data Host not reporting conditions API data Update (PUT) an infrastructure condition You only need to include the fields that need to be changed when updating an infrastructure condition. The API keeps the existing values for any missing fields. Important If you want to change the condition type, do not use PUT. Instead, delete the existing condition, then add (POST) a new condition with the new condition type and all fields. To update an infrastructure condition, use this basic cURL command. To indicate which condition is to be updated, be sure to include the \"id\": . Example update (PUT) a condition curl -X PUT 'https://infra-api.newrelic.com/v2/alerts/conditions/condition-id' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{\"data\":{DATA object details}}' Copy Include details in the DATA object (-d \\ section) for the type of infrastructure condition you are updating: Process running conditions API data Metric conditions API data Host not reporting conditions API data Remove (DELETE) an infrastructure condition To delete an infrastructure condition, use this basic cURL command: curl -v -X DELETE --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions/condition_id\" Copy Types of conditions Process running conditions API data A process running condition alerts you when the number of processes is above, below, or equal to the threshold you define. To add (POST) or update (PUT) a process running condition, use your API key, and refer to the definitions to customize your values in the API call. Example condition types For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_process_running\", \"name\":\"Java is running\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"comparison\":\"equal\", \"critical_threshold\":{ \"value\":0, \"duration_minutes\":6 }, \"process_where_clause\":\"(commandName = '\\''java'\\'')\" } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause and process_where_clause Metric conditions API data A metric condition alerts you when the metric of your choice is above, below, or equal to the threshold you define. This includes: System metrics Process metrics Network metrics Storage metrics Cloud integration metrics To add (POST) or update (PUT) a metric condition, use your API key, and refer to the definitions to customize your values in the API call. If you are adding or updating a cloud integration alert condition: For the event_type field, enter the event type generated by your selected cloud integration service (for example, ComputeSample for the AWS EC2 integration). If you are setting up an alert condition on a cloud integration service that requires a provider value (for example, AWS RDS uses DatastoreSample with a provider value of RdsDbInstance or RdsDbCluster), you will need to add the \"integration_provider\" field and use the value that is appropriate for the service your alert condition is targeting (for example, \"integration_provider\":\"RdsDbInstance\"). For the select_value field, build the metric name by using the following syntax, where provider is a standard prefix string: provider.metric.aggregation_type Copy metric: Use the metric name as described in the New Relic documentation for your integration. aggregation_type: Use Sum, Average, Minimum, or Maximum. Refer to the original documentation by the integration's cloud provider to see which statistic aggregations are available for each metric. Example For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_metric\", \"name\":\"Disk Space Condition\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"event_type\":\"StorageSample\", \"select_value\":\"diskFreePercent\", \"comparison\":\"below\", \"critical_threshold\":{ \"value\":10, \"duration_minutes\":1, \"time_function\":\"any\" }, \"warning_threshold\":{ \"value\":30, \"duration_minutes\":2, \"time_function\":\"any\" } } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause Host not reporting condition A host not reporting condition alerts you when a host stops reporting. To add (POST) or update (PUT) a host not reporting condition, use your API key, and refer to the definitions to customize your values in the API call. Example For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_host_not_reporting\", \"name\":\"Cassandra Host Reporting Condition\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"critical_threshold\":{ \"duration_minutes\":12 } } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause Definitions When formatting your cURL commands, use these values as needed. These are listed in alphabetical order, not the order they appear in your API calls. Field Definition comparison (enum) Condition type: infra_metric, infra_process_running The value used to define the threshold; for example, \"[\"above\", \"below\", \"equal\"]. critical_threshold and warning_threshold Condition type: all This object identifies the threshold value before opening a violation. The critical_threshold is required. The warning_threshold is optional and may only be used with infra_metric conditions. The keys of this object depend on the condition type. Condition type: infra_metric format: \"critical_threshold\":{ \"value\":<number>, \"duration_minutes\":<integer>, \"time_function\":\"any\" or \"all\" }, Copy Condition type: infra_process_running format: \"critical_threshold\":{ \"value\":<integer>, \"duration_minutes\":<integer>, }, Copy Condition type: infra_host_not_reporting format: \"critical_threshold\":{ \"duration_minutes\":<integer>, }, Copy value The numeric value that must be breached for the condition to open a violation duration_minutes The number of minutes the value must be passed or met for the condition to open a violation time_function Indicates if the condition needs to be sustained for a certain period of time to create a violation, or if it only needs to break the threshold once within a certain period of time. If you're setting up a for at least x minutes threshold, use all; for an at least once in x minutes threshold, use any. enabled (boolean) Condition type: all Whether the condition is turned on or off; true or false. event_type (string) Condition type: infra_metric The metric event; for example, system metrics, process metrics, storage metrics, or network metrics. This automatically populates for infrastructure integrations; for example, StorageSample or SystemSample. filter (string) Condition type: all If the condition was made in the UI, filter appears instead of where_clause; for example: {and: [{is: {ec2InstanceType: \"m3.medium\"}}]} Copy Recommendation: Use where_clause when creating a new condition. id (integer) Condition type: all The condition ID located in the URL. GET: This value appears in the GET response. PUT: Include this value in the DATA section. POST: Do not include this in the DATA section. DELETE: Include this value in the -X DELETE call. integration_provider (string) Condition type: infra_metric For alerts on integrations, use integration_provider instead of event_type. To see valid values: From the New Relic documentation for your cloud service, check the Find and use data section. Example: In the AWS RDS monitoring integration documentation, you can see that the DatastoreSample event type can be used with an integration_provider value of either RdsDbInstance for DB instances, or RdsDbCluster for Aurora DB clusters. name (string) Condition type: all The infrastructure alerting condition's name; for example: \"[test] process running\" Copy policy_id (integer) Condition type: all The unique ID for the alert policy's account ID associated with the condition; for example, 1234567890. This is not the policy's global ID. process_where_clause (string) Condition type: infra_process_running Any filters applied to processes, specifically in process running alert conditions. This parameter is mandatory for those types of alert conditions. For example: \"commandName = '\\''java'\\''\" Copy runbook_url (string) Condition type: all The runbook URL to display in notifications. select_value (string) Condition type: infra_metric The attribute name to identify the metric being targeted; for example, \"cpuPercent\", \"diskFreePercent\", \"memoryResidentSizeBytes\", or \"memoryFreeBytes/memoryTotalBytes*100\". This automatically populates for Infrastructure Integrations; for example, diskFreePercent. type (enum) Condition type: all The type of infrastructure alert condition: \"infra_process_running\", \"infra_metric\", or \"infra_host_not_reporting\". violation_close_timer (integer) Condition type: all The Violation time limit setting, expressed as hours. Possible values are 0, 1, 2, 4, 8,12, 24, 48, 72. This determines how much time will pass before a violation is automatically closed. Setting the time limit to 0 prevents a violation from being force-closed. For new conditions, if a value is not provided, the following default values are used: Host Not Responding (HNR) conditions: 0 (disabled) All other conditions: 24 When updating existing conditions, if a value is provided, it overrides the existing value, but does not affect already opened violations. where_clause (string) Condition type: all If applicable, this identifies any infrastructure host filters used; for example: \"(`hostname` LIKE '\\''%cassandra%'\\'')\", Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.25702,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>infrastructure</em> <em>alerts</em>",
        "sections": "REST API calls for <em>infrastructure</em> <em>alerts</em>",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "Use the <em>infrastructure</em> REST API to add, update, delete, and list alerting <em>conditions</em>. You can also manage individual alerting <em>conditions</em> using the <em>infrastructure</em> monitoring UI. REST API calls for <em>infrastructure</em> <em>alerts</em> are not available in the API Explorer. Why use the API Examples Consistency"
      },
      "id": "6043fa6c196a678ae2960f31"
    },
    {
      "sections": [
        "Alert on infrastructure processes",
        "Important",
        "Examples",
        "Ensure enough processes are running to satisfy load",
        "Ensure that critical services run constantly",
        "Monitor startup for critical processes that require special attention",
        "Make sure a job doesn't take too long",
        "Validate that services started successfully",
        "Watch for runaway processes or configuration problems",
        "Create an infrastructure process running condition"
      ],
      "title": "Alert on infrastructure processes",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "5fcbe11b9beb16723ff2521fca981f19a4c716ce",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/alert-infrastructure-processes/",
      "published_at": "2021-06-15T02:33:23Z",
      "updated_at": "2021-03-16T08:35:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use New Relic infrastructure's Process running alert condition to be notified when a set of processes on your filtered hosts stop running for a configurable number of minutes. This is useful, for example, when: Any of the processes on the hosts stop reporting A process you expected to start on a host (such as a new program) is not actually running This feature's flexibility allows you to easily filter what hosts and processes to monitor and when to notify selected individuals or teams. In addition, the email notification includes links to help you quickly troubleshoot the situation. Important By default, the infrastructure agent doesn't send data about the operating system's processes. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Examples By applying filters to the hosts and processes that are important to your business, you can define alerting thresholds to decide when violations open and New Relic sends an email notification to you depending on the policy's incident preferences. These examples illustrate how to use infrastructure monitoring's Process running condition to monitor your processes. Ensure enough processes are running to satisfy load Problem: Some load balancers and application servers work by running many worker processes in parallel. Here, for example, you may want an alert violation when fewer than eight processes are running for a service like gunicorn. Solution: Depending on the situation, use any of these Process running thresholds options as needed: More than the defined number of processes are running Exactly the defined number of processes are running Fewer than the defined number of processes are running Ensure that critical services run constantly Problem: A service, such as a database or application server, is expected to be running constantly on certain hosts, and you need to know when it has stopped. Solution: Use the No processes are running (default) threshold. Monitor startup for critical processes that require special attention Problem: You have processes requiring special attention due to security or potential performance impact. Solution: Use the At least one process is running threshold with condition filters set to a username and specific executable so that New Relic can open a violation when the process is running. Make sure a job doesn't take too long Problem: You have a job that runs periodically, and you want to open a violation when it has been running longer than an expected number of minutes. Solution: Use the At least one process is running threshold. Validate that services started successfully Problem: When provisioning new hosts, you want to open a violation if a required service fails to successfully start up. Solution: Use the No processes are running (default) threshold. Watch for runaway processes or configuration problems Problem: Sometimes problems with processes can be solved with changes to your configuration. For example, you have more than one Chef process running, and you may need to address an issue with how that service is configured. Solution: Depending on the situation, use any of these Process running thresholds options as needed: More than the defined number of processes are running Exactly the defined number of processes are running Fewer than the defined number of processes are running Create an infrastructure process running condition To define the Process running alert criteria: Follow standard procedures to create an infrastructure alert condition. Select Process running as the Alert type. Filter what hosts and processes you want the alert condition to apply to. Define the Critical threshold for triggering the alert notification: minimum 1 minute, default 5 minutes, maximum 60 minutes. If you create the alert condition directly with infrastructure monitoring, New Relic will send an email notification when the defined threshold for the alert condition passes depending on the policy's incident preferences. Your alert policy defines which personnel or teams and which notification channels we use.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.8956,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alert</em> on <em>infrastructure</em> processes",
        "sections": "<em>Alert</em> on <em>infrastructure</em> processes",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "Use New Relic <em>infrastructure</em>&#x27;s Process running <em>alert</em> condition to be notified when a set of processes on your filtered hosts stop running for a configurable number of minutes. This is useful, for example, when: Any of the processes on the hosts stop reporting A process you expected to start"
      },
      "id": "603eb49128ccbca939eba74a"
    },
    {
      "sections": [
        "Create infrastructure \"host not reporting\" condition",
        "Features",
        "Create \"host not reporting\" condition",
        "Investigate the problem",
        "Intentional outages"
      ],
      "title": "Create infrastructure \"host not reporting\" condition",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "0a74e7e65e3eeb5268eac310c11802ca2e78a614",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-alerts/infrastructure-alert-conditions/create-infrastructure-host-not-reporting-condition/",
      "published_at": "2021-06-15T06:58:45Z",
      "updated_at": "2021-03-16T08:30:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use Infrastructure monitoring's Host not reporting condition to notify you when we've stopped receiving data from an infrastructure agent. This feature allows you to dynamically alert on groups of hosts, configure the time window from five to 60 minutes, and take full advantage of alerts notifications. Features You can define conditions based on the sets of hosts most important to you, and configure thresholds appropriate for each filter set. The Host not reporting event triggers when data from the infrastructure agent doesn't reach our collector within the time frame you specify. This feature's flexibility allows you to easily customize what to monitor and when to notify selected individuals or teams. In addition, the email notification includes links to help you quickly troubleshoot the situation. Host not reporting condition Features What to monitor You can use filter sets to select which hosts you want to be monitored with the alert condition. The condition will also automatically apply to any hosts you add in the future that match these filters. How to notify Conditions are contained in policies. You can select an existing policy or create a new policy with email notifications from the Infrastructure monitoring UI. If you want to create a new policy with other types of notification channels, use the UI. When to notify Email addresses (identified in the policy) will be notified automatically about threshold violations for any host matching the filters you have applied, depending on the policy's incident preferences. Where to troubleshoot The link at the top of the email notification will take you to the infrastructure Events page centered on the time when the host disconnected. Additional links in the email will take you to additional detail. Create \"host not reporting\" condition To define the Host not reporting condition criteria: Follow standard procedures to create an infrastructure condition. Select Host not reporting as the Alert type. Define the Critical threshold for triggering the notification: minimum 5 minutes, maximum 60 minutes. Enable 'Don't trigger alerts for hosts that perform a clean shutdown' option, if you want to prevent false alerts when you have hosts set to shut down via command line. Currently this feature is supported on all Windows systems and Linux systems using systemd. Depending on the policy's incident preferences, it will define which notification channels to use when the defined Critical threshold for the condition passes. To avoid \"false positives,\" the host must stop reporting for the entire time period before a violation is opened. Example: You create a condition to open a violation when any of the filtered set of hosts stop reporting data for seven minutes. If any host stops reporting for five minutes, then resumes reporting, the condition does not open a violation. If any host stops reporting for seven minutes, even if the others are fine, the condition does open a violation. Investigate the problem To further investigate why a host is not reporting data: Review the details in the email notification. Use the link from the email notification to monitor ongoing changes in your environment from Infrastructure monitoring's Events page. For example, use the Events page to help determine if a host disconnected right after a root user made a configuration change to the host. Optional: Use the email notification's Acknowledge link to verify you are aware of and taking ownership of the alerting incident. Use the email links to examine additional details in the Incident details page. Intentional outages We can distinguish between unexpected situations and planned situations with the option Don't trigger alerts for hosts that perform a clean shutdown. Use this option for situations such as: Host has been taken offline intentionally. Host has planned downtime for maintenance. Host has been shut down or decommissioned. Autoscaling hosts or shutting down instances in a cloud console. We rely on Linux and Windows shutdown signals to flag a clean shutdown. We've confirmed that these scenarios are detected by the agent: AWS Auto-scaling event with EC2 instances that use systemd (Amazon Linux, CentOs/RedHat 7 and newer, Ubuntu 16 and newer, Suse 12 and newer, Debian 9 and newer) User-initiated shutdown of Windows systems User-initiated shutdown of Linux systems that use systemd (Amazon Linux, CentOs/RedHat 7 and newer, Ubuntu 16 and newer, Suse 12 and newer, Debian 9 and newer) We know that these scenarios are not detected by the agent: User-initiated shutdown of Linux systems that don't use systemd (CentOs/RedHat 6 and earlier, Ubuntu 14, Debian 8). This includes other modern Linux systems that still use Upstart or SysV init systems. AWS Auto-scaling event with EC2 instances that don't use systemd (CentOs/RedHat 6 and earlier, Ubuntu 14, Debian 8). This includes other more modern Linux systems that still use Upstart or SysV init systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.89491,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create <em>infrastructure</em> &quot;host not reporting&quot; <em>condition</em>",
        "sections": "Create <em>infrastructure</em> &quot;host not reporting&quot; <em>condition</em>",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "Use <em>Infrastructure</em> monitoring&#x27;s Host not reporting condition to notify you when we&#x27;ve stopped receiving data from an <em>infrastructure</em> agent. This feature allows you to dynamically <em>alert</em> on groups of hosts, configure the time window from five to 60 minutes, and take full advantage of <em>alerts</em>"
      },
      "id": "603ea06c196a67cd47a83dc1"
    }
  ]
}