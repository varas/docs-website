{
  "/docs/licenses/product-or-service-licenses/mobile-app-licenses/android-application-licenses": [
    {
      "sections": [
        "tvOS application licenses"
      ],
      "title": "tvOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "0b3ac8ec42cef00f5a4d3ddf354e4be38ad0595f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/tvos-application-licenses/",
      "published_at": "2021-07-02T15:41:19Z",
      "updated_at": "2021-05-05T16:26:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation (http://alamofire.org/) Analytics MIT Copyright © 2016 Segment.io, Inc. CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me LoginManagerSDK New Relic License © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License © 2010-2021 New Relic, Inc. All rights reserved. UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. iOS-fontawesome CC BY 3.0 & MIT Copyright © 2012 Alex Usbergo. All rights reserved. The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.85754,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "tvOS <em>application</em> <em>licenses</em>",
        "sections": "tvOS <em>application</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic for TV <em>app</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "6072d619196a6795b664a75c"
    },
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-07-02T15:41:19Z",
      "updated_at": "2021-05-05T16:26:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2018 Alamofire Software Foundation AlamofireObjectMapper MIT Copyright © 2015 Tristan Himmelman Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.85754,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS <em>application</em> <em>licenses</em>",
        "sections": "iOS <em>application</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic iOS <em>app</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    },
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-07-02T13:42:10Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.11974,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    }
  ],
  "/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses": [
    {
      "sections": [
        "Android application licenses"
      ],
      "title": "Android application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "68c9bdc9dec6f02240f002494309519e41619f29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/android-application-licenses/",
      "published_at": "2021-07-02T15:40:23Z",
      "updated_at": "2021-05-05T16:29:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Third Party Dependencies License Copyright Android-FlowLayout Apache 2.0 Copyright © 2011, Artem Votincev (apmem.org) AVLoadingIndicatorView Apache 2.0 Copyright © 2015, Jack Wang BottomNavigationViewEx MIT Copyright © 2017, ittianyu Butterknife Apache 2.0 Copyright © 2013, Jake Wharton Crouton Apache 2.0 Copyright © 2012 - 2014, Benjamin Weiss CWAC-SafeRoom Apache 2.0 The copyrights are owned by CommonsWare for things unique to this library and a combination of CommonsWare and the Android Open Source Project for code modified from the Architecture Components' Framework* set of classes. Dagger 2 Apache 2.0 Copyright © 2012, The Dagger Authors Dragtop Layout Apache 2.0 Copyright © 2015, chenupt EventBus Apache 2.0 Copyright © 2012-2017 Markus Junginger, greenrobot FlexibleAdapter Apache 2.0 Copyright © 2015-2018 Davide Steduto, Davidea Solutions Sprl Gson Apache 2.0 Copyright © 2008, Google Inc. markwon Apache 2.0 Copyright © 2019 Dimitry Ivanov (legal@noties.io) mockk Apache 2.0 Copyright © [ 2017] [ github.com/mockk] leakcanary Apache 2.0 Copyright © 2015 Square, Inc. mockito mockito MIT Copyright © 2007 Mockito contributors mosby Apache 2.0 Copyright © 2015 Hannes Dorfmann moshi Apache 2.0 Copyright © 2015 Square, Inc. MPAndroidChart Apache 2.0 Copyright © 2019 Philipp Jahoda New Relic Mobile Agent OKHttp Apache 2.0 Copyright © 2019 Square, Inc. okio Apache 2.0 Copyright © 2013 Square, Inc. Picasso Apache 2.0 Copyright © 2013 Square, Inc. RESTMock Apache 2.0 Copyright © 2016 Appflate.io Retrofit Apache 2.0 Copyright © 2013 Square, Inc. RxJava Apache 2.0 Copyright © 2016-present, RxJava Contributors. Segment IO MIT Copyright © 2016 Segment, Inc. Snackyaml Apache 2.0 Copyright © 2008, www.snakeyaml.org. StickyHeaders Apache 2.0 Copyright © 2014 Emil Sjölander TableView Apache 2.0 Copyright © 2017 Evren Coşkun Transitions-Everywhere Apache 2.0 The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.85822,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android <em>application</em> <em>licenses</em>",
        "sections": "Android <em>application</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic Android <em>app</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Third Party Dependencies"
      },
      "id": "603e9e30196a67b71fa83d96"
    },
    {
      "sections": [
        "tvOS application licenses"
      ],
      "title": "tvOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "0b3ac8ec42cef00f5a4d3ddf354e4be38ad0595f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/tvos-application-licenses/",
      "published_at": "2021-07-02T15:41:19Z",
      "updated_at": "2021-05-05T16:26:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation (http://alamofire.org/) Analytics MIT Copyright © 2016 Segment.io, Inc. CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me LoginManagerSDK New Relic License © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License © 2010-2021 New Relic, Inc. All rights reserved. UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. iOS-fontawesome CC BY 3.0 & MIT Copyright © 2012 Alex Usbergo. All rights reserved. The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.85754,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "tvOS <em>application</em> <em>licenses</em>",
        "sections": "tvOS <em>application</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic for TV <em>app</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "6072d619196a6795b664a75c"
    },
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-07-02T13:42:10Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.11974,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    }
  ],
  "/docs/licenses/product-or-service-licenses/mobile-app-licenses/tvos-application-licenses": [
    {
      "sections": [
        "Android application licenses"
      ],
      "title": "Android application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "68c9bdc9dec6f02240f002494309519e41619f29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/android-application-licenses/",
      "published_at": "2021-07-02T15:40:23Z",
      "updated_at": "2021-05-05T16:29:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Third Party Dependencies License Copyright Android-FlowLayout Apache 2.0 Copyright © 2011, Artem Votincev (apmem.org) AVLoadingIndicatorView Apache 2.0 Copyright © 2015, Jack Wang BottomNavigationViewEx MIT Copyright © 2017, ittianyu Butterknife Apache 2.0 Copyright © 2013, Jake Wharton Crouton Apache 2.0 Copyright © 2012 - 2014, Benjamin Weiss CWAC-SafeRoom Apache 2.0 The copyrights are owned by CommonsWare for things unique to this library and a combination of CommonsWare and the Android Open Source Project for code modified from the Architecture Components' Framework* set of classes. Dagger 2 Apache 2.0 Copyright © 2012, The Dagger Authors Dragtop Layout Apache 2.0 Copyright © 2015, chenupt EventBus Apache 2.0 Copyright © 2012-2017 Markus Junginger, greenrobot FlexibleAdapter Apache 2.0 Copyright © 2015-2018 Davide Steduto, Davidea Solutions Sprl Gson Apache 2.0 Copyright © 2008, Google Inc. markwon Apache 2.0 Copyright © 2019 Dimitry Ivanov (legal@noties.io) mockk Apache 2.0 Copyright © [ 2017] [ github.com/mockk] leakcanary Apache 2.0 Copyright © 2015 Square, Inc. mockito mockito MIT Copyright © 2007 Mockito contributors mosby Apache 2.0 Copyright © 2015 Hannes Dorfmann moshi Apache 2.0 Copyright © 2015 Square, Inc. MPAndroidChart Apache 2.0 Copyright © 2019 Philipp Jahoda New Relic Mobile Agent OKHttp Apache 2.0 Copyright © 2019 Square, Inc. okio Apache 2.0 Copyright © 2013 Square, Inc. Picasso Apache 2.0 Copyright © 2013 Square, Inc. RESTMock Apache 2.0 Copyright © 2016 Appflate.io Retrofit Apache 2.0 Copyright © 2013 Square, Inc. RxJava Apache 2.0 Copyright © 2016-present, RxJava Contributors. Segment IO MIT Copyright © 2016 Segment, Inc. Snackyaml Apache 2.0 Copyright © 2008, www.snakeyaml.org. StickyHeaders Apache 2.0 Copyright © 2014 Emil Sjölander TableView Apache 2.0 Copyright © 2017 Evren Coşkun Transitions-Everywhere Apache 2.0 The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.8582,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android <em>application</em> <em>licenses</em>",
        "sections": "Android <em>application</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic Android <em>app</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Third Party Dependencies"
      },
      "id": "603e9e30196a67b71fa83d96"
    },
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-07-02T15:41:19Z",
      "updated_at": "2021-05-05T16:26:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2018 Alamofire Software Foundation AlamofireObjectMapper MIT Copyright © 2015 Tristan Himmelman Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.85754,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS <em>application</em> <em>licenses</em>",
        "sections": "iOS <em>application</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic iOS <em>app</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    },
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-07-02T13:42:10Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.11974,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/apm-agent-sdk-licenses": [
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-07-02T14:08:04Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.0537,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> <em>APM</em>, including a large number contributed by the open source community. To view <em>licenses</em> for... See... <em>APM</em> agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-<em>apm</em>"
      },
      "id": "603e7895e7b9d24e832a07d5"
    },
    {
      "sections": [
        "Python agent licenses"
      ],
      "title": "Python agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "6949c60ba3a446b93561658282def2bb7a8721c3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/python-agent-licenses/",
      "published_at": "2021-07-02T14:09:08Z",
      "updated_at": "2021-05-05T16:20:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Python Agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library Copyright License asgiref Copyright © Django Software Foundation and individual contributors. The BSD 3-Clause License six Copyright © 2010-2013 Benjamin Peterson The MIT License time.monotonic Copyright © 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013 Python Software Foundation; All Rights Reserved Python Software Foundation urllib3 Copyright © 2008-2019 Andrey Petrov and contributors (see CONTRIBUTORS.txt) The MIT License wrapt Copyright © 2013-2019, Graham Dumpleton All rights reserved. The BSD 2-Clause License The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.19409,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Python agent <em>licenses</em>",
        "sections": "Python agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Python Agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library Copyright License"
      },
      "id": "6044e7bbe7b9d242575799d1"
    },
    {
      "sections": [
        "Go agent licenses"
      ],
      "title": "Go agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "08a72af2529390cf6296870147ce00b64ea7f633",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/go-agent-licenses/",
      "published_at": "2021-07-02T14:49:26Z",
      "updated_at": "2021-03-16T04:25:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Go Go BSD The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.03333,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Go agent <em>licenses</em>",
        "sections": "Go agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Go Go BSD The remainder of the code is covered by the <em>New</em> <em>Relic</em> agent license agreement."
      },
      "id": "603ea506196a67b2b3a83dee"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/c-sdk-licenses": [
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-07-02T14:08:04Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.0537,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> <em>APM</em>, including a large number contributed by the open source community. To view <em>licenses</em> for... See... <em>APM</em> agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-<em>apm</em>"
      },
      "id": "603e7895e7b9d24e832a07d5"
    },
    {
      "sections": [
        "Python agent licenses"
      ],
      "title": "Python agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "6949c60ba3a446b93561658282def2bb7a8721c3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/python-agent-licenses/",
      "published_at": "2021-07-02T14:09:08Z",
      "updated_at": "2021-05-05T16:20:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Python Agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library Copyright License asgiref Copyright © Django Software Foundation and individual contributors. The BSD 3-Clause License six Copyright © 2010-2013 Benjamin Peterson The MIT License time.monotonic Copyright © 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013 Python Software Foundation; All Rights Reserved Python Software Foundation urllib3 Copyright © 2008-2019 Andrey Petrov and contributors (see CONTRIBUTORS.txt) The MIT License wrapt Copyright © 2013-2019, Graham Dumpleton All rights reserved. The BSD 2-Clause License The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.19408,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Python agent <em>licenses</em>",
        "sections": "Python agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Python Agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library Copyright License"
      },
      "id": "6044e7bbe7b9d242575799d1"
    },
    {
      "sections": [
        "Go agent licenses"
      ],
      "title": "Go agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "08a72af2529390cf6296870147ce00b64ea7f633",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/go-agent-licenses/",
      "published_at": "2021-07-02T14:49:26Z",
      "updated_at": "2021-03-16T04:25:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Go Go BSD The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.03333,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Go agent <em>licenses</em>",
        "sections": "Go agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Go Go BSD The remainder of the code is covered by the <em>New</em> <em>Relic</em> agent license agreement."
      },
      "id": "603ea506196a67b2b3a83dee"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/go-agent-licenses": [
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-07-02T14:08:04Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.0537,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> <em>APM</em>, including a large number contributed by the open source community. To view <em>licenses</em> for... See... <em>APM</em> agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-<em>apm</em>"
      },
      "id": "603e7895e7b9d24e832a07d5"
    },
    {
      "sections": [
        "Python agent licenses"
      ],
      "title": "Python agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "6949c60ba3a446b93561658282def2bb7a8721c3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/python-agent-licenses/",
      "published_at": "2021-07-02T14:09:08Z",
      "updated_at": "2021-05-05T16:20:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Python Agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library Copyright License asgiref Copyright © Django Software Foundation and individual contributors. The BSD 3-Clause License six Copyright © 2010-2013 Benjamin Peterson The MIT License time.monotonic Copyright © 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013 Python Software Foundation; All Rights Reserved Python Software Foundation urllib3 Copyright © 2008-2019 Andrey Petrov and contributors (see CONTRIBUTORS.txt) The MIT License wrapt Copyright © 2013-2019, Graham Dumpleton All rights reserved. The BSD 2-Clause License The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.19408,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Python agent <em>licenses</em>",
        "sections": "Python agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Python Agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library Copyright License"
      },
      "id": "6044e7bbe7b9d242575799d1"
    },
    {
      "sections": [
        ".NET agent: Microsoft Azure Portal Extension licenses"
      ],
      "title": ".NET agent: Microsoft Azure Portal Extension licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "19d61cf14551e1be8895993d42d2c640d7cd238b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/net-agent-microsoft-azure-portal-extension-licenses/",
      "published_at": "2021-07-02T14:08:05Z",
      "updated_at": "2021-03-13T03:35:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Microsoft Azure Portal Extension. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Antlr BSD JSON.NET MIT PowerArgs MIT The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 168.67317,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET agent: Microsoft Azure Portal Extension <em>licenses</em>",
        "sections": ".NET agent: Microsoft Azure Portal Extension <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": " Antlr BSD JSON.NET MIT PowerArgs MIT The remainder of the code is covered by the <em>New</em> <em>Relic</em> License agreement found in the LICENSE file in the distribution."
      },
      "id": "6044e7bb64441f6e4e378f1a"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/java-agent-licenses": [
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-07-02T14:08:04Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.05368,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> <em>APM</em>, including a large number contributed by the open source community. To view <em>licenses</em> for... See... <em>APM</em> agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-<em>apm</em>"
      },
      "id": "603e7895e7b9d24e832a07d5"
    },
    {
      "sections": [
        "Python agent licenses"
      ],
      "title": "Python agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "6949c60ba3a446b93561658282def2bb7a8721c3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/python-agent-licenses/",
      "published_at": "2021-07-02T14:09:08Z",
      "updated_at": "2021-05-05T16:20:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Python Agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library Copyright License asgiref Copyright © Django Software Foundation and individual contributors. The BSD 3-Clause License six Copyright © 2010-2013 Benjamin Peterson The MIT License time.monotonic Copyright © 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013 Python Software Foundation; All Rights Reserved Python Software Foundation urllib3 Copyright © 2008-2019 Andrey Petrov and contributors (see CONTRIBUTORS.txt) The MIT License wrapt Copyright © 2013-2019, Graham Dumpleton All rights reserved. The BSD 2-Clause License The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.19408,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Python agent <em>licenses</em>",
        "sections": "Python agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Python Agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library Copyright License"
      },
      "id": "6044e7bbe7b9d242575799d1"
    },
    {
      "sections": [
        "Go agent licenses"
      ],
      "title": "Go agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "08a72af2529390cf6296870147ce00b64ea7f633",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/go-agent-licenses/",
      "published_at": "2021-07-02T14:49:26Z",
      "updated_at": "2021-03-16T04:25:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Go Go BSD The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.03333,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Go agent <em>licenses</em>",
        "sections": "Go agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Go Go BSD The remainder of the code is covered by the <em>New</em> <em>Relic</em> agent license agreement."
      },
      "id": "603ea506196a67b2b3a83dee"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/net-agent-licenses": [
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-07-02T14:08:04Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.05368,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> <em>APM</em>, including a large number contributed by the open source community. To view <em>licenses</em> for... See... <em>APM</em> agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-<em>apm</em>"
      },
      "id": "603e7895e7b9d24e832a07d5"
    },
    {
      "sections": [
        "Python agent licenses"
      ],
      "title": "Python agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "6949c60ba3a446b93561658282def2bb7a8721c3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/python-agent-licenses/",
      "published_at": "2021-07-02T14:09:08Z",
      "updated_at": "2021-05-05T16:20:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Python Agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library Copyright License asgiref Copyright © Django Software Foundation and individual contributors. The BSD 3-Clause License six Copyright © 2010-2013 Benjamin Peterson The MIT License time.monotonic Copyright © 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013 Python Software Foundation; All Rights Reserved Python Software Foundation urllib3 Copyright © 2008-2019 Andrey Petrov and contributors (see CONTRIBUTORS.txt) The MIT License wrapt Copyright © 2013-2019, Graham Dumpleton All rights reserved. The BSD 2-Clause License The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.19408,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Python agent <em>licenses</em>",
        "sections": "Python agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Python Agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library Copyright License"
      },
      "id": "6044e7bbe7b9d242575799d1"
    },
    {
      "sections": [
        "Go agent licenses"
      ],
      "title": "Go agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "08a72af2529390cf6296870147ce00b64ea7f633",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/go-agent-licenses/",
      "published_at": "2021-07-02T14:49:26Z",
      "updated_at": "2021-03-16T04:25:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Go Go BSD The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.03333,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Go agent <em>licenses</em>",
        "sections": "Go agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Go Go BSD The remainder of the code is covered by the <em>New</em> <em>Relic</em> agent license agreement."
      },
      "id": "603ea506196a67b2b3a83dee"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/net-agent-microsoft-azure-portal-extension-licenses": [
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-07-02T14:08:04Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.05368,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> <em>APM</em>, including a large number contributed by the open source community. To view <em>licenses</em> for... See... <em>APM</em> agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-<em>apm</em>"
      },
      "id": "603e7895e7b9d24e832a07d5"
    },
    {
      "sections": [
        "Python agent licenses"
      ],
      "title": "Python agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "6949c60ba3a446b93561658282def2bb7a8721c3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/python-agent-licenses/",
      "published_at": "2021-07-02T14:09:08Z",
      "updated_at": "2021-05-05T16:20:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Python Agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library Copyright License asgiref Copyright © Django Software Foundation and individual contributors. The BSD 3-Clause License six Copyright © 2010-2013 Benjamin Peterson The MIT License time.monotonic Copyright © 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013 Python Software Foundation; All Rights Reserved Python Software Foundation urllib3 Copyright © 2008-2019 Andrey Petrov and contributors (see CONTRIBUTORS.txt) The MIT License wrapt Copyright © 2013-2019, Graham Dumpleton All rights reserved. The BSD 2-Clause License The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.19408,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Python agent <em>licenses</em>",
        "sections": "Python agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Python Agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library Copyright License"
      },
      "id": "6044e7bbe7b9d242575799d1"
    },
    {
      "sections": [
        "Go agent licenses"
      ],
      "title": "Go agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "08a72af2529390cf6296870147ce00b64ea7f633",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/go-agent-licenses/",
      "published_at": "2021-07-02T14:49:26Z",
      "updated_at": "2021-03-16T04:25:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Go Go BSD The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.03333,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Go agent <em>licenses</em>",
        "sections": "Go agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Go Go BSD The remainder of the code is covered by the <em>New</em> <em>Relic</em> agent license agreement."
      },
      "id": "603ea506196a67b2b3a83dee"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/net-agent-microsoft-azure-portal-resource-provider-licenses": [
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-07-02T14:08:04Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.05368,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> <em>APM</em>, including a large number contributed by the open source community. To view <em>licenses</em> for... See... <em>APM</em> agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-<em>apm</em>"
      },
      "id": "603e7895e7b9d24e832a07d5"
    },
    {
      "sections": [
        "Python agent licenses"
      ],
      "title": "Python agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "6949c60ba3a446b93561658282def2bb7a8721c3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/python-agent-licenses/",
      "published_at": "2021-07-02T14:09:08Z",
      "updated_at": "2021-05-05T16:20:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Python Agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library Copyright License asgiref Copyright © Django Software Foundation and individual contributors. The BSD 3-Clause License six Copyright © 2010-2013 Benjamin Peterson The MIT License time.monotonic Copyright © 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013 Python Software Foundation; All Rights Reserved Python Software Foundation urllib3 Copyright © 2008-2019 Andrey Petrov and contributors (see CONTRIBUTORS.txt) The MIT License wrapt Copyright © 2013-2019, Graham Dumpleton All rights reserved. The BSD 2-Clause License The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.19408,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Python agent <em>licenses</em>",
        "sections": "Python agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Python Agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library Copyright License"
      },
      "id": "6044e7bbe7b9d242575799d1"
    },
    {
      "sections": [
        "Go agent licenses"
      ],
      "title": "Go agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "08a72af2529390cf6296870147ce00b64ea7f633",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/go-agent-licenses/",
      "published_at": "2021-07-02T14:49:26Z",
      "updated_at": "2021-03-16T04:25:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Go Go BSD The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.03333,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Go agent <em>licenses</em>",
        "sections": "Go agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Go Go BSD The remainder of the code is covered by the <em>New</em> <em>Relic</em> agent license agreement."
      },
      "id": "603ea506196a67b2b3a83dee"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses": [
    {
      "sections": [
        "Python agent licenses"
      ],
      "title": "Python agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "6949c60ba3a446b93561658282def2bb7a8721c3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/python-agent-licenses/",
      "published_at": "2021-07-02T14:09:08Z",
      "updated_at": "2021-05-05T16:20:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Python Agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library Copyright License asgiref Copyright © Django Software Foundation and individual contributors. The BSD 3-Clause License six Copyright © 2010-2013 Benjamin Peterson The MIT License time.monotonic Copyright © 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013 Python Software Foundation; All Rights Reserved Python Software Foundation urllib3 Copyright © 2008-2019 Andrey Petrov and contributors (see CONTRIBUTORS.txt) The MIT License wrapt Copyright © 2013-2019, Graham Dumpleton All rights reserved. The BSD 2-Clause License The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.19408,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Python agent <em>licenses</em>",
        "sections": "Python agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Python Agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library Copyright License"
      },
      "id": "6044e7bbe7b9d242575799d1"
    },
    {
      "sections": [
        "Go agent licenses"
      ],
      "title": "Go agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "08a72af2529390cf6296870147ce00b64ea7f633",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/go-agent-licenses/",
      "published_at": "2021-07-02T14:49:26Z",
      "updated_at": "2021-03-16T04:25:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Go Go BSD The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.03333,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Go agent <em>licenses</em>",
        "sections": "Go agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Go Go BSD The remainder of the code is covered by the <em>New</em> <em>Relic</em> agent license agreement."
      },
      "id": "603ea506196a67b2b3a83dee"
    },
    {
      "sections": [
        ".NET agent: Microsoft Azure Portal Extension licenses"
      ],
      "title": ".NET agent: Microsoft Azure Portal Extension licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "19d61cf14551e1be8895993d42d2c640d7cd238b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/net-agent-microsoft-azure-portal-extension-licenses/",
      "published_at": "2021-07-02T14:08:05Z",
      "updated_at": "2021-03-13T03:35:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Microsoft Azure Portal Extension. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Antlr BSD JSON.NET MIT PowerArgs MIT The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 168.67317,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET agent: Microsoft Azure Portal Extension <em>licenses</em>",
        "sections": ".NET agent: Microsoft Azure Portal Extension <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": " Antlr BSD JSON.NET MIT PowerArgs MIT The remainder of the code is covered by the <em>New</em> <em>Relic</em> License agreement found in the LICENSE file in the distribution."
      },
      "id": "6044e7bb64441f6e4e378f1a"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/nodejs-agent-licenses": [
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-07-02T14:08:04Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.05368,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> <em>APM</em>, including a large number contributed by the open source community. To view <em>licenses</em> for... See... <em>APM</em> agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-<em>apm</em>"
      },
      "id": "603e7895e7b9d24e832a07d5"
    },
    {
      "sections": [
        "Python agent licenses"
      ],
      "title": "Python agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "6949c60ba3a446b93561658282def2bb7a8721c3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/python-agent-licenses/",
      "published_at": "2021-07-02T14:09:08Z",
      "updated_at": "2021-05-05T16:20:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Python Agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library Copyright License asgiref Copyright © Django Software Foundation and individual contributors. The BSD 3-Clause License six Copyright © 2010-2013 Benjamin Peterson The MIT License time.monotonic Copyright © 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013 Python Software Foundation; All Rights Reserved Python Software Foundation urllib3 Copyright © 2008-2019 Andrey Petrov and contributors (see CONTRIBUTORS.txt) The MIT License wrapt Copyright © 2013-2019, Graham Dumpleton All rights reserved. The BSD 2-Clause License The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.19406,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Python agent <em>licenses</em>",
        "sections": "Python agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Python Agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library Copyright License"
      },
      "id": "6044e7bbe7b9d242575799d1"
    },
    {
      "sections": [
        "Go agent licenses"
      ],
      "title": "Go agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "08a72af2529390cf6296870147ce00b64ea7f633",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/go-agent-licenses/",
      "published_at": "2021-07-02T14:49:26Z",
      "updated_at": "2021-03-16T04:25:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Go Go BSD The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.03333,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Go agent <em>licenses</em>",
        "sections": "Go agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Go Go BSD The remainder of the code is covered by the <em>New</em> <em>Relic</em> agent license agreement."
      },
      "id": "603ea506196a67b2b3a83dee"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/php-agent-licenses": [
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-07-02T14:08:04Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.05368,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> <em>APM</em>, including a large number contributed by the open source community. To view <em>licenses</em> for... See... <em>APM</em> agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-<em>apm</em>"
      },
      "id": "603e7895e7b9d24e832a07d5"
    },
    {
      "sections": [
        "Python agent licenses"
      ],
      "title": "Python agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "6949c60ba3a446b93561658282def2bb7a8721c3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/python-agent-licenses/",
      "published_at": "2021-07-02T14:09:08Z",
      "updated_at": "2021-05-05T16:20:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Python Agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library Copyright License asgiref Copyright © Django Software Foundation and individual contributors. The BSD 3-Clause License six Copyright © 2010-2013 Benjamin Peterson The MIT License time.monotonic Copyright © 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013 Python Software Foundation; All Rights Reserved Python Software Foundation urllib3 Copyright © 2008-2019 Andrey Petrov and contributors (see CONTRIBUTORS.txt) The MIT License wrapt Copyright © 2013-2019, Graham Dumpleton All rights reserved. The BSD 2-Clause License The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.19406,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Python agent <em>licenses</em>",
        "sections": "Python agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Python Agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library Copyright License"
      },
      "id": "6044e7bbe7b9d242575799d1"
    },
    {
      "sections": [
        "Go agent licenses"
      ],
      "title": "Go agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "08a72af2529390cf6296870147ce00b64ea7f633",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/go-agent-licenses/",
      "published_at": "2021-07-02T14:49:26Z",
      "updated_at": "2021-03-16T04:25:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Go Go BSD The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.03333,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Go agent <em>licenses</em>",
        "sections": "Go agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Go Go BSD The remainder of the code is covered by the <em>New</em> <em>Relic</em> agent license agreement."
      },
      "id": "603ea506196a67b2b3a83dee"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/python-agent-licenses": [
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-07-02T14:08:04Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.05368,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> <em>APM</em>, including a large number contributed by the open source community. To view <em>licenses</em> for... See... <em>APM</em> agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-<em>apm</em>"
      },
      "id": "603e7895e7b9d24e832a07d5"
    },
    {
      "sections": [
        "Go agent licenses"
      ],
      "title": "Go agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "08a72af2529390cf6296870147ce00b64ea7f633",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/go-agent-licenses/",
      "published_at": "2021-07-02T14:49:26Z",
      "updated_at": "2021-03-16T04:25:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Go Go BSD The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.03333,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Go agent <em>licenses</em>",
        "sections": "Go agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Go Go BSD The remainder of the code is covered by the <em>New</em> <em>Relic</em> agent license agreement."
      },
      "id": "603ea506196a67b2b3a83dee"
    },
    {
      "sections": [
        ".NET agent: Microsoft Azure Portal Extension licenses"
      ],
      "title": ".NET agent: Microsoft Azure Portal Extension licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "19d61cf14551e1be8895993d42d2c640d7cd238b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/net-agent-microsoft-azure-portal-extension-licenses/",
      "published_at": "2021-07-02T14:08:05Z",
      "updated_at": "2021-03-13T03:35:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Microsoft Azure Portal Extension. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Antlr BSD JSON.NET MIT PowerArgs MIT The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 168.67317,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET agent: Microsoft Azure Portal Extension <em>licenses</em>",
        "sections": ".NET agent: Microsoft Azure Portal Extension <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": " Antlr BSD JSON.NET MIT PowerArgs MIT The remainder of the code is covered by the <em>New</em> <em>Relic</em> License agreement found in the LICENSE file in the distribution."
      },
      "id": "6044e7bb64441f6e4e378f1a"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-apm/ruby-agent-licenses": [
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-07-02T14:08:04Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.05368,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> <em>APM</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> <em>APM</em>, including a large number contributed by the open source community. To view <em>licenses</em> for... See... <em>APM</em> agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-<em>apm</em>"
      },
      "id": "603e7895e7b9d24e832a07d5"
    },
    {
      "sections": [
        "Python agent licenses"
      ],
      "title": "Python agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "6949c60ba3a446b93561658282def2bb7a8721c3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/python-agent-licenses/",
      "published_at": "2021-07-02T14:09:08Z",
      "updated_at": "2021-05-05T16:20:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Python Agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library Copyright License asgiref Copyright © Django Software Foundation and individual contributors. The BSD 3-Clause License six Copyright © 2010-2013 Benjamin Peterson The MIT License time.monotonic Copyright © 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013 Python Software Foundation; All Rights Reserved Python Software Foundation urllib3 Copyright © 2008-2019 Andrey Petrov and contributors (see CONTRIBUTORS.txt) The MIT License wrapt Copyright © 2013-2019, Graham Dumpleton All rights reserved. The BSD 2-Clause License The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.19406,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Python agent <em>licenses</em>",
        "sections": "Python agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Python Agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library Copyright License"
      },
      "id": "6044e7bbe7b9d242575799d1"
    },
    {
      "sections": [
        "Go agent licenses"
      ],
      "title": "Go agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "08a72af2529390cf6296870147ce00b64ea7f633",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/go-agent-licenses/",
      "published_at": "2021-07-02T14:49:26Z",
      "updated_at": "2021-03-16T04:25:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Go Go BSD The remainder of the code is covered by the New Relic agent license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.03333,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Go agent <em>licenses</em>",
        "sections": "Go agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Go agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Go Go BSD The remainder of the code is covered by the <em>New</em> <em>Relic</em> agent license agreement."
      },
      "id": "603ea506196a67b2b3a83dee"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-browser/browser-agent-licenses": [
    {
      "sections": [
        "New Relic Browser licenses",
        "UI tier"
      ],
      "title": "New Relic Browser licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Browser"
      ],
      "external_id": "b308c950e31570ee201237a88bfb8891da10a23c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-browser/new-relic-browser-licenses/",
      "published_at": "2021-07-02T17:17:24Z",
      "updated_at": "2021-03-16T04:45:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Browser. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. UI tier Library License DataStax Cassandra Java Driver Apache 2.0 d3 BSD Finagle Apache 2.0 gulp-rename MIT Jackson Apache 2.0 nee ISC nscala-time Apache 2.0 photocopy ISC Rapture Apache 2.0 React Apache 2.0 require.dir MIT Scrooge Apache 2.0 slf4j MIT snappy-java Apache 2.0 TwitterServer Apache 2.0 Typesafe Config Apache 2.0",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.65723,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> <em>Browser</em> <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> <em>Browser</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> <em>Browser</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. UI tier Library License DataStax"
      },
      "id": "603ece91e7b9d2c9d02a07c2"
    },
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-07-02T13:42:10Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.51733,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-07-02T14:08:04Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.35602,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> APM <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> APM <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> APM, including a large number contributed by the open source community. To view <em>licenses</em> for... See... APM agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-apm"
      },
      "id": "603e7895e7b9d24e832a07d5"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-browser/new-relic-browser-licenses": [
    {
      "sections": [
        "Browser agent licenses"
      ],
      "title": "Browser agent licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Browser"
      ],
      "external_id": "9fac9d2d566767575f22d9458e49410063a83406",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-browser/browser-agent-licenses/",
      "published_at": "2021-07-02T17:16:25Z",
      "updated_at": "2021-03-16T04:45:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Browser agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Browserify MIT Episodes Apache 2.0 Lo-Dash MIT TraceKit MIT",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.53958,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Browser</em> agent <em>licenses</em>",
        "sections": "<em>Browser</em> agent <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> <em>Browser</em> agent. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Browserify MIT Episodes Apache 2.0 Lo-Dash MIT TraceKit MIT"
      },
      "id": "603eb41ce7b9d298012a080a"
    },
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-07-02T13:42:10Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.51733,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-07-02T14:08:04Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.35602,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> APM <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> APM <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> APM, including a large number contributed by the open source community. To view <em>licenses</em> for... See... APM agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-apm"
      },
      "id": "603e7895e7b9d24e832a07d5"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-developer-edition/developer-edition": [
    {
      "sections": [
        "Developer Program Resources"
      ],
      "title": "Developer Program Resources",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Developer edition"
      ],
      "external_id": "8a2f08905c7dcd10e50e975783ca3cf0071324c0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-developer-edition/developer-program-resources/",
      "published_at": "2021-07-02T17:17:24Z",
      "updated_at": "2021-03-13T03:24:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As a customer, you are eligible to participate in New Relic’s Developer Program. Additional information and resources are available at New Relic’s Developer Program site. By downloading, accessing, or using the developer resources (including the CLI), you agree that usage of the developer resources is pursuant to the New Relic Developers Terms and Conditions and that you have the authority to bind your organization. Such terms do not have to be signed in order to be binding. If you do not agree to these terms and conditions, your sole remedy is to not use these developer resources. If your use of the New Relic developer resources are covered under a separate agreement, the above does not apply to you.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.28052,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Developer</em> Program Resources",
        "sections": "<em>Developer</em> Program Resources",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "As a customer, you are eligible to participate in <em>New</em> <em>Relic</em>’s <em>Developer</em> Program. Additional information and resources are available at <em>New</em> <em>Relic</em>’s <em>Developer</em> Program site. By downloading, accessing, or using the <em>developer</em> resources (including the CLI), you agree that usage of the <em>developer</em> resources"
      },
      "id": "6044e7bb196a676d20960f4d"
    },
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-07-02T13:42:10Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.1197,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-07-02T14:08:04Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 139.19287,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> APM <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> APM <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> APM, including a large number contributed by the open source community. To view <em>licenses</em> for... See... APM agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-apm"
      },
      "id": "603e7895e7b9d24e832a07d5"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-developer-edition/developer-program-resources": [
    {
      "sections": [
        "Developer edition",
        "Terms"
      ],
      "title": "Developer edition",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Developer edition"
      ],
      "external_id": "60bc94afd677817a7b7fd7dd471c537090a9f711",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-developer-edition/developer-edition/",
      "published_at": "2021-07-02T17:17:24Z",
      "updated_at": "2021-03-13T02:26:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "All new accounts (outside Japan) created on or after July 30, 2020 are on the New Relic One pricing plan and have the newer New Relic One user model as described here. If (i) your account was created prior to July 30, 2020; or (ii) you are a current New Relic K.K. customer (Japan): in addition to the New Relic Pre-release policy, use of the Developer Edition of New Relic to the extent it is available is also subject to the following terms: Terms Non-production use only Up to $500 per month in total product usage across the New Relic platform Up to 2 users",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.27469,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Developer</em> <em>edition</em>",
        "sections": "<em>Developer</em> <em>edition</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": " to the <em>New</em> <em>Relic</em> Pre-release policy, use of the <em>Developer</em> <em>Edition</em> of <em>New</em> <em>Relic</em> to the extent it is available is also subject to the following terms: Terms Non-production use only Up to $500 per month in total <em>product</em> usage across the <em>New</em> <em>Relic</em> platform Up to 2 users"
      },
      "id": "604506b9e7b9d22d115799c8"
    },
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-07-02T13:42:10Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.1197,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-07-02T14:08:04Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 139.19287,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> APM <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> APM <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> APM, including a large number contributed by the open source community. To view <em>licenses</em> for... See... APM agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-apm"
      },
      "id": "603e7895e7b9d24e832a07d5"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-infrastructure/new-relic-infrastructure-licenses": [
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-07-02T13:42:10Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.51733,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-07-02T14:08:04Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.35602,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> APM <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> APM <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> APM, including a large number contributed by the open source community. To view <em>licenses</em> for... See... APM agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-apm"
      },
      "id": "603e7895e7b9d24e832a07d5"
    },
    {
      "sections": [
        "New Relic Insights licenses"
      ],
      "title": "New Relic Insights licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Insights"
      ],
      "external_id": "3d0f8f4275af8bcf9f6f3ffb02a2e46ff3fc374f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-insights/new-relic-insights-licenses/",
      "published_at": "2021-07-02T15:42:10Z",
      "updated_at": "2021-03-13T04:04:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in New Relic Insights. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Product Licenses New Relic Insights See insights.newrelic.com/licenses",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 141.58337,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> Insights <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> Insights <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in <em>New</em> <em>Relic</em> Insights. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. <em>Product</em> <em>Licenses</em> <em>New</em> <em>Relic</em> Insights See insights.newrelic.com&#x2F;<em>licenses</em>"
      },
      "id": "6044e84428ccbcf6fa2c60c1"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-insights/new-relic-insights-licenses": [
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-07-02T13:42:10Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.51732,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-07-02T14:08:04Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.356,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> APM <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> APM <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> APM, including a large number contributed by the open source community. To view <em>licenses</em> for... See... APM agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-apm"
      },
      "id": "603e7895e7b9d24e832a07d5"
    },
    {
      "sections": [
        "Help Center and documentation licenses",
        "Drupal",
        "PHP libraries",
        "JavaScript libraries",
        "Other libraries"
      ],
      "title": "Help Center and documentation licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Miscellaneous"
      ],
      "external_id": "8d09fb862a5e7aeb4e562eae0b68019496d9c92a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/miscellaneous/help-center-documentation-licenses/",
      "published_at": "2021-07-02T15:40:22Z",
      "updated_at": "2021-03-13T03:32:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open source software, and use the following on docs.newrelic.com. Thank you, open source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Drupal Drupal and all modules contributed to Drupal are licensed under the GNU GPL v2 or higher. The following list includes third party libraries and modules downloaded from third party sites that may not fall under the Drupal licensing model. PHP libraries PHP License PHP PHP license v3.01 PHP SAML MIT PHP SASS BSD JavaScript libraries JavaScript License Backbone.js MIT Clipboard.js MIT Google Analytics Manually reviewed jQuery MIT Kissmetrics Manually reviewed Modernizr MIT Underscore MIT Other libraries Other License Ace Editor BSD CKEditor GPL, LGPL, MPL Font Awesome OFL, MIT",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.50227,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Help Center and documentation <em>licenses</em>",
        "sections": "Help Center and documentation <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open source software, and use the following on docs.newrelic.com. Thank you, open source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Drupal Drupal and all modules"
      },
      "id": "6044e74fe7b9d261ea5799f5"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-logs/logs-licenses": [
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-07-02T13:42:10Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.53828,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Logs</em> plugin <em>licenses</em>",
        "sections": "<em>Logs</em> plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": " used for <em>New</em> <em>Relic</em> <em>Logs</em>, see <em>Logs</em> <em>licenses</em>. Plugins for <em>Logs</em> The following <em>licenses</em> are for the plugins used to connects your <em>log</em> data with <em>New</em> <em>Relic</em> <em>Logs</em>. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 <em>New</em> <em>Relic</em>, Inc. Fluentd Library License Copyright Fluentd Apache"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-07-02T14:08:04Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 139.19287,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> APM <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> APM <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> APM, including a large number contributed by the open source community. To view <em>licenses</em> for... See... APM agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-apm"
      },
      "id": "603e7895e7b9d24e832a07d5"
    },
    {
      "sections": [
        "New Relic Insights licenses"
      ],
      "title": "New Relic Insights licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Insights"
      ],
      "external_id": "3d0f8f4275af8bcf9f6f3ffb02a2e46ff3fc374f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-insights/new-relic-insights-licenses/",
      "published_at": "2021-07-02T15:42:10Z",
      "updated_at": "2021-03-13T04:04:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in New Relic Insights. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Product Licenses New Relic Insights See insights.newrelic.com/licenses",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.52393,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> Insights <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> Insights <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in <em>New</em> <em>Relic</em> Insights. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. <em>Product</em> <em>Licenses</em> <em>New</em> <em>Relic</em> Insights See insights.newrelic.com&#x2F;<em>licenses</em>"
      },
      "id": "6044e84428ccbcf6fa2c60c1"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses": [
    {
      "sections": [
        "Logs licenses",
        "Logs"
      ],
      "title": "Logs licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "229757bf0e3d8f3518533b11a059b9e4516e4699",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-licenses/",
      "published_at": "2021-07-02T13:08:28Z",
      "updated_at": "2021-03-16T04:46:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for the New Relic Logs plugins, see Logs plugin licenses. Logs axios MIT Copyright © 2014-present Matt Zabriskie Babel-plugin-transform-runtime MIT Copyright © 2014-present Sebastian McKenzie and other contributors Classnames MIT Copyright © 2018 Jed Watson Downshift MIT Copyright © 2017 PayPal Fuzzy-search ISC Copyright © 2016, Wouter Rutgers Immer MIT Copyright © 2017 Michel Weststrate Lodash MIT Copyright © JS Foundation and other contributors Lodash.debounce MIT Copyright © JS Foundation and other contributors Moment MIT Copyright © JS Foundation and other contributors Node-sass MIT Copyright © 2013-2016 Andrew Nesbitt Prop-types MIT Copyright © 2013-present, Facebook, Inc. React MIT Copyright © Facebook, Inc. and its affiliates. React-dom MIT Copyright © Facebook, Inc. and its affiliates. React-highlight-words MIT Copyright © 2015 Treasure Data React-json-view MIT Copyright © 2015 Mac Gainor React-popper MIT Copyright © 2018 React Popper authors React-redux MIT Copyright © 2015-present Dan Abramov React-select MIT Copyright © 2018 Jed Watson React-tooltip MIT Copyright © 2015 Wang Zixiao Redux MIT Copyright © 2015-present Dan Abramov Redux-logger MIT Copyright © 2016 Eugene Rodionov Redux-saga MIT Copyright © 2015 Yassine Elouafi Reselect MIT Copyright © 2015-2018 Reselect Contributors Shortid MIT Copyright © Dylan Greene Snyk Apache License 2.0 Copyright © 2015 Snyk Ltd. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.53143,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Logs</em> <em>licenses</em>",
        "sections": "<em>Logs</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> <em>Logs</em> plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea57b28ccbce04ceba77a"
    },
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-07-02T14:08:04Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 139.19286,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> APM <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> APM <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> APM, including a large number contributed by the open source community. To view <em>licenses</em> for... See... APM agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-apm"
      },
      "id": "603e7895e7b9d24e832a07d5"
    },
    {
      "sections": [
        "New Relic Insights licenses"
      ],
      "title": "New Relic Insights licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Insights"
      ],
      "external_id": "3d0f8f4275af8bcf9f6f3ffb02a2e46ff3fc374f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-insights/new-relic-insights-licenses/",
      "published_at": "2021-07-02T15:42:10Z",
      "updated_at": "2021-03-13T04:04:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in New Relic Insights. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Product Licenses New Relic Insights See insights.newrelic.com/licenses",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.52393,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> Insights <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> Insights <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in <em>New</em> <em>Relic</em> Insights. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. <em>Product</em> <em>Licenses</em> <em>New</em> <em>Relic</em> Insights See insights.newrelic.com&#x2F;<em>licenses</em>"
      },
      "id": "6044e84428ccbcf6fa2c60c1"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-mobile/android-sdk-new-relic-mobile-licenses": [
    {
      "sections": [
        "iOS SDK for New Relic Mobile licenses"
      ],
      "title": "iOS SDK for New Relic Mobile licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Mobile"
      ],
      "external_id": "71d2df4a922b6728230da4b4e8241f2d458ea66c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-mobile/ios-sdk-new-relic-mobile-licenses/",
      "published_at": "2021-07-02T14:27:02Z",
      "updated_at": "2021-03-13T04:09:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the iOS SDK for New Relic Mobile. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Apple Reachability Apple Reachability JSON++ MIT mod-pbxproj BSD-3 PLCrashReporter MIT The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.50375,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS SDK for <em>New</em> <em>Relic</em> <em>Mobile</em> <em>licenses</em>",
        "sections": "iOS SDK for <em>New</em> <em>Relic</em> <em>Mobile</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the iOS SDK for <em>New</em> <em>Relic</em> <em>Mobile</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Apple"
      },
      "id": "60450cfde7b9d2c9eb5799c3"
    },
    {
      "sections": [
        "Android application licenses"
      ],
      "title": "Android application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "68c9bdc9dec6f02240f002494309519e41619f29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/android-application-licenses/",
      "published_at": "2021-07-02T15:40:23Z",
      "updated_at": "2021-05-05T16:29:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Third Party Dependencies License Copyright Android-FlowLayout Apache 2.0 Copyright © 2011, Artem Votincev (apmem.org) AVLoadingIndicatorView Apache 2.0 Copyright © 2015, Jack Wang BottomNavigationViewEx MIT Copyright © 2017, ittianyu Butterknife Apache 2.0 Copyright © 2013, Jake Wharton Crouton Apache 2.0 Copyright © 2012 - 2014, Benjamin Weiss CWAC-SafeRoom Apache 2.0 The copyrights are owned by CommonsWare for things unique to this library and a combination of CommonsWare and the Android Open Source Project for code modified from the Architecture Components' Framework* set of classes. Dagger 2 Apache 2.0 Copyright © 2012, The Dagger Authors Dragtop Layout Apache 2.0 Copyright © 2015, chenupt EventBus Apache 2.0 Copyright © 2012-2017 Markus Junginger, greenrobot FlexibleAdapter Apache 2.0 Copyright © 2015-2018 Davide Steduto, Davidea Solutions Sprl Gson Apache 2.0 Copyright © 2008, Google Inc. markwon Apache 2.0 Copyright © 2019 Dimitry Ivanov (legal@noties.io) mockk Apache 2.0 Copyright © [ 2017] [ github.com/mockk] leakcanary Apache 2.0 Copyright © 2015 Square, Inc. mockito mockito MIT Copyright © 2007 Mockito contributors mosby Apache 2.0 Copyright © 2015 Hannes Dorfmann moshi Apache 2.0 Copyright © 2015 Square, Inc. MPAndroidChart Apache 2.0 Copyright © 2019 Philipp Jahoda New Relic Mobile Agent OKHttp Apache 2.0 Copyright © 2019 Square, Inc. okio Apache 2.0 Copyright © 2013 Square, Inc. Picasso Apache 2.0 Copyright © 2013 Square, Inc. RESTMock Apache 2.0 Copyright © 2016 Appflate.io Retrofit Apache 2.0 Copyright © 2013 Square, Inc. RxJava Apache 2.0 Copyright © 2016-present, RxJava Contributors. Segment IO MIT Copyright © 2016 Segment, Inc. Snackyaml Apache 2.0 Copyright © 2008, www.snakeyaml.org. StickyHeaders Apache 2.0 Copyright © 2014 Emil Sjölander TableView Apache 2.0 Copyright © 2017 Evren Coşkun Transitions-Everywhere Apache 2.0 The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.88385,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android application <em>licenses</em>",
        "sections": "Android application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Third Party Dependencies"
      },
      "id": "603e9e30196a67b71fa83d96"
    },
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-07-02T13:42:10Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.1197,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-mobile/ios-sdk-new-relic-mobile-licenses": [
    {
      "sections": [
        "Android SDK for New Relic Mobile licenses"
      ],
      "title": "Android SDK for New Relic Mobile licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Mobile"
      ],
      "external_id": "7e7fa828754c2ba00d4e2138653c7cdd00ed6c90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-mobile/android-sdk-new-relic-mobile-licenses/",
      "published_at": "2021-07-02T14:49:25Z",
      "updated_at": "2021-03-16T04:46:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the Android SDK for New Relic Mobile. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Android SDK Creative Commons Attribution Apache Commons IO Apache 2.0 Apache Commons Logging Apache 2.0 Apache HttpClient Apache 2.0 ASM ASM (BSD-3 style) Gradle Apache 2.0 Gson Apache 2.0 Guava Apache 2.0 JarJar Apache 2.0 Javassist Apache 2.0 org.json JSON Reflections WTFPL SLF4J MIT Square OkHttp Apache 2.0 The remainder of the code is covered by the New Relic License agreement found in the LICENSE file in the distribution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.08408,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android SDK for <em>New</em> <em>Relic</em> <em>Mobile</em> <em>licenses</em>",
        "sections": "Android SDK for <em>New</em> <em>Relic</em> <em>Mobile</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the Android SDK for <em>New</em> <em>Relic</em> <em>Mobile</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License"
      },
      "id": "603e9eb628ccbc117beba796"
    },
    {
      "sections": [
        "Android application licenses"
      ],
      "title": "Android application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "68c9bdc9dec6f02240f002494309519e41619f29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/android-application-licenses/",
      "published_at": "2021-07-02T15:40:23Z",
      "updated_at": "2021-05-05T16:29:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Third Party Dependencies License Copyright Android-FlowLayout Apache 2.0 Copyright © 2011, Artem Votincev (apmem.org) AVLoadingIndicatorView Apache 2.0 Copyright © 2015, Jack Wang BottomNavigationViewEx MIT Copyright © 2017, ittianyu Butterknife Apache 2.0 Copyright © 2013, Jake Wharton Crouton Apache 2.0 Copyright © 2012 - 2014, Benjamin Weiss CWAC-SafeRoom Apache 2.0 The copyrights are owned by CommonsWare for things unique to this library and a combination of CommonsWare and the Android Open Source Project for code modified from the Architecture Components' Framework* set of classes. Dagger 2 Apache 2.0 Copyright © 2012, The Dagger Authors Dragtop Layout Apache 2.0 Copyright © 2015, chenupt EventBus Apache 2.0 Copyright © 2012-2017 Markus Junginger, greenrobot FlexibleAdapter Apache 2.0 Copyright © 2015-2018 Davide Steduto, Davidea Solutions Sprl Gson Apache 2.0 Copyright © 2008, Google Inc. markwon Apache 2.0 Copyright © 2019 Dimitry Ivanov (legal@noties.io) mockk Apache 2.0 Copyright © [ 2017] [ github.com/mockk] leakcanary Apache 2.0 Copyright © 2015 Square, Inc. mockito mockito MIT Copyright © 2007 Mockito contributors mosby Apache 2.0 Copyright © 2015 Hannes Dorfmann moshi Apache 2.0 Copyright © 2015 Square, Inc. MPAndroidChart Apache 2.0 Copyright © 2019 Philipp Jahoda New Relic Mobile Agent OKHttp Apache 2.0 Copyright © 2019 Square, Inc. okio Apache 2.0 Copyright © 2013 Square, Inc. Picasso Apache 2.0 Copyright © 2013 Square, Inc. RESTMock Apache 2.0 Copyright © 2016 Appflate.io Retrofit Apache 2.0 Copyright © 2013 Square, Inc. RxJava Apache 2.0 Copyright © 2016-present, RxJava Contributors. Segment IO MIT Copyright © 2016 Segment, Inc. Snackyaml Apache 2.0 Copyright © 2008, www.snakeyaml.org. StickyHeaders Apache 2.0 Copyright © 2014 Emil Sjölander TableView Apache 2.0 Copyright © 2017 Evren Coşkun Transitions-Everywhere Apache 2.0 The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.88385,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android application <em>licenses</em>",
        "sections": "Android application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Third Party Dependencies"
      },
      "id": "603e9e30196a67b71fa83d96"
    },
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-07-02T13:42:10Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.11969,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-one/preview-access-new-relic-one": [
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-07-02T13:42:10Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.11969,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-07-02T14:08:04Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 139.19286,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> APM <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> APM <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> APM, including a large number contributed by the open source community. To view <em>licenses</em> for... See... APM agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-apm"
      },
      "id": "603e7895e7b9d24e832a07d5"
    },
    {
      "sections": [
        "New Relic Insights licenses"
      ],
      "title": "New Relic Insights licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Insights"
      ],
      "external_id": "3d0f8f4275af8bcf9f6f3ffb02a2e46ff3fc374f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-insights/new-relic-insights-licenses/",
      "published_at": "2021-07-02T15:42:10Z",
      "updated_at": "2021-03-13T04:04:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in New Relic Insights. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Product Licenses New Relic Insights See insights.newrelic.com/licenses",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.52393,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> Insights <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> Insights <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in <em>New</em> <em>Relic</em> Insights. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. <em>Product</em> <em>Licenses</em> <em>New</em> <em>Relic</em> Insights See insights.newrelic.com&#x2F;<em>licenses</em>"
      },
      "id": "6044e84428ccbcf6fa2c60c1"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-plugins/plugins-licenses": [
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-07-02T13:42:10Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 170.24004,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs <em>plugin</em> <em>licenses</em>",
        "sections": "Logs <em>plugin</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Logs <em>plugins</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "Logs licenses",
        "Logs"
      ],
      "title": "Logs licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "229757bf0e3d8f3518533b11a059b9e4516e4699",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-licenses/",
      "published_at": "2021-07-02T13:08:28Z",
      "updated_at": "2021-03-16T04:46:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for the New Relic Logs plugins, see Logs plugin licenses. Logs axios MIT Copyright © 2014-present Matt Zabriskie Babel-plugin-transform-runtime MIT Copyright © 2014-present Sebastian McKenzie and other contributors Classnames MIT Copyright © 2018 Jed Watson Downshift MIT Copyright © 2017 PayPal Fuzzy-search ISC Copyright © 2016, Wouter Rutgers Immer MIT Copyright © 2017 Michel Weststrate Lodash MIT Copyright © JS Foundation and other contributors Lodash.debounce MIT Copyright © JS Foundation and other contributors Moment MIT Copyright © JS Foundation and other contributors Node-sass MIT Copyright © 2013-2016 Andrew Nesbitt Prop-types MIT Copyright © 2013-present, Facebook, Inc. React MIT Copyright © Facebook, Inc. and its affiliates. React-dom MIT Copyright © Facebook, Inc. and its affiliates. React-highlight-words MIT Copyright © 2015 Treasure Data React-json-view MIT Copyright © 2015 Mac Gainor React-popper MIT Copyright © 2018 React Popper authors React-redux MIT Copyright © 2015-present Dan Abramov React-select MIT Copyright © 2018 Jed Watson React-tooltip MIT Copyright © 2015 Wang Zixiao Redux MIT Copyright © 2015-present Dan Abramov Redux-logger MIT Copyright © 2016 Eugene Rodionov Redux-saga MIT Copyright © 2015 Yassine Elouafi Reselect MIT Copyright © 2015-2018 Reselect Contributors Shortid MIT Copyright © Dylan Greene Snyk Apache License 2.0 Copyright © 2015 Snyk Ltd. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 156.1431,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs <em>licenses</em>",
        "sections": "Logs <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": " used for the <em>New</em> <em>Relic</em> Logs <em>plugins</em>, see Logs <em>plugin</em> <em>licenses</em>. Logs axios MIT Copyright © 2014-present Matt Zabriskie Babel-<em>plugin</em>-transform-runtime MIT Copyright © 2014-present Sebastian McKenzie and other contributors Classnames MIT Copyright © 2018 Jed Watson Downshift MIT Copyright © 2017 PayPal"
      },
      "id": "603ea57b28ccbce04ceba77a"
    },
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-07-02T14:08:04Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 139.19286,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> APM <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> APM <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> APM, including a large number contributed by the open source community. To view <em>licenses</em> for... See... APM agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-apm"
      },
      "id": "603e7895e7b9d24e832a07d5"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-synthetics/new-relic-synthetics-licenses": [
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-07-02T13:42:10Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0 © 2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0 © 2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0 © 2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0 © 2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0 © 2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright © 2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright © 1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright © 2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright © 1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright © 1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.11969,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-07-02T14:08:04Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 139.19286,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> APM <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> APM <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create <em>New</em> <em>Relic</em> APM, including a large number contributed by the open source community. To view <em>licenses</em> for... See... APM agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;<em>new</em>-<em>relic</em>-apm"
      },
      "id": "603e7895e7b9d24e832a07d5"
    },
    {
      "sections": [
        "New Relic Insights licenses"
      ],
      "title": "New Relic Insights licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Insights"
      ],
      "external_id": "3d0f8f4275af8bcf9f6f3ffb02a2e46ff3fc374f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-insights/new-relic-insights-licenses/",
      "published_at": "2021-07-02T15:42:10Z",
      "updated_at": "2021-03-13T04:04:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in New Relic Insights. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Product Licenses New Relic Insights See insights.newrelic.com/licenses",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.52393,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> Insights <em>licenses</em>",
        "sections": "<em>New</em> <em>Relic</em> Insights <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in <em>New</em> <em>Relic</em> Insights. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. <em>Product</em> <em>Licenses</em> <em>New</em> <em>Relic</em> Insights See insights.newrelic.com&#x2F;<em>licenses</em>"
      },
      "id": "6044e84428ccbcf6fa2c60c1"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/configure-logs-context/configure-logs-context-apm-agents": [
    {
      "sections": [
        "Node.js: Configure with Winston",
        "Compatibility and requirements",
        "Configure logs in context with log monitoring",
        "Enable log monitoring",
        "Install or update the Node.js agent",
        "Configure the Winston extension",
        "Check for logging data",
        "Troubleshooting",
        "What's next?"
      ],
      "title": "Node.js: Configure with Winston",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Node.js"
      ],
      "external_id": "0ed58684c33d758f2bdc599295fa356d9418702e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-nodejs/nodejs-configure-winston/",
      "published_at": "2021-07-02T13:26:55Z",
      "updated_at": "2021-03-13T01:09:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Winston extension to link your log data with related data across the rest of the New Relic platform. Read on to learn how to configure logs in context and enrich your log data. Compatibility and requirements To use New Relic logs in context with Winston, ensure your configuration meets the following requirements: Node.js agent 6.2.0 or higher: Install or update Winston version 3.0.0 or higher Configure logs in context with log monitoring To configure logs in context with Winston: Enable log monitoring with a compatible log forwarding plugin. Install or update the Node.js agent. Configure the Winston extension. Check for logging data. Enable log monitoring Confirm that you have log monitoring enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Node.js agent Install or update to the most recent Node.js agent version, and enable Distributed tracing. Configure the Winston extension To configure logs in context with the Winston extension, complete the following steps: To install the New Relic Winston log enricher, enter the following command into your terminal or command line interface: npm install @newrelic/winston-enricher Copy In your application code, update your logging configuration to add the newrelicFormatter as shown below: // index.js require('newrelic') const newrelicFormatter = require('@newrelic/winston-enricher') Copy The New Relic formatter can be used individually or combined with other formatters as the final format. format: winston.format.combine( winston.format.label({label: 'test'}), newrelicFormatter() ) Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. Troubleshooting Problem Not all log data in a message or for a specific attribute is being displayed. Cause The stack trace will be written to the error.stack property. To accommodate the 4000 character log line limit for New Relic Logs, the stack and trace properties will be removed and the message, error.message and error.stack values will be truncated to 1024 characters. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 222.45926,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Node.js: <em>Configure</em> with Winston",
        "sections": "<em>Configure</em> <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> monitoring",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " version, and <em>enable</em> Distributed tracing. <em>Configure</em> the Winston extension To <em>configure</em> <em>logs</em> in <em>context</em> with the Winston extension, complete the following steps: To install the <em>New</em> <em>Relic</em> Winston <em>log</em> enricher, enter the following command into your terminal or command line interface: npm install"
      },
      "id": "60450d71196a675ce1960f82"
    },
    {
      "sections": [
        "Configure logs in context for Go",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Go agent",
        "Configure logs in context using the Logrus extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Configure logs in context for Go",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Go"
      ],
      "external_id": "b99217c9f669b61dc96bdc21f3a183b84ab0c801",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-go/configure-logs-context-go/",
      "published_at": "2021-07-02T13:09:31Z",
      "updated_at": "2021-03-16T08:39:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the Go agent connects your logs and APM data in New Relic, giving full context to high-level events, as well as providing high value data to specific log lines. Read on to learn how to configure logs in context and enrich your log data. Compatibility and requirements To use log management with the Go agent, ensure your configuration meets the following requirements: Go agent 2.12 or higher: Install or update Logrus logging framework v1.4.0 or higher Configure logs in context with log management To configure New Relic logs in context with Go: Enable log management with a compatible log forwarding plugin. Install or update the Go agent. Configure logs in context using the Logrus extension. Optional: Configure the Logrus extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Go agent Install or update to the most recent Go agent version, and enable Distributed tracing. Configure logs in context using the Logrus extension To configure the Logrus plugin: This step assumes that you have imported the following packages in files where Logrus is configured: import ( log \"github.com/sirupsen/logrus\" \"github.com/newrelic/go-agent/v3/integrations/logcontext/nrlogrusplugin\" \"github.com/newrelic/go-agent/v3/newrelic\" ) Copy Set the Logrus formatter to nrlogrusplugin.ContextFormatter: logger := log.New() logger.SetFormatter(nrlogrusplugin.ContextFormatter{}) Copy Or, if you are using the Logrus standard logger: log.SetFormatter(nrlogrusplugin.ContextFormatter{}) Copy The logger will now look for a newrelic.Transaction inside its context and decorate logs accordingly. Update your standard logging call to include contextual logging and pass this to the logger. For example, instead of logger.Info(\"Hello New Relic!\"), use ctx := newrelic.NewContext(context.Background(), txn) logger.WithContext(ctx).Info(\"Hello New Relic!\") Copy where txn is the current running transaction. Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has:span.id OR has:trace.id What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 220.59956,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Configure</em> <em>logs</em> <em>in</em> <em>context</em> for Go",
        "sections": "<em>Configure</em> <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " <em>management</em> with the Go agent, ensure your configuration meets the following requirements: Go agent 2.12 or higher: Install or update Logrus logging framework v1.4.0 or higher <em>Configure</em> <em>logs</em> in <em>context</em> with <em>log</em> <em>management</em> To <em>configure</em> <em>New</em> <em>Relic</em> <em>logs</em> in <em>context</em> with Go: <em>Enable</em> <em>log</em> <em>management</em>"
      },
      "id": "603ea67c28ccbc0c01eba74e"
    },
    {
      "sections": [
        "Java: Configure with Log4j 1.x",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Log4j 1.x extension",
        "Example configuration file for the Log4j 1.x extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Log4j 1.x",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "c037c5f99fbe16c9ae129d177d246009df25fb45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-1x/",
      "published_at": "2021-07-02T13:23:38Z",
      "updated_at": "2021-04-16T21:20:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Log4j 1.x extension for New Relic log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Log4j 1.x, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Log4j 1.x package installed and working on the application. log4j must be configured in code or via XML. Properties files are not supported because AsyncAppender instances can only be automatically configured via XML. Configure logs in context with log management To configure logs in context with Logs4j 1.x: Enable log management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Log4j 1.x extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable Distributed tracing. Configure the Log4j 1.x extension To configure logs in context with the Log4j 1.x extension, complete the following steps: Update your project's dependencies to include the Log4j 1.x extension as applicable: To update with Gradle, add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j1:2.0\") } Copy To update with Maven, add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j1</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <appender> element with a NewRelicLayout, adding <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> as shown below: <appender name=\" TypicalFile \" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <layout class=\" com.newrelic.logging.log4j1.NewRelicLayout \"/> <!-- only this line needs to be added --> </appender> Copy Once updated, use NewRelicAsyncAppender to wrap any appenders that will target New Relic's log forwarder. For example: <appender name=\" NewRelicFile \" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\" TypicalFile \" /> </appender> Copy Once updated, use the async appender on the root logger. For example: <root> <appender-ref ref=\" NewRelicFile \" /> </root> Copy Example configuration file for the Log4j 1.x extension <?xml version=\"1.0\" encoding=\"UTF-8\" ?> <!DOCTYPE log4j:configuration SYSTEM \"log4j.dtd\"> <log4j:configuration debug=\"false\"> <appender name=\"TypicalFile\" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <!-- layout has been replaced --> <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> </appender> <!-- this appender was added --> <appender name=\"NewRelicFile\" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\"TypicalFile\" /> </appender> <appender name=\"TypicalConsole\" class=\"org.apache.log4j.ConsoleAppender\"> <layout class=\"org.apache.log4j.PatternLayout\"> <param name=\"ConversionPattern\" value=\"%-5p %c{1} - %m%n\"/> </layout> </appender> <root> ​ <!-- the new appender was used here -->​​ <appender-ref ref=\"NewRelicFile\" /> <appender-ref ref=\"TypicalConsole\" /> </root> </log4j:configuration> Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 220.12465,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Java: <em>Configure</em> with <em>Log4j</em> 1.x",
        "sections": "<em>Configure</em> <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>New</em> <em>Relic</em> offers a <em>Log</em>4j 1.x extension for <em>New</em> <em>Relic</em> <em>log</em> <em>management</em>, allowing you link to your <em>log</em> data with related data across the rest of the <em>New</em> <em>Relic</em> platform. This document explains how to <em>configure</em> <em>logs</em> in <em>context</em> and start getting <em>log</em> data. The code and an example application are available"
      },
      "id": "603ead8b196a675ad7a83dd6"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/aws-firelens-plugin-log-forwarding": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Tip",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent(#automatically-inserted-attributes)",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-07-02T17:22:19Z",
      "updated_at": "2021-06-25T23:18:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use log management and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x and 18.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes as key-value pairs that can be used to send additional data with the logs which you can then query. Add attributes to any log source. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent(#automatically-inserted-attributes) The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 270.1254,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure <em>monitoring</em> agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use <em>log</em> <em>management</em> and the rest of our observability"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Vector output sink for log forwarding",
        "Compatibility and requirements",
        "Configure the Vector New Relic Logs sink",
        "Configure with the New Relic license key (recommended)",
        "Configure with the New Relic Insert API key",
        "Test the Vector New Relic logs sink",
        "View log data",
        "What's next?"
      ],
      "title": "Vector output sink for log forwarding",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "b2c621a62e9cc89c6b52e1a3e49411fb120b0de5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/vector-output-sink-log-forwarding/",
      "published_at": "2021-07-02T17:24:30Z",
      "updated_at": "2021-05-22T16:44:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Vector output sink to connect your Vector-monitored log data to New Relic. Read on to learn how to configure and test the Vector New Relic logs sink. Compatibility and requirements To forward your logs to New Relic using Vector, ensure your configuration meets the following requirements: New Relic license key (recommended) or Insert API key Vector version 0.7.0 or higher Configure the Vector New Relic Logs sink To configure the Vector New Relic logs sink: Choose one of the following options for adding a snippet to your vector.toml file (located in /etc/vector by default): Configure with the New Relic license key (recommended) Replace YOUR_LICENSE_KEY with the New Relic license key: # Ingest data by tailing one or more files [sources.mylog] type = \"file\" include = [\"/path/to/file\"] # Specify file or files to be tailed ignore_older = 86400 # Ignore events older than 1 day file_key = \"file\" # Add filename to log events host_key = \"host\" # Add hostname to log events # Configure sink to forward events to New Relic Logs [sinks.new_relic_logs] # REQUIRED type = \"new_relic_logs\" # must be: \"new_relic_logs\" inputs = [\"mylog\"] # example - value must be one or more source IDs license_key = \"YOUR_LICENSE_KEY\" region = \"us\" # Enum, must be one of: \"us\" \"eu\" depending on your New Relic Logs account region encoding.codec = \"json\" # OPTIONAL healthcheck = true # default Copy Configure with the New Relic Insert API key Replace YOUR_INSERT_KEY with the Insert API key: # Ingest data by tailing one or more files [sources.mylog] type = \"file\" include = [\"/path/to/file\"] # Specify file or files to be tailed ignore_older = 86400 # Ignore events older than 1 day file_key = \"file\" # Add filename to log events host_key = \"host\" # Add hostname to log events # Configure sink to forward events to New Relic Logs [sinks.new_relic_logs] # REQUIRED type = \"new_relic_logs\" # must be: \"new_relic_logs\" inputs = [\"mylog\"] # example - value must be one or more source IDs insert_key = \"YOUR_INSERT_KEY\" region = \"us\" # Enum, must be one of: \"us\" \"eu\" depending on your New Relic Logs account region encoding.codec = \"json\" # OPTIONAL healthcheck = true # default Copy Restart the Vector service to ensure your changes are applied. Test the Vector New Relic logs sink To test if the New Relic logs sink is forwarding events: Run the following command to append a test log message to your log file: echo \"test message\" >> /PATH/TO/YOUR/LOG/FILE Copy Search New Relic Logs UI for your test message. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable New Relic Logs, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.66756,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Vector output sink for <em>log</em> forwarding",
        "sections": "Configure the Vector <em>New</em> <em>Relic</em> <em>Logs</em> sink",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": ". For example, you can execute a query like this: SELECT * FROM <em>Log</em> Copy What&#x27;s next? Now that you&#x27;ve enabled <em>Logs</em>, here are some potential next steps: Explore your data using the <em>Logs</em> UI. Configure your agent to see contextual <em>log</em> data, such as distributed tracing, stack traces, application <em>logs</em>, and more. Query your data and create custom dashboards or alerts. If no data appears after you <em>enable</em> <em>New</em> <em>Relic</em> <em>Logs</em>, follow the troubleshooting procedures."
      },
      "id": "6045057664441f9a4a378f17"
    },
    {
      "sections": [
        "Logstash plugin for log forwarding",
        "Compatibility and requirements",
        "Enable Logstash for log management",
        "Install the Logstash plugin",
        "Configure the Logstash plugin",
        "Optional configuration",
        "Test the Logstash plugin",
        "View log data",
        "What's next?"
      ],
      "title": "Logstash plugin for log forwarding",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "62c6a8a5a160b466aaa7f852a085e47290169de1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/logstash-plugin-log-forwarding/",
      "published_at": "2021-07-02T17:23:20Z",
      "updated_at": "2021-05-16T06:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Logstash output plugin to connect your Logstash monitored log data to New Relic. Read on to learn how to enable this feature. Compatibility and requirements To forward your logs to New Relic using Logstash, ensure your configuration meets the following requirements: New Relic license key (recommended) or Insert API key Logstash 6.6 or higher Logstash requires Java 8 or Java 11. Use the official Oracle distribution or an open-source distribution such as OpenJDK. Enable Logstash for log management To enable log management using Logstash: Install the Logstash plugin. Configure the Logstash plugin. Optional: Configure additional plugin attributes. Test the Logstash plugin. Generate some traffic and wait a few minutes, then check your account for data. Install the Logstash plugin To install the Logstash plugin, enter the following command into your terminal or command line interface: logstash-plugin install logstash-output-newrelic Copy Configure the Logstash plugin To configure your Logstash plugin: In your logstash.conf file, add the following block of data. Be sure to replace the placeholder text with your New Relic license key or Insights Insert key. Configure with the New Relic license key (recommended): output { newrelic { license_key => \"LICENSE_KEY\" } } Copy Or, configure with the New Relic Insert API key: output { newrelic { api_key => \"INSERT_API_KEY\" } } Copy Restart your Logstash instance. Optional configuration Once you have installed and configured the Logstash plugin, you can use the following attributes to configure how the plugin sends data to New Relic: Property Description Default value concurrent_requests The number of threads to make requests from. 1 base_uri The New Relic ingestion endpoint. US endpoint: https://log-api.newrelic.com/log/v1 EU endpoint: https://log-api.eu.newrelic.com/log/v1 max_retries Maximum number attempts to retry to send a message. If set to 0, no re-attempts will be made. 3 For more information on adding or configuring attributes, see Example Configurations for Logstash. Test the Logstash plugin To test if your Logstash plugin is receiving input from a log file: Add the following to your logstash.conf file: input { file { path => \"/PATH/TO/YOUR/LOG/FILE\" } } Copy Restart your Logstash instance. Run the following command to append a test log message to your log file: echo \"test message\" >> /PATH/TO/YOUR/LOG/FILE Copy Search New Relic Logs UI for test message. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable New Relic Logs, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.70963,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Logstash</em> plugin for <em>log</em> forwarding",
        "sections": "<em>Enable</em> <em>Logstash</em> for <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "Use our Logstash output plugin to connect your Logstash monitored <em>log</em> data to <em>New</em> <em>Relic</em>. Read on to learn how to <em>enable</em> this feature. Compatibility and requirements To forward your <em>logs</em> to <em>New</em> <em>Relic</em> using Logstash, ensure your configuration meets the following requirements: <em>New</em> <em>Relic</em> license key"
      },
      "id": "603ebf8a28ccbc2307eba794"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/aws-lambda-sending-cloudwatch-logs": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Tip",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent(#automatically-inserted-attributes)",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-07-02T17:22:19Z",
      "updated_at": "2021-06-25T23:18:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use log management and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x and 18.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes as key-value pairs that can be used to send additional data with the logs which you can then query. Add attributes to any log source. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent(#automatically-inserted-attributes) The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 270.12534,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure <em>monitoring</em> agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use <em>log</em> <em>management</em> and the rest of our observability"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Vector output sink for log forwarding",
        "Compatibility and requirements",
        "Configure the Vector New Relic Logs sink",
        "Configure with the New Relic license key (recommended)",
        "Configure with the New Relic Insert API key",
        "Test the Vector New Relic logs sink",
        "View log data",
        "What's next?"
      ],
      "title": "Vector output sink for log forwarding",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "b2c621a62e9cc89c6b52e1a3e49411fb120b0de5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/vector-output-sink-log-forwarding/",
      "published_at": "2021-07-02T17:24:30Z",
      "updated_at": "2021-05-22T16:44:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Vector output sink to connect your Vector-monitored log data to New Relic. Read on to learn how to configure and test the Vector New Relic logs sink. Compatibility and requirements To forward your logs to New Relic using Vector, ensure your configuration meets the following requirements: New Relic license key (recommended) or Insert API key Vector version 0.7.0 or higher Configure the Vector New Relic Logs sink To configure the Vector New Relic logs sink: Choose one of the following options for adding a snippet to your vector.toml file (located in /etc/vector by default): Configure with the New Relic license key (recommended) Replace YOUR_LICENSE_KEY with the New Relic license key: # Ingest data by tailing one or more files [sources.mylog] type = \"file\" include = [\"/path/to/file\"] # Specify file or files to be tailed ignore_older = 86400 # Ignore events older than 1 day file_key = \"file\" # Add filename to log events host_key = \"host\" # Add hostname to log events # Configure sink to forward events to New Relic Logs [sinks.new_relic_logs] # REQUIRED type = \"new_relic_logs\" # must be: \"new_relic_logs\" inputs = [\"mylog\"] # example - value must be one or more source IDs license_key = \"YOUR_LICENSE_KEY\" region = \"us\" # Enum, must be one of: \"us\" \"eu\" depending on your New Relic Logs account region encoding.codec = \"json\" # OPTIONAL healthcheck = true # default Copy Configure with the New Relic Insert API key Replace YOUR_INSERT_KEY with the Insert API key: # Ingest data by tailing one or more files [sources.mylog] type = \"file\" include = [\"/path/to/file\"] # Specify file or files to be tailed ignore_older = 86400 # Ignore events older than 1 day file_key = \"file\" # Add filename to log events host_key = \"host\" # Add hostname to log events # Configure sink to forward events to New Relic Logs [sinks.new_relic_logs] # REQUIRED type = \"new_relic_logs\" # must be: \"new_relic_logs\" inputs = [\"mylog\"] # example - value must be one or more source IDs insert_key = \"YOUR_INSERT_KEY\" region = \"us\" # Enum, must be one of: \"us\" \"eu\" depending on your New Relic Logs account region encoding.codec = \"json\" # OPTIONAL healthcheck = true # default Copy Restart the Vector service to ensure your changes are applied. Test the Vector New Relic logs sink To test if the New Relic logs sink is forwarding events: Run the following command to append a test log message to your log file: echo \"test message\" >> /PATH/TO/YOUR/LOG/FILE Copy Search New Relic Logs UI for your test message. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable New Relic Logs, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.66754,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Vector output sink for <em>log</em> forwarding",
        "sections": "Configure the Vector <em>New</em> <em>Relic</em> <em>Logs</em> sink",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": ". For example, you can execute a query like this: SELECT * FROM <em>Log</em> Copy What&#x27;s next? Now that you&#x27;ve enabled <em>Logs</em>, here are some potential next steps: Explore your data using the <em>Logs</em> UI. Configure your agent to see contextual <em>log</em> data, such as distributed tracing, stack traces, application <em>logs</em>, and more. Query your data and create custom dashboards or alerts. If no data appears after you <em>enable</em> <em>New</em> <em>Relic</em> <em>Logs</em>, follow the troubleshooting procedures."
      },
      "id": "6045057664441f9a4a378f17"
    },
    {
      "sections": [
        "Logstash plugin for log forwarding",
        "Compatibility and requirements",
        "Enable Logstash for log management",
        "Install the Logstash plugin",
        "Configure the Logstash plugin",
        "Optional configuration",
        "Test the Logstash plugin",
        "View log data",
        "What's next?"
      ],
      "title": "Logstash plugin for log forwarding",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "62c6a8a5a160b466aaa7f852a085e47290169de1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/logstash-plugin-log-forwarding/",
      "published_at": "2021-07-02T17:23:20Z",
      "updated_at": "2021-05-16T06:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Logstash output plugin to connect your Logstash monitored log data to New Relic. Read on to learn how to enable this feature. Compatibility and requirements To forward your logs to New Relic using Logstash, ensure your configuration meets the following requirements: New Relic license key (recommended) or Insert API key Logstash 6.6 or higher Logstash requires Java 8 or Java 11. Use the official Oracle distribution or an open-source distribution such as OpenJDK. Enable Logstash for log management To enable log management using Logstash: Install the Logstash plugin. Configure the Logstash plugin. Optional: Configure additional plugin attributes. Test the Logstash plugin. Generate some traffic and wait a few minutes, then check your account for data. Install the Logstash plugin To install the Logstash plugin, enter the following command into your terminal or command line interface: logstash-plugin install logstash-output-newrelic Copy Configure the Logstash plugin To configure your Logstash plugin: In your logstash.conf file, add the following block of data. Be sure to replace the placeholder text with your New Relic license key or Insights Insert key. Configure with the New Relic license key (recommended): output { newrelic { license_key => \"LICENSE_KEY\" } } Copy Or, configure with the New Relic Insert API key: output { newrelic { api_key => \"INSERT_API_KEY\" } } Copy Restart your Logstash instance. Optional configuration Once you have installed and configured the Logstash plugin, you can use the following attributes to configure how the plugin sends data to New Relic: Property Description Default value concurrent_requests The number of threads to make requests from. 1 base_uri The New Relic ingestion endpoint. US endpoint: https://log-api.newrelic.com/log/v1 EU endpoint: https://log-api.eu.newrelic.com/log/v1 max_retries Maximum number attempts to retry to send a message. If set to 0, no re-attempts will be made. 3 For more information on adding or configuring attributes, see Example Configurations for Logstash. Test the Logstash plugin To test if your Logstash plugin is receiving input from a log file: Add the following to your logstash.conf file: input { file { path => \"/PATH/TO/YOUR/LOG/FILE\" } } Copy Restart your Logstash instance. Run the following command to append a test log message to your log file: echo \"test message\" >> /PATH/TO/YOUR/LOG/FILE Copy Search New Relic Logs UI for test message. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable New Relic Logs, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.70961,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Logstash</em> plugin for <em>log</em> forwarding",
        "sections": "<em>Enable</em> <em>Logstash</em> for <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "Use our Logstash output plugin to connect your Logstash monitored <em>log</em> data to <em>New</em> <em>Relic</em>. Read on to learn how to <em>enable</em> this feature. Compatibility and requirements To forward your <em>logs</em> to <em>New</em> <em>Relic</em> using Logstash, ensure your configuration meets the following requirements: <em>New</em> <em>Relic</em> license key"
      },
      "id": "603ebf8a28ccbc2307eba794"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/aws-lambda-sending-logs-s3": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Tip",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent(#automatically-inserted-attributes)",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-07-02T17:22:19Z",
      "updated_at": "2021-06-25T23:18:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use log management and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x and 18.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes as key-value pairs that can be used to send additional data with the logs which you can then query. Add attributes to any log source. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent(#automatically-inserted-attributes) The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 270.12534,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure <em>monitoring</em> agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use <em>log</em> <em>management</em> and the rest of our observability"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Vector output sink for log forwarding",
        "Compatibility and requirements",
        "Configure the Vector New Relic Logs sink",
        "Configure with the New Relic license key (recommended)",
        "Configure with the New Relic Insert API key",
        "Test the Vector New Relic logs sink",
        "View log data",
        "What's next?"
      ],
      "title": "Vector output sink for log forwarding",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "b2c621a62e9cc89c6b52e1a3e49411fb120b0de5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/vector-output-sink-log-forwarding/",
      "published_at": "2021-07-02T17:24:30Z",
      "updated_at": "2021-05-22T16:44:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Vector output sink to connect your Vector-monitored log data to New Relic. Read on to learn how to configure and test the Vector New Relic logs sink. Compatibility and requirements To forward your logs to New Relic using Vector, ensure your configuration meets the following requirements: New Relic license key (recommended) or Insert API key Vector version 0.7.0 or higher Configure the Vector New Relic Logs sink To configure the Vector New Relic logs sink: Choose one of the following options for adding a snippet to your vector.toml file (located in /etc/vector by default): Configure with the New Relic license key (recommended) Replace YOUR_LICENSE_KEY with the New Relic license key: # Ingest data by tailing one or more files [sources.mylog] type = \"file\" include = [\"/path/to/file\"] # Specify file or files to be tailed ignore_older = 86400 # Ignore events older than 1 day file_key = \"file\" # Add filename to log events host_key = \"host\" # Add hostname to log events # Configure sink to forward events to New Relic Logs [sinks.new_relic_logs] # REQUIRED type = \"new_relic_logs\" # must be: \"new_relic_logs\" inputs = [\"mylog\"] # example - value must be one or more source IDs license_key = \"YOUR_LICENSE_KEY\" region = \"us\" # Enum, must be one of: \"us\" \"eu\" depending on your New Relic Logs account region encoding.codec = \"json\" # OPTIONAL healthcheck = true # default Copy Configure with the New Relic Insert API key Replace YOUR_INSERT_KEY with the Insert API key: # Ingest data by tailing one or more files [sources.mylog] type = \"file\" include = [\"/path/to/file\"] # Specify file or files to be tailed ignore_older = 86400 # Ignore events older than 1 day file_key = \"file\" # Add filename to log events host_key = \"host\" # Add hostname to log events # Configure sink to forward events to New Relic Logs [sinks.new_relic_logs] # REQUIRED type = \"new_relic_logs\" # must be: \"new_relic_logs\" inputs = [\"mylog\"] # example - value must be one or more source IDs insert_key = \"YOUR_INSERT_KEY\" region = \"us\" # Enum, must be one of: \"us\" \"eu\" depending on your New Relic Logs account region encoding.codec = \"json\" # OPTIONAL healthcheck = true # default Copy Restart the Vector service to ensure your changes are applied. Test the Vector New Relic logs sink To test if the New Relic logs sink is forwarding events: Run the following command to append a test log message to your log file: echo \"test message\" >> /PATH/TO/YOUR/LOG/FILE Copy Search New Relic Logs UI for your test message. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable New Relic Logs, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.66754,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Vector output sink for <em>log</em> forwarding",
        "sections": "Configure the Vector <em>New</em> <em>Relic</em> <em>Logs</em> sink",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": ". For example, you can execute a query like this: SELECT * FROM <em>Log</em> Copy What&#x27;s next? Now that you&#x27;ve enabled <em>Logs</em>, here are some potential next steps: Explore your data using the <em>Logs</em> UI. Configure your agent to see contextual <em>log</em> data, such as distributed tracing, stack traces, application <em>logs</em>, and more. Query your data and create custom dashboards or alerts. If no data appears after you <em>enable</em> <em>New</em> <em>Relic</em> <em>Logs</em>, follow the troubleshooting procedures."
      },
      "id": "6045057664441f9a4a378f17"
    },
    {
      "sections": [
        "Logstash plugin for log forwarding",
        "Compatibility and requirements",
        "Enable Logstash for log management",
        "Install the Logstash plugin",
        "Configure the Logstash plugin",
        "Optional configuration",
        "Test the Logstash plugin",
        "View log data",
        "What's next?"
      ],
      "title": "Logstash plugin for log forwarding",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "62c6a8a5a160b466aaa7f852a085e47290169de1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/logstash-plugin-log-forwarding/",
      "published_at": "2021-07-02T17:23:20Z",
      "updated_at": "2021-05-16T06:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Logstash output plugin to connect your Logstash monitored log data to New Relic. Read on to learn how to enable this feature. Compatibility and requirements To forward your logs to New Relic using Logstash, ensure your configuration meets the following requirements: New Relic license key (recommended) or Insert API key Logstash 6.6 or higher Logstash requires Java 8 or Java 11. Use the official Oracle distribution or an open-source distribution such as OpenJDK. Enable Logstash for log management To enable log management using Logstash: Install the Logstash plugin. Configure the Logstash plugin. Optional: Configure additional plugin attributes. Test the Logstash plugin. Generate some traffic and wait a few minutes, then check your account for data. Install the Logstash plugin To install the Logstash plugin, enter the following command into your terminal or command line interface: logstash-plugin install logstash-output-newrelic Copy Configure the Logstash plugin To configure your Logstash plugin: In your logstash.conf file, add the following block of data. Be sure to replace the placeholder text with your New Relic license key or Insights Insert key. Configure with the New Relic license key (recommended): output { newrelic { license_key => \"LICENSE_KEY\" } } Copy Or, configure with the New Relic Insert API key: output { newrelic { api_key => \"INSERT_API_KEY\" } } Copy Restart your Logstash instance. Optional configuration Once you have installed and configured the Logstash plugin, you can use the following attributes to configure how the plugin sends data to New Relic: Property Description Default value concurrent_requests The number of threads to make requests from. 1 base_uri The New Relic ingestion endpoint. US endpoint: https://log-api.newrelic.com/log/v1 EU endpoint: https://log-api.eu.newrelic.com/log/v1 max_retries Maximum number attempts to retry to send a message. If set to 0, no re-attempts will be made. 3 For more information on adding or configuring attributes, see Example Configurations for Logstash. Test the Logstash plugin To test if your Logstash plugin is receiving input from a log file: Add the following to your logstash.conf file: input { file { path => \"/PATH/TO/YOUR/LOG/FILE\" } } Copy Restart your Logstash instance. Run the following command to append a test log message to your log file: echo \"test message\" >> /PATH/TO/YOUR/LOG/FILE Copy Search New Relic Logs UI for test message. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable New Relic Logs, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.70961,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Logstash</em> plugin for <em>log</em> forwarding",
        "sections": "<em>Enable</em> <em>Logstash</em> for <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "Use our Logstash output plugin to connect your Logstash monitored <em>log</em> data to <em>New</em> <em>Relic</em>. Read on to learn how to <em>enable</em> this feature. Compatibility and requirements To forward your <em>logs</em> to <em>New</em> <em>Relic</em> using Logstash, ensure your configuration meets the following requirements: <em>New</em> <em>Relic</em> license key"
      },
      "id": "603ebf8a28ccbc2307eba794"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/enable-log-management-new-relic": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Tip",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent(#automatically-inserted-attributes)",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-07-02T17:22:19Z",
      "updated_at": "2021-06-25T23:18:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use log management and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x and 18.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes as key-value pairs that can be used to send additional data with the logs which you can then query. Add attributes to any log source. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent(#automatically-inserted-attributes) The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 270.12524,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure <em>monitoring</em> agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use <em>log</em> <em>management</em> and the rest of our observability"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Vector output sink for log forwarding",
        "Compatibility and requirements",
        "Configure the Vector New Relic Logs sink",
        "Configure with the New Relic license key (recommended)",
        "Configure with the New Relic Insert API key",
        "Test the Vector New Relic logs sink",
        "View log data",
        "What's next?"
      ],
      "title": "Vector output sink for log forwarding",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "b2c621a62e9cc89c6b52e1a3e49411fb120b0de5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/vector-output-sink-log-forwarding/",
      "published_at": "2021-07-02T17:24:30Z",
      "updated_at": "2021-05-22T16:44:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Vector output sink to connect your Vector-monitored log data to New Relic. Read on to learn how to configure and test the Vector New Relic logs sink. Compatibility and requirements To forward your logs to New Relic using Vector, ensure your configuration meets the following requirements: New Relic license key (recommended) or Insert API key Vector version 0.7.0 or higher Configure the Vector New Relic Logs sink To configure the Vector New Relic logs sink: Choose one of the following options for adding a snippet to your vector.toml file (located in /etc/vector by default): Configure with the New Relic license key (recommended) Replace YOUR_LICENSE_KEY with the New Relic license key: # Ingest data by tailing one or more files [sources.mylog] type = \"file\" include = [\"/path/to/file\"] # Specify file or files to be tailed ignore_older = 86400 # Ignore events older than 1 day file_key = \"file\" # Add filename to log events host_key = \"host\" # Add hostname to log events # Configure sink to forward events to New Relic Logs [sinks.new_relic_logs] # REQUIRED type = \"new_relic_logs\" # must be: \"new_relic_logs\" inputs = [\"mylog\"] # example - value must be one or more source IDs license_key = \"YOUR_LICENSE_KEY\" region = \"us\" # Enum, must be one of: \"us\" \"eu\" depending on your New Relic Logs account region encoding.codec = \"json\" # OPTIONAL healthcheck = true # default Copy Configure with the New Relic Insert API key Replace YOUR_INSERT_KEY with the Insert API key: # Ingest data by tailing one or more files [sources.mylog] type = \"file\" include = [\"/path/to/file\"] # Specify file or files to be tailed ignore_older = 86400 # Ignore events older than 1 day file_key = \"file\" # Add filename to log events host_key = \"host\" # Add hostname to log events # Configure sink to forward events to New Relic Logs [sinks.new_relic_logs] # REQUIRED type = \"new_relic_logs\" # must be: \"new_relic_logs\" inputs = [\"mylog\"] # example - value must be one or more source IDs insert_key = \"YOUR_INSERT_KEY\" region = \"us\" # Enum, must be one of: \"us\" \"eu\" depending on your New Relic Logs account region encoding.codec = \"json\" # OPTIONAL healthcheck = true # default Copy Restart the Vector service to ensure your changes are applied. Test the Vector New Relic logs sink To test if the New Relic logs sink is forwarding events: Run the following command to append a test log message to your log file: echo \"test message\" >> /PATH/TO/YOUR/LOG/FILE Copy Search New Relic Logs UI for your test message. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable New Relic Logs, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.66754,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Vector output sink for <em>log</em> forwarding",
        "sections": "Configure the Vector <em>New</em> <em>Relic</em> <em>Logs</em> sink",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": ". For example, you can execute a query like this: SELECT * FROM <em>Log</em> Copy What&#x27;s next? Now that you&#x27;ve enabled <em>Logs</em>, here are some potential next steps: Explore your data using the <em>Logs</em> UI. Configure your agent to see contextual <em>log</em> data, such as distributed tracing, stack traces, application <em>logs</em>, and more. Query your data and create custom dashboards or alerts. If no data appears after you <em>enable</em> <em>New</em> <em>Relic</em> <em>Logs</em>, follow the troubleshooting procedures."
      },
      "id": "6045057664441f9a4a378f17"
    },
    {
      "sections": [
        "Logstash plugin for log forwarding",
        "Compatibility and requirements",
        "Enable Logstash for log management",
        "Install the Logstash plugin",
        "Configure the Logstash plugin",
        "Optional configuration",
        "Test the Logstash plugin",
        "View log data",
        "What's next?"
      ],
      "title": "Logstash plugin for log forwarding",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "62c6a8a5a160b466aaa7f852a085e47290169de1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/logstash-plugin-log-forwarding/",
      "published_at": "2021-07-02T17:23:20Z",
      "updated_at": "2021-05-16T06:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Logstash output plugin to connect your Logstash monitored log data to New Relic. Read on to learn how to enable this feature. Compatibility and requirements To forward your logs to New Relic using Logstash, ensure your configuration meets the following requirements: New Relic license key (recommended) or Insert API key Logstash 6.6 or higher Logstash requires Java 8 or Java 11. Use the official Oracle distribution or an open-source distribution such as OpenJDK. Enable Logstash for log management To enable log management using Logstash: Install the Logstash plugin. Configure the Logstash plugin. Optional: Configure additional plugin attributes. Test the Logstash plugin. Generate some traffic and wait a few minutes, then check your account for data. Install the Logstash plugin To install the Logstash plugin, enter the following command into your terminal or command line interface: logstash-plugin install logstash-output-newrelic Copy Configure the Logstash plugin To configure your Logstash plugin: In your logstash.conf file, add the following block of data. Be sure to replace the placeholder text with your New Relic license key or Insights Insert key. Configure with the New Relic license key (recommended): output { newrelic { license_key => \"LICENSE_KEY\" } } Copy Or, configure with the New Relic Insert API key: output { newrelic { api_key => \"INSERT_API_KEY\" } } Copy Restart your Logstash instance. Optional configuration Once you have installed and configured the Logstash plugin, you can use the following attributes to configure how the plugin sends data to New Relic: Property Description Default value concurrent_requests The number of threads to make requests from. 1 base_uri The New Relic ingestion endpoint. US endpoint: https://log-api.newrelic.com/log/v1 EU endpoint: https://log-api.eu.newrelic.com/log/v1 max_retries Maximum number attempts to retry to send a message. If set to 0, no re-attempts will be made. 3 For more information on adding or configuring attributes, see Example Configurations for Logstash. Test the Logstash plugin To test if your Logstash plugin is receiving input from a log file: Add the following to your logstash.conf file: input { file { path => \"/PATH/TO/YOUR/LOG/FILE\" } } Copy Restart your Logstash instance. Run the following command to append a test log message to your log file: echo \"test message\" >> /PATH/TO/YOUR/LOG/FILE Copy Search New Relic Logs UI for test message. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable New Relic Logs, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.70961,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Logstash</em> plugin for <em>log</em> forwarding",
        "sections": "<em>Enable</em> <em>Logstash</em> for <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "Use our Logstash output plugin to connect your Logstash monitored <em>log</em> data to <em>New</em> <em>Relic</em>. Read on to learn how to <em>enable</em> this feature. Compatibility and requirements To forward your <em>logs</em> to <em>New</em> <em>Relic</em> using Logstash, ensure your configuration meets the following requirements: <em>New</em> <em>Relic</em> license key"
      },
      "id": "603ebf8a28ccbc2307eba794"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/fluent-bit-plugin-log-forwarding": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Tip",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent(#automatically-inserted-attributes)",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-07-02T17:22:19Z",
      "updated_at": "2021-06-25T23:18:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use log management and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x and 18.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes as key-value pairs that can be used to send additional data with the logs which you can then query. Add attributes to any log source. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent(#automatically-inserted-attributes) The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 270.12524,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure <em>monitoring</em> agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use <em>log</em> <em>management</em> and the rest of our observability"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Vector output sink for log forwarding",
        "Compatibility and requirements",
        "Configure the Vector New Relic Logs sink",
        "Configure with the New Relic license key (recommended)",
        "Configure with the New Relic Insert API key",
        "Test the Vector New Relic logs sink",
        "View log data",
        "What's next?"
      ],
      "title": "Vector output sink for log forwarding",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "b2c621a62e9cc89c6b52e1a3e49411fb120b0de5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/vector-output-sink-log-forwarding/",
      "published_at": "2021-07-02T17:24:30Z",
      "updated_at": "2021-05-22T16:44:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Vector output sink to connect your Vector-monitored log data to New Relic. Read on to learn how to configure and test the Vector New Relic logs sink. Compatibility and requirements To forward your logs to New Relic using Vector, ensure your configuration meets the following requirements: New Relic license key (recommended) or Insert API key Vector version 0.7.0 or higher Configure the Vector New Relic Logs sink To configure the Vector New Relic logs sink: Choose one of the following options for adding a snippet to your vector.toml file (located in /etc/vector by default): Configure with the New Relic license key (recommended) Replace YOUR_LICENSE_KEY with the New Relic license key: # Ingest data by tailing one or more files [sources.mylog] type = \"file\" include = [\"/path/to/file\"] # Specify file or files to be tailed ignore_older = 86400 # Ignore events older than 1 day file_key = \"file\" # Add filename to log events host_key = \"host\" # Add hostname to log events # Configure sink to forward events to New Relic Logs [sinks.new_relic_logs] # REQUIRED type = \"new_relic_logs\" # must be: \"new_relic_logs\" inputs = [\"mylog\"] # example - value must be one or more source IDs license_key = \"YOUR_LICENSE_KEY\" region = \"us\" # Enum, must be one of: \"us\" \"eu\" depending on your New Relic Logs account region encoding.codec = \"json\" # OPTIONAL healthcheck = true # default Copy Configure with the New Relic Insert API key Replace YOUR_INSERT_KEY with the Insert API key: # Ingest data by tailing one or more files [sources.mylog] type = \"file\" include = [\"/path/to/file\"] # Specify file or files to be tailed ignore_older = 86400 # Ignore events older than 1 day file_key = \"file\" # Add filename to log events host_key = \"host\" # Add hostname to log events # Configure sink to forward events to New Relic Logs [sinks.new_relic_logs] # REQUIRED type = \"new_relic_logs\" # must be: \"new_relic_logs\" inputs = [\"mylog\"] # example - value must be one or more source IDs insert_key = \"YOUR_INSERT_KEY\" region = \"us\" # Enum, must be one of: \"us\" \"eu\" depending on your New Relic Logs account region encoding.codec = \"json\" # OPTIONAL healthcheck = true # default Copy Restart the Vector service to ensure your changes are applied. Test the Vector New Relic logs sink To test if the New Relic logs sink is forwarding events: Run the following command to append a test log message to your log file: echo \"test message\" >> /PATH/TO/YOUR/LOG/FILE Copy Search New Relic Logs UI for your test message. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable New Relic Logs, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.66754,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Vector output sink for <em>log</em> forwarding",
        "sections": "Configure the Vector <em>New</em> <em>Relic</em> <em>Logs</em> sink",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": ". For example, you can execute a query like this: SELECT * FROM <em>Log</em> Copy What&#x27;s next? Now that you&#x27;ve enabled <em>Logs</em>, here are some potential next steps: Explore your data using the <em>Logs</em> UI. Configure your agent to see contextual <em>log</em> data, such as distributed tracing, stack traces, application <em>logs</em>, and more. Query your data and create custom dashboards or alerts. If no data appears after you <em>enable</em> <em>New</em> <em>Relic</em> <em>Logs</em>, follow the troubleshooting procedures."
      },
      "id": "6045057664441f9a4a378f17"
    },
    {
      "sections": [
        "Logstash plugin for log forwarding",
        "Compatibility and requirements",
        "Enable Logstash for log management",
        "Install the Logstash plugin",
        "Configure the Logstash plugin",
        "Optional configuration",
        "Test the Logstash plugin",
        "View log data",
        "What's next?"
      ],
      "title": "Logstash plugin for log forwarding",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "62c6a8a5a160b466aaa7f852a085e47290169de1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/logstash-plugin-log-forwarding/",
      "published_at": "2021-07-02T17:23:20Z",
      "updated_at": "2021-05-16T06:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Logstash output plugin to connect your Logstash monitored log data to New Relic. Read on to learn how to enable this feature. Compatibility and requirements To forward your logs to New Relic using Logstash, ensure your configuration meets the following requirements: New Relic license key (recommended) or Insert API key Logstash 6.6 or higher Logstash requires Java 8 or Java 11. Use the official Oracle distribution or an open-source distribution such as OpenJDK. Enable Logstash for log management To enable log management using Logstash: Install the Logstash plugin. Configure the Logstash plugin. Optional: Configure additional plugin attributes. Test the Logstash plugin. Generate some traffic and wait a few minutes, then check your account for data. Install the Logstash plugin To install the Logstash plugin, enter the following command into your terminal or command line interface: logstash-plugin install logstash-output-newrelic Copy Configure the Logstash plugin To configure your Logstash plugin: In your logstash.conf file, add the following block of data. Be sure to replace the placeholder text with your New Relic license key or Insights Insert key. Configure with the New Relic license key (recommended): output { newrelic { license_key => \"LICENSE_KEY\" } } Copy Or, configure with the New Relic Insert API key: output { newrelic { api_key => \"INSERT_API_KEY\" } } Copy Restart your Logstash instance. Optional configuration Once you have installed and configured the Logstash plugin, you can use the following attributes to configure how the plugin sends data to New Relic: Property Description Default value concurrent_requests The number of threads to make requests from. 1 base_uri The New Relic ingestion endpoint. US endpoint: https://log-api.newrelic.com/log/v1 EU endpoint: https://log-api.eu.newrelic.com/log/v1 max_retries Maximum number attempts to retry to send a message. If set to 0, no re-attempts will be made. 3 For more information on adding or configuring attributes, see Example Configurations for Logstash. Test the Logstash plugin To test if your Logstash plugin is receiving input from a log file: Add the following to your logstash.conf file: input { file { path => \"/PATH/TO/YOUR/LOG/FILE\" } } Copy Restart your Logstash instance. Run the following command to append a test log message to your log file: echo \"test message\" >> /PATH/TO/YOUR/LOG/FILE Copy Search New Relic Logs UI for test message. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable New Relic Logs, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.70961,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Logstash</em> plugin for <em>log</em> forwarding",
        "sections": "<em>Enable</em> <em>Logstash</em> for <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "Use our Logstash output plugin to connect your Logstash monitored <em>log</em> data to <em>New</em> <em>Relic</em>. Read on to learn how to <em>enable</em> this feature. Compatibility and requirements To forward your <em>logs</em> to <em>New</em> <em>Relic</em> using Logstash, ensure your configuration meets the following requirements: <em>New</em> <em>Relic</em> license key"
      },
      "id": "603ebf8a28ccbc2307eba794"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/fluentd-plugin-log-forwarding": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Tip",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent(#automatically-inserted-attributes)",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-07-02T17:22:19Z",
      "updated_at": "2021-06-25T23:18:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use log management and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x and 18.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes as key-value pairs that can be used to send additional data with the logs which you can then query. Add attributes to any log source. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent(#automatically-inserted-attributes) The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 270.12518,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure <em>monitoring</em> agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use <em>log</em> <em>management</em> and the rest of our observability"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Vector output sink for log forwarding",
        "Compatibility and requirements",
        "Configure the Vector New Relic Logs sink",
        "Configure with the New Relic license key (recommended)",
        "Configure with the New Relic Insert API key",
        "Test the Vector New Relic logs sink",
        "View log data",
        "What's next?"
      ],
      "title": "Vector output sink for log forwarding",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "b2c621a62e9cc89c6b52e1a3e49411fb120b0de5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/vector-output-sink-log-forwarding/",
      "published_at": "2021-07-02T17:24:30Z",
      "updated_at": "2021-05-22T16:44:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Vector output sink to connect your Vector-monitored log data to New Relic. Read on to learn how to configure and test the Vector New Relic logs sink. Compatibility and requirements To forward your logs to New Relic using Vector, ensure your configuration meets the following requirements: New Relic license key (recommended) or Insert API key Vector version 0.7.0 or higher Configure the Vector New Relic Logs sink To configure the Vector New Relic logs sink: Choose one of the following options for adding a snippet to your vector.toml file (located in /etc/vector by default): Configure with the New Relic license key (recommended) Replace YOUR_LICENSE_KEY with the New Relic license key: # Ingest data by tailing one or more files [sources.mylog] type = \"file\" include = [\"/path/to/file\"] # Specify file or files to be tailed ignore_older = 86400 # Ignore events older than 1 day file_key = \"file\" # Add filename to log events host_key = \"host\" # Add hostname to log events # Configure sink to forward events to New Relic Logs [sinks.new_relic_logs] # REQUIRED type = \"new_relic_logs\" # must be: \"new_relic_logs\" inputs = [\"mylog\"] # example - value must be one or more source IDs license_key = \"YOUR_LICENSE_KEY\" region = \"us\" # Enum, must be one of: \"us\" \"eu\" depending on your New Relic Logs account region encoding.codec = \"json\" # OPTIONAL healthcheck = true # default Copy Configure with the New Relic Insert API key Replace YOUR_INSERT_KEY with the Insert API key: # Ingest data by tailing one or more files [sources.mylog] type = \"file\" include = [\"/path/to/file\"] # Specify file or files to be tailed ignore_older = 86400 # Ignore events older than 1 day file_key = \"file\" # Add filename to log events host_key = \"host\" # Add hostname to log events # Configure sink to forward events to New Relic Logs [sinks.new_relic_logs] # REQUIRED type = \"new_relic_logs\" # must be: \"new_relic_logs\" inputs = [\"mylog\"] # example - value must be one or more source IDs insert_key = \"YOUR_INSERT_KEY\" region = \"us\" # Enum, must be one of: \"us\" \"eu\" depending on your New Relic Logs account region encoding.codec = \"json\" # OPTIONAL healthcheck = true # default Copy Restart the Vector service to ensure your changes are applied. Test the Vector New Relic logs sink To test if the New Relic logs sink is forwarding events: Run the following command to append a test log message to your log file: echo \"test message\" >> /PATH/TO/YOUR/LOG/FILE Copy Search New Relic Logs UI for your test message. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable New Relic Logs, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.66753,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Vector output sink for <em>log</em> forwarding",
        "sections": "Configure the Vector <em>New</em> <em>Relic</em> <em>Logs</em> sink",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": ". For example, you can execute a query like this: SELECT * FROM <em>Log</em> Copy What&#x27;s next? Now that you&#x27;ve enabled <em>Logs</em>, here are some potential next steps: Explore your data using the <em>Logs</em> UI. Configure your agent to see contextual <em>log</em> data, such as distributed tracing, stack traces, application <em>logs</em>, and more. Query your data and create custom dashboards or alerts. If no data appears after you <em>enable</em> <em>New</em> <em>Relic</em> <em>Logs</em>, follow the troubleshooting procedures."
      },
      "id": "6045057664441f9a4a378f17"
    },
    {
      "sections": [
        "Logstash plugin for log forwarding",
        "Compatibility and requirements",
        "Enable Logstash for log management",
        "Install the Logstash plugin",
        "Configure the Logstash plugin",
        "Optional configuration",
        "Test the Logstash plugin",
        "View log data",
        "What's next?"
      ],
      "title": "Logstash plugin for log forwarding",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "62c6a8a5a160b466aaa7f852a085e47290169de1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/logstash-plugin-log-forwarding/",
      "published_at": "2021-07-02T17:23:20Z",
      "updated_at": "2021-05-16T06:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Logstash output plugin to connect your Logstash monitored log data to New Relic. Read on to learn how to enable this feature. Compatibility and requirements To forward your logs to New Relic using Logstash, ensure your configuration meets the following requirements: New Relic license key (recommended) or Insert API key Logstash 6.6 or higher Logstash requires Java 8 or Java 11. Use the official Oracle distribution or an open-source distribution such as OpenJDK. Enable Logstash for log management To enable log management using Logstash: Install the Logstash plugin. Configure the Logstash plugin. Optional: Configure additional plugin attributes. Test the Logstash plugin. Generate some traffic and wait a few minutes, then check your account for data. Install the Logstash plugin To install the Logstash plugin, enter the following command into your terminal or command line interface: logstash-plugin install logstash-output-newrelic Copy Configure the Logstash plugin To configure your Logstash plugin: In your logstash.conf file, add the following block of data. Be sure to replace the placeholder text with your New Relic license key or Insights Insert key. Configure with the New Relic license key (recommended): output { newrelic { license_key => \"LICENSE_KEY\" } } Copy Or, configure with the New Relic Insert API key: output { newrelic { api_key => \"INSERT_API_KEY\" } } Copy Restart your Logstash instance. Optional configuration Once you have installed and configured the Logstash plugin, you can use the following attributes to configure how the plugin sends data to New Relic: Property Description Default value concurrent_requests The number of threads to make requests from. 1 base_uri The New Relic ingestion endpoint. US endpoint: https://log-api.newrelic.com/log/v1 EU endpoint: https://log-api.eu.newrelic.com/log/v1 max_retries Maximum number attempts to retry to send a message. If set to 0, no re-attempts will be made. 3 For more information on adding or configuring attributes, see Example Configurations for Logstash. Test the Logstash plugin To test if your Logstash plugin is receiving input from a log file: Add the following to your logstash.conf file: input { file { path => \"/PATH/TO/YOUR/LOG/FILE\" } } Copy Restart your Logstash instance. Run the following command to append a test log message to your log file: echo \"test message\" >> /PATH/TO/YOUR/LOG/FILE Copy Search New Relic Logs UI for test message. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable New Relic Logs, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.7096,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Logstash</em> plugin for <em>log</em> forwarding",
        "sections": "<em>Enable</em> <em>Logstash</em> for <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "Use our Logstash output plugin to connect your Logstash monitored <em>log</em> data to <em>New</em> <em>Relic</em>. Read on to learn how to <em>enable</em> this feature. Compatibility and requirements To forward your <em>logs</em> to <em>New</em> <em>Relic</em> using Logstash, ensure your configuration meets the following requirements: <em>New</em> <em>Relic</em> license key"
      },
      "id": "603ebf8a28ccbc2307eba794"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent": [
    {
      "sections": [
        "Vector output sink for log forwarding",
        "Compatibility and requirements",
        "Configure the Vector New Relic Logs sink",
        "Configure with the New Relic license key (recommended)",
        "Configure with the New Relic Insert API key",
        "Test the Vector New Relic logs sink",
        "View log data",
        "What's next?"
      ],
      "title": "Vector output sink for log forwarding",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "b2c621a62e9cc89c6b52e1a3e49411fb120b0de5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/vector-output-sink-log-forwarding/",
      "published_at": "2021-07-02T17:24:30Z",
      "updated_at": "2021-05-22T16:44:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Vector output sink to connect your Vector-monitored log data to New Relic. Read on to learn how to configure and test the Vector New Relic logs sink. Compatibility and requirements To forward your logs to New Relic using Vector, ensure your configuration meets the following requirements: New Relic license key (recommended) or Insert API key Vector version 0.7.0 or higher Configure the Vector New Relic Logs sink To configure the Vector New Relic logs sink: Choose one of the following options for adding a snippet to your vector.toml file (located in /etc/vector by default): Configure with the New Relic license key (recommended) Replace YOUR_LICENSE_KEY with the New Relic license key: # Ingest data by tailing one or more files [sources.mylog] type = \"file\" include = [\"/path/to/file\"] # Specify file or files to be tailed ignore_older = 86400 # Ignore events older than 1 day file_key = \"file\" # Add filename to log events host_key = \"host\" # Add hostname to log events # Configure sink to forward events to New Relic Logs [sinks.new_relic_logs] # REQUIRED type = \"new_relic_logs\" # must be: \"new_relic_logs\" inputs = [\"mylog\"] # example - value must be one or more source IDs license_key = \"YOUR_LICENSE_KEY\" region = \"us\" # Enum, must be one of: \"us\" \"eu\" depending on your New Relic Logs account region encoding.codec = \"json\" # OPTIONAL healthcheck = true # default Copy Configure with the New Relic Insert API key Replace YOUR_INSERT_KEY with the Insert API key: # Ingest data by tailing one or more files [sources.mylog] type = \"file\" include = [\"/path/to/file\"] # Specify file or files to be tailed ignore_older = 86400 # Ignore events older than 1 day file_key = \"file\" # Add filename to log events host_key = \"host\" # Add hostname to log events # Configure sink to forward events to New Relic Logs [sinks.new_relic_logs] # REQUIRED type = \"new_relic_logs\" # must be: \"new_relic_logs\" inputs = [\"mylog\"] # example - value must be one or more source IDs insert_key = \"YOUR_INSERT_KEY\" region = \"us\" # Enum, must be one of: \"us\" \"eu\" depending on your New Relic Logs account region encoding.codec = \"json\" # OPTIONAL healthcheck = true # default Copy Restart the Vector service to ensure your changes are applied. Test the Vector New Relic logs sink To test if the New Relic logs sink is forwarding events: Run the following command to append a test log message to your log file: echo \"test message\" >> /PATH/TO/YOUR/LOG/FILE Copy Search New Relic Logs UI for your test message. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable New Relic Logs, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.66753,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Vector output sink for <em>log</em> forwarding",
        "sections": "Configure the Vector <em>New</em> <em>Relic</em> <em>Logs</em> sink",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": ". For example, you can execute a query like this: SELECT * FROM <em>Log</em> Copy What&#x27;s next? Now that you&#x27;ve enabled <em>Logs</em>, here are some potential next steps: Explore your data using the <em>Logs</em> UI. Configure your agent to see contextual <em>log</em> data, such as distributed tracing, stack traces, application <em>logs</em>, and more. Query your data and create custom dashboards or alerts. If no data appears after you <em>enable</em> <em>New</em> <em>Relic</em> <em>Logs</em>, follow the troubleshooting procedures."
      },
      "id": "6045057664441f9a4a378f17"
    },
    {
      "sections": [
        "Logstash plugin for log forwarding",
        "Compatibility and requirements",
        "Enable Logstash for log management",
        "Install the Logstash plugin",
        "Configure the Logstash plugin",
        "Optional configuration",
        "Test the Logstash plugin",
        "View log data",
        "What's next?"
      ],
      "title": "Logstash plugin for log forwarding",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "62c6a8a5a160b466aaa7f852a085e47290169de1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/logstash-plugin-log-forwarding/",
      "published_at": "2021-07-02T17:23:20Z",
      "updated_at": "2021-05-16T06:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Logstash output plugin to connect your Logstash monitored log data to New Relic. Read on to learn how to enable this feature. Compatibility and requirements To forward your logs to New Relic using Logstash, ensure your configuration meets the following requirements: New Relic license key (recommended) or Insert API key Logstash 6.6 or higher Logstash requires Java 8 or Java 11. Use the official Oracle distribution or an open-source distribution such as OpenJDK. Enable Logstash for log management To enable log management using Logstash: Install the Logstash plugin. Configure the Logstash plugin. Optional: Configure additional plugin attributes. Test the Logstash plugin. Generate some traffic and wait a few minutes, then check your account for data. Install the Logstash plugin To install the Logstash plugin, enter the following command into your terminal or command line interface: logstash-plugin install logstash-output-newrelic Copy Configure the Logstash plugin To configure your Logstash plugin: In your logstash.conf file, add the following block of data. Be sure to replace the placeholder text with your New Relic license key or Insights Insert key. Configure with the New Relic license key (recommended): output { newrelic { license_key => \"LICENSE_KEY\" } } Copy Or, configure with the New Relic Insert API key: output { newrelic { api_key => \"INSERT_API_KEY\" } } Copy Restart your Logstash instance. Optional configuration Once you have installed and configured the Logstash plugin, you can use the following attributes to configure how the plugin sends data to New Relic: Property Description Default value concurrent_requests The number of threads to make requests from. 1 base_uri The New Relic ingestion endpoint. US endpoint: https://log-api.newrelic.com/log/v1 EU endpoint: https://log-api.eu.newrelic.com/log/v1 max_retries Maximum number attempts to retry to send a message. If set to 0, no re-attempts will be made. 3 For more information on adding or configuring attributes, see Example Configurations for Logstash. Test the Logstash plugin To test if your Logstash plugin is receiving input from a log file: Add the following to your logstash.conf file: input { file { path => \"/PATH/TO/YOUR/LOG/FILE\" } } Copy Restart your Logstash instance. Run the following command to append a test log message to your log file: echo \"test message\" >> /PATH/TO/YOUR/LOG/FILE Copy Search New Relic Logs UI for test message. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable New Relic Logs, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.7096,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Logstash</em> plugin for <em>log</em> forwarding",
        "sections": "<em>Enable</em> <em>Logstash</em> for <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "Use our Logstash output plugin to connect your Logstash monitored <em>log</em> data to <em>New</em> <em>Relic</em>. Read on to learn how to <em>enable</em> this feature. Compatibility and requirements To forward your <em>logs</em> to <em>New</em> <em>Relic</em> using Logstash, ensure your configuration meets the following requirements: <em>New</em> <em>Relic</em> license key"
      },
      "id": "603ebf8a28ccbc2307eba794"
    },
    {
      "sections": [
        "Enable log management in New Relic",
        "Tip",
        "Requirements",
        "Enable log management using the infrastructure agent",
        "Enable log management in New Relic using a log forwarding solution",
        "Enable using the Logs API",
        "What's next?"
      ],
      "title": "Enable log management in New Relic",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "9574655633e0f3d9ac206488be9c8b240710483e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/enable-log-management-new-relic/",
      "published_at": "2021-07-02T14:30:36Z",
      "updated_at": "2021-05-16T06:06:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's log management allows you to collect, process, explore, visualize, and alert on your log data using your existing log forwarder. Read on to learn how to enable this feature and start using it. Tip To use log management and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Requirements To use log management, ensure your configuration meets the following requirements: Your New Relic account's license key A compatible log forwarding plugin installed Ensure outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region The preferred configuration method is to use the DNS name log-api.newrelic.com or log-api.eu.newrelic.com. Enable log management in New Relic There are several ways of bringing your logs into New Relic: Use the New Relic infrastructure agent Use log forwarding plugins (like Fluentd) Use the New Relic Logs API Enable log management using the infrastructure agent You can forward your logs to New Relic using the infrastructure agent, our lightweight data collector, without having to use additional software. For more information, see Forward your logs using the infrastructure agent. Enable log management in New Relic using a log forwarding solution You can use any of these solutions to forward your logs to New Relic: Infrastructure agent Kubernetes plugin AWS Lambda for sending logs from S3 AWS CloudWatch plugin AWS Kinesis Firehose AWS FireLens plugin Fluent Bit plugin Fluentd plugin Logstash plugin Vector plugin Heroku Log Streaming Syslog TCP Endpoint Enable using the Logs API If you prefer to connect to New Relic without installing a plugin, New Relic offers HTTP input integration. This will allow you to send your monitored log data directly to New Relic via the Log API. For more information, see Introduction to Log API. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable New Relic Logs, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.70927,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "sections": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " installed Ensure outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region The preferred configuration method is to use the DNS name <em>log</em>-api.newrelic.com or <em>log</em>-api.eu.newrelic.com. <em>Enable</em> <em>log</em> <em>management</em> in <em>New</em> <em>Relic</em> There are several ways of bringing your <em>logs</em> into <em>New</em>"
      },
      "id": "603ea41828ccbc872beba761"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/heroku-log-forwarding": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Tip",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent(#automatically-inserted-attributes)",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-07-02T17:22:19Z",
      "updated_at": "2021-06-25T23:18:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use log management and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x and 18.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes as key-value pairs that can be used to send additional data with the logs which you can then query. Add attributes to any log source. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent(#automatically-inserted-attributes) The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 270.12518,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure <em>monitoring</em> agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use <em>log</em> <em>management</em> and the rest of our observability"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Vector output sink for log forwarding",
        "Compatibility and requirements",
        "Configure the Vector New Relic Logs sink",
        "Configure with the New Relic license key (recommended)",
        "Configure with the New Relic Insert API key",
        "Test the Vector New Relic logs sink",
        "View log data",
        "What's next?"
      ],
      "title": "Vector output sink for log forwarding",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "b2c621a62e9cc89c6b52e1a3e49411fb120b0de5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/vector-output-sink-log-forwarding/",
      "published_at": "2021-07-02T17:24:30Z",
      "updated_at": "2021-05-22T16:44:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Vector output sink to connect your Vector-monitored log data to New Relic. Read on to learn how to configure and test the Vector New Relic logs sink. Compatibility and requirements To forward your logs to New Relic using Vector, ensure your configuration meets the following requirements: New Relic license key (recommended) or Insert API key Vector version 0.7.0 or higher Configure the Vector New Relic Logs sink To configure the Vector New Relic logs sink: Choose one of the following options for adding a snippet to your vector.toml file (located in /etc/vector by default): Configure with the New Relic license key (recommended) Replace YOUR_LICENSE_KEY with the New Relic license key: # Ingest data by tailing one or more files [sources.mylog] type = \"file\" include = [\"/path/to/file\"] # Specify file or files to be tailed ignore_older = 86400 # Ignore events older than 1 day file_key = \"file\" # Add filename to log events host_key = \"host\" # Add hostname to log events # Configure sink to forward events to New Relic Logs [sinks.new_relic_logs] # REQUIRED type = \"new_relic_logs\" # must be: \"new_relic_logs\" inputs = [\"mylog\"] # example - value must be one or more source IDs license_key = \"YOUR_LICENSE_KEY\" region = \"us\" # Enum, must be one of: \"us\" \"eu\" depending on your New Relic Logs account region encoding.codec = \"json\" # OPTIONAL healthcheck = true # default Copy Configure with the New Relic Insert API key Replace YOUR_INSERT_KEY with the Insert API key: # Ingest data by tailing one or more files [sources.mylog] type = \"file\" include = [\"/path/to/file\"] # Specify file or files to be tailed ignore_older = 86400 # Ignore events older than 1 day file_key = \"file\" # Add filename to log events host_key = \"host\" # Add hostname to log events # Configure sink to forward events to New Relic Logs [sinks.new_relic_logs] # REQUIRED type = \"new_relic_logs\" # must be: \"new_relic_logs\" inputs = [\"mylog\"] # example - value must be one or more source IDs insert_key = \"YOUR_INSERT_KEY\" region = \"us\" # Enum, must be one of: \"us\" \"eu\" depending on your New Relic Logs account region encoding.codec = \"json\" # OPTIONAL healthcheck = true # default Copy Restart the Vector service to ensure your changes are applied. Test the Vector New Relic logs sink To test if the New Relic logs sink is forwarding events: Run the following command to append a test log message to your log file: echo \"test message\" >> /PATH/TO/YOUR/LOG/FILE Copy Search New Relic Logs UI for your test message. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable New Relic Logs, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.66753,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Vector output sink for <em>log</em> forwarding",
        "sections": "Configure the Vector <em>New</em> <em>Relic</em> <em>Logs</em> sink",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": ". For example, you can execute a query like this: SELECT * FROM <em>Log</em> Copy What&#x27;s next? Now that you&#x27;ve enabled <em>Logs</em>, here are some potential next steps: Explore your data using the <em>Logs</em> UI. Configure your agent to see contextual <em>log</em> data, such as distributed tracing, stack traces, application <em>logs</em>, and more. Query your data and create custom dashboards or alerts. If no data appears after you <em>enable</em> <em>New</em> <em>Relic</em> <em>Logs</em>, follow the troubleshooting procedures."
      },
      "id": "6045057664441f9a4a378f17"
    },
    {
      "sections": [
        "Logstash plugin for log forwarding",
        "Compatibility and requirements",
        "Enable Logstash for log management",
        "Install the Logstash plugin",
        "Configure the Logstash plugin",
        "Optional configuration",
        "Test the Logstash plugin",
        "View log data",
        "What's next?"
      ],
      "title": "Logstash plugin for log forwarding",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "62c6a8a5a160b466aaa7f852a085e47290169de1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/logstash-plugin-log-forwarding/",
      "published_at": "2021-07-02T17:23:20Z",
      "updated_at": "2021-05-16T06:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Logstash output plugin to connect your Logstash monitored log data to New Relic. Read on to learn how to enable this feature. Compatibility and requirements To forward your logs to New Relic using Logstash, ensure your configuration meets the following requirements: New Relic license key (recommended) or Insert API key Logstash 6.6 or higher Logstash requires Java 8 or Java 11. Use the official Oracle distribution or an open-source distribution such as OpenJDK. Enable Logstash for log management To enable log management using Logstash: Install the Logstash plugin. Configure the Logstash plugin. Optional: Configure additional plugin attributes. Test the Logstash plugin. Generate some traffic and wait a few minutes, then check your account for data. Install the Logstash plugin To install the Logstash plugin, enter the following command into your terminal or command line interface: logstash-plugin install logstash-output-newrelic Copy Configure the Logstash plugin To configure your Logstash plugin: In your logstash.conf file, add the following block of data. Be sure to replace the placeholder text with your New Relic license key or Insights Insert key. Configure with the New Relic license key (recommended): output { newrelic { license_key => \"LICENSE_KEY\" } } Copy Or, configure with the New Relic Insert API key: output { newrelic { api_key => \"INSERT_API_KEY\" } } Copy Restart your Logstash instance. Optional configuration Once you have installed and configured the Logstash plugin, you can use the following attributes to configure how the plugin sends data to New Relic: Property Description Default value concurrent_requests The number of threads to make requests from. 1 base_uri The New Relic ingestion endpoint. US endpoint: https://log-api.newrelic.com/log/v1 EU endpoint: https://log-api.eu.newrelic.com/log/v1 max_retries Maximum number attempts to retry to send a message. If set to 0, no re-attempts will be made. 3 For more information on adding or configuring attributes, see Example Configurations for Logstash. Test the Logstash plugin To test if your Logstash plugin is receiving input from a log file: Add the following to your logstash.conf file: input { file { path => \"/PATH/TO/YOUR/LOG/FILE\" } } Copy Restart your Logstash instance. Run the following command to append a test log message to your log file: echo \"test message\" >> /PATH/TO/YOUR/LOG/FILE Copy Search New Relic Logs UI for test message. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable New Relic Logs, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.7096,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Logstash</em> plugin for <em>log</em> forwarding",
        "sections": "<em>Enable</em> <em>Logstash</em> for <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "Use our Logstash output plugin to connect your Logstash monitored <em>log</em> data to <em>New</em> <em>Relic</em>. Read on to learn how to <em>enable</em> this feature. Compatibility and requirements To forward your <em>logs</em> to <em>New</em> <em>Relic</em> using Logstash, ensure your configuration meets the following requirements: <em>New</em> <em>Relic</em> license key"
      },
      "id": "603ebf8a28ccbc2307eba794"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/kubernetes-plugin-log-forwarding": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Tip",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent(#automatically-inserted-attributes)",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-07-02T17:22:19Z",
      "updated_at": "2021-06-25T23:18:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use log management and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x and 18.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes as key-value pairs that can be used to send additional data with the logs which you can then query. Add attributes to any log source. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent(#automatically-inserted-attributes) The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 270.1251,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure <em>monitoring</em> agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use <em>log</em> <em>management</em> and the rest of our observability"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Vector output sink for log forwarding",
        "Compatibility and requirements",
        "Configure the Vector New Relic Logs sink",
        "Configure with the New Relic license key (recommended)",
        "Configure with the New Relic Insert API key",
        "Test the Vector New Relic logs sink",
        "View log data",
        "What's next?"
      ],
      "title": "Vector output sink for log forwarding",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "b2c621a62e9cc89c6b52e1a3e49411fb120b0de5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/vector-output-sink-log-forwarding/",
      "published_at": "2021-07-02T17:24:30Z",
      "updated_at": "2021-05-22T16:44:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Vector output sink to connect your Vector-monitored log data to New Relic. Read on to learn how to configure and test the Vector New Relic logs sink. Compatibility and requirements To forward your logs to New Relic using Vector, ensure your configuration meets the following requirements: New Relic license key (recommended) or Insert API key Vector version 0.7.0 or higher Configure the Vector New Relic Logs sink To configure the Vector New Relic logs sink: Choose one of the following options for adding a snippet to your vector.toml file (located in /etc/vector by default): Configure with the New Relic license key (recommended) Replace YOUR_LICENSE_KEY with the New Relic license key: # Ingest data by tailing one or more files [sources.mylog] type = \"file\" include = [\"/path/to/file\"] # Specify file or files to be tailed ignore_older = 86400 # Ignore events older than 1 day file_key = \"file\" # Add filename to log events host_key = \"host\" # Add hostname to log events # Configure sink to forward events to New Relic Logs [sinks.new_relic_logs] # REQUIRED type = \"new_relic_logs\" # must be: \"new_relic_logs\" inputs = [\"mylog\"] # example - value must be one or more source IDs license_key = \"YOUR_LICENSE_KEY\" region = \"us\" # Enum, must be one of: \"us\" \"eu\" depending on your New Relic Logs account region encoding.codec = \"json\" # OPTIONAL healthcheck = true # default Copy Configure with the New Relic Insert API key Replace YOUR_INSERT_KEY with the Insert API key: # Ingest data by tailing one or more files [sources.mylog] type = \"file\" include = [\"/path/to/file\"] # Specify file or files to be tailed ignore_older = 86400 # Ignore events older than 1 day file_key = \"file\" # Add filename to log events host_key = \"host\" # Add hostname to log events # Configure sink to forward events to New Relic Logs [sinks.new_relic_logs] # REQUIRED type = \"new_relic_logs\" # must be: \"new_relic_logs\" inputs = [\"mylog\"] # example - value must be one or more source IDs insert_key = \"YOUR_INSERT_KEY\" region = \"us\" # Enum, must be one of: \"us\" \"eu\" depending on your New Relic Logs account region encoding.codec = \"json\" # OPTIONAL healthcheck = true # default Copy Restart the Vector service to ensure your changes are applied. Test the Vector New Relic logs sink To test if the New Relic logs sink is forwarding events: Run the following command to append a test log message to your log file: echo \"test message\" >> /PATH/TO/YOUR/LOG/FILE Copy Search New Relic Logs UI for your test message. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable New Relic Logs, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.66753,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Vector output sink for <em>log</em> forwarding",
        "sections": "Configure the Vector <em>New</em> <em>Relic</em> <em>Logs</em> sink",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": ". For example, you can execute a query like this: SELECT * FROM <em>Log</em> Copy What&#x27;s next? Now that you&#x27;ve enabled <em>Logs</em>, here are some potential next steps: Explore your data using the <em>Logs</em> UI. Configure your agent to see contextual <em>log</em> data, such as distributed tracing, stack traces, application <em>logs</em>, and more. Query your data and create custom dashboards or alerts. If no data appears after you <em>enable</em> <em>New</em> <em>Relic</em> <em>Logs</em>, follow the troubleshooting procedures."
      },
      "id": "6045057664441f9a4a378f17"
    },
    {
      "sections": [
        "Logstash plugin for log forwarding",
        "Compatibility and requirements",
        "Enable Logstash for log management",
        "Install the Logstash plugin",
        "Configure the Logstash plugin",
        "Optional configuration",
        "Test the Logstash plugin",
        "View log data",
        "What's next?"
      ],
      "title": "Logstash plugin for log forwarding",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "62c6a8a5a160b466aaa7f852a085e47290169de1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/logstash-plugin-log-forwarding/",
      "published_at": "2021-07-02T17:23:20Z",
      "updated_at": "2021-05-16T06:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Logstash output plugin to connect your Logstash monitored log data to New Relic. Read on to learn how to enable this feature. Compatibility and requirements To forward your logs to New Relic using Logstash, ensure your configuration meets the following requirements: New Relic license key (recommended) or Insert API key Logstash 6.6 or higher Logstash requires Java 8 or Java 11. Use the official Oracle distribution or an open-source distribution such as OpenJDK. Enable Logstash for log management To enable log management using Logstash: Install the Logstash plugin. Configure the Logstash plugin. Optional: Configure additional plugin attributes. Test the Logstash plugin. Generate some traffic and wait a few minutes, then check your account for data. Install the Logstash plugin To install the Logstash plugin, enter the following command into your terminal or command line interface: logstash-plugin install logstash-output-newrelic Copy Configure the Logstash plugin To configure your Logstash plugin: In your logstash.conf file, add the following block of data. Be sure to replace the placeholder text with your New Relic license key or Insights Insert key. Configure with the New Relic license key (recommended): output { newrelic { license_key => \"LICENSE_KEY\" } } Copy Or, configure with the New Relic Insert API key: output { newrelic { api_key => \"INSERT_API_KEY\" } } Copy Restart your Logstash instance. Optional configuration Once you have installed and configured the Logstash plugin, you can use the following attributes to configure how the plugin sends data to New Relic: Property Description Default value concurrent_requests The number of threads to make requests from. 1 base_uri The New Relic ingestion endpoint. US endpoint: https://log-api.newrelic.com/log/v1 EU endpoint: https://log-api.eu.newrelic.com/log/v1 max_retries Maximum number attempts to retry to send a message. If set to 0, no re-attempts will be made. 3 For more information on adding or configuring attributes, see Example Configurations for Logstash. Test the Logstash plugin To test if your Logstash plugin is receiving input from a log file: Add the following to your logstash.conf file: input { file { path => \"/PATH/TO/YOUR/LOG/FILE\" } } Copy Restart your Logstash instance. Run the following command to append a test log message to your log file: echo \"test message\" >> /PATH/TO/YOUR/LOG/FILE Copy Search New Relic Logs UI for test message. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable New Relic Logs, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.7096,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Logstash</em> plugin for <em>log</em> forwarding",
        "sections": "<em>Enable</em> <em>Logstash</em> for <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "Use our Logstash output plugin to connect your Logstash monitored <em>log</em> data to <em>New</em> <em>Relic</em>. Read on to learn how to <em>enable</em> this feature. Compatibility and requirements To forward your <em>logs</em> to <em>New</em> <em>Relic</em> using Logstash, ensure your configuration meets the following requirements: <em>New</em> <em>Relic</em> license key"
      },
      "id": "603ebf8a28ccbc2307eba794"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/logstash-plugin-log-forwarding": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Tip",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent(#automatically-inserted-attributes)",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-07-02T17:22:19Z",
      "updated_at": "2021-06-25T23:18:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use log management and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x and 18.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes as key-value pairs that can be used to send additional data with the logs which you can then query. Add attributes to any log source. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent(#automatically-inserted-attributes) The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 270.1251,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure <em>monitoring</em> agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use <em>log</em> <em>management</em> and the rest of our observability"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Vector output sink for log forwarding",
        "Compatibility and requirements",
        "Configure the Vector New Relic Logs sink",
        "Configure with the New Relic license key (recommended)",
        "Configure with the New Relic Insert API key",
        "Test the Vector New Relic logs sink",
        "View log data",
        "What's next?"
      ],
      "title": "Vector output sink for log forwarding",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "b2c621a62e9cc89c6b52e1a3e49411fb120b0de5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/vector-output-sink-log-forwarding/",
      "published_at": "2021-07-02T17:24:30Z",
      "updated_at": "2021-05-22T16:44:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Vector output sink to connect your Vector-monitored log data to New Relic. Read on to learn how to configure and test the Vector New Relic logs sink. Compatibility and requirements To forward your logs to New Relic using Vector, ensure your configuration meets the following requirements: New Relic license key (recommended) or Insert API key Vector version 0.7.0 or higher Configure the Vector New Relic Logs sink To configure the Vector New Relic logs sink: Choose one of the following options for adding a snippet to your vector.toml file (located in /etc/vector by default): Configure with the New Relic license key (recommended) Replace YOUR_LICENSE_KEY with the New Relic license key: # Ingest data by tailing one or more files [sources.mylog] type = \"file\" include = [\"/path/to/file\"] # Specify file or files to be tailed ignore_older = 86400 # Ignore events older than 1 day file_key = \"file\" # Add filename to log events host_key = \"host\" # Add hostname to log events # Configure sink to forward events to New Relic Logs [sinks.new_relic_logs] # REQUIRED type = \"new_relic_logs\" # must be: \"new_relic_logs\" inputs = [\"mylog\"] # example - value must be one or more source IDs license_key = \"YOUR_LICENSE_KEY\" region = \"us\" # Enum, must be one of: \"us\" \"eu\" depending on your New Relic Logs account region encoding.codec = \"json\" # OPTIONAL healthcheck = true # default Copy Configure with the New Relic Insert API key Replace YOUR_INSERT_KEY with the Insert API key: # Ingest data by tailing one or more files [sources.mylog] type = \"file\" include = [\"/path/to/file\"] # Specify file or files to be tailed ignore_older = 86400 # Ignore events older than 1 day file_key = \"file\" # Add filename to log events host_key = \"host\" # Add hostname to log events # Configure sink to forward events to New Relic Logs [sinks.new_relic_logs] # REQUIRED type = \"new_relic_logs\" # must be: \"new_relic_logs\" inputs = [\"mylog\"] # example - value must be one or more source IDs insert_key = \"YOUR_INSERT_KEY\" region = \"us\" # Enum, must be one of: \"us\" \"eu\" depending on your New Relic Logs account region encoding.codec = \"json\" # OPTIONAL healthcheck = true # default Copy Restart the Vector service to ensure your changes are applied. Test the Vector New Relic logs sink To test if the New Relic logs sink is forwarding events: Run the following command to append a test log message to your log file: echo \"test message\" >> /PATH/TO/YOUR/LOG/FILE Copy Search New Relic Logs UI for your test message. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable New Relic Logs, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.66753,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Vector output sink for <em>log</em> forwarding",
        "sections": "Configure the Vector <em>New</em> <em>Relic</em> <em>Logs</em> sink",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": ". For example, you can execute a query like this: SELECT * FROM <em>Log</em> Copy What&#x27;s next? Now that you&#x27;ve enabled <em>Logs</em>, here are some potential next steps: Explore your data using the <em>Logs</em> UI. Configure your agent to see contextual <em>log</em> data, such as distributed tracing, stack traces, application <em>logs</em>, and more. Query your data and create custom dashboards or alerts. If no data appears after you <em>enable</em> <em>New</em> <em>Relic</em> <em>Logs</em>, follow the troubleshooting procedures."
      },
      "id": "6045057664441f9a4a378f17"
    },
    {
      "sections": [
        "Enable log management in New Relic",
        "Tip",
        "Requirements",
        "Enable log management using the infrastructure agent",
        "Enable log management in New Relic using a log forwarding solution",
        "Enable using the Logs API",
        "What's next?"
      ],
      "title": "Enable log management in New Relic",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "9574655633e0f3d9ac206488be9c8b240710483e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/enable-log-management-new-relic/",
      "published_at": "2021-07-02T14:30:36Z",
      "updated_at": "2021-05-16T06:06:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's log management allows you to collect, process, explore, visualize, and alert on your log data using your existing log forwarder. Read on to learn how to enable this feature and start using it. Tip To use log management and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Requirements To use log management, ensure your configuration meets the following requirements: Your New Relic account's license key A compatible log forwarding plugin installed Ensure outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region The preferred configuration method is to use the DNS name log-api.newrelic.com or log-api.eu.newrelic.com. Enable log management in New Relic There are several ways of bringing your logs into New Relic: Use the New Relic infrastructure agent Use log forwarding plugins (like Fluentd) Use the New Relic Logs API Enable log management using the infrastructure agent You can forward your logs to New Relic using the infrastructure agent, our lightweight data collector, without having to use additional software. For more information, see Forward your logs using the infrastructure agent. Enable log management in New Relic using a log forwarding solution You can use any of these solutions to forward your logs to New Relic: Infrastructure agent Kubernetes plugin AWS Lambda for sending logs from S3 AWS CloudWatch plugin AWS Kinesis Firehose AWS FireLens plugin Fluent Bit plugin Fluentd plugin Logstash plugin Vector plugin Heroku Log Streaming Syslog TCP Endpoint Enable using the Logs API If you prefer to connect to New Relic without installing a plugin, New Relic offers HTTP input integration. This will allow you to send your monitored log data directly to New Relic via the Log API. For more information, see Introduction to Log API. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable New Relic Logs, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.70927,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "sections": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " installed Ensure outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region The preferred configuration method is to use the DNS name <em>log</em>-api.newrelic.com or <em>log</em>-api.eu.newrelic.com. <em>Enable</em> <em>log</em> <em>management</em> in <em>New</em> <em>Relic</em> There are several ways of bringing your <em>logs</em> into <em>New</em>"
      },
      "id": "603ea41828ccbc872beba761"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/stream-logs-using-kinesis-data-firehose": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Tip",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent(#automatically-inserted-attributes)",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-07-02T17:22:19Z",
      "updated_at": "2021-06-25T23:18:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use log management and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x and 18.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes as key-value pairs that can be used to send additional data with the logs which you can then query. Add attributes to any log source. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent(#automatically-inserted-attributes) The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 270.125,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure <em>monitoring</em> agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use <em>log</em> <em>management</em> and the rest of our observability"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Vector output sink for log forwarding",
        "Compatibility and requirements",
        "Configure the Vector New Relic Logs sink",
        "Configure with the New Relic license key (recommended)",
        "Configure with the New Relic Insert API key",
        "Test the Vector New Relic logs sink",
        "View log data",
        "What's next?"
      ],
      "title": "Vector output sink for log forwarding",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "b2c621a62e9cc89c6b52e1a3e49411fb120b0de5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/vector-output-sink-log-forwarding/",
      "published_at": "2021-07-02T17:24:30Z",
      "updated_at": "2021-05-22T16:44:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Vector output sink to connect your Vector-monitored log data to New Relic. Read on to learn how to configure and test the Vector New Relic logs sink. Compatibility and requirements To forward your logs to New Relic using Vector, ensure your configuration meets the following requirements: New Relic license key (recommended) or Insert API key Vector version 0.7.0 or higher Configure the Vector New Relic Logs sink To configure the Vector New Relic logs sink: Choose one of the following options for adding a snippet to your vector.toml file (located in /etc/vector by default): Configure with the New Relic license key (recommended) Replace YOUR_LICENSE_KEY with the New Relic license key: # Ingest data by tailing one or more files [sources.mylog] type = \"file\" include = [\"/path/to/file\"] # Specify file or files to be tailed ignore_older = 86400 # Ignore events older than 1 day file_key = \"file\" # Add filename to log events host_key = \"host\" # Add hostname to log events # Configure sink to forward events to New Relic Logs [sinks.new_relic_logs] # REQUIRED type = \"new_relic_logs\" # must be: \"new_relic_logs\" inputs = [\"mylog\"] # example - value must be one or more source IDs license_key = \"YOUR_LICENSE_KEY\" region = \"us\" # Enum, must be one of: \"us\" \"eu\" depending on your New Relic Logs account region encoding.codec = \"json\" # OPTIONAL healthcheck = true # default Copy Configure with the New Relic Insert API key Replace YOUR_INSERT_KEY with the Insert API key: # Ingest data by tailing one or more files [sources.mylog] type = \"file\" include = [\"/path/to/file\"] # Specify file or files to be tailed ignore_older = 86400 # Ignore events older than 1 day file_key = \"file\" # Add filename to log events host_key = \"host\" # Add hostname to log events # Configure sink to forward events to New Relic Logs [sinks.new_relic_logs] # REQUIRED type = \"new_relic_logs\" # must be: \"new_relic_logs\" inputs = [\"mylog\"] # example - value must be one or more source IDs insert_key = \"YOUR_INSERT_KEY\" region = \"us\" # Enum, must be one of: \"us\" \"eu\" depending on your New Relic Logs account region encoding.codec = \"json\" # OPTIONAL healthcheck = true # default Copy Restart the Vector service to ensure your changes are applied. Test the Vector New Relic logs sink To test if the New Relic logs sink is forwarding events: Run the following command to append a test log message to your log file: echo \"test message\" >> /PATH/TO/YOUR/LOG/FILE Copy Search New Relic Logs UI for your test message. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable New Relic Logs, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.66751,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Vector output sink for <em>log</em> forwarding",
        "sections": "Configure the Vector <em>New</em> <em>Relic</em> <em>Logs</em> sink",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": ". For example, you can execute a query like this: SELECT * FROM <em>Log</em> Copy What&#x27;s next? Now that you&#x27;ve enabled <em>Logs</em>, here are some potential next steps: Explore your data using the <em>Logs</em> UI. Configure your agent to see contextual <em>log</em> data, such as distributed tracing, stack traces, application <em>logs</em>, and more. Query your data and create custom dashboards or alerts. If no data appears after you <em>enable</em> <em>New</em> <em>Relic</em> <em>Logs</em>, follow the troubleshooting procedures."
      },
      "id": "6045057664441f9a4a378f17"
    },
    {
      "sections": [
        "Logstash plugin for log forwarding",
        "Compatibility and requirements",
        "Enable Logstash for log management",
        "Install the Logstash plugin",
        "Configure the Logstash plugin",
        "Optional configuration",
        "Test the Logstash plugin",
        "View log data",
        "What's next?"
      ],
      "title": "Logstash plugin for log forwarding",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "62c6a8a5a160b466aaa7f852a085e47290169de1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/logstash-plugin-log-forwarding/",
      "published_at": "2021-07-02T17:23:20Z",
      "updated_at": "2021-05-16T06:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Logstash output plugin to connect your Logstash monitored log data to New Relic. Read on to learn how to enable this feature. Compatibility and requirements To forward your logs to New Relic using Logstash, ensure your configuration meets the following requirements: New Relic license key (recommended) or Insert API key Logstash 6.6 or higher Logstash requires Java 8 or Java 11. Use the official Oracle distribution or an open-source distribution such as OpenJDK. Enable Logstash for log management To enable log management using Logstash: Install the Logstash plugin. Configure the Logstash plugin. Optional: Configure additional plugin attributes. Test the Logstash plugin. Generate some traffic and wait a few minutes, then check your account for data. Install the Logstash plugin To install the Logstash plugin, enter the following command into your terminal or command line interface: logstash-plugin install logstash-output-newrelic Copy Configure the Logstash plugin To configure your Logstash plugin: In your logstash.conf file, add the following block of data. Be sure to replace the placeholder text with your New Relic license key or Insights Insert key. Configure with the New Relic license key (recommended): output { newrelic { license_key => \"LICENSE_KEY\" } } Copy Or, configure with the New Relic Insert API key: output { newrelic { api_key => \"INSERT_API_KEY\" } } Copy Restart your Logstash instance. Optional configuration Once you have installed and configured the Logstash plugin, you can use the following attributes to configure how the plugin sends data to New Relic: Property Description Default value concurrent_requests The number of threads to make requests from. 1 base_uri The New Relic ingestion endpoint. US endpoint: https://log-api.newrelic.com/log/v1 EU endpoint: https://log-api.eu.newrelic.com/log/v1 max_retries Maximum number attempts to retry to send a message. If set to 0, no re-attempts will be made. 3 For more information on adding or configuring attributes, see Example Configurations for Logstash. Test the Logstash plugin To test if your Logstash plugin is receiving input from a log file: Add the following to your logstash.conf file: input { file { path => \"/PATH/TO/YOUR/LOG/FILE\" } } Copy Restart your Logstash instance. Run the following command to append a test log message to your log file: echo \"test message\" >> /PATH/TO/YOUR/LOG/FILE Copy Search New Relic Logs UI for test message. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable New Relic Logs, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.7096,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Logstash</em> plugin for <em>log</em> forwarding",
        "sections": "<em>Enable</em> <em>Logstash</em> for <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "Use our Logstash output plugin to connect your Logstash monitored <em>log</em> data to <em>New</em> <em>Relic</em>. Read on to learn how to <em>enable</em> this feature. Compatibility and requirements To forward your <em>logs</em> to <em>New</em> <em>Relic</em> using Logstash, ensure your configuration meets the following requirements: <em>New</em> <em>Relic</em> license key"
      },
      "id": "603ebf8a28ccbc2307eba794"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/vector-output-sink-log-forwarding": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Tip",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent(#automatically-inserted-attributes)",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-07-02T17:22:19Z",
      "updated_at": "2021-06-25T23:18:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use log management and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x and 18.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes as key-value pairs that can be used to send additional data with the logs which you can then query. Add attributes to any log source. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent(#automatically-inserted-attributes) The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 270.125,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure <em>monitoring</em> agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use <em>log</em> <em>management</em> and the rest of our observability"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Logstash plugin for log forwarding",
        "Compatibility and requirements",
        "Enable Logstash for log management",
        "Install the Logstash plugin",
        "Configure the Logstash plugin",
        "Optional configuration",
        "Test the Logstash plugin",
        "View log data",
        "What's next?"
      ],
      "title": "Logstash plugin for log forwarding",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "62c6a8a5a160b466aaa7f852a085e47290169de1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/logstash-plugin-log-forwarding/",
      "published_at": "2021-07-02T17:23:20Z",
      "updated_at": "2021-05-16T06:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Logstash output plugin to connect your Logstash monitored log data to New Relic. Read on to learn how to enable this feature. Compatibility and requirements To forward your logs to New Relic using Logstash, ensure your configuration meets the following requirements: New Relic license key (recommended) or Insert API key Logstash 6.6 or higher Logstash requires Java 8 or Java 11. Use the official Oracle distribution or an open-source distribution such as OpenJDK. Enable Logstash for log management To enable log management using Logstash: Install the Logstash plugin. Configure the Logstash plugin. Optional: Configure additional plugin attributes. Test the Logstash plugin. Generate some traffic and wait a few minutes, then check your account for data. Install the Logstash plugin To install the Logstash plugin, enter the following command into your terminal or command line interface: logstash-plugin install logstash-output-newrelic Copy Configure the Logstash plugin To configure your Logstash plugin: In your logstash.conf file, add the following block of data. Be sure to replace the placeholder text with your New Relic license key or Insights Insert key. Configure with the New Relic license key (recommended): output { newrelic { license_key => \"LICENSE_KEY\" } } Copy Or, configure with the New Relic Insert API key: output { newrelic { api_key => \"INSERT_API_KEY\" } } Copy Restart your Logstash instance. Optional configuration Once you have installed and configured the Logstash plugin, you can use the following attributes to configure how the plugin sends data to New Relic: Property Description Default value concurrent_requests The number of threads to make requests from. 1 base_uri The New Relic ingestion endpoint. US endpoint: https://log-api.newrelic.com/log/v1 EU endpoint: https://log-api.eu.newrelic.com/log/v1 max_retries Maximum number attempts to retry to send a message. If set to 0, no re-attempts will be made. 3 For more information on adding or configuring attributes, see Example Configurations for Logstash. Test the Logstash plugin To test if your Logstash plugin is receiving input from a log file: Add the following to your logstash.conf file: input { file { path => \"/PATH/TO/YOUR/LOG/FILE\" } } Copy Restart your Logstash instance. Run the following command to append a test log message to your log file: echo \"test message\" >> /PATH/TO/YOUR/LOG/FILE Copy Search New Relic Logs UI for test message. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable New Relic Logs, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.7096,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Logstash</em> plugin for <em>log</em> forwarding",
        "sections": "<em>Enable</em> <em>Logstash</em> for <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "Use our Logstash output plugin to connect your Logstash monitored <em>log</em> data to <em>New</em> <em>Relic</em>. Read on to learn how to <em>enable</em> this feature. Compatibility and requirements To forward your <em>logs</em> to <em>New</em> <em>Relic</em> using Logstash, ensure your configuration meets the following requirements: <em>New</em> <em>Relic</em> license key"
      },
      "id": "603ebf8a28ccbc2307eba794"
    },
    {
      "sections": [
        "Enable log management in New Relic",
        "Tip",
        "Requirements",
        "Enable log management using the infrastructure agent",
        "Enable log management in New Relic using a log forwarding solution",
        "Enable using the Logs API",
        "What's next?"
      ],
      "title": "Enable log management in New Relic",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "9574655633e0f3d9ac206488be9c8b240710483e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/enable-log-management-new-relic/",
      "published_at": "2021-07-02T14:30:36Z",
      "updated_at": "2021-05-16T06:06:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's log management allows you to collect, process, explore, visualize, and alert on your log data using your existing log forwarder. Read on to learn how to enable this feature and start using it. Tip To use log management and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Requirements To use log management, ensure your configuration meets the following requirements: Your New Relic account's license key A compatible log forwarding plugin installed Ensure outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region The preferred configuration method is to use the DNS name log-api.newrelic.com or log-api.eu.newrelic.com. Enable log management in New Relic There are several ways of bringing your logs into New Relic: Use the New Relic infrastructure agent Use log forwarding plugins (like Fluentd) Use the New Relic Logs API Enable log management using the infrastructure agent You can forward your logs to New Relic using the infrastructure agent, our lightweight data collector, without having to use additional software. For more information, see Forward your logs using the infrastructure agent. Enable log management in New Relic using a log forwarding solution You can use any of these solutions to forward your logs to New Relic: Infrastructure agent Kubernetes plugin AWS Lambda for sending logs from S3 AWS CloudWatch plugin AWS Kinesis Firehose AWS FireLens plugin Fluent Bit plugin Fluentd plugin Logstash plugin Vector plugin Heroku Log Streaming Syslog TCP Endpoint Enable using the Logs API If you prefer to connect to New Relic without installing a plugin, New Relic offers HTTP input integration. This will allow you to send your monitored log data directly to New Relic via the Log API. For more information, see Introduction to Log API. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts. If no data appears after you enable New Relic Logs, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.70926,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "sections": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " installed Ensure outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region The preferred configuration method is to use the DNS name <em>log</em>-api.newrelic.com or <em>log</em>-api.eu.newrelic.com. <em>Enable</em> <em>log</em> <em>management</em> in <em>New</em> <em>Relic</em> There are several ways of bringing your <em>logs</em> into <em>New</em>"
      },
      "id": "603ea41828ccbc872beba761"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/logs-context-agent-apis/annotate-logs-logs-context-using-apm-agent-apis": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Tip",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent(#automatically-inserted-attributes)",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-07-02T17:22:19Z",
      "updated_at": "2021-06-25T23:18:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use log management and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x and 18.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes as key-value pairs that can be used to send additional data with the logs which you can then query. Add attributes to any log source. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent(#automatically-inserted-attributes) The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.7998,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> <em>agent</em>",
        "sections": "<em>Enable</em> <em>log</em> forwarding using the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure monitoring <em>agent</em>. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use <em>log</em> <em>management</em> and the rest of our observability"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Java: Configure with Log4j 1.x",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Log4j 1.x extension",
        "Example configuration file for the Log4j 1.x extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Log4j 1.x",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "c037c5f99fbe16c9ae129d177d246009df25fb45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-1x/",
      "published_at": "2021-07-02T13:23:38Z",
      "updated_at": "2021-04-16T21:20:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Log4j 1.x extension for New Relic log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Log4j 1.x, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Log4j 1.x package installed and working on the application. log4j must be configured in code or via XML. Properties files are not supported because AsyncAppender instances can only be automatically configured via XML. Configure logs in context with log management To configure logs in context with Logs4j 1.x: Enable log management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Log4j 1.x extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable Distributed tracing. Configure the Log4j 1.x extension To configure logs in context with the Log4j 1.x extension, complete the following steps: Update your project's dependencies to include the Log4j 1.x extension as applicable: To update with Gradle, add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j1:2.0\") } Copy To update with Maven, add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j1</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <appender> element with a NewRelicLayout, adding <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> as shown below: <appender name=\" TypicalFile \" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <layout class=\" com.newrelic.logging.log4j1.NewRelicLayout \"/> <!-- only this line needs to be added --> </appender> Copy Once updated, use NewRelicAsyncAppender to wrap any appenders that will target New Relic's log forwarder. For example: <appender name=\" NewRelicFile \" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\" TypicalFile \" /> </appender> Copy Once updated, use the async appender on the root logger. For example: <root> <appender-ref ref=\" NewRelicFile \" /> </root> Copy Example configuration file for the Log4j 1.x extension <?xml version=\"1.0\" encoding=\"UTF-8\" ?> <!DOCTYPE log4j:configuration SYSTEM \"log4j.dtd\"> <log4j:configuration debug=\"false\"> <appender name=\"TypicalFile\" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <!-- layout has been replaced --> <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> </appender> <!-- this appender was added --> <appender name=\"NewRelicFile\" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\"TypicalFile\" /> </appender> <appender name=\"TypicalConsole\" class=\"org.apache.log4j.ConsoleAppender\"> <layout class=\"org.apache.log4j.PatternLayout\"> <param name=\"ConversionPattern\" value=\"%-5p %c{1} - %m%n\"/> </layout> </appender> <root> ​ <!-- the new appender was used here -->​​ <appender-ref ref=\"NewRelicFile\" /> <appender-ref ref=\"TypicalConsole\" /> </root> </log4j:configuration> Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 141.19643,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Java: Configure <em>with</em> <em>Log4j</em> 1.x",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> <em>with</em> <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " <em>log</em> forwarding plugin. Install or update the Java <em>agent</em>. Configure the <em>Log</em>4j 1.x extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em> Confirm that you have <em>log</em> <em>management</em> enabled, with a compatible <em>log</em> forwarding plugin installed to send your application <em>logs</em> to <em>New</em> <em>Relic</em>. Install or update"
      },
      "id": "603ead8b196a675ad7a83dd6"
    },
    {
      "sections": [
        "Configure logs in context for Ruby",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Ruby agent",
        "Configure for Rails",
        "Rails advanced configuration",
        "Configure for Ruby without Rails",
        "Advanced configuration",
        "Custom logger configuration",
        "Lograge configuration",
        "Check for logging data",
        "Troubleshooting",
        "Incompatible gems",
        "What's next?"
      ],
      "title": "Configure logs in context for Ruby",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Ruby"
      ],
      "external_id": "b9fec1d5dca01fdafbd45a26f6f9dc2030ae78a5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-ruby/configure-logs-context-ruby/",
      "published_at": "2021-07-02T15:43:26Z",
      "updated_at": "2021-03-16T09:25:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the Ruby agent connects your logs and APM data in New Relic, giving full context to high-level events and providing high value data to specific log lines. Read on to learn how to configure logs in context and enrich your log data. Compatibility and requirements To use log management with the Ruby agent, ensure your configuration meets the following requirements: Ruby agent 6.7.0 or higher: Install or update Supported Rails version (for Rails applications) Configure logs in context with log management To configure logs in context with Ruby: Enable log management with a compatible log forwarding plugin. Install or update the Ruby agent. Configure logs in context for Ruby. Optional: Advanced configuration. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Ruby agent Install or update to the most recent Ruby agent version, and enable distributed tracing. Configure logs in context for Ruby Configure for Rails Rails logging is controlled by two components: a logger (customizable by setting config.logger) and a log formatter (customizable by setting config.log_formatter). In most cases, logs in context should be configured by setting config.log_formatter to the DecoratingFormatter in your Rails application. For more guidance regarding Rails configuration, see Configuring Rails Applications. In your application's config, require 'newrelic_rpm', then add the following line: module ________ class Application < Rails::Application ... config.log_formatter = ::NewRelic::Agent::Logging::DecoratingFormatter.new end end Copy This will use the New Relic formatter to format log messages, but the rest of the logging configuration will be provided by the other Rails config settings. Please note that Logs in Context for Ruby does not currently support tagged logging; if you are initializing your logger with a log_tags argument, your custom tags may not appear on the final version of your logs. Rails advanced configuration If setting the log_formatter option doesn't meet your needs, replace the entire Rails logger with an instance of the New Relic logger. Provide the parameters to the logger's constructor, like this: module ________ class Application < Rails::Application ... config.logger = ::NewRelic::Agent::Logging::DecoratingLogger.new( \"log/application.log\", #etc... ) end end Copy Configure for Ruby without Rails For non-Rails applications, use the DecoratingLogger in place of the Ruby standard ::Logger, like this: logger = ::NewRelic::Agent::Logging::DecoratingLogger.new( 'log/application.log', #etc... ) ... logger.info(...) Copy The DecoratingLogger is a drop-in replacement for the Ruby standard ::Logger. Their constructors accept the same parameters. Advanced configuration Custom logger configuration To use our logging extension with a different logging implementation, or your own custom logger, use the DecoratingFormatter. Example: module ________ class Application < Rails::Application ... config.logger = ::YourCustomLoggerImplementation.new( $stdout, formatter: ::NewRelic::Agent::Logging::DecoratingFormatter.new ) end end Copy Lograge configuration To configure this extension with the lograge gem, there is no additional configuration required. Check for logging data If you have configured your logging in /config/application.rb, or in /config/environments/development.rb, run your application locally and check its logging output. You should see some output like this: {\"entity.name\":\"your_app_name\",\"entity.type\":\"SERVICE\",\"hostname\":\"79bcbf8d\",\"trace.id\":\"79bcbf8d\",\"span.id\":\"00fc7d46\",\"timestamp\":1567701375543,\"message\":\"example log message one\",\"log.level\":\"DEBUG\"} {\"entity.name\":\"your_app_name\",\"entity.type\":\"SERVICE\",\"hostname\":\"79bcbf8d\",\"trace.id\":\"79bcbf8d\",\"span.id\":\"6754870b\",\"timestamp\":1567702843604,\"message\":\"example log message two\",\"log.level\":\"DEBUG\"} Copy If you have deployed this application to an environment with a log forwarder, your application's logs will appear in the New Relic Logs UI with metadata linking them to a trace and a span. You can find them using a query like this: entity.name:\"your_app_name\" has:trace.id Copy If you see JSON logs in your application's output, but no logs returned by a query like the above, check your log forwarder. Troubleshooting If the logs from your application are not formatted in JSON with fields like trace.id and span.id, there may be a problem with the configuration of the New Relic Logging Extension. Check that: the application is using a supported logging framework. the configuration has been applied to all the environments where you would like to use the New Relic Logging Extension. there is not another logger configured later in the configuration of the application. Incompatible gems The New Relic decorating logger is known to be incompatible with the following gems: logging semantic logger rails_stdout_logger rails_12factor What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.94392,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure <em>logs</em> <em>in</em> <em>context</em> for Ruby",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> <em>with</em> <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the Ruby <em>agent</em> connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>, giving full <em>context</em> to high-level events and providing high value data to specific <em>log</em> lines. Read on to learn how to configure <em>logs</em> in <em>context</em> and enrich your <em>log</em> data. Compatibility and requirements To use <em>log</em>"
      },
      "id": "603ea67c64441fe0c34e886e"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/logs-context-go/configure-logs-context-go": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Tip",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent(#automatically-inserted-attributes)",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-07-02T17:22:19Z",
      "updated_at": "2021-06-25T23:18:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use log management and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x and 18.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes as key-value pairs that can be used to send additional data with the logs which you can then query. Add attributes to any log source. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent(#automatically-inserted-attributes) The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.91827,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Forward</em> your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> <em>forwarding</em> using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use <em>log</em> <em>management</em> and the rest of our observability"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Java: Configure with Log4j 1.x",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Log4j 1.x extension",
        "Example configuration file for the Log4j 1.x extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Log4j 1.x",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "c037c5f99fbe16c9ae129d177d246009df25fb45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-1x/",
      "published_at": "2021-07-02T13:23:38Z",
      "updated_at": "2021-04-16T21:20:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Log4j 1.x extension for New Relic log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Log4j 1.x, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Log4j 1.x package installed and working on the application. log4j must be configured in code or via XML. Properties files are not supported because AsyncAppender instances can only be automatically configured via XML. Configure logs in context with log management To configure logs in context with Logs4j 1.x: Enable log management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Log4j 1.x extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable Distributed tracing. Configure the Log4j 1.x extension To configure logs in context with the Log4j 1.x extension, complete the following steps: Update your project's dependencies to include the Log4j 1.x extension as applicable: To update with Gradle, add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j1:2.0\") } Copy To update with Maven, add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j1</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <appender> element with a NewRelicLayout, adding <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> as shown below: <appender name=\" TypicalFile \" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <layout class=\" com.newrelic.logging.log4j1.NewRelicLayout \"/> <!-- only this line needs to be added --> </appender> Copy Once updated, use NewRelicAsyncAppender to wrap any appenders that will target New Relic's log forwarder. For example: <appender name=\" NewRelicFile \" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\" TypicalFile \" /> </appender> Copy Once updated, use the async appender on the root logger. For example: <root> <appender-ref ref=\" NewRelicFile \" /> </root> Copy Example configuration file for the Log4j 1.x extension <?xml version=\"1.0\" encoding=\"UTF-8\" ?> <!DOCTYPE log4j:configuration SYSTEM \"log4j.dtd\"> <log4j:configuration debug=\"false\"> <appender name=\"TypicalFile\" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <!-- layout has been replaced --> <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> </appender> <!-- this appender was added --> <appender name=\"NewRelicFile\" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\"TypicalFile\" /> </appender> <appender name=\"TypicalConsole\" class=\"org.apache.log4j.ConsoleAppender\"> <layout class=\"org.apache.log4j.PatternLayout\"> <param name=\"ConversionPattern\" value=\"%-5p %c{1} - %m%n\"/> </layout> </appender> <root> ​ <!-- the new appender was used here -->​​ <appender-ref ref=\"NewRelicFile\" /> <appender-ref ref=\"TypicalConsole\" /> </root> </log4j:configuration> Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 132.61632,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Java: Configure with <em>Log4j</em> 1.x",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>New</em> <em>Relic</em> offers a <em>Log</em>4j 1.x extension for <em>New</em> <em>Relic</em> <em>log</em> <em>management</em>, allowing you link to your <em>log</em> data with related data across the rest of the <em>New</em> <em>Relic</em> platform. This document explains how to configure <em>logs</em> in <em>context</em> and start getting <em>log</em> data. The code and an example application are available"
      },
      "id": "603ead8b196a675ad7a83dd6"
    },
    {
      "sections": [
        "Configure logs in context for Ruby",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Ruby agent",
        "Configure for Rails",
        "Rails advanced configuration",
        "Configure for Ruby without Rails",
        "Advanced configuration",
        "Custom logger configuration",
        "Lograge configuration",
        "Check for logging data",
        "Troubleshooting",
        "Incompatible gems",
        "What's next?"
      ],
      "title": "Configure logs in context for Ruby",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Ruby"
      ],
      "external_id": "b9fec1d5dca01fdafbd45a26f6f9dc2030ae78a5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-ruby/configure-logs-context-ruby/",
      "published_at": "2021-07-02T15:43:26Z",
      "updated_at": "2021-03-16T09:25:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the Ruby agent connects your logs and APM data in New Relic, giving full context to high-level events and providing high value data to specific log lines. Read on to learn how to configure logs in context and enrich your log data. Compatibility and requirements To use log management with the Ruby agent, ensure your configuration meets the following requirements: Ruby agent 6.7.0 or higher: Install or update Supported Rails version (for Rails applications) Configure logs in context with log management To configure logs in context with Ruby: Enable log management with a compatible log forwarding plugin. Install or update the Ruby agent. Configure logs in context for Ruby. Optional: Advanced configuration. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Ruby agent Install or update to the most recent Ruby agent version, and enable distributed tracing. Configure logs in context for Ruby Configure for Rails Rails logging is controlled by two components: a logger (customizable by setting config.logger) and a log formatter (customizable by setting config.log_formatter). In most cases, logs in context should be configured by setting config.log_formatter to the DecoratingFormatter in your Rails application. For more guidance regarding Rails configuration, see Configuring Rails Applications. In your application's config, require 'newrelic_rpm', then add the following line: module ________ class Application < Rails::Application ... config.log_formatter = ::NewRelic::Agent::Logging::DecoratingFormatter.new end end Copy This will use the New Relic formatter to format log messages, but the rest of the logging configuration will be provided by the other Rails config settings. Please note that Logs in Context for Ruby does not currently support tagged logging; if you are initializing your logger with a log_tags argument, your custom tags may not appear on the final version of your logs. Rails advanced configuration If setting the log_formatter option doesn't meet your needs, replace the entire Rails logger with an instance of the New Relic logger. Provide the parameters to the logger's constructor, like this: module ________ class Application < Rails::Application ... config.logger = ::NewRelic::Agent::Logging::DecoratingLogger.new( \"log/application.log\", #etc... ) end end Copy Configure for Ruby without Rails For non-Rails applications, use the DecoratingLogger in place of the Ruby standard ::Logger, like this: logger = ::NewRelic::Agent::Logging::DecoratingLogger.new( 'log/application.log', #etc... ) ... logger.info(...) Copy The DecoratingLogger is a drop-in replacement for the Ruby standard ::Logger. Their constructors accept the same parameters. Advanced configuration Custom logger configuration To use our logging extension with a different logging implementation, or your own custom logger, use the DecoratingFormatter. Example: module ________ class Application < Rails::Application ... config.logger = ::YourCustomLoggerImplementation.new( $stdout, formatter: ::NewRelic::Agent::Logging::DecoratingFormatter.new ) end end Copy Lograge configuration To configure this extension with the lograge gem, there is no additional configuration required. Check for logging data If you have configured your logging in /config/application.rb, or in /config/environments/development.rb, run your application locally and check its logging output. You should see some output like this: {\"entity.name\":\"your_app_name\",\"entity.type\":\"SERVICE\",\"hostname\":\"79bcbf8d\",\"trace.id\":\"79bcbf8d\",\"span.id\":\"00fc7d46\",\"timestamp\":1567701375543,\"message\":\"example log message one\",\"log.level\":\"DEBUG\"} {\"entity.name\":\"your_app_name\",\"entity.type\":\"SERVICE\",\"hostname\":\"79bcbf8d\",\"trace.id\":\"79bcbf8d\",\"span.id\":\"6754870b\",\"timestamp\":1567702843604,\"message\":\"example log message two\",\"log.level\":\"DEBUG\"} Copy If you have deployed this application to an environment with a log forwarder, your application's logs will appear in the New Relic Logs UI with metadata linking them to a trace and a span. You can find them using a query like this: entity.name:\"your_app_name\" has:trace.id Copy If you see JSON logs in your application's output, but no logs returned by a query like the above, check your log forwarder. Troubleshooting If the logs from your application are not formatted in JSON with fields like trace.id and span.id, there may be a problem with the configuration of the New Relic Logging Extension. Check that: the application is using a supported logging framework. the configuration has been applied to all the environments where you would like to use the New Relic Logging Extension. there is not another logger configured later in the configuration of the application. Incompatible gems The New Relic decorating logger is known to be incompatible with the following gems: logging semantic logger rails_stdout_logger rails_12factor What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 128.62224,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure <em>logs</em> <em>in</em> <em>context</em> <em>for</em> Ruby",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the Ruby agent connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>, giving full <em>context</em> to high-level events and providing high value data to specific <em>log</em> lines. Read on to learn how to configure <em>logs</em> in <em>context</em> and enrich your <em>log</em> data. Compatibility and requirements To use <em>log</em>"
      },
      "id": "603ea67c64441fe0c34e886e"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/logs-context-java/configure-logs-context-java": [
    {
      "sections": [
        "Java: Configure with Log4j 1.x",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Log4j 1.x extension",
        "Example configuration file for the Log4j 1.x extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Log4j 1.x",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "c037c5f99fbe16c9ae129d177d246009df25fb45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-1x/",
      "published_at": "2021-07-02T13:23:38Z",
      "updated_at": "2021-04-16T21:20:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Log4j 1.x extension for New Relic log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Log4j 1.x, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Log4j 1.x package installed and working on the application. log4j must be configured in code or via XML. Properties files are not supported because AsyncAppender instances can only be automatically configured via XML. Configure logs in context with log management To configure logs in context with Logs4j 1.x: Enable log management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Log4j 1.x extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable Distributed tracing. Configure the Log4j 1.x extension To configure logs in context with the Log4j 1.x extension, complete the following steps: Update your project's dependencies to include the Log4j 1.x extension as applicable: To update with Gradle, add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j1:2.0\") } Copy To update with Maven, add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j1</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <appender> element with a NewRelicLayout, adding <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> as shown below: <appender name=\" TypicalFile \" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <layout class=\" com.newrelic.logging.log4j1.NewRelicLayout \"/> <!-- only this line needs to be added --> </appender> Copy Once updated, use NewRelicAsyncAppender to wrap any appenders that will target New Relic's log forwarder. For example: <appender name=\" NewRelicFile \" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\" TypicalFile \" /> </appender> Copy Once updated, use the async appender on the root logger. For example: <root> <appender-ref ref=\" NewRelicFile \" /> </root> Copy Example configuration file for the Log4j 1.x extension <?xml version=\"1.0\" encoding=\"UTF-8\" ?> <!DOCTYPE log4j:configuration SYSTEM \"log4j.dtd\"> <log4j:configuration debug=\"false\"> <appender name=\"TypicalFile\" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <!-- layout has been replaced --> <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> </appender> <!-- this appender was added --> <appender name=\"NewRelicFile\" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\"TypicalFile\" /> </appender> <appender name=\"TypicalConsole\" class=\"org.apache.log4j.ConsoleAppender\"> <layout class=\"org.apache.log4j.PatternLayout\"> <param name=\"ConversionPattern\" value=\"%-5p %c{1} - %m%n\"/> </layout> </appender> <root> ​ <!-- the new appender was used here -->​​ <appender-ref ref=\"NewRelicFile\" /> <appender-ref ref=\"TypicalConsole\" /> </root> </log4j:configuration> Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 236.09816,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Java</em>: Configure with <em>Log4j</em> 1.x",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " <em>log</em> forwarding plugin. Install or update the <em>Java</em> agent. Configure the <em>Log</em>4j 1.x extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em> Confirm that you have <em>log</em> <em>management</em> enabled, with a compatible <em>log</em> forwarding plugin installed to send your application <em>logs</em> to <em>New</em> <em>Relic</em>. Install or update"
      },
      "id": "603ead8b196a675ad7a83dd6"
    },
    {
      "sections": [
        "Java: Configure with Log4j 2.x",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Log4j 2.x extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Log4j 2.x",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "481ea55e236babf6d2ee7f7326db4c27e3dd37a3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-2x/",
      "published_at": "2021-07-02T13:23:38Z",
      "updated_at": "2021-03-16T09:23:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Log4j 2.x extension for log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Log4j 2.x, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Log4j 2.x or Logs4j 2 binding package installed and working on the application. Configure logs in context with log management To configure New Relic logs in context with Log4j 2.x: Enable logs management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Log4j 2.x extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable distributed tracing. Configure the Log4j 2.x extension To configure logs in context with the Log4j 2.x extension, complete the following steps: Update your project's dependencies to include the Log4j 2.x extension as applicable: To update with Gradle, add the highlighted section to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j2:2.0\") } Copy To update with Maven, add the highlighted section to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j2</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <configuration> element by adding the highlighted section: <Configuration xmlns=\"http://logging.apache.org/log4j/2.0/config\" packages=\"com.newrelic.logging.log4j2\" > Copy If you are using a properties file, add packages=com.newrelic.logging.log4j2. Once updated, add <NewRelicLayout/> to use a NewRelicLayout element within one of the appenders. For example: <File name=\"MyFile\" fileName=\"logs/app-log-file.log\"> <NewRelicLayout/> </File> Copy If you are using a properties file, change only the layout.type property, as shown below: appender.console.type = Console appender.console.name = STDOUT appender.console.layout.type = NewRelicLayout Copy If you only modified an existing appender, you can skip this step. Add <AppenderRef/> within <Root> to use this appender. The ref attribute refers to the name of the appender you created in the previous step. For example: <Root level=\"info\"> <AppenderRef ref=\"MyFile\"/> </Root> Copy If you are using a properties file, you will need to add a property if you added a new appender: rootLogger.level = info rootLogger.appenderRef.stdout.ref = STDOUT ​​​​​ Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.98721,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Java</em>: Configure with <em>Log4j</em> 2.x",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " on the application. Configure <em>logs</em> in <em>context</em> with <em>log</em> <em>management</em> To configure <em>New</em> <em>Relic</em> <em>logs</em> in <em>context</em> with <em>Log</em>4j 2.x: <em>Enable</em> <em>logs</em> <em>management</em> with a compatible <em>log</em> forwarding plugin. Install or update the <em>Java</em> agent. Configure the <em>Log</em>4j 2.x extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em>"
      },
      "id": "603ead8a28ccbc47a2eba74f"
    },
    {
      "sections": [
        "Java: Configure with Logback",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Logback extension",
        "Important",
        "Example configuration files",
        "Single console appender example",
        "Two-appender example",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Logback",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "d43c55efa817768e3840897678b966f896fd268d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-logback/",
      "published_at": "2021-07-02T13:23:38Z",
      "updated_at": "2021-03-16T09:23:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Logback extension for log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Logback, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update Logback 1.2.0 or higher installed and working on the application. Configure logs in context with log management To configure New Relic logs in context with Logback: Enable log management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Logback extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable Distributed tracing. Configure the Logback extension To configure logs in context with the Logback extension, complete the following steps: Update your project's dependencies to include the Logback extension as applicable: To update with Gradle, add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:logback:2.0\") } Copy To update with Maven, add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>logback</artifactId> <version>2.0</version> </dependency> </dependencies> Copy Update your logging configuration xml to replace any existing < encoder> element as shown below. If you are logging to the console (stdout/stderr), look for ConsoleAppender and replace : <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy If you are logging to a file, look for FileAppender and replace <encoder>: <appender name=\"LOG_FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>logs/app-log-file.log</file> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy Update your logging configuration xml with the NewRelicAsyncAppender. To ensure that NewRelicAsyncAppender wraps any appenders that will target New Relic's log forwarder, add the following section. Change \"LOG_FILE\" to the name of the appender you updated in the previous step. <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"LOG_FILE\" /> </appender> Copy Make sure NewRelicAsyncAppender is the appender used in your logger. Replace your root logger’s appenders with the ASYNC appender created in the previous step. <root> <appender-ref ref=\"ASYNC\" /> </root> Copy Important It's important that the NewRelicAsyncAppender be the first appender to see the log message. List any other appenders after the NewRelicAsyncAppender in the <root> list. Example configuration files You can find a working example in GitHub. Here are examples of an updated logging .xml file for the Logback extension. Single console appender example Example configuration file after adding in the logging extension information. <configuration> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <!-- changed the encoder --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- added the ASYNC appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"STDOUT\" /> </appender> <root level=\"debug\"> <!-- changed the root logger --> <appender-ref ref=\"ASYNC\" /> </root> </configuration> Copy Two-appender example This example sends New Relic logging to a file, but still sends standard logging to the console. <configuration> <appender name=\"FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>myApp.log</file> <!-- encoder changed --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- this appender does normal console logging --> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder> <pattern>%msg%n</pattern> </encoder> </appender> <!-- The required New Relic ASYNC appender wraps the FILE appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"FILE\" /> </appender> <root level=\"debug\"> <!-- ASYNC is one of the main appenders --> <appender-ref ref=\"ASYNC\" /> <!-- Send every message to normal console logging, as well. --> <appender-ref ref=\"STDOUT\" /> </root> </configuration> Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.98721,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Java</em>: Configure with <em>Logback</em>",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " To configure <em>New</em> <em>Relic</em> <em>logs</em> in <em>context</em> with Logback: <em>Enable</em> <em>log</em> <em>management</em> with a compatible <em>log</em> forwarding plugin. Install or update the <em>Java</em> agent. Configure the Logback extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em> Confirm that you have <em>log</em> <em>management</em> enabled, with a compatible <em>log</em>"
      },
      "id": "603ead8a196a679235a83d96"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-dropwizard": [
    {
      "sections": [
        "Java: Configure with Log4j 1.x",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Log4j 1.x extension",
        "Example configuration file for the Log4j 1.x extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Log4j 1.x",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "c037c5f99fbe16c9ae129d177d246009df25fb45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-1x/",
      "published_at": "2021-07-02T13:23:38Z",
      "updated_at": "2021-04-16T21:20:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Log4j 1.x extension for New Relic log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Log4j 1.x, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Log4j 1.x package installed and working on the application. log4j must be configured in code or via XML. Properties files are not supported because AsyncAppender instances can only be automatically configured via XML. Configure logs in context with log management To configure logs in context with Logs4j 1.x: Enable log management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Log4j 1.x extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable Distributed tracing. Configure the Log4j 1.x extension To configure logs in context with the Log4j 1.x extension, complete the following steps: Update your project's dependencies to include the Log4j 1.x extension as applicable: To update with Gradle, add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j1:2.0\") } Copy To update with Maven, add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j1</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <appender> element with a NewRelicLayout, adding <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> as shown below: <appender name=\" TypicalFile \" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <layout class=\" com.newrelic.logging.log4j1.NewRelicLayout \"/> <!-- only this line needs to be added --> </appender> Copy Once updated, use NewRelicAsyncAppender to wrap any appenders that will target New Relic's log forwarder. For example: <appender name=\" NewRelicFile \" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\" TypicalFile \" /> </appender> Copy Once updated, use the async appender on the root logger. For example: <root> <appender-ref ref=\" NewRelicFile \" /> </root> Copy Example configuration file for the Log4j 1.x extension <?xml version=\"1.0\" encoding=\"UTF-8\" ?> <!DOCTYPE log4j:configuration SYSTEM \"log4j.dtd\"> <log4j:configuration debug=\"false\"> <appender name=\"TypicalFile\" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <!-- layout has been replaced --> <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> </appender> <!-- this appender was added --> <appender name=\"NewRelicFile\" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\"TypicalFile\" /> </appender> <appender name=\"TypicalConsole\" class=\"org.apache.log4j.ConsoleAppender\"> <layout class=\"org.apache.log4j.PatternLayout\"> <param name=\"ConversionPattern\" value=\"%-5p %c{1} - %m%n\"/> </layout> </appender> <root> ​ <!-- the new appender was used here -->​​ <appender-ref ref=\"NewRelicFile\" /> <appender-ref ref=\"TypicalConsole\" /> </root> </log4j:configuration> Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 236.09816,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Java</em>: Configure with <em>Log4j</em> 1.x",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " <em>log</em> forwarding plugin. Install or update the <em>Java</em> agent. Configure the <em>Log</em>4j 1.x extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em> Confirm that you have <em>log</em> <em>management</em> enabled, with a compatible <em>log</em> forwarding plugin installed to send your application <em>logs</em> to <em>New</em> <em>Relic</em>. Install or update"
      },
      "id": "603ead8b196a675ad7a83dd6"
    },
    {
      "sections": [
        "Java: Configure with Log4j 2.x",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Log4j 2.x extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Log4j 2.x",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "481ea55e236babf6d2ee7f7326db4c27e3dd37a3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-2x/",
      "published_at": "2021-07-02T13:23:38Z",
      "updated_at": "2021-03-16T09:23:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Log4j 2.x extension for log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Log4j 2.x, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Log4j 2.x or Logs4j 2 binding package installed and working on the application. Configure logs in context with log management To configure New Relic logs in context with Log4j 2.x: Enable logs management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Log4j 2.x extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable distributed tracing. Configure the Log4j 2.x extension To configure logs in context with the Log4j 2.x extension, complete the following steps: Update your project's dependencies to include the Log4j 2.x extension as applicable: To update with Gradle, add the highlighted section to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j2:2.0\") } Copy To update with Maven, add the highlighted section to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j2</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <configuration> element by adding the highlighted section: <Configuration xmlns=\"http://logging.apache.org/log4j/2.0/config\" packages=\"com.newrelic.logging.log4j2\" > Copy If you are using a properties file, add packages=com.newrelic.logging.log4j2. Once updated, add <NewRelicLayout/> to use a NewRelicLayout element within one of the appenders. For example: <File name=\"MyFile\" fileName=\"logs/app-log-file.log\"> <NewRelicLayout/> </File> Copy If you are using a properties file, change only the layout.type property, as shown below: appender.console.type = Console appender.console.name = STDOUT appender.console.layout.type = NewRelicLayout Copy If you only modified an existing appender, you can skip this step. Add <AppenderRef/> within <Root> to use this appender. The ref attribute refers to the name of the appender you created in the previous step. For example: <Root level=\"info\"> <AppenderRef ref=\"MyFile\"/> </Root> Copy If you are using a properties file, you will need to add a property if you added a new appender: rootLogger.level = info rootLogger.appenderRef.stdout.ref = STDOUT ​​​​​ Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.98721,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Java</em>: Configure with <em>Log4j</em> 2.x",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " on the application. Configure <em>logs</em> in <em>context</em> with <em>log</em> <em>management</em> To configure <em>New</em> <em>Relic</em> <em>logs</em> in <em>context</em> with <em>Log</em>4j 2.x: <em>Enable</em> <em>logs</em> <em>management</em> with a compatible <em>log</em> forwarding plugin. Install or update the <em>Java</em> agent. Configure the <em>Log</em>4j 2.x extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em>"
      },
      "id": "603ead8a28ccbc47a2eba74f"
    },
    {
      "sections": [
        "Java: Configure with Logback",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Logback extension",
        "Important",
        "Example configuration files",
        "Single console appender example",
        "Two-appender example",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Logback",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "d43c55efa817768e3840897678b966f896fd268d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-logback/",
      "published_at": "2021-07-02T13:23:38Z",
      "updated_at": "2021-03-16T09:23:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Logback extension for log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Logback, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update Logback 1.2.0 or higher installed and working on the application. Configure logs in context with log management To configure New Relic logs in context with Logback: Enable log management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Logback extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable Distributed tracing. Configure the Logback extension To configure logs in context with the Logback extension, complete the following steps: Update your project's dependencies to include the Logback extension as applicable: To update with Gradle, add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:logback:2.0\") } Copy To update with Maven, add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>logback</artifactId> <version>2.0</version> </dependency> </dependencies> Copy Update your logging configuration xml to replace any existing < encoder> element as shown below. If you are logging to the console (stdout/stderr), look for ConsoleAppender and replace : <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy If you are logging to a file, look for FileAppender and replace <encoder>: <appender name=\"LOG_FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>logs/app-log-file.log</file> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy Update your logging configuration xml with the NewRelicAsyncAppender. To ensure that NewRelicAsyncAppender wraps any appenders that will target New Relic's log forwarder, add the following section. Change \"LOG_FILE\" to the name of the appender you updated in the previous step. <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"LOG_FILE\" /> </appender> Copy Make sure NewRelicAsyncAppender is the appender used in your logger. Replace your root logger’s appenders with the ASYNC appender created in the previous step. <root> <appender-ref ref=\"ASYNC\" /> </root> Copy Important It's important that the NewRelicAsyncAppender be the first appender to see the log message. List any other appenders after the NewRelicAsyncAppender in the <root> list. Example configuration files You can find a working example in GitHub. Here are examples of an updated logging .xml file for the Logback extension. Single console appender example Example configuration file after adding in the logging extension information. <configuration> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <!-- changed the encoder --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- added the ASYNC appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"STDOUT\" /> </appender> <root level=\"debug\"> <!-- changed the root logger --> <appender-ref ref=\"ASYNC\" /> </root> </configuration> Copy Two-appender example This example sends New Relic logging to a file, but still sends standard logging to the console. <configuration> <appender name=\"FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>myApp.log</file> <!-- encoder changed --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- this appender does normal console logging --> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder> <pattern>%msg%n</pattern> </encoder> </appender> <!-- The required New Relic ASYNC appender wraps the FILE appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"FILE\" /> </appender> <root level=\"debug\"> <!-- ASYNC is one of the main appenders --> <appender-ref ref=\"ASYNC\" /> <!-- Send every message to normal console logging, as well. --> <appender-ref ref=\"STDOUT\" /> </root> </configuration> Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.98721,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Java</em>: Configure with <em>Logback</em>",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " To configure <em>New</em> <em>Relic</em> <em>logs</em> in <em>context</em> with Logback: <em>Enable</em> <em>log</em> <em>management</em> with a compatible <em>log</em> forwarding plugin. Install or update the <em>Java</em> agent. Configure the Logback extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em> Confirm that you have <em>log</em> <em>management</em> enabled, with a compatible <em>log</em>"
      },
      "id": "603ead8a196a679235a83d96"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-javautillogging": [
    {
      "sections": [
        "Java: Configure with Log4j 1.x",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Log4j 1.x extension",
        "Example configuration file for the Log4j 1.x extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Log4j 1.x",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "c037c5f99fbe16c9ae129d177d246009df25fb45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-1x/",
      "published_at": "2021-07-02T13:23:38Z",
      "updated_at": "2021-04-16T21:20:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Log4j 1.x extension for New Relic log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Log4j 1.x, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Log4j 1.x package installed and working on the application. log4j must be configured in code or via XML. Properties files are not supported because AsyncAppender instances can only be automatically configured via XML. Configure logs in context with log management To configure logs in context with Logs4j 1.x: Enable log management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Log4j 1.x extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable Distributed tracing. Configure the Log4j 1.x extension To configure logs in context with the Log4j 1.x extension, complete the following steps: Update your project's dependencies to include the Log4j 1.x extension as applicable: To update with Gradle, add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j1:2.0\") } Copy To update with Maven, add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j1</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <appender> element with a NewRelicLayout, adding <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> as shown below: <appender name=\" TypicalFile \" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <layout class=\" com.newrelic.logging.log4j1.NewRelicLayout \"/> <!-- only this line needs to be added --> </appender> Copy Once updated, use NewRelicAsyncAppender to wrap any appenders that will target New Relic's log forwarder. For example: <appender name=\" NewRelicFile \" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\" TypicalFile \" /> </appender> Copy Once updated, use the async appender on the root logger. For example: <root> <appender-ref ref=\" NewRelicFile \" /> </root> Copy Example configuration file for the Log4j 1.x extension <?xml version=\"1.0\" encoding=\"UTF-8\" ?> <!DOCTYPE log4j:configuration SYSTEM \"log4j.dtd\"> <log4j:configuration debug=\"false\"> <appender name=\"TypicalFile\" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <!-- layout has been replaced --> <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> </appender> <!-- this appender was added --> <appender name=\"NewRelicFile\" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\"TypicalFile\" /> </appender> <appender name=\"TypicalConsole\" class=\"org.apache.log4j.ConsoleAppender\"> <layout class=\"org.apache.log4j.PatternLayout\"> <param name=\"ConversionPattern\" value=\"%-5p %c{1} - %m%n\"/> </layout> </appender> <root> ​ <!-- the new appender was used here -->​​ <appender-ref ref=\"NewRelicFile\" /> <appender-ref ref=\"TypicalConsole\" /> </root> </log4j:configuration> Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 236.09816,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Java</em>: Configure with <em>Log4j</em> 1.x",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " <em>log</em> forwarding plugin. Install or update the <em>Java</em> agent. Configure the <em>Log</em>4j 1.x extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em> Confirm that you have <em>log</em> <em>management</em> enabled, with a compatible <em>log</em> forwarding plugin installed to send your application <em>logs</em> to <em>New</em> <em>Relic</em>. Install or update"
      },
      "id": "603ead8b196a675ad7a83dd6"
    },
    {
      "sections": [
        "Java: Configure with Log4j 2.x",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Log4j 2.x extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Log4j 2.x",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "481ea55e236babf6d2ee7f7326db4c27e3dd37a3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-2x/",
      "published_at": "2021-07-02T13:23:38Z",
      "updated_at": "2021-03-16T09:23:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Log4j 2.x extension for log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Log4j 2.x, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Log4j 2.x or Logs4j 2 binding package installed and working on the application. Configure logs in context with log management To configure New Relic logs in context with Log4j 2.x: Enable logs management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Log4j 2.x extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable distributed tracing. Configure the Log4j 2.x extension To configure logs in context with the Log4j 2.x extension, complete the following steps: Update your project's dependencies to include the Log4j 2.x extension as applicable: To update with Gradle, add the highlighted section to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j2:2.0\") } Copy To update with Maven, add the highlighted section to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j2</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <configuration> element by adding the highlighted section: <Configuration xmlns=\"http://logging.apache.org/log4j/2.0/config\" packages=\"com.newrelic.logging.log4j2\" > Copy If you are using a properties file, add packages=com.newrelic.logging.log4j2. Once updated, add <NewRelicLayout/> to use a NewRelicLayout element within one of the appenders. For example: <File name=\"MyFile\" fileName=\"logs/app-log-file.log\"> <NewRelicLayout/> </File> Copy If you are using a properties file, change only the layout.type property, as shown below: appender.console.type = Console appender.console.name = STDOUT appender.console.layout.type = NewRelicLayout Copy If you only modified an existing appender, you can skip this step. Add <AppenderRef/> within <Root> to use this appender. The ref attribute refers to the name of the appender you created in the previous step. For example: <Root level=\"info\"> <AppenderRef ref=\"MyFile\"/> </Root> Copy If you are using a properties file, you will need to add a property if you added a new appender: rootLogger.level = info rootLogger.appenderRef.stdout.ref = STDOUT ​​​​​ Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.98721,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Java</em>: Configure with <em>Log4j</em> 2.x",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " on the application. Configure <em>logs</em> in <em>context</em> with <em>log</em> <em>management</em> To configure <em>New</em> <em>Relic</em> <em>logs</em> in <em>context</em> with <em>Log</em>4j 2.x: <em>Enable</em> <em>logs</em> <em>management</em> with a compatible <em>log</em> forwarding plugin. Install or update the <em>Java</em> agent. Configure the <em>Log</em>4j 2.x extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em>"
      },
      "id": "603ead8a28ccbc47a2eba74f"
    },
    {
      "sections": [
        "Java: Configure with Logback",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Logback extension",
        "Important",
        "Example configuration files",
        "Single console appender example",
        "Two-appender example",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Logback",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "d43c55efa817768e3840897678b966f896fd268d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-logback/",
      "published_at": "2021-07-02T13:23:38Z",
      "updated_at": "2021-03-16T09:23:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Logback extension for log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Logback, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update Logback 1.2.0 or higher installed and working on the application. Configure logs in context with log management To configure New Relic logs in context with Logback: Enable log management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Logback extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable Distributed tracing. Configure the Logback extension To configure logs in context with the Logback extension, complete the following steps: Update your project's dependencies to include the Logback extension as applicable: To update with Gradle, add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:logback:2.0\") } Copy To update with Maven, add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>logback</artifactId> <version>2.0</version> </dependency> </dependencies> Copy Update your logging configuration xml to replace any existing < encoder> element as shown below. If you are logging to the console (stdout/stderr), look for ConsoleAppender and replace : <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy If you are logging to a file, look for FileAppender and replace <encoder>: <appender name=\"LOG_FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>logs/app-log-file.log</file> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy Update your logging configuration xml with the NewRelicAsyncAppender. To ensure that NewRelicAsyncAppender wraps any appenders that will target New Relic's log forwarder, add the following section. Change \"LOG_FILE\" to the name of the appender you updated in the previous step. <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"LOG_FILE\" /> </appender> Copy Make sure NewRelicAsyncAppender is the appender used in your logger. Replace your root logger’s appenders with the ASYNC appender created in the previous step. <root> <appender-ref ref=\"ASYNC\" /> </root> Copy Important It's important that the NewRelicAsyncAppender be the first appender to see the log message. List any other appenders after the NewRelicAsyncAppender in the <root> list. Example configuration files You can find a working example in GitHub. Here are examples of an updated logging .xml file for the Logback extension. Single console appender example Example configuration file after adding in the logging extension information. <configuration> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <!-- changed the encoder --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- added the ASYNC appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"STDOUT\" /> </appender> <root level=\"debug\"> <!-- changed the root logger --> <appender-ref ref=\"ASYNC\" /> </root> </configuration> Copy Two-appender example This example sends New Relic logging to a file, but still sends standard logging to the console. <configuration> <appender name=\"FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>myApp.log</file> <!-- encoder changed --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- this appender does normal console logging --> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder> <pattern>%msg%n</pattern> </encoder> </appender> <!-- The required New Relic ASYNC appender wraps the FILE appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"FILE\" /> </appender> <root level=\"debug\"> <!-- ASYNC is one of the main appenders --> <appender-ref ref=\"ASYNC\" /> <!-- Send every message to normal console logging, as well. --> <appender-ref ref=\"STDOUT\" /> </root> </configuration> Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.98721,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Java</em>: Configure with <em>Logback</em>",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " To configure <em>New</em> <em>Relic</em> <em>logs</em> in <em>context</em> with Logback: <em>Enable</em> <em>log</em> <em>management</em> with a compatible <em>log</em> forwarding plugin. Install or update the <em>Java</em> agent. Configure the Logback extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em> Confirm that you have <em>log</em> <em>management</em> enabled, with a compatible <em>log</em>"
      },
      "id": "603ead8a196a679235a83d96"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-1x": [
    {
      "sections": [
        "Java: Configure with Log4j 2.x",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Log4j 2.x extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Log4j 2.x",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "481ea55e236babf6d2ee7f7326db4c27e3dd37a3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-2x/",
      "published_at": "2021-07-02T13:23:38Z",
      "updated_at": "2021-03-16T09:23:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Log4j 2.x extension for log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Log4j 2.x, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Log4j 2.x or Logs4j 2 binding package installed and working on the application. Configure logs in context with log management To configure New Relic logs in context with Log4j 2.x: Enable logs management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Log4j 2.x extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable distributed tracing. Configure the Log4j 2.x extension To configure logs in context with the Log4j 2.x extension, complete the following steps: Update your project's dependencies to include the Log4j 2.x extension as applicable: To update with Gradle, add the highlighted section to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j2:2.0\") } Copy To update with Maven, add the highlighted section to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j2</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <configuration> element by adding the highlighted section: <Configuration xmlns=\"http://logging.apache.org/log4j/2.0/config\" packages=\"com.newrelic.logging.log4j2\" > Copy If you are using a properties file, add packages=com.newrelic.logging.log4j2. Once updated, add <NewRelicLayout/> to use a NewRelicLayout element within one of the appenders. For example: <File name=\"MyFile\" fileName=\"logs/app-log-file.log\"> <NewRelicLayout/> </File> Copy If you are using a properties file, change only the layout.type property, as shown below: appender.console.type = Console appender.console.name = STDOUT appender.console.layout.type = NewRelicLayout Copy If you only modified an existing appender, you can skip this step. Add <AppenderRef/> within <Root> to use this appender. The ref attribute refers to the name of the appender you created in the previous step. For example: <Root level=\"info\"> <AppenderRef ref=\"MyFile\"/> </Root> Copy If you are using a properties file, you will need to add a property if you added a new appender: rootLogger.level = info rootLogger.appenderRef.stdout.ref = STDOUT ​​​​​ Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.98721,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Java</em>: Configure with <em>Log4j</em> 2.x",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " on the application. Configure <em>logs</em> in <em>context</em> with <em>log</em> <em>management</em> To configure <em>New</em> <em>Relic</em> <em>logs</em> in <em>context</em> with <em>Log</em>4j 2.x: <em>Enable</em> <em>logs</em> <em>management</em> with a compatible <em>log</em> forwarding plugin. Install or update the <em>Java</em> agent. Configure the <em>Log</em>4j 2.x extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em>"
      },
      "id": "603ead8a28ccbc47a2eba74f"
    },
    {
      "sections": [
        "Java: Configure with Logback",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Logback extension",
        "Important",
        "Example configuration files",
        "Single console appender example",
        "Two-appender example",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Logback",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "d43c55efa817768e3840897678b966f896fd268d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-logback/",
      "published_at": "2021-07-02T13:23:38Z",
      "updated_at": "2021-03-16T09:23:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Logback extension for log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Logback, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update Logback 1.2.0 or higher installed and working on the application. Configure logs in context with log management To configure New Relic logs in context with Logback: Enable log management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Logback extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable Distributed tracing. Configure the Logback extension To configure logs in context with the Logback extension, complete the following steps: Update your project's dependencies to include the Logback extension as applicable: To update with Gradle, add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:logback:2.0\") } Copy To update with Maven, add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>logback</artifactId> <version>2.0</version> </dependency> </dependencies> Copy Update your logging configuration xml to replace any existing < encoder> element as shown below. If you are logging to the console (stdout/stderr), look for ConsoleAppender and replace : <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy If you are logging to a file, look for FileAppender and replace <encoder>: <appender name=\"LOG_FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>logs/app-log-file.log</file> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy Update your logging configuration xml with the NewRelicAsyncAppender. To ensure that NewRelicAsyncAppender wraps any appenders that will target New Relic's log forwarder, add the following section. Change \"LOG_FILE\" to the name of the appender you updated in the previous step. <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"LOG_FILE\" /> </appender> Copy Make sure NewRelicAsyncAppender is the appender used in your logger. Replace your root logger’s appenders with the ASYNC appender created in the previous step. <root> <appender-ref ref=\"ASYNC\" /> </root> Copy Important It's important that the NewRelicAsyncAppender be the first appender to see the log message. List any other appenders after the NewRelicAsyncAppender in the <root> list. Example configuration files You can find a working example in GitHub. Here are examples of an updated logging .xml file for the Logback extension. Single console appender example Example configuration file after adding in the logging extension information. <configuration> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <!-- changed the encoder --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- added the ASYNC appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"STDOUT\" /> </appender> <root level=\"debug\"> <!-- changed the root logger --> <appender-ref ref=\"ASYNC\" /> </root> </configuration> Copy Two-appender example This example sends New Relic logging to a file, but still sends standard logging to the console. <configuration> <appender name=\"FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>myApp.log</file> <!-- encoder changed --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- this appender does normal console logging --> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder> <pattern>%msg%n</pattern> </encoder> </appender> <!-- The required New Relic ASYNC appender wraps the FILE appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"FILE\" /> </appender> <root level=\"debug\"> <!-- ASYNC is one of the main appenders --> <appender-ref ref=\"ASYNC\" /> <!-- Send every message to normal console logging, as well. --> <appender-ref ref=\"STDOUT\" /> </root> </configuration> Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.98721,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Java</em>: Configure with <em>Logback</em>",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " To configure <em>New</em> <em>Relic</em> <em>logs</em> in <em>context</em> with Logback: <em>Enable</em> <em>log</em> <em>management</em> with a compatible <em>log</em> forwarding plugin. Install or update the <em>Java</em> agent. Configure the Logback extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em> Confirm that you have <em>log</em> <em>management</em> enabled, with a compatible <em>log</em>"
      },
      "id": "603ead8a196a679235a83d96"
    },
    {
      "sections": [
        "Configure logs in context for Java",
        "Compatibility and requirements",
        "What's next?"
      ],
      "title": "Configure logs in context for Java",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "204d0cbbece1c5640142f9213a4930fc91c6b3f6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/configure-logs-context-java/",
      "published_at": "2021-07-02T13:21:16Z",
      "updated_at": "2021-03-16T09:21:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the Java agent connects your logs and APM data in New Relic, giving full context to high-level events and providing high value data to specific log lines. Read on to learn how to configure logs in context and enrich your log data. Compatibility and requirements To use log management with the Java agent, ensure your configuration meets the following requirements: Log management enabled, with a compatible log forwarding plugin installed Java agent 5.6.0 or higher: Install or update Configure logs in context for Java Choose an extension to see specific instructions: Dropwizard v1.3 extension java.util.logging extension Logback extension Log4j 1.x extension Log4j 2.x extension Use Spring or Spring Boot and not sure which extension you need? See our Spring documentation. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.98706,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure <em>logs</em> <em>in</em> <em>context</em> <em>for</em> <em>Java</em>",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> <em>for</em> <em>Java</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the <em>Java</em> agent connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>, giving full <em>context</em> to high-level events and providing high value data to specific <em>log</em> lines. Read on to learn how to configure <em>logs</em> in <em>context</em> and enrich your <em>log</em> data. Compatibility and requirements To use <em>log</em>"
      },
      "id": "603ea6bc196a676505a83df0"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-2x": [
    {
      "sections": [
        "Java: Configure with Log4j 1.x",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Log4j 1.x extension",
        "Example configuration file for the Log4j 1.x extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Log4j 1.x",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "c037c5f99fbe16c9ae129d177d246009df25fb45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-1x/",
      "published_at": "2021-07-02T13:23:38Z",
      "updated_at": "2021-04-16T21:20:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Log4j 1.x extension for New Relic log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Log4j 1.x, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Log4j 1.x package installed and working on the application. log4j must be configured in code or via XML. Properties files are not supported because AsyncAppender instances can only be automatically configured via XML. Configure logs in context with log management To configure logs in context with Logs4j 1.x: Enable log management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Log4j 1.x extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable Distributed tracing. Configure the Log4j 1.x extension To configure logs in context with the Log4j 1.x extension, complete the following steps: Update your project's dependencies to include the Log4j 1.x extension as applicable: To update with Gradle, add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j1:2.0\") } Copy To update with Maven, add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j1</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <appender> element with a NewRelicLayout, adding <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> as shown below: <appender name=\" TypicalFile \" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <layout class=\" com.newrelic.logging.log4j1.NewRelicLayout \"/> <!-- only this line needs to be added --> </appender> Copy Once updated, use NewRelicAsyncAppender to wrap any appenders that will target New Relic's log forwarder. For example: <appender name=\" NewRelicFile \" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\" TypicalFile \" /> </appender> Copy Once updated, use the async appender on the root logger. For example: <root> <appender-ref ref=\" NewRelicFile \" /> </root> Copy Example configuration file for the Log4j 1.x extension <?xml version=\"1.0\" encoding=\"UTF-8\" ?> <!DOCTYPE log4j:configuration SYSTEM \"log4j.dtd\"> <log4j:configuration debug=\"false\"> <appender name=\"TypicalFile\" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <!-- layout has been replaced --> <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> </appender> <!-- this appender was added --> <appender name=\"NewRelicFile\" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\"TypicalFile\" /> </appender> <appender name=\"TypicalConsole\" class=\"org.apache.log4j.ConsoleAppender\"> <layout class=\"org.apache.log4j.PatternLayout\"> <param name=\"ConversionPattern\" value=\"%-5p %c{1} - %m%n\"/> </layout> </appender> <root> ​ <!-- the new appender was used here -->​​ <appender-ref ref=\"NewRelicFile\" /> <appender-ref ref=\"TypicalConsole\" /> </root> </log4j:configuration> Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 236.09816,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Java</em>: Configure with <em>Log4j</em> 1.x",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " <em>log</em> forwarding plugin. Install or update the <em>Java</em> agent. Configure the <em>Log</em>4j 1.x extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em> Confirm that you have <em>log</em> <em>management</em> enabled, with a compatible <em>log</em> forwarding plugin installed to send your application <em>logs</em> to <em>New</em> <em>Relic</em>. Install or update"
      },
      "id": "603ead8b196a675ad7a83dd6"
    },
    {
      "sections": [
        "Java: Configure with Logback",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Logback extension",
        "Important",
        "Example configuration files",
        "Single console appender example",
        "Two-appender example",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Logback",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "d43c55efa817768e3840897678b966f896fd268d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-logback/",
      "published_at": "2021-07-02T13:23:38Z",
      "updated_at": "2021-03-16T09:23:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Logback extension for log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Logback, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update Logback 1.2.0 or higher installed and working on the application. Configure logs in context with log management To configure New Relic logs in context with Logback: Enable log management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Logback extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable Distributed tracing. Configure the Logback extension To configure logs in context with the Logback extension, complete the following steps: Update your project's dependencies to include the Logback extension as applicable: To update with Gradle, add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:logback:2.0\") } Copy To update with Maven, add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>logback</artifactId> <version>2.0</version> </dependency> </dependencies> Copy Update your logging configuration xml to replace any existing < encoder> element as shown below. If you are logging to the console (stdout/stderr), look for ConsoleAppender and replace : <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy If you are logging to a file, look for FileAppender and replace <encoder>: <appender name=\"LOG_FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>logs/app-log-file.log</file> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy Update your logging configuration xml with the NewRelicAsyncAppender. To ensure that NewRelicAsyncAppender wraps any appenders that will target New Relic's log forwarder, add the following section. Change \"LOG_FILE\" to the name of the appender you updated in the previous step. <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"LOG_FILE\" /> </appender> Copy Make sure NewRelicAsyncAppender is the appender used in your logger. Replace your root logger’s appenders with the ASYNC appender created in the previous step. <root> <appender-ref ref=\"ASYNC\" /> </root> Copy Important It's important that the NewRelicAsyncAppender be the first appender to see the log message. List any other appenders after the NewRelicAsyncAppender in the <root> list. Example configuration files You can find a working example in GitHub. Here are examples of an updated logging .xml file for the Logback extension. Single console appender example Example configuration file after adding in the logging extension information. <configuration> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <!-- changed the encoder --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- added the ASYNC appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"STDOUT\" /> </appender> <root level=\"debug\"> <!-- changed the root logger --> <appender-ref ref=\"ASYNC\" /> </root> </configuration> Copy Two-appender example This example sends New Relic logging to a file, but still sends standard logging to the console. <configuration> <appender name=\"FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>myApp.log</file> <!-- encoder changed --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- this appender does normal console logging --> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder> <pattern>%msg%n</pattern> </encoder> </appender> <!-- The required New Relic ASYNC appender wraps the FILE appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"FILE\" /> </appender> <root level=\"debug\"> <!-- ASYNC is one of the main appenders --> <appender-ref ref=\"ASYNC\" /> <!-- Send every message to normal console logging, as well. --> <appender-ref ref=\"STDOUT\" /> </root> </configuration> Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.98721,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Java</em>: Configure with <em>Logback</em>",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " To configure <em>New</em> <em>Relic</em> <em>logs</em> in <em>context</em> with Logback: <em>Enable</em> <em>log</em> <em>management</em> with a compatible <em>log</em> forwarding plugin. Install or update the <em>Java</em> agent. Configure the Logback extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em> Confirm that you have <em>log</em> <em>management</em> enabled, with a compatible <em>log</em>"
      },
      "id": "603ead8a196a679235a83d96"
    },
    {
      "sections": [
        "Configure logs in context for Java",
        "Compatibility and requirements",
        "What's next?"
      ],
      "title": "Configure logs in context for Java",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "204d0cbbece1c5640142f9213a4930fc91c6b3f6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/configure-logs-context-java/",
      "published_at": "2021-07-02T13:21:16Z",
      "updated_at": "2021-03-16T09:21:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the Java agent connects your logs and APM data in New Relic, giving full context to high-level events and providing high value data to specific log lines. Read on to learn how to configure logs in context and enrich your log data. Compatibility and requirements To use log management with the Java agent, ensure your configuration meets the following requirements: Log management enabled, with a compatible log forwarding plugin installed Java agent 5.6.0 or higher: Install or update Configure logs in context for Java Choose an extension to see specific instructions: Dropwizard v1.3 extension java.util.logging extension Logback extension Log4j 1.x extension Log4j 2.x extension Use Spring or Spring Boot and not sure which extension you need? See our Spring documentation. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.98706,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure <em>logs</em> <em>in</em> <em>context</em> <em>for</em> <em>Java</em>",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> <em>for</em> <em>Java</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the <em>Java</em> agent connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>, giving full <em>context</em> to high-level events and providing high value data to specific <em>log</em> lines. Read on to learn how to configure <em>logs</em> in <em>context</em> and enrich your <em>log</em> data. Compatibility and requirements To use <em>log</em>"
      },
      "id": "603ea6bc196a676505a83df0"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-logback": [
    {
      "sections": [
        "Java: Configure with Log4j 1.x",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Log4j 1.x extension",
        "Example configuration file for the Log4j 1.x extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Log4j 1.x",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "c037c5f99fbe16c9ae129d177d246009df25fb45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-1x/",
      "published_at": "2021-07-02T13:23:38Z",
      "updated_at": "2021-04-16T21:20:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Log4j 1.x extension for New Relic log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Log4j 1.x, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Log4j 1.x package installed and working on the application. log4j must be configured in code or via XML. Properties files are not supported because AsyncAppender instances can only be automatically configured via XML. Configure logs in context with log management To configure logs in context with Logs4j 1.x: Enable log management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Log4j 1.x extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable Distributed tracing. Configure the Log4j 1.x extension To configure logs in context with the Log4j 1.x extension, complete the following steps: Update your project's dependencies to include the Log4j 1.x extension as applicable: To update with Gradle, add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j1:2.0\") } Copy To update with Maven, add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j1</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <appender> element with a NewRelicLayout, adding <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> as shown below: <appender name=\" TypicalFile \" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <layout class=\" com.newrelic.logging.log4j1.NewRelicLayout \"/> <!-- only this line needs to be added --> </appender> Copy Once updated, use NewRelicAsyncAppender to wrap any appenders that will target New Relic's log forwarder. For example: <appender name=\" NewRelicFile \" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\" TypicalFile \" /> </appender> Copy Once updated, use the async appender on the root logger. For example: <root> <appender-ref ref=\" NewRelicFile \" /> </root> Copy Example configuration file for the Log4j 1.x extension <?xml version=\"1.0\" encoding=\"UTF-8\" ?> <!DOCTYPE log4j:configuration SYSTEM \"log4j.dtd\"> <log4j:configuration debug=\"false\"> <appender name=\"TypicalFile\" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <!-- layout has been replaced --> <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> </appender> <!-- this appender was added --> <appender name=\"NewRelicFile\" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\"TypicalFile\" /> </appender> <appender name=\"TypicalConsole\" class=\"org.apache.log4j.ConsoleAppender\"> <layout class=\"org.apache.log4j.PatternLayout\"> <param name=\"ConversionPattern\" value=\"%-5p %c{1} - %m%n\"/> </layout> </appender> <root> ​ <!-- the new appender was used here -->​​ <appender-ref ref=\"NewRelicFile\" /> <appender-ref ref=\"TypicalConsole\" /> </root> </log4j:configuration> Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 236.09816,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Java</em>: Configure with <em>Log4j</em> 1.x",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " <em>log</em> forwarding plugin. Install or update the <em>Java</em> agent. Configure the <em>Log</em>4j 1.x extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em> Confirm that you have <em>log</em> <em>management</em> enabled, with a compatible <em>log</em> forwarding plugin installed to send your application <em>logs</em> to <em>New</em> <em>Relic</em>. Install or update"
      },
      "id": "603ead8b196a675ad7a83dd6"
    },
    {
      "sections": [
        "Java: Configure with Log4j 2.x",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Log4j 2.x extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Log4j 2.x",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "481ea55e236babf6d2ee7f7326db4c27e3dd37a3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-2x/",
      "published_at": "2021-07-02T13:23:38Z",
      "updated_at": "2021-03-16T09:23:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Log4j 2.x extension for log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Log4j 2.x, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Log4j 2.x or Logs4j 2 binding package installed and working on the application. Configure logs in context with log management To configure New Relic logs in context with Log4j 2.x: Enable logs management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Log4j 2.x extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable distributed tracing. Configure the Log4j 2.x extension To configure logs in context with the Log4j 2.x extension, complete the following steps: Update your project's dependencies to include the Log4j 2.x extension as applicable: To update with Gradle, add the highlighted section to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j2:2.0\") } Copy To update with Maven, add the highlighted section to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j2</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <configuration> element by adding the highlighted section: <Configuration xmlns=\"http://logging.apache.org/log4j/2.0/config\" packages=\"com.newrelic.logging.log4j2\" > Copy If you are using a properties file, add packages=com.newrelic.logging.log4j2. Once updated, add <NewRelicLayout/> to use a NewRelicLayout element within one of the appenders. For example: <File name=\"MyFile\" fileName=\"logs/app-log-file.log\"> <NewRelicLayout/> </File> Copy If you are using a properties file, change only the layout.type property, as shown below: appender.console.type = Console appender.console.name = STDOUT appender.console.layout.type = NewRelicLayout Copy If you only modified an existing appender, you can skip this step. Add <AppenderRef/> within <Root> to use this appender. The ref attribute refers to the name of the appender you created in the previous step. For example: <Root level=\"info\"> <AppenderRef ref=\"MyFile\"/> </Root> Copy If you are using a properties file, you will need to add a property if you added a new appender: rootLogger.level = info rootLogger.appenderRef.stdout.ref = STDOUT ​​​​​ Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.98721,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Java</em>: Configure with <em>Log4j</em> 2.x",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " on the application. Configure <em>logs</em> in <em>context</em> with <em>log</em> <em>management</em> To configure <em>New</em> <em>Relic</em> <em>logs</em> in <em>context</em> with <em>Log</em>4j 2.x: <em>Enable</em> <em>logs</em> <em>management</em> with a compatible <em>log</em> forwarding plugin. Install or update the <em>Java</em> agent. Configure the <em>Log</em>4j 2.x extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em>"
      },
      "id": "603ead8a28ccbc47a2eba74f"
    },
    {
      "sections": [
        "Configure logs in context for Java",
        "Compatibility and requirements",
        "What's next?"
      ],
      "title": "Configure logs in context for Java",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "204d0cbbece1c5640142f9213a4930fc91c6b3f6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/configure-logs-context-java/",
      "published_at": "2021-07-02T13:21:16Z",
      "updated_at": "2021-03-16T09:21:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the Java agent connects your logs and APM data in New Relic, giving full context to high-level events and providing high value data to specific log lines. Read on to learn how to configure logs in context and enrich your log data. Compatibility and requirements To use log management with the Java agent, ensure your configuration meets the following requirements: Log management enabled, with a compatible log forwarding plugin installed Java agent 5.6.0 or higher: Install or update Configure logs in context for Java Choose an extension to see specific instructions: Dropwizard v1.3 extension java.util.logging extension Logback extension Log4j 1.x extension Log4j 2.x extension Use Spring or Spring Boot and not sure which extension you need? See our Spring documentation. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.98706,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure <em>logs</em> <em>in</em> <em>context</em> <em>for</em> <em>Java</em>",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> <em>for</em> <em>Java</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the <em>Java</em> agent connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>, giving full <em>context</em> to high-level events and providing high value data to specific <em>log</em> lines. Read on to learn how to configure <em>logs</em> in <em>context</em> and enrich your <em>log</em> data. Compatibility and requirements To use <em>log</em>"
      },
      "id": "603ea6bc196a676505a83df0"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-spring-spring-boot": [
    {
      "sections": [
        "Java: Configure with Log4j 1.x",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Log4j 1.x extension",
        "Example configuration file for the Log4j 1.x extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Log4j 1.x",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "c037c5f99fbe16c9ae129d177d246009df25fb45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-1x/",
      "published_at": "2021-07-02T13:23:38Z",
      "updated_at": "2021-04-16T21:20:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Log4j 1.x extension for New Relic log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Log4j 1.x, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Log4j 1.x package installed and working on the application. log4j must be configured in code or via XML. Properties files are not supported because AsyncAppender instances can only be automatically configured via XML. Configure logs in context with log management To configure logs in context with Logs4j 1.x: Enable log management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Log4j 1.x extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable Distributed tracing. Configure the Log4j 1.x extension To configure logs in context with the Log4j 1.x extension, complete the following steps: Update your project's dependencies to include the Log4j 1.x extension as applicable: To update with Gradle, add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j1:2.0\") } Copy To update with Maven, add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j1</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <appender> element with a NewRelicLayout, adding <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> as shown below: <appender name=\" TypicalFile \" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <layout class=\" com.newrelic.logging.log4j1.NewRelicLayout \"/> <!-- only this line needs to be added --> </appender> Copy Once updated, use NewRelicAsyncAppender to wrap any appenders that will target New Relic's log forwarder. For example: <appender name=\" NewRelicFile \" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\" TypicalFile \" /> </appender> Copy Once updated, use the async appender on the root logger. For example: <root> <appender-ref ref=\" NewRelicFile \" /> </root> Copy Example configuration file for the Log4j 1.x extension <?xml version=\"1.0\" encoding=\"UTF-8\" ?> <!DOCTYPE log4j:configuration SYSTEM \"log4j.dtd\"> <log4j:configuration debug=\"false\"> <appender name=\"TypicalFile\" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <!-- layout has been replaced --> <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> </appender> <!-- this appender was added --> <appender name=\"NewRelicFile\" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\"TypicalFile\" /> </appender> <appender name=\"TypicalConsole\" class=\"org.apache.log4j.ConsoleAppender\"> <layout class=\"org.apache.log4j.PatternLayout\"> <param name=\"ConversionPattern\" value=\"%-5p %c{1} - %m%n\"/> </layout> </appender> <root> ​ <!-- the new appender was used here -->​​ <appender-ref ref=\"NewRelicFile\" /> <appender-ref ref=\"TypicalConsole\" /> </root> </log4j:configuration> Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 236.09816,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Java</em>: Configure with <em>Log4j</em> 1.x",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " <em>log</em> forwarding plugin. Install or update the <em>Java</em> agent. Configure the <em>Log</em>4j 1.x extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em> Confirm that you have <em>log</em> <em>management</em> enabled, with a compatible <em>log</em> forwarding plugin installed to send your application <em>logs</em> to <em>New</em> <em>Relic</em>. Install or update"
      },
      "id": "603ead8b196a675ad7a83dd6"
    },
    {
      "sections": [
        "Java: Configure with Log4j 2.x",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Log4j 2.x extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Log4j 2.x",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "481ea55e236babf6d2ee7f7326db4c27e3dd37a3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-2x/",
      "published_at": "2021-07-02T13:23:38Z",
      "updated_at": "2021-03-16T09:23:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Log4j 2.x extension for log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Log4j 2.x, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Log4j 2.x or Logs4j 2 binding package installed and working on the application. Configure logs in context with log management To configure New Relic logs in context with Log4j 2.x: Enable logs management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Log4j 2.x extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable distributed tracing. Configure the Log4j 2.x extension To configure logs in context with the Log4j 2.x extension, complete the following steps: Update your project's dependencies to include the Log4j 2.x extension as applicable: To update with Gradle, add the highlighted section to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j2:2.0\") } Copy To update with Maven, add the highlighted section to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j2</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <configuration> element by adding the highlighted section: <Configuration xmlns=\"http://logging.apache.org/log4j/2.0/config\" packages=\"com.newrelic.logging.log4j2\" > Copy If you are using a properties file, add packages=com.newrelic.logging.log4j2. Once updated, add <NewRelicLayout/> to use a NewRelicLayout element within one of the appenders. For example: <File name=\"MyFile\" fileName=\"logs/app-log-file.log\"> <NewRelicLayout/> </File> Copy If you are using a properties file, change only the layout.type property, as shown below: appender.console.type = Console appender.console.name = STDOUT appender.console.layout.type = NewRelicLayout Copy If you only modified an existing appender, you can skip this step. Add <AppenderRef/> within <Root> to use this appender. The ref attribute refers to the name of the appender you created in the previous step. For example: <Root level=\"info\"> <AppenderRef ref=\"MyFile\"/> </Root> Copy If you are using a properties file, you will need to add a property if you added a new appender: rootLogger.level = info rootLogger.appenderRef.stdout.ref = STDOUT ​​​​​ Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.98721,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Java</em>: Configure with <em>Log4j</em> 2.x",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " on the application. Configure <em>logs</em> in <em>context</em> with <em>log</em> <em>management</em> To configure <em>New</em> <em>Relic</em> <em>logs</em> in <em>context</em> with <em>Log</em>4j 2.x: <em>Enable</em> <em>logs</em> <em>management</em> with a compatible <em>log</em> forwarding plugin. Install or update the <em>Java</em> agent. Configure the <em>Log</em>4j 2.x extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em>"
      },
      "id": "603ead8a28ccbc47a2eba74f"
    },
    {
      "sections": [
        "Java: Configure with Logback",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Logback extension",
        "Important",
        "Example configuration files",
        "Single console appender example",
        "Two-appender example",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Logback",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "d43c55efa817768e3840897678b966f896fd268d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-logback/",
      "published_at": "2021-07-02T13:23:38Z",
      "updated_at": "2021-03-16T09:23:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Logback extension for log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Logback, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update Logback 1.2.0 or higher installed and working on the application. Configure logs in context with log management To configure New Relic logs in context with Logback: Enable log management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Logback extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable Distributed tracing. Configure the Logback extension To configure logs in context with the Logback extension, complete the following steps: Update your project's dependencies to include the Logback extension as applicable: To update with Gradle, add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:logback:2.0\") } Copy To update with Maven, add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>logback</artifactId> <version>2.0</version> </dependency> </dependencies> Copy Update your logging configuration xml to replace any existing < encoder> element as shown below. If you are logging to the console (stdout/stderr), look for ConsoleAppender and replace : <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy If you are logging to a file, look for FileAppender and replace <encoder>: <appender name=\"LOG_FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>logs/app-log-file.log</file> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy Update your logging configuration xml with the NewRelicAsyncAppender. To ensure that NewRelicAsyncAppender wraps any appenders that will target New Relic's log forwarder, add the following section. Change \"LOG_FILE\" to the name of the appender you updated in the previous step. <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"LOG_FILE\" /> </appender> Copy Make sure NewRelicAsyncAppender is the appender used in your logger. Replace your root logger’s appenders with the ASYNC appender created in the previous step. <root> <appender-ref ref=\"ASYNC\" /> </root> Copy Important It's important that the NewRelicAsyncAppender be the first appender to see the log message. List any other appenders after the NewRelicAsyncAppender in the <root> list. Example configuration files You can find a working example in GitHub. Here are examples of an updated logging .xml file for the Logback extension. Single console appender example Example configuration file after adding in the logging extension information. <configuration> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <!-- changed the encoder --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- added the ASYNC appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"STDOUT\" /> </appender> <root level=\"debug\"> <!-- changed the root logger --> <appender-ref ref=\"ASYNC\" /> </root> </configuration> Copy Two-appender example This example sends New Relic logging to a file, but still sends standard logging to the console. <configuration> <appender name=\"FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>myApp.log</file> <!-- encoder changed --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- this appender does normal console logging --> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder> <pattern>%msg%n</pattern> </encoder> </appender> <!-- The required New Relic ASYNC appender wraps the FILE appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"FILE\" /> </appender> <root level=\"debug\"> <!-- ASYNC is one of the main appenders --> <appender-ref ref=\"ASYNC\" /> <!-- Send every message to normal console logging, as well. --> <appender-ref ref=\"STDOUT\" /> </root> </configuration> Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.98721,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Java</em>: Configure with <em>Logback</em>",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " To configure <em>New</em> <em>Relic</em> <em>logs</em> in <em>context</em> with Logback: <em>Enable</em> <em>log</em> <em>management</em> with a compatible <em>log</em> forwarding plugin. Install or update the <em>Java</em> agent. Configure the Logback extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em> Confirm that you have <em>log</em> <em>management</em> enabled, with a compatible <em>log</em>"
      },
      "id": "603ead8a196a679235a83d96"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/logs-context-net/configure-logs-context-net": [
    {
      "sections": [
        ".NET: Configure with Serilog",
        "Compatibility and requirements",
        "Overview",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the .NET agent",
        "Configure the Serilog extension",
        "Caution",
        "Important",
        "File-based configuration",
        "appsettings.json based configuration",
        ".Config based configuration",
        "What's next?"
      ],
      "title": ".NET: Configure with Serilog",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for .NET"
      ],
      "external_id": "f3d5ac2ad158b199811541f699cb3c1a8139aa3b",
      "image": "https://docs.newrelic.com/static/783ba8b8cb8b25e4c8ee8aecf0464395/29d31/LogsInContext---Serilog-%25282%2529_0.jpg",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-net/net-configure-serilog/",
      "published_at": "2021-07-02T13:26:54Z",
      "updated_at": "2021-03-13T03:17:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Serilog extension to link to your log data with related data across the rest of the New Relic platform. Read on to learn how to configure logs in context and enrich your log data. Compatibility and requirements To use New Relic logs in context with Serilog, ensure your configuration meets the following requirements: Microsoft .NET Framework 4.5+ or .NET Core 2.0+ New Relic .NET agent 8.21+ New Relic .NET agent API 8.21+ Serilog 2.5+ Serilog File Sinks v4.0+ Overview Serilog is a structured logging framework that records log messages from your application and creates a LogEvent to store the message data. Using Enrichers, you can add additional information to the log events, while Sinks and Formatters allow you to format and output those log events for downstream consumption and viewing. This diagram illustrates the flow of log messages through Serilog. This diagram illustrates the flow of log messages through Serilog, highlighting specific components of the New Relic Serilog extension. The above diagram highlights several components of the Serilog extension: New Relic Enricher: The NewRelicEnricher adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. New Relic Formatter: The NewRelicFormattertranslates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the Log Forwarder expects. New Relic Log Forwarder: The NewRelicFormattertranslates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the log forwarder expects. The example below uses the New Relic Fluentd log forwarded, however there are many other log forwarders that can be used. For more information, see Introduction to log management. For more information about Serilog log events, see the Serilog Getting started documentation. Configure logs in context with log management To configure New Relic logs in context with Serilog: Enable log management with a compatible log forwarding plugin. Install or update the .NET agent. Configure the Serilog extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the .NET agent Install or update to the most recent .NET agent version, and enable Distributed tracing. Configure the Serilog extension To configure logs in context with the Serilog extension, complete the following steps: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.Serilog package. In your application code, update your logging configuration to add the NewRelicEnricher and NewRelicFormatter. The following code example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\SerilogExample.log.json for consumption by the Log Forwarder: var loggerConfig = new LoggerConfiguration() loggerConfig .Enrich.WithThreadName() .Enrich.WithThreadId() .Enrich.WithNewRelicLogsInContext() .WriteTo.File( path: @\"C:\\logs\\ExistingLoggingOutput.txt\") .WriteTo.File( formatter: new NewRelicFormatter(), path: @\"C:\\logs\\SerilogExample.log.json\"); var log = loggerConfig.CreateLogger(); Copy Caution The above configuration results in new JSON files that are written to disk. Some of these configuration options may be useful in managing the amount of disk space used and/or the performance of the sink. restrictedToMinimumLevel buffered rollingInterval rollOnFileSizeLimit retainedFileCountLimit Important Though not required, using the Serilog Asynchronous Sink Wrapper may help improve the performance by performing formatting and output of log files on a different thread. Once you have configured the Serilog extension and updated your logging file, you can configure your extension to send data to New Relic Logs. See below for an example of this configuration using the Fluentd plugin for New Relic Logs: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\SerilogExample.log.json pos_file C:\\logs\\SerilogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy File-based configuration Configuration of the New Relic Logs Serilog extension may also be accomplished with file-based configuration providers. appsettings.json based configuration The example code below creates a logger based on settings contained in an appSettings.json file. Important The following additional NuGet Packages are required: Microsoft.Extensions.Configuration Serilog.Settings.Configuration Instantiating Logger using appsettings.json var builder = new ConfigurationBuilder() .AddJsonFile(\"appsettings.json\"); var configuration = builder.Build(); var logger = new LoggerConfiguration() .ReadFrom.Configuration(configuration) .CreateLogger(); Copy Sample appsettings.json file { \"Serilog\": { \"Using\": [ \"Serilog.Sinks.Console\", \"Serilog.Sinks.File\", \"NewRelic.LogEnrichers.Serilog\" ], \"MinimumLevel\": \"Debug\", \"Enrich\": [ \"WithNewRelicLogsInContext\" ], \"WriteTo\": [ { \"Name\": \"File\", \"Args\": { \"path\": \"C:\\\\Logs\\\\SerilogExample.log.json\", \"formatter\": \"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" } } ], \"Properties\": { \"Application\": \"NewRelic Logging Serilog Example\" } } } Copy .Config based configuration The example code below creates a logger based on settings contained in an web.config file. Important The Serilog.Settings.AppSettings NuGet Package is required. Instantiating Logger using .config file var logger = new LoggerConfiguration() .ReadFrom.AppSettings() .CreateLogger(); Copy Sample web.config file <?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <appSettings> <add key=\"serilog:using:NewRelic\" value=\"NewRelic.LogEnrichers.Serilog\" /> <add key=\"serilog:using:File\" value=\"Serilog.Sinks.File\" /> <!--Add other enrichers here--> <add key=\"serilog:enrich:WithNewRelicLogsInContext\" /> <add key=\"serilog:write-to:File.path\" value=\"C:\\logs\\SerilogExample.log.json\" /> <add key=\"serilog:write-to:File.formatter\" value=\"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" /> </appSettings> Copy What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 248.84961,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".<em>NET</em>: Configure with Serilog",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " documentation. Configure <em>logs</em> in <em>context</em> with <em>log</em> <em>management</em> To configure <em>New</em> <em>Relic</em> <em>logs</em> in <em>context</em> with Serilog: <em>Enable</em> <em>log</em> <em>management</em> with a compatible <em>log</em> forwarding plugin. Install or update the .<em>NET</em> agent. Configure the Serilog extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em> Confirm"
      },
      "id": "60450d33e7b9d2773f5799c7"
    },
    {
      "sections": [
        ".NET: Configure with NLog",
        "Compatibility and requirements",
        "Overview",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the .NET agent",
        "Configure the NLog extension",
        "Caution",
        "Important",
        "File-based configuration",
        ".Config based configuration",
        "What's next?"
      ],
      "title": ".NET: Configure with NLog",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for .NET"
      ],
      "external_id": "4320e73b1b248d30e66c1e4ce701a733256cc19d",
      "image": "https://docs.newrelic.com/static/82029cf4cbc1cf0a2eb07844326dd8bb/29d31/LogsInContext---NLog.jpg",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-net/net-configure-nlog/",
      "published_at": "2021-07-02T13:25:38Z",
      "updated_at": "2021-03-13T01:59:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our NLog extension to link to your log data with related data across the rest of the New Relic platform. Read on to learn how to configure logs in context and enrich your log data. Compatibility and requirements To use New Relic logs in context with NLog, ensure your configuration meets the following requirements: Microsoft .NET Framework 4.5+ or .NET Core 2.0+ New Relic .NET agent 8.21+ New Relic .NET agent API 8.21+ NLog 4.5+ Overview NLog works by having Layouts (which guide what data is added to log events and in what format) and Targets (which control where logging data is sent.) The New Relic NLog extension provides a NewRelicJsonLayout which formats a log event in the way required by the New Relic logging endpoint, and adds contextual information from the .NET agent when attached to your application. A target can then be configured to write logging data to an output folder, which can be monitored by a log forwarder to incrementally send log information to New Relic. This diagram illustrates the flow of log messages through NLog: This diagram illustrates the flow of log messages through NLog, highlighting specific components of the New Relic NLog extension. The above diagram highlights the main components of the NLog Logs-in-Context solution: New Relic JSON Layout: The NewRelicJsonLayout adds contextual information from the .NET agent (using the API) to the log events generated by the application, and outputs log messages in the JSON format expected by New Relic. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. File Target: A FileTarget defines a file on disk where log messages will be written. Adding the NewRelicJsonLayout to that target will cause the output to be formatted correctly for forwarding to New Relic. New Relic Log Forwarder: The log forwarder is configured to send the log data from the FileTarget's output to New Relic. The example below uses the New Relic Fluentd log forwarder, however there are many other log forwarders that can be used. For more information, see Introduction to log management. For more information about logging with NLog, see the NLog Getting started documentation. Configure logs in context with log management To configure logs in context with NLog: Enable log management with a compatible log forwarding plugin. Install or update the .NET agent. Configure the NLog extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the .NET agent Install or update to the most recent .NET agent version, and enable Distributed tracing. Configure the NLog extension To configure logs in context with the NLog extension, complete the following steps: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.NLog package. In your application code, update your logging configuration to add the NewRelicJsonLayout. The following code example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the Log Forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); newRelicFileTarget.Layout = new NewRelicJsonLayout(); newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Caution The above configuration results in new JSON files that are written to disk. Some of these configuration options may be useful in managing the amount of disk space used and/or the performance of the target. archiveAboveSize maxArchiveFiles bufferSize enableArchiveFileCompression autoFlush concurrentWrites Important Though not required, using the NLog AsyncWrapper Target may help improve the performance by performing formatting and output of log files on a different thread. Once you have configured the NLog extension and updated your logging file, you can configure your extension to send data to New Relic. See below for an example of this configuration using the Fluentd plugin for New Relic's log management: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\NLogExample.log.json pos_file C:\\logs\\NLogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy File-based configuration Configuration of the New Relic NLog extension may also be accomplished with file based configuration providers. .Config based configuration The example code below creates a logger based on settings contained in an App.config file. Instantiating Logger using .config file var logger = LogManager.GetLogger(\"NewRelicLog\"); logger.Info(\"Hello, New Relic!\"); Copy Sample App.config file <?xml version=\"1.0\" encoding=\"utf-8\" ?> <configuration> <configSections> <section name=\"nlog\" type=\"NLog.Config.ConfigSectionHandler, NLog\"/> </configSections> <startup> <supportedRuntime version=\"v4.0\" sku=\".NETFramework,Version=v4.5\" /> </startup> <nlog xmlns=\"http://www.nlog-project.org/schemas/NLog.xsd\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <extensions> <add assembly=\"NewRelic.LogEnrichers.NLog\" /> </extensions> <targets> <target name=\"NewRelicLogFile\" xsi:type=\"File\" fileName=\"C:/path/to/NewRelicLog.json\"> <layout xsi:type=\"newrelic-jsonlayout\"> </layout> </target> </targets> <rules> <logger name=\"NewRelicLog\" minlevel=\"Info\" writeTo=\"newRelicLogFile\" /> </rules> </nlog> </configuration> Copy What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 248.8404,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".<em>NET</em>: Configure with NLog",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " plugin. Install or update the .<em>NET</em> agent. Configure the NLog extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em> Confirm that you have <em>log</em> <em>management</em> enabled, with a compatible <em>log</em> forwarding plugin installed to send your application <em>logs</em> to <em>New</em> <em>Relic</em>. Install or update the .<em>NET</em> agent Install"
      },
      "id": "60450d32196a67923c960f6f"
    },
    {
      "sections": [
        ".NET: Configure with log4net",
        "Compatibility and requirements",
        "Overview",
        "Configure logs in context with New Relic Logs",
        "Enable New Relic Logs",
        "Install or update the .NET agent",
        "Configure the log4net extension",
        "What's next?"
      ],
      "title": ".NET: Configure with log4net",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for .NET"
      ],
      "external_id": "ccffdaabc7111e7bd5a13239e1d9c927d26a4bd1",
      "image": "https://docs.newrelic.com/static/90e8518fffeb7d9cc28f58f29fe749a5/e5166/LogsInContext---Log4Net.jpg",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-net/net-configure-log4net/",
      "published_at": "2021-07-02T13:25:38Z",
      "updated_at": "2021-03-13T01:10:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Apache log4net extension to link to your log data with related data across the rest of the New Relic platform. Read on to learn how to configure logs in context and enrich your log data. Compatibility and requirements To use New Relic logs in context with log4net, ensure your configuration meets the following requirements: Microsoft .NET Framework 4.5+ or .NET Core 2.0+ New Relic .NET agent 8.21+ New Relic .NET agent API 8.21+ Log4net 2.0.8+ Overview Log4net uses appender and layout to store and format log messages. NewRelicAppender enriches log messages with contextual information from the New Relic .NET agent if it is attached to your application. The appender passes enriched log messages to downstream appenders for specific use case log message handle. Log4net also provides NewRelicLayout to output log messages in the way required by the New Relic logging endpoint. A target can then be configured to write logging data to an output folder, which can be monitored by a log forwarder to incrementally send log information to New Relic. This diagram illustrates the flow of log messages through log4net: This diagram illustrates the flow of log messages through log4net, highlighting specific components of the New Relic log4net extension. The above diagram highlights the main components of the log4net logs in context solution: New Relic Appender: The NewRelicAppender adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. This appender will pass the enriched Log Events to downstream appenders for further processing. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain and requires another appender that can write to an actual output destination as its child in order to work. New Relic Layout: The NewRelicLayout formats the enriched log events into the JSON format expected by New Relic. The appender, which this layout is assigned to, instructs log4net to output the JSON to a file in the location that the log forwarder expects. New Relic Log Forwarder: The log forwarder monitors an output folder and incrementally sends New Relic formatted Log information to the New Relic Logging Endpoint. There are many log-forwarders available. For our examples, we will use Fluentd. For more information about logging with log4net, see the Apache log4net Getting started documentation. Configure logs in context with New Relic Logs To configure New Relic logs in context with Enable New Relic Logs with a compatible log forwarding plugin. Install or update the .NET agent. Configure the log4net extension. Check for logging data. Enable New Relic Logs Confirm that you have New Relic Logs enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the .NET agent Install or update to the most recent .NET agent version, and enable Distributed tracing. Configure the log4net extension To configure logs in context with the log4net extension, complete the following steps: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.Log4Net package. In your log4net configuration file, update your logging configuration to use the NewRelicAppender as the first level appender, and reference your existing appenders as its children. You also need to replace the layout of the appender that writes log messages to an output destination with the NewRelicLayout . The following log4net configuration example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\log4netExample.log.json for consumption by the log forwarder: <log4net> <root> <level value=\"ALL\" /> <appender-ref ref=\"NewRelicAppender\" /> </root> <appender name=\"NewRelicAppender\" type=\"NewRelic.LogEnrichers.Log4Net.NewRelicAppender, NewRelic.LogEnrichers.Log4Net\" > <threshold value=\"ALL\"/> <appender-ref ref=\"FileAppender\" /> </appender> <appender name=\"FileAppender\" type=\"log4net.Appender.FileAppender\"> <file value=\"C:\\logs\\log4netExample.log.json\" /> <param name=\"AppendToFile\" value=\"true\" /> <layout type=\"NewRelic.LogEnrichers.Log4Net.NewRelicLayout, NewRelic.LogEnrichers.Log4Net\"> </layout> </appender> </log4net> Copy Once you have configured the log4net extension and updated your logging file, you can configure your extension to send data to New Relic Logs. See below for an example of this configuration using the Fluentd plugin for New Relic Logs: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\log4netExample.log.json pos_file C:\\logs\\log4netExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 248.83461,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".<em>NET</em>: Configure with <em>log4net</em>",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>New</em> <em>Relic</em> <em>Logs</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": ". There are many <em>log</em>-forwarders available. For our examples, we will use Fluentd. For more information about logging with <em>log4net</em>, see the Apache <em>log4net</em> Getting started documentation. Configure <em>logs</em> in <em>context</em> with <em>New</em> <em>Relic</em> <em>Logs</em> To configure <em>New</em> <em>Relic</em> <em>logs</em> in <em>context</em> with <em>Enable</em> <em>New</em> <em>Relic</em> <em>Logs</em>"
      },
      "id": "60450d7164441f0d80378f09"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/logs-context-net/net-configure-log4net": [
    {
      "sections": [
        "Configure logs in context for .NET",
        "Compatibility and requirements",
        "What's next?"
      ],
      "title": "Configure logs in context for .NET",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for .NET"
      ],
      "external_id": "777ae1eb11df98af5d4ed37061399ff4bca00889",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-net/configure-logs-context-net/",
      "published_at": "2021-07-02T13:24:42Z",
      "updated_at": "2021-03-16T09:23:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the .NET agent connects your Logs and APM data in New Relic, giving full context to high-level events and providing high value data to specific log lines. Read on to learn how to configure logs in context and enrich log data. Compatibility and requirements To use New Relic Logs with the .NET agent, ensure your configuration meets the following requirements: Log management enabled, with a compatible log forwarding plugin installed New Relic .NET agent 8.21+ New Relic .NET agent API 8.21+ Microsoft .NET Framework 4.5+ or .NET Core 2.0+ Configure logs in context for .NET Choose a extension to see specific instructions: log4net NLog Serilog What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.42033,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure <em>logs</em> <em>in</em> <em>context</em> <em>for</em> .<em>NET</em>",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> <em>for</em> .<em>NET</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " with the .<em>NET</em> agent, ensure your configuration meets the following requirements: <em>Log</em> <em>management</em> enabled, with a compatible <em>log</em> forwarding plugin installed <em>New</em> <em>Relic</em> .<em>NET</em> agent 8.21+ <em>New</em> <em>Relic</em> .<em>NET</em> agent API 8.21+ Microsoft .<em>NET</em> Framework 4.5+ or .<em>NET</em> Core 2.0+ Configure <em>logs</em> in <em>context</em> for .<em>NET</em>"
      },
      "id": "603e7f60196a67185ea83d81"
    },
    {
      "sections": [
        ".NET: Configure with Serilog",
        "Compatibility and requirements",
        "Overview",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the .NET agent",
        "Configure the Serilog extension",
        "Caution",
        "Important",
        "File-based configuration",
        "appsettings.json based configuration",
        ".Config based configuration",
        "What's next?"
      ],
      "title": ".NET: Configure with Serilog",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for .NET"
      ],
      "external_id": "f3d5ac2ad158b199811541f699cb3c1a8139aa3b",
      "image": "https://docs.newrelic.com/static/783ba8b8cb8b25e4c8ee8aecf0464395/29d31/LogsInContext---Serilog-%25282%2529_0.jpg",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-net/net-configure-serilog/",
      "published_at": "2021-07-02T13:26:54Z",
      "updated_at": "2021-03-13T03:17:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Serilog extension to link to your log data with related data across the rest of the New Relic platform. Read on to learn how to configure logs in context and enrich your log data. Compatibility and requirements To use New Relic logs in context with Serilog, ensure your configuration meets the following requirements: Microsoft .NET Framework 4.5+ or .NET Core 2.0+ New Relic .NET agent 8.21+ New Relic .NET agent API 8.21+ Serilog 2.5+ Serilog File Sinks v4.0+ Overview Serilog is a structured logging framework that records log messages from your application and creates a LogEvent to store the message data. Using Enrichers, you can add additional information to the log events, while Sinks and Formatters allow you to format and output those log events for downstream consumption and viewing. This diagram illustrates the flow of log messages through Serilog. This diagram illustrates the flow of log messages through Serilog, highlighting specific components of the New Relic Serilog extension. The above diagram highlights several components of the Serilog extension: New Relic Enricher: The NewRelicEnricher adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. New Relic Formatter: The NewRelicFormattertranslates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the Log Forwarder expects. New Relic Log Forwarder: The NewRelicFormattertranslates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the log forwarder expects. The example below uses the New Relic Fluentd log forwarded, however there are many other log forwarders that can be used. For more information, see Introduction to log management. For more information about Serilog log events, see the Serilog Getting started documentation. Configure logs in context with log management To configure New Relic logs in context with Serilog: Enable log management with a compatible log forwarding plugin. Install or update the .NET agent. Configure the Serilog extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the .NET agent Install or update to the most recent .NET agent version, and enable Distributed tracing. Configure the Serilog extension To configure logs in context with the Serilog extension, complete the following steps: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.Serilog package. In your application code, update your logging configuration to add the NewRelicEnricher and NewRelicFormatter. The following code example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\SerilogExample.log.json for consumption by the Log Forwarder: var loggerConfig = new LoggerConfiguration() loggerConfig .Enrich.WithThreadName() .Enrich.WithThreadId() .Enrich.WithNewRelicLogsInContext() .WriteTo.File( path: @\"C:\\logs\\ExistingLoggingOutput.txt\") .WriteTo.File( formatter: new NewRelicFormatter(), path: @\"C:\\logs\\SerilogExample.log.json\"); var log = loggerConfig.CreateLogger(); Copy Caution The above configuration results in new JSON files that are written to disk. Some of these configuration options may be useful in managing the amount of disk space used and/or the performance of the sink. restrictedToMinimumLevel buffered rollingInterval rollOnFileSizeLimit retainedFileCountLimit Important Though not required, using the Serilog Asynchronous Sink Wrapper may help improve the performance by performing formatting and output of log files on a different thread. Once you have configured the Serilog extension and updated your logging file, you can configure your extension to send data to New Relic Logs. See below for an example of this configuration using the Fluentd plugin for New Relic Logs: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\SerilogExample.log.json pos_file C:\\logs\\SerilogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy File-based configuration Configuration of the New Relic Logs Serilog extension may also be accomplished with file-based configuration providers. appsettings.json based configuration The example code below creates a logger based on settings contained in an appSettings.json file. Important The following additional NuGet Packages are required: Microsoft.Extensions.Configuration Serilog.Settings.Configuration Instantiating Logger using appsettings.json var builder = new ConfigurationBuilder() .AddJsonFile(\"appsettings.json\"); var configuration = builder.Build(); var logger = new LoggerConfiguration() .ReadFrom.Configuration(configuration) .CreateLogger(); Copy Sample appsettings.json file { \"Serilog\": { \"Using\": [ \"Serilog.Sinks.Console\", \"Serilog.Sinks.File\", \"NewRelic.LogEnrichers.Serilog\" ], \"MinimumLevel\": \"Debug\", \"Enrich\": [ \"WithNewRelicLogsInContext\" ], \"WriteTo\": [ { \"Name\": \"File\", \"Args\": { \"path\": \"C:\\\\Logs\\\\SerilogExample.log.json\", \"formatter\": \"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" } } ], \"Properties\": { \"Application\": \"NewRelic Logging Serilog Example\" } } } Copy .Config based configuration The example code below creates a logger based on settings contained in an web.config file. Important The Serilog.Settings.AppSettings NuGet Package is required. Instantiating Logger using .config file var logger = new LoggerConfiguration() .ReadFrom.AppSettings() .CreateLogger(); Copy Sample web.config file <?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <appSettings> <add key=\"serilog:using:NewRelic\" value=\"NewRelic.LogEnrichers.Serilog\" /> <add key=\"serilog:using:File\" value=\"Serilog.Sinks.File\" /> <!--Add other enrichers here--> <add key=\"serilog:enrich:WithNewRelicLogsInContext\" /> <add key=\"serilog:write-to:File.path\" value=\"C:\\logs\\SerilogExample.log.json\" /> <add key=\"serilog:write-to:File.formatter\" value=\"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" /> </appSettings> Copy What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 248.84961,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".<em>NET</em>: Configure with Serilog",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " documentation. Configure <em>logs</em> in <em>context</em> with <em>log</em> <em>management</em> To configure <em>New</em> <em>Relic</em> <em>logs</em> in <em>context</em> with Serilog: <em>Enable</em> <em>log</em> <em>management</em> with a compatible <em>log</em> forwarding plugin. Install or update the .<em>NET</em> agent. Configure the Serilog extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em> Confirm"
      },
      "id": "60450d33e7b9d2773f5799c7"
    },
    {
      "sections": [
        ".NET: Configure with NLog",
        "Compatibility and requirements",
        "Overview",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the .NET agent",
        "Configure the NLog extension",
        "Caution",
        "Important",
        "File-based configuration",
        ".Config based configuration",
        "What's next?"
      ],
      "title": ".NET: Configure with NLog",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for .NET"
      ],
      "external_id": "4320e73b1b248d30e66c1e4ce701a733256cc19d",
      "image": "https://docs.newrelic.com/static/82029cf4cbc1cf0a2eb07844326dd8bb/29d31/LogsInContext---NLog.jpg",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-net/net-configure-nlog/",
      "published_at": "2021-07-02T13:25:38Z",
      "updated_at": "2021-03-13T01:59:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our NLog extension to link to your log data with related data across the rest of the New Relic platform. Read on to learn how to configure logs in context and enrich your log data. Compatibility and requirements To use New Relic logs in context with NLog, ensure your configuration meets the following requirements: Microsoft .NET Framework 4.5+ or .NET Core 2.0+ New Relic .NET agent 8.21+ New Relic .NET agent API 8.21+ NLog 4.5+ Overview NLog works by having Layouts (which guide what data is added to log events and in what format) and Targets (which control where logging data is sent.) The New Relic NLog extension provides a NewRelicJsonLayout which formats a log event in the way required by the New Relic logging endpoint, and adds contextual information from the .NET agent when attached to your application. A target can then be configured to write logging data to an output folder, which can be monitored by a log forwarder to incrementally send log information to New Relic. This diagram illustrates the flow of log messages through NLog: This diagram illustrates the flow of log messages through NLog, highlighting specific components of the New Relic NLog extension. The above diagram highlights the main components of the NLog Logs-in-Context solution: New Relic JSON Layout: The NewRelicJsonLayout adds contextual information from the .NET agent (using the API) to the log events generated by the application, and outputs log messages in the JSON format expected by New Relic. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. File Target: A FileTarget defines a file on disk where log messages will be written. Adding the NewRelicJsonLayout to that target will cause the output to be formatted correctly for forwarding to New Relic. New Relic Log Forwarder: The log forwarder is configured to send the log data from the FileTarget's output to New Relic. The example below uses the New Relic Fluentd log forwarder, however there are many other log forwarders that can be used. For more information, see Introduction to log management. For more information about logging with NLog, see the NLog Getting started documentation. Configure logs in context with log management To configure logs in context with NLog: Enable log management with a compatible log forwarding plugin. Install or update the .NET agent. Configure the NLog extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the .NET agent Install or update to the most recent .NET agent version, and enable Distributed tracing. Configure the NLog extension To configure logs in context with the NLog extension, complete the following steps: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.NLog package. In your application code, update your logging configuration to add the NewRelicJsonLayout. The following code example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the Log Forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); newRelicFileTarget.Layout = new NewRelicJsonLayout(); newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Caution The above configuration results in new JSON files that are written to disk. Some of these configuration options may be useful in managing the amount of disk space used and/or the performance of the target. archiveAboveSize maxArchiveFiles bufferSize enableArchiveFileCompression autoFlush concurrentWrites Important Though not required, using the NLog AsyncWrapper Target may help improve the performance by performing formatting and output of log files on a different thread. Once you have configured the NLog extension and updated your logging file, you can configure your extension to send data to New Relic. See below for an example of this configuration using the Fluentd plugin for New Relic's log management: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\NLogExample.log.json pos_file C:\\logs\\NLogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy File-based configuration Configuration of the New Relic NLog extension may also be accomplished with file based configuration providers. .Config based configuration The example code below creates a logger based on settings contained in an App.config file. Instantiating Logger using .config file var logger = LogManager.GetLogger(\"NewRelicLog\"); logger.Info(\"Hello, New Relic!\"); Copy Sample App.config file <?xml version=\"1.0\" encoding=\"utf-8\" ?> <configuration> <configSections> <section name=\"nlog\" type=\"NLog.Config.ConfigSectionHandler, NLog\"/> </configSections> <startup> <supportedRuntime version=\"v4.0\" sku=\".NETFramework,Version=v4.5\" /> </startup> <nlog xmlns=\"http://www.nlog-project.org/schemas/NLog.xsd\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <extensions> <add assembly=\"NewRelic.LogEnrichers.NLog\" /> </extensions> <targets> <target name=\"NewRelicLogFile\" xsi:type=\"File\" fileName=\"C:/path/to/NewRelicLog.json\"> <layout xsi:type=\"newrelic-jsonlayout\"> </layout> </target> </targets> <rules> <logger name=\"NewRelicLog\" minlevel=\"Info\" writeTo=\"newRelicLogFile\" /> </rules> </nlog> </configuration> Copy What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 248.8404,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".<em>NET</em>: Configure with NLog",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " plugin. Install or update the .<em>NET</em> agent. Configure the NLog extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em> Confirm that you have <em>log</em> <em>management</em> enabled, with a compatible <em>log</em> forwarding plugin installed to send your application <em>logs</em> to <em>New</em> <em>Relic</em>. Install or update the .<em>NET</em> agent Install"
      },
      "id": "60450d32196a67923c960f6f"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/logs-context-net/net-configure-nlog": [
    {
      "sections": [
        "Configure logs in context for .NET",
        "Compatibility and requirements",
        "What's next?"
      ],
      "title": "Configure logs in context for .NET",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for .NET"
      ],
      "external_id": "777ae1eb11df98af5d4ed37061399ff4bca00889",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-net/configure-logs-context-net/",
      "published_at": "2021-07-02T13:24:42Z",
      "updated_at": "2021-03-16T09:23:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the .NET agent connects your Logs and APM data in New Relic, giving full context to high-level events and providing high value data to specific log lines. Read on to learn how to configure logs in context and enrich log data. Compatibility and requirements To use New Relic Logs with the .NET agent, ensure your configuration meets the following requirements: Log management enabled, with a compatible log forwarding plugin installed New Relic .NET agent 8.21+ New Relic .NET agent API 8.21+ Microsoft .NET Framework 4.5+ or .NET Core 2.0+ Configure logs in context for .NET Choose a extension to see specific instructions: log4net NLog Serilog What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.42033,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure <em>logs</em> <em>in</em> <em>context</em> <em>for</em> .<em>NET</em>",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> <em>for</em> .<em>NET</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " with the .<em>NET</em> agent, ensure your configuration meets the following requirements: <em>Log</em> <em>management</em> enabled, with a compatible <em>log</em> forwarding plugin installed <em>New</em> <em>Relic</em> .<em>NET</em> agent 8.21+ <em>New</em> <em>Relic</em> .<em>NET</em> agent API 8.21+ Microsoft .<em>NET</em> Framework 4.5+ or .<em>NET</em> Core 2.0+ Configure <em>logs</em> in <em>context</em> for .<em>NET</em>"
      },
      "id": "603e7f60196a67185ea83d81"
    },
    {
      "sections": [
        ".NET: Configure with Serilog",
        "Compatibility and requirements",
        "Overview",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the .NET agent",
        "Configure the Serilog extension",
        "Caution",
        "Important",
        "File-based configuration",
        "appsettings.json based configuration",
        ".Config based configuration",
        "What's next?"
      ],
      "title": ".NET: Configure with Serilog",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for .NET"
      ],
      "external_id": "f3d5ac2ad158b199811541f699cb3c1a8139aa3b",
      "image": "https://docs.newrelic.com/static/783ba8b8cb8b25e4c8ee8aecf0464395/29d31/LogsInContext---Serilog-%25282%2529_0.jpg",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-net/net-configure-serilog/",
      "published_at": "2021-07-02T13:26:54Z",
      "updated_at": "2021-03-13T03:17:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Serilog extension to link to your log data with related data across the rest of the New Relic platform. Read on to learn how to configure logs in context and enrich your log data. Compatibility and requirements To use New Relic logs in context with Serilog, ensure your configuration meets the following requirements: Microsoft .NET Framework 4.5+ or .NET Core 2.0+ New Relic .NET agent 8.21+ New Relic .NET agent API 8.21+ Serilog 2.5+ Serilog File Sinks v4.0+ Overview Serilog is a structured logging framework that records log messages from your application and creates a LogEvent to store the message data. Using Enrichers, you can add additional information to the log events, while Sinks and Formatters allow you to format and output those log events for downstream consumption and viewing. This diagram illustrates the flow of log messages through Serilog. This diagram illustrates the flow of log messages through Serilog, highlighting specific components of the New Relic Serilog extension. The above diagram highlights several components of the Serilog extension: New Relic Enricher: The NewRelicEnricher adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. New Relic Formatter: The NewRelicFormattertranslates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the Log Forwarder expects. New Relic Log Forwarder: The NewRelicFormattertranslates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the log forwarder expects. The example below uses the New Relic Fluentd log forwarded, however there are many other log forwarders that can be used. For more information, see Introduction to log management. For more information about Serilog log events, see the Serilog Getting started documentation. Configure logs in context with log management To configure New Relic logs in context with Serilog: Enable log management with a compatible log forwarding plugin. Install or update the .NET agent. Configure the Serilog extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the .NET agent Install or update to the most recent .NET agent version, and enable Distributed tracing. Configure the Serilog extension To configure logs in context with the Serilog extension, complete the following steps: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.Serilog package. In your application code, update your logging configuration to add the NewRelicEnricher and NewRelicFormatter. The following code example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\SerilogExample.log.json for consumption by the Log Forwarder: var loggerConfig = new LoggerConfiguration() loggerConfig .Enrich.WithThreadName() .Enrich.WithThreadId() .Enrich.WithNewRelicLogsInContext() .WriteTo.File( path: @\"C:\\logs\\ExistingLoggingOutput.txt\") .WriteTo.File( formatter: new NewRelicFormatter(), path: @\"C:\\logs\\SerilogExample.log.json\"); var log = loggerConfig.CreateLogger(); Copy Caution The above configuration results in new JSON files that are written to disk. Some of these configuration options may be useful in managing the amount of disk space used and/or the performance of the sink. restrictedToMinimumLevel buffered rollingInterval rollOnFileSizeLimit retainedFileCountLimit Important Though not required, using the Serilog Asynchronous Sink Wrapper may help improve the performance by performing formatting and output of log files on a different thread. Once you have configured the Serilog extension and updated your logging file, you can configure your extension to send data to New Relic Logs. See below for an example of this configuration using the Fluentd plugin for New Relic Logs: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\SerilogExample.log.json pos_file C:\\logs\\SerilogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy File-based configuration Configuration of the New Relic Logs Serilog extension may also be accomplished with file-based configuration providers. appsettings.json based configuration The example code below creates a logger based on settings contained in an appSettings.json file. Important The following additional NuGet Packages are required: Microsoft.Extensions.Configuration Serilog.Settings.Configuration Instantiating Logger using appsettings.json var builder = new ConfigurationBuilder() .AddJsonFile(\"appsettings.json\"); var configuration = builder.Build(); var logger = new LoggerConfiguration() .ReadFrom.Configuration(configuration) .CreateLogger(); Copy Sample appsettings.json file { \"Serilog\": { \"Using\": [ \"Serilog.Sinks.Console\", \"Serilog.Sinks.File\", \"NewRelic.LogEnrichers.Serilog\" ], \"MinimumLevel\": \"Debug\", \"Enrich\": [ \"WithNewRelicLogsInContext\" ], \"WriteTo\": [ { \"Name\": \"File\", \"Args\": { \"path\": \"C:\\\\Logs\\\\SerilogExample.log.json\", \"formatter\": \"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" } } ], \"Properties\": { \"Application\": \"NewRelic Logging Serilog Example\" } } } Copy .Config based configuration The example code below creates a logger based on settings contained in an web.config file. Important The Serilog.Settings.AppSettings NuGet Package is required. Instantiating Logger using .config file var logger = new LoggerConfiguration() .ReadFrom.AppSettings() .CreateLogger(); Copy Sample web.config file <?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <appSettings> <add key=\"serilog:using:NewRelic\" value=\"NewRelic.LogEnrichers.Serilog\" /> <add key=\"serilog:using:File\" value=\"Serilog.Sinks.File\" /> <!--Add other enrichers here--> <add key=\"serilog:enrich:WithNewRelicLogsInContext\" /> <add key=\"serilog:write-to:File.path\" value=\"C:\\logs\\SerilogExample.log.json\" /> <add key=\"serilog:write-to:File.formatter\" value=\"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" /> </appSettings> Copy What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 248.84961,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".<em>NET</em>: Configure with Serilog",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " documentation. Configure <em>logs</em> in <em>context</em> with <em>log</em> <em>management</em> To configure <em>New</em> <em>Relic</em> <em>logs</em> in <em>context</em> with Serilog: <em>Enable</em> <em>log</em> <em>management</em> with a compatible <em>log</em> forwarding plugin. Install or update the .<em>NET</em> agent. Configure the Serilog extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em> Confirm"
      },
      "id": "60450d33e7b9d2773f5799c7"
    },
    {
      "sections": [
        ".NET: Configure with log4net",
        "Compatibility and requirements",
        "Overview",
        "Configure logs in context with New Relic Logs",
        "Enable New Relic Logs",
        "Install or update the .NET agent",
        "Configure the log4net extension",
        "What's next?"
      ],
      "title": ".NET: Configure with log4net",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for .NET"
      ],
      "external_id": "ccffdaabc7111e7bd5a13239e1d9c927d26a4bd1",
      "image": "https://docs.newrelic.com/static/90e8518fffeb7d9cc28f58f29fe749a5/e5166/LogsInContext---Log4Net.jpg",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-net/net-configure-log4net/",
      "published_at": "2021-07-02T13:25:38Z",
      "updated_at": "2021-03-13T01:10:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Apache log4net extension to link to your log data with related data across the rest of the New Relic platform. Read on to learn how to configure logs in context and enrich your log data. Compatibility and requirements To use New Relic logs in context with log4net, ensure your configuration meets the following requirements: Microsoft .NET Framework 4.5+ or .NET Core 2.0+ New Relic .NET agent 8.21+ New Relic .NET agent API 8.21+ Log4net 2.0.8+ Overview Log4net uses appender and layout to store and format log messages. NewRelicAppender enriches log messages with contextual information from the New Relic .NET agent if it is attached to your application. The appender passes enriched log messages to downstream appenders for specific use case log message handle. Log4net also provides NewRelicLayout to output log messages in the way required by the New Relic logging endpoint. A target can then be configured to write logging data to an output folder, which can be monitored by a log forwarder to incrementally send log information to New Relic. This diagram illustrates the flow of log messages through log4net: This diagram illustrates the flow of log messages through log4net, highlighting specific components of the New Relic log4net extension. The above diagram highlights the main components of the log4net logs in context solution: New Relic Appender: The NewRelicAppender adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. This appender will pass the enriched Log Events to downstream appenders for further processing. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain and requires another appender that can write to an actual output destination as its child in order to work. New Relic Layout: The NewRelicLayout formats the enriched log events into the JSON format expected by New Relic. The appender, which this layout is assigned to, instructs log4net to output the JSON to a file in the location that the log forwarder expects. New Relic Log Forwarder: The log forwarder monitors an output folder and incrementally sends New Relic formatted Log information to the New Relic Logging Endpoint. There are many log-forwarders available. For our examples, we will use Fluentd. For more information about logging with log4net, see the Apache log4net Getting started documentation. Configure logs in context with New Relic Logs To configure New Relic logs in context with Enable New Relic Logs with a compatible log forwarding plugin. Install or update the .NET agent. Configure the log4net extension. Check for logging data. Enable New Relic Logs Confirm that you have New Relic Logs enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the .NET agent Install or update to the most recent .NET agent version, and enable Distributed tracing. Configure the log4net extension To configure logs in context with the log4net extension, complete the following steps: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.Log4Net package. In your log4net configuration file, update your logging configuration to use the NewRelicAppender as the first level appender, and reference your existing appenders as its children. You also need to replace the layout of the appender that writes log messages to an output destination with the NewRelicLayout . The following log4net configuration example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\log4netExample.log.json for consumption by the log forwarder: <log4net> <root> <level value=\"ALL\" /> <appender-ref ref=\"NewRelicAppender\" /> </root> <appender name=\"NewRelicAppender\" type=\"NewRelic.LogEnrichers.Log4Net.NewRelicAppender, NewRelic.LogEnrichers.Log4Net\" > <threshold value=\"ALL\"/> <appender-ref ref=\"FileAppender\" /> </appender> <appender name=\"FileAppender\" type=\"log4net.Appender.FileAppender\"> <file value=\"C:\\logs\\log4netExample.log.json\" /> <param name=\"AppendToFile\" value=\"true\" /> <layout type=\"NewRelic.LogEnrichers.Log4Net.NewRelicLayout, NewRelic.LogEnrichers.Log4Net\"> </layout> </appender> </log4net> Copy Once you have configured the log4net extension and updated your logging file, you can configure your extension to send data to New Relic Logs. See below for an example of this configuration using the Fluentd plugin for New Relic Logs: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\log4netExample.log.json pos_file C:\\logs\\log4netExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 248.83461,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".<em>NET</em>: Configure with <em>log4net</em>",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>New</em> <em>Relic</em> <em>Logs</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": ". There are many <em>log</em>-forwarders available. For our examples, we will use Fluentd. For more information about logging with <em>log4net</em>, see the Apache <em>log4net</em> Getting started documentation. Configure <em>logs</em> in <em>context</em> with <em>New</em> <em>Relic</em> <em>Logs</em> To configure <em>New</em> <em>Relic</em> <em>logs</em> in <em>context</em> with <em>Enable</em> <em>New</em> <em>Relic</em> <em>Logs</em>"
      },
      "id": "60450d7164441f0d80378f09"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/logs-context-net/net-configure-serilog": [
    {
      "sections": [
        "Configure logs in context for .NET",
        "Compatibility and requirements",
        "What's next?"
      ],
      "title": "Configure logs in context for .NET",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for .NET"
      ],
      "external_id": "777ae1eb11df98af5d4ed37061399ff4bca00889",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-net/configure-logs-context-net/",
      "published_at": "2021-07-02T13:24:42Z",
      "updated_at": "2021-03-16T09:23:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the .NET agent connects your Logs and APM data in New Relic, giving full context to high-level events and providing high value data to specific log lines. Read on to learn how to configure logs in context and enrich log data. Compatibility and requirements To use New Relic Logs with the .NET agent, ensure your configuration meets the following requirements: Log management enabled, with a compatible log forwarding plugin installed New Relic .NET agent 8.21+ New Relic .NET agent API 8.21+ Microsoft .NET Framework 4.5+ or .NET Core 2.0+ Configure logs in context for .NET Choose a extension to see specific instructions: log4net NLog Serilog What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.42033,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure <em>logs</em> <em>in</em> <em>context</em> <em>for</em> .<em>NET</em>",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> <em>for</em> .<em>NET</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " with the .<em>NET</em> agent, ensure your configuration meets the following requirements: <em>Log</em> <em>management</em> enabled, with a compatible <em>log</em> forwarding plugin installed <em>New</em> <em>Relic</em> .<em>NET</em> agent 8.21+ <em>New</em> <em>Relic</em> .<em>NET</em> agent API 8.21+ Microsoft .<em>NET</em> Framework 4.5+ or .<em>NET</em> Core 2.0+ Configure <em>logs</em> in <em>context</em> for .<em>NET</em>"
      },
      "id": "603e7f60196a67185ea83d81"
    },
    {
      "sections": [
        ".NET: Configure with NLog",
        "Compatibility and requirements",
        "Overview",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the .NET agent",
        "Configure the NLog extension",
        "Caution",
        "Important",
        "File-based configuration",
        ".Config based configuration",
        "What's next?"
      ],
      "title": ".NET: Configure with NLog",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for .NET"
      ],
      "external_id": "4320e73b1b248d30e66c1e4ce701a733256cc19d",
      "image": "https://docs.newrelic.com/static/82029cf4cbc1cf0a2eb07844326dd8bb/29d31/LogsInContext---NLog.jpg",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-net/net-configure-nlog/",
      "published_at": "2021-07-02T13:25:38Z",
      "updated_at": "2021-03-13T01:59:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our NLog extension to link to your log data with related data across the rest of the New Relic platform. Read on to learn how to configure logs in context and enrich your log data. Compatibility and requirements To use New Relic logs in context with NLog, ensure your configuration meets the following requirements: Microsoft .NET Framework 4.5+ or .NET Core 2.0+ New Relic .NET agent 8.21+ New Relic .NET agent API 8.21+ NLog 4.5+ Overview NLog works by having Layouts (which guide what data is added to log events and in what format) and Targets (which control where logging data is sent.) The New Relic NLog extension provides a NewRelicJsonLayout which formats a log event in the way required by the New Relic logging endpoint, and adds contextual information from the .NET agent when attached to your application. A target can then be configured to write logging data to an output folder, which can be monitored by a log forwarder to incrementally send log information to New Relic. This diagram illustrates the flow of log messages through NLog: This diagram illustrates the flow of log messages through NLog, highlighting specific components of the New Relic NLog extension. The above diagram highlights the main components of the NLog Logs-in-Context solution: New Relic JSON Layout: The NewRelicJsonLayout adds contextual information from the .NET agent (using the API) to the log events generated by the application, and outputs log messages in the JSON format expected by New Relic. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. File Target: A FileTarget defines a file on disk where log messages will be written. Adding the NewRelicJsonLayout to that target will cause the output to be formatted correctly for forwarding to New Relic. New Relic Log Forwarder: The log forwarder is configured to send the log data from the FileTarget's output to New Relic. The example below uses the New Relic Fluentd log forwarder, however there are many other log forwarders that can be used. For more information, see Introduction to log management. For more information about logging with NLog, see the NLog Getting started documentation. Configure logs in context with log management To configure logs in context with NLog: Enable log management with a compatible log forwarding plugin. Install or update the .NET agent. Configure the NLog extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the .NET agent Install or update to the most recent .NET agent version, and enable Distributed tracing. Configure the NLog extension To configure logs in context with the NLog extension, complete the following steps: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.NLog package. In your application code, update your logging configuration to add the NewRelicJsonLayout. The following code example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the Log Forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); newRelicFileTarget.Layout = new NewRelicJsonLayout(); newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Caution The above configuration results in new JSON files that are written to disk. Some of these configuration options may be useful in managing the amount of disk space used and/or the performance of the target. archiveAboveSize maxArchiveFiles bufferSize enableArchiveFileCompression autoFlush concurrentWrites Important Though not required, using the NLog AsyncWrapper Target may help improve the performance by performing formatting and output of log files on a different thread. Once you have configured the NLog extension and updated your logging file, you can configure your extension to send data to New Relic. See below for an example of this configuration using the Fluentd plugin for New Relic's log management: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\NLogExample.log.json pos_file C:\\logs\\NLogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy File-based configuration Configuration of the New Relic NLog extension may also be accomplished with file based configuration providers. .Config based configuration The example code below creates a logger based on settings contained in an App.config file. Instantiating Logger using .config file var logger = LogManager.GetLogger(\"NewRelicLog\"); logger.Info(\"Hello, New Relic!\"); Copy Sample App.config file <?xml version=\"1.0\" encoding=\"utf-8\" ?> <configuration> <configSections> <section name=\"nlog\" type=\"NLog.Config.ConfigSectionHandler, NLog\"/> </configSections> <startup> <supportedRuntime version=\"v4.0\" sku=\".NETFramework,Version=v4.5\" /> </startup> <nlog xmlns=\"http://www.nlog-project.org/schemas/NLog.xsd\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <extensions> <add assembly=\"NewRelic.LogEnrichers.NLog\" /> </extensions> <targets> <target name=\"NewRelicLogFile\" xsi:type=\"File\" fileName=\"C:/path/to/NewRelicLog.json\"> <layout xsi:type=\"newrelic-jsonlayout\"> </layout> </target> </targets> <rules> <logger name=\"NewRelicLog\" minlevel=\"Info\" writeTo=\"newRelicLogFile\" /> </rules> </nlog> </configuration> Copy What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 248.8404,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".<em>NET</em>: Configure with NLog",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " plugin. Install or update the .<em>NET</em> agent. Configure the NLog extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em> Confirm that you have <em>log</em> <em>management</em> enabled, with a compatible <em>log</em> forwarding plugin installed to send your application <em>logs</em> to <em>New</em> <em>Relic</em>. Install or update the .<em>NET</em> agent Install"
      },
      "id": "60450d32196a67923c960f6f"
    },
    {
      "sections": [
        ".NET: Configure with log4net",
        "Compatibility and requirements",
        "Overview",
        "Configure logs in context with New Relic Logs",
        "Enable New Relic Logs",
        "Install or update the .NET agent",
        "Configure the log4net extension",
        "What's next?"
      ],
      "title": ".NET: Configure with log4net",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for .NET"
      ],
      "external_id": "ccffdaabc7111e7bd5a13239e1d9c927d26a4bd1",
      "image": "https://docs.newrelic.com/static/90e8518fffeb7d9cc28f58f29fe749a5/e5166/LogsInContext---Log4Net.jpg",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-net/net-configure-log4net/",
      "published_at": "2021-07-02T13:25:38Z",
      "updated_at": "2021-03-13T01:10:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Apache log4net extension to link to your log data with related data across the rest of the New Relic platform. Read on to learn how to configure logs in context and enrich your log data. Compatibility and requirements To use New Relic logs in context with log4net, ensure your configuration meets the following requirements: Microsoft .NET Framework 4.5+ or .NET Core 2.0+ New Relic .NET agent 8.21+ New Relic .NET agent API 8.21+ Log4net 2.0.8+ Overview Log4net uses appender and layout to store and format log messages. NewRelicAppender enriches log messages with contextual information from the New Relic .NET agent if it is attached to your application. The appender passes enriched log messages to downstream appenders for specific use case log message handle. Log4net also provides NewRelicLayout to output log messages in the way required by the New Relic logging endpoint. A target can then be configured to write logging data to an output folder, which can be monitored by a log forwarder to incrementally send log information to New Relic. This diagram illustrates the flow of log messages through log4net: This diagram illustrates the flow of log messages through log4net, highlighting specific components of the New Relic log4net extension. The above diagram highlights the main components of the log4net logs in context solution: New Relic Appender: The NewRelicAppender adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. This appender will pass the enriched Log Events to downstream appenders for further processing. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain and requires another appender that can write to an actual output destination as its child in order to work. New Relic Layout: The NewRelicLayout formats the enriched log events into the JSON format expected by New Relic. The appender, which this layout is assigned to, instructs log4net to output the JSON to a file in the location that the log forwarder expects. New Relic Log Forwarder: The log forwarder monitors an output folder and incrementally sends New Relic formatted Log information to the New Relic Logging Endpoint. There are many log-forwarders available. For our examples, we will use Fluentd. For more information about logging with log4net, see the Apache log4net Getting started documentation. Configure logs in context with New Relic Logs To configure New Relic logs in context with Enable New Relic Logs with a compatible log forwarding plugin. Install or update the .NET agent. Configure the log4net extension. Check for logging data. Enable New Relic Logs Confirm that you have New Relic Logs enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the .NET agent Install or update to the most recent .NET agent version, and enable Distributed tracing. Configure the log4net extension To configure logs in context with the log4net extension, complete the following steps: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.Log4Net package. In your log4net configuration file, update your logging configuration to use the NewRelicAppender as the first level appender, and reference your existing appenders as its children. You also need to replace the layout of the appender that writes log messages to an output destination with the NewRelicLayout . The following log4net configuration example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\log4netExample.log.json for consumption by the log forwarder: <log4net> <root> <level value=\"ALL\" /> <appender-ref ref=\"NewRelicAppender\" /> </root> <appender name=\"NewRelicAppender\" type=\"NewRelic.LogEnrichers.Log4Net.NewRelicAppender, NewRelic.LogEnrichers.Log4Net\" > <threshold value=\"ALL\"/> <appender-ref ref=\"FileAppender\" /> </appender> <appender name=\"FileAppender\" type=\"log4net.Appender.FileAppender\"> <file value=\"C:\\logs\\log4netExample.log.json\" /> <param name=\"AppendToFile\" value=\"true\" /> <layout type=\"NewRelic.LogEnrichers.Log4Net.NewRelicLayout, NewRelic.LogEnrichers.Log4Net\"> </layout> </appender> </log4net> Copy Once you have configured the log4net extension and updated your logging file, you can configure your extension to send data to New Relic Logs. See below for an example of this configuration using the Fluentd plugin for New Relic Logs: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\log4netExample.log.json pos_file C:\\logs\\log4netExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 248.83461,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".<em>NET</em>: Configure with <em>log4net</em>",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>New</em> <em>Relic</em> <em>Logs</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": ". There are many <em>log</em>-forwarders available. For our examples, we will use Fluentd. For more information about logging with <em>log4net</em>, see the Apache <em>log4net</em> Getting started documentation. Configure <em>logs</em> in <em>context</em> with <em>New</em> <em>Relic</em> <em>Logs</em> To configure <em>New</em> <em>Relic</em> <em>logs</em> in <em>context</em> with <em>Enable</em> <em>New</em> <em>Relic</em> <em>Logs</em>"
      },
      "id": "60450d7164441f0d80378f09"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/logs-context-nodejs/configure-logs-context-nodejs": [
    {
      "sections": [
        "Node.js: Configure with Winston",
        "Compatibility and requirements",
        "Configure logs in context with log monitoring",
        "Enable log monitoring",
        "Install or update the Node.js agent",
        "Configure the Winston extension",
        "Check for logging data",
        "Troubleshooting",
        "What's next?"
      ],
      "title": "Node.js: Configure with Winston",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Node.js"
      ],
      "external_id": "0ed58684c33d758f2bdc599295fa356d9418702e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-nodejs/nodejs-configure-winston/",
      "published_at": "2021-07-02T13:26:55Z",
      "updated_at": "2021-03-13T01:09:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our Winston extension to link your log data with related data across the rest of the New Relic platform. Read on to learn how to configure logs in context and enrich your log data. Compatibility and requirements To use New Relic logs in context with Winston, ensure your configuration meets the following requirements: Node.js agent 6.2.0 or higher: Install or update Winston version 3.0.0 or higher Configure logs in context with log monitoring To configure logs in context with Winston: Enable log monitoring with a compatible log forwarding plugin. Install or update the Node.js agent. Configure the Winston extension. Check for logging data. Enable log monitoring Confirm that you have log monitoring enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Node.js agent Install or update to the most recent Node.js agent version, and enable Distributed tracing. Configure the Winston extension To configure logs in context with the Winston extension, complete the following steps: To install the New Relic Winston log enricher, enter the following command into your terminal or command line interface: npm install @newrelic/winston-enricher Copy In your application code, update your logging configuration to add the newrelicFormatter as shown below: // index.js require('newrelic') const newrelicFormatter = require('@newrelic/winston-enricher') Copy The New Relic formatter can be used individually or combined with other formatters as the final format. format: winston.format.combine( winston.format.label({label: 'test'}), newrelicFormatter() ) Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. Troubleshooting Problem Not all log data in a message or for a specific attribute is being displayed. Cause The stack trace will be written to the error.stack property. To accommodate the 4000 character log line limit for New Relic Logs, the stack and trace properties will be removed and the message, error.message and error.stack values will be truncated to 1024 characters. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 252.02669,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Node.js</em>: Configure with Winston",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> monitoring",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": ". Configure the Winston extension. Check for logging data. <em>Enable</em> <em>log</em> monitoring Confirm that you have <em>log</em> monitoring enabled, with a compatible <em>log</em> forwarding plugin installed to send your application <em>logs</em> to <em>New</em> <em>Relic</em>. Install or update the <em>Node.js</em> agent Install or update to the most recent <em>Node.js</em> agent"
      },
      "id": "60450d71196a675ce1960f82"
    },
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Tip",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent(#automatically-inserted-attributes)",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-07-02T17:22:19Z",
      "updated_at": "2021-06-25T23:18:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use log management and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x and 18.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes as key-value pairs that can be used to send additional data with the logs which you can then query. Add attributes to any log source. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent(#automatically-inserted-attributes) The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.79953,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Forward</em> your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> <em>forwarding</em> using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use <em>log</em> <em>management</em> and the rest of our observability"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Java: Configure with Log4j 1.x",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Log4j 1.x extension",
        "Example configuration file for the Log4j 1.x extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Log4j 1.x",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "c037c5f99fbe16c9ae129d177d246009df25fb45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-1x/",
      "published_at": "2021-07-02T13:23:38Z",
      "updated_at": "2021-04-16T21:20:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Log4j 1.x extension for New Relic log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Log4j 1.x, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Log4j 1.x package installed and working on the application. log4j must be configured in code or via XML. Properties files are not supported because AsyncAppender instances can only be automatically configured via XML. Configure logs in context with log management To configure logs in context with Logs4j 1.x: Enable log management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Log4j 1.x extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable Distributed tracing. Configure the Log4j 1.x extension To configure logs in context with the Log4j 1.x extension, complete the following steps: Update your project's dependencies to include the Log4j 1.x extension as applicable: To update with Gradle, add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j1:2.0\") } Copy To update with Maven, add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j1</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <appender> element with a NewRelicLayout, adding <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> as shown below: <appender name=\" TypicalFile \" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <layout class=\" com.newrelic.logging.log4j1.NewRelicLayout \"/> <!-- only this line needs to be added --> </appender> Copy Once updated, use NewRelicAsyncAppender to wrap any appenders that will target New Relic's log forwarder. For example: <appender name=\" NewRelicFile \" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\" TypicalFile \" /> </appender> Copy Once updated, use the async appender on the root logger. For example: <root> <appender-ref ref=\" NewRelicFile \" /> </root> Copy Example configuration file for the Log4j 1.x extension <?xml version=\"1.0\" encoding=\"UTF-8\" ?> <!DOCTYPE log4j:configuration SYSTEM \"log4j.dtd\"> <log4j:configuration debug=\"false\"> <appender name=\"TypicalFile\" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <!-- layout has been replaced --> <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> </appender> <!-- this appender was added --> <appender name=\"NewRelicFile\" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\"TypicalFile\" /> </appender> <appender name=\"TypicalConsole\" class=\"org.apache.log4j.ConsoleAppender\"> <layout class=\"org.apache.log4j.PatternLayout\"> <param name=\"ConversionPattern\" value=\"%-5p %c{1} - %m%n\"/> </layout> </appender> <root> ​ <!-- the new appender was used here -->​​ <appender-ref ref=\"NewRelicFile\" /> <appender-ref ref=\"TypicalConsole\" /> </root> </log4j:configuration> Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 141.19641,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Java: Configure with <em>Log4j</em> 1.x",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>New</em> <em>Relic</em> offers a <em>Log</em>4j 1.x extension for <em>New</em> <em>Relic</em> <em>log</em> <em>management</em>, allowing you link to your <em>log</em> data with related data across the rest of the <em>New</em> <em>Relic</em> platform. This document explains how to configure <em>logs</em> in <em>context</em> and start getting <em>log</em> data. The code and an example application are available"
      },
      "id": "603ead8b196a675ad7a83dd6"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/logs-context-nodejs/nodejs-configure-winston": [
    {
      "sections": [
        "Configure logs in context for Node.js",
        "Compatibility and requirements",
        "What's next?"
      ],
      "title": "Configure logs in context for Node.js",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Node.js"
      ],
      "external_id": "fcb49eac4608f936beb447ec385aba16d31ebf8b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-nodejs/configure-logs-context-nodejs/",
      "published_at": "2021-07-02T13:26:54Z",
      "updated_at": "2021-03-13T00:59:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the Node.js agent connects your Logs and APM data in New Relic, giving full context to high-level events and providing high value data to specific log lines. Compatibility and requirements To use log management with the Node.js agent, ensure your configuration meets the following requirements: Log management enabled, with a compatible log forwarding plugin installed Node.js agent 6.2.0 or higher: Install or update Configure logs in context for Node.js Choose a extension to see specific instructions: Winston What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 252.0255,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure <em>logs</em> <em>in</em> <em>context</em> <em>for</em> <em>Node.js</em>",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> <em>for</em> <em>Node.js</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the <em>Node.js</em> agent connects your <em>Logs</em> and APM data in <em>New</em> <em>Relic</em>, giving full <em>context</em> to high-level events and providing high value data to specific <em>log</em> lines. Compatibility and requirements To use <em>log</em> <em>management</em> with the <em>Node.js</em> agent, ensure your configuration meets"
      },
      "id": "60450dae28ccbcd15d2c60c4"
    },
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Tip",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent(#automatically-inserted-attributes)",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-07-02T17:22:19Z",
      "updated_at": "2021-06-25T23:18:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use log management and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x and 18.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes as key-value pairs that can be used to send additional data with the logs which you can then query. Add attributes to any log source. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent(#automatically-inserted-attributes) The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.79953,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Forward</em> your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> <em>forwarding</em> using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use <em>log</em> <em>management</em> and the rest of our observability"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Java: Configure with Log4j 1.x",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Log4j 1.x extension",
        "Example configuration file for the Log4j 1.x extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Log4j 1.x",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "c037c5f99fbe16c9ae129d177d246009df25fb45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-1x/",
      "published_at": "2021-07-02T13:23:38Z",
      "updated_at": "2021-04-16T21:20:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Log4j 1.x extension for New Relic log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Log4j 1.x, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Log4j 1.x package installed and working on the application. log4j must be configured in code or via XML. Properties files are not supported because AsyncAppender instances can only be automatically configured via XML. Configure logs in context with log management To configure logs in context with Logs4j 1.x: Enable log management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Log4j 1.x extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable Distributed tracing. Configure the Log4j 1.x extension To configure logs in context with the Log4j 1.x extension, complete the following steps: Update your project's dependencies to include the Log4j 1.x extension as applicable: To update with Gradle, add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j1:2.0\") } Copy To update with Maven, add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j1</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <appender> element with a NewRelicLayout, adding <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> as shown below: <appender name=\" TypicalFile \" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <layout class=\" com.newrelic.logging.log4j1.NewRelicLayout \"/> <!-- only this line needs to be added --> </appender> Copy Once updated, use NewRelicAsyncAppender to wrap any appenders that will target New Relic's log forwarder. For example: <appender name=\" NewRelicFile \" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\" TypicalFile \" /> </appender> Copy Once updated, use the async appender on the root logger. For example: <root> <appender-ref ref=\" NewRelicFile \" /> </root> Copy Example configuration file for the Log4j 1.x extension <?xml version=\"1.0\" encoding=\"UTF-8\" ?> <!DOCTYPE log4j:configuration SYSTEM \"log4j.dtd\"> <log4j:configuration debug=\"false\"> <appender name=\"TypicalFile\" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <!-- layout has been replaced --> <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> </appender> <!-- this appender was added --> <appender name=\"NewRelicFile\" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\"TypicalFile\" /> </appender> <appender name=\"TypicalConsole\" class=\"org.apache.log4j.ConsoleAppender\"> <layout class=\"org.apache.log4j.PatternLayout\"> <param name=\"ConversionPattern\" value=\"%-5p %c{1} - %m%n\"/> </layout> </appender> <root> ​ <!-- the new appender was used here -->​​ <appender-ref ref=\"NewRelicFile\" /> <appender-ref ref=\"TypicalConsole\" /> </root> </log4j:configuration> Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 141.19641,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Java: Configure with <em>Log4j</em> 1.x",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>New</em> <em>Relic</em> offers a <em>Log</em>4j 1.x extension for <em>New</em> <em>Relic</em> <em>log</em> <em>management</em>, allowing you link to your <em>log</em> data with related data across the rest of the <em>New</em> <em>Relic</em> platform. This document explains how to configure <em>logs</em> in <em>context</em> and start getting <em>log</em> data. The code and an example application are available"
      },
      "id": "603ead8b196a675ad7a83dd6"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/logs-context-php/configure-logs-context-php": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Tip",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent(#automatically-inserted-attributes)",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-07-02T17:22:19Z",
      "updated_at": "2021-06-25T23:18:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use log management and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x and 18.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes as key-value pairs that can be used to send additional data with the logs which you can then query. Add attributes to any log source. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent(#automatically-inserted-attributes) The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.79947,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Forward</em> your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> <em>forwarding</em> using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use <em>log</em> <em>management</em> and the rest of our observability"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Java: Configure with Log4j 1.x",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Log4j 1.x extension",
        "Example configuration file for the Log4j 1.x extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Log4j 1.x",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "c037c5f99fbe16c9ae129d177d246009df25fb45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-1x/",
      "published_at": "2021-07-02T13:23:38Z",
      "updated_at": "2021-04-16T21:20:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Log4j 1.x extension for New Relic log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Log4j 1.x, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Log4j 1.x package installed and working on the application. log4j must be configured in code or via XML. Properties files are not supported because AsyncAppender instances can only be automatically configured via XML. Configure logs in context with log management To configure logs in context with Logs4j 1.x: Enable log management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Log4j 1.x extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable Distributed tracing. Configure the Log4j 1.x extension To configure logs in context with the Log4j 1.x extension, complete the following steps: Update your project's dependencies to include the Log4j 1.x extension as applicable: To update with Gradle, add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j1:2.0\") } Copy To update with Maven, add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j1</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <appender> element with a NewRelicLayout, adding <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> as shown below: <appender name=\" TypicalFile \" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <layout class=\" com.newrelic.logging.log4j1.NewRelicLayout \"/> <!-- only this line needs to be added --> </appender> Copy Once updated, use NewRelicAsyncAppender to wrap any appenders that will target New Relic's log forwarder. For example: <appender name=\" NewRelicFile \" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\" TypicalFile \" /> </appender> Copy Once updated, use the async appender on the root logger. For example: <root> <appender-ref ref=\" NewRelicFile \" /> </root> Copy Example configuration file for the Log4j 1.x extension <?xml version=\"1.0\" encoding=\"UTF-8\" ?> <!DOCTYPE log4j:configuration SYSTEM \"log4j.dtd\"> <log4j:configuration debug=\"false\"> <appender name=\"TypicalFile\" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <!-- layout has been replaced --> <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> </appender> <!-- this appender was added --> <appender name=\"NewRelicFile\" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\"TypicalFile\" /> </appender> <appender name=\"TypicalConsole\" class=\"org.apache.log4j.ConsoleAppender\"> <layout class=\"org.apache.log4j.PatternLayout\"> <param name=\"ConversionPattern\" value=\"%-5p %c{1} - %m%n\"/> </layout> </appender> <root> ​ <!-- the new appender was used here -->​​ <appender-ref ref=\"NewRelicFile\" /> <appender-ref ref=\"TypicalConsole\" /> </root> </log4j:configuration> Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 141.19641,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Java: Configure with <em>Log4j</em> 1.x",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>New</em> <em>Relic</em> offers a <em>Log</em>4j 1.x extension for <em>New</em> <em>Relic</em> <em>log</em> <em>management</em>, allowing you link to your <em>log</em> data with related data across the rest of the <em>New</em> <em>Relic</em> platform. This document explains how to configure <em>logs</em> in <em>context</em> and start getting <em>log</em> data. The code and an example application are available"
      },
      "id": "603ead8b196a675ad7a83dd6"
    },
    {
      "sections": [
        "Configure logs in context for Ruby",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Ruby agent",
        "Configure for Rails",
        "Rails advanced configuration",
        "Configure for Ruby without Rails",
        "Advanced configuration",
        "Custom logger configuration",
        "Lograge configuration",
        "Check for logging data",
        "Troubleshooting",
        "Incompatible gems",
        "What's next?"
      ],
      "title": "Configure logs in context for Ruby",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Ruby"
      ],
      "external_id": "b9fec1d5dca01fdafbd45a26f6f9dc2030ae78a5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-ruby/configure-logs-context-ruby/",
      "published_at": "2021-07-02T15:43:26Z",
      "updated_at": "2021-03-16T09:25:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the Ruby agent connects your logs and APM data in New Relic, giving full context to high-level events and providing high value data to specific log lines. Read on to learn how to configure logs in context and enrich your log data. Compatibility and requirements To use log management with the Ruby agent, ensure your configuration meets the following requirements: Ruby agent 6.7.0 or higher: Install or update Supported Rails version (for Rails applications) Configure logs in context with log management To configure logs in context with Ruby: Enable log management with a compatible log forwarding plugin. Install or update the Ruby agent. Configure logs in context for Ruby. Optional: Advanced configuration. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Ruby agent Install or update to the most recent Ruby agent version, and enable distributed tracing. Configure logs in context for Ruby Configure for Rails Rails logging is controlled by two components: a logger (customizable by setting config.logger) and a log formatter (customizable by setting config.log_formatter). In most cases, logs in context should be configured by setting config.log_formatter to the DecoratingFormatter in your Rails application. For more guidance regarding Rails configuration, see Configuring Rails Applications. In your application's config, require 'newrelic_rpm', then add the following line: module ________ class Application < Rails::Application ... config.log_formatter = ::NewRelic::Agent::Logging::DecoratingFormatter.new end end Copy This will use the New Relic formatter to format log messages, but the rest of the logging configuration will be provided by the other Rails config settings. Please note that Logs in Context for Ruby does not currently support tagged logging; if you are initializing your logger with a log_tags argument, your custom tags may not appear on the final version of your logs. Rails advanced configuration If setting the log_formatter option doesn't meet your needs, replace the entire Rails logger with an instance of the New Relic logger. Provide the parameters to the logger's constructor, like this: module ________ class Application < Rails::Application ... config.logger = ::NewRelic::Agent::Logging::DecoratingLogger.new( \"log/application.log\", #etc... ) end end Copy Configure for Ruby without Rails For non-Rails applications, use the DecoratingLogger in place of the Ruby standard ::Logger, like this: logger = ::NewRelic::Agent::Logging::DecoratingLogger.new( 'log/application.log', #etc... ) ... logger.info(...) Copy The DecoratingLogger is a drop-in replacement for the Ruby standard ::Logger. Their constructors accept the same parameters. Advanced configuration Custom logger configuration To use our logging extension with a different logging implementation, or your own custom logger, use the DecoratingFormatter. Example: module ________ class Application < Rails::Application ... config.logger = ::YourCustomLoggerImplementation.new( $stdout, formatter: ::NewRelic::Agent::Logging::DecoratingFormatter.new ) end end Copy Lograge configuration To configure this extension with the lograge gem, there is no additional configuration required. Check for logging data If you have configured your logging in /config/application.rb, or in /config/environments/development.rb, run your application locally and check its logging output. You should see some output like this: {\"entity.name\":\"your_app_name\",\"entity.type\":\"SERVICE\",\"hostname\":\"79bcbf8d\",\"trace.id\":\"79bcbf8d\",\"span.id\":\"00fc7d46\",\"timestamp\":1567701375543,\"message\":\"example log message one\",\"log.level\":\"DEBUG\"} {\"entity.name\":\"your_app_name\",\"entity.type\":\"SERVICE\",\"hostname\":\"79bcbf8d\",\"trace.id\":\"79bcbf8d\",\"span.id\":\"6754870b\",\"timestamp\":1567702843604,\"message\":\"example log message two\",\"log.level\":\"DEBUG\"} Copy If you have deployed this application to an environment with a log forwarder, your application's logs will appear in the New Relic Logs UI with metadata linking them to a trace and a span. You can find them using a query like this: entity.name:\"your_app_name\" has:trace.id Copy If you see JSON logs in your application's output, but no logs returned by a query like the above, check your log forwarder. Troubleshooting If the logs from your application are not formatted in JSON with fields like trace.id and span.id, there may be a problem with the configuration of the New Relic Logging Extension. Check that: the application is using a supported logging framework. the configuration has been applied to all the environments where you would like to use the New Relic Logging Extension. there is not another logger configured later in the configuration of the application. Incompatible gems The New Relic decorating logger is known to be incompatible with the following gems: logging semantic logger rails_stdout_logger rails_12factor What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.94392,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure <em>logs</em> <em>in</em> <em>context</em> <em>for</em> Ruby",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the Ruby agent connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>, giving full <em>context</em> to high-level events and providing high value data to specific <em>log</em> lines. Read on to learn how to configure <em>logs</em> in <em>context</em> and enrich your <em>log</em> data. Compatibility and requirements To use <em>log</em>"
      },
      "id": "603ea67c64441fe0c34e886e"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/logs-context-python/configure-logs-context-python": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Tip",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent(#automatically-inserted-attributes)",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-07-02T17:22:19Z",
      "updated_at": "2021-06-25T23:18:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use log management and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x and 18.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes as key-value pairs that can be used to send additional data with the logs which you can then query. Add attributes to any log source. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent(#automatically-inserted-attributes) The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.79947,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Forward</em> your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> <em>forwarding</em> using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use <em>log</em> <em>management</em> and the rest of our observability"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Java: Configure with Log4j 1.x",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Log4j 1.x extension",
        "Example configuration file for the Log4j 1.x extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Log4j 1.x",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "c037c5f99fbe16c9ae129d177d246009df25fb45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-1x/",
      "published_at": "2021-07-02T13:23:38Z",
      "updated_at": "2021-04-16T21:20:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Log4j 1.x extension for New Relic log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Log4j 1.x, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Log4j 1.x package installed and working on the application. log4j must be configured in code or via XML. Properties files are not supported because AsyncAppender instances can only be automatically configured via XML. Configure logs in context with log management To configure logs in context with Logs4j 1.x: Enable log management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Log4j 1.x extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable Distributed tracing. Configure the Log4j 1.x extension To configure logs in context with the Log4j 1.x extension, complete the following steps: Update your project's dependencies to include the Log4j 1.x extension as applicable: To update with Gradle, add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j1:2.0\") } Copy To update with Maven, add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j1</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <appender> element with a NewRelicLayout, adding <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> as shown below: <appender name=\" TypicalFile \" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <layout class=\" com.newrelic.logging.log4j1.NewRelicLayout \"/> <!-- only this line needs to be added --> </appender> Copy Once updated, use NewRelicAsyncAppender to wrap any appenders that will target New Relic's log forwarder. For example: <appender name=\" NewRelicFile \" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\" TypicalFile \" /> </appender> Copy Once updated, use the async appender on the root logger. For example: <root> <appender-ref ref=\" NewRelicFile \" /> </root> Copy Example configuration file for the Log4j 1.x extension <?xml version=\"1.0\" encoding=\"UTF-8\" ?> <!DOCTYPE log4j:configuration SYSTEM \"log4j.dtd\"> <log4j:configuration debug=\"false\"> <appender name=\"TypicalFile\" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <!-- layout has been replaced --> <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> </appender> <!-- this appender was added --> <appender name=\"NewRelicFile\" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\"TypicalFile\" /> </appender> <appender name=\"TypicalConsole\" class=\"org.apache.log4j.ConsoleAppender\"> <layout class=\"org.apache.log4j.PatternLayout\"> <param name=\"ConversionPattern\" value=\"%-5p %c{1} - %m%n\"/> </layout> </appender> <root> ​ <!-- the new appender was used here -->​​ <appender-ref ref=\"NewRelicFile\" /> <appender-ref ref=\"TypicalConsole\" /> </root> </log4j:configuration> Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 141.19641,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Java: Configure with <em>Log4j</em> 1.x",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>New</em> <em>Relic</em> offers a <em>Log</em>4j 1.x extension for <em>New</em> <em>Relic</em> <em>log</em> <em>management</em>, allowing you link to your <em>log</em> data with related data across the rest of the <em>New</em> <em>Relic</em> platform. This document explains how to configure <em>logs</em> in <em>context</em> and start getting <em>log</em> data. The code and an example application are available"
      },
      "id": "603ead8b196a675ad7a83dd6"
    },
    {
      "sections": [
        "Configure logs in context for Ruby",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Ruby agent",
        "Configure for Rails",
        "Rails advanced configuration",
        "Configure for Ruby without Rails",
        "Advanced configuration",
        "Custom logger configuration",
        "Lograge configuration",
        "Check for logging data",
        "Troubleshooting",
        "Incompatible gems",
        "What's next?"
      ],
      "title": "Configure logs in context for Ruby",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Ruby"
      ],
      "external_id": "b9fec1d5dca01fdafbd45a26f6f9dc2030ae78a5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-ruby/configure-logs-context-ruby/",
      "published_at": "2021-07-02T15:43:26Z",
      "updated_at": "2021-03-16T09:25:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the Ruby agent connects your logs and APM data in New Relic, giving full context to high-level events and providing high value data to specific log lines. Read on to learn how to configure logs in context and enrich your log data. Compatibility and requirements To use log management with the Ruby agent, ensure your configuration meets the following requirements: Ruby agent 6.7.0 or higher: Install or update Supported Rails version (for Rails applications) Configure logs in context with log management To configure logs in context with Ruby: Enable log management with a compatible log forwarding plugin. Install or update the Ruby agent. Configure logs in context for Ruby. Optional: Advanced configuration. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Ruby agent Install or update to the most recent Ruby agent version, and enable distributed tracing. Configure logs in context for Ruby Configure for Rails Rails logging is controlled by two components: a logger (customizable by setting config.logger) and a log formatter (customizable by setting config.log_formatter). In most cases, logs in context should be configured by setting config.log_formatter to the DecoratingFormatter in your Rails application. For more guidance regarding Rails configuration, see Configuring Rails Applications. In your application's config, require 'newrelic_rpm', then add the following line: module ________ class Application < Rails::Application ... config.log_formatter = ::NewRelic::Agent::Logging::DecoratingFormatter.new end end Copy This will use the New Relic formatter to format log messages, but the rest of the logging configuration will be provided by the other Rails config settings. Please note that Logs in Context for Ruby does not currently support tagged logging; if you are initializing your logger with a log_tags argument, your custom tags may not appear on the final version of your logs. Rails advanced configuration If setting the log_formatter option doesn't meet your needs, replace the entire Rails logger with an instance of the New Relic logger. Provide the parameters to the logger's constructor, like this: module ________ class Application < Rails::Application ... config.logger = ::NewRelic::Agent::Logging::DecoratingLogger.new( \"log/application.log\", #etc... ) end end Copy Configure for Ruby without Rails For non-Rails applications, use the DecoratingLogger in place of the Ruby standard ::Logger, like this: logger = ::NewRelic::Agent::Logging::DecoratingLogger.new( 'log/application.log', #etc... ) ... logger.info(...) Copy The DecoratingLogger is a drop-in replacement for the Ruby standard ::Logger. Their constructors accept the same parameters. Advanced configuration Custom logger configuration To use our logging extension with a different logging implementation, or your own custom logger, use the DecoratingFormatter. Example: module ________ class Application < Rails::Application ... config.logger = ::YourCustomLoggerImplementation.new( $stdout, formatter: ::NewRelic::Agent::Logging::DecoratingFormatter.new ) end end Copy Lograge configuration To configure this extension with the lograge gem, there is no additional configuration required. Check for logging data If you have configured your logging in /config/application.rb, or in /config/environments/development.rb, run your application locally and check its logging output. You should see some output like this: {\"entity.name\":\"your_app_name\",\"entity.type\":\"SERVICE\",\"hostname\":\"79bcbf8d\",\"trace.id\":\"79bcbf8d\",\"span.id\":\"00fc7d46\",\"timestamp\":1567701375543,\"message\":\"example log message one\",\"log.level\":\"DEBUG\"} {\"entity.name\":\"your_app_name\",\"entity.type\":\"SERVICE\",\"hostname\":\"79bcbf8d\",\"trace.id\":\"79bcbf8d\",\"span.id\":\"6754870b\",\"timestamp\":1567702843604,\"message\":\"example log message two\",\"log.level\":\"DEBUG\"} Copy If you have deployed this application to an environment with a log forwarder, your application's logs will appear in the New Relic Logs UI with metadata linking them to a trace and a span. You can find them using a query like this: entity.name:\"your_app_name\" has:trace.id Copy If you see JSON logs in your application's output, but no logs returned by a query like the above, check your log forwarder. Troubleshooting If the logs from your application are not formatted in JSON with fields like trace.id and span.id, there may be a problem with the configuration of the New Relic Logging Extension. Check that: the application is using a supported logging framework. the configuration has been applied to all the environments where you would like to use the New Relic Logging Extension. there is not another logger configured later in the configuration of the application. Incompatible gems The New Relic decorating logger is known to be incompatible with the following gems: logging semantic logger rails_stdout_logger rails_12factor What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.94392,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure <em>logs</em> <em>in</em> <em>context</em> <em>for</em> Ruby",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the Ruby agent connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>, giving full <em>context</em> to high-level events and providing high value data to specific <em>log</em> lines. Read on to learn how to configure <em>logs</em> in <em>context</em> and enrich your <em>log</em> data. Compatibility and requirements To use <em>log</em>"
      },
      "id": "603ea67c64441fe0c34e886e"
    }
  ],
  "/docs/logs/enable-log-management-new-relic/logs-context-ruby/configure-logs-context-ruby": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Tip",
        "Enable log forwarding using the infrastructure agent",
        "System Requirements",
        "Caution",
        "Install the infrastructure agent",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "name",
        "Log source (required)",
        "file",
        "Important",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional Configuration",
        "attributes",
        "Log attributes automatically inserted by the infrastructure agent(#automatically-inserted-attributes)",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshoot log forwarding",
        "No data appears when tailing a file",
        "Example: checking file access under Linux",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Send the agent's logs to New Relic",
        "Fluent Bit does not start with the infra-agent",
        "Runtime error on Windows",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "dddab40697224ea7f816e70b05d18f8d75fb5084",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-07-02T17:22:19Z",
      "updated_at": "2021-06-25T23:18:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use log management and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Enable log forwarding using the infrastructure agent To enable log forwarding through the infrastructure agent: Start by verifying the system requirements needed for configuring Logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System Requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x and 18.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Caution The log forwarding feature is not supported on containerized infrastructure agents. Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. The Infrastructure agent uses .yml files for configuring logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the logging forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file and add the parameters you need. The logging.d directory has various .yml.example files that can be used as a reference or starting point. The agent automatically processes new configuration files without having to restart the Infrastructure service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, make sure to define a name for the logs you want to forward: name Name of the log or logs being forwarding to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. The available options are listed below: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd paramater to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional Configuration The following are configuration paramaters that are not required but are still recommended. attributes List of custom attributes as key-value pairs that can be used to send additional data with the logs which you can then query. Add attributes to any log source. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy Log attributes automatically inserted by the infrastructure agent(#automatically-inserted-attributes) The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Find a summary of these attributes in the following table: Attribute name Inserting conditions Description entity.guids Always inserted The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted The underlying Fluent Bit input plugin type used to capture the logs. Currently, its values are tail, systemd, winlog, syslog, and tcp. filePath When using the file input type Absolute file path of the file being monitored. hostname Always inserted The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and data is being collected, you should see data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries; for example, you can execute a query like this: SELECT * FROM Log Copy Troubleshoot log forwarding If no data appears after you enable log management, follow standard troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: checking file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others\". We can fix this by executing: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log-forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. Send the agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3 Important On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the following configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the fluentbit option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra-agent For Linux versions previous to 2016 you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agenthas started Fluent Bit by doing ps -aux | grep fluent-bit Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable: x64 or x86. What's next? Now that you've enabled Logs, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.79944,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Forward</em> your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "<em>Enable</em> <em>log</em> <em>forwarding</em> using the <em>infrastructure</em> agent",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Tip To use <em>log</em> <em>management</em> and the rest of our observability"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Java: Configure with Log4j 1.x",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Log4j 1.x extension",
        "Example configuration file for the Log4j 1.x extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Log4j 1.x",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "c037c5f99fbe16c9ae129d177d246009df25fb45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-1x/",
      "published_at": "2021-07-02T13:23:38Z",
      "updated_at": "2021-04-16T21:20:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Log4j 1.x extension for New Relic log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Log4j 1.x, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Log4j 1.x package installed and working on the application. log4j must be configured in code or via XML. Properties files are not supported because AsyncAppender instances can only be automatically configured via XML. Configure logs in context with log management To configure logs in context with Logs4j 1.x: Enable log management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Log4j 1.x extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable Distributed tracing. Configure the Log4j 1.x extension To configure logs in context with the Log4j 1.x extension, complete the following steps: Update your project's dependencies to include the Log4j 1.x extension as applicable: To update with Gradle, add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j1:2.0\") } Copy To update with Maven, add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j1</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <appender> element with a NewRelicLayout, adding <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> as shown below: <appender name=\" TypicalFile \" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <layout class=\" com.newrelic.logging.log4j1.NewRelicLayout \"/> <!-- only this line needs to be added --> </appender> Copy Once updated, use NewRelicAsyncAppender to wrap any appenders that will target New Relic's log forwarder. For example: <appender name=\" NewRelicFile \" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\" TypicalFile \" /> </appender> Copy Once updated, use the async appender on the root logger. For example: <root> <appender-ref ref=\" NewRelicFile \" /> </root> Copy Example configuration file for the Log4j 1.x extension <?xml version=\"1.0\" encoding=\"UTF-8\" ?> <!DOCTYPE log4j:configuration SYSTEM \"log4j.dtd\"> <log4j:configuration debug=\"false\"> <appender name=\"TypicalFile\" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <!-- layout has been replaced --> <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> </appender> <!-- this appender was added --> <appender name=\"NewRelicFile\" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\"TypicalFile\" /> </appender> <appender name=\"TypicalConsole\" class=\"org.apache.log4j.ConsoleAppender\"> <layout class=\"org.apache.log4j.PatternLayout\"> <param name=\"ConversionPattern\" value=\"%-5p %c{1} - %m%n\"/> </layout> </appender> <root> ​ <!-- the new appender was used here -->​​ <appender-ref ref=\"NewRelicFile\" /> <appender-ref ref=\"TypicalConsole\" /> </root> </log4j:configuration> Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 141.19641,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Java: Configure with <em>Log4j</em> 1.x",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>New</em> <em>Relic</em> offers a <em>Log</em>4j 1.x extension for <em>New</em> <em>Relic</em> <em>log</em> <em>management</em>, allowing you link to your <em>log</em> data with related data across the rest of the <em>New</em> <em>Relic</em> platform. This document explains how to configure <em>logs</em> in <em>context</em> and start getting <em>log</em> data. The code and an example application are available"
      },
      "id": "603ead8b196a675ad7a83dd6"
    },
    {
      "sections": [
        "Java: Configure with Log4j 2.x",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Log4j 2.x extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Log4j 2.x",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "481ea55e236babf6d2ee7f7326db4c27e3dd37a3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-2x/",
      "published_at": "2021-07-02T13:23:38Z",
      "updated_at": "2021-03-16T09:23:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Log4j 2.x extension for log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Log4j 2.x, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Log4j 2.x or Logs4j 2 binding package installed and working on the application. Configure logs in context with log management To configure New Relic logs in context with Log4j 2.x: Enable logs management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Log4j 2.x extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable distributed tracing. Configure the Log4j 2.x extension To configure logs in context with the Log4j 2.x extension, complete the following steps: Update your project's dependencies to include the Log4j 2.x extension as applicable: To update with Gradle, add the highlighted section to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j2:2.0\") } Copy To update with Maven, add the highlighted section to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j2</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <configuration> element by adding the highlighted section: <Configuration xmlns=\"http://logging.apache.org/log4j/2.0/config\" packages=\"com.newrelic.logging.log4j2\" > Copy If you are using a properties file, add packages=com.newrelic.logging.log4j2. Once updated, add <NewRelicLayout/> to use a NewRelicLayout element within one of the appenders. For example: <File name=\"MyFile\" fileName=\"logs/app-log-file.log\"> <NewRelicLayout/> </File> Copy If you are using a properties file, change only the layout.type property, as shown below: appender.console.type = Console appender.console.name = STDOUT appender.console.layout.type = NewRelicLayout Copy If you only modified an existing appender, you can skip this step. Add <AppenderRef/> within <Root> to use this appender. The ref attribute refers to the name of the appender you created in the previous step. For example: <Root level=\"info\"> <AppenderRef ref=\"MyFile\"/> </Root> Copy If you are using a properties file, you will need to add a property if you added a new appender: rootLogger.level = info rootLogger.appenderRef.stdout.ref = STDOUT ​​​​​ Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.94377,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Java: Configure with <em>Log4j</em> 2.x",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " on the application. Configure <em>logs</em> in <em>context</em> with <em>log</em> <em>management</em> To configure <em>New</em> <em>Relic</em> <em>logs</em> in <em>context</em> with <em>Log</em>4j 2.x: <em>Enable</em> <em>logs</em> <em>management</em> with a compatible <em>log</em> forwarding plugin. Install or update the Java agent. Configure the <em>Log</em>4j 2.x extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em>"
      },
      "id": "603ead8a28ccbc47a2eba74f"
    }
  ],
  "/docs/logs/enable-log-monitoring-new-relic/logs-context-java/java-adding-classpath": [
    {
      "sections": [
        "Java: Configure with Log4j 1.x",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Log4j 1.x extension",
        "Example configuration file for the Log4j 1.x extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Log4j 1.x",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "c037c5f99fbe16c9ae129d177d246009df25fb45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-1x/",
      "published_at": "2021-07-02T13:23:38Z",
      "updated_at": "2021-04-16T21:20:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Log4j 1.x extension for New Relic log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Log4j 1.x, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Log4j 1.x package installed and working on the application. log4j must be configured in code or via XML. Properties files are not supported because AsyncAppender instances can only be automatically configured via XML. Configure logs in context with log management To configure logs in context with Logs4j 1.x: Enable log management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Log4j 1.x extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable Distributed tracing. Configure the Log4j 1.x extension To configure logs in context with the Log4j 1.x extension, complete the following steps: Update your project's dependencies to include the Log4j 1.x extension as applicable: To update with Gradle, add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j1:2.0\") } Copy To update with Maven, add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j1</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <appender> element with a NewRelicLayout, adding <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> as shown below: <appender name=\" TypicalFile \" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <layout class=\" com.newrelic.logging.log4j1.NewRelicLayout \"/> <!-- only this line needs to be added --> </appender> Copy Once updated, use NewRelicAsyncAppender to wrap any appenders that will target New Relic's log forwarder. For example: <appender name=\" NewRelicFile \" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\" TypicalFile \" /> </appender> Copy Once updated, use the async appender on the root logger. For example: <root> <appender-ref ref=\" NewRelicFile \" /> </root> Copy Example configuration file for the Log4j 1.x extension <?xml version=\"1.0\" encoding=\"UTF-8\" ?> <!DOCTYPE log4j:configuration SYSTEM \"log4j.dtd\"> <log4j:configuration debug=\"false\"> <appender name=\"TypicalFile\" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <!-- layout has been replaced --> <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> </appender> <!-- this appender was added --> <appender name=\"NewRelicFile\" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\"TypicalFile\" /> </appender> <appender name=\"TypicalConsole\" class=\"org.apache.log4j.ConsoleAppender\"> <layout class=\"org.apache.log4j.PatternLayout\"> <param name=\"ConversionPattern\" value=\"%-5p %c{1} - %m%n\"/> </layout> </appender> <root> ​ <!-- the new appender was used here -->​​ <appender-ref ref=\"NewRelicFile\" /> <appender-ref ref=\"TypicalConsole\" /> </root> </log4j:configuration> Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 236.09813,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Java</em>: Configure with <em>Log4j</em> 1.x",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " <em>log</em> forwarding plugin. Install or update the <em>Java</em> agent. Configure the <em>Log</em>4j 1.x extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em> Confirm that you have <em>log</em> <em>management</em> enabled, with a compatible <em>log</em> forwarding plugin installed to send your application <em>logs</em> to <em>New</em> <em>Relic</em>. Install or update"
      },
      "id": "603ead8b196a675ad7a83dd6"
    },
    {
      "sections": [
        "Java: Configure with Log4j 2.x",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Log4j 2.x extension",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Log4j 2.x",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "481ea55e236babf6d2ee7f7326db4c27e3dd37a3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-log4j-2x/",
      "published_at": "2021-07-02T13:23:38Z",
      "updated_at": "2021-03-16T09:23:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Log4j 2.x extension for log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Log4j 2.x, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update JVM argument -javaagent enabled on the Java agent. Log4j 2.x or Logs4j 2 binding package installed and working on the application. Configure logs in context with log management To configure New Relic logs in context with Log4j 2.x: Enable logs management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Log4j 2.x extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable distributed tracing. Configure the Log4j 2.x extension To configure logs in context with the Log4j 2.x extension, complete the following steps: Update your project's dependencies to include the Log4j 2.x extension as applicable: To update with Gradle, add the highlighted section to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j2:2.0\") } Copy To update with Maven, add the highlighted section to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j2</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <configuration> element by adding the highlighted section: <Configuration xmlns=\"http://logging.apache.org/log4j/2.0/config\" packages=\"com.newrelic.logging.log4j2\" > Copy If you are using a properties file, add packages=com.newrelic.logging.log4j2. Once updated, add <NewRelicLayout/> to use a NewRelicLayout element within one of the appenders. For example: <File name=\"MyFile\" fileName=\"logs/app-log-file.log\"> <NewRelicLayout/> </File> Copy If you are using a properties file, change only the layout.type property, as shown below: appender.console.type = Console appender.console.name = STDOUT appender.console.layout.type = NewRelicLayout Copy If you only modified an existing appender, you can skip this step. Add <AppenderRef/> within <Root> to use this appender. The ref attribute refers to the name of the appender you created in the previous step. For example: <Root level=\"info\"> <AppenderRef ref=\"MyFile\"/> </Root> Copy If you are using a properties file, you will need to add a property if you added a new appender: rootLogger.level = info rootLogger.appenderRef.stdout.ref = STDOUT ​​​​​ Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.9872,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Java</em>: Configure with <em>Log4j</em> 2.x",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " on the application. Configure <em>logs</em> in <em>context</em> with <em>log</em> <em>management</em> To configure <em>New</em> <em>Relic</em> <em>logs</em> in <em>context</em> with <em>Log</em>4j 2.x: <em>Enable</em> <em>logs</em> <em>management</em> with a compatible <em>log</em> forwarding plugin. Install or update the <em>Java</em> agent. Configure the <em>Log</em>4j 2.x extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em>"
      },
      "id": "603ead8a28ccbc47a2eba74f"
    },
    {
      "sections": [
        "Java: Configure with Logback",
        "Compatibility and requirements",
        "Configure logs in context with log management",
        "Enable log management",
        "Install or update the Java agent",
        "Configure the Logback extension",
        "Important",
        "Example configuration files",
        "Single console appender example",
        "Two-appender example",
        "Check for logging data",
        "What's next?"
      ],
      "title": "Java: Configure with Logback",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Java"
      ],
      "external_id": "d43c55efa817768e3840897678b966f896fd268d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/logs-context-java/java-configure-logback/",
      "published_at": "2021-07-02T13:23:38Z",
      "updated_at": "2021-03-16T09:23:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a Logback extension for log management, allowing you link to your log data with related data across the rest of the New Relic platform. This document explains how to configure logs in context and start getting log data. The code and an example application are available on GitHub. Compatibility and requirements To use New Relic logs in context with Logback, ensure your configuration meets the following requirements: Java agent 5.6.0 or higher: Install or update Logback 1.2.0 or higher installed and working on the application. Configure logs in context with log management To configure New Relic logs in context with Logback: Enable log management with a compatible log forwarding plugin. Install or update the Java agent. Configure the Logback extension. Check for logging data. Enable log management Confirm that you have log management enabled, with a compatible log forwarding plugin installed to send your application logs to New Relic. Install or update the Java agent Install or update to the most recent Java agent version, and enable Distributed tracing. Configure the Logback extension To configure logs in context with the Logback extension, complete the following steps: Update your project's dependencies to include the Logback extension as applicable: To update with Gradle, add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:logback:2.0\") } Copy To update with Maven, add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>logback</artifactId> <version>2.0</version> </dependency> </dependencies> Copy Update your logging configuration xml to replace any existing < encoder> element as shown below. If you are logging to the console (stdout/stderr), look for ConsoleAppender and replace : <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy If you are logging to a file, look for FileAppender and replace <encoder>: <appender name=\"LOG_FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>logs/app-log-file.log</file> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy Update your logging configuration xml with the NewRelicAsyncAppender. To ensure that NewRelicAsyncAppender wraps any appenders that will target New Relic's log forwarder, add the following section. Change \"LOG_FILE\" to the name of the appender you updated in the previous step. <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"LOG_FILE\" /> </appender> Copy Make sure NewRelicAsyncAppender is the appender used in your logger. Replace your root logger’s appenders with the ASYNC appender created in the previous step. <root> <appender-ref ref=\"ASYNC\" /> </root> Copy Important It's important that the NewRelicAsyncAppender be the first appender to see the log message. List any other appenders after the NewRelicAsyncAppender in the <root> list. Example configuration files You can find a working example in GitHub. Here are examples of an updated logging .xml file for the Logback extension. Single console appender example Example configuration file after adding in the logging extension information. <configuration> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <!-- changed the encoder --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- added the ASYNC appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"STDOUT\" /> </appender> <root level=\"debug\"> <!-- changed the root logger --> <appender-ref ref=\"ASYNC\" /> </root> </configuration> Copy Two-appender example This example sends New Relic logging to a file, but still sends standard logging to the console. <configuration> <appender name=\"FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>myApp.log</file> <!-- encoder changed --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- this appender does normal console logging --> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder> <pattern>%msg%n</pattern> </encoder> </appender> <!-- The required New Relic ASYNC appender wraps the FILE appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"FILE\" /> </appender> <root level=\"debug\"> <!-- ASYNC is one of the main appenders --> <appender-ref ref=\"ASYNC\" /> <!-- Send every message to normal console logging, as well. --> <appender-ref ref=\"STDOUT\" /> </root> </configuration> Copy Check for logging data To verify that you have configured the extension correctly, run your application and verify that the logging you have configured contains the following: Includes trace.id and span.id fields Is properly-formatted JSON lines If everything is configured correctly and your data is being reported, you should see data logs in the New Relic Logs UI using the query operator has: span.id/trace.id. What's next? Now that you've set up APM logs in context, here are some potential next steps: Explore your data using the Logs UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards or alerts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.9872,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Java</em>: Configure with <em>Logback</em>",
        "sections": "Configure <em>logs</em> <em>in</em> <em>context</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " To configure <em>New</em> <em>Relic</em> <em>logs</em> in <em>context</em> with Logback: <em>Enable</em> <em>log</em> <em>management</em> with a compatible <em>log</em> forwarding plugin. Install or update the <em>Java</em> agent. Configure the Logback extension. Check for logging data. <em>Enable</em> <em>log</em> <em>management</em> Confirm that you have <em>log</em> <em>management</em> enabled, with a compatible <em>log</em>"
      },
      "id": "603ead8a196a679235a83d96"
    }
  ],
  "/docs/logs/index": [
    {
      "sections": [
        "Discover value in log data with patterns",
        "Technical overview",
        "Availability",
        "Important",
        "Get started",
        "Explore log patterns",
        "Explore logs with no pattern",
        "Masked attributes and wildcards",
        "Troubleshooting",
        "Put the platform to work with patterns"
      ],
      "title": "Discover value in log data with patterns",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "8f1e27c94327ca4888a945f8e12f9c2310ccd7a6",
      "image": "https://docs.newrelic.com/static/578d7186bb34352855696e5307cc82f2/c1b63/log-patterns-logs-without-a-pattern.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/find-unusual-logs-log-patterns/",
      "published_at": "2021-07-02T14:37:14Z",
      "updated_at": "2021-07-02T14:37:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Log patterns are the fastest way to discover value in log data without searching. Log data is high volume telemetry with a low value per individual record. Searching can quickly lead to logs that provide a root cause explanation, but most data is repetitive and hard to contextualize when browsing. Patterns can make log data discoverable without spending a lot of time reading through low value data. one.newrelic.com > Logs > Patterns: Use patterns as the basis for alerts when the frequency of important data changes, or for configuring drop rules to get rid of unnecessary repetitive data. Technical overview Log patterns functionality applies machine learning to normalize and group log messages that are consistent in format but variable in content. These grouped messages can be sorted, making it easy to find the most frequent or rarest sets of logs in your environment. Use patterns as the basis for alerts when the frequency of important data changes, or to configure drop rules to get rid of unnecessary repetitive data. Log patterns use advanced clustering algorithms to group together similar log messages automatically. With patterns, you can: Orient more quickly through millions of logs. Reduce the time it takes to identify unusual behavior in your log estate. Monitor the frequency of known patterns over time to focus your energy on what matters, and exclude what's irrelevant. Availability Important Log patterns are not available in the EU region. The ability to configure this feature is dependent on role-based permissions. If you see Patterns are turned off in your Log management Patterns UI, click the Configure Patterns button and enable it. If you don't see patterns within 30 minutes of enabling the feature, there may be a lack of data with a message attribute for the system to create a pattern from. Log patterns Limitations and considerations Pricing There is no separate pricing for log patterns. The only cost is for additional data generated and added to your log records. A pattern attribute will be added to all logs that match a pattern. Attributes also may be added when common values are discovered, such as GUIDs, IP addresses, URL, or email addresses. These attributes are automatically extracted from the log message as part of the pattern process. HITRUST accounts The log patterns feature is not FedRAMP compliant. FedRAMP or other HITRUST accounts are not eligible to use patterns. Regional availability Availability for this feature depends on whether you have a US or EU region account: US region accounts can use log patterns. EU region accounts cannot enable log patterns at this time. Parsing limits We have a system of safety limits on memory and CPU resources when processing logs and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com > Log management, and use the account picker dropdown to select the target account where you want to explore patterns. In the left navigation of the Log management UI, click Patterns. The main log UI changes to show patterns that match the query in the query bar. one.newrelic.com > Log management > Log patterns: The line chart shows the top 5 patterns over time. Use the time picker and query bar to adjust the results. Explore log patterns By default the log patterns UI first shows the most frequent occurrence of patterns. To sort to show the rarest patterns first, click the Count column. You can also use the query bar or attributes bar to filter your log patterns. If you want to... Do this... Understand the rate of change in patterns Look at the line chart. The color-coded patterns correspond to the plot column in the table. You can toggle individual plot patterns to narrow your focus. See the individual log messages that match each pattern Click pattern to expand the row and see a table of individual log records. To see additional records, scroll up or down. To explore an individual log in more detail, click it to open the details panel. Group and filter patterns by their attributes Use the query bar and time picker. As you apply different filters and time windows, the log patterns adjust to your new target data. Create an alert from a pattern Add the pattern to the query bar and run the query. Then click Create alert condition in the left nav. Troubleshoot log messages that haven't been clustered into a pattern Use the Logs with no pattern tab in the Log patterns UI. Clicking a specific log message will open the log message details panel you're familiar with from the Logs management page. Explore logs with no pattern The Logs with no pattern tab groups all recent log messages in your account that were not clustered into a known pattern yet. These log messages don't represent any problem or flaw in the system; they have no pattern because they are too new to have been processed by the machine learning system. This makes them valuable to explore when you want to understand what has recently changed in your environment. one.newrelic.com > Log management > Log patterns: New Relic's log patterns feature automatically groups logs without a matching pattern. For example: Are any of these logs tied to a recent problem? This is a quick way to discover unique log data that is appearing for the first time in your environment. Does your log data have a new format? Sometimes the logs don't represent a problem, but a new format of log data that deviates from the data model you expect your applications to follow. Catching these logs early gives you the opportunity to ask developers to correct any deviations in their log output. The more consistent people are in the way log data is generated, the easier it becomes to use logs across a diverse set of teams. Masked attributes and wildcards Parts of the log messages in patterns are classified as variables and are substituted by masked attributes. The masking process supports and improves the clustering phase by allowing the algorithm to ignore changing details and focus on the repetitive structure. Masked attributes include: date_time ip url uuid Masked attributes are highlighted and are easy to identify, as shown in the following example. one.newrelic.com > Log management > Log patterns: Here is an example of a pattern that has masked attributes. Log patterns extract other less trivial variables that don't belong to any masked attribute. These variables are indicated as wildcards *. one.newrelic.com > Log management > Log patterns: Here is an example of how wildcards * group variables. Troubleshooting Here are a few reasons why you might have patterns enabled but not see any pattern data. If you're sure none of the items below are true, get help from support.newrelic.com. No data has arrived in the timeframe you're observing. Try expanding the time range you're viewing with the time picker. It's been less than 24 hours since patterns were enabled in the account. This means the ML model may not be generated for the account yet. None of the data coming in has a message field. Patterns will only be generated for values in the message field of a log record. If your logs don't contain message, there will be no data. Put the platform to work with patterns Patterns are a value that is enriched onto the existing log message as a new attribute named newrelic.logPattern. Anything you can do with logs generally can be done with log patterns, such as: Build your own dashboards with patterns, to monitor a specific pattern or group of patterns you care about. Create alerts for patterns by adding NRQL alerts. Use baseline alert conditions to detect anomalies in known log patterns.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 83.95293,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Discover value in <em>log</em> data with patterns",
        "sections": "Explore <em>logs</em> with no pattern",
        "tags": "<em>Logs</em>",
        "body": "<em>Log</em> patterns are the fastest way to discover value in <em>log</em> data without searching. <em>Log</em> data is high volume telemetry with a low value per individual record. Searching can quickly lead to <em>logs</em> that provide a root cause explanation, but most data is repetitive and hard to contextualize when browsing"
      },
      "id": "6072d46128ccbc244451c18b"
    },
    {
      "sections": [
        "Organize data with partitions",
        "Plan your partition",
        "Important",
        "Required roles and permissions",
        "Sizing and organizing a partition",
        "Choosing a namespace",
        "Create partition rules",
        "Search data partitions",
        "Manage data partitions programatically with NerdGraph"
      ],
      "title": "Organize data with partitions",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "28cac5fac1065f4b1756700e7f6c11c325734c35",
      "image": "https://docs.newrelic.com/static/7815845d8068377477aa26f8571d5907/c1b63/log-partitions-crop.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/data-partitions/",
      "published_at": "2021-07-02T14:35:27Z",
      "updated_at": "2021-07-02T14:35:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Data partitions are a way to group or organize log data for faster and more efficient querying. When a query targets a single partition, New Relic Logs: Scans less unrelated data. Returns results faster. Accounts can have multiple partitions, and multiple partitions can be queried at the same time. Data partitions also allow data to be mapped to an alternative, or “secondary” namespace with a fixed 30-day retention. This is useful for maintaining compliance with privacy-centric regulations and standards like the General Data Protection Regulation (GDPR). Plan your partition Before you start creating partitions, make sure you have the right permissions and a partition plan. Important Logs are routed to partitions during the ingestion process, before data is written to NRDB. Partition rules will not affect logs that were ingested before the rule was created. Required roles and permissions Users require an Admin role to create and modify partition rules. Sizing and organizing a partition You can gain significant performance improvements with proper use of data partitions. Organizing your data into discrete partitions enables you to query them separately or all together. The goals of partitioning your data should be: Create data partitions that align with concepts in your environment or organization that are static or change infrequently (for example, by business unit, team, environment, service, etc.). Ensure each partition remains below 1 TB of daily ingest for optimal performance. Having more partitions allows for more targeted searches, but creating too many partitions can make logs hard to find and increase administrative overhead. Finding the right balance is important. We support 100 partitions maximum per account, but the optimal number for most accounts is 10 to 15 partitions. Choosing a namespace A partition’s namespace determines its retention period. We offer two retention options: Standard: The account’s default retention determined by your New Relic subscription. This is the maximum retention period available in your account and is the namespace you'll select for most of your partitions. Secondary: 30-day retention. All logs sent to a partition that's a member of the Secondary namespace will be purged on a rolling basis 30 days after having been ingested. Secondary retention is not a cost control mechanism; data is billed on ingest. Create partition rules one.newrelic.com > Logs: From the left nav in the Logs UI, select Data partitions, then create a Log_ partition name with the retention namespace, optional description, and matching criteria. To create a new partition rule: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Data partitions, then click Create partition rule. Define a Partition name as an alphanumeric string that begins with Log_. Add an optional description. Select the retention namespace for the partition. Set your rule's Matching criteria: Select EQUALS to target logs that match your criteria exactly, or select LIKE to apply a fuzzy match. Click the Enable Rule slider, and click Create. To view a list of data partitions: From Manage Data on the left nav of the Logs UI, click Data partitions. Search data partitions The default partition for all Logs accounts is Log. Any log that is not affected by a partition rule will be stored in the Log partition by default. You can query multiple partitions simultaneously. For best performance, select the smallest number of partitions possible. To search data partitions: From Views and Attributes on the left nav of the Logs UI, click Select partitions. Click one or more partitions you want to query, or search for a partition name. Click Query logs to search your selected partitions. Manage data partitions programatically with NerdGraph If you want to manage your data partitions programatically, you can use NerdGraph, our graphQL API, to do so. This tutorial shows how to query, create, and delete data partitions using our API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 83.94725,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Logs</em>",
        "body": "Data partitions are a way to group or organize <em>log</em> data for faster and more efficient querying. When a query targets a single partition, New Relic <em>Logs</em>: Scans less unrelated data. Returns results faster. Accounts can have multiple partitions, and multiple partitions can be queried at the same time"
      },
      "id": "6087e311e7b9d2f90ba5c6a4"
    },
    {
      "sections": [
        "Use TCP endpoint to forward logs to New Relic",
        "Compatibility and requirements",
        "Important",
        "Configure rsyslog",
        "Legacy config file for rsyslog 7 or earlier",
        "Configure syslog-ng",
        "Tip"
      ],
      "title": "Use TCP endpoint to forward logs to New Relic",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Log API"
      ],
      "external_id": "3f572fe998dd7f72516a7b654295b779ff290176",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/log-api/use-tcp-endpoint-forward-logs-new-relic/",
      "published_at": "2021-07-02T14:33:44Z",
      "updated_at": "2021-06-25T22:58:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer a wide range of solutions to get your log data into New Relic. But in other situations where you don't have log forwarders (such as CDNs, hardware devices, or managed services), you can use syslog protocols via a TCP endpoint. You can forward your logs to New Relic using syslog clients such as rsyslog and syslog-ng. Compatibility and requirements To forward logs to New Relic using a syslog client, you need: A valid Insights API Insert key Some minor changes to the syslog client's configuration, as explained in this document Important Currently, our syslog endpoint only supports accounts in our US data center. Configure rsyslog To forward logs to New Relic with rsyslog: Install packages required to allow rsyslog to send logs using TLS encryption: sudo yum install rsyslog-gnutls ca-certificates Copy Optional: Configure rsyslog to tail log files and forward their contents to New Relic. Add the following to the /etc/rsyslog.conf file in order to enable its text file input module: module(load=\"imfile\" PollingInterval=\"10\" statefile.directory=\"/var/spool/rsyslog\" ) Copy In the /etc/rsyslog.d/ directory, create a text file named newrelic.conf. Explicitly include the newly created newrelic.conf to the /etc/rsyslog.d/ file: include(file=\"/etc/rsyslog.conf.d/newrelic.conf\") Copy Add the following to newrelic.conf, replacing YOUR_INSERT_KEY with your New Relic Insights API Insert key: ## Specify each of the files to be tailed in case step 1 is done input(type=\"imfile\" ruleset=\"infiles\" Tag=\"<YOUR_FILE_TAG>\" File=\"<PATH_TO_FILE>\" StateFile=\"<UNIQUE_STATEFILE_NAME >\") ## Template expected by the New Relic Syslog endpoint template(name=\"newrelic-rfc5424\" type=\"string\" string=\"<YOUR_INSERT_KEY> <%pri%>%protocol-version% %timestamp:::date-rfc3339% %hostname% %app-name% %procid% %msgid% %structured-data% %msg%\\n\" ) ## Configure TLS and log forwarding global(DefaultNetstreamDriver=\"gtls\" DefaultNetstreamDriverCAFile=\"/etc/ssl/certs/ca-certificates.crt\" ) action(type=\"omfwd\" Target=\"newrelic.syslog.nr-data.net\" Port=\"6514\" Protocol=\"tcp\" Template=\"newrelic-rfc5424\" ResendLastMSGOnReconnect=\"on\" StreamDriver=\"gtls\" StreamDriverAuthMode=\"x509/name\" StreamDriverPermittedPeers=\"*.syslog.nr-data.net\" StreamDriverMode=\"1\" ) Copy Restart the rsyslog service by running: sudo systemctl restart rsyslog Copy Check your New Relic account for logs. Legacy config file for rsyslog 7 or earlier If you are using rsyslog version 7 or below, the configuration files need to be adapted to the obsolete legacy format. This format is only kept for retro compatibility purposes. We strongly recommend to avoid using it, as stated in the rsyslog documentation. Install packages required to allow rsyslog to send logs using TLS encryption: sudo yum install rsyslog-gnutls ca-certificates Copy Optional: Configure rsyslog to tail log files and forward their contents to New Relic. Add the following to the /etc/rsyslog.conf file in order to enable its text file input module: $ModLoad imfile $InputFilePollInterval 10 $PrivDropToGroup adm $WorkDirectory /var/spool/rsyslog Copy In the /etc/rsyslog.d/ directory, create a text file named newrelic.conf. Explicitly include the newly created newrelic.conf to the /etc/rsyslog.d/ file: $IncludeConfig /etc/rsyslog.conf.d/newrelic.conf Copy Add the following to newrelic.conf, replacing YOUR_INSERT_KEY with your New Relic Insights API Insert key: ## Template expected by the New Relic Syslog endpoint $template NRLogFormat,\"YOUR_INSERT_KEY <%pri%>%protocol-version% %timestamp:::date-rfc3339% %hostname% %app-name% %procid% %msgid% %structured-data% %msg%\\n\" ## Specify each of the files to be tailed in case step 1 is done $InputFileName /path/to/file $InputFileTag <YOUR_FILE_TAG> $InputFileStateFile <UNIQUE_STATEFILE_NAME> $InputFileSeverity info $InputRunFileMonitor ## Configure TLS and log forwarding $DefaultNetstreamDriverCAFile /etc/ssl/certs/ca-certificates.crt $ActionSendStreamDriver gtls $ActionSendStreamDriverMode 1 $ActionSendStreamDriverAuthMode x509/name $ActionSendStreamDriverPermittedPeer *.syslog.nr-data.net *.* @@newrelic.syslog.nr-data.net:6514;NRLogFormat Copy Restart the rsyslog service by running: sudo systemctl restart rsyslog Copy Check your New Relic account for logs. Configure syslog-ng To forward logs to New Relic with syslog-ng: Install ca-certificates required to allow syslog-ng to send logs using TLS encryption: sudo yum install ca-certificates Copy Open the syslog-ng configuration file (/etc/syslog-ng/syslog-ng.conf) in a text editor. Define the sources to be monitored by adding: source s_src { internal(); }; Copy Optional: Configure syslog-ng to tail files by adding the following to the Sources configuration block: source s_files { file(\"<PATH_TO_FILE>\"); }; Copy Define the New Relic syslog format and add your New Relic Insights API Insert key: template NRFormat { template(\"YOUR_INSERT_KEY ${PRI}>1 ${ISODATE} ${HOST:--} ${PROGRAM:--} ${PID:--} ${MSGID:--} ${SDATA:--} $MSG\\n\"); template_escape(no); }; Copy Add the New Relic Syslog endpoint: destination d_newrelic { network(\"newrelic.syslog.nr-data.net\" port(6514) transport(\"tls\") tls(peer-verify(no)) template(NRFormat) ); }; Copy Add the following output to the log path configuration block: log { source(s_src); source(s_files); ## in case step 4 is implemented. destination(d_newrelic); }; Copy Restart syslog-ng by running: sudo service syslog-ng restart Copy Check your New Relic account for logs. Tip If you are running syslog-ng from a Docker container and experience issues, check balait/syslog image documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 74.41446,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use TCP endpoint to forward <em>logs</em> to New Relic",
        "sections": "Use TCP endpoint to forward <em>logs</em> to New Relic",
        "tags": "<em>Logs</em>",
        "body": "We offer a wide range of solutions to get your <em>log</em> data into New Relic. But in other situations where you don&#x27;t have <em>log</em> forwarders (such as CDNs, hardware devices, or managed services), you can use syslog protocols via a TCP endpoint. You can forward your <em>logs</em> to New Relic using syslog clients"
      },
      "id": "603e7d6764441f1a774e88a0"
    }
  ],
  "/docs/logs/log-management/get-started/get-started-log-management": [
    {
      "sections": [
        "Discover value in log data with patterns",
        "Technical overview",
        "Availability",
        "Important",
        "Get started",
        "Explore log patterns",
        "Explore logs with no pattern",
        "Masked attributes and wildcards",
        "Troubleshooting",
        "Put the platform to work with patterns"
      ],
      "title": "Discover value in log data with patterns",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "8f1e27c94327ca4888a945f8e12f9c2310ccd7a6",
      "image": "https://docs.newrelic.com/static/578d7186bb34352855696e5307cc82f2/c1b63/log-patterns-logs-without-a-pattern.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/find-unusual-logs-log-patterns/",
      "published_at": "2021-07-02T14:37:14Z",
      "updated_at": "2021-07-02T14:37:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Log patterns are the fastest way to discover value in log data without searching. Log data is high volume telemetry with a low value per individual record. Searching can quickly lead to logs that provide a root cause explanation, but most data is repetitive and hard to contextualize when browsing. Patterns can make log data discoverable without spending a lot of time reading through low value data. one.newrelic.com > Logs > Patterns: Use patterns as the basis for alerts when the frequency of important data changes, or for configuring drop rules to get rid of unnecessary repetitive data. Technical overview Log patterns functionality applies machine learning to normalize and group log messages that are consistent in format but variable in content. These grouped messages can be sorted, making it easy to find the most frequent or rarest sets of logs in your environment. Use patterns as the basis for alerts when the frequency of important data changes, or to configure drop rules to get rid of unnecessary repetitive data. Log patterns use advanced clustering algorithms to group together similar log messages automatically. With patterns, you can: Orient more quickly through millions of logs. Reduce the time it takes to identify unusual behavior in your log estate. Monitor the frequency of known patterns over time to focus your energy on what matters, and exclude what's irrelevant. Availability Important Log patterns are not available in the EU region. The ability to configure this feature is dependent on role-based permissions. If you see Patterns are turned off in your Log management Patterns UI, click the Configure Patterns button and enable it. If you don't see patterns within 30 minutes of enabling the feature, there may be a lack of data with a message attribute for the system to create a pattern from. Log patterns Limitations and considerations Pricing There is no separate pricing for log patterns. The only cost is for additional data generated and added to your log records. A pattern attribute will be added to all logs that match a pattern. Attributes also may be added when common values are discovered, such as GUIDs, IP addresses, URL, or email addresses. These attributes are automatically extracted from the log message as part of the pattern process. HITRUST accounts The log patterns feature is not FedRAMP compliant. FedRAMP or other HITRUST accounts are not eligible to use patterns. Regional availability Availability for this feature depends on whether you have a US or EU region account: US region accounts can use log patterns. EU region accounts cannot enable log patterns at this time. Parsing limits We have a system of safety limits on memory and CPU resources when processing logs and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com > Log management, and use the account picker dropdown to select the target account where you want to explore patterns. In the left navigation of the Log management UI, click Patterns. The main log UI changes to show patterns that match the query in the query bar. one.newrelic.com > Log management > Log patterns: The line chart shows the top 5 patterns over time. Use the time picker and query bar to adjust the results. Explore log patterns By default the log patterns UI first shows the most frequent occurrence of patterns. To sort to show the rarest patterns first, click the Count column. You can also use the query bar or attributes bar to filter your log patterns. If you want to... Do this... Understand the rate of change in patterns Look at the line chart. The color-coded patterns correspond to the plot column in the table. You can toggle individual plot patterns to narrow your focus. See the individual log messages that match each pattern Click pattern to expand the row and see a table of individual log records. To see additional records, scroll up or down. To explore an individual log in more detail, click it to open the details panel. Group and filter patterns by their attributes Use the query bar and time picker. As you apply different filters and time windows, the log patterns adjust to your new target data. Create an alert from a pattern Add the pattern to the query bar and run the query. Then click Create alert condition in the left nav. Troubleshoot log messages that haven't been clustered into a pattern Use the Logs with no pattern tab in the Log patterns UI. Clicking a specific log message will open the log message details panel you're familiar with from the Logs management page. Explore logs with no pattern The Logs with no pattern tab groups all recent log messages in your account that were not clustered into a known pattern yet. These log messages don't represent any problem or flaw in the system; they have no pattern because they are too new to have been processed by the machine learning system. This makes them valuable to explore when you want to understand what has recently changed in your environment. one.newrelic.com > Log management > Log patterns: New Relic's log patterns feature automatically groups logs without a matching pattern. For example: Are any of these logs tied to a recent problem? This is a quick way to discover unique log data that is appearing for the first time in your environment. Does your log data have a new format? Sometimes the logs don't represent a problem, but a new format of log data that deviates from the data model you expect your applications to follow. Catching these logs early gives you the opportunity to ask developers to correct any deviations in their log output. The more consistent people are in the way log data is generated, the easier it becomes to use logs across a diverse set of teams. Masked attributes and wildcards Parts of the log messages in patterns are classified as variables and are substituted by masked attributes. The masking process supports and improves the clustering phase by allowing the algorithm to ignore changing details and focus on the repetitive structure. Masked attributes include: date_time ip url uuid Masked attributes are highlighted and are easy to identify, as shown in the following example. one.newrelic.com > Log management > Log patterns: Here is an example of a pattern that has masked attributes. Log patterns extract other less trivial variables that don't belong to any masked attribute. These variables are indicated as wildcards *. one.newrelic.com > Log management > Log patterns: Here is an example of how wildcards * group variables. Troubleshooting Here are a few reasons why you might have patterns enabled but not see any pattern data. If you're sure none of the items below are true, get help from support.newrelic.com. No data has arrived in the timeframe you're observing. Try expanding the time range you're viewing with the time picker. It's been less than 24 hours since patterns were enabled in the account. This means the ML model may not be generated for the account yet. None of the data coming in has a message field. Patterns will only be generated for values in the message field of a log record. If your logs don't contain message, there will be no data. Put the platform to work with patterns Patterns are a value that is enriched onto the existing log message as a new attribute named newrelic.logPattern. Anything you can do with logs generally can be done with log patterns, such as: Build your own dashboards with patterns, to monitor a specific pattern or group of patterns you care about. Create alerts for patterns by adding NRQL alerts. Use baseline alert conditions to detect anomalies in known log patterns.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 215.49893,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Discover value in <em>log</em> data with patterns",
        "sections": "<em>Get</em> <em>started</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " and CPU resources when processing <em>logs</em> and their patterns. These parsing limits can have an impact on the data you <em>get</em>. For more information, see our documentation about parsing limits. <em>Get</em> <em>started</em> To <em>start</em> examining patterns: Go to one.newrelic.com &gt; <em>Log</em> <em>management</em>, and use the account picker dropdown"
      },
      "id": "6072d46128ccbc244451c18b"
    },
    {
      "sections": [
        "Organize data with partitions",
        "Plan your partition",
        "Important",
        "Required roles and permissions",
        "Sizing and organizing a partition",
        "Choosing a namespace",
        "Create partition rules",
        "Search data partitions",
        "Manage data partitions programatically with NerdGraph"
      ],
      "title": "Organize data with partitions",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "28cac5fac1065f4b1756700e7f6c11c325734c35",
      "image": "https://docs.newrelic.com/static/7815845d8068377477aa26f8571d5907/c1b63/log-partitions-crop.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/data-partitions/",
      "published_at": "2021-07-02T14:35:27Z",
      "updated_at": "2021-07-02T14:35:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Data partitions are a way to group or organize log data for faster and more efficient querying. When a query targets a single partition, New Relic Logs: Scans less unrelated data. Returns results faster. Accounts can have multiple partitions, and multiple partitions can be queried at the same time. Data partitions also allow data to be mapped to an alternative, or “secondary” namespace with a fixed 30-day retention. This is useful for maintaining compliance with privacy-centric regulations and standards like the General Data Protection Regulation (GDPR). Plan your partition Before you start creating partitions, make sure you have the right permissions and a partition plan. Important Logs are routed to partitions during the ingestion process, before data is written to NRDB. Partition rules will not affect logs that were ingested before the rule was created. Required roles and permissions Users require an Admin role to create and modify partition rules. Sizing and organizing a partition You can gain significant performance improvements with proper use of data partitions. Organizing your data into discrete partitions enables you to query them separately or all together. The goals of partitioning your data should be: Create data partitions that align with concepts in your environment or organization that are static or change infrequently (for example, by business unit, team, environment, service, etc.). Ensure each partition remains below 1 TB of daily ingest for optimal performance. Having more partitions allows for more targeted searches, but creating too many partitions can make logs hard to find and increase administrative overhead. Finding the right balance is important. We support 100 partitions maximum per account, but the optimal number for most accounts is 10 to 15 partitions. Choosing a namespace A partition’s namespace determines its retention period. We offer two retention options: Standard: The account’s default retention determined by your New Relic subscription. This is the maximum retention period available in your account and is the namespace you'll select for most of your partitions. Secondary: 30-day retention. All logs sent to a partition that's a member of the Secondary namespace will be purged on a rolling basis 30 days after having been ingested. Secondary retention is not a cost control mechanism; data is billed on ingest. Create partition rules one.newrelic.com > Logs: From the left nav in the Logs UI, select Data partitions, then create a Log_ partition name with the retention namespace, optional description, and matching criteria. To create a new partition rule: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Data partitions, then click Create partition rule. Define a Partition name as an alphanumeric string that begins with Log_. Add an optional description. Select the retention namespace for the partition. Set your rule's Matching criteria: Select EQUALS to target logs that match your criteria exactly, or select LIKE to apply a fuzzy match. Click the Enable Rule slider, and click Create. To view a list of data partitions: From Manage Data on the left nav of the Logs UI, click Data partitions. Search data partitions The default partition for all Logs accounts is Log. Any log that is not affected by a partition rule will be stored in the Log partition by default. You can query multiple partitions simultaneously. For best performance, select the smallest number of partitions possible. To search data partitions: From Views and Attributes on the left nav of the Logs UI, click Select partitions. Click one or more partitions you want to query, or search for a partition name. Click Query logs to search your selected partitions. Manage data partitions programatically with NerdGraph If you want to manage your data partitions programatically, you can use NerdGraph, our graphQL API, to do so. This tutorial shows how to query, create, and delete data partitions using our API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.79782,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Manage</em> data partitions programatically with NerdGraph",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Data partitions are a way to group or organize <em>log</em> data for faster and more efficient querying. When a query targets a single partition, New Relic <em>Logs</em>: Scans less unrelated data. Returns results faster. Accounts can have multiple partitions, and multiple partitions can be queried at the same time"
      },
      "id": "6087e311e7b9d2f90ba5c6a4"
    },
    {
      "sections": [
        "Use TCP endpoint to forward logs to New Relic",
        "Compatibility and requirements",
        "Important",
        "Configure rsyslog",
        "Legacy config file for rsyslog 7 or earlier",
        "Configure syslog-ng",
        "Tip"
      ],
      "title": "Use TCP endpoint to forward logs to New Relic",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Log API"
      ],
      "external_id": "3f572fe998dd7f72516a7b654295b779ff290176",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/log-api/use-tcp-endpoint-forward-logs-new-relic/",
      "published_at": "2021-07-02T14:33:44Z",
      "updated_at": "2021-06-25T22:58:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer a wide range of solutions to get your log data into New Relic. But in other situations where you don't have log forwarders (such as CDNs, hardware devices, or managed services), you can use syslog protocols via a TCP endpoint. You can forward your logs to New Relic using syslog clients such as rsyslog and syslog-ng. Compatibility and requirements To forward logs to New Relic using a syslog client, you need: A valid Insights API Insert key Some minor changes to the syslog client's configuration, as explained in this document Important Currently, our syslog endpoint only supports accounts in our US data center. Configure rsyslog To forward logs to New Relic with rsyslog: Install packages required to allow rsyslog to send logs using TLS encryption: sudo yum install rsyslog-gnutls ca-certificates Copy Optional: Configure rsyslog to tail log files and forward their contents to New Relic. Add the following to the /etc/rsyslog.conf file in order to enable its text file input module: module(load=\"imfile\" PollingInterval=\"10\" statefile.directory=\"/var/spool/rsyslog\" ) Copy In the /etc/rsyslog.d/ directory, create a text file named newrelic.conf. Explicitly include the newly created newrelic.conf to the /etc/rsyslog.d/ file: include(file=\"/etc/rsyslog.conf.d/newrelic.conf\") Copy Add the following to newrelic.conf, replacing YOUR_INSERT_KEY with your New Relic Insights API Insert key: ## Specify each of the files to be tailed in case step 1 is done input(type=\"imfile\" ruleset=\"infiles\" Tag=\"<YOUR_FILE_TAG>\" File=\"<PATH_TO_FILE>\" StateFile=\"<UNIQUE_STATEFILE_NAME >\") ## Template expected by the New Relic Syslog endpoint template(name=\"newrelic-rfc5424\" type=\"string\" string=\"<YOUR_INSERT_KEY> <%pri%>%protocol-version% %timestamp:::date-rfc3339% %hostname% %app-name% %procid% %msgid% %structured-data% %msg%\\n\" ) ## Configure TLS and log forwarding global(DefaultNetstreamDriver=\"gtls\" DefaultNetstreamDriverCAFile=\"/etc/ssl/certs/ca-certificates.crt\" ) action(type=\"omfwd\" Target=\"newrelic.syslog.nr-data.net\" Port=\"6514\" Protocol=\"tcp\" Template=\"newrelic-rfc5424\" ResendLastMSGOnReconnect=\"on\" StreamDriver=\"gtls\" StreamDriverAuthMode=\"x509/name\" StreamDriverPermittedPeers=\"*.syslog.nr-data.net\" StreamDriverMode=\"1\" ) Copy Restart the rsyslog service by running: sudo systemctl restart rsyslog Copy Check your New Relic account for logs. Legacy config file for rsyslog 7 or earlier If you are using rsyslog version 7 or below, the configuration files need to be adapted to the obsolete legacy format. This format is only kept for retro compatibility purposes. We strongly recommend to avoid using it, as stated in the rsyslog documentation. Install packages required to allow rsyslog to send logs using TLS encryption: sudo yum install rsyslog-gnutls ca-certificates Copy Optional: Configure rsyslog to tail log files and forward their contents to New Relic. Add the following to the /etc/rsyslog.conf file in order to enable its text file input module: $ModLoad imfile $InputFilePollInterval 10 $PrivDropToGroup adm $WorkDirectory /var/spool/rsyslog Copy In the /etc/rsyslog.d/ directory, create a text file named newrelic.conf. Explicitly include the newly created newrelic.conf to the /etc/rsyslog.d/ file: $IncludeConfig /etc/rsyslog.conf.d/newrelic.conf Copy Add the following to newrelic.conf, replacing YOUR_INSERT_KEY with your New Relic Insights API Insert key: ## Template expected by the New Relic Syslog endpoint $template NRLogFormat,\"YOUR_INSERT_KEY <%pri%>%protocol-version% %timestamp:::date-rfc3339% %hostname% %app-name% %procid% %msgid% %structured-data% %msg%\\n\" ## Specify each of the files to be tailed in case step 1 is done $InputFileName /path/to/file $InputFileTag <YOUR_FILE_TAG> $InputFileStateFile <UNIQUE_STATEFILE_NAME> $InputFileSeverity info $InputRunFileMonitor ## Configure TLS and log forwarding $DefaultNetstreamDriverCAFile /etc/ssl/certs/ca-certificates.crt $ActionSendStreamDriver gtls $ActionSendStreamDriverMode 1 $ActionSendStreamDriverAuthMode x509/name $ActionSendStreamDriverPermittedPeer *.syslog.nr-data.net *.* @@newrelic.syslog.nr-data.net:6514;NRLogFormat Copy Restart the rsyslog service by running: sudo systemctl restart rsyslog Copy Check your New Relic account for logs. Configure syslog-ng To forward logs to New Relic with syslog-ng: Install ca-certificates required to allow syslog-ng to send logs using TLS encryption: sudo yum install ca-certificates Copy Open the syslog-ng configuration file (/etc/syslog-ng/syslog-ng.conf) in a text editor. Define the sources to be monitored by adding: source s_src { internal(); }; Copy Optional: Configure syslog-ng to tail files by adding the following to the Sources configuration block: source s_files { file(\"<PATH_TO_FILE>\"); }; Copy Define the New Relic syslog format and add your New Relic Insights API Insert key: template NRFormat { template(\"YOUR_INSERT_KEY ${PRI}>1 ${ISODATE} ${HOST:--} ${PROGRAM:--} ${PID:--} ${MSGID:--} ${SDATA:--} $MSG\\n\"); template_escape(no); }; Copy Add the New Relic Syslog endpoint: destination d_newrelic { network(\"newrelic.syslog.nr-data.net\" port(6514) transport(\"tls\") tls(peer-verify(no)) template(NRFormat) ); }; Copy Add the following output to the log path configuration block: log { source(s_src); source(s_files); ## in case step 4 is implemented. destination(d_newrelic); }; Copy Restart syslog-ng by running: sudo service syslog-ng restart Copy Check your New Relic account for logs. Tip If you are running syslog-ng from a Docker container and experience issues, check balait/syslog image documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.16702,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use TCP endpoint to forward <em>logs</em> to New Relic",
        "sections": "Use TCP endpoint to forward <em>logs</em> to New Relic",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "We offer a wide range of solutions to <em>get</em> your <em>log</em> data into New Relic. But in other situations where you don&#x27;t have <em>log</em> forwarders (such as CDNs, hardware devices, or managed services), you can use syslog protocols via a TCP endpoint. You can forward your <em>logs</em> to New Relic using syslog clients"
      },
      "id": "603e7d6764441f1a774e88a0"
    }
  ],
  "/docs/logs/log-management/get-started/new-relics-log-management-security-privacy": [
    {
      "sections": [
        "Discover value in log data with patterns",
        "Technical overview",
        "Availability",
        "Important",
        "Get started",
        "Explore log patterns",
        "Explore logs with no pattern",
        "Masked attributes and wildcards",
        "Troubleshooting",
        "Put the platform to work with patterns"
      ],
      "title": "Discover value in log data with patterns",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "8f1e27c94327ca4888a945f8e12f9c2310ccd7a6",
      "image": "https://docs.newrelic.com/static/578d7186bb34352855696e5307cc82f2/c1b63/log-patterns-logs-without-a-pattern.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/find-unusual-logs-log-patterns/",
      "published_at": "2021-07-02T14:37:14Z",
      "updated_at": "2021-07-02T14:37:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Log patterns are the fastest way to discover value in log data without searching. Log data is high volume telemetry with a low value per individual record. Searching can quickly lead to logs that provide a root cause explanation, but most data is repetitive and hard to contextualize when browsing. Patterns can make log data discoverable without spending a lot of time reading through low value data. one.newrelic.com > Logs > Patterns: Use patterns as the basis for alerts when the frequency of important data changes, or for configuring drop rules to get rid of unnecessary repetitive data. Technical overview Log patterns functionality applies machine learning to normalize and group log messages that are consistent in format but variable in content. These grouped messages can be sorted, making it easy to find the most frequent or rarest sets of logs in your environment. Use patterns as the basis for alerts when the frequency of important data changes, or to configure drop rules to get rid of unnecessary repetitive data. Log patterns use advanced clustering algorithms to group together similar log messages automatically. With patterns, you can: Orient more quickly through millions of logs. Reduce the time it takes to identify unusual behavior in your log estate. Monitor the frequency of known patterns over time to focus your energy on what matters, and exclude what's irrelevant. Availability Important Log patterns are not available in the EU region. The ability to configure this feature is dependent on role-based permissions. If you see Patterns are turned off in your Log management Patterns UI, click the Configure Patterns button and enable it. If you don't see patterns within 30 minutes of enabling the feature, there may be a lack of data with a message attribute for the system to create a pattern from. Log patterns Limitations and considerations Pricing There is no separate pricing for log patterns. The only cost is for additional data generated and added to your log records. A pattern attribute will be added to all logs that match a pattern. Attributes also may be added when common values are discovered, such as GUIDs, IP addresses, URL, or email addresses. These attributes are automatically extracted from the log message as part of the pattern process. HITRUST accounts The log patterns feature is not FedRAMP compliant. FedRAMP or other HITRUST accounts are not eligible to use patterns. Regional availability Availability for this feature depends on whether you have a US or EU region account: US region accounts can use log patterns. EU region accounts cannot enable log patterns at this time. Parsing limits We have a system of safety limits on memory and CPU resources when processing logs and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com > Log management, and use the account picker dropdown to select the target account where you want to explore patterns. In the left navigation of the Log management UI, click Patterns. The main log UI changes to show patterns that match the query in the query bar. one.newrelic.com > Log management > Log patterns: The line chart shows the top 5 patterns over time. Use the time picker and query bar to adjust the results. Explore log patterns By default the log patterns UI first shows the most frequent occurrence of patterns. To sort to show the rarest patterns first, click the Count column. You can also use the query bar or attributes bar to filter your log patterns. If you want to... Do this... Understand the rate of change in patterns Look at the line chart. The color-coded patterns correspond to the plot column in the table. You can toggle individual plot patterns to narrow your focus. See the individual log messages that match each pattern Click pattern to expand the row and see a table of individual log records. To see additional records, scroll up or down. To explore an individual log in more detail, click it to open the details panel. Group and filter patterns by their attributes Use the query bar and time picker. As you apply different filters and time windows, the log patterns adjust to your new target data. Create an alert from a pattern Add the pattern to the query bar and run the query. Then click Create alert condition in the left nav. Troubleshoot log messages that haven't been clustered into a pattern Use the Logs with no pattern tab in the Log patterns UI. Clicking a specific log message will open the log message details panel you're familiar with from the Logs management page. Explore logs with no pattern The Logs with no pattern tab groups all recent log messages in your account that were not clustered into a known pattern yet. These log messages don't represent any problem or flaw in the system; they have no pattern because they are too new to have been processed by the machine learning system. This makes them valuable to explore when you want to understand what has recently changed in your environment. one.newrelic.com > Log management > Log patterns: New Relic's log patterns feature automatically groups logs without a matching pattern. For example: Are any of these logs tied to a recent problem? This is a quick way to discover unique log data that is appearing for the first time in your environment. Does your log data have a new format? Sometimes the logs don't represent a problem, but a new format of log data that deviates from the data model you expect your applications to follow. Catching these logs early gives you the opportunity to ask developers to correct any deviations in their log output. The more consistent people are in the way log data is generated, the easier it becomes to use logs across a diverse set of teams. Masked attributes and wildcards Parts of the log messages in patterns are classified as variables and are substituted by masked attributes. The masking process supports and improves the clustering phase by allowing the algorithm to ignore changing details and focus on the repetitive structure. Masked attributes include: date_time ip url uuid Masked attributes are highlighted and are easy to identify, as shown in the following example. one.newrelic.com > Log management > Log patterns: Here is an example of a pattern that has masked attributes. Log patterns extract other less trivial variables that don't belong to any masked attribute. These variables are indicated as wildcards *. one.newrelic.com > Log management > Log patterns: Here is an example of how wildcards * group variables. Troubleshooting Here are a few reasons why you might have patterns enabled but not see any pattern data. If you're sure none of the items below are true, get help from support.newrelic.com. No data has arrived in the timeframe you're observing. Try expanding the time range you're viewing with the time picker. It's been less than 24 hours since patterns were enabled in the account. This means the ML model may not be generated for the account yet. None of the data coming in has a message field. Patterns will only be generated for values in the message field of a log record. If your logs don't contain message, there will be no data. Put the platform to work with patterns Patterns are a value that is enriched onto the existing log message as a new attribute named newrelic.logPattern. Anything you can do with logs generally can be done with log patterns, such as: Build your own dashboards with patterns, to monitor a specific pattern or group of patterns you care about. Create alerts for patterns by adding NRQL alerts. Use baseline alert conditions to detect anomalies in known log patterns.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 215.4988,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Discover value in <em>log</em> data with patterns",
        "sections": "<em>Get</em> <em>started</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " and CPU resources when processing <em>logs</em> and their patterns. These parsing limits can have an impact on the data you <em>get</em>. For more information, see our documentation about parsing limits. <em>Get</em> <em>started</em> To <em>start</em> examining patterns: Go to one.newrelic.com &gt; <em>Log</em> <em>management</em>, and use the account picker dropdown"
      },
      "id": "6072d46128ccbc244451c18b"
    },
    {
      "sections": [
        "Organize data with partitions",
        "Plan your partition",
        "Important",
        "Required roles and permissions",
        "Sizing and organizing a partition",
        "Choosing a namespace",
        "Create partition rules",
        "Search data partitions",
        "Manage data partitions programatically with NerdGraph"
      ],
      "title": "Organize data with partitions",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "28cac5fac1065f4b1756700e7f6c11c325734c35",
      "image": "https://docs.newrelic.com/static/7815845d8068377477aa26f8571d5907/c1b63/log-partitions-crop.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/data-partitions/",
      "published_at": "2021-07-02T14:35:27Z",
      "updated_at": "2021-07-02T14:35:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Data partitions are a way to group or organize log data for faster and more efficient querying. When a query targets a single partition, New Relic Logs: Scans less unrelated data. Returns results faster. Accounts can have multiple partitions, and multiple partitions can be queried at the same time. Data partitions also allow data to be mapped to an alternative, or “secondary” namespace with a fixed 30-day retention. This is useful for maintaining compliance with privacy-centric regulations and standards like the General Data Protection Regulation (GDPR). Plan your partition Before you start creating partitions, make sure you have the right permissions and a partition plan. Important Logs are routed to partitions during the ingestion process, before data is written to NRDB. Partition rules will not affect logs that were ingested before the rule was created. Required roles and permissions Users require an Admin role to create and modify partition rules. Sizing and organizing a partition You can gain significant performance improvements with proper use of data partitions. Organizing your data into discrete partitions enables you to query them separately or all together. The goals of partitioning your data should be: Create data partitions that align with concepts in your environment or organization that are static or change infrequently (for example, by business unit, team, environment, service, etc.). Ensure each partition remains below 1 TB of daily ingest for optimal performance. Having more partitions allows for more targeted searches, but creating too many partitions can make logs hard to find and increase administrative overhead. Finding the right balance is important. We support 100 partitions maximum per account, but the optimal number for most accounts is 10 to 15 partitions. Choosing a namespace A partition’s namespace determines its retention period. We offer two retention options: Standard: The account’s default retention determined by your New Relic subscription. This is the maximum retention period available in your account and is the namespace you'll select for most of your partitions. Secondary: 30-day retention. All logs sent to a partition that's a member of the Secondary namespace will be purged on a rolling basis 30 days after having been ingested. Secondary retention is not a cost control mechanism; data is billed on ingest. Create partition rules one.newrelic.com > Logs: From the left nav in the Logs UI, select Data partitions, then create a Log_ partition name with the retention namespace, optional description, and matching criteria. To create a new partition rule: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Data partitions, then click Create partition rule. Define a Partition name as an alphanumeric string that begins with Log_. Add an optional description. Select the retention namespace for the partition. Set your rule's Matching criteria: Select EQUALS to target logs that match your criteria exactly, or select LIKE to apply a fuzzy match. Click the Enable Rule slider, and click Create. To view a list of data partitions: From Manage Data on the left nav of the Logs UI, click Data partitions. Search data partitions The default partition for all Logs accounts is Log. Any log that is not affected by a partition rule will be stored in the Log partition by default. You can query multiple partitions simultaneously. For best performance, select the smallest number of partitions possible. To search data partitions: From Views and Attributes on the left nav of the Logs UI, click Select partitions. Click one or more partitions you want to query, or search for a partition name. Click Query logs to search your selected partitions. Manage data partitions programatically with NerdGraph If you want to manage your data partitions programatically, you can use NerdGraph, our graphQL API, to do so. This tutorial shows how to query, create, and delete data partitions using our API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.7977,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Manage</em> data partitions programatically with NerdGraph",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Data partitions are a way to group or organize <em>log</em> data for faster and more efficient querying. When a query targets a single partition, New Relic <em>Logs</em>: Scans less unrelated data. Returns results faster. Accounts can have multiple partitions, and multiple partitions can be queried at the same time"
      },
      "id": "6087e311e7b9d2f90ba5c6a4"
    },
    {
      "sections": [
        "Get started with log management",
        "Tip",
        "Why New Relic for log management?",
        "Log management features",
        "Bring in your logging data",
        "View your logging data in New Relic"
      ],
      "title": "Get started with log management",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Get started"
      ],
      "external_id": "77761091d3c83970c78e92210970ade2a7441df9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/get-started/get-started-log-management/",
      "published_at": "2021-07-02T14:32:42Z",
      "updated_at": "2021-06-20T15:00:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a fast, scalable log management platform that allows you to connect your logs with the rest of your telemetry and infrastructure data. Tip To use log management and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Why New Relic for log management? As applications move towards the cloud, microservices architecture is becoming more dispersed, making the ability to monitor logs essential. Log management provides deeper visibility into application and infrastructure performance data (events and errors) to reduce mean-time-to-resolve (MTTR) and quickly troubleshoot production incidents. It does this by providing super-fast searching capabilities, alerts, and co-location of application, infrastructure, and log data, while visualizing everything from a single pane of glass. Log management features Log management provides a way to connect your log data with the rest of your application and infrastructure data, allowing you to get to the root cause of problems quickly, without losing context switching between tools. Log management's features include: Instantly search through your logs. Visualize your log data directly from the Logs UI. Use logging data to create custom charts, dashboards, and alerts. Troubleshoot performance issues without switching between tools. Bring in your logging data You can bring your log data into New Relic using a compatible log forwarding plugin, or with OpenTelemetry. Forward your logs using our Infrastructure agent or our Kubernetes plugin. Use our plugins for well-known log forwarders, like Fluentd, Fluent Bit, and Logstash. Stream or ship your logs from Amazon using AWS Lambda or Kinesis. Send your logs data using the Logs API. Once log management is enabled, you can also connect your logs with your APM agent, Kubernetes clusters, or distributed tracing to get additional contextual logging data with our logs in context extensions. View your logging data in New Relic Logging data can be found in these locations: In our Logs UI: Logs UI for US Logs UI for EU By querying the Log data type. For example, you can use NRQL to run: SELECT * FROM Log Copy For information on querying in general, see Query your data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.67647,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> <em>started</em> with <em>log</em> <em>management</em>",
        "sections": "<em>Get</em> <em>started</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " your <em>logs</em> data using the <em>Logs</em> API. Once <em>log</em> <em>management</em> is enabled, you can also connect your <em>logs</em> with your APM agent, Kubernetes clusters, or distributed tracing to <em>get</em> additional contextual logging data with our <em>logs</em> in context extensions. View your logging data in New Relic Logging data can"
      },
      "id": "603ea62ee7b9d249432a07e2"
    }
  ],
  "/docs/logs/log-management/log-api/introduction-log-api": [
    {
      "sections": [
        "Use TCP endpoint to forward logs to New Relic",
        "Compatibility and requirements",
        "Important",
        "Configure rsyslog",
        "Legacy config file for rsyslog 7 or earlier",
        "Configure syslog-ng",
        "Tip"
      ],
      "title": "Use TCP endpoint to forward logs to New Relic",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Log API"
      ],
      "external_id": "3f572fe998dd7f72516a7b654295b779ff290176",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/log-api/use-tcp-endpoint-forward-logs-new-relic/",
      "published_at": "2021-07-02T14:33:44Z",
      "updated_at": "2021-06-25T22:58:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer a wide range of solutions to get your log data into New Relic. But in other situations where you don't have log forwarders (such as CDNs, hardware devices, or managed services), you can use syslog protocols via a TCP endpoint. You can forward your logs to New Relic using syslog clients such as rsyslog and syslog-ng. Compatibility and requirements To forward logs to New Relic using a syslog client, you need: A valid Insights API Insert key Some minor changes to the syslog client's configuration, as explained in this document Important Currently, our syslog endpoint only supports accounts in our US data center. Configure rsyslog To forward logs to New Relic with rsyslog: Install packages required to allow rsyslog to send logs using TLS encryption: sudo yum install rsyslog-gnutls ca-certificates Copy Optional: Configure rsyslog to tail log files and forward their contents to New Relic. Add the following to the /etc/rsyslog.conf file in order to enable its text file input module: module(load=\"imfile\" PollingInterval=\"10\" statefile.directory=\"/var/spool/rsyslog\" ) Copy In the /etc/rsyslog.d/ directory, create a text file named newrelic.conf. Explicitly include the newly created newrelic.conf to the /etc/rsyslog.d/ file: include(file=\"/etc/rsyslog.conf.d/newrelic.conf\") Copy Add the following to newrelic.conf, replacing YOUR_INSERT_KEY with your New Relic Insights API Insert key: ## Specify each of the files to be tailed in case step 1 is done input(type=\"imfile\" ruleset=\"infiles\" Tag=\"<YOUR_FILE_TAG>\" File=\"<PATH_TO_FILE>\" StateFile=\"<UNIQUE_STATEFILE_NAME >\") ## Template expected by the New Relic Syslog endpoint template(name=\"newrelic-rfc5424\" type=\"string\" string=\"<YOUR_INSERT_KEY> <%pri%>%protocol-version% %timestamp:::date-rfc3339% %hostname% %app-name% %procid% %msgid% %structured-data% %msg%\\n\" ) ## Configure TLS and log forwarding global(DefaultNetstreamDriver=\"gtls\" DefaultNetstreamDriverCAFile=\"/etc/ssl/certs/ca-certificates.crt\" ) action(type=\"omfwd\" Target=\"newrelic.syslog.nr-data.net\" Port=\"6514\" Protocol=\"tcp\" Template=\"newrelic-rfc5424\" ResendLastMSGOnReconnect=\"on\" StreamDriver=\"gtls\" StreamDriverAuthMode=\"x509/name\" StreamDriverPermittedPeers=\"*.syslog.nr-data.net\" StreamDriverMode=\"1\" ) Copy Restart the rsyslog service by running: sudo systemctl restart rsyslog Copy Check your New Relic account for logs. Legacy config file for rsyslog 7 or earlier If you are using rsyslog version 7 or below, the configuration files need to be adapted to the obsolete legacy format. This format is only kept for retro compatibility purposes. We strongly recommend to avoid using it, as stated in the rsyslog documentation. Install packages required to allow rsyslog to send logs using TLS encryption: sudo yum install rsyslog-gnutls ca-certificates Copy Optional: Configure rsyslog to tail log files and forward their contents to New Relic. Add the following to the /etc/rsyslog.conf file in order to enable its text file input module: $ModLoad imfile $InputFilePollInterval 10 $PrivDropToGroup adm $WorkDirectory /var/spool/rsyslog Copy In the /etc/rsyslog.d/ directory, create a text file named newrelic.conf. Explicitly include the newly created newrelic.conf to the /etc/rsyslog.d/ file: $IncludeConfig /etc/rsyslog.conf.d/newrelic.conf Copy Add the following to newrelic.conf, replacing YOUR_INSERT_KEY with your New Relic Insights API Insert key: ## Template expected by the New Relic Syslog endpoint $template NRLogFormat,\"YOUR_INSERT_KEY <%pri%>%protocol-version% %timestamp:::date-rfc3339% %hostname% %app-name% %procid% %msgid% %structured-data% %msg%\\n\" ## Specify each of the files to be tailed in case step 1 is done $InputFileName /path/to/file $InputFileTag <YOUR_FILE_TAG> $InputFileStateFile <UNIQUE_STATEFILE_NAME> $InputFileSeverity info $InputRunFileMonitor ## Configure TLS and log forwarding $DefaultNetstreamDriverCAFile /etc/ssl/certs/ca-certificates.crt $ActionSendStreamDriver gtls $ActionSendStreamDriverMode 1 $ActionSendStreamDriverAuthMode x509/name $ActionSendStreamDriverPermittedPeer *.syslog.nr-data.net *.* @@newrelic.syslog.nr-data.net:6514;NRLogFormat Copy Restart the rsyslog service by running: sudo systemctl restart rsyslog Copy Check your New Relic account for logs. Configure syslog-ng To forward logs to New Relic with syslog-ng: Install ca-certificates required to allow syslog-ng to send logs using TLS encryption: sudo yum install ca-certificates Copy Open the syslog-ng configuration file (/etc/syslog-ng/syslog-ng.conf) in a text editor. Define the sources to be monitored by adding: source s_src { internal(); }; Copy Optional: Configure syslog-ng to tail files by adding the following to the Sources configuration block: source s_files { file(\"<PATH_TO_FILE>\"); }; Copy Define the New Relic syslog format and add your New Relic Insights API Insert key: template NRFormat { template(\"YOUR_INSERT_KEY ${PRI}>1 ${ISODATE} ${HOST:--} ${PROGRAM:--} ${PID:--} ${MSGID:--} ${SDATA:--} $MSG\\n\"); template_escape(no); }; Copy Add the New Relic Syslog endpoint: destination d_newrelic { network(\"newrelic.syslog.nr-data.net\" port(6514) transport(\"tls\") tls(peer-verify(no)) template(NRFormat) ); }; Copy Add the following output to the log path configuration block: log { source(s_src); source(s_files); ## in case step 4 is implemented. destination(d_newrelic); }; Copy Restart syslog-ng by running: sudo service syslog-ng restart Copy Check your New Relic account for logs. Tip If you are running syslog-ng from a Docker container and experience issues, check balait/syslog image documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 240.61713,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use TCP endpoint to forward <em>logs</em> to New Relic",
        "sections": "Use TCP endpoint to forward <em>logs</em> to New Relic",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "We offer a wide range of solutions to get your <em>log</em> data into New Relic. But in other situations where you don&#x27;t have <em>log</em> forwarders (such as CDNs, hardware devices, or managed services), you can use syslog protocols via a TCP endpoint. You can forward your <em>logs</em> to New Relic using syslog clients"
      },
      "id": "603e7d6764441f1a774e88a0"
    },
    {
      "sections": [
        "Discover value in log data with patterns",
        "Technical overview",
        "Availability",
        "Important",
        "Get started",
        "Explore log patterns",
        "Explore logs with no pattern",
        "Masked attributes and wildcards",
        "Troubleshooting",
        "Put the platform to work with patterns"
      ],
      "title": "Discover value in log data with patterns",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "8f1e27c94327ca4888a945f8e12f9c2310ccd7a6",
      "image": "https://docs.newrelic.com/static/578d7186bb34352855696e5307cc82f2/c1b63/log-patterns-logs-without-a-pattern.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/find-unusual-logs-log-patterns/",
      "published_at": "2021-07-02T14:37:14Z",
      "updated_at": "2021-07-02T14:37:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Log patterns are the fastest way to discover value in log data without searching. Log data is high volume telemetry with a low value per individual record. Searching can quickly lead to logs that provide a root cause explanation, but most data is repetitive and hard to contextualize when browsing. Patterns can make log data discoverable without spending a lot of time reading through low value data. one.newrelic.com > Logs > Patterns: Use patterns as the basis for alerts when the frequency of important data changes, or for configuring drop rules to get rid of unnecessary repetitive data. Technical overview Log patterns functionality applies machine learning to normalize and group log messages that are consistent in format but variable in content. These grouped messages can be sorted, making it easy to find the most frequent or rarest sets of logs in your environment. Use patterns as the basis for alerts when the frequency of important data changes, or to configure drop rules to get rid of unnecessary repetitive data. Log patterns use advanced clustering algorithms to group together similar log messages automatically. With patterns, you can: Orient more quickly through millions of logs. Reduce the time it takes to identify unusual behavior in your log estate. Monitor the frequency of known patterns over time to focus your energy on what matters, and exclude what's irrelevant. Availability Important Log patterns are not available in the EU region. The ability to configure this feature is dependent on role-based permissions. If you see Patterns are turned off in your Log management Patterns UI, click the Configure Patterns button and enable it. If you don't see patterns within 30 minutes of enabling the feature, there may be a lack of data with a message attribute for the system to create a pattern from. Log patterns Limitations and considerations Pricing There is no separate pricing for log patterns. The only cost is for additional data generated and added to your log records. A pattern attribute will be added to all logs that match a pattern. Attributes also may be added when common values are discovered, such as GUIDs, IP addresses, URL, or email addresses. These attributes are automatically extracted from the log message as part of the pattern process. HITRUST accounts The log patterns feature is not FedRAMP compliant. FedRAMP or other HITRUST accounts are not eligible to use patterns. Regional availability Availability for this feature depends on whether you have a US or EU region account: US region accounts can use log patterns. EU region accounts cannot enable log patterns at this time. Parsing limits We have a system of safety limits on memory and CPU resources when processing logs and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com > Log management, and use the account picker dropdown to select the target account where you want to explore patterns. In the left navigation of the Log management UI, click Patterns. The main log UI changes to show patterns that match the query in the query bar. one.newrelic.com > Log management > Log patterns: The line chart shows the top 5 patterns over time. Use the time picker and query bar to adjust the results. Explore log patterns By default the log patterns UI first shows the most frequent occurrence of patterns. To sort to show the rarest patterns first, click the Count column. You can also use the query bar or attributes bar to filter your log patterns. If you want to... Do this... Understand the rate of change in patterns Look at the line chart. The color-coded patterns correspond to the plot column in the table. You can toggle individual plot patterns to narrow your focus. See the individual log messages that match each pattern Click pattern to expand the row and see a table of individual log records. To see additional records, scroll up or down. To explore an individual log in more detail, click it to open the details panel. Group and filter patterns by their attributes Use the query bar and time picker. As you apply different filters and time windows, the log patterns adjust to your new target data. Create an alert from a pattern Add the pattern to the query bar and run the query. Then click Create alert condition in the left nav. Troubleshoot log messages that haven't been clustered into a pattern Use the Logs with no pattern tab in the Log patterns UI. Clicking a specific log message will open the log message details panel you're familiar with from the Logs management page. Explore logs with no pattern The Logs with no pattern tab groups all recent log messages in your account that were not clustered into a known pattern yet. These log messages don't represent any problem or flaw in the system; they have no pattern because they are too new to have been processed by the machine learning system. This makes them valuable to explore when you want to understand what has recently changed in your environment. one.newrelic.com > Log management > Log patterns: New Relic's log patterns feature automatically groups logs without a matching pattern. For example: Are any of these logs tied to a recent problem? This is a quick way to discover unique log data that is appearing for the first time in your environment. Does your log data have a new format? Sometimes the logs don't represent a problem, but a new format of log data that deviates from the data model you expect your applications to follow. Catching these logs early gives you the opportunity to ask developers to correct any deviations in their log output. The more consistent people are in the way log data is generated, the easier it becomes to use logs across a diverse set of teams. Masked attributes and wildcards Parts of the log messages in patterns are classified as variables and are substituted by masked attributes. The masking process supports and improves the clustering phase by allowing the algorithm to ignore changing details and focus on the repetitive structure. Masked attributes include: date_time ip url uuid Masked attributes are highlighted and are easy to identify, as shown in the following example. one.newrelic.com > Log management > Log patterns: Here is an example of a pattern that has masked attributes. Log patterns extract other less trivial variables that don't belong to any masked attribute. These variables are indicated as wildcards *. one.newrelic.com > Log management > Log patterns: Here is an example of how wildcards * group variables. Troubleshooting Here are a few reasons why you might have patterns enabled but not see any pattern data. If you're sure none of the items below are true, get help from support.newrelic.com. No data has arrived in the timeframe you're observing. Try expanding the time range you're viewing with the time picker. It's been less than 24 hours since patterns were enabled in the account. This means the ML model may not be generated for the account yet. None of the data coming in has a message field. Patterns will only be generated for values in the message field of a log record. If your logs don't contain message, there will be no data. Put the platform to work with patterns Patterns are a value that is enriched onto the existing log message as a new attribute named newrelic.logPattern. Anything you can do with logs generally can be done with log patterns, such as: Build your own dashboards with patterns, to monitor a specific pattern or group of patterns you care about. Create alerts for patterns by adding NRQL alerts. Use baseline alert conditions to detect anomalies in known log patterns.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.14047,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Discover value in <em>log</em> data with patterns",
        "sections": "Explore <em>logs</em> with no pattern",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " and CPU resources when processing <em>logs</em> and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com &gt; <em>Log</em> <em>management</em>, and use the account picker dropdown"
      },
      "id": "6072d46128ccbc244451c18b"
    },
    {
      "sections": [
        "Organize data with partitions",
        "Plan your partition",
        "Important",
        "Required roles and permissions",
        "Sizing and organizing a partition",
        "Choosing a namespace",
        "Create partition rules",
        "Search data partitions",
        "Manage data partitions programatically with NerdGraph"
      ],
      "title": "Organize data with partitions",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "28cac5fac1065f4b1756700e7f6c11c325734c35",
      "image": "https://docs.newrelic.com/static/7815845d8068377477aa26f8571d5907/c1b63/log-partitions-crop.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/data-partitions/",
      "published_at": "2021-07-02T14:35:27Z",
      "updated_at": "2021-07-02T14:35:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Data partitions are a way to group or organize log data for faster and more efficient querying. When a query targets a single partition, New Relic Logs: Scans less unrelated data. Returns results faster. Accounts can have multiple partitions, and multiple partitions can be queried at the same time. Data partitions also allow data to be mapped to an alternative, or “secondary” namespace with a fixed 30-day retention. This is useful for maintaining compliance with privacy-centric regulations and standards like the General Data Protection Regulation (GDPR). Plan your partition Before you start creating partitions, make sure you have the right permissions and a partition plan. Important Logs are routed to partitions during the ingestion process, before data is written to NRDB. Partition rules will not affect logs that were ingested before the rule was created. Required roles and permissions Users require an Admin role to create and modify partition rules. Sizing and organizing a partition You can gain significant performance improvements with proper use of data partitions. Organizing your data into discrete partitions enables you to query them separately or all together. The goals of partitioning your data should be: Create data partitions that align with concepts in your environment or organization that are static or change infrequently (for example, by business unit, team, environment, service, etc.). Ensure each partition remains below 1 TB of daily ingest for optimal performance. Having more partitions allows for more targeted searches, but creating too many partitions can make logs hard to find and increase administrative overhead. Finding the right balance is important. We support 100 partitions maximum per account, but the optimal number for most accounts is 10 to 15 partitions. Choosing a namespace A partition’s namespace determines its retention period. We offer two retention options: Standard: The account’s default retention determined by your New Relic subscription. This is the maximum retention period available in your account and is the namespace you'll select for most of your partitions. Secondary: 30-day retention. All logs sent to a partition that's a member of the Secondary namespace will be purged on a rolling basis 30 days after having been ingested. Secondary retention is not a cost control mechanism; data is billed on ingest. Create partition rules one.newrelic.com > Logs: From the left nav in the Logs UI, select Data partitions, then create a Log_ partition name with the retention namespace, optional description, and matching criteria. To create a new partition rule: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Data partitions, then click Create partition rule. Define a Partition name as an alphanumeric string that begins with Log_. Add an optional description. Select the retention namespace for the partition. Set your rule's Matching criteria: Select EQUALS to target logs that match your criteria exactly, or select LIKE to apply a fuzzy match. Click the Enable Rule slider, and click Create. To view a list of data partitions: From Manage Data on the left nav of the Logs UI, click Data partitions. Search data partitions The default partition for all Logs accounts is Log. Any log that is not affected by a partition rule will be stored in the Log partition by default. You can query multiple partitions simultaneously. For best performance, select the smallest number of partitions possible. To search data partitions: From Views and Attributes on the left nav of the Logs UI, click Select partitions. Click one or more partitions you want to query, or search for a partition name. Click Query logs to search your selected partitions. Manage data partitions programatically with NerdGraph If you want to manage your data partitions programatically, you can use NerdGraph, our graphQL API, to do so. This tutorial shows how to query, create, and delete data partitions using our API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.1279,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Manage</em> data partitions programatically with NerdGraph",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Data partitions are a way to group or organize <em>log</em> data for faster and more efficient querying. When a query targets a single partition, New Relic <em>Logs</em>: Scans less unrelated data. Returns results faster. Accounts can have multiple partitions, and multiple partitions can be queried at the same time"
      },
      "id": "6087e311e7b9d2f90ba5c6a4"
    }
  ],
  "/docs/logs/log-management/log-api/use-tcp-endpoint-forward-logs-new-relic": [
    {
      "sections": [
        "Introduction to the Log API",
        "Compatibility and requirements",
        "Tip",
        "HTTP setup",
        "HTTP headers",
        "JSON body",
        "Simplified JSON body message",
        "Detailed JSON body message",
        "Limits and restricted characters",
        "Caution",
        "Rate limit violations",
        "HTTP requests per minute",
        "JSON bytes per minute",
        "Log payload format",
        "Important",
        "JSON message attributes",
        "Common block attributes",
        "Logs block attributes",
        "JSON message attribute parsing",
        "Log JSON example",
        "Log POST example",
        "Example of stored common block attributes:",
        "Example of stored logs block attributes example:",
        "HTTP endpoint",
        "Find log data",
        "What's next?"
      ],
      "title": "Introduction to the Log API",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Log API"
      ],
      "external_id": "198ebbf54f4a13fdf2f5b0f19d8cc8677afd09a2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/log-api/introduction-log-api/",
      "published_at": "2021-07-02T14:32:44Z",
      "updated_at": "2021-06-20T15:00:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If our logging solutions don't meet your needs, you can use our Log API to send log data directly to New Relic's Log management via an HTTP endpoint. Compatibility and requirements Requirements include: New Relic license key (recommended) or an Insert API key. For payload details, see limits and restricted characters. Tip To use APIs and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. HTTP setup To send log data to your New Relic account: Get your New Relic license key (recommended) or register an Insert API key. Generate the JSON message using the required headers and body fields. Submit the JSON message to the HTTP endpoint in a POST request. Generate some traffic and wait a few minutes, then check your account for data. HTTP headers When creating your HTTP headers, use these guidelines: Header Supported values Content-Type Required application/json json application/gzip gzip Exactly one of: Api-Key or X-License-Key Required Use either your New Relic Insert API key (with Api-Key) or license key (with X-License-Key). Gzipped JSON formatting is accepted. If sending compressed JSON, please include the Content-Type: application/json and Content-Encoding: gzip headers. JSON body You can send your JSON message using either a simplified or detailed set of attributes: Simplified JSON body message When using the simplified format to create your JSON message, send a single JSON object with the following: Field Value type Format Required Notes \"timestamp\" Integer Either milliseconds or seconds since epoch No If the field is not specific as millisecond or seconds since epoch, the message will be timestamped using the ingest time \"message\" String any string No This is the main log message field that is searched by default \"logtype\" String any string No Primary field for identifying logs and matching parsing rules other_fields (must not contain white space) String any string No These will become attributes of the log message Note: Log management does not support white space in attribute names Detailed JSON body message When using the detailed format to create your body, it must be a JSON array containing one or more JSON objects, each of which with the following format: Field Value type Format Required Notes \"common\" Object See common. No Any attributes that are common to all log messages \"logs\" Array See logs. Yes Array with the log entries Limits and restricted characters Caution Avoid calling our API from within the code of a customer-facing application. This could cause performance issues or be blocking if response time is slow. If you must do this, try to do it asynchronously. Restrictions on logs sent to the Log API: Payload total size: 1MB(10^6 bytes) maximum per POST. We highly recommend using compression. The payload must be encoded as UTF-8. Number of attributes per event: 255 maximum Length of attribute name: 255 characters Length of attribute value: 4096 maximum character length Some specific attributes have additional restrictions: accountId: This is a reserved attribute name. If it is included, it will be dropped during ingest. entity.guid, entity.name, and entity.type: These attributes are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis. appId: Value must be an integer. If it is not an integer, the attribute name and value will be dropped during ingest. eventType: Can be a combination of alphanumeric characters, _ underscores, and : colons. timestamp: Must be a Unix epoch timestamp. You can define timestamps either in seconds or in milliseconds. Rate limits on logs sent to the Log API: Maximum rate for HTTP requests sent to the Log API: 300,000 requests per minute Maximum rate of uncompressed Log JSON bytes sent to the Log API: 10 GB per minute Rate limit violations Exceeding rate limits affects how the Log API behaves. Follow these instructions if this happens. HTTP requests per minute When the maximum request rate limit is exceeded for an account, the New Relic Log API returns a 429 response for the remainder of the minute. This response includes a Retry-After header indicating how long to wait in seconds before resubmitting or sending new data. To resolve this issue, either reduce the number of data points you are sending, or request a rate limit change. Subsequent subscription changes do not impact modified rate limits. If an account change impacts your rate limit, you must notify us to adjust your rate limit. To request rate limit changes, contact your New Relic account representative, or visit our Support portal. JSON bytes per minute When the maximum Log JSON byte limit is exceeded for an account, the New Relic Log API returns a 429 response for the remainder of the minute. This response includes a Retry-After header indicating how long to wait in seconds before resubmitting or sending new data. To resolve this issue, try to reduce the amount of log data you are sending, or spread it out over a larger period of time. To request rate limit changes, contact your New Relic account representative, or visit our Support portal. Log payload format We accept any valid JSON payload. The payload must encoded as UTF-8. Important Log management does not support white space in attribute names. For example, {\"Sample Attribute\": \"Value\"} would cause errors. JSON message attributes Common block attributes This is a block containing attributes that will be common to all log entries in logs: Field Value type Format Required Notes \"timestamp\" Integer Milliseconds or seconds since epoch No Message timestamp default to ingest time \"attributes\" Object JSON No This sub-object contains all other attributes of the message Logs block attributes This is an array containing log entries with the following format: Field Value type Format Required Notes \"timestamp\" Integer Milliseconds or seconds since epoch No Message timestamp default to ingest time \"attributes\" Object JSON No This sub-object contains all other attributes of the message \"message\" String (any string) Yes This is the main log message field that is searched by default \"log\" String (any string) No We will rewrite this string as the field message on ingest \"LOG\" String (any string) No We will rewrite this string as the field message on ingest \"MESSAGE\" String (any string) No We will rewrite this string as the field message on ingest JSON message attribute parsing This will attempt to parse any message attribute as JSON. If the message attribute is JSON, it will be parsed and the resultant JSON attributes will be added to the event. If the message attribute is not JSON, it is left as is. For example, the event: { \"timestamp\": 1562767499238, \"message\": \"{\\\"service-name\\\": \\\"login-service\\\", \\\"user\\\": {\\\"id\\\": 123, \\\"name\\\": \\\"alice\\\"}}\" } Copy Will be treated as: { \"timestamp\": 1562767499238, \"message\": \"{\\\"service-name\\\": \\\"my-service\\\", \\\"user\\\": {\\\"id\\\": 123, \\\"name\\\": \\\"alice\\\"}}\", \"service-name\": \"login-service\", \"user\": { \"id\": 123, \"name\": \"alice\" } } Copy Important Log management does not support white space in attribute names. For example, {\"Sample Attribute\": \"Value\"} would cause errors. Log JSON example Attributes may be scalar JSON types like string and number, but may also be compound (or nested) objects. Compound attributes will have their leaf attributes stored with flattened names. For instance, a compound user attribute in a log entry's attributes: \"attributes\": { \"action\": \"login\", \"user\": { \"id\": 123, \"name\": \"alice\" } } Copy will result in the following attributes being stored with the log event: Attribute Value \"action\" \"login\" \"user.id\" 123 \"user.name\" \"alice\" Log POST example Log POST message example: POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: <YOUR_LICENSE_KEY> Accept: */* Content-Length: 319 [{ \"common\": { \"attributes\": { \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } }, \"logs\": [{ \"timestamp\": <TIMESTAMP_IN_UNIX_EPOCH>, \"message\": \"User 'xyz' logged in\" },{ \"timestamp\": <TIMESTAMP_IN_UNIX_EPOCH>, \"message\": \"User 'xyz' logged out\", \"attributes\": { \"auditId\": 123 } }] }] Copy The above POST message would result in the following log messages being stored in Log management: Example of stored common block attributes: Attribute Value \"logtype\" \"accesslogs\" \"service\" \"login-service\" \"hostname\" \"login.example.com\" Example of stored logs block attributes example: Attribute Value \"timestamp\" 1550086450124 \"message\" \"User 'xyz' logged out\" \"auditId\" 123 HTTP endpoint Once configured, your JSON data can be sent to the following endpoint in a POST request: United States (US) endpoint: https://log-api.newrelic.com/log/v1 Copy European Union (EU) endpoint: https://log-api.eu.newrelic.com/log/v1 Copy Here's an example of a JSON POST request: POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: <YOUR_LICENSE_KEY> Accept: */* Content-Length: 133 { \"timestamp\": <TIMESTAMP_IN_UNIX_EPOCH>, \"message\": \"User 'xyz' logged in\", \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } Copy Find log data For where to find data sent via the Log API (including from integrations that use that API), see Find log data. What's next? Now that you've enabled Log management, here are some potential next steps: Explore your data using the Logs UI. Configure your agent to see contextual log data, such as distributed tracing, stack traces, application logs, and more. Query your data and create custom dashboards, charts, or alerts. If no data appears after you enable Log management, follow the troubleshooting procedures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.88385,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Log</em> <em>API</em>",
        "sections": "Introduction to the <em>Log</em> <em>API</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "If our logging solutions don&#x27;t meet your needs, you can use our <em>Log</em> <em>API</em> to send <em>log</em> data directly to New Relic&#x27;s <em>Log</em> <em>management</em> via an HTTP endpoint. Compatibility and requirements Requirements include: New Relic license key (recommended) or an Insert <em>API</em> key. For payload details, see limits"
      },
      "id": "603ea832196a6726e7a83da1"
    },
    {
      "sections": [
        "Discover value in log data with patterns",
        "Technical overview",
        "Availability",
        "Important",
        "Get started",
        "Explore log patterns",
        "Explore logs with no pattern",
        "Masked attributes and wildcards",
        "Troubleshooting",
        "Put the platform to work with patterns"
      ],
      "title": "Discover value in log data with patterns",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "8f1e27c94327ca4888a945f8e12f9c2310ccd7a6",
      "image": "https://docs.newrelic.com/static/578d7186bb34352855696e5307cc82f2/c1b63/log-patterns-logs-without-a-pattern.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/find-unusual-logs-log-patterns/",
      "published_at": "2021-07-02T14:37:14Z",
      "updated_at": "2021-07-02T14:37:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Log patterns are the fastest way to discover value in log data without searching. Log data is high volume telemetry with a low value per individual record. Searching can quickly lead to logs that provide a root cause explanation, but most data is repetitive and hard to contextualize when browsing. Patterns can make log data discoverable without spending a lot of time reading through low value data. one.newrelic.com > Logs > Patterns: Use patterns as the basis for alerts when the frequency of important data changes, or for configuring drop rules to get rid of unnecessary repetitive data. Technical overview Log patterns functionality applies machine learning to normalize and group log messages that are consistent in format but variable in content. These grouped messages can be sorted, making it easy to find the most frequent or rarest sets of logs in your environment. Use patterns as the basis for alerts when the frequency of important data changes, or to configure drop rules to get rid of unnecessary repetitive data. Log patterns use advanced clustering algorithms to group together similar log messages automatically. With patterns, you can: Orient more quickly through millions of logs. Reduce the time it takes to identify unusual behavior in your log estate. Monitor the frequency of known patterns over time to focus your energy on what matters, and exclude what's irrelevant. Availability Important Log patterns are not available in the EU region. The ability to configure this feature is dependent on role-based permissions. If you see Patterns are turned off in your Log management Patterns UI, click the Configure Patterns button and enable it. If you don't see patterns within 30 minutes of enabling the feature, there may be a lack of data with a message attribute for the system to create a pattern from. Log patterns Limitations and considerations Pricing There is no separate pricing for log patterns. The only cost is for additional data generated and added to your log records. A pattern attribute will be added to all logs that match a pattern. Attributes also may be added when common values are discovered, such as GUIDs, IP addresses, URL, or email addresses. These attributes are automatically extracted from the log message as part of the pattern process. HITRUST accounts The log patterns feature is not FedRAMP compliant. FedRAMP or other HITRUST accounts are not eligible to use patterns. Regional availability Availability for this feature depends on whether you have a US or EU region account: US region accounts can use log patterns. EU region accounts cannot enable log patterns at this time. Parsing limits We have a system of safety limits on memory and CPU resources when processing logs and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com > Log management, and use the account picker dropdown to select the target account where you want to explore patterns. In the left navigation of the Log management UI, click Patterns. The main log UI changes to show patterns that match the query in the query bar. one.newrelic.com > Log management > Log patterns: The line chart shows the top 5 patterns over time. Use the time picker and query bar to adjust the results. Explore log patterns By default the log patterns UI first shows the most frequent occurrence of patterns. To sort to show the rarest patterns first, click the Count column. You can also use the query bar or attributes bar to filter your log patterns. If you want to... Do this... Understand the rate of change in patterns Look at the line chart. The color-coded patterns correspond to the plot column in the table. You can toggle individual plot patterns to narrow your focus. See the individual log messages that match each pattern Click pattern to expand the row and see a table of individual log records. To see additional records, scroll up or down. To explore an individual log in more detail, click it to open the details panel. Group and filter patterns by their attributes Use the query bar and time picker. As you apply different filters and time windows, the log patterns adjust to your new target data. Create an alert from a pattern Add the pattern to the query bar and run the query. Then click Create alert condition in the left nav. Troubleshoot log messages that haven't been clustered into a pattern Use the Logs with no pattern tab in the Log patterns UI. Clicking a specific log message will open the log message details panel you're familiar with from the Logs management page. Explore logs with no pattern The Logs with no pattern tab groups all recent log messages in your account that were not clustered into a known pattern yet. These log messages don't represent any problem or flaw in the system; they have no pattern because they are too new to have been processed by the machine learning system. This makes them valuable to explore when you want to understand what has recently changed in your environment. one.newrelic.com > Log management > Log patterns: New Relic's log patterns feature automatically groups logs without a matching pattern. For example: Are any of these logs tied to a recent problem? This is a quick way to discover unique log data that is appearing for the first time in your environment. Does your log data have a new format? Sometimes the logs don't represent a problem, but a new format of log data that deviates from the data model you expect your applications to follow. Catching these logs early gives you the opportunity to ask developers to correct any deviations in their log output. The more consistent people are in the way log data is generated, the easier it becomes to use logs across a diverse set of teams. Masked attributes and wildcards Parts of the log messages in patterns are classified as variables and are substituted by masked attributes. The masking process supports and improves the clustering phase by allowing the algorithm to ignore changing details and focus on the repetitive structure. Masked attributes include: date_time ip url uuid Masked attributes are highlighted and are easy to identify, as shown in the following example. one.newrelic.com > Log management > Log patterns: Here is an example of a pattern that has masked attributes. Log patterns extract other less trivial variables that don't belong to any masked attribute. These variables are indicated as wildcards *. one.newrelic.com > Log management > Log patterns: Here is an example of how wildcards * group variables. Troubleshooting Here are a few reasons why you might have patterns enabled but not see any pattern data. If you're sure none of the items below are true, get help from support.newrelic.com. No data has arrived in the timeframe you're observing. Try expanding the time range you're viewing with the time picker. It's been less than 24 hours since patterns were enabled in the account. This means the ML model may not be generated for the account yet. None of the data coming in has a message field. Patterns will only be generated for values in the message field of a log record. If your logs don't contain message, there will be no data. Put the platform to work with patterns Patterns are a value that is enriched onto the existing log message as a new attribute named newrelic.logPattern. Anything you can do with logs generally can be done with log patterns, such as: Build your own dashboards with patterns, to monitor a specific pattern or group of patterns you care about. Create alerts for patterns by adding NRQL alerts. Use baseline alert conditions to detect anomalies in known log patterns.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.14035,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Discover value in <em>log</em> data with patterns",
        "sections": "Explore <em>logs</em> with no pattern",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " and CPU resources when processing <em>logs</em> and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com &gt; <em>Log</em> <em>management</em>, and use the account picker dropdown"
      },
      "id": "6072d46128ccbc244451c18b"
    },
    {
      "sections": [
        "Organize data with partitions",
        "Plan your partition",
        "Important",
        "Required roles and permissions",
        "Sizing and organizing a partition",
        "Choosing a namespace",
        "Create partition rules",
        "Search data partitions",
        "Manage data partitions programatically with NerdGraph"
      ],
      "title": "Organize data with partitions",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "28cac5fac1065f4b1756700e7f6c11c325734c35",
      "image": "https://docs.newrelic.com/static/7815845d8068377477aa26f8571d5907/c1b63/log-partitions-crop.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/data-partitions/",
      "published_at": "2021-07-02T14:35:27Z",
      "updated_at": "2021-07-02T14:35:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Data partitions are a way to group or organize log data for faster and more efficient querying. When a query targets a single partition, New Relic Logs: Scans less unrelated data. Returns results faster. Accounts can have multiple partitions, and multiple partitions can be queried at the same time. Data partitions also allow data to be mapped to an alternative, or “secondary” namespace with a fixed 30-day retention. This is useful for maintaining compliance with privacy-centric regulations and standards like the General Data Protection Regulation (GDPR). Plan your partition Before you start creating partitions, make sure you have the right permissions and a partition plan. Important Logs are routed to partitions during the ingestion process, before data is written to NRDB. Partition rules will not affect logs that were ingested before the rule was created. Required roles and permissions Users require an Admin role to create and modify partition rules. Sizing and organizing a partition You can gain significant performance improvements with proper use of data partitions. Organizing your data into discrete partitions enables you to query them separately or all together. The goals of partitioning your data should be: Create data partitions that align with concepts in your environment or organization that are static or change infrequently (for example, by business unit, team, environment, service, etc.). Ensure each partition remains below 1 TB of daily ingest for optimal performance. Having more partitions allows for more targeted searches, but creating too many partitions can make logs hard to find and increase administrative overhead. Finding the right balance is important. We support 100 partitions maximum per account, but the optimal number for most accounts is 10 to 15 partitions. Choosing a namespace A partition’s namespace determines its retention period. We offer two retention options: Standard: The account’s default retention determined by your New Relic subscription. This is the maximum retention period available in your account and is the namespace you'll select for most of your partitions. Secondary: 30-day retention. All logs sent to a partition that's a member of the Secondary namespace will be purged on a rolling basis 30 days after having been ingested. Secondary retention is not a cost control mechanism; data is billed on ingest. Create partition rules one.newrelic.com > Logs: From the left nav in the Logs UI, select Data partitions, then create a Log_ partition name with the retention namespace, optional description, and matching criteria. To create a new partition rule: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Data partitions, then click Create partition rule. Define a Partition name as an alphanumeric string that begins with Log_. Add an optional description. Select the retention namespace for the partition. Set your rule's Matching criteria: Select EQUALS to target logs that match your criteria exactly, or select LIKE to apply a fuzzy match. Click the Enable Rule slider, and click Create. To view a list of data partitions: From Manage Data on the left nav of the Logs UI, click Data partitions. Search data partitions The default partition for all Logs accounts is Log. Any log that is not affected by a partition rule will be stored in the Log partition by default. You can query multiple partitions simultaneously. For best performance, select the smallest number of partitions possible. To search data partitions: From Views and Attributes on the left nav of the Logs UI, click Select partitions. Click one or more partitions you want to query, or search for a partition name. Click Query logs to search your selected partitions. Manage data partitions programatically with NerdGraph If you want to manage your data partitions programatically, you can use NerdGraph, our graphQL API, to do so. This tutorial shows how to query, create, and delete data partitions using our API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.12778,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Manage</em> data partitions programatically with NerdGraph",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Data partitions are a way to group or organize <em>log</em> data for faster and more efficient querying. When a query targets a single partition, New Relic <em>Logs</em>: Scans less unrelated data. Returns results faster. Accounts can have multiple partitions, and multiple partitions can be queried at the same time"
      },
      "id": "6087e311e7b9d2f90ba5c6a4"
    }
  ],
  "/docs/logs/log-management/troubleshooting/find-issues-cause-or-impact-surrounding-logs": [
    {
      "sections": [
        "Discover value in log data with patterns",
        "Technical overview",
        "Availability",
        "Important",
        "Get started",
        "Explore log patterns",
        "Explore logs with no pattern",
        "Masked attributes and wildcards",
        "Troubleshooting",
        "Put the platform to work with patterns"
      ],
      "title": "Discover value in log data with patterns",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "8f1e27c94327ca4888a945f8e12f9c2310ccd7a6",
      "image": "https://docs.newrelic.com/static/578d7186bb34352855696e5307cc82f2/c1b63/log-patterns-logs-without-a-pattern.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/find-unusual-logs-log-patterns/",
      "published_at": "2021-07-02T14:37:14Z",
      "updated_at": "2021-07-02T14:37:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Log patterns are the fastest way to discover value in log data without searching. Log data is high volume telemetry with a low value per individual record. Searching can quickly lead to logs that provide a root cause explanation, but most data is repetitive and hard to contextualize when browsing. Patterns can make log data discoverable without spending a lot of time reading through low value data. one.newrelic.com > Logs > Patterns: Use patterns as the basis for alerts when the frequency of important data changes, or for configuring drop rules to get rid of unnecessary repetitive data. Technical overview Log patterns functionality applies machine learning to normalize and group log messages that are consistent in format but variable in content. These grouped messages can be sorted, making it easy to find the most frequent or rarest sets of logs in your environment. Use patterns as the basis for alerts when the frequency of important data changes, or to configure drop rules to get rid of unnecessary repetitive data. Log patterns use advanced clustering algorithms to group together similar log messages automatically. With patterns, you can: Orient more quickly through millions of logs. Reduce the time it takes to identify unusual behavior in your log estate. Monitor the frequency of known patterns over time to focus your energy on what matters, and exclude what's irrelevant. Availability Important Log patterns are not available in the EU region. The ability to configure this feature is dependent on role-based permissions. If you see Patterns are turned off in your Log management Patterns UI, click the Configure Patterns button and enable it. If you don't see patterns within 30 minutes of enabling the feature, there may be a lack of data with a message attribute for the system to create a pattern from. Log patterns Limitations and considerations Pricing There is no separate pricing for log patterns. The only cost is for additional data generated and added to your log records. A pattern attribute will be added to all logs that match a pattern. Attributes also may be added when common values are discovered, such as GUIDs, IP addresses, URL, or email addresses. These attributes are automatically extracted from the log message as part of the pattern process. HITRUST accounts The log patterns feature is not FedRAMP compliant. FedRAMP or other HITRUST accounts are not eligible to use patterns. Regional availability Availability for this feature depends on whether you have a US or EU region account: US region accounts can use log patterns. EU region accounts cannot enable log patterns at this time. Parsing limits We have a system of safety limits on memory and CPU resources when processing logs and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com > Log management, and use the account picker dropdown to select the target account where you want to explore patterns. In the left navigation of the Log management UI, click Patterns. The main log UI changes to show patterns that match the query in the query bar. one.newrelic.com > Log management > Log patterns: The line chart shows the top 5 patterns over time. Use the time picker and query bar to adjust the results. Explore log patterns By default the log patterns UI first shows the most frequent occurrence of patterns. To sort to show the rarest patterns first, click the Count column. You can also use the query bar or attributes bar to filter your log patterns. If you want to... Do this... Understand the rate of change in patterns Look at the line chart. The color-coded patterns correspond to the plot column in the table. You can toggle individual plot patterns to narrow your focus. See the individual log messages that match each pattern Click pattern to expand the row and see a table of individual log records. To see additional records, scroll up or down. To explore an individual log in more detail, click it to open the details panel. Group and filter patterns by their attributes Use the query bar and time picker. As you apply different filters and time windows, the log patterns adjust to your new target data. Create an alert from a pattern Add the pattern to the query bar and run the query. Then click Create alert condition in the left nav. Troubleshoot log messages that haven't been clustered into a pattern Use the Logs with no pattern tab in the Log patterns UI. Clicking a specific log message will open the log message details panel you're familiar with from the Logs management page. Explore logs with no pattern The Logs with no pattern tab groups all recent log messages in your account that were not clustered into a known pattern yet. These log messages don't represent any problem or flaw in the system; they have no pattern because they are too new to have been processed by the machine learning system. This makes them valuable to explore when you want to understand what has recently changed in your environment. one.newrelic.com > Log management > Log patterns: New Relic's log patterns feature automatically groups logs without a matching pattern. For example: Are any of these logs tied to a recent problem? This is a quick way to discover unique log data that is appearing for the first time in your environment. Does your log data have a new format? Sometimes the logs don't represent a problem, but a new format of log data that deviates from the data model you expect your applications to follow. Catching these logs early gives you the opportunity to ask developers to correct any deviations in their log output. The more consistent people are in the way log data is generated, the easier it becomes to use logs across a diverse set of teams. Masked attributes and wildcards Parts of the log messages in patterns are classified as variables and are substituted by masked attributes. The masking process supports and improves the clustering phase by allowing the algorithm to ignore changing details and focus on the repetitive structure. Masked attributes include: date_time ip url uuid Masked attributes are highlighted and are easy to identify, as shown in the following example. one.newrelic.com > Log management > Log patterns: Here is an example of a pattern that has masked attributes. Log patterns extract other less trivial variables that don't belong to any masked attribute. These variables are indicated as wildcards *. one.newrelic.com > Log management > Log patterns: Here is an example of how wildcards * group variables. Troubleshooting Here are a few reasons why you might have patterns enabled but not see any pattern data. If you're sure none of the items below are true, get help from support.newrelic.com. No data has arrived in the timeframe you're observing. Try expanding the time range you're viewing with the time picker. It's been less than 24 hours since patterns were enabled in the account. This means the ML model may not be generated for the account yet. None of the data coming in has a message field. Patterns will only be generated for values in the message field of a log record. If your logs don't contain message, there will be no data. Put the platform to work with patterns Patterns are a value that is enriched onto the existing log message as a new attribute named newrelic.logPattern. Anything you can do with logs generally can be done with log patterns, such as: Build your own dashboards with patterns, to monitor a specific pattern or group of patterns you care about. Create alerts for patterns by adding NRQL alerts. Use baseline alert conditions to detect anomalies in known log patterns.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 217.56651,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Discover value in <em>log</em> data with patterns",
        "sections": "Explore <em>logs</em> with no pattern",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " and CPU resources when processing <em>logs</em> and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com &gt; <em>Log</em> <em>management</em>, and use the account picker dropdown"
      },
      "id": "6072d46128ccbc244451c18b"
    },
    {
      "sections": [
        "Organize data with partitions",
        "Plan your partition",
        "Important",
        "Required roles and permissions",
        "Sizing and organizing a partition",
        "Choosing a namespace",
        "Create partition rules",
        "Search data partitions",
        "Manage data partitions programatically with NerdGraph"
      ],
      "title": "Organize data with partitions",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "28cac5fac1065f4b1756700e7f6c11c325734c35",
      "image": "https://docs.newrelic.com/static/7815845d8068377477aa26f8571d5907/c1b63/log-partitions-crop.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/data-partitions/",
      "published_at": "2021-07-02T14:35:27Z",
      "updated_at": "2021-07-02T14:35:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Data partitions are a way to group or organize log data for faster and more efficient querying. When a query targets a single partition, New Relic Logs: Scans less unrelated data. Returns results faster. Accounts can have multiple partitions, and multiple partitions can be queried at the same time. Data partitions also allow data to be mapped to an alternative, or “secondary” namespace with a fixed 30-day retention. This is useful for maintaining compliance with privacy-centric regulations and standards like the General Data Protection Regulation (GDPR). Plan your partition Before you start creating partitions, make sure you have the right permissions and a partition plan. Important Logs are routed to partitions during the ingestion process, before data is written to NRDB. Partition rules will not affect logs that were ingested before the rule was created. Required roles and permissions Users require an Admin role to create and modify partition rules. Sizing and organizing a partition You can gain significant performance improvements with proper use of data partitions. Organizing your data into discrete partitions enables you to query them separately or all together. The goals of partitioning your data should be: Create data partitions that align with concepts in your environment or organization that are static or change infrequently (for example, by business unit, team, environment, service, etc.). Ensure each partition remains below 1 TB of daily ingest for optimal performance. Having more partitions allows for more targeted searches, but creating too many partitions can make logs hard to find and increase administrative overhead. Finding the right balance is important. We support 100 partitions maximum per account, but the optimal number for most accounts is 10 to 15 partitions. Choosing a namespace A partition’s namespace determines its retention period. We offer two retention options: Standard: The account’s default retention determined by your New Relic subscription. This is the maximum retention period available in your account and is the namespace you'll select for most of your partitions. Secondary: 30-day retention. All logs sent to a partition that's a member of the Secondary namespace will be purged on a rolling basis 30 days after having been ingested. Secondary retention is not a cost control mechanism; data is billed on ingest. Create partition rules one.newrelic.com > Logs: From the left nav in the Logs UI, select Data partitions, then create a Log_ partition name with the retention namespace, optional description, and matching criteria. To create a new partition rule: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Data partitions, then click Create partition rule. Define a Partition name as an alphanumeric string that begins with Log_. Add an optional description. Select the retention namespace for the partition. Set your rule's Matching criteria: Select EQUALS to target logs that match your criteria exactly, or select LIKE to apply a fuzzy match. Click the Enable Rule slider, and click Create. To view a list of data partitions: From Manage Data on the left nav of the Logs UI, click Data partitions. Search data partitions The default partition for all Logs accounts is Log. Any log that is not affected by a partition rule will be stored in the Log partition by default. You can query multiple partitions simultaneously. For best performance, select the smallest number of partitions possible. To search data partitions: From Views and Attributes on the left nav of the Logs UI, click Select partitions. Click one or more partitions you want to query, or search for a partition name. Click Query logs to search your selected partitions. Manage data partitions programatically with NerdGraph If you want to manage your data partitions programatically, you can use NerdGraph, our graphQL API, to do so. This tutorial shows how to query, create, and delete data partitions using our API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.79758,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Manage</em> data partitions programatically with NerdGraph",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Data partitions are a way to group or organize <em>log</em> data for faster and more efficient querying. When a query targets a single partition, New Relic <em>Logs</em>: Scans less unrelated data. Returns results faster. Accounts can have multiple partitions, and multiple partitions can be queried at the same time"
      },
      "id": "6087e311e7b9d2f90ba5c6a4"
    },
    {
      "sections": [
        "Use TCP endpoint to forward logs to New Relic",
        "Compatibility and requirements",
        "Important",
        "Configure rsyslog",
        "Legacy config file for rsyslog 7 or earlier",
        "Configure syslog-ng",
        "Tip"
      ],
      "title": "Use TCP endpoint to forward logs to New Relic",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Log API"
      ],
      "external_id": "3f572fe998dd7f72516a7b654295b779ff290176",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/log-api/use-tcp-endpoint-forward-logs-new-relic/",
      "published_at": "2021-07-02T14:33:44Z",
      "updated_at": "2021-06-25T22:58:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer a wide range of solutions to get your log data into New Relic. But in other situations where you don't have log forwarders (such as CDNs, hardware devices, or managed services), you can use syslog protocols via a TCP endpoint. You can forward your logs to New Relic using syslog clients such as rsyslog and syslog-ng. Compatibility and requirements To forward logs to New Relic using a syslog client, you need: A valid Insights API Insert key Some minor changes to the syslog client's configuration, as explained in this document Important Currently, our syslog endpoint only supports accounts in our US data center. Configure rsyslog To forward logs to New Relic with rsyslog: Install packages required to allow rsyslog to send logs using TLS encryption: sudo yum install rsyslog-gnutls ca-certificates Copy Optional: Configure rsyslog to tail log files and forward their contents to New Relic. Add the following to the /etc/rsyslog.conf file in order to enable its text file input module: module(load=\"imfile\" PollingInterval=\"10\" statefile.directory=\"/var/spool/rsyslog\" ) Copy In the /etc/rsyslog.d/ directory, create a text file named newrelic.conf. Explicitly include the newly created newrelic.conf to the /etc/rsyslog.d/ file: include(file=\"/etc/rsyslog.conf.d/newrelic.conf\") Copy Add the following to newrelic.conf, replacing YOUR_INSERT_KEY with your New Relic Insights API Insert key: ## Specify each of the files to be tailed in case step 1 is done input(type=\"imfile\" ruleset=\"infiles\" Tag=\"<YOUR_FILE_TAG>\" File=\"<PATH_TO_FILE>\" StateFile=\"<UNIQUE_STATEFILE_NAME >\") ## Template expected by the New Relic Syslog endpoint template(name=\"newrelic-rfc5424\" type=\"string\" string=\"<YOUR_INSERT_KEY> <%pri%>%protocol-version% %timestamp:::date-rfc3339% %hostname% %app-name% %procid% %msgid% %structured-data% %msg%\\n\" ) ## Configure TLS and log forwarding global(DefaultNetstreamDriver=\"gtls\" DefaultNetstreamDriverCAFile=\"/etc/ssl/certs/ca-certificates.crt\" ) action(type=\"omfwd\" Target=\"newrelic.syslog.nr-data.net\" Port=\"6514\" Protocol=\"tcp\" Template=\"newrelic-rfc5424\" ResendLastMSGOnReconnect=\"on\" StreamDriver=\"gtls\" StreamDriverAuthMode=\"x509/name\" StreamDriverPermittedPeers=\"*.syslog.nr-data.net\" StreamDriverMode=\"1\" ) Copy Restart the rsyslog service by running: sudo systemctl restart rsyslog Copy Check your New Relic account for logs. Legacy config file for rsyslog 7 or earlier If you are using rsyslog version 7 or below, the configuration files need to be adapted to the obsolete legacy format. This format is only kept for retro compatibility purposes. We strongly recommend to avoid using it, as stated in the rsyslog documentation. Install packages required to allow rsyslog to send logs using TLS encryption: sudo yum install rsyslog-gnutls ca-certificates Copy Optional: Configure rsyslog to tail log files and forward their contents to New Relic. Add the following to the /etc/rsyslog.conf file in order to enable its text file input module: $ModLoad imfile $InputFilePollInterval 10 $PrivDropToGroup adm $WorkDirectory /var/spool/rsyslog Copy In the /etc/rsyslog.d/ directory, create a text file named newrelic.conf. Explicitly include the newly created newrelic.conf to the /etc/rsyslog.d/ file: $IncludeConfig /etc/rsyslog.conf.d/newrelic.conf Copy Add the following to newrelic.conf, replacing YOUR_INSERT_KEY with your New Relic Insights API Insert key: ## Template expected by the New Relic Syslog endpoint $template NRLogFormat,\"YOUR_INSERT_KEY <%pri%>%protocol-version% %timestamp:::date-rfc3339% %hostname% %app-name% %procid% %msgid% %structured-data% %msg%\\n\" ## Specify each of the files to be tailed in case step 1 is done $InputFileName /path/to/file $InputFileTag <YOUR_FILE_TAG> $InputFileStateFile <UNIQUE_STATEFILE_NAME> $InputFileSeverity info $InputRunFileMonitor ## Configure TLS and log forwarding $DefaultNetstreamDriverCAFile /etc/ssl/certs/ca-certificates.crt $ActionSendStreamDriver gtls $ActionSendStreamDriverMode 1 $ActionSendStreamDriverAuthMode x509/name $ActionSendStreamDriverPermittedPeer *.syslog.nr-data.net *.* @@newrelic.syslog.nr-data.net:6514;NRLogFormat Copy Restart the rsyslog service by running: sudo systemctl restart rsyslog Copy Check your New Relic account for logs. Configure syslog-ng To forward logs to New Relic with syslog-ng: Install ca-certificates required to allow syslog-ng to send logs using TLS encryption: sudo yum install ca-certificates Copy Open the syslog-ng configuration file (/etc/syslog-ng/syslog-ng.conf) in a text editor. Define the sources to be monitored by adding: source s_src { internal(); }; Copy Optional: Configure syslog-ng to tail files by adding the following to the Sources configuration block: source s_files { file(\"<PATH_TO_FILE>\"); }; Copy Define the New Relic syslog format and add your New Relic Insights API Insert key: template NRFormat { template(\"YOUR_INSERT_KEY ${PRI}>1 ${ISODATE} ${HOST:--} ${PROGRAM:--} ${PID:--} ${MSGID:--} ${SDATA:--} $MSG\\n\"); template_escape(no); }; Copy Add the New Relic Syslog endpoint: destination d_newrelic { network(\"newrelic.syslog.nr-data.net\" port(6514) transport(\"tls\") tls(peer-verify(no)) template(NRFormat) ); }; Copy Add the following output to the log path configuration block: log { source(s_src); source(s_files); ## in case step 4 is implemented. destination(d_newrelic); }; Copy Restart syslog-ng by running: sudo service syslog-ng restart Copy Check your New Relic account for logs. Tip If you are running syslog-ng from a Docker container and experience issues, check balait/syslog image documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.16693,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use TCP endpoint to forward <em>logs</em> to New Relic",
        "sections": "Use TCP endpoint to forward <em>logs</em> to New Relic",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "We offer a wide range of solutions to get your <em>log</em> data into New Relic. But in other situations where you don&#x27;t have <em>log</em> forwarders (such as CDNs, hardware devices, or managed services), you can use syslog protocols via a TCP endpoint. You can forward your <em>logs</em> to New Relic using syslog clients"
      },
      "id": "603e7d6764441f1a774e88a0"
    }
  ],
  "/docs/logs/log-management/troubleshooting/log-message-truncated": [
    {
      "sections": [
        "Discover value in log data with patterns",
        "Technical overview",
        "Availability",
        "Important",
        "Get started",
        "Explore log patterns",
        "Explore logs with no pattern",
        "Masked attributes and wildcards",
        "Troubleshooting",
        "Put the platform to work with patterns"
      ],
      "title": "Discover value in log data with patterns",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "8f1e27c94327ca4888a945f8e12f9c2310ccd7a6",
      "image": "https://docs.newrelic.com/static/578d7186bb34352855696e5307cc82f2/c1b63/log-patterns-logs-without-a-pattern.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/find-unusual-logs-log-patterns/",
      "published_at": "2021-07-02T14:37:14Z",
      "updated_at": "2021-07-02T14:37:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Log patterns are the fastest way to discover value in log data without searching. Log data is high volume telemetry with a low value per individual record. Searching can quickly lead to logs that provide a root cause explanation, but most data is repetitive and hard to contextualize when browsing. Patterns can make log data discoverable without spending a lot of time reading through low value data. one.newrelic.com > Logs > Patterns: Use patterns as the basis for alerts when the frequency of important data changes, or for configuring drop rules to get rid of unnecessary repetitive data. Technical overview Log patterns functionality applies machine learning to normalize and group log messages that are consistent in format but variable in content. These grouped messages can be sorted, making it easy to find the most frequent or rarest sets of logs in your environment. Use patterns as the basis for alerts when the frequency of important data changes, or to configure drop rules to get rid of unnecessary repetitive data. Log patterns use advanced clustering algorithms to group together similar log messages automatically. With patterns, you can: Orient more quickly through millions of logs. Reduce the time it takes to identify unusual behavior in your log estate. Monitor the frequency of known patterns over time to focus your energy on what matters, and exclude what's irrelevant. Availability Important Log patterns are not available in the EU region. The ability to configure this feature is dependent on role-based permissions. If you see Patterns are turned off in your Log management Patterns UI, click the Configure Patterns button and enable it. If you don't see patterns within 30 minutes of enabling the feature, there may be a lack of data with a message attribute for the system to create a pattern from. Log patterns Limitations and considerations Pricing There is no separate pricing for log patterns. The only cost is for additional data generated and added to your log records. A pattern attribute will be added to all logs that match a pattern. Attributes also may be added when common values are discovered, such as GUIDs, IP addresses, URL, or email addresses. These attributes are automatically extracted from the log message as part of the pattern process. HITRUST accounts The log patterns feature is not FedRAMP compliant. FedRAMP or other HITRUST accounts are not eligible to use patterns. Regional availability Availability for this feature depends on whether you have a US or EU region account: US region accounts can use log patterns. EU region accounts cannot enable log patterns at this time. Parsing limits We have a system of safety limits on memory and CPU resources when processing logs and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com > Log management, and use the account picker dropdown to select the target account where you want to explore patterns. In the left navigation of the Log management UI, click Patterns. The main log UI changes to show patterns that match the query in the query bar. one.newrelic.com > Log management > Log patterns: The line chart shows the top 5 patterns over time. Use the time picker and query bar to adjust the results. Explore log patterns By default the log patterns UI first shows the most frequent occurrence of patterns. To sort to show the rarest patterns first, click the Count column. You can also use the query bar or attributes bar to filter your log patterns. If you want to... Do this... Understand the rate of change in patterns Look at the line chart. The color-coded patterns correspond to the plot column in the table. You can toggle individual plot patterns to narrow your focus. See the individual log messages that match each pattern Click pattern to expand the row and see a table of individual log records. To see additional records, scroll up or down. To explore an individual log in more detail, click it to open the details panel. Group and filter patterns by their attributes Use the query bar and time picker. As you apply different filters and time windows, the log patterns adjust to your new target data. Create an alert from a pattern Add the pattern to the query bar and run the query. Then click Create alert condition in the left nav. Troubleshoot log messages that haven't been clustered into a pattern Use the Logs with no pattern tab in the Log patterns UI. Clicking a specific log message will open the log message details panel you're familiar with from the Logs management page. Explore logs with no pattern The Logs with no pattern tab groups all recent log messages in your account that were not clustered into a known pattern yet. These log messages don't represent any problem or flaw in the system; they have no pattern because they are too new to have been processed by the machine learning system. This makes them valuable to explore when you want to understand what has recently changed in your environment. one.newrelic.com > Log management > Log patterns: New Relic's log patterns feature automatically groups logs without a matching pattern. For example: Are any of these logs tied to a recent problem? This is a quick way to discover unique log data that is appearing for the first time in your environment. Does your log data have a new format? Sometimes the logs don't represent a problem, but a new format of log data that deviates from the data model you expect your applications to follow. Catching these logs early gives you the opportunity to ask developers to correct any deviations in their log output. The more consistent people are in the way log data is generated, the easier it becomes to use logs across a diverse set of teams. Masked attributes and wildcards Parts of the log messages in patterns are classified as variables and are substituted by masked attributes. The masking process supports and improves the clustering phase by allowing the algorithm to ignore changing details and focus on the repetitive structure. Masked attributes include: date_time ip url uuid Masked attributes are highlighted and are easy to identify, as shown in the following example. one.newrelic.com > Log management > Log patterns: Here is an example of a pattern that has masked attributes. Log patterns extract other less trivial variables that don't belong to any masked attribute. These variables are indicated as wildcards *. one.newrelic.com > Log management > Log patterns: Here is an example of how wildcards * group variables. Troubleshooting Here are a few reasons why you might have patterns enabled but not see any pattern data. If you're sure none of the items below are true, get help from support.newrelic.com. No data has arrived in the timeframe you're observing. Try expanding the time range you're viewing with the time picker. It's been less than 24 hours since patterns were enabled in the account. This means the ML model may not be generated for the account yet. None of the data coming in has a message field. Patterns will only be generated for values in the message field of a log record. If your logs don't contain message, there will be no data. Put the platform to work with patterns Patterns are a value that is enriched onto the existing log message as a new attribute named newrelic.logPattern. Anything you can do with logs generally can be done with log patterns, such as: Build your own dashboards with patterns, to monitor a specific pattern or group of patterns you care about. Create alerts for patterns by adding NRQL alerts. Use baseline alert conditions to detect anomalies in known log patterns.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 217.56651,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Discover value in <em>log</em> data with patterns",
        "sections": "Explore <em>logs</em> with no pattern",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " and CPU resources when processing <em>logs</em> and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com &gt; <em>Log</em> <em>management</em>, and use the account picker dropdown"
      },
      "id": "6072d46128ccbc244451c18b"
    },
    {
      "sections": [
        "Organize data with partitions",
        "Plan your partition",
        "Important",
        "Required roles and permissions",
        "Sizing and organizing a partition",
        "Choosing a namespace",
        "Create partition rules",
        "Search data partitions",
        "Manage data partitions programatically with NerdGraph"
      ],
      "title": "Organize data with partitions",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "28cac5fac1065f4b1756700e7f6c11c325734c35",
      "image": "https://docs.newrelic.com/static/7815845d8068377477aa26f8571d5907/c1b63/log-partitions-crop.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/data-partitions/",
      "published_at": "2021-07-02T14:35:27Z",
      "updated_at": "2021-07-02T14:35:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Data partitions are a way to group or organize log data for faster and more efficient querying. When a query targets a single partition, New Relic Logs: Scans less unrelated data. Returns results faster. Accounts can have multiple partitions, and multiple partitions can be queried at the same time. Data partitions also allow data to be mapped to an alternative, or “secondary” namespace with a fixed 30-day retention. This is useful for maintaining compliance with privacy-centric regulations and standards like the General Data Protection Regulation (GDPR). Plan your partition Before you start creating partitions, make sure you have the right permissions and a partition plan. Important Logs are routed to partitions during the ingestion process, before data is written to NRDB. Partition rules will not affect logs that were ingested before the rule was created. Required roles and permissions Users require an Admin role to create and modify partition rules. Sizing and organizing a partition You can gain significant performance improvements with proper use of data partitions. Organizing your data into discrete partitions enables you to query them separately or all together. The goals of partitioning your data should be: Create data partitions that align with concepts in your environment or organization that are static or change infrequently (for example, by business unit, team, environment, service, etc.). Ensure each partition remains below 1 TB of daily ingest for optimal performance. Having more partitions allows for more targeted searches, but creating too many partitions can make logs hard to find and increase administrative overhead. Finding the right balance is important. We support 100 partitions maximum per account, but the optimal number for most accounts is 10 to 15 partitions. Choosing a namespace A partition’s namespace determines its retention period. We offer two retention options: Standard: The account’s default retention determined by your New Relic subscription. This is the maximum retention period available in your account and is the namespace you'll select for most of your partitions. Secondary: 30-day retention. All logs sent to a partition that's a member of the Secondary namespace will be purged on a rolling basis 30 days after having been ingested. Secondary retention is not a cost control mechanism; data is billed on ingest. Create partition rules one.newrelic.com > Logs: From the left nav in the Logs UI, select Data partitions, then create a Log_ partition name with the retention namespace, optional description, and matching criteria. To create a new partition rule: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Data partitions, then click Create partition rule. Define a Partition name as an alphanumeric string that begins with Log_. Add an optional description. Select the retention namespace for the partition. Set your rule's Matching criteria: Select EQUALS to target logs that match your criteria exactly, or select LIKE to apply a fuzzy match. Click the Enable Rule slider, and click Create. To view a list of data partitions: From Manage Data on the left nav of the Logs UI, click Data partitions. Search data partitions The default partition for all Logs accounts is Log. Any log that is not affected by a partition rule will be stored in the Log partition by default. You can query multiple partitions simultaneously. For best performance, select the smallest number of partitions possible. To search data partitions: From Views and Attributes on the left nav of the Logs UI, click Select partitions. Click one or more partitions you want to query, or search for a partition name. Click Query logs to search your selected partitions. Manage data partitions programatically with NerdGraph If you want to manage your data partitions programatically, you can use NerdGraph, our graphQL API, to do so. This tutorial shows how to query, create, and delete data partitions using our API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.79758,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Manage</em> data partitions programatically with NerdGraph",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Data partitions are a way to group or organize <em>log</em> data for faster and more efficient querying. When a query targets a single partition, New Relic <em>Logs</em>: Scans less unrelated data. Returns results faster. Accounts can have multiple partitions, and multiple partitions can be queried at the same time"
      },
      "id": "6087e311e7b9d2f90ba5c6a4"
    },
    {
      "sections": [
        "Use TCP endpoint to forward logs to New Relic",
        "Compatibility and requirements",
        "Important",
        "Configure rsyslog",
        "Legacy config file for rsyslog 7 or earlier",
        "Configure syslog-ng",
        "Tip"
      ],
      "title": "Use TCP endpoint to forward logs to New Relic",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Log API"
      ],
      "external_id": "3f572fe998dd7f72516a7b654295b779ff290176",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/log-api/use-tcp-endpoint-forward-logs-new-relic/",
      "published_at": "2021-07-02T14:33:44Z",
      "updated_at": "2021-06-25T22:58:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer a wide range of solutions to get your log data into New Relic. But in other situations where you don't have log forwarders (such as CDNs, hardware devices, or managed services), you can use syslog protocols via a TCP endpoint. You can forward your logs to New Relic using syslog clients such as rsyslog and syslog-ng. Compatibility and requirements To forward logs to New Relic using a syslog client, you need: A valid Insights API Insert key Some minor changes to the syslog client's configuration, as explained in this document Important Currently, our syslog endpoint only supports accounts in our US data center. Configure rsyslog To forward logs to New Relic with rsyslog: Install packages required to allow rsyslog to send logs using TLS encryption: sudo yum install rsyslog-gnutls ca-certificates Copy Optional: Configure rsyslog to tail log files and forward their contents to New Relic. Add the following to the /etc/rsyslog.conf file in order to enable its text file input module: module(load=\"imfile\" PollingInterval=\"10\" statefile.directory=\"/var/spool/rsyslog\" ) Copy In the /etc/rsyslog.d/ directory, create a text file named newrelic.conf. Explicitly include the newly created newrelic.conf to the /etc/rsyslog.d/ file: include(file=\"/etc/rsyslog.conf.d/newrelic.conf\") Copy Add the following to newrelic.conf, replacing YOUR_INSERT_KEY with your New Relic Insights API Insert key: ## Specify each of the files to be tailed in case step 1 is done input(type=\"imfile\" ruleset=\"infiles\" Tag=\"<YOUR_FILE_TAG>\" File=\"<PATH_TO_FILE>\" StateFile=\"<UNIQUE_STATEFILE_NAME >\") ## Template expected by the New Relic Syslog endpoint template(name=\"newrelic-rfc5424\" type=\"string\" string=\"<YOUR_INSERT_KEY> <%pri%>%protocol-version% %timestamp:::date-rfc3339% %hostname% %app-name% %procid% %msgid% %structured-data% %msg%\\n\" ) ## Configure TLS and log forwarding global(DefaultNetstreamDriver=\"gtls\" DefaultNetstreamDriverCAFile=\"/etc/ssl/certs/ca-certificates.crt\" ) action(type=\"omfwd\" Target=\"newrelic.syslog.nr-data.net\" Port=\"6514\" Protocol=\"tcp\" Template=\"newrelic-rfc5424\" ResendLastMSGOnReconnect=\"on\" StreamDriver=\"gtls\" StreamDriverAuthMode=\"x509/name\" StreamDriverPermittedPeers=\"*.syslog.nr-data.net\" StreamDriverMode=\"1\" ) Copy Restart the rsyslog service by running: sudo systemctl restart rsyslog Copy Check your New Relic account for logs. Legacy config file for rsyslog 7 or earlier If you are using rsyslog version 7 or below, the configuration files need to be adapted to the obsolete legacy format. This format is only kept for retro compatibility purposes. We strongly recommend to avoid using it, as stated in the rsyslog documentation. Install packages required to allow rsyslog to send logs using TLS encryption: sudo yum install rsyslog-gnutls ca-certificates Copy Optional: Configure rsyslog to tail log files and forward their contents to New Relic. Add the following to the /etc/rsyslog.conf file in order to enable its text file input module: $ModLoad imfile $InputFilePollInterval 10 $PrivDropToGroup adm $WorkDirectory /var/spool/rsyslog Copy In the /etc/rsyslog.d/ directory, create a text file named newrelic.conf. Explicitly include the newly created newrelic.conf to the /etc/rsyslog.d/ file: $IncludeConfig /etc/rsyslog.conf.d/newrelic.conf Copy Add the following to newrelic.conf, replacing YOUR_INSERT_KEY with your New Relic Insights API Insert key: ## Template expected by the New Relic Syslog endpoint $template NRLogFormat,\"YOUR_INSERT_KEY <%pri%>%protocol-version% %timestamp:::date-rfc3339% %hostname% %app-name% %procid% %msgid% %structured-data% %msg%\\n\" ## Specify each of the files to be tailed in case step 1 is done $InputFileName /path/to/file $InputFileTag <YOUR_FILE_TAG> $InputFileStateFile <UNIQUE_STATEFILE_NAME> $InputFileSeverity info $InputRunFileMonitor ## Configure TLS and log forwarding $DefaultNetstreamDriverCAFile /etc/ssl/certs/ca-certificates.crt $ActionSendStreamDriver gtls $ActionSendStreamDriverMode 1 $ActionSendStreamDriverAuthMode x509/name $ActionSendStreamDriverPermittedPeer *.syslog.nr-data.net *.* @@newrelic.syslog.nr-data.net:6514;NRLogFormat Copy Restart the rsyslog service by running: sudo systemctl restart rsyslog Copy Check your New Relic account for logs. Configure syslog-ng To forward logs to New Relic with syslog-ng: Install ca-certificates required to allow syslog-ng to send logs using TLS encryption: sudo yum install ca-certificates Copy Open the syslog-ng configuration file (/etc/syslog-ng/syslog-ng.conf) in a text editor. Define the sources to be monitored by adding: source s_src { internal(); }; Copy Optional: Configure syslog-ng to tail files by adding the following to the Sources configuration block: source s_files { file(\"<PATH_TO_FILE>\"); }; Copy Define the New Relic syslog format and add your New Relic Insights API Insert key: template NRFormat { template(\"YOUR_INSERT_KEY ${PRI}>1 ${ISODATE} ${HOST:--} ${PROGRAM:--} ${PID:--} ${MSGID:--} ${SDATA:--} $MSG\\n\"); template_escape(no); }; Copy Add the New Relic Syslog endpoint: destination d_newrelic { network(\"newrelic.syslog.nr-data.net\" port(6514) transport(\"tls\") tls(peer-verify(no)) template(NRFormat) ); }; Copy Add the following output to the log path configuration block: log { source(s_src); source(s_files); ## in case step 4 is implemented. destination(d_newrelic); }; Copy Restart syslog-ng by running: sudo service syslog-ng restart Copy Check your New Relic account for logs. Tip If you are running syslog-ng from a Docker container and experience issues, check balait/syslog image documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.16693,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use TCP endpoint to forward <em>logs</em> to New Relic",
        "sections": "Use TCP endpoint to forward <em>logs</em> to New Relic",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "We offer a wide range of solutions to get your <em>log</em> data into New Relic. But in other situations where you don&#x27;t have <em>log</em> forwarders (such as CDNs, hardware devices, or managed services), you can use syslog protocols via a TCP endpoint. You can forward your <em>logs</em> to New Relic using syslog clients"
      },
      "id": "603e7d6764441f1a774e88a0"
    }
  ],
  "/docs/logs/log-management/troubleshooting/no-log-data-appears-ui": [
    {
      "sections": [
        "Discover value in log data with patterns",
        "Technical overview",
        "Availability",
        "Important",
        "Get started",
        "Explore log patterns",
        "Explore logs with no pattern",
        "Masked attributes and wildcards",
        "Troubleshooting",
        "Put the platform to work with patterns"
      ],
      "title": "Discover value in log data with patterns",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "8f1e27c94327ca4888a945f8e12f9c2310ccd7a6",
      "image": "https://docs.newrelic.com/static/578d7186bb34352855696e5307cc82f2/c1b63/log-patterns-logs-without-a-pattern.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/find-unusual-logs-log-patterns/",
      "published_at": "2021-07-02T14:37:14Z",
      "updated_at": "2021-07-02T14:37:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Log patterns are the fastest way to discover value in log data without searching. Log data is high volume telemetry with a low value per individual record. Searching can quickly lead to logs that provide a root cause explanation, but most data is repetitive and hard to contextualize when browsing. Patterns can make log data discoverable without spending a lot of time reading through low value data. one.newrelic.com > Logs > Patterns: Use patterns as the basis for alerts when the frequency of important data changes, or for configuring drop rules to get rid of unnecessary repetitive data. Technical overview Log patterns functionality applies machine learning to normalize and group log messages that are consistent in format but variable in content. These grouped messages can be sorted, making it easy to find the most frequent or rarest sets of logs in your environment. Use patterns as the basis for alerts when the frequency of important data changes, or to configure drop rules to get rid of unnecessary repetitive data. Log patterns use advanced clustering algorithms to group together similar log messages automatically. With patterns, you can: Orient more quickly through millions of logs. Reduce the time it takes to identify unusual behavior in your log estate. Monitor the frequency of known patterns over time to focus your energy on what matters, and exclude what's irrelevant. Availability Important Log patterns are not available in the EU region. The ability to configure this feature is dependent on role-based permissions. If you see Patterns are turned off in your Log management Patterns UI, click the Configure Patterns button and enable it. If you don't see patterns within 30 minutes of enabling the feature, there may be a lack of data with a message attribute for the system to create a pattern from. Log patterns Limitations and considerations Pricing There is no separate pricing for log patterns. The only cost is for additional data generated and added to your log records. A pattern attribute will be added to all logs that match a pattern. Attributes also may be added when common values are discovered, such as GUIDs, IP addresses, URL, or email addresses. These attributes are automatically extracted from the log message as part of the pattern process. HITRUST accounts The log patterns feature is not FedRAMP compliant. FedRAMP or other HITRUST accounts are not eligible to use patterns. Regional availability Availability for this feature depends on whether you have a US or EU region account: US region accounts can use log patterns. EU region accounts cannot enable log patterns at this time. Parsing limits We have a system of safety limits on memory and CPU resources when processing logs and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com > Log management, and use the account picker dropdown to select the target account where you want to explore patterns. In the left navigation of the Log management UI, click Patterns. The main log UI changes to show patterns that match the query in the query bar. one.newrelic.com > Log management > Log patterns: The line chart shows the top 5 patterns over time. Use the time picker and query bar to adjust the results. Explore log patterns By default the log patterns UI first shows the most frequent occurrence of patterns. To sort to show the rarest patterns first, click the Count column. You can also use the query bar or attributes bar to filter your log patterns. If you want to... Do this... Understand the rate of change in patterns Look at the line chart. The color-coded patterns correspond to the plot column in the table. You can toggle individual plot patterns to narrow your focus. See the individual log messages that match each pattern Click pattern to expand the row and see a table of individual log records. To see additional records, scroll up or down. To explore an individual log in more detail, click it to open the details panel. Group and filter patterns by their attributes Use the query bar and time picker. As you apply different filters and time windows, the log patterns adjust to your new target data. Create an alert from a pattern Add the pattern to the query bar and run the query. Then click Create alert condition in the left nav. Troubleshoot log messages that haven't been clustered into a pattern Use the Logs with no pattern tab in the Log patterns UI. Clicking a specific log message will open the log message details panel you're familiar with from the Logs management page. Explore logs with no pattern The Logs with no pattern tab groups all recent log messages in your account that were not clustered into a known pattern yet. These log messages don't represent any problem or flaw in the system; they have no pattern because they are too new to have been processed by the machine learning system. This makes them valuable to explore when you want to understand what has recently changed in your environment. one.newrelic.com > Log management > Log patterns: New Relic's log patterns feature automatically groups logs without a matching pattern. For example: Are any of these logs tied to a recent problem? This is a quick way to discover unique log data that is appearing for the first time in your environment. Does your log data have a new format? Sometimes the logs don't represent a problem, but a new format of log data that deviates from the data model you expect your applications to follow. Catching these logs early gives you the opportunity to ask developers to correct any deviations in their log output. The more consistent people are in the way log data is generated, the easier it becomes to use logs across a diverse set of teams. Masked attributes and wildcards Parts of the log messages in patterns are classified as variables and are substituted by masked attributes. The masking process supports and improves the clustering phase by allowing the algorithm to ignore changing details and focus on the repetitive structure. Masked attributes include: date_time ip url uuid Masked attributes are highlighted and are easy to identify, as shown in the following example. one.newrelic.com > Log management > Log patterns: Here is an example of a pattern that has masked attributes. Log patterns extract other less trivial variables that don't belong to any masked attribute. These variables are indicated as wildcards *. one.newrelic.com > Log management > Log patterns: Here is an example of how wildcards * group variables. Troubleshooting Here are a few reasons why you might have patterns enabled but not see any pattern data. If you're sure none of the items below are true, get help from support.newrelic.com. No data has arrived in the timeframe you're observing. Try expanding the time range you're viewing with the time picker. It's been less than 24 hours since patterns were enabled in the account. This means the ML model may not be generated for the account yet. None of the data coming in has a message field. Patterns will only be generated for values in the message field of a log record. If your logs don't contain message, there will be no data. Put the platform to work with patterns Patterns are a value that is enriched onto the existing log message as a new attribute named newrelic.logPattern. Anything you can do with logs generally can be done with log patterns, such as: Build your own dashboards with patterns, to monitor a specific pattern or group of patterns you care about. Create alerts for patterns by adding NRQL alerts. Use baseline alert conditions to detect anomalies in known log patterns.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 217.56638,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Discover value in <em>log</em> data with patterns",
        "sections": "Explore <em>logs</em> with no pattern",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " and CPU resources when processing <em>logs</em> and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com &gt; <em>Log</em> <em>management</em>, and use the account picker dropdown"
      },
      "id": "6072d46128ccbc244451c18b"
    },
    {
      "sections": [
        "Organize data with partitions",
        "Plan your partition",
        "Important",
        "Required roles and permissions",
        "Sizing and organizing a partition",
        "Choosing a namespace",
        "Create partition rules",
        "Search data partitions",
        "Manage data partitions programatically with NerdGraph"
      ],
      "title": "Organize data with partitions",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "28cac5fac1065f4b1756700e7f6c11c325734c35",
      "image": "https://docs.newrelic.com/static/7815845d8068377477aa26f8571d5907/c1b63/log-partitions-crop.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/data-partitions/",
      "published_at": "2021-07-02T14:35:27Z",
      "updated_at": "2021-07-02T14:35:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Data partitions are a way to group or organize log data for faster and more efficient querying. When a query targets a single partition, New Relic Logs: Scans less unrelated data. Returns results faster. Accounts can have multiple partitions, and multiple partitions can be queried at the same time. Data partitions also allow data to be mapped to an alternative, or “secondary” namespace with a fixed 30-day retention. This is useful for maintaining compliance with privacy-centric regulations and standards like the General Data Protection Regulation (GDPR). Plan your partition Before you start creating partitions, make sure you have the right permissions and a partition plan. Important Logs are routed to partitions during the ingestion process, before data is written to NRDB. Partition rules will not affect logs that were ingested before the rule was created. Required roles and permissions Users require an Admin role to create and modify partition rules. Sizing and organizing a partition You can gain significant performance improvements with proper use of data partitions. Organizing your data into discrete partitions enables you to query them separately or all together. The goals of partitioning your data should be: Create data partitions that align with concepts in your environment or organization that are static or change infrequently (for example, by business unit, team, environment, service, etc.). Ensure each partition remains below 1 TB of daily ingest for optimal performance. Having more partitions allows for more targeted searches, but creating too many partitions can make logs hard to find and increase administrative overhead. Finding the right balance is important. We support 100 partitions maximum per account, but the optimal number for most accounts is 10 to 15 partitions. Choosing a namespace A partition’s namespace determines its retention period. We offer two retention options: Standard: The account’s default retention determined by your New Relic subscription. This is the maximum retention period available in your account and is the namespace you'll select for most of your partitions. Secondary: 30-day retention. All logs sent to a partition that's a member of the Secondary namespace will be purged on a rolling basis 30 days after having been ingested. Secondary retention is not a cost control mechanism; data is billed on ingest. Create partition rules one.newrelic.com > Logs: From the left nav in the Logs UI, select Data partitions, then create a Log_ partition name with the retention namespace, optional description, and matching criteria. To create a new partition rule: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Data partitions, then click Create partition rule. Define a Partition name as an alphanumeric string that begins with Log_. Add an optional description. Select the retention namespace for the partition. Set your rule's Matching criteria: Select EQUALS to target logs that match your criteria exactly, or select LIKE to apply a fuzzy match. Click the Enable Rule slider, and click Create. To view a list of data partitions: From Manage Data on the left nav of the Logs UI, click Data partitions. Search data partitions The default partition for all Logs accounts is Log. Any log that is not affected by a partition rule will be stored in the Log partition by default. You can query multiple partitions simultaneously. For best performance, select the smallest number of partitions possible. To search data partitions: From Views and Attributes on the left nav of the Logs UI, click Select partitions. Click one or more partitions you want to query, or search for a partition name. Click Query logs to search your selected partitions. Manage data partitions programatically with NerdGraph If you want to manage your data partitions programatically, you can use NerdGraph, our graphQL API, to do so. This tutorial shows how to query, create, and delete data partitions using our API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.79745,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Manage</em> data partitions programatically with NerdGraph",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Data partitions are a way to group or organize <em>log</em> data for faster and more efficient querying. When a query targets a single partition, New Relic <em>Logs</em>: Scans less unrelated data. Returns results faster. Accounts can have multiple partitions, and multiple partitions can be queried at the same time"
      },
      "id": "6087e311e7b9d2f90ba5c6a4"
    },
    {
      "sections": [
        "Use TCP endpoint to forward logs to New Relic",
        "Compatibility and requirements",
        "Important",
        "Configure rsyslog",
        "Legacy config file for rsyslog 7 or earlier",
        "Configure syslog-ng",
        "Tip"
      ],
      "title": "Use TCP endpoint to forward logs to New Relic",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Log API"
      ],
      "external_id": "3f572fe998dd7f72516a7b654295b779ff290176",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/log-api/use-tcp-endpoint-forward-logs-new-relic/",
      "published_at": "2021-07-02T14:33:44Z",
      "updated_at": "2021-06-25T22:58:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer a wide range of solutions to get your log data into New Relic. But in other situations where you don't have log forwarders (such as CDNs, hardware devices, or managed services), you can use syslog protocols via a TCP endpoint. You can forward your logs to New Relic using syslog clients such as rsyslog and syslog-ng. Compatibility and requirements To forward logs to New Relic using a syslog client, you need: A valid Insights API Insert key Some minor changes to the syslog client's configuration, as explained in this document Important Currently, our syslog endpoint only supports accounts in our US data center. Configure rsyslog To forward logs to New Relic with rsyslog: Install packages required to allow rsyslog to send logs using TLS encryption: sudo yum install rsyslog-gnutls ca-certificates Copy Optional: Configure rsyslog to tail log files and forward their contents to New Relic. Add the following to the /etc/rsyslog.conf file in order to enable its text file input module: module(load=\"imfile\" PollingInterval=\"10\" statefile.directory=\"/var/spool/rsyslog\" ) Copy In the /etc/rsyslog.d/ directory, create a text file named newrelic.conf. Explicitly include the newly created newrelic.conf to the /etc/rsyslog.d/ file: include(file=\"/etc/rsyslog.conf.d/newrelic.conf\") Copy Add the following to newrelic.conf, replacing YOUR_INSERT_KEY with your New Relic Insights API Insert key: ## Specify each of the files to be tailed in case step 1 is done input(type=\"imfile\" ruleset=\"infiles\" Tag=\"<YOUR_FILE_TAG>\" File=\"<PATH_TO_FILE>\" StateFile=\"<UNIQUE_STATEFILE_NAME >\") ## Template expected by the New Relic Syslog endpoint template(name=\"newrelic-rfc5424\" type=\"string\" string=\"<YOUR_INSERT_KEY> <%pri%>%protocol-version% %timestamp:::date-rfc3339% %hostname% %app-name% %procid% %msgid% %structured-data% %msg%\\n\" ) ## Configure TLS and log forwarding global(DefaultNetstreamDriver=\"gtls\" DefaultNetstreamDriverCAFile=\"/etc/ssl/certs/ca-certificates.crt\" ) action(type=\"omfwd\" Target=\"newrelic.syslog.nr-data.net\" Port=\"6514\" Protocol=\"tcp\" Template=\"newrelic-rfc5424\" ResendLastMSGOnReconnect=\"on\" StreamDriver=\"gtls\" StreamDriverAuthMode=\"x509/name\" StreamDriverPermittedPeers=\"*.syslog.nr-data.net\" StreamDriverMode=\"1\" ) Copy Restart the rsyslog service by running: sudo systemctl restart rsyslog Copy Check your New Relic account for logs. Legacy config file for rsyslog 7 or earlier If you are using rsyslog version 7 or below, the configuration files need to be adapted to the obsolete legacy format. This format is only kept for retro compatibility purposes. We strongly recommend to avoid using it, as stated in the rsyslog documentation. Install packages required to allow rsyslog to send logs using TLS encryption: sudo yum install rsyslog-gnutls ca-certificates Copy Optional: Configure rsyslog to tail log files and forward their contents to New Relic. Add the following to the /etc/rsyslog.conf file in order to enable its text file input module: $ModLoad imfile $InputFilePollInterval 10 $PrivDropToGroup adm $WorkDirectory /var/spool/rsyslog Copy In the /etc/rsyslog.d/ directory, create a text file named newrelic.conf. Explicitly include the newly created newrelic.conf to the /etc/rsyslog.d/ file: $IncludeConfig /etc/rsyslog.conf.d/newrelic.conf Copy Add the following to newrelic.conf, replacing YOUR_INSERT_KEY with your New Relic Insights API Insert key: ## Template expected by the New Relic Syslog endpoint $template NRLogFormat,\"YOUR_INSERT_KEY <%pri%>%protocol-version% %timestamp:::date-rfc3339% %hostname% %app-name% %procid% %msgid% %structured-data% %msg%\\n\" ## Specify each of the files to be tailed in case step 1 is done $InputFileName /path/to/file $InputFileTag <YOUR_FILE_TAG> $InputFileStateFile <UNIQUE_STATEFILE_NAME> $InputFileSeverity info $InputRunFileMonitor ## Configure TLS and log forwarding $DefaultNetstreamDriverCAFile /etc/ssl/certs/ca-certificates.crt $ActionSendStreamDriver gtls $ActionSendStreamDriverMode 1 $ActionSendStreamDriverAuthMode x509/name $ActionSendStreamDriverPermittedPeer *.syslog.nr-data.net *.* @@newrelic.syslog.nr-data.net:6514;NRLogFormat Copy Restart the rsyslog service by running: sudo systemctl restart rsyslog Copy Check your New Relic account for logs. Configure syslog-ng To forward logs to New Relic with syslog-ng: Install ca-certificates required to allow syslog-ng to send logs using TLS encryption: sudo yum install ca-certificates Copy Open the syslog-ng configuration file (/etc/syslog-ng/syslog-ng.conf) in a text editor. Define the sources to be monitored by adding: source s_src { internal(); }; Copy Optional: Configure syslog-ng to tail files by adding the following to the Sources configuration block: source s_files { file(\"<PATH_TO_FILE>\"); }; Copy Define the New Relic syslog format and add your New Relic Insights API Insert key: template NRFormat { template(\"YOUR_INSERT_KEY ${PRI}>1 ${ISODATE} ${HOST:--} ${PROGRAM:--} ${PID:--} ${MSGID:--} ${SDATA:--} $MSG\\n\"); template_escape(no); }; Copy Add the New Relic Syslog endpoint: destination d_newrelic { network(\"newrelic.syslog.nr-data.net\" port(6514) transport(\"tls\") tls(peer-verify(no)) template(NRFormat) ); }; Copy Add the following output to the log path configuration block: log { source(s_src); source(s_files); ## in case step 4 is implemented. destination(d_newrelic); }; Copy Restart syslog-ng by running: sudo service syslog-ng restart Copy Check your New Relic account for logs. Tip If you are running syslog-ng from a Docker container and experience issues, check balait/syslog image documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.16689,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use TCP endpoint to forward <em>logs</em> to New Relic",
        "sections": "Use TCP endpoint to forward <em>logs</em> to New Relic",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "We offer a wide range of solutions to get your <em>log</em> data into New Relic. But in other situations where you don&#x27;t have <em>log</em> forwarders (such as CDNs, hardware devices, or managed services), you can use syslog protocols via a TCP endpoint. You can forward your <em>logs</em> to New Relic using syslog clients"
      },
      "id": "603e7d6764441f1a774e88a0"
    }
  ],
  "/docs/logs/log-management/troubleshooting/view-log-messages-real-time-live-tail": [
    {
      "sections": [
        "Discover value in log data with patterns",
        "Technical overview",
        "Availability",
        "Important",
        "Get started",
        "Explore log patterns",
        "Explore logs with no pattern",
        "Masked attributes and wildcards",
        "Troubleshooting",
        "Put the platform to work with patterns"
      ],
      "title": "Discover value in log data with patterns",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "8f1e27c94327ca4888a945f8e12f9c2310ccd7a6",
      "image": "https://docs.newrelic.com/static/578d7186bb34352855696e5307cc82f2/c1b63/log-patterns-logs-without-a-pattern.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/find-unusual-logs-log-patterns/",
      "published_at": "2021-07-02T14:37:14Z",
      "updated_at": "2021-07-02T14:37:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Log patterns are the fastest way to discover value in log data without searching. Log data is high volume telemetry with a low value per individual record. Searching can quickly lead to logs that provide a root cause explanation, but most data is repetitive and hard to contextualize when browsing. Patterns can make log data discoverable without spending a lot of time reading through low value data. one.newrelic.com > Logs > Patterns: Use patterns as the basis for alerts when the frequency of important data changes, or for configuring drop rules to get rid of unnecessary repetitive data. Technical overview Log patterns functionality applies machine learning to normalize and group log messages that are consistent in format but variable in content. These grouped messages can be sorted, making it easy to find the most frequent or rarest sets of logs in your environment. Use patterns as the basis for alerts when the frequency of important data changes, or to configure drop rules to get rid of unnecessary repetitive data. Log patterns use advanced clustering algorithms to group together similar log messages automatically. With patterns, you can: Orient more quickly through millions of logs. Reduce the time it takes to identify unusual behavior in your log estate. Monitor the frequency of known patterns over time to focus your energy on what matters, and exclude what's irrelevant. Availability Important Log patterns are not available in the EU region. The ability to configure this feature is dependent on role-based permissions. If you see Patterns are turned off in your Log management Patterns UI, click the Configure Patterns button and enable it. If you don't see patterns within 30 minutes of enabling the feature, there may be a lack of data with a message attribute for the system to create a pattern from. Log patterns Limitations and considerations Pricing There is no separate pricing for log patterns. The only cost is for additional data generated and added to your log records. A pattern attribute will be added to all logs that match a pattern. Attributes also may be added when common values are discovered, such as GUIDs, IP addresses, URL, or email addresses. These attributes are automatically extracted from the log message as part of the pattern process. HITRUST accounts The log patterns feature is not FedRAMP compliant. FedRAMP or other HITRUST accounts are not eligible to use patterns. Regional availability Availability for this feature depends on whether you have a US or EU region account: US region accounts can use log patterns. EU region accounts cannot enable log patterns at this time. Parsing limits We have a system of safety limits on memory and CPU resources when processing logs and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com > Log management, and use the account picker dropdown to select the target account where you want to explore patterns. In the left navigation of the Log management UI, click Patterns. The main log UI changes to show patterns that match the query in the query bar. one.newrelic.com > Log management > Log patterns: The line chart shows the top 5 patterns over time. Use the time picker and query bar to adjust the results. Explore log patterns By default the log patterns UI first shows the most frequent occurrence of patterns. To sort to show the rarest patterns first, click the Count column. You can also use the query bar or attributes bar to filter your log patterns. If you want to... Do this... Understand the rate of change in patterns Look at the line chart. The color-coded patterns correspond to the plot column in the table. You can toggle individual plot patterns to narrow your focus. See the individual log messages that match each pattern Click pattern to expand the row and see a table of individual log records. To see additional records, scroll up or down. To explore an individual log in more detail, click it to open the details panel. Group and filter patterns by their attributes Use the query bar and time picker. As you apply different filters and time windows, the log patterns adjust to your new target data. Create an alert from a pattern Add the pattern to the query bar and run the query. Then click Create alert condition in the left nav. Troubleshoot log messages that haven't been clustered into a pattern Use the Logs with no pattern tab in the Log patterns UI. Clicking a specific log message will open the log message details panel you're familiar with from the Logs management page. Explore logs with no pattern The Logs with no pattern tab groups all recent log messages in your account that were not clustered into a known pattern yet. These log messages don't represent any problem or flaw in the system; they have no pattern because they are too new to have been processed by the machine learning system. This makes them valuable to explore when you want to understand what has recently changed in your environment. one.newrelic.com > Log management > Log patterns: New Relic's log patterns feature automatically groups logs without a matching pattern. For example: Are any of these logs tied to a recent problem? This is a quick way to discover unique log data that is appearing for the first time in your environment. Does your log data have a new format? Sometimes the logs don't represent a problem, but a new format of log data that deviates from the data model you expect your applications to follow. Catching these logs early gives you the opportunity to ask developers to correct any deviations in their log output. The more consistent people are in the way log data is generated, the easier it becomes to use logs across a diverse set of teams. Masked attributes and wildcards Parts of the log messages in patterns are classified as variables and are substituted by masked attributes. The masking process supports and improves the clustering phase by allowing the algorithm to ignore changing details and focus on the repetitive structure. Masked attributes include: date_time ip url uuid Masked attributes are highlighted and are easy to identify, as shown in the following example. one.newrelic.com > Log management > Log patterns: Here is an example of a pattern that has masked attributes. Log patterns extract other less trivial variables that don't belong to any masked attribute. These variables are indicated as wildcards *. one.newrelic.com > Log management > Log patterns: Here is an example of how wildcards * group variables. Troubleshooting Here are a few reasons why you might have patterns enabled but not see any pattern data. If you're sure none of the items below are true, get help from support.newrelic.com. No data has arrived in the timeframe you're observing. Try expanding the time range you're viewing with the time picker. It's been less than 24 hours since patterns were enabled in the account. This means the ML model may not be generated for the account yet. None of the data coming in has a message field. Patterns will only be generated for values in the message field of a log record. If your logs don't contain message, there will be no data. Put the platform to work with patterns Patterns are a value that is enriched onto the existing log message as a new attribute named newrelic.logPattern. Anything you can do with logs generally can be done with log patterns, such as: Build your own dashboards with patterns, to monitor a specific pattern or group of patterns you care about. Create alerts for patterns by adding NRQL alerts. Use baseline alert conditions to detect anomalies in known log patterns.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 217.56638,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Discover value in <em>log</em> data with patterns",
        "sections": "Explore <em>logs</em> with no pattern",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " and CPU resources when processing <em>logs</em> and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com &gt; <em>Log</em> <em>management</em>, and use the account picker dropdown"
      },
      "id": "6072d46128ccbc244451c18b"
    },
    {
      "sections": [
        "Organize data with partitions",
        "Plan your partition",
        "Important",
        "Required roles and permissions",
        "Sizing and organizing a partition",
        "Choosing a namespace",
        "Create partition rules",
        "Search data partitions",
        "Manage data partitions programatically with NerdGraph"
      ],
      "title": "Organize data with partitions",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "28cac5fac1065f4b1756700e7f6c11c325734c35",
      "image": "https://docs.newrelic.com/static/7815845d8068377477aa26f8571d5907/c1b63/log-partitions-crop.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/data-partitions/",
      "published_at": "2021-07-02T14:35:27Z",
      "updated_at": "2021-07-02T14:35:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Data partitions are a way to group or organize log data for faster and more efficient querying. When a query targets a single partition, New Relic Logs: Scans less unrelated data. Returns results faster. Accounts can have multiple partitions, and multiple partitions can be queried at the same time. Data partitions also allow data to be mapped to an alternative, or “secondary” namespace with a fixed 30-day retention. This is useful for maintaining compliance with privacy-centric regulations and standards like the General Data Protection Regulation (GDPR). Plan your partition Before you start creating partitions, make sure you have the right permissions and a partition plan. Important Logs are routed to partitions during the ingestion process, before data is written to NRDB. Partition rules will not affect logs that were ingested before the rule was created. Required roles and permissions Users require an Admin role to create and modify partition rules. Sizing and organizing a partition You can gain significant performance improvements with proper use of data partitions. Organizing your data into discrete partitions enables you to query them separately or all together. The goals of partitioning your data should be: Create data partitions that align with concepts in your environment or organization that are static or change infrequently (for example, by business unit, team, environment, service, etc.). Ensure each partition remains below 1 TB of daily ingest for optimal performance. Having more partitions allows for more targeted searches, but creating too many partitions can make logs hard to find and increase administrative overhead. Finding the right balance is important. We support 100 partitions maximum per account, but the optimal number for most accounts is 10 to 15 partitions. Choosing a namespace A partition’s namespace determines its retention period. We offer two retention options: Standard: The account’s default retention determined by your New Relic subscription. This is the maximum retention period available in your account and is the namespace you'll select for most of your partitions. Secondary: 30-day retention. All logs sent to a partition that's a member of the Secondary namespace will be purged on a rolling basis 30 days after having been ingested. Secondary retention is not a cost control mechanism; data is billed on ingest. Create partition rules one.newrelic.com > Logs: From the left nav in the Logs UI, select Data partitions, then create a Log_ partition name with the retention namespace, optional description, and matching criteria. To create a new partition rule: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Data partitions, then click Create partition rule. Define a Partition name as an alphanumeric string that begins with Log_. Add an optional description. Select the retention namespace for the partition. Set your rule's Matching criteria: Select EQUALS to target logs that match your criteria exactly, or select LIKE to apply a fuzzy match. Click the Enable Rule slider, and click Create. To view a list of data partitions: From Manage Data on the left nav of the Logs UI, click Data partitions. Search data partitions The default partition for all Logs accounts is Log. Any log that is not affected by a partition rule will be stored in the Log partition by default. You can query multiple partitions simultaneously. For best performance, select the smallest number of partitions possible. To search data partitions: From Views and Attributes on the left nav of the Logs UI, click Select partitions. Click one or more partitions you want to query, or search for a partition name. Click Query logs to search your selected partitions. Manage data partitions programatically with NerdGraph If you want to manage your data partitions programatically, you can use NerdGraph, our graphQL API, to do so. This tutorial shows how to query, create, and delete data partitions using our API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.79745,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Manage</em> data partitions programatically with NerdGraph",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Data partitions are a way to group or organize <em>log</em> data for faster and more efficient querying. When a query targets a single partition, New Relic <em>Logs</em>: Scans less unrelated data. Returns results faster. Accounts can have multiple partitions, and multiple partitions can be queried at the same time"
      },
      "id": "6087e311e7b9d2f90ba5c6a4"
    },
    {
      "sections": [
        "Use TCP endpoint to forward logs to New Relic",
        "Compatibility and requirements",
        "Important",
        "Configure rsyslog",
        "Legacy config file for rsyslog 7 or earlier",
        "Configure syslog-ng",
        "Tip"
      ],
      "title": "Use TCP endpoint to forward logs to New Relic",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Log API"
      ],
      "external_id": "3f572fe998dd7f72516a7b654295b779ff290176",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/log-api/use-tcp-endpoint-forward-logs-new-relic/",
      "published_at": "2021-07-02T14:33:44Z",
      "updated_at": "2021-06-25T22:58:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer a wide range of solutions to get your log data into New Relic. But in other situations where you don't have log forwarders (such as CDNs, hardware devices, or managed services), you can use syslog protocols via a TCP endpoint. You can forward your logs to New Relic using syslog clients such as rsyslog and syslog-ng. Compatibility and requirements To forward logs to New Relic using a syslog client, you need: A valid Insights API Insert key Some minor changes to the syslog client's configuration, as explained in this document Important Currently, our syslog endpoint only supports accounts in our US data center. Configure rsyslog To forward logs to New Relic with rsyslog: Install packages required to allow rsyslog to send logs using TLS encryption: sudo yum install rsyslog-gnutls ca-certificates Copy Optional: Configure rsyslog to tail log files and forward their contents to New Relic. Add the following to the /etc/rsyslog.conf file in order to enable its text file input module: module(load=\"imfile\" PollingInterval=\"10\" statefile.directory=\"/var/spool/rsyslog\" ) Copy In the /etc/rsyslog.d/ directory, create a text file named newrelic.conf. Explicitly include the newly created newrelic.conf to the /etc/rsyslog.d/ file: include(file=\"/etc/rsyslog.conf.d/newrelic.conf\") Copy Add the following to newrelic.conf, replacing YOUR_INSERT_KEY with your New Relic Insights API Insert key: ## Specify each of the files to be tailed in case step 1 is done input(type=\"imfile\" ruleset=\"infiles\" Tag=\"<YOUR_FILE_TAG>\" File=\"<PATH_TO_FILE>\" StateFile=\"<UNIQUE_STATEFILE_NAME >\") ## Template expected by the New Relic Syslog endpoint template(name=\"newrelic-rfc5424\" type=\"string\" string=\"<YOUR_INSERT_KEY> <%pri%>%protocol-version% %timestamp:::date-rfc3339% %hostname% %app-name% %procid% %msgid% %structured-data% %msg%\\n\" ) ## Configure TLS and log forwarding global(DefaultNetstreamDriver=\"gtls\" DefaultNetstreamDriverCAFile=\"/etc/ssl/certs/ca-certificates.crt\" ) action(type=\"omfwd\" Target=\"newrelic.syslog.nr-data.net\" Port=\"6514\" Protocol=\"tcp\" Template=\"newrelic-rfc5424\" ResendLastMSGOnReconnect=\"on\" StreamDriver=\"gtls\" StreamDriverAuthMode=\"x509/name\" StreamDriverPermittedPeers=\"*.syslog.nr-data.net\" StreamDriverMode=\"1\" ) Copy Restart the rsyslog service by running: sudo systemctl restart rsyslog Copy Check your New Relic account for logs. Legacy config file for rsyslog 7 or earlier If you are using rsyslog version 7 or below, the configuration files need to be adapted to the obsolete legacy format. This format is only kept for retro compatibility purposes. We strongly recommend to avoid using it, as stated in the rsyslog documentation. Install packages required to allow rsyslog to send logs using TLS encryption: sudo yum install rsyslog-gnutls ca-certificates Copy Optional: Configure rsyslog to tail log files and forward their contents to New Relic. Add the following to the /etc/rsyslog.conf file in order to enable its text file input module: $ModLoad imfile $InputFilePollInterval 10 $PrivDropToGroup adm $WorkDirectory /var/spool/rsyslog Copy In the /etc/rsyslog.d/ directory, create a text file named newrelic.conf. Explicitly include the newly created newrelic.conf to the /etc/rsyslog.d/ file: $IncludeConfig /etc/rsyslog.conf.d/newrelic.conf Copy Add the following to newrelic.conf, replacing YOUR_INSERT_KEY with your New Relic Insights API Insert key: ## Template expected by the New Relic Syslog endpoint $template NRLogFormat,\"YOUR_INSERT_KEY <%pri%>%protocol-version% %timestamp:::date-rfc3339% %hostname% %app-name% %procid% %msgid% %structured-data% %msg%\\n\" ## Specify each of the files to be tailed in case step 1 is done $InputFileName /path/to/file $InputFileTag <YOUR_FILE_TAG> $InputFileStateFile <UNIQUE_STATEFILE_NAME> $InputFileSeverity info $InputRunFileMonitor ## Configure TLS and log forwarding $DefaultNetstreamDriverCAFile /etc/ssl/certs/ca-certificates.crt $ActionSendStreamDriver gtls $ActionSendStreamDriverMode 1 $ActionSendStreamDriverAuthMode x509/name $ActionSendStreamDriverPermittedPeer *.syslog.nr-data.net *.* @@newrelic.syslog.nr-data.net:6514;NRLogFormat Copy Restart the rsyslog service by running: sudo systemctl restart rsyslog Copy Check your New Relic account for logs. Configure syslog-ng To forward logs to New Relic with syslog-ng: Install ca-certificates required to allow syslog-ng to send logs using TLS encryption: sudo yum install ca-certificates Copy Open the syslog-ng configuration file (/etc/syslog-ng/syslog-ng.conf) in a text editor. Define the sources to be monitored by adding: source s_src { internal(); }; Copy Optional: Configure syslog-ng to tail files by adding the following to the Sources configuration block: source s_files { file(\"<PATH_TO_FILE>\"); }; Copy Define the New Relic syslog format and add your New Relic Insights API Insert key: template NRFormat { template(\"YOUR_INSERT_KEY ${PRI}>1 ${ISODATE} ${HOST:--} ${PROGRAM:--} ${PID:--} ${MSGID:--} ${SDATA:--} $MSG\\n\"); template_escape(no); }; Copy Add the New Relic Syslog endpoint: destination d_newrelic { network(\"newrelic.syslog.nr-data.net\" port(6514) transport(\"tls\") tls(peer-verify(no)) template(NRFormat) ); }; Copy Add the following output to the log path configuration block: log { source(s_src); source(s_files); ## in case step 4 is implemented. destination(d_newrelic); }; Copy Restart syslog-ng by running: sudo service syslog-ng restart Copy Check your New Relic account for logs. Tip If you are running syslog-ng from a Docker container and experience issues, check balait/syslog image documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.16689,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use TCP endpoint to forward <em>logs</em> to New Relic",
        "sections": "Use TCP endpoint to forward <em>logs</em> to New Relic",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "We offer a wide range of solutions to get your <em>log</em> data into New Relic. But in other situations where you don&#x27;t have <em>log</em> forwarders (such as CDNs, hardware devices, or managed services), you can use syslog protocols via a TCP endpoint. You can forward your <em>logs</em> to New Relic using syslog clients"
      },
      "id": "603e7d6764441f1a774e88a0"
    }
  ],
  "/docs/logs/log-management/ui-data/built-log-parsing-rulesets": [
    {
      "sections": [
        "Discover value in log data with patterns",
        "Technical overview",
        "Availability",
        "Important",
        "Get started",
        "Explore log patterns",
        "Explore logs with no pattern",
        "Masked attributes and wildcards",
        "Troubleshooting",
        "Put the platform to work with patterns"
      ],
      "title": "Discover value in log data with patterns",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "8f1e27c94327ca4888a945f8e12f9c2310ccd7a6",
      "image": "https://docs.newrelic.com/static/578d7186bb34352855696e5307cc82f2/c1b63/log-patterns-logs-without-a-pattern.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/find-unusual-logs-log-patterns/",
      "published_at": "2021-07-02T14:37:14Z",
      "updated_at": "2021-07-02T14:37:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Log patterns are the fastest way to discover value in log data without searching. Log data is high volume telemetry with a low value per individual record. Searching can quickly lead to logs that provide a root cause explanation, but most data is repetitive and hard to contextualize when browsing. Patterns can make log data discoverable without spending a lot of time reading through low value data. one.newrelic.com > Logs > Patterns: Use patterns as the basis for alerts when the frequency of important data changes, or for configuring drop rules to get rid of unnecessary repetitive data. Technical overview Log patterns functionality applies machine learning to normalize and group log messages that are consistent in format but variable in content. These grouped messages can be sorted, making it easy to find the most frequent or rarest sets of logs in your environment. Use patterns as the basis for alerts when the frequency of important data changes, or to configure drop rules to get rid of unnecessary repetitive data. Log patterns use advanced clustering algorithms to group together similar log messages automatically. With patterns, you can: Orient more quickly through millions of logs. Reduce the time it takes to identify unusual behavior in your log estate. Monitor the frequency of known patterns over time to focus your energy on what matters, and exclude what's irrelevant. Availability Important Log patterns are not available in the EU region. The ability to configure this feature is dependent on role-based permissions. If you see Patterns are turned off in your Log management Patterns UI, click the Configure Patterns button and enable it. If you don't see patterns within 30 minutes of enabling the feature, there may be a lack of data with a message attribute for the system to create a pattern from. Log patterns Limitations and considerations Pricing There is no separate pricing for log patterns. The only cost is for additional data generated and added to your log records. A pattern attribute will be added to all logs that match a pattern. Attributes also may be added when common values are discovered, such as GUIDs, IP addresses, URL, or email addresses. These attributes are automatically extracted from the log message as part of the pattern process. HITRUST accounts The log patterns feature is not FedRAMP compliant. FedRAMP or other HITRUST accounts are not eligible to use patterns. Regional availability Availability for this feature depends on whether you have a US or EU region account: US region accounts can use log patterns. EU region accounts cannot enable log patterns at this time. Parsing limits We have a system of safety limits on memory and CPU resources when processing logs and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com > Log management, and use the account picker dropdown to select the target account where you want to explore patterns. In the left navigation of the Log management UI, click Patterns. The main log UI changes to show patterns that match the query in the query bar. one.newrelic.com > Log management > Log patterns: The line chart shows the top 5 patterns over time. Use the time picker and query bar to adjust the results. Explore log patterns By default the log patterns UI first shows the most frequent occurrence of patterns. To sort to show the rarest patterns first, click the Count column. You can also use the query bar or attributes bar to filter your log patterns. If you want to... Do this... Understand the rate of change in patterns Look at the line chart. The color-coded patterns correspond to the plot column in the table. You can toggle individual plot patterns to narrow your focus. See the individual log messages that match each pattern Click pattern to expand the row and see a table of individual log records. To see additional records, scroll up or down. To explore an individual log in more detail, click it to open the details panel. Group and filter patterns by their attributes Use the query bar and time picker. As you apply different filters and time windows, the log patterns adjust to your new target data. Create an alert from a pattern Add the pattern to the query bar and run the query. Then click Create alert condition in the left nav. Troubleshoot log messages that haven't been clustered into a pattern Use the Logs with no pattern tab in the Log patterns UI. Clicking a specific log message will open the log message details panel you're familiar with from the Logs management page. Explore logs with no pattern The Logs with no pattern tab groups all recent log messages in your account that were not clustered into a known pattern yet. These log messages don't represent any problem or flaw in the system; they have no pattern because they are too new to have been processed by the machine learning system. This makes them valuable to explore when you want to understand what has recently changed in your environment. one.newrelic.com > Log management > Log patterns: New Relic's log patterns feature automatically groups logs without a matching pattern. For example: Are any of these logs tied to a recent problem? This is a quick way to discover unique log data that is appearing for the first time in your environment. Does your log data have a new format? Sometimes the logs don't represent a problem, but a new format of log data that deviates from the data model you expect your applications to follow. Catching these logs early gives you the opportunity to ask developers to correct any deviations in their log output. The more consistent people are in the way log data is generated, the easier it becomes to use logs across a diverse set of teams. Masked attributes and wildcards Parts of the log messages in patterns are classified as variables and are substituted by masked attributes. The masking process supports and improves the clustering phase by allowing the algorithm to ignore changing details and focus on the repetitive structure. Masked attributes include: date_time ip url uuid Masked attributes are highlighted and are easy to identify, as shown in the following example. one.newrelic.com > Log management > Log patterns: Here is an example of a pattern that has masked attributes. Log patterns extract other less trivial variables that don't belong to any masked attribute. These variables are indicated as wildcards *. one.newrelic.com > Log management > Log patterns: Here is an example of how wildcards * group variables. Troubleshooting Here are a few reasons why you might have patterns enabled but not see any pattern data. If you're sure none of the items below are true, get help from support.newrelic.com. No data has arrived in the timeframe you're observing. Try expanding the time range you're viewing with the time picker. It's been less than 24 hours since patterns were enabled in the account. This means the ML model may not be generated for the account yet. None of the data coming in has a message field. Patterns will only be generated for values in the message field of a log record. If your logs don't contain message, there will be no data. Put the platform to work with patterns Patterns are a value that is enriched onto the existing log message as a new attribute named newrelic.logPattern. Anything you can do with logs generally can be done with log patterns, such as: Build your own dashboards with patterns, to monitor a specific pattern or group of patterns you care about. Create alerts for patterns by adding NRQL alerts. Use baseline alert conditions to detect anomalies in known log patterns.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 336.3489,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Discover value in <em>log</em> <em>data</em> with patterns",
        "sections": "Discover value in <em>log</em> <em>data</em> with patterns",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " this feature is dependent on role-based permissions. If you see Patterns are turned off in your <em>Log</em> <em>management</em> Patterns <em>UI</em>, click the Configure Patterns button and enable it. If you don&#x27;t see patterns within 30 minutes of enabling the feature, there may be a lack of <em>data</em> with a message attribute"
      },
      "id": "6072d46128ccbc244451c18b"
    },
    {
      "sections": [
        "Organize data with partitions",
        "Plan your partition",
        "Important",
        "Required roles and permissions",
        "Sizing and organizing a partition",
        "Choosing a namespace",
        "Create partition rules",
        "Search data partitions",
        "Manage data partitions programatically with NerdGraph"
      ],
      "title": "Organize data with partitions",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "28cac5fac1065f4b1756700e7f6c11c325734c35",
      "image": "https://docs.newrelic.com/static/7815845d8068377477aa26f8571d5907/c1b63/log-partitions-crop.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/data-partitions/",
      "published_at": "2021-07-02T14:35:27Z",
      "updated_at": "2021-07-02T14:35:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Data partitions are a way to group or organize log data for faster and more efficient querying. When a query targets a single partition, New Relic Logs: Scans less unrelated data. Returns results faster. Accounts can have multiple partitions, and multiple partitions can be queried at the same time. Data partitions also allow data to be mapped to an alternative, or “secondary” namespace with a fixed 30-day retention. This is useful for maintaining compliance with privacy-centric regulations and standards like the General Data Protection Regulation (GDPR). Plan your partition Before you start creating partitions, make sure you have the right permissions and a partition plan. Important Logs are routed to partitions during the ingestion process, before data is written to NRDB. Partition rules will not affect logs that were ingested before the rule was created. Required roles and permissions Users require an Admin role to create and modify partition rules. Sizing and organizing a partition You can gain significant performance improvements with proper use of data partitions. Organizing your data into discrete partitions enables you to query them separately or all together. The goals of partitioning your data should be: Create data partitions that align with concepts in your environment or organization that are static or change infrequently (for example, by business unit, team, environment, service, etc.). Ensure each partition remains below 1 TB of daily ingest for optimal performance. Having more partitions allows for more targeted searches, but creating too many partitions can make logs hard to find and increase administrative overhead. Finding the right balance is important. We support 100 partitions maximum per account, but the optimal number for most accounts is 10 to 15 partitions. Choosing a namespace A partition’s namespace determines its retention period. We offer two retention options: Standard: The account’s default retention determined by your New Relic subscription. This is the maximum retention period available in your account and is the namespace you'll select for most of your partitions. Secondary: 30-day retention. All logs sent to a partition that's a member of the Secondary namespace will be purged on a rolling basis 30 days after having been ingested. Secondary retention is not a cost control mechanism; data is billed on ingest. Create partition rules one.newrelic.com > Logs: From the left nav in the Logs UI, select Data partitions, then create a Log_ partition name with the retention namespace, optional description, and matching criteria. To create a new partition rule: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Data partitions, then click Create partition rule. Define a Partition name as an alphanumeric string that begins with Log_. Add an optional description. Select the retention namespace for the partition. Set your rule's Matching criteria: Select EQUALS to target logs that match your criteria exactly, or select LIKE to apply a fuzzy match. Click the Enable Rule slider, and click Create. To view a list of data partitions: From Manage Data on the left nav of the Logs UI, click Data partitions. Search data partitions The default partition for all Logs accounts is Log. Any log that is not affected by a partition rule will be stored in the Log partition by default. You can query multiple partitions simultaneously. For best performance, select the smallest number of partitions possible. To search data partitions: From Views and Attributes on the left nav of the Logs UI, click Select partitions. Click one or more partitions you want to query, or search for a partition name. Click Query logs to search your selected partitions. Manage data partitions programatically with NerdGraph If you want to manage your data partitions programatically, you can use NerdGraph, our graphQL API, to do so. This tutorial shows how to query, create, and delete data partitions using our API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 336.32617,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Organize <em>data</em> with partitions",
        "sections": "<em>Manage</em> <em>data</em> partitions programatically with NerdGraph",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " partition rules one.newrelic.com &gt; <em>Logs</em>: From the left nav in the <em>Logs</em> <em>UI</em>, select <em>Data</em> partitions, then create a <em>Log</em>_ partition name with the retention namespace, optional description, and matching criteria. To create a new partition rule: Go to one.newrelic.com &gt; <em>Logs</em>. From Manage <em>Data</em> on the left nav"
      },
      "id": "6087e311e7b9d2f90ba5c6a4"
    },
    {
      "sections": [
        "Drop data with drop filter rules",
        "Savings, security, speed",
        "Caution",
        "How drop filter rules work",
        "Cautions when dropping data",
        "Create drop filter rules",
        "Types of drop filter rules",
        "Drop log events",
        "Drop attributes",
        "Tip",
        "View or delete drop filter rules"
      ],
      "title": "Drop data with drop filter rules ",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "9590bd4593abd451633a4beacd94d56eb1a481bd",
      "image": "https://docs.newrelic.com/static/db4b077fafd911b9f5019b022b3048ab/b04e4/ingest-pipeline.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/drop-data-drop-filter-rules/",
      "published_at": "2021-07-02T14:35:27Z",
      "updated_at": "2021-06-26T14:34:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After log event data has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both log events and event attributes via drop filter rules. You can manage drop filter rules using our Logs UI, as explained in this document. You can also use NerdGraph. Savings, security, speed Drop filter rules help you accomplish several important goals: Lower costs by storing only logs relevant to your account. Protect privacy and security by removing personal identifiable information (PII). Reduce noise by removing irrelevant events and attributes. Caution Use caution when deciding to drop data. The data you drop is not recoverable. Before using this feature, review the responsibilities and considerations for dropping data. How drop filter rules work A drop filter rule matches data based on a query. When triggered, the drop filter rule removes the matching data from the ingestion pipeline before it is written to NRDB. This creates an explicit demarcation between the logs being forwarded from your domain and the data that New Relic collects. Since the data removed by the drop filter rule doesn't reach our backend, it cannot be queried: the data is gone and cannot be restored. During the ingestion process, customer log data can be parsed, transformed, or dropped before being stored in New Relic's database. Cautions when dropping data When creating drop rules, you are responsible for ensuring that the rules accurately identify and discard the data that meets the conditions that you have established. You are also responsible for monitoring the rule, as well as the data you disclose to New Relic. New Relic cannot guarantee that this functionality will completely resolve data disclosure concerns you may have. New Relic doesn't review or monitor how effective the rules you develop are. Creating rules about sensitive data can leak information about what kinds of data you maintain, including the format of your data or systems (for example, through referencing email addresses or specific credit card numbers). Any user with the relevant role-based access control permissions can view and edit all information in the rules you create. Create drop filter rules To create and edit drop filters, you must have admin permissions in New Relic, or you must be a member of a role with create and edit permissions for Logging Parsing Rules. Once a drop filter rule is active, it's applied to all log events ingested from that point onwards. Rules are not applied retroactively. Logs collected before creating a rule are not filtered by that rule. one.newrelic.com > Logs: Filter or query the set of logs that contain the data you want to drop. Then, from Manage Data on the left nav of the Logs UI, click Create drop filter. To create a new drop filter rule, you can use new or existing log queries. Go to one.newrelic.com > Logs. Filter or query to the specific set of logs that contain the data to be dropped. Once the query is active, from Manage Data on the left nav of the Logs UI, click Create drop filter. Recommendation: Change the drop rule's default name to a meaningful name. Choose to either drop the entire log event that matches the query or just a specific subset of attributes in the matching events. Review the log partitions where this drop rule applies. Save the drop filter rule. Types of drop filter rules The drop filters UI prompts you to select whether to drop logs based on the query or on specific attributes. Drop log events The default type of drop filter rule is to drop logs. This option drops the entire log events that match the filter or query. When creating a rule, try to provide a specific query that only matches log data that should be dropped. Our drop filters process won't let you create drop filter rules without values in the matching query. This prevents badly formed rules from dropping all log data. Drop attributes You can specify attributes to be dropped in a log event that matches your query. At least one or more attributes must be selected. Any attribute which is selected will be dropped; all remaining attributes will be kept and stored in NRDB. Tip We recommend this method for removing fields that could contain personal identifiable information (PII) or other sensitive attributes without losing valuable monitoring data. View or delete drop filter rules To view or delete a drop filter rule: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Drop filters. Click the delete icon next to the drop filter rule you want to remove. Once deleted, rules no longer filter ingested log events.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.24423,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Drop <em>data</em> with drop filter rules ",
        "sections": "Drop <em>data</em> with drop filter rules",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "After <em>log</em> event <em>data</em> has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both <em>log</em> events and event attributes via drop filter rules. You can manage drop filter rules using our <em>Logs</em> <em>UI</em>, as explained in this document. You can also use"
      },
      "id": "603e813f28ccbc08c1eba787"
    }
  ],
  "/docs/logs/log-management/ui-data/data-partitions": [
    {
      "sections": [
        "Discover value in log data with patterns",
        "Technical overview",
        "Availability",
        "Important",
        "Get started",
        "Explore log patterns",
        "Explore logs with no pattern",
        "Masked attributes and wildcards",
        "Troubleshooting",
        "Put the platform to work with patterns"
      ],
      "title": "Discover value in log data with patterns",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "8f1e27c94327ca4888a945f8e12f9c2310ccd7a6",
      "image": "https://docs.newrelic.com/static/578d7186bb34352855696e5307cc82f2/c1b63/log-patterns-logs-without-a-pattern.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/find-unusual-logs-log-patterns/",
      "published_at": "2021-07-02T14:37:14Z",
      "updated_at": "2021-07-02T14:37:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Log patterns are the fastest way to discover value in log data without searching. Log data is high volume telemetry with a low value per individual record. Searching can quickly lead to logs that provide a root cause explanation, but most data is repetitive and hard to contextualize when browsing. Patterns can make log data discoverable without spending a lot of time reading through low value data. one.newrelic.com > Logs > Patterns: Use patterns as the basis for alerts when the frequency of important data changes, or for configuring drop rules to get rid of unnecessary repetitive data. Technical overview Log patterns functionality applies machine learning to normalize and group log messages that are consistent in format but variable in content. These grouped messages can be sorted, making it easy to find the most frequent or rarest sets of logs in your environment. Use patterns as the basis for alerts when the frequency of important data changes, or to configure drop rules to get rid of unnecessary repetitive data. Log patterns use advanced clustering algorithms to group together similar log messages automatically. With patterns, you can: Orient more quickly through millions of logs. Reduce the time it takes to identify unusual behavior in your log estate. Monitor the frequency of known patterns over time to focus your energy on what matters, and exclude what's irrelevant. Availability Important Log patterns are not available in the EU region. The ability to configure this feature is dependent on role-based permissions. If you see Patterns are turned off in your Log management Patterns UI, click the Configure Patterns button and enable it. If you don't see patterns within 30 minutes of enabling the feature, there may be a lack of data with a message attribute for the system to create a pattern from. Log patterns Limitations and considerations Pricing There is no separate pricing for log patterns. The only cost is for additional data generated and added to your log records. A pattern attribute will be added to all logs that match a pattern. Attributes also may be added when common values are discovered, such as GUIDs, IP addresses, URL, or email addresses. These attributes are automatically extracted from the log message as part of the pattern process. HITRUST accounts The log patterns feature is not FedRAMP compliant. FedRAMP or other HITRUST accounts are not eligible to use patterns. Regional availability Availability for this feature depends on whether you have a US or EU region account: US region accounts can use log patterns. EU region accounts cannot enable log patterns at this time. Parsing limits We have a system of safety limits on memory and CPU resources when processing logs and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com > Log management, and use the account picker dropdown to select the target account where you want to explore patterns. In the left navigation of the Log management UI, click Patterns. The main log UI changes to show patterns that match the query in the query bar. one.newrelic.com > Log management > Log patterns: The line chart shows the top 5 patterns over time. Use the time picker and query bar to adjust the results. Explore log patterns By default the log patterns UI first shows the most frequent occurrence of patterns. To sort to show the rarest patterns first, click the Count column. You can also use the query bar or attributes bar to filter your log patterns. If you want to... Do this... Understand the rate of change in patterns Look at the line chart. The color-coded patterns correspond to the plot column in the table. You can toggle individual plot patterns to narrow your focus. See the individual log messages that match each pattern Click pattern to expand the row and see a table of individual log records. To see additional records, scroll up or down. To explore an individual log in more detail, click it to open the details panel. Group and filter patterns by their attributes Use the query bar and time picker. As you apply different filters and time windows, the log patterns adjust to your new target data. Create an alert from a pattern Add the pattern to the query bar and run the query. Then click Create alert condition in the left nav. Troubleshoot log messages that haven't been clustered into a pattern Use the Logs with no pattern tab in the Log patterns UI. Clicking a specific log message will open the log message details panel you're familiar with from the Logs management page. Explore logs with no pattern The Logs with no pattern tab groups all recent log messages in your account that were not clustered into a known pattern yet. These log messages don't represent any problem or flaw in the system; they have no pattern because they are too new to have been processed by the machine learning system. This makes them valuable to explore when you want to understand what has recently changed in your environment. one.newrelic.com > Log management > Log patterns: New Relic's log patterns feature automatically groups logs without a matching pattern. For example: Are any of these logs tied to a recent problem? This is a quick way to discover unique log data that is appearing for the first time in your environment. Does your log data have a new format? Sometimes the logs don't represent a problem, but a new format of log data that deviates from the data model you expect your applications to follow. Catching these logs early gives you the opportunity to ask developers to correct any deviations in their log output. The more consistent people are in the way log data is generated, the easier it becomes to use logs across a diverse set of teams. Masked attributes and wildcards Parts of the log messages in patterns are classified as variables and are substituted by masked attributes. The masking process supports and improves the clustering phase by allowing the algorithm to ignore changing details and focus on the repetitive structure. Masked attributes include: date_time ip url uuid Masked attributes are highlighted and are easy to identify, as shown in the following example. one.newrelic.com > Log management > Log patterns: Here is an example of a pattern that has masked attributes. Log patterns extract other less trivial variables that don't belong to any masked attribute. These variables are indicated as wildcards *. one.newrelic.com > Log management > Log patterns: Here is an example of how wildcards * group variables. Troubleshooting Here are a few reasons why you might have patterns enabled but not see any pattern data. If you're sure none of the items below are true, get help from support.newrelic.com. No data has arrived in the timeframe you're observing. Try expanding the time range you're viewing with the time picker. It's been less than 24 hours since patterns were enabled in the account. This means the ML model may not be generated for the account yet. None of the data coming in has a message field. Patterns will only be generated for values in the message field of a log record. If your logs don't contain message, there will be no data. Put the platform to work with patterns Patterns are a value that is enriched onto the existing log message as a new attribute named newrelic.logPattern. Anything you can do with logs generally can be done with log patterns, such as: Build your own dashboards with patterns, to monitor a specific pattern or group of patterns you care about. Create alerts for patterns by adding NRQL alerts. Use baseline alert conditions to detect anomalies in known log patterns.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 336.3489,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Discover value in <em>log</em> <em>data</em> with patterns",
        "sections": "Discover value in <em>log</em> <em>data</em> with patterns",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " this feature is dependent on role-based permissions. If you see Patterns are turned off in your <em>Log</em> <em>management</em> Patterns <em>UI</em>, click the Configure Patterns button and enable it. If you don&#x27;t see patterns within 30 minutes of enabling the feature, there may be a lack of <em>data</em> with a message attribute"
      },
      "id": "6072d46128ccbc244451c18b"
    },
    {
      "sections": [
        "Drop data with drop filter rules",
        "Savings, security, speed",
        "Caution",
        "How drop filter rules work",
        "Cautions when dropping data",
        "Create drop filter rules",
        "Types of drop filter rules",
        "Drop log events",
        "Drop attributes",
        "Tip",
        "View or delete drop filter rules"
      ],
      "title": "Drop data with drop filter rules ",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "9590bd4593abd451633a4beacd94d56eb1a481bd",
      "image": "https://docs.newrelic.com/static/db4b077fafd911b9f5019b022b3048ab/b04e4/ingest-pipeline.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/drop-data-drop-filter-rules/",
      "published_at": "2021-07-02T14:35:27Z",
      "updated_at": "2021-06-26T14:34:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After log event data has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both log events and event attributes via drop filter rules. You can manage drop filter rules using our Logs UI, as explained in this document. You can also use NerdGraph. Savings, security, speed Drop filter rules help you accomplish several important goals: Lower costs by storing only logs relevant to your account. Protect privacy and security by removing personal identifiable information (PII). Reduce noise by removing irrelevant events and attributes. Caution Use caution when deciding to drop data. The data you drop is not recoverable. Before using this feature, review the responsibilities and considerations for dropping data. How drop filter rules work A drop filter rule matches data based on a query. When triggered, the drop filter rule removes the matching data from the ingestion pipeline before it is written to NRDB. This creates an explicit demarcation between the logs being forwarded from your domain and the data that New Relic collects. Since the data removed by the drop filter rule doesn't reach our backend, it cannot be queried: the data is gone and cannot be restored. During the ingestion process, customer log data can be parsed, transformed, or dropped before being stored in New Relic's database. Cautions when dropping data When creating drop rules, you are responsible for ensuring that the rules accurately identify and discard the data that meets the conditions that you have established. You are also responsible for monitoring the rule, as well as the data you disclose to New Relic. New Relic cannot guarantee that this functionality will completely resolve data disclosure concerns you may have. New Relic doesn't review or monitor how effective the rules you develop are. Creating rules about sensitive data can leak information about what kinds of data you maintain, including the format of your data or systems (for example, through referencing email addresses or specific credit card numbers). Any user with the relevant role-based access control permissions can view and edit all information in the rules you create. Create drop filter rules To create and edit drop filters, you must have admin permissions in New Relic, or you must be a member of a role with create and edit permissions for Logging Parsing Rules. Once a drop filter rule is active, it's applied to all log events ingested from that point onwards. Rules are not applied retroactively. Logs collected before creating a rule are not filtered by that rule. one.newrelic.com > Logs: Filter or query the set of logs that contain the data you want to drop. Then, from Manage Data on the left nav of the Logs UI, click Create drop filter. To create a new drop filter rule, you can use new or existing log queries. Go to one.newrelic.com > Logs. Filter or query to the specific set of logs that contain the data to be dropped. Once the query is active, from Manage Data on the left nav of the Logs UI, click Create drop filter. Recommendation: Change the drop rule's default name to a meaningful name. Choose to either drop the entire log event that matches the query or just a specific subset of attributes in the matching events. Review the log partitions where this drop rule applies. Save the drop filter rule. Types of drop filter rules The drop filters UI prompts you to select whether to drop logs based on the query or on specific attributes. Drop log events The default type of drop filter rule is to drop logs. This option drops the entire log events that match the filter or query. When creating a rule, try to provide a specific query that only matches log data that should be dropped. Our drop filters process won't let you create drop filter rules without values in the matching query. This prevents badly formed rules from dropping all log data. Drop attributes You can specify attributes to be dropped in a log event that matches your query. At least one or more attributes must be selected. Any attribute which is selected will be dropped; all remaining attributes will be kept and stored in NRDB. Tip We recommend this method for removing fields that could contain personal identifiable information (PII) or other sensitive attributes without losing valuable monitoring data. View or delete drop filter rules To view or delete a drop filter rule: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Drop filters. Click the delete icon next to the drop filter rule you want to remove. Once deleted, rules no longer filter ingested log events.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.24423,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Drop <em>data</em> with drop filter rules ",
        "sections": "Drop <em>data</em> with drop filter rules",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "After <em>log</em> event <em>data</em> has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both <em>log</em> events and event attributes via drop filter rules. You can manage drop filter rules using our <em>Logs</em> <em>UI</em>, as explained in this document. You can also use"
      },
      "id": "603e813f28ccbc08c1eba787"
    },
    {
      "sections": [
        "Understand and use the distributed tracing UI",
        "Open the distributed tracing UI",
        "View traces for a specific service",
        "View traces across all accounts",
        "Tip",
        "Find traces that are useful",
        "Filter using the query bar",
        "Find traces that touch two services",
        "Find error spans using the like operator",
        "Trace groups",
        "Filter using the scatter plot",
        "Filters",
        "Trace histograms",
        "Important",
        "Trace details UI page",
        "Span details pane",
        "View related logs",
        "Additional UI details",
        "How to understand span errors",
        "Anomalous spans",
        "Client span duration: time differences between client and server spans",
        "Fragmented traces",
        "Trace details obfuscated based on account access",
        "Span limits and sampling",
        "Incomplete span names in waterfall view",
        "Missing spans and span/service count discrepancies"
      ],
      "title": "Understand and use the distributed tracing UI",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "f5b66e03583e42613810f1390b4e5adab4ed2caa",
      "image": "https://docs.newrelic.com/static/ec08996f31e6586bb257c6f89b3c8f99/e5166/new-relic-distributed-tracing-client-span-time.jpg",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/understand-use-distributed-tracing-ui/",
      "published_at": "2021-07-02T19:11:31Z",
      "updated_at": "2021-07-02T19:11:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing helps you monitor and analyze the behavior of your distributed system. After you enable distributed tracing, you can use our UI tools to search for traces and analyze them. For example, let's say you are an engineer troubleshooting errors in a complex transaction spanning many services. Here's what you can do in our UI: Open the distributed tracing UI page. Sort through your traces using a filter to find that specific request and show only traces containing errors. On the trace details page, you review the span along the request route that originated the error. Noting the error class and message, navigate to the service from its span in the trace so you can see that the error is occurring at a high rate. Read on to explore the options in the distributed tracing UI. Open the distributed tracing UI Here's how you can access the distributed tracing UI, depending on the type of search you want to do: View traces for a specific service The New Relic Explorer and APM are two menu options that help you navigate to a specific service so you can see traces that include that service. Go to one.newrelic.com. Click Explorer or APM in the top menu bar. Filter to the service you enabled for distributed tracing by typing the service name, and then press Enter. In the left navigation's Monitor section, click Distributed tracing. View traces across all accounts If you want to view traces from across all accounts you have access to, go to one.newrelic.com, click Browse data, and then Traces. Tip If you don't have access to accounts for some services in a trace, we'll obfuscate some details for those services. Find traces that are useful We have a variety of tools to help you find traces and spans so you can resolve issues. The opening distributed tracing page is populated with a default list of traces, and you can quickly refine this list using these tools: Query bar Trace groups Scatter plot chart Filters Interactive histograms Tip In addition to these tools, you can also use other options mentioned in Query distributed trace data. Filter using the query bar The Find traces query bar is a quick way to narrow your search for traces. You can either start typing in the query bar or use the dropdown to create a compound query. Query returns are based on span attributes, not on trace attributes. You define spans that have certain criteria, and the search displays traces that contain those spans. If you use a multi-attribute filter, it is affected by first attribute selected. Distributed tracing reports on two types of data: transaction events and spans. When you select an attribute in the filter, the data type that attribute is attached to dictates the available attributes. For example, if you filter on an attribute that is attached to a transaction event, only transaction event attributes are available when you attempt to add filter on additional attribute values. Queries for traces are similar to NRQL (our query language). Here are the main exceptions: String values don't require quote marks (for example, you can use either appName = MyApp or appName = 'MyApp') The like operator doesn’t require % (for example, you can use either appName like product or appName like %product%). Tip Some queries that return a large number of results may return false positives. The trace list limits these incorrect results to 10% of the returned results. False positives may also result in histogram chart results that are not displayed in the trace list. Here are two query bar examples: Find traces that touch two services The query in the image below finds traces that: Pass through both WebPortal and Inventory Service applications Have an Inventory Service datastore call that takes longer than 500 ms Contains an error in any span. Go to one.newrelic.com > Apps > Distributed tracing Find error spans using the like operator The query in the image below finds traces that: Contain spans that pass through the WebPortal application and where an error occurred on any span in the WebPortal application Contain spans where the customer_user_email attribute contains a value ending with hotmail.com anywhere in the trace. Go to one.newrelic.com > Apps > Distributed tracing Trace groups The default view of distributed tracing shows traces grouped by the same root entry span. In other words, traces are grouped by the span where New Relic began recording the request. You can slide the toggle Group similar traces to turn this on and off. With trace groups you get a high-level view of traces so you can understand request behavior for groups of similar traces. This helps you understand dips or spikes in trace count, duration, and errors. When you click on one of the trace groups, you get all the standard details in context of the specific trace group you selected. Filter using the scatter plot The trace scatter plot is a quick way to search for outlying traces. This is available on the opening page of distributed tracing if you turn off the Group similar traces toggle at the top of the page. In the scatter plot, you can move the cursor across the chart to view trace details and you can click individual points to get details: Here's how you can control what's displayed in the scatter plot: In the View by dropdown, select the duration type: Back-end duration Root span duration Trace duration In Group traces by, select one of these options: Errors: Group by whether or not traces contain errors. Root service: Group by the name of the first service in traces. In a trace where Service A calls Service B and Service B calls Service C, the root service would be Service A. Root entry span: Group by the root transaction, which is the root service's endpoint. In a trace where Service A calls Service B and Service B calls Service C, the root entry span is Service A's endpoint. For example: \"Service A - GET /user/%\". Service entry span: Group by the span name of the service currently being viewed in APM. For example, for a trace where Service A calls Service B and Service B calls Service C, if you're viewing Service B in APM and select this grouping, the traces will be represented by their Service B span names. If a service has multiple spans in a trace, this grouping option will use that service's first entry point. Filters In the left pane, you can filter traces by multi-span traces, specific entities, or error types. Once you select a filter, only traces associated with that specific type are displayed. This makes it much easier to view the traces you're most interested in so you can find and fix issues faster. Trace histograms The histogram charts give you a quick understanding of trace distribution for important values, such as duration. Click Show filters at the bottom of the left pane to display the histograms. When you move the histogram sliders, they change the data displayed in the scatterplot or the trace group charts. For example, you can drag the Trace duration chart slider to show only traces over 500 ms, as shown in the histogram example below. Important Some queries that produce many results may result in false positives in histograms. This could manifest as histograms showing trace results that are not in the trace list. Trace details UI page When you select a trace from the trace list, you see that trace's timeline and spans: one.newrelic.com > APM > (select an application) > Monitor > Distributed tracing > (select a trace) > (select a span): See the spans in a trace. Examine individual span details and see notifications for spans with anomalous behavior. The UI indicates some span properties with icons: Span property Indicator Description Service This icon represents a span that's a service's entry point. In-process This icon represents an in-process span, which is a span that takes place within a process (as opposed to a cross-process span). Examples: middleware instrumentation, user-created spans. Datastore This icon represents a span call to a datastore. External This icon represents category representing a call to an external service made via HTTP. Browser app This icon represents a browser application span. Lambda This icon represents a span from a Lambda function. Some spans will have additional indicators: Span property Indicator Description Type of connection Solid lines indicate a direct parent-child relationship; in other words, one process or function directly calling another. A dotted line indicates a non-direct relationship. For more on relationships between spans, see Trace structure. Errors A span with an error. See How to understand span errors. Anomalous This icon represents the detection of an anomalous span. Orphaned spans Some spans may be \"orphaned,\" or separated, from the trace. These spans will appear at the bottom of the trace. For more details, see Fragmented traces. Multiple app names When beside a span name, this represents an entity that has had multiple app names set. Select this to see all app names it reports to. To search trace data by alternate app names, use the appName attribute. Client/server time difference If a span's duration indicator is not completely colored in (like in this example), it means that there is a time discrepancy between the server-side duration and the client-side duration for that activity. For details on this, see Client/server time difference. For more on the trace structure and how span properties are determined, see Trace structure. Span details pane When you select a span, a pane opens up with span details. These details can be helpful for troubleshooting performance issues. Details include: Performance charts Span attributes The span's data source Anomalous span details The span's full name What a span displays is based on its span type. For example, a datastore span's name attribute will contain the datastore query. View related logs If you are using our logs in context feature together with our log management, you can see any logs that are linked to your traces: Go to the trace details page by clicking on a trace. Click See logs in the upper-right corner. For details related to an individual log message, click directly on the message. Additional UI details Here are some additional distributed tracing UI details, rules, and limits: How to understand span errors Span-level errors show you where errors originated in a process, how they bubbled up, and where they were handled. Every span that ends with an exception is shown with an error in the UI and contributes to the total error count for that trace. Here are some general tips about understanding span errors: Spans with errors are highlighted red in the distributed tracing UI. You can see more information on the Error Details pane for each span. All spans that exit with errors are counted in the span error count. When multiple errors occur on the same span, only one is written to the span in this order of precedence: A noticeError The most recent span exception This table describes how different span errors are handled: Error type Description Spans ending in exceptions An exception that leaves the boundary of a span results in an error on that span and on any ancestor spans that also exit with an error, until the exception is caught or exits the transaction. You can see if an exception is caught in an ancestor span. Notice errors Errors noticed by calls to the agent noticeError API or by the automatic agent instrumentation are attached to the currently executing span. Response code errors Response code errors are attached to the associated span, such as: Client span: External transactions prefixed with http or db. Entry span: In the case of a transaction ending in a response code error. The response code for these spans is captured as an attribute httpResponseCode and attached to that span. Anomalous spans If a span is displayed as anomalous in the UI, it means that the following are both true: The span is more than two standard deviations slower than the average of all spans with the same name from the same service over the last six hours. The span's duration is more than 10% of the trace's duration. Client span duration: time differences between client and server spans When a process calls another process, and both processes are instrumented by New Relic, the trace contains both a client-side representation of the call and a server-side representation. The client span (calling process) can have time-related differences when compared to the server span (called process). These differences could be due to: Clock skew, due to system clock time differences Differences in duration, due to things like network latency or DNS resolution delay The UI shows these time-related differences by displaying an outline of the client span in the same space as the server span. This span represents the duration of the client span. It isn't possible to determine every factor contributing to these time-related discrepancies, but here are some common span patterns and tips for understanding them: When a client span is longer than the server span, this could be due to latency in a number of areas, such as: network time, queue time, DNS resolution time, or from a load balancer that we cannot see. When a client span starts and ends before a server span begins, this could be due to clock skew, or due to the server doing asynchronous work that continues after sending the response. When a client span starts after a server span, this is most likely clock skew. Fragmented traces Fragmented traces are traces with missing spans. When a span is missing or has invalid parent span IDs, its children spans become separated from the rest of the trace, which we refer to as \"orphaned.\" Orphaned spans appear at the bottom of the trace, and they will lack connecting lines to the rest of the trace. Types of orphaned span properties indicated in the UI: No root span. Missing the root span, which is the first operation in the request. When this happens, the span with the earliest timestamp is displayed as the root. Orphaned span. A single span with a missing parent span. This could be due to the parent span having an ID that doesn't match its child span. Orphaned trace fragment. A group of connected spans where the first span in the group is an orphan span. This can happen for a number of reasons, including: Collection limits. Some high-throughput applications may exceed collection limits (for example, APM agent collection limits, or API limits). When this happens, it may result in traces having missing spans. One way to remedy this is to turn off some reporting, so that the limit is not reached. Incorrect instrumentation. If an application is instrumented incorrectly, it won't pass trace context correctly and this will result in fragmented traces. To remedy this, examine the data source that is generating orphan spans to ensure instrumentation is done correctly. To discover a span's data source, select it and examine its span details. Spans still arriving. If some parent spans haven't been collected yet, this can result in temporary gaps until the entire trace has reported. UI display limits. Orphaned spans may result if a trace exceeds the 10K span display limit. Trace details obfuscated based on account access If you don’t have access to the New Relic accounts that monitor other services, some of the span and service details will be obfuscated in the UI. Obfuscation can include: Span name concealed by asterisks Service name replaced with New Relic account ID and app ID For more information on the factors affecting your access to accounts, see Account access. Span limits and sampling See Sampling. Incomplete span names in waterfall view When viewing the span waterfall, span names may be displayed in an incomplete form that is more human-readable than the complete span name. To find the complete name, select that span and look for the Full span name. Knowing the complete name can be valuable for querying that data with NRQL. Missing spans and span/service count discrepancies A trace may sometimes have (or seem to have) missing spans or services. This can manifest as a discrepancy between the count of a trace's spans or services displayed in the trace list and the count displayed on the trace details page. Reasons for missing spans and count discrepancies include: An APM agent may have hit its 1K span collection limit. A span may be initially counted but not make it into a trace display, for reasons such as network latency or a query issue. The UI may have hit its 10K span display limit. All spans collected, including those not displayed, can be queried with NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.27554,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Understand <em>and</em> use the distributed tracing <em>UI</em>",
        "sections": "Understand <em>and</em> use the distributed tracing <em>UI</em>",
        "tags": "<em>UI</em> <em>and</em> <em>data</em>",
        "body": " together with our <em>log</em> <em>management</em>, you can see any <em>logs</em> that are linked to your traces: Go to the trace details page by clicking on a trace. Click See <em>logs</em> in the upper-right corner. For details related to an individual <em>log</em> message, click directly on the message. Additional <em>UI</em> details Here are some"
      },
      "id": "6072a70028ccbc265a51c13d"
    }
  ],
  "/docs/logs/log-management/ui-data/drop-data-drop-filter-rules": [
    {
      "sections": [
        "Discover value in log data with patterns",
        "Technical overview",
        "Availability",
        "Important",
        "Get started",
        "Explore log patterns",
        "Explore logs with no pattern",
        "Masked attributes and wildcards",
        "Troubleshooting",
        "Put the platform to work with patterns"
      ],
      "title": "Discover value in log data with patterns",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "8f1e27c94327ca4888a945f8e12f9c2310ccd7a6",
      "image": "https://docs.newrelic.com/static/578d7186bb34352855696e5307cc82f2/c1b63/log-patterns-logs-without-a-pattern.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/find-unusual-logs-log-patterns/",
      "published_at": "2021-07-02T14:37:14Z",
      "updated_at": "2021-07-02T14:37:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Log patterns are the fastest way to discover value in log data without searching. Log data is high volume telemetry with a low value per individual record. Searching can quickly lead to logs that provide a root cause explanation, but most data is repetitive and hard to contextualize when browsing. Patterns can make log data discoverable without spending a lot of time reading through low value data. one.newrelic.com > Logs > Patterns: Use patterns as the basis for alerts when the frequency of important data changes, or for configuring drop rules to get rid of unnecessary repetitive data. Technical overview Log patterns functionality applies machine learning to normalize and group log messages that are consistent in format but variable in content. These grouped messages can be sorted, making it easy to find the most frequent or rarest sets of logs in your environment. Use patterns as the basis for alerts when the frequency of important data changes, or to configure drop rules to get rid of unnecessary repetitive data. Log patterns use advanced clustering algorithms to group together similar log messages automatically. With patterns, you can: Orient more quickly through millions of logs. Reduce the time it takes to identify unusual behavior in your log estate. Monitor the frequency of known patterns over time to focus your energy on what matters, and exclude what's irrelevant. Availability Important Log patterns are not available in the EU region. The ability to configure this feature is dependent on role-based permissions. If you see Patterns are turned off in your Log management Patterns UI, click the Configure Patterns button and enable it. If you don't see patterns within 30 minutes of enabling the feature, there may be a lack of data with a message attribute for the system to create a pattern from. Log patterns Limitations and considerations Pricing There is no separate pricing for log patterns. The only cost is for additional data generated and added to your log records. A pattern attribute will be added to all logs that match a pattern. Attributes also may be added when common values are discovered, such as GUIDs, IP addresses, URL, or email addresses. These attributes are automatically extracted from the log message as part of the pattern process. HITRUST accounts The log patterns feature is not FedRAMP compliant. FedRAMP or other HITRUST accounts are not eligible to use patterns. Regional availability Availability for this feature depends on whether you have a US or EU region account: US region accounts can use log patterns. EU region accounts cannot enable log patterns at this time. Parsing limits We have a system of safety limits on memory and CPU resources when processing logs and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com > Log management, and use the account picker dropdown to select the target account where you want to explore patterns. In the left navigation of the Log management UI, click Patterns. The main log UI changes to show patterns that match the query in the query bar. one.newrelic.com > Log management > Log patterns: The line chart shows the top 5 patterns over time. Use the time picker and query bar to adjust the results. Explore log patterns By default the log patterns UI first shows the most frequent occurrence of patterns. To sort to show the rarest patterns first, click the Count column. You can also use the query bar or attributes bar to filter your log patterns. If you want to... Do this... Understand the rate of change in patterns Look at the line chart. The color-coded patterns correspond to the plot column in the table. You can toggle individual plot patterns to narrow your focus. See the individual log messages that match each pattern Click pattern to expand the row and see a table of individual log records. To see additional records, scroll up or down. To explore an individual log in more detail, click it to open the details panel. Group and filter patterns by their attributes Use the query bar and time picker. As you apply different filters and time windows, the log patterns adjust to your new target data. Create an alert from a pattern Add the pattern to the query bar and run the query. Then click Create alert condition in the left nav. Troubleshoot log messages that haven't been clustered into a pattern Use the Logs with no pattern tab in the Log patterns UI. Clicking a specific log message will open the log message details panel you're familiar with from the Logs management page. Explore logs with no pattern The Logs with no pattern tab groups all recent log messages in your account that were not clustered into a known pattern yet. These log messages don't represent any problem or flaw in the system; they have no pattern because they are too new to have been processed by the machine learning system. This makes them valuable to explore when you want to understand what has recently changed in your environment. one.newrelic.com > Log management > Log patterns: New Relic's log patterns feature automatically groups logs without a matching pattern. For example: Are any of these logs tied to a recent problem? This is a quick way to discover unique log data that is appearing for the first time in your environment. Does your log data have a new format? Sometimes the logs don't represent a problem, but a new format of log data that deviates from the data model you expect your applications to follow. Catching these logs early gives you the opportunity to ask developers to correct any deviations in their log output. The more consistent people are in the way log data is generated, the easier it becomes to use logs across a diverse set of teams. Masked attributes and wildcards Parts of the log messages in patterns are classified as variables and are substituted by masked attributes. The masking process supports and improves the clustering phase by allowing the algorithm to ignore changing details and focus on the repetitive structure. Masked attributes include: date_time ip url uuid Masked attributes are highlighted and are easy to identify, as shown in the following example. one.newrelic.com > Log management > Log patterns: Here is an example of a pattern that has masked attributes. Log patterns extract other less trivial variables that don't belong to any masked attribute. These variables are indicated as wildcards *. one.newrelic.com > Log management > Log patterns: Here is an example of how wildcards * group variables. Troubleshooting Here are a few reasons why you might have patterns enabled but not see any pattern data. If you're sure none of the items below are true, get help from support.newrelic.com. No data has arrived in the timeframe you're observing. Try expanding the time range you're viewing with the time picker. It's been less than 24 hours since patterns were enabled in the account. This means the ML model may not be generated for the account yet. None of the data coming in has a message field. Patterns will only be generated for values in the message field of a log record. If your logs don't contain message, there will be no data. Put the platform to work with patterns Patterns are a value that is enriched onto the existing log message as a new attribute named newrelic.logPattern. Anything you can do with logs generally can be done with log patterns, such as: Build your own dashboards with patterns, to monitor a specific pattern or group of patterns you care about. Create alerts for patterns by adding NRQL alerts. Use baseline alert conditions to detect anomalies in known log patterns.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 336.3487,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Discover value in <em>log</em> <em>data</em> with patterns",
        "sections": "Discover value in <em>log</em> <em>data</em> with patterns",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " this feature is dependent on role-based permissions. If you see Patterns are turned off in your <em>Log</em> <em>management</em> Patterns <em>UI</em>, click the Configure Patterns button and enable it. If you don&#x27;t see patterns within 30 minutes of enabling the feature, there may be a lack of <em>data</em> with a message attribute"
      },
      "id": "6072d46128ccbc244451c18b"
    },
    {
      "sections": [
        "Organize data with partitions",
        "Plan your partition",
        "Important",
        "Required roles and permissions",
        "Sizing and organizing a partition",
        "Choosing a namespace",
        "Create partition rules",
        "Search data partitions",
        "Manage data partitions programatically with NerdGraph"
      ],
      "title": "Organize data with partitions",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "28cac5fac1065f4b1756700e7f6c11c325734c35",
      "image": "https://docs.newrelic.com/static/7815845d8068377477aa26f8571d5907/c1b63/log-partitions-crop.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/data-partitions/",
      "published_at": "2021-07-02T14:35:27Z",
      "updated_at": "2021-07-02T14:35:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Data partitions are a way to group or organize log data for faster and more efficient querying. When a query targets a single partition, New Relic Logs: Scans less unrelated data. Returns results faster. Accounts can have multiple partitions, and multiple partitions can be queried at the same time. Data partitions also allow data to be mapped to an alternative, or “secondary” namespace with a fixed 30-day retention. This is useful for maintaining compliance with privacy-centric regulations and standards like the General Data Protection Regulation (GDPR). Plan your partition Before you start creating partitions, make sure you have the right permissions and a partition plan. Important Logs are routed to partitions during the ingestion process, before data is written to NRDB. Partition rules will not affect logs that were ingested before the rule was created. Required roles and permissions Users require an Admin role to create and modify partition rules. Sizing and organizing a partition You can gain significant performance improvements with proper use of data partitions. Organizing your data into discrete partitions enables you to query them separately or all together. The goals of partitioning your data should be: Create data partitions that align with concepts in your environment or organization that are static or change infrequently (for example, by business unit, team, environment, service, etc.). Ensure each partition remains below 1 TB of daily ingest for optimal performance. Having more partitions allows for more targeted searches, but creating too many partitions can make logs hard to find and increase administrative overhead. Finding the right balance is important. We support 100 partitions maximum per account, but the optimal number for most accounts is 10 to 15 partitions. Choosing a namespace A partition’s namespace determines its retention period. We offer two retention options: Standard: The account’s default retention determined by your New Relic subscription. This is the maximum retention period available in your account and is the namespace you'll select for most of your partitions. Secondary: 30-day retention. All logs sent to a partition that's a member of the Secondary namespace will be purged on a rolling basis 30 days after having been ingested. Secondary retention is not a cost control mechanism; data is billed on ingest. Create partition rules one.newrelic.com > Logs: From the left nav in the Logs UI, select Data partitions, then create a Log_ partition name with the retention namespace, optional description, and matching criteria. To create a new partition rule: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Data partitions, then click Create partition rule. Define a Partition name as an alphanumeric string that begins with Log_. Add an optional description. Select the retention namespace for the partition. Set your rule's Matching criteria: Select EQUALS to target logs that match your criteria exactly, or select LIKE to apply a fuzzy match. Click the Enable Rule slider, and click Create. To view a list of data partitions: From Manage Data on the left nav of the Logs UI, click Data partitions. Search data partitions The default partition for all Logs accounts is Log. Any log that is not affected by a partition rule will be stored in the Log partition by default. You can query multiple partitions simultaneously. For best performance, select the smallest number of partitions possible. To search data partitions: From Views and Attributes on the left nav of the Logs UI, click Select partitions. Click one or more partitions you want to query, or search for a partition name. Click Query logs to search your selected partitions. Manage data partitions programatically with NerdGraph If you want to manage your data partitions programatically, you can use NerdGraph, our graphQL API, to do so. This tutorial shows how to query, create, and delete data partitions using our API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 336.32596,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Organize <em>data</em> with partitions",
        "sections": "<em>Manage</em> <em>data</em> partitions programatically with NerdGraph",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " partition rules one.newrelic.com &gt; <em>Logs</em>: From the left nav in the <em>Logs</em> <em>UI</em>, select <em>Data</em> partitions, then create a <em>Log</em>_ partition name with the retention namespace, optional description, and matching criteria. To create a new partition rule: Go to one.newrelic.com &gt; <em>Logs</em>. From Manage <em>Data</em> on the left nav"
      },
      "id": "6087e311e7b9d2f90ba5c6a4"
    },
    {
      "sections": [
        "Understand and use the distributed tracing UI",
        "Open the distributed tracing UI",
        "View traces for a specific service",
        "View traces across all accounts",
        "Tip",
        "Find traces that are useful",
        "Filter using the query bar",
        "Find traces that touch two services",
        "Find error spans using the like operator",
        "Trace groups",
        "Filter using the scatter plot",
        "Filters",
        "Trace histograms",
        "Important",
        "Trace details UI page",
        "Span details pane",
        "View related logs",
        "Additional UI details",
        "How to understand span errors",
        "Anomalous spans",
        "Client span duration: time differences between client and server spans",
        "Fragmented traces",
        "Trace details obfuscated based on account access",
        "Span limits and sampling",
        "Incomplete span names in waterfall view",
        "Missing spans and span/service count discrepancies"
      ],
      "title": "Understand and use the distributed tracing UI",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "f5b66e03583e42613810f1390b4e5adab4ed2caa",
      "image": "https://docs.newrelic.com/static/ec08996f31e6586bb257c6f89b3c8f99/e5166/new-relic-distributed-tracing-client-span-time.jpg",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/understand-use-distributed-tracing-ui/",
      "published_at": "2021-07-02T19:11:31Z",
      "updated_at": "2021-07-02T19:11:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing helps you monitor and analyze the behavior of your distributed system. After you enable distributed tracing, you can use our UI tools to search for traces and analyze them. For example, let's say you are an engineer troubleshooting errors in a complex transaction spanning many services. Here's what you can do in our UI: Open the distributed tracing UI page. Sort through your traces using a filter to find that specific request and show only traces containing errors. On the trace details page, you review the span along the request route that originated the error. Noting the error class and message, navigate to the service from its span in the trace so you can see that the error is occurring at a high rate. Read on to explore the options in the distributed tracing UI. Open the distributed tracing UI Here's how you can access the distributed tracing UI, depending on the type of search you want to do: View traces for a specific service The New Relic Explorer and APM are two menu options that help you navigate to a specific service so you can see traces that include that service. Go to one.newrelic.com. Click Explorer or APM in the top menu bar. Filter to the service you enabled for distributed tracing by typing the service name, and then press Enter. In the left navigation's Monitor section, click Distributed tracing. View traces across all accounts If you want to view traces from across all accounts you have access to, go to one.newrelic.com, click Browse data, and then Traces. Tip If you don't have access to accounts for some services in a trace, we'll obfuscate some details for those services. Find traces that are useful We have a variety of tools to help you find traces and spans so you can resolve issues. The opening distributed tracing page is populated with a default list of traces, and you can quickly refine this list using these tools: Query bar Trace groups Scatter plot chart Filters Interactive histograms Tip In addition to these tools, you can also use other options mentioned in Query distributed trace data. Filter using the query bar The Find traces query bar is a quick way to narrow your search for traces. You can either start typing in the query bar or use the dropdown to create a compound query. Query returns are based on span attributes, not on trace attributes. You define spans that have certain criteria, and the search displays traces that contain those spans. If you use a multi-attribute filter, it is affected by first attribute selected. Distributed tracing reports on two types of data: transaction events and spans. When you select an attribute in the filter, the data type that attribute is attached to dictates the available attributes. For example, if you filter on an attribute that is attached to a transaction event, only transaction event attributes are available when you attempt to add filter on additional attribute values. Queries for traces are similar to NRQL (our query language). Here are the main exceptions: String values don't require quote marks (for example, you can use either appName = MyApp or appName = 'MyApp') The like operator doesn’t require % (for example, you can use either appName like product or appName like %product%). Tip Some queries that return a large number of results may return false positives. The trace list limits these incorrect results to 10% of the returned results. False positives may also result in histogram chart results that are not displayed in the trace list. Here are two query bar examples: Find traces that touch two services The query in the image below finds traces that: Pass through both WebPortal and Inventory Service applications Have an Inventory Service datastore call that takes longer than 500 ms Contains an error in any span. Go to one.newrelic.com > Apps > Distributed tracing Find error spans using the like operator The query in the image below finds traces that: Contain spans that pass through the WebPortal application and where an error occurred on any span in the WebPortal application Contain spans where the customer_user_email attribute contains a value ending with hotmail.com anywhere in the trace. Go to one.newrelic.com > Apps > Distributed tracing Trace groups The default view of distributed tracing shows traces grouped by the same root entry span. In other words, traces are grouped by the span where New Relic began recording the request. You can slide the toggle Group similar traces to turn this on and off. With trace groups you get a high-level view of traces so you can understand request behavior for groups of similar traces. This helps you understand dips or spikes in trace count, duration, and errors. When you click on one of the trace groups, you get all the standard details in context of the specific trace group you selected. Filter using the scatter plot The trace scatter plot is a quick way to search for outlying traces. This is available on the opening page of distributed tracing if you turn off the Group similar traces toggle at the top of the page. In the scatter plot, you can move the cursor across the chart to view trace details and you can click individual points to get details: Here's how you can control what's displayed in the scatter plot: In the View by dropdown, select the duration type: Back-end duration Root span duration Trace duration In Group traces by, select one of these options: Errors: Group by whether or not traces contain errors. Root service: Group by the name of the first service in traces. In a trace where Service A calls Service B and Service B calls Service C, the root service would be Service A. Root entry span: Group by the root transaction, which is the root service's endpoint. In a trace where Service A calls Service B and Service B calls Service C, the root entry span is Service A's endpoint. For example: \"Service A - GET /user/%\". Service entry span: Group by the span name of the service currently being viewed in APM. For example, for a trace where Service A calls Service B and Service B calls Service C, if you're viewing Service B in APM and select this grouping, the traces will be represented by their Service B span names. If a service has multiple spans in a trace, this grouping option will use that service's first entry point. Filters In the left pane, you can filter traces by multi-span traces, specific entities, or error types. Once you select a filter, only traces associated with that specific type are displayed. This makes it much easier to view the traces you're most interested in so you can find and fix issues faster. Trace histograms The histogram charts give you a quick understanding of trace distribution for important values, such as duration. Click Show filters at the bottom of the left pane to display the histograms. When you move the histogram sliders, they change the data displayed in the scatterplot or the trace group charts. For example, you can drag the Trace duration chart slider to show only traces over 500 ms, as shown in the histogram example below. Important Some queries that produce many results may result in false positives in histograms. This could manifest as histograms showing trace results that are not in the trace list. Trace details UI page When you select a trace from the trace list, you see that trace's timeline and spans: one.newrelic.com > APM > (select an application) > Monitor > Distributed tracing > (select a trace) > (select a span): See the spans in a trace. Examine individual span details and see notifications for spans with anomalous behavior. The UI indicates some span properties with icons: Span property Indicator Description Service This icon represents a span that's a service's entry point. In-process This icon represents an in-process span, which is a span that takes place within a process (as opposed to a cross-process span). Examples: middleware instrumentation, user-created spans. Datastore This icon represents a span call to a datastore. External This icon represents category representing a call to an external service made via HTTP. Browser app This icon represents a browser application span. Lambda This icon represents a span from a Lambda function. Some spans will have additional indicators: Span property Indicator Description Type of connection Solid lines indicate a direct parent-child relationship; in other words, one process or function directly calling another. A dotted line indicates a non-direct relationship. For more on relationships between spans, see Trace structure. Errors A span with an error. See How to understand span errors. Anomalous This icon represents the detection of an anomalous span. Orphaned spans Some spans may be \"orphaned,\" or separated, from the trace. These spans will appear at the bottom of the trace. For more details, see Fragmented traces. Multiple app names When beside a span name, this represents an entity that has had multiple app names set. Select this to see all app names it reports to. To search trace data by alternate app names, use the appName attribute. Client/server time difference If a span's duration indicator is not completely colored in (like in this example), it means that there is a time discrepancy between the server-side duration and the client-side duration for that activity. For details on this, see Client/server time difference. For more on the trace structure and how span properties are determined, see Trace structure. Span details pane When you select a span, a pane opens up with span details. These details can be helpful for troubleshooting performance issues. Details include: Performance charts Span attributes The span's data source Anomalous span details The span's full name What a span displays is based on its span type. For example, a datastore span's name attribute will contain the datastore query. View related logs If you are using our logs in context feature together with our log management, you can see any logs that are linked to your traces: Go to the trace details page by clicking on a trace. Click See logs in the upper-right corner. For details related to an individual log message, click directly on the message. Additional UI details Here are some additional distributed tracing UI details, rules, and limits: How to understand span errors Span-level errors show you where errors originated in a process, how they bubbled up, and where they were handled. Every span that ends with an exception is shown with an error in the UI and contributes to the total error count for that trace. Here are some general tips about understanding span errors: Spans with errors are highlighted red in the distributed tracing UI. You can see more information on the Error Details pane for each span. All spans that exit with errors are counted in the span error count. When multiple errors occur on the same span, only one is written to the span in this order of precedence: A noticeError The most recent span exception This table describes how different span errors are handled: Error type Description Spans ending in exceptions An exception that leaves the boundary of a span results in an error on that span and on any ancestor spans that also exit with an error, until the exception is caught or exits the transaction. You can see if an exception is caught in an ancestor span. Notice errors Errors noticed by calls to the agent noticeError API or by the automatic agent instrumentation are attached to the currently executing span. Response code errors Response code errors are attached to the associated span, such as: Client span: External transactions prefixed with http or db. Entry span: In the case of a transaction ending in a response code error. The response code for these spans is captured as an attribute httpResponseCode and attached to that span. Anomalous spans If a span is displayed as anomalous in the UI, it means that the following are both true: The span is more than two standard deviations slower than the average of all spans with the same name from the same service over the last six hours. The span's duration is more than 10% of the trace's duration. Client span duration: time differences between client and server spans When a process calls another process, and both processes are instrumented by New Relic, the trace contains both a client-side representation of the call and a server-side representation. The client span (calling process) can have time-related differences when compared to the server span (called process). These differences could be due to: Clock skew, due to system clock time differences Differences in duration, due to things like network latency or DNS resolution delay The UI shows these time-related differences by displaying an outline of the client span in the same space as the server span. This span represents the duration of the client span. It isn't possible to determine every factor contributing to these time-related discrepancies, but here are some common span patterns and tips for understanding them: When a client span is longer than the server span, this could be due to latency in a number of areas, such as: network time, queue time, DNS resolution time, or from a load balancer that we cannot see. When a client span starts and ends before a server span begins, this could be due to clock skew, or due to the server doing asynchronous work that continues after sending the response. When a client span starts after a server span, this is most likely clock skew. Fragmented traces Fragmented traces are traces with missing spans. When a span is missing or has invalid parent span IDs, its children spans become separated from the rest of the trace, which we refer to as \"orphaned.\" Orphaned spans appear at the bottom of the trace, and they will lack connecting lines to the rest of the trace. Types of orphaned span properties indicated in the UI: No root span. Missing the root span, which is the first operation in the request. When this happens, the span with the earliest timestamp is displayed as the root. Orphaned span. A single span with a missing parent span. This could be due to the parent span having an ID that doesn't match its child span. Orphaned trace fragment. A group of connected spans where the first span in the group is an orphan span. This can happen for a number of reasons, including: Collection limits. Some high-throughput applications may exceed collection limits (for example, APM agent collection limits, or API limits). When this happens, it may result in traces having missing spans. One way to remedy this is to turn off some reporting, so that the limit is not reached. Incorrect instrumentation. If an application is instrumented incorrectly, it won't pass trace context correctly and this will result in fragmented traces. To remedy this, examine the data source that is generating orphan spans to ensure instrumentation is done correctly. To discover a span's data source, select it and examine its span details. Spans still arriving. If some parent spans haven't been collected yet, this can result in temporary gaps until the entire trace has reported. UI display limits. Orphaned spans may result if a trace exceeds the 10K span display limit. Trace details obfuscated based on account access If you don’t have access to the New Relic accounts that monitor other services, some of the span and service details will be obfuscated in the UI. Obfuscation can include: Span name concealed by asterisks Service name replaced with New Relic account ID and app ID For more information on the factors affecting your access to accounts, see Account access. Span limits and sampling See Sampling. Incomplete span names in waterfall view When viewing the span waterfall, span names may be displayed in an incomplete form that is more human-readable than the complete span name. To find the complete name, select that span and look for the Full span name. Knowing the complete name can be valuable for querying that data with NRQL. Missing spans and span/service count discrepancies A trace may sometimes have (or seem to have) missing spans or services. This can manifest as a discrepancy between the count of a trace's spans or services displayed in the trace list and the count displayed on the trace details page. Reasons for missing spans and count discrepancies include: An APM agent may have hit its 1K span collection limit. A span may be initially counted but not make it into a trace display, for reasons such as network latency or a query issue. The UI may have hit its 10K span display limit. All spans collected, including those not displayed, can be queried with NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.27542,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Understand <em>and</em> use the distributed tracing <em>UI</em>",
        "sections": "Understand <em>and</em> use the distributed tracing <em>UI</em>",
        "tags": "<em>UI</em> <em>and</em> <em>data</em>",
        "body": " together with our <em>log</em> <em>management</em>, you can see any <em>logs</em> that are linked to your traces: Go to the trace details page by clicking on a trace. Click See <em>logs</em> in the upper-right corner. For details related to an individual <em>log</em> message, click directly on the message. Additional <em>UI</em> details Here are some"
      },
      "id": "6072a70028ccbc265a51c13d"
    }
  ],
  "/docs/logs/log-management/ui-data/find-unusual-logs-log-patterns": [
    {
      "sections": [
        "Organize data with partitions",
        "Plan your partition",
        "Important",
        "Required roles and permissions",
        "Sizing and organizing a partition",
        "Choosing a namespace",
        "Create partition rules",
        "Search data partitions",
        "Manage data partitions programatically with NerdGraph"
      ],
      "title": "Organize data with partitions",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "28cac5fac1065f4b1756700e7f6c11c325734c35",
      "image": "https://docs.newrelic.com/static/7815845d8068377477aa26f8571d5907/c1b63/log-partitions-crop.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/data-partitions/",
      "published_at": "2021-07-02T14:35:27Z",
      "updated_at": "2021-07-02T14:35:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Data partitions are a way to group or organize log data for faster and more efficient querying. When a query targets a single partition, New Relic Logs: Scans less unrelated data. Returns results faster. Accounts can have multiple partitions, and multiple partitions can be queried at the same time. Data partitions also allow data to be mapped to an alternative, or “secondary” namespace with a fixed 30-day retention. This is useful for maintaining compliance with privacy-centric regulations and standards like the General Data Protection Regulation (GDPR). Plan your partition Before you start creating partitions, make sure you have the right permissions and a partition plan. Important Logs are routed to partitions during the ingestion process, before data is written to NRDB. Partition rules will not affect logs that were ingested before the rule was created. Required roles and permissions Users require an Admin role to create and modify partition rules. Sizing and organizing a partition You can gain significant performance improvements with proper use of data partitions. Organizing your data into discrete partitions enables you to query them separately or all together. The goals of partitioning your data should be: Create data partitions that align with concepts in your environment or organization that are static or change infrequently (for example, by business unit, team, environment, service, etc.). Ensure each partition remains below 1 TB of daily ingest for optimal performance. Having more partitions allows for more targeted searches, but creating too many partitions can make logs hard to find and increase administrative overhead. Finding the right balance is important. We support 100 partitions maximum per account, but the optimal number for most accounts is 10 to 15 partitions. Choosing a namespace A partition’s namespace determines its retention period. We offer two retention options: Standard: The account’s default retention determined by your New Relic subscription. This is the maximum retention period available in your account and is the namespace you'll select for most of your partitions. Secondary: 30-day retention. All logs sent to a partition that's a member of the Secondary namespace will be purged on a rolling basis 30 days after having been ingested. Secondary retention is not a cost control mechanism; data is billed on ingest. Create partition rules one.newrelic.com > Logs: From the left nav in the Logs UI, select Data partitions, then create a Log_ partition name with the retention namespace, optional description, and matching criteria. To create a new partition rule: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Data partitions, then click Create partition rule. Define a Partition name as an alphanumeric string that begins with Log_. Add an optional description. Select the retention namespace for the partition. Set your rule's Matching criteria: Select EQUALS to target logs that match your criteria exactly, or select LIKE to apply a fuzzy match. Click the Enable Rule slider, and click Create. To view a list of data partitions: From Manage Data on the left nav of the Logs UI, click Data partitions. Search data partitions The default partition for all Logs accounts is Log. Any log that is not affected by a partition rule will be stored in the Log partition by default. You can query multiple partitions simultaneously. For best performance, select the smallest number of partitions possible. To search data partitions: From Views and Attributes on the left nav of the Logs UI, click Select partitions. Click one or more partitions you want to query, or search for a partition name. Click Query logs to search your selected partitions. Manage data partitions programatically with NerdGraph If you want to manage your data partitions programatically, you can use NerdGraph, our graphQL API, to do so. This tutorial shows how to query, create, and delete data partitions using our API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 336.32596,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Organize <em>data</em> with partitions",
        "sections": "<em>Manage</em> <em>data</em> partitions programatically with NerdGraph",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " partition rules one.newrelic.com &gt; <em>Logs</em>: From the left nav in the <em>Logs</em> <em>UI</em>, select <em>Data</em> partitions, then create a <em>Log</em>_ partition name with the retention namespace, optional description, and matching criteria. To create a new partition rule: Go to one.newrelic.com &gt; <em>Logs</em>. From Manage <em>Data</em> on the left nav"
      },
      "id": "6087e311e7b9d2f90ba5c6a4"
    },
    {
      "sections": [
        "Drop data with drop filter rules",
        "Savings, security, speed",
        "Caution",
        "How drop filter rules work",
        "Cautions when dropping data",
        "Create drop filter rules",
        "Types of drop filter rules",
        "Drop log events",
        "Drop attributes",
        "Tip",
        "View or delete drop filter rules"
      ],
      "title": "Drop data with drop filter rules ",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "9590bd4593abd451633a4beacd94d56eb1a481bd",
      "image": "https://docs.newrelic.com/static/db4b077fafd911b9f5019b022b3048ab/b04e4/ingest-pipeline.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/drop-data-drop-filter-rules/",
      "published_at": "2021-07-02T14:35:27Z",
      "updated_at": "2021-06-26T14:34:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After log event data has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both log events and event attributes via drop filter rules. You can manage drop filter rules using our Logs UI, as explained in this document. You can also use NerdGraph. Savings, security, speed Drop filter rules help you accomplish several important goals: Lower costs by storing only logs relevant to your account. Protect privacy and security by removing personal identifiable information (PII). Reduce noise by removing irrelevant events and attributes. Caution Use caution when deciding to drop data. The data you drop is not recoverable. Before using this feature, review the responsibilities and considerations for dropping data. How drop filter rules work A drop filter rule matches data based on a query. When triggered, the drop filter rule removes the matching data from the ingestion pipeline before it is written to NRDB. This creates an explicit demarcation between the logs being forwarded from your domain and the data that New Relic collects. Since the data removed by the drop filter rule doesn't reach our backend, it cannot be queried: the data is gone and cannot be restored. During the ingestion process, customer log data can be parsed, transformed, or dropped before being stored in New Relic's database. Cautions when dropping data When creating drop rules, you are responsible for ensuring that the rules accurately identify and discard the data that meets the conditions that you have established. You are also responsible for monitoring the rule, as well as the data you disclose to New Relic. New Relic cannot guarantee that this functionality will completely resolve data disclosure concerns you may have. New Relic doesn't review or monitor how effective the rules you develop are. Creating rules about sensitive data can leak information about what kinds of data you maintain, including the format of your data or systems (for example, through referencing email addresses or specific credit card numbers). Any user with the relevant role-based access control permissions can view and edit all information in the rules you create. Create drop filter rules To create and edit drop filters, you must have admin permissions in New Relic, or you must be a member of a role with create and edit permissions for Logging Parsing Rules. Once a drop filter rule is active, it's applied to all log events ingested from that point onwards. Rules are not applied retroactively. Logs collected before creating a rule are not filtered by that rule. one.newrelic.com > Logs: Filter or query the set of logs that contain the data you want to drop. Then, from Manage Data on the left nav of the Logs UI, click Create drop filter. To create a new drop filter rule, you can use new or existing log queries. Go to one.newrelic.com > Logs. Filter or query to the specific set of logs that contain the data to be dropped. Once the query is active, from Manage Data on the left nav of the Logs UI, click Create drop filter. Recommendation: Change the drop rule's default name to a meaningful name. Choose to either drop the entire log event that matches the query or just a specific subset of attributes in the matching events. Review the log partitions where this drop rule applies. Save the drop filter rule. Types of drop filter rules The drop filters UI prompts you to select whether to drop logs based on the query or on specific attributes. Drop log events The default type of drop filter rule is to drop logs. This option drops the entire log events that match the filter or query. When creating a rule, try to provide a specific query that only matches log data that should be dropped. Our drop filters process won't let you create drop filter rules without values in the matching query. This prevents badly formed rules from dropping all log data. Drop attributes You can specify attributes to be dropped in a log event that matches your query. At least one or more attributes must be selected. Any attribute which is selected will be dropped; all remaining attributes will be kept and stored in NRDB. Tip We recommend this method for removing fields that could contain personal identifiable information (PII) or other sensitive attributes without losing valuable monitoring data. View or delete drop filter rules To view or delete a drop filter rule: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Drop filters. Click the delete icon next to the drop filter rule you want to remove. Once deleted, rules no longer filter ingested log events.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.24414,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Drop <em>data</em> with drop filter rules ",
        "sections": "Drop <em>data</em> with drop filter rules",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "After <em>log</em> event <em>data</em> has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both <em>log</em> events and event attributes via drop filter rules. You can manage drop filter rules using our <em>Logs</em> <em>UI</em>, as explained in this document. You can also use"
      },
      "id": "603e813f28ccbc08c1eba787"
    },
    {
      "sections": [
        "Understand and use the distributed tracing UI",
        "Open the distributed tracing UI",
        "View traces for a specific service",
        "View traces across all accounts",
        "Tip",
        "Find traces that are useful",
        "Filter using the query bar",
        "Find traces that touch two services",
        "Find error spans using the like operator",
        "Trace groups",
        "Filter using the scatter plot",
        "Filters",
        "Trace histograms",
        "Important",
        "Trace details UI page",
        "Span details pane",
        "View related logs",
        "Additional UI details",
        "How to understand span errors",
        "Anomalous spans",
        "Client span duration: time differences between client and server spans",
        "Fragmented traces",
        "Trace details obfuscated based on account access",
        "Span limits and sampling",
        "Incomplete span names in waterfall view",
        "Missing spans and span/service count discrepancies"
      ],
      "title": "Understand and use the distributed tracing UI",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "f5b66e03583e42613810f1390b4e5adab4ed2caa",
      "image": "https://docs.newrelic.com/static/ec08996f31e6586bb257c6f89b3c8f99/e5166/new-relic-distributed-tracing-client-span-time.jpg",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/understand-use-distributed-tracing-ui/",
      "published_at": "2021-07-02T19:11:31Z",
      "updated_at": "2021-07-02T19:11:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing helps you monitor and analyze the behavior of your distributed system. After you enable distributed tracing, you can use our UI tools to search for traces and analyze them. For example, let's say you are an engineer troubleshooting errors in a complex transaction spanning many services. Here's what you can do in our UI: Open the distributed tracing UI page. Sort through your traces using a filter to find that specific request and show only traces containing errors. On the trace details page, you review the span along the request route that originated the error. Noting the error class and message, navigate to the service from its span in the trace so you can see that the error is occurring at a high rate. Read on to explore the options in the distributed tracing UI. Open the distributed tracing UI Here's how you can access the distributed tracing UI, depending on the type of search you want to do: View traces for a specific service The New Relic Explorer and APM are two menu options that help you navigate to a specific service so you can see traces that include that service. Go to one.newrelic.com. Click Explorer or APM in the top menu bar. Filter to the service you enabled for distributed tracing by typing the service name, and then press Enter. In the left navigation's Monitor section, click Distributed tracing. View traces across all accounts If you want to view traces from across all accounts you have access to, go to one.newrelic.com, click Browse data, and then Traces. Tip If you don't have access to accounts for some services in a trace, we'll obfuscate some details for those services. Find traces that are useful We have a variety of tools to help you find traces and spans so you can resolve issues. The opening distributed tracing page is populated with a default list of traces, and you can quickly refine this list using these tools: Query bar Trace groups Scatter plot chart Filters Interactive histograms Tip In addition to these tools, you can also use other options mentioned in Query distributed trace data. Filter using the query bar The Find traces query bar is a quick way to narrow your search for traces. You can either start typing in the query bar or use the dropdown to create a compound query. Query returns are based on span attributes, not on trace attributes. You define spans that have certain criteria, and the search displays traces that contain those spans. If you use a multi-attribute filter, it is affected by first attribute selected. Distributed tracing reports on two types of data: transaction events and spans. When you select an attribute in the filter, the data type that attribute is attached to dictates the available attributes. For example, if you filter on an attribute that is attached to a transaction event, only transaction event attributes are available when you attempt to add filter on additional attribute values. Queries for traces are similar to NRQL (our query language). Here are the main exceptions: String values don't require quote marks (for example, you can use either appName = MyApp or appName = 'MyApp') The like operator doesn’t require % (for example, you can use either appName like product or appName like %product%). Tip Some queries that return a large number of results may return false positives. The trace list limits these incorrect results to 10% of the returned results. False positives may also result in histogram chart results that are not displayed in the trace list. Here are two query bar examples: Find traces that touch two services The query in the image below finds traces that: Pass through both WebPortal and Inventory Service applications Have an Inventory Service datastore call that takes longer than 500 ms Contains an error in any span. Go to one.newrelic.com > Apps > Distributed tracing Find error spans using the like operator The query in the image below finds traces that: Contain spans that pass through the WebPortal application and where an error occurred on any span in the WebPortal application Contain spans where the customer_user_email attribute contains a value ending with hotmail.com anywhere in the trace. Go to one.newrelic.com > Apps > Distributed tracing Trace groups The default view of distributed tracing shows traces grouped by the same root entry span. In other words, traces are grouped by the span where New Relic began recording the request. You can slide the toggle Group similar traces to turn this on and off. With trace groups you get a high-level view of traces so you can understand request behavior for groups of similar traces. This helps you understand dips or spikes in trace count, duration, and errors. When you click on one of the trace groups, you get all the standard details in context of the specific trace group you selected. Filter using the scatter plot The trace scatter plot is a quick way to search for outlying traces. This is available on the opening page of distributed tracing if you turn off the Group similar traces toggle at the top of the page. In the scatter plot, you can move the cursor across the chart to view trace details and you can click individual points to get details: Here's how you can control what's displayed in the scatter plot: In the View by dropdown, select the duration type: Back-end duration Root span duration Trace duration In Group traces by, select one of these options: Errors: Group by whether or not traces contain errors. Root service: Group by the name of the first service in traces. In a trace where Service A calls Service B and Service B calls Service C, the root service would be Service A. Root entry span: Group by the root transaction, which is the root service's endpoint. In a trace where Service A calls Service B and Service B calls Service C, the root entry span is Service A's endpoint. For example: \"Service A - GET /user/%\". Service entry span: Group by the span name of the service currently being viewed in APM. For example, for a trace where Service A calls Service B and Service B calls Service C, if you're viewing Service B in APM and select this grouping, the traces will be represented by their Service B span names. If a service has multiple spans in a trace, this grouping option will use that service's first entry point. Filters In the left pane, you can filter traces by multi-span traces, specific entities, or error types. Once you select a filter, only traces associated with that specific type are displayed. This makes it much easier to view the traces you're most interested in so you can find and fix issues faster. Trace histograms The histogram charts give you a quick understanding of trace distribution for important values, such as duration. Click Show filters at the bottom of the left pane to display the histograms. When you move the histogram sliders, they change the data displayed in the scatterplot or the trace group charts. For example, you can drag the Trace duration chart slider to show only traces over 500 ms, as shown in the histogram example below. Important Some queries that produce many results may result in false positives in histograms. This could manifest as histograms showing trace results that are not in the trace list. Trace details UI page When you select a trace from the trace list, you see that trace's timeline and spans: one.newrelic.com > APM > (select an application) > Monitor > Distributed tracing > (select a trace) > (select a span): See the spans in a trace. Examine individual span details and see notifications for spans with anomalous behavior. The UI indicates some span properties with icons: Span property Indicator Description Service This icon represents a span that's a service's entry point. In-process This icon represents an in-process span, which is a span that takes place within a process (as opposed to a cross-process span). Examples: middleware instrumentation, user-created spans. Datastore This icon represents a span call to a datastore. External This icon represents category representing a call to an external service made via HTTP. Browser app This icon represents a browser application span. Lambda This icon represents a span from a Lambda function. Some spans will have additional indicators: Span property Indicator Description Type of connection Solid lines indicate a direct parent-child relationship; in other words, one process or function directly calling another. A dotted line indicates a non-direct relationship. For more on relationships between spans, see Trace structure. Errors A span with an error. See How to understand span errors. Anomalous This icon represents the detection of an anomalous span. Orphaned spans Some spans may be \"orphaned,\" or separated, from the trace. These spans will appear at the bottom of the trace. For more details, see Fragmented traces. Multiple app names When beside a span name, this represents an entity that has had multiple app names set. Select this to see all app names it reports to. To search trace data by alternate app names, use the appName attribute. Client/server time difference If a span's duration indicator is not completely colored in (like in this example), it means that there is a time discrepancy between the server-side duration and the client-side duration for that activity. For details on this, see Client/server time difference. For more on the trace structure and how span properties are determined, see Trace structure. Span details pane When you select a span, a pane opens up with span details. These details can be helpful for troubleshooting performance issues. Details include: Performance charts Span attributes The span's data source Anomalous span details The span's full name What a span displays is based on its span type. For example, a datastore span's name attribute will contain the datastore query. View related logs If you are using our logs in context feature together with our log management, you can see any logs that are linked to your traces: Go to the trace details page by clicking on a trace. Click See logs in the upper-right corner. For details related to an individual log message, click directly on the message. Additional UI details Here are some additional distributed tracing UI details, rules, and limits: How to understand span errors Span-level errors show you where errors originated in a process, how they bubbled up, and where they were handled. Every span that ends with an exception is shown with an error in the UI and contributes to the total error count for that trace. Here are some general tips about understanding span errors: Spans with errors are highlighted red in the distributed tracing UI. You can see more information on the Error Details pane for each span. All spans that exit with errors are counted in the span error count. When multiple errors occur on the same span, only one is written to the span in this order of precedence: A noticeError The most recent span exception This table describes how different span errors are handled: Error type Description Spans ending in exceptions An exception that leaves the boundary of a span results in an error on that span and on any ancestor spans that also exit with an error, until the exception is caught or exits the transaction. You can see if an exception is caught in an ancestor span. Notice errors Errors noticed by calls to the agent noticeError API or by the automatic agent instrumentation are attached to the currently executing span. Response code errors Response code errors are attached to the associated span, such as: Client span: External transactions prefixed with http or db. Entry span: In the case of a transaction ending in a response code error. The response code for these spans is captured as an attribute httpResponseCode and attached to that span. Anomalous spans If a span is displayed as anomalous in the UI, it means that the following are both true: The span is more than two standard deviations slower than the average of all spans with the same name from the same service over the last six hours. The span's duration is more than 10% of the trace's duration. Client span duration: time differences between client and server spans When a process calls another process, and both processes are instrumented by New Relic, the trace contains both a client-side representation of the call and a server-side representation. The client span (calling process) can have time-related differences when compared to the server span (called process). These differences could be due to: Clock skew, due to system clock time differences Differences in duration, due to things like network latency or DNS resolution delay The UI shows these time-related differences by displaying an outline of the client span in the same space as the server span. This span represents the duration of the client span. It isn't possible to determine every factor contributing to these time-related discrepancies, but here are some common span patterns and tips for understanding them: When a client span is longer than the server span, this could be due to latency in a number of areas, such as: network time, queue time, DNS resolution time, or from a load balancer that we cannot see. When a client span starts and ends before a server span begins, this could be due to clock skew, or due to the server doing asynchronous work that continues after sending the response. When a client span starts after a server span, this is most likely clock skew. Fragmented traces Fragmented traces are traces with missing spans. When a span is missing or has invalid parent span IDs, its children spans become separated from the rest of the trace, which we refer to as \"orphaned.\" Orphaned spans appear at the bottom of the trace, and they will lack connecting lines to the rest of the trace. Types of orphaned span properties indicated in the UI: No root span. Missing the root span, which is the first operation in the request. When this happens, the span with the earliest timestamp is displayed as the root. Orphaned span. A single span with a missing parent span. This could be due to the parent span having an ID that doesn't match its child span. Orphaned trace fragment. A group of connected spans where the first span in the group is an orphan span. This can happen for a number of reasons, including: Collection limits. Some high-throughput applications may exceed collection limits (for example, APM agent collection limits, or API limits). When this happens, it may result in traces having missing spans. One way to remedy this is to turn off some reporting, so that the limit is not reached. Incorrect instrumentation. If an application is instrumented incorrectly, it won't pass trace context correctly and this will result in fragmented traces. To remedy this, examine the data source that is generating orphan spans to ensure instrumentation is done correctly. To discover a span's data source, select it and examine its span details. Spans still arriving. If some parent spans haven't been collected yet, this can result in temporary gaps until the entire trace has reported. UI display limits. Orphaned spans may result if a trace exceeds the 10K span display limit. Trace details obfuscated based on account access If you don’t have access to the New Relic accounts that monitor other services, some of the span and service details will be obfuscated in the UI. Obfuscation can include: Span name concealed by asterisks Service name replaced with New Relic account ID and app ID For more information on the factors affecting your access to accounts, see Account access. Span limits and sampling See Sampling. Incomplete span names in waterfall view When viewing the span waterfall, span names may be displayed in an incomplete form that is more human-readable than the complete span name. To find the complete name, select that span and look for the Full span name. Knowing the complete name can be valuable for querying that data with NRQL. Missing spans and span/service count discrepancies A trace may sometimes have (or seem to have) missing spans or services. This can manifest as a discrepancy between the count of a trace's spans or services displayed in the trace list and the count displayed on the trace details page. Reasons for missing spans and count discrepancies include: An APM agent may have hit its 1K span collection limit. A span may be initially counted but not make it into a trace display, for reasons such as network latency or a query issue. The UI may have hit its 10K span display limit. All spans collected, including those not displayed, can be queried with NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.27542,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Understand <em>and</em> use the distributed tracing <em>UI</em>",
        "sections": "Understand <em>and</em> use the distributed tracing <em>UI</em>",
        "tags": "<em>UI</em> <em>and</em> <em>data</em>",
        "body": " together with our <em>log</em> <em>management</em>, you can see any <em>logs</em> that are linked to your traces: Go to the trace details page by clicking on a trace. Click See <em>logs</em> in the upper-right corner. For details related to an individual <em>log</em> message, click directly on the message. Additional <em>UI</em> details Here are some"
      },
      "id": "6072a70028ccbc265a51c13d"
    }
  ],
  "/docs/logs/log-management/ui-data/parsing": [
    {
      "sections": [
        "Discover value in log data with patterns",
        "Technical overview",
        "Availability",
        "Important",
        "Get started",
        "Explore log patterns",
        "Explore logs with no pattern",
        "Masked attributes and wildcards",
        "Troubleshooting",
        "Put the platform to work with patterns"
      ],
      "title": "Discover value in log data with patterns",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "8f1e27c94327ca4888a945f8e12f9c2310ccd7a6",
      "image": "https://docs.newrelic.com/static/578d7186bb34352855696e5307cc82f2/c1b63/log-patterns-logs-without-a-pattern.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/find-unusual-logs-log-patterns/",
      "published_at": "2021-07-02T14:37:14Z",
      "updated_at": "2021-07-02T14:37:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Log patterns are the fastest way to discover value in log data without searching. Log data is high volume telemetry with a low value per individual record. Searching can quickly lead to logs that provide a root cause explanation, but most data is repetitive and hard to contextualize when browsing. Patterns can make log data discoverable without spending a lot of time reading through low value data. one.newrelic.com > Logs > Patterns: Use patterns as the basis for alerts when the frequency of important data changes, or for configuring drop rules to get rid of unnecessary repetitive data. Technical overview Log patterns functionality applies machine learning to normalize and group log messages that are consistent in format but variable in content. These grouped messages can be sorted, making it easy to find the most frequent or rarest sets of logs in your environment. Use patterns as the basis for alerts when the frequency of important data changes, or to configure drop rules to get rid of unnecessary repetitive data. Log patterns use advanced clustering algorithms to group together similar log messages automatically. With patterns, you can: Orient more quickly through millions of logs. Reduce the time it takes to identify unusual behavior in your log estate. Monitor the frequency of known patterns over time to focus your energy on what matters, and exclude what's irrelevant. Availability Important Log patterns are not available in the EU region. The ability to configure this feature is dependent on role-based permissions. If you see Patterns are turned off in your Log management Patterns UI, click the Configure Patterns button and enable it. If you don't see patterns within 30 minutes of enabling the feature, there may be a lack of data with a message attribute for the system to create a pattern from. Log patterns Limitations and considerations Pricing There is no separate pricing for log patterns. The only cost is for additional data generated and added to your log records. A pattern attribute will be added to all logs that match a pattern. Attributes also may be added when common values are discovered, such as GUIDs, IP addresses, URL, or email addresses. These attributes are automatically extracted from the log message as part of the pattern process. HITRUST accounts The log patterns feature is not FedRAMP compliant. FedRAMP or other HITRUST accounts are not eligible to use patterns. Regional availability Availability for this feature depends on whether you have a US or EU region account: US region accounts can use log patterns. EU region accounts cannot enable log patterns at this time. Parsing limits We have a system of safety limits on memory and CPU resources when processing logs and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com > Log management, and use the account picker dropdown to select the target account where you want to explore patterns. In the left navigation of the Log management UI, click Patterns. The main log UI changes to show patterns that match the query in the query bar. one.newrelic.com > Log management > Log patterns: The line chart shows the top 5 patterns over time. Use the time picker and query bar to adjust the results. Explore log patterns By default the log patterns UI first shows the most frequent occurrence of patterns. To sort to show the rarest patterns first, click the Count column. You can also use the query bar or attributes bar to filter your log patterns. If you want to... Do this... Understand the rate of change in patterns Look at the line chart. The color-coded patterns correspond to the plot column in the table. You can toggle individual plot patterns to narrow your focus. See the individual log messages that match each pattern Click pattern to expand the row and see a table of individual log records. To see additional records, scroll up or down. To explore an individual log in more detail, click it to open the details panel. Group and filter patterns by their attributes Use the query bar and time picker. As you apply different filters and time windows, the log patterns adjust to your new target data. Create an alert from a pattern Add the pattern to the query bar and run the query. Then click Create alert condition in the left nav. Troubleshoot log messages that haven't been clustered into a pattern Use the Logs with no pattern tab in the Log patterns UI. Clicking a specific log message will open the log message details panel you're familiar with from the Logs management page. Explore logs with no pattern The Logs with no pattern tab groups all recent log messages in your account that were not clustered into a known pattern yet. These log messages don't represent any problem or flaw in the system; they have no pattern because they are too new to have been processed by the machine learning system. This makes them valuable to explore when you want to understand what has recently changed in your environment. one.newrelic.com > Log management > Log patterns: New Relic's log patterns feature automatically groups logs without a matching pattern. For example: Are any of these logs tied to a recent problem? This is a quick way to discover unique log data that is appearing for the first time in your environment. Does your log data have a new format? Sometimes the logs don't represent a problem, but a new format of log data that deviates from the data model you expect your applications to follow. Catching these logs early gives you the opportunity to ask developers to correct any deviations in their log output. The more consistent people are in the way log data is generated, the easier it becomes to use logs across a diverse set of teams. Masked attributes and wildcards Parts of the log messages in patterns are classified as variables and are substituted by masked attributes. The masking process supports and improves the clustering phase by allowing the algorithm to ignore changing details and focus on the repetitive structure. Masked attributes include: date_time ip url uuid Masked attributes are highlighted and are easy to identify, as shown in the following example. one.newrelic.com > Log management > Log patterns: Here is an example of a pattern that has masked attributes. Log patterns extract other less trivial variables that don't belong to any masked attribute. These variables are indicated as wildcards *. one.newrelic.com > Log management > Log patterns: Here is an example of how wildcards * group variables. Troubleshooting Here are a few reasons why you might have patterns enabled but not see any pattern data. If you're sure none of the items below are true, get help from support.newrelic.com. No data has arrived in the timeframe you're observing. Try expanding the time range you're viewing with the time picker. It's been less than 24 hours since patterns were enabled in the account. This means the ML model may not be generated for the account yet. None of the data coming in has a message field. Patterns will only be generated for values in the message field of a log record. If your logs don't contain message, there will be no data. Put the platform to work with patterns Patterns are a value that is enriched onto the existing log message as a new attribute named newrelic.logPattern. Anything you can do with logs generally can be done with log patterns, such as: Build your own dashboards with patterns, to monitor a specific pattern or group of patterns you care about. Create alerts for patterns by adding NRQL alerts. Use baseline alert conditions to detect anomalies in known log patterns.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 336.34848,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Discover value in <em>log</em> <em>data</em> with patterns",
        "sections": "Discover value in <em>log</em> <em>data</em> with patterns",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " this feature is dependent on role-based permissions. If you see Patterns are turned off in your <em>Log</em> <em>management</em> Patterns <em>UI</em>, click the Configure Patterns button and enable it. If you don&#x27;t see patterns within 30 minutes of enabling the feature, there may be a lack of <em>data</em> with a message attribute"
      },
      "id": "6072d46128ccbc244451c18b"
    },
    {
      "sections": [
        "Organize data with partitions",
        "Plan your partition",
        "Important",
        "Required roles and permissions",
        "Sizing and organizing a partition",
        "Choosing a namespace",
        "Create partition rules",
        "Search data partitions",
        "Manage data partitions programatically with NerdGraph"
      ],
      "title": "Organize data with partitions",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "28cac5fac1065f4b1756700e7f6c11c325734c35",
      "image": "https://docs.newrelic.com/static/7815845d8068377477aa26f8571d5907/c1b63/log-partitions-crop.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/data-partitions/",
      "published_at": "2021-07-02T14:35:27Z",
      "updated_at": "2021-07-02T14:35:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Data partitions are a way to group or organize log data for faster and more efficient querying. When a query targets a single partition, New Relic Logs: Scans less unrelated data. Returns results faster. Accounts can have multiple partitions, and multiple partitions can be queried at the same time. Data partitions also allow data to be mapped to an alternative, or “secondary” namespace with a fixed 30-day retention. This is useful for maintaining compliance with privacy-centric regulations and standards like the General Data Protection Regulation (GDPR). Plan your partition Before you start creating partitions, make sure you have the right permissions and a partition plan. Important Logs are routed to partitions during the ingestion process, before data is written to NRDB. Partition rules will not affect logs that were ingested before the rule was created. Required roles and permissions Users require an Admin role to create and modify partition rules. Sizing and organizing a partition You can gain significant performance improvements with proper use of data partitions. Organizing your data into discrete partitions enables you to query them separately or all together. The goals of partitioning your data should be: Create data partitions that align with concepts in your environment or organization that are static or change infrequently (for example, by business unit, team, environment, service, etc.). Ensure each partition remains below 1 TB of daily ingest for optimal performance. Having more partitions allows for more targeted searches, but creating too many partitions can make logs hard to find and increase administrative overhead. Finding the right balance is important. We support 100 partitions maximum per account, but the optimal number for most accounts is 10 to 15 partitions. Choosing a namespace A partition’s namespace determines its retention period. We offer two retention options: Standard: The account’s default retention determined by your New Relic subscription. This is the maximum retention period available in your account and is the namespace you'll select for most of your partitions. Secondary: 30-day retention. All logs sent to a partition that's a member of the Secondary namespace will be purged on a rolling basis 30 days after having been ingested. Secondary retention is not a cost control mechanism; data is billed on ingest. Create partition rules one.newrelic.com > Logs: From the left nav in the Logs UI, select Data partitions, then create a Log_ partition name with the retention namespace, optional description, and matching criteria. To create a new partition rule: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Data partitions, then click Create partition rule. Define a Partition name as an alphanumeric string that begins with Log_. Add an optional description. Select the retention namespace for the partition. Set your rule's Matching criteria: Select EQUALS to target logs that match your criteria exactly, or select LIKE to apply a fuzzy match. Click the Enable Rule slider, and click Create. To view a list of data partitions: From Manage Data on the left nav of the Logs UI, click Data partitions. Search data partitions The default partition for all Logs accounts is Log. Any log that is not affected by a partition rule will be stored in the Log partition by default. You can query multiple partitions simultaneously. For best performance, select the smallest number of partitions possible. To search data partitions: From Views and Attributes on the left nav of the Logs UI, click Select partitions. Click one or more partitions you want to query, or search for a partition name. Click Query logs to search your selected partitions. Manage data partitions programatically with NerdGraph If you want to manage your data partitions programatically, you can use NerdGraph, our graphQL API, to do so. This tutorial shows how to query, create, and delete data partitions using our API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 336.32574,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Organize <em>data</em> with partitions",
        "sections": "<em>Manage</em> <em>data</em> partitions programatically with NerdGraph",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " partition rules one.newrelic.com &gt; <em>Logs</em>: From the left nav in the <em>Logs</em> <em>UI</em>, select <em>Data</em> partitions, then create a <em>Log</em>_ partition name with the retention namespace, optional description, and matching criteria. To create a new partition rule: Go to one.newrelic.com &gt; <em>Logs</em>. From Manage <em>Data</em> on the left nav"
      },
      "id": "6087e311e7b9d2f90ba5c6a4"
    },
    {
      "sections": [
        "Drop data with drop filter rules",
        "Savings, security, speed",
        "Caution",
        "How drop filter rules work",
        "Cautions when dropping data",
        "Create drop filter rules",
        "Types of drop filter rules",
        "Drop log events",
        "Drop attributes",
        "Tip",
        "View or delete drop filter rules"
      ],
      "title": "Drop data with drop filter rules ",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "9590bd4593abd451633a4beacd94d56eb1a481bd",
      "image": "https://docs.newrelic.com/static/db4b077fafd911b9f5019b022b3048ab/b04e4/ingest-pipeline.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/drop-data-drop-filter-rules/",
      "published_at": "2021-07-02T14:35:27Z",
      "updated_at": "2021-06-26T14:34:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After log event data has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both log events and event attributes via drop filter rules. You can manage drop filter rules using our Logs UI, as explained in this document. You can also use NerdGraph. Savings, security, speed Drop filter rules help you accomplish several important goals: Lower costs by storing only logs relevant to your account. Protect privacy and security by removing personal identifiable information (PII). Reduce noise by removing irrelevant events and attributes. Caution Use caution when deciding to drop data. The data you drop is not recoverable. Before using this feature, review the responsibilities and considerations for dropping data. How drop filter rules work A drop filter rule matches data based on a query. When triggered, the drop filter rule removes the matching data from the ingestion pipeline before it is written to NRDB. This creates an explicit demarcation between the logs being forwarded from your domain and the data that New Relic collects. Since the data removed by the drop filter rule doesn't reach our backend, it cannot be queried: the data is gone and cannot be restored. During the ingestion process, customer log data can be parsed, transformed, or dropped before being stored in New Relic's database. Cautions when dropping data When creating drop rules, you are responsible for ensuring that the rules accurately identify and discard the data that meets the conditions that you have established. You are also responsible for monitoring the rule, as well as the data you disclose to New Relic. New Relic cannot guarantee that this functionality will completely resolve data disclosure concerns you may have. New Relic doesn't review or monitor how effective the rules you develop are. Creating rules about sensitive data can leak information about what kinds of data you maintain, including the format of your data or systems (for example, through referencing email addresses or specific credit card numbers). Any user with the relevant role-based access control permissions can view and edit all information in the rules you create. Create drop filter rules To create and edit drop filters, you must have admin permissions in New Relic, or you must be a member of a role with create and edit permissions for Logging Parsing Rules. Once a drop filter rule is active, it's applied to all log events ingested from that point onwards. Rules are not applied retroactively. Logs collected before creating a rule are not filtered by that rule. one.newrelic.com > Logs: Filter or query the set of logs that contain the data you want to drop. Then, from Manage Data on the left nav of the Logs UI, click Create drop filter. To create a new drop filter rule, you can use new or existing log queries. Go to one.newrelic.com > Logs. Filter or query to the specific set of logs that contain the data to be dropped. Once the query is active, from Manage Data on the left nav of the Logs UI, click Create drop filter. Recommendation: Change the drop rule's default name to a meaningful name. Choose to either drop the entire log event that matches the query or just a specific subset of attributes in the matching events. Review the log partitions where this drop rule applies. Save the drop filter rule. Types of drop filter rules The drop filters UI prompts you to select whether to drop logs based on the query or on specific attributes. Drop log events The default type of drop filter rule is to drop logs. This option drops the entire log events that match the filter or query. When creating a rule, try to provide a specific query that only matches log data that should be dropped. Our drop filters process won't let you create drop filter rules without values in the matching query. This prevents badly formed rules from dropping all log data. Drop attributes You can specify attributes to be dropped in a log event that matches your query. At least one or more attributes must be selected. Any attribute which is selected will be dropped; all remaining attributes will be kept and stored in NRDB. Tip We recommend this method for removing fields that could contain personal identifiable information (PII) or other sensitive attributes without losing valuable monitoring data. View or delete drop filter rules To view or delete a drop filter rule: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Drop filters. Click the delete icon next to the drop filter rule you want to remove. Once deleted, rules no longer filter ingested log events.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.24408,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Drop <em>data</em> with drop filter rules ",
        "sections": "Drop <em>data</em> with drop filter rules",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "After <em>log</em> event <em>data</em> has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both <em>log</em> events and event attributes via drop filter rules. You can manage drop filter rules using our <em>Logs</em> <em>UI</em>, as explained in this document. You can also use"
      },
      "id": "603e813f28ccbc08c1eba787"
    }
  ],
  "/docs/logs/log-management/ui-data/query-syntax-logs": [
    {
      "sections": [
        "Discover value in log data with patterns",
        "Technical overview",
        "Availability",
        "Important",
        "Get started",
        "Explore log patterns",
        "Explore logs with no pattern",
        "Masked attributes and wildcards",
        "Troubleshooting",
        "Put the platform to work with patterns"
      ],
      "title": "Discover value in log data with patterns",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "8f1e27c94327ca4888a945f8e12f9c2310ccd7a6",
      "image": "https://docs.newrelic.com/static/578d7186bb34352855696e5307cc82f2/c1b63/log-patterns-logs-without-a-pattern.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/find-unusual-logs-log-patterns/",
      "published_at": "2021-07-02T14:37:14Z",
      "updated_at": "2021-07-02T14:37:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Log patterns are the fastest way to discover value in log data without searching. Log data is high volume telemetry with a low value per individual record. Searching can quickly lead to logs that provide a root cause explanation, but most data is repetitive and hard to contextualize when browsing. Patterns can make log data discoverable without spending a lot of time reading through low value data. one.newrelic.com > Logs > Patterns: Use patterns as the basis for alerts when the frequency of important data changes, or for configuring drop rules to get rid of unnecessary repetitive data. Technical overview Log patterns functionality applies machine learning to normalize and group log messages that are consistent in format but variable in content. These grouped messages can be sorted, making it easy to find the most frequent or rarest sets of logs in your environment. Use patterns as the basis for alerts when the frequency of important data changes, or to configure drop rules to get rid of unnecessary repetitive data. Log patterns use advanced clustering algorithms to group together similar log messages automatically. With patterns, you can: Orient more quickly through millions of logs. Reduce the time it takes to identify unusual behavior in your log estate. Monitor the frequency of known patterns over time to focus your energy on what matters, and exclude what's irrelevant. Availability Important Log patterns are not available in the EU region. The ability to configure this feature is dependent on role-based permissions. If you see Patterns are turned off in your Log management Patterns UI, click the Configure Patterns button and enable it. If you don't see patterns within 30 minutes of enabling the feature, there may be a lack of data with a message attribute for the system to create a pattern from. Log patterns Limitations and considerations Pricing There is no separate pricing for log patterns. The only cost is for additional data generated and added to your log records. A pattern attribute will be added to all logs that match a pattern. Attributes also may be added when common values are discovered, such as GUIDs, IP addresses, URL, or email addresses. These attributes are automatically extracted from the log message as part of the pattern process. HITRUST accounts The log patterns feature is not FedRAMP compliant. FedRAMP or other HITRUST accounts are not eligible to use patterns. Regional availability Availability for this feature depends on whether you have a US or EU region account: US region accounts can use log patterns. EU region accounts cannot enable log patterns at this time. Parsing limits We have a system of safety limits on memory and CPU resources when processing logs and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com > Log management, and use the account picker dropdown to select the target account where you want to explore patterns. In the left navigation of the Log management UI, click Patterns. The main log UI changes to show patterns that match the query in the query bar. one.newrelic.com > Log management > Log patterns: The line chart shows the top 5 patterns over time. Use the time picker and query bar to adjust the results. Explore log patterns By default the log patterns UI first shows the most frequent occurrence of patterns. To sort to show the rarest patterns first, click the Count column. You can also use the query bar or attributes bar to filter your log patterns. If you want to... Do this... Understand the rate of change in patterns Look at the line chart. The color-coded patterns correspond to the plot column in the table. You can toggle individual plot patterns to narrow your focus. See the individual log messages that match each pattern Click pattern to expand the row and see a table of individual log records. To see additional records, scroll up or down. To explore an individual log in more detail, click it to open the details panel. Group and filter patterns by their attributes Use the query bar and time picker. As you apply different filters and time windows, the log patterns adjust to your new target data. Create an alert from a pattern Add the pattern to the query bar and run the query. Then click Create alert condition in the left nav. Troubleshoot log messages that haven't been clustered into a pattern Use the Logs with no pattern tab in the Log patterns UI. Clicking a specific log message will open the log message details panel you're familiar with from the Logs management page. Explore logs with no pattern The Logs with no pattern tab groups all recent log messages in your account that were not clustered into a known pattern yet. These log messages don't represent any problem or flaw in the system; they have no pattern because they are too new to have been processed by the machine learning system. This makes them valuable to explore when you want to understand what has recently changed in your environment. one.newrelic.com > Log management > Log patterns: New Relic's log patterns feature automatically groups logs without a matching pattern. For example: Are any of these logs tied to a recent problem? This is a quick way to discover unique log data that is appearing for the first time in your environment. Does your log data have a new format? Sometimes the logs don't represent a problem, but a new format of log data that deviates from the data model you expect your applications to follow. Catching these logs early gives you the opportunity to ask developers to correct any deviations in their log output. The more consistent people are in the way log data is generated, the easier it becomes to use logs across a diverse set of teams. Masked attributes and wildcards Parts of the log messages in patterns are classified as variables and are substituted by masked attributes. The masking process supports and improves the clustering phase by allowing the algorithm to ignore changing details and focus on the repetitive structure. Masked attributes include: date_time ip url uuid Masked attributes are highlighted and are easy to identify, as shown in the following example. one.newrelic.com > Log management > Log patterns: Here is an example of a pattern that has masked attributes. Log patterns extract other less trivial variables that don't belong to any masked attribute. These variables are indicated as wildcards *. one.newrelic.com > Log management > Log patterns: Here is an example of how wildcards * group variables. Troubleshooting Here are a few reasons why you might have patterns enabled but not see any pattern data. If you're sure none of the items below are true, get help from support.newrelic.com. No data has arrived in the timeframe you're observing. Try expanding the time range you're viewing with the time picker. It's been less than 24 hours since patterns were enabled in the account. This means the ML model may not be generated for the account yet. None of the data coming in has a message field. Patterns will only be generated for values in the message field of a log record. If your logs don't contain message, there will be no data. Put the platform to work with patterns Patterns are a value that is enriched onto the existing log message as a new attribute named newrelic.logPattern. Anything you can do with logs generally can be done with log patterns, such as: Build your own dashboards with patterns, to monitor a specific pattern or group of patterns you care about. Create alerts for patterns by adding NRQL alerts. Use baseline alert conditions to detect anomalies in known log patterns.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 336.34848,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Discover value in <em>log</em> <em>data</em> with patterns",
        "sections": "Discover value in <em>log</em> <em>data</em> with patterns",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " this feature is dependent on role-based permissions. If you see Patterns are turned off in your <em>Log</em> <em>management</em> Patterns <em>UI</em>, click the Configure Patterns button and enable it. If you don&#x27;t see patterns within 30 minutes of enabling the feature, there may be a lack of <em>data</em> with a message attribute"
      },
      "id": "6072d46128ccbc244451c18b"
    },
    {
      "sections": [
        "Organize data with partitions",
        "Plan your partition",
        "Important",
        "Required roles and permissions",
        "Sizing and organizing a partition",
        "Choosing a namespace",
        "Create partition rules",
        "Search data partitions",
        "Manage data partitions programatically with NerdGraph"
      ],
      "title": "Organize data with partitions",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "28cac5fac1065f4b1756700e7f6c11c325734c35",
      "image": "https://docs.newrelic.com/static/7815845d8068377477aa26f8571d5907/c1b63/log-partitions-crop.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/data-partitions/",
      "published_at": "2021-07-02T14:35:27Z",
      "updated_at": "2021-07-02T14:35:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Data partitions are a way to group or organize log data for faster and more efficient querying. When a query targets a single partition, New Relic Logs: Scans less unrelated data. Returns results faster. Accounts can have multiple partitions, and multiple partitions can be queried at the same time. Data partitions also allow data to be mapped to an alternative, or “secondary” namespace with a fixed 30-day retention. This is useful for maintaining compliance with privacy-centric regulations and standards like the General Data Protection Regulation (GDPR). Plan your partition Before you start creating partitions, make sure you have the right permissions and a partition plan. Important Logs are routed to partitions during the ingestion process, before data is written to NRDB. Partition rules will not affect logs that were ingested before the rule was created. Required roles and permissions Users require an Admin role to create and modify partition rules. Sizing and organizing a partition You can gain significant performance improvements with proper use of data partitions. Organizing your data into discrete partitions enables you to query them separately or all together. The goals of partitioning your data should be: Create data partitions that align with concepts in your environment or organization that are static or change infrequently (for example, by business unit, team, environment, service, etc.). Ensure each partition remains below 1 TB of daily ingest for optimal performance. Having more partitions allows for more targeted searches, but creating too many partitions can make logs hard to find and increase administrative overhead. Finding the right balance is important. We support 100 partitions maximum per account, but the optimal number for most accounts is 10 to 15 partitions. Choosing a namespace A partition’s namespace determines its retention period. We offer two retention options: Standard: The account’s default retention determined by your New Relic subscription. This is the maximum retention period available in your account and is the namespace you'll select for most of your partitions. Secondary: 30-day retention. All logs sent to a partition that's a member of the Secondary namespace will be purged on a rolling basis 30 days after having been ingested. Secondary retention is not a cost control mechanism; data is billed on ingest. Create partition rules one.newrelic.com > Logs: From the left nav in the Logs UI, select Data partitions, then create a Log_ partition name with the retention namespace, optional description, and matching criteria. To create a new partition rule: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Data partitions, then click Create partition rule. Define a Partition name as an alphanumeric string that begins with Log_. Add an optional description. Select the retention namespace for the partition. Set your rule's Matching criteria: Select EQUALS to target logs that match your criteria exactly, or select LIKE to apply a fuzzy match. Click the Enable Rule slider, and click Create. To view a list of data partitions: From Manage Data on the left nav of the Logs UI, click Data partitions. Search data partitions The default partition for all Logs accounts is Log. Any log that is not affected by a partition rule will be stored in the Log partition by default. You can query multiple partitions simultaneously. For best performance, select the smallest number of partitions possible. To search data partitions: From Views and Attributes on the left nav of the Logs UI, click Select partitions. Click one or more partitions you want to query, or search for a partition name. Click Query logs to search your selected partitions. Manage data partitions programatically with NerdGraph If you want to manage your data partitions programatically, you can use NerdGraph, our graphQL API, to do so. This tutorial shows how to query, create, and delete data partitions using our API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 336.32574,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Organize <em>data</em> with partitions",
        "sections": "<em>Manage</em> <em>data</em> partitions programatically with NerdGraph",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " partition rules one.newrelic.com &gt; <em>Logs</em>: From the left nav in the <em>Logs</em> <em>UI</em>, select <em>Data</em> partitions, then create a <em>Log</em>_ partition name with the retention namespace, optional description, and matching criteria. To create a new partition rule: Go to one.newrelic.com &gt; <em>Logs</em>. From Manage <em>Data</em> on the left nav"
      },
      "id": "6087e311e7b9d2f90ba5c6a4"
    },
    {
      "sections": [
        "Drop data with drop filter rules",
        "Savings, security, speed",
        "Caution",
        "How drop filter rules work",
        "Cautions when dropping data",
        "Create drop filter rules",
        "Types of drop filter rules",
        "Drop log events",
        "Drop attributes",
        "Tip",
        "View or delete drop filter rules"
      ],
      "title": "Drop data with drop filter rules ",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "9590bd4593abd451633a4beacd94d56eb1a481bd",
      "image": "https://docs.newrelic.com/static/db4b077fafd911b9f5019b022b3048ab/b04e4/ingest-pipeline.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/drop-data-drop-filter-rules/",
      "published_at": "2021-07-02T14:35:27Z",
      "updated_at": "2021-06-26T14:34:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After log event data has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both log events and event attributes via drop filter rules. You can manage drop filter rules using our Logs UI, as explained in this document. You can also use NerdGraph. Savings, security, speed Drop filter rules help you accomplish several important goals: Lower costs by storing only logs relevant to your account. Protect privacy and security by removing personal identifiable information (PII). Reduce noise by removing irrelevant events and attributes. Caution Use caution when deciding to drop data. The data you drop is not recoverable. Before using this feature, review the responsibilities and considerations for dropping data. How drop filter rules work A drop filter rule matches data based on a query. When triggered, the drop filter rule removes the matching data from the ingestion pipeline before it is written to NRDB. This creates an explicit demarcation between the logs being forwarded from your domain and the data that New Relic collects. Since the data removed by the drop filter rule doesn't reach our backend, it cannot be queried: the data is gone and cannot be restored. During the ingestion process, customer log data can be parsed, transformed, or dropped before being stored in New Relic's database. Cautions when dropping data When creating drop rules, you are responsible for ensuring that the rules accurately identify and discard the data that meets the conditions that you have established. You are also responsible for monitoring the rule, as well as the data you disclose to New Relic. New Relic cannot guarantee that this functionality will completely resolve data disclosure concerns you may have. New Relic doesn't review or monitor how effective the rules you develop are. Creating rules about sensitive data can leak information about what kinds of data you maintain, including the format of your data or systems (for example, through referencing email addresses or specific credit card numbers). Any user with the relevant role-based access control permissions can view and edit all information in the rules you create. Create drop filter rules To create and edit drop filters, you must have admin permissions in New Relic, or you must be a member of a role with create and edit permissions for Logging Parsing Rules. Once a drop filter rule is active, it's applied to all log events ingested from that point onwards. Rules are not applied retroactively. Logs collected before creating a rule are not filtered by that rule. one.newrelic.com > Logs: Filter or query the set of logs that contain the data you want to drop. Then, from Manage Data on the left nav of the Logs UI, click Create drop filter. To create a new drop filter rule, you can use new or existing log queries. Go to one.newrelic.com > Logs. Filter or query to the specific set of logs that contain the data to be dropped. Once the query is active, from Manage Data on the left nav of the Logs UI, click Create drop filter. Recommendation: Change the drop rule's default name to a meaningful name. Choose to either drop the entire log event that matches the query or just a specific subset of attributes in the matching events. Review the log partitions where this drop rule applies. Save the drop filter rule. Types of drop filter rules The drop filters UI prompts you to select whether to drop logs based on the query or on specific attributes. Drop log events The default type of drop filter rule is to drop logs. This option drops the entire log events that match the filter or query. When creating a rule, try to provide a specific query that only matches log data that should be dropped. Our drop filters process won't let you create drop filter rules without values in the matching query. This prevents badly formed rules from dropping all log data. Drop attributes You can specify attributes to be dropped in a log event that matches your query. At least one or more attributes must be selected. Any attribute which is selected will be dropped; all remaining attributes will be kept and stored in NRDB. Tip We recommend this method for removing fields that could contain personal identifiable information (PII) or other sensitive attributes without losing valuable monitoring data. View or delete drop filter rules To view or delete a drop filter rule: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Drop filters. Click the delete icon next to the drop filter rule you want to remove. Once deleted, rules no longer filter ingested log events.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.24408,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Drop <em>data</em> with drop filter rules ",
        "sections": "Drop <em>data</em> with drop filter rules",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "After <em>log</em> event <em>data</em> has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both <em>log</em> events and event attributes via drop filter rules. You can manage drop filter rules using our <em>Logs</em> <em>UI</em>, as explained in this document. You can also use"
      },
      "id": "603e813f28ccbc08c1eba787"
    }
  ],
  "/docs/logs/log-management/ui-data/use-logs-ui": [
    {
      "sections": [
        "Discover value in log data with patterns",
        "Technical overview",
        "Availability",
        "Important",
        "Get started",
        "Explore log patterns",
        "Explore logs with no pattern",
        "Masked attributes and wildcards",
        "Troubleshooting",
        "Put the platform to work with patterns"
      ],
      "title": "Discover value in log data with patterns",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "8f1e27c94327ca4888a945f8e12f9c2310ccd7a6",
      "image": "https://docs.newrelic.com/static/578d7186bb34352855696e5307cc82f2/c1b63/log-patterns-logs-without-a-pattern.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/find-unusual-logs-log-patterns/",
      "published_at": "2021-07-02T14:37:14Z",
      "updated_at": "2021-07-02T14:37:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Log patterns are the fastest way to discover value in log data without searching. Log data is high volume telemetry with a low value per individual record. Searching can quickly lead to logs that provide a root cause explanation, but most data is repetitive and hard to contextualize when browsing. Patterns can make log data discoverable without spending a lot of time reading through low value data. one.newrelic.com > Logs > Patterns: Use patterns as the basis for alerts when the frequency of important data changes, or for configuring drop rules to get rid of unnecessary repetitive data. Technical overview Log patterns functionality applies machine learning to normalize and group log messages that are consistent in format but variable in content. These grouped messages can be sorted, making it easy to find the most frequent or rarest sets of logs in your environment. Use patterns as the basis for alerts when the frequency of important data changes, or to configure drop rules to get rid of unnecessary repetitive data. Log patterns use advanced clustering algorithms to group together similar log messages automatically. With patterns, you can: Orient more quickly through millions of logs. Reduce the time it takes to identify unusual behavior in your log estate. Monitor the frequency of known patterns over time to focus your energy on what matters, and exclude what's irrelevant. Availability Important Log patterns are not available in the EU region. The ability to configure this feature is dependent on role-based permissions. If you see Patterns are turned off in your Log management Patterns UI, click the Configure Patterns button and enable it. If you don't see patterns within 30 minutes of enabling the feature, there may be a lack of data with a message attribute for the system to create a pattern from. Log patterns Limitations and considerations Pricing There is no separate pricing for log patterns. The only cost is for additional data generated and added to your log records. A pattern attribute will be added to all logs that match a pattern. Attributes also may be added when common values are discovered, such as GUIDs, IP addresses, URL, or email addresses. These attributes are automatically extracted from the log message as part of the pattern process. HITRUST accounts The log patterns feature is not FedRAMP compliant. FedRAMP or other HITRUST accounts are not eligible to use patterns. Regional availability Availability for this feature depends on whether you have a US or EU region account: US region accounts can use log patterns. EU region accounts cannot enable log patterns at this time. Parsing limits We have a system of safety limits on memory and CPU resources when processing logs and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com > Log management, and use the account picker dropdown to select the target account where you want to explore patterns. In the left navigation of the Log management UI, click Patterns. The main log UI changes to show patterns that match the query in the query bar. one.newrelic.com > Log management > Log patterns: The line chart shows the top 5 patterns over time. Use the time picker and query bar to adjust the results. Explore log patterns By default the log patterns UI first shows the most frequent occurrence of patterns. To sort to show the rarest patterns first, click the Count column. You can also use the query bar or attributes bar to filter your log patterns. If you want to... Do this... Understand the rate of change in patterns Look at the line chart. The color-coded patterns correspond to the plot column in the table. You can toggle individual plot patterns to narrow your focus. See the individual log messages that match each pattern Click pattern to expand the row and see a table of individual log records. To see additional records, scroll up or down. To explore an individual log in more detail, click it to open the details panel. Group and filter patterns by their attributes Use the query bar and time picker. As you apply different filters and time windows, the log patterns adjust to your new target data. Create an alert from a pattern Add the pattern to the query bar and run the query. Then click Create alert condition in the left nav. Troubleshoot log messages that haven't been clustered into a pattern Use the Logs with no pattern tab in the Log patterns UI. Clicking a specific log message will open the log message details panel you're familiar with from the Logs management page. Explore logs with no pattern The Logs with no pattern tab groups all recent log messages in your account that were not clustered into a known pattern yet. These log messages don't represent any problem or flaw in the system; they have no pattern because they are too new to have been processed by the machine learning system. This makes them valuable to explore when you want to understand what has recently changed in your environment. one.newrelic.com > Log management > Log patterns: New Relic's log patterns feature automatically groups logs without a matching pattern. For example: Are any of these logs tied to a recent problem? This is a quick way to discover unique log data that is appearing for the first time in your environment. Does your log data have a new format? Sometimes the logs don't represent a problem, but a new format of log data that deviates from the data model you expect your applications to follow. Catching these logs early gives you the opportunity to ask developers to correct any deviations in their log output. The more consistent people are in the way log data is generated, the easier it becomes to use logs across a diverse set of teams. Masked attributes and wildcards Parts of the log messages in patterns are classified as variables and are substituted by masked attributes. The masking process supports and improves the clustering phase by allowing the algorithm to ignore changing details and focus on the repetitive structure. Masked attributes include: date_time ip url uuid Masked attributes are highlighted and are easy to identify, as shown in the following example. one.newrelic.com > Log management > Log patterns: Here is an example of a pattern that has masked attributes. Log patterns extract other less trivial variables that don't belong to any masked attribute. These variables are indicated as wildcards *. one.newrelic.com > Log management > Log patterns: Here is an example of how wildcards * group variables. Troubleshooting Here are a few reasons why you might have patterns enabled but not see any pattern data. If you're sure none of the items below are true, get help from support.newrelic.com. No data has arrived in the timeframe you're observing. Try expanding the time range you're viewing with the time picker. It's been less than 24 hours since patterns were enabled in the account. This means the ML model may not be generated for the account yet. None of the data coming in has a message field. Patterns will only be generated for values in the message field of a log record. If your logs don't contain message, there will be no data. Put the platform to work with patterns Patterns are a value that is enriched onto the existing log message as a new attribute named newrelic.logPattern. Anything you can do with logs generally can be done with log patterns, such as: Build your own dashboards with patterns, to monitor a specific pattern or group of patterns you care about. Create alerts for patterns by adding NRQL alerts. Use baseline alert conditions to detect anomalies in known log patterns.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 336.34827,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Discover value in <em>log</em> <em>data</em> with patterns",
        "sections": "Discover value in <em>log</em> <em>data</em> with patterns",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " this feature is dependent on role-based permissions. If you see Patterns are turned off in your <em>Log</em> <em>management</em> Patterns <em>UI</em>, click the Configure Patterns button and enable it. If you don&#x27;t see patterns within 30 minutes of enabling the feature, there may be a lack of <em>data</em> with a message attribute"
      },
      "id": "6072d46128ccbc244451c18b"
    },
    {
      "sections": [
        "Organize data with partitions",
        "Plan your partition",
        "Important",
        "Required roles and permissions",
        "Sizing and organizing a partition",
        "Choosing a namespace",
        "Create partition rules",
        "Search data partitions",
        "Manage data partitions programatically with NerdGraph"
      ],
      "title": "Organize data with partitions",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "28cac5fac1065f4b1756700e7f6c11c325734c35",
      "image": "https://docs.newrelic.com/static/7815845d8068377477aa26f8571d5907/c1b63/log-partitions-crop.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/data-partitions/",
      "published_at": "2021-07-02T14:35:27Z",
      "updated_at": "2021-07-02T14:35:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Data partitions are a way to group or organize log data for faster and more efficient querying. When a query targets a single partition, New Relic Logs: Scans less unrelated data. Returns results faster. Accounts can have multiple partitions, and multiple partitions can be queried at the same time. Data partitions also allow data to be mapped to an alternative, or “secondary” namespace with a fixed 30-day retention. This is useful for maintaining compliance with privacy-centric regulations and standards like the General Data Protection Regulation (GDPR). Plan your partition Before you start creating partitions, make sure you have the right permissions and a partition plan. Important Logs are routed to partitions during the ingestion process, before data is written to NRDB. Partition rules will not affect logs that were ingested before the rule was created. Required roles and permissions Users require an Admin role to create and modify partition rules. Sizing and organizing a partition You can gain significant performance improvements with proper use of data partitions. Organizing your data into discrete partitions enables you to query them separately or all together. The goals of partitioning your data should be: Create data partitions that align with concepts in your environment or organization that are static or change infrequently (for example, by business unit, team, environment, service, etc.). Ensure each partition remains below 1 TB of daily ingest for optimal performance. Having more partitions allows for more targeted searches, but creating too many partitions can make logs hard to find and increase administrative overhead. Finding the right balance is important. We support 100 partitions maximum per account, but the optimal number for most accounts is 10 to 15 partitions. Choosing a namespace A partition’s namespace determines its retention period. We offer two retention options: Standard: The account’s default retention determined by your New Relic subscription. This is the maximum retention period available in your account and is the namespace you'll select for most of your partitions. Secondary: 30-day retention. All logs sent to a partition that's a member of the Secondary namespace will be purged on a rolling basis 30 days after having been ingested. Secondary retention is not a cost control mechanism; data is billed on ingest. Create partition rules one.newrelic.com > Logs: From the left nav in the Logs UI, select Data partitions, then create a Log_ partition name with the retention namespace, optional description, and matching criteria. To create a new partition rule: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Data partitions, then click Create partition rule. Define a Partition name as an alphanumeric string that begins with Log_. Add an optional description. Select the retention namespace for the partition. Set your rule's Matching criteria: Select EQUALS to target logs that match your criteria exactly, or select LIKE to apply a fuzzy match. Click the Enable Rule slider, and click Create. To view a list of data partitions: From Manage Data on the left nav of the Logs UI, click Data partitions. Search data partitions The default partition for all Logs accounts is Log. Any log that is not affected by a partition rule will be stored in the Log partition by default. You can query multiple partitions simultaneously. For best performance, select the smallest number of partitions possible. To search data partitions: From Views and Attributes on the left nav of the Logs UI, click Select partitions. Click one or more partitions you want to query, or search for a partition name. Click Query logs to search your selected partitions. Manage data partitions programatically with NerdGraph If you want to manage your data partitions programatically, you can use NerdGraph, our graphQL API, to do so. This tutorial shows how to query, create, and delete data partitions using our API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 336.32556,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Organize <em>data</em> with partitions",
        "sections": "<em>Manage</em> <em>data</em> partitions programatically with NerdGraph",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " partition rules one.newrelic.com &gt; <em>Logs</em>: From the left nav in the <em>Logs</em> <em>UI</em>, select <em>Data</em> partitions, then create a <em>Log</em>_ partition name with the retention namespace, optional description, and matching criteria. To create a new partition rule: Go to one.newrelic.com &gt; <em>Logs</em>. From Manage <em>Data</em> on the left nav"
      },
      "id": "6087e311e7b9d2f90ba5c6a4"
    },
    {
      "sections": [
        "Drop data with drop filter rules",
        "Savings, security, speed",
        "Caution",
        "How drop filter rules work",
        "Cautions when dropping data",
        "Create drop filter rules",
        "Types of drop filter rules",
        "Drop log events",
        "Drop attributes",
        "Tip",
        "View or delete drop filter rules"
      ],
      "title": "Drop data with drop filter rules ",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "9590bd4593abd451633a4beacd94d56eb1a481bd",
      "image": "https://docs.newrelic.com/static/db4b077fafd911b9f5019b022b3048ab/b04e4/ingest-pipeline.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/drop-data-drop-filter-rules/",
      "published_at": "2021-07-02T14:35:27Z",
      "updated_at": "2021-06-26T14:34:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After log event data has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both log events and event attributes via drop filter rules. You can manage drop filter rules using our Logs UI, as explained in this document. You can also use NerdGraph. Savings, security, speed Drop filter rules help you accomplish several important goals: Lower costs by storing only logs relevant to your account. Protect privacy and security by removing personal identifiable information (PII). Reduce noise by removing irrelevant events and attributes. Caution Use caution when deciding to drop data. The data you drop is not recoverable. Before using this feature, review the responsibilities and considerations for dropping data. How drop filter rules work A drop filter rule matches data based on a query. When triggered, the drop filter rule removes the matching data from the ingestion pipeline before it is written to NRDB. This creates an explicit demarcation between the logs being forwarded from your domain and the data that New Relic collects. Since the data removed by the drop filter rule doesn't reach our backend, it cannot be queried: the data is gone and cannot be restored. During the ingestion process, customer log data can be parsed, transformed, or dropped before being stored in New Relic's database. Cautions when dropping data When creating drop rules, you are responsible for ensuring that the rules accurately identify and discard the data that meets the conditions that you have established. You are also responsible for monitoring the rule, as well as the data you disclose to New Relic. New Relic cannot guarantee that this functionality will completely resolve data disclosure concerns you may have. New Relic doesn't review or monitor how effective the rules you develop are. Creating rules about sensitive data can leak information about what kinds of data you maintain, including the format of your data or systems (for example, through referencing email addresses or specific credit card numbers). Any user with the relevant role-based access control permissions can view and edit all information in the rules you create. Create drop filter rules To create and edit drop filters, you must have admin permissions in New Relic, or you must be a member of a role with create and edit permissions for Logging Parsing Rules. Once a drop filter rule is active, it's applied to all log events ingested from that point onwards. Rules are not applied retroactively. Logs collected before creating a rule are not filtered by that rule. one.newrelic.com > Logs: Filter or query the set of logs that contain the data you want to drop. Then, from Manage Data on the left nav of the Logs UI, click Create drop filter. To create a new drop filter rule, you can use new or existing log queries. Go to one.newrelic.com > Logs. Filter or query to the specific set of logs that contain the data to be dropped. Once the query is active, from Manage Data on the left nav of the Logs UI, click Create drop filter. Recommendation: Change the drop rule's default name to a meaningful name. Choose to either drop the entire log event that matches the query or just a specific subset of attributes in the matching events. Review the log partitions where this drop rule applies. Save the drop filter rule. Types of drop filter rules The drop filters UI prompts you to select whether to drop logs based on the query or on specific attributes. Drop log events The default type of drop filter rule is to drop logs. This option drops the entire log events that match the filter or query. When creating a rule, try to provide a specific query that only matches log data that should be dropped. Our drop filters process won't let you create drop filter rules without values in the matching query. This prevents badly formed rules from dropping all log data. Drop attributes You can specify attributes to be dropped in a log event that matches your query. At least one or more attributes must be selected. Any attribute which is selected will be dropped; all remaining attributes will be kept and stored in NRDB. Tip We recommend this method for removing fields that could contain personal identifiable information (PII) or other sensitive attributes without losing valuable monitoring data. View or delete drop filter rules To view or delete a drop filter rule: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Drop filters. Click the delete icon next to the drop filter rule you want to remove. Once deleted, rules no longer filter ingested log events.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.244,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Drop <em>data</em> with drop filter rules ",
        "sections": "Drop <em>data</em> with drop filter rules",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "After <em>log</em> event <em>data</em> has been shipped to New Relic, it can either be stored in our NRDB database or dropped (discarded). We can drop both <em>log</em> events and event attributes via drop filter rules. You can manage drop filter rules using our <em>Logs</em> <em>UI</em>, as explained in this document. You can also use"
      },
      "id": "603e813f28ccbc08c1eba787"
    }
  ],
  "/docs/logs/new-relic-logs/troubleshooting/json-message-not-parsed": [
    {
      "sections": [
        "Discover value in log data with patterns",
        "Technical overview",
        "Availability",
        "Important",
        "Get started",
        "Explore log patterns",
        "Explore logs with no pattern",
        "Masked attributes and wildcards",
        "Troubleshooting",
        "Put the platform to work with patterns"
      ],
      "title": "Discover value in log data with patterns",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "8f1e27c94327ca4888a945f8e12f9c2310ccd7a6",
      "image": "https://docs.newrelic.com/static/578d7186bb34352855696e5307cc82f2/c1b63/log-patterns-logs-without-a-pattern.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/find-unusual-logs-log-patterns/",
      "published_at": "2021-07-02T14:37:14Z",
      "updated_at": "2021-07-02T14:37:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Log patterns are the fastest way to discover value in log data without searching. Log data is high volume telemetry with a low value per individual record. Searching can quickly lead to logs that provide a root cause explanation, but most data is repetitive and hard to contextualize when browsing. Patterns can make log data discoverable without spending a lot of time reading through low value data. one.newrelic.com > Logs > Patterns: Use patterns as the basis for alerts when the frequency of important data changes, or for configuring drop rules to get rid of unnecessary repetitive data. Technical overview Log patterns functionality applies machine learning to normalize and group log messages that are consistent in format but variable in content. These grouped messages can be sorted, making it easy to find the most frequent or rarest sets of logs in your environment. Use patterns as the basis for alerts when the frequency of important data changes, or to configure drop rules to get rid of unnecessary repetitive data. Log patterns use advanced clustering algorithms to group together similar log messages automatically. With patterns, you can: Orient more quickly through millions of logs. Reduce the time it takes to identify unusual behavior in your log estate. Monitor the frequency of known patterns over time to focus your energy on what matters, and exclude what's irrelevant. Availability Important Log patterns are not available in the EU region. The ability to configure this feature is dependent on role-based permissions. If you see Patterns are turned off in your Log management Patterns UI, click the Configure Patterns button and enable it. If you don't see patterns within 30 minutes of enabling the feature, there may be a lack of data with a message attribute for the system to create a pattern from. Log patterns Limitations and considerations Pricing There is no separate pricing for log patterns. The only cost is for additional data generated and added to your log records. A pattern attribute will be added to all logs that match a pattern. Attributes also may be added when common values are discovered, such as GUIDs, IP addresses, URL, or email addresses. These attributes are automatically extracted from the log message as part of the pattern process. HITRUST accounts The log patterns feature is not FedRAMP compliant. FedRAMP or other HITRUST accounts are not eligible to use patterns. Regional availability Availability for this feature depends on whether you have a US or EU region account: US region accounts can use log patterns. EU region accounts cannot enable log patterns at this time. Parsing limits We have a system of safety limits on memory and CPU resources when processing logs and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com > Log management, and use the account picker dropdown to select the target account where you want to explore patterns. In the left navigation of the Log management UI, click Patterns. The main log UI changes to show patterns that match the query in the query bar. one.newrelic.com > Log management > Log patterns: The line chart shows the top 5 patterns over time. Use the time picker and query bar to adjust the results. Explore log patterns By default the log patterns UI first shows the most frequent occurrence of patterns. To sort to show the rarest patterns first, click the Count column. You can also use the query bar or attributes bar to filter your log patterns. If you want to... Do this... Understand the rate of change in patterns Look at the line chart. The color-coded patterns correspond to the plot column in the table. You can toggle individual plot patterns to narrow your focus. See the individual log messages that match each pattern Click pattern to expand the row and see a table of individual log records. To see additional records, scroll up or down. To explore an individual log in more detail, click it to open the details panel. Group and filter patterns by their attributes Use the query bar and time picker. As you apply different filters and time windows, the log patterns adjust to your new target data. Create an alert from a pattern Add the pattern to the query bar and run the query. Then click Create alert condition in the left nav. Troubleshoot log messages that haven't been clustered into a pattern Use the Logs with no pattern tab in the Log patterns UI. Clicking a specific log message will open the log message details panel you're familiar with from the Logs management page. Explore logs with no pattern The Logs with no pattern tab groups all recent log messages in your account that were not clustered into a known pattern yet. These log messages don't represent any problem or flaw in the system; they have no pattern because they are too new to have been processed by the machine learning system. This makes them valuable to explore when you want to understand what has recently changed in your environment. one.newrelic.com > Log management > Log patterns: New Relic's log patterns feature automatically groups logs without a matching pattern. For example: Are any of these logs tied to a recent problem? This is a quick way to discover unique log data that is appearing for the first time in your environment. Does your log data have a new format? Sometimes the logs don't represent a problem, but a new format of log data that deviates from the data model you expect your applications to follow. Catching these logs early gives you the opportunity to ask developers to correct any deviations in their log output. The more consistent people are in the way log data is generated, the easier it becomes to use logs across a diverse set of teams. Masked attributes and wildcards Parts of the log messages in patterns are classified as variables and are substituted by masked attributes. The masking process supports and improves the clustering phase by allowing the algorithm to ignore changing details and focus on the repetitive structure. Masked attributes include: date_time ip url uuid Masked attributes are highlighted and are easy to identify, as shown in the following example. one.newrelic.com > Log management > Log patterns: Here is an example of a pattern that has masked attributes. Log patterns extract other less trivial variables that don't belong to any masked attribute. These variables are indicated as wildcards *. one.newrelic.com > Log management > Log patterns: Here is an example of how wildcards * group variables. Troubleshooting Here are a few reasons why you might have patterns enabled but not see any pattern data. If you're sure none of the items below are true, get help from support.newrelic.com. No data has arrived in the timeframe you're observing. Try expanding the time range you're viewing with the time picker. It's been less than 24 hours since patterns were enabled in the account. This means the ML model may not be generated for the account yet. None of the data coming in has a message field. Patterns will only be generated for values in the message field of a log record. If your logs don't contain message, there will be no data. Put the platform to work with patterns Patterns are a value that is enriched onto the existing log message as a new attribute named newrelic.logPattern. Anything you can do with logs generally can be done with log patterns, such as: Build your own dashboards with patterns, to monitor a specific pattern or group of patterns you care about. Create alerts for patterns by adding NRQL alerts. Use baseline alert conditions to detect anomalies in known log patterns.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 217.56583,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Discover value in <em>log</em> data with patterns",
        "sections": "Explore <em>logs</em> with no pattern",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " and CPU resources when processing <em>logs</em> and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com &gt; <em>Log</em> <em>management</em>, and use the account picker dropdown"
      },
      "id": "6072d46128ccbc244451c18b"
    },
    {
      "sections": [
        "Organize data with partitions",
        "Plan your partition",
        "Important",
        "Required roles and permissions",
        "Sizing and organizing a partition",
        "Choosing a namespace",
        "Create partition rules",
        "Search data partitions",
        "Manage data partitions programatically with NerdGraph"
      ],
      "title": "Organize data with partitions",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "28cac5fac1065f4b1756700e7f6c11c325734c35",
      "image": "https://docs.newrelic.com/static/7815845d8068377477aa26f8571d5907/c1b63/log-partitions-crop.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/data-partitions/",
      "published_at": "2021-07-02T14:35:27Z",
      "updated_at": "2021-07-02T14:35:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Data partitions are a way to group or organize log data for faster and more efficient querying. When a query targets a single partition, New Relic Logs: Scans less unrelated data. Returns results faster. Accounts can have multiple partitions, and multiple partitions can be queried at the same time. Data partitions also allow data to be mapped to an alternative, or “secondary” namespace with a fixed 30-day retention. This is useful for maintaining compliance with privacy-centric regulations and standards like the General Data Protection Regulation (GDPR). Plan your partition Before you start creating partitions, make sure you have the right permissions and a partition plan. Important Logs are routed to partitions during the ingestion process, before data is written to NRDB. Partition rules will not affect logs that were ingested before the rule was created. Required roles and permissions Users require an Admin role to create and modify partition rules. Sizing and organizing a partition You can gain significant performance improvements with proper use of data partitions. Organizing your data into discrete partitions enables you to query them separately or all together. The goals of partitioning your data should be: Create data partitions that align with concepts in your environment or organization that are static or change infrequently (for example, by business unit, team, environment, service, etc.). Ensure each partition remains below 1 TB of daily ingest for optimal performance. Having more partitions allows for more targeted searches, but creating too many partitions can make logs hard to find and increase administrative overhead. Finding the right balance is important. We support 100 partitions maximum per account, but the optimal number for most accounts is 10 to 15 partitions. Choosing a namespace A partition’s namespace determines its retention period. We offer two retention options: Standard: The account’s default retention determined by your New Relic subscription. This is the maximum retention period available in your account and is the namespace you'll select for most of your partitions. Secondary: 30-day retention. All logs sent to a partition that's a member of the Secondary namespace will be purged on a rolling basis 30 days after having been ingested. Secondary retention is not a cost control mechanism; data is billed on ingest. Create partition rules one.newrelic.com > Logs: From the left nav in the Logs UI, select Data partitions, then create a Log_ partition name with the retention namespace, optional description, and matching criteria. To create a new partition rule: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Data partitions, then click Create partition rule. Define a Partition name as an alphanumeric string that begins with Log_. Add an optional description. Select the retention namespace for the partition. Set your rule's Matching criteria: Select EQUALS to target logs that match your criteria exactly, or select LIKE to apply a fuzzy match. Click the Enable Rule slider, and click Create. To view a list of data partitions: From Manage Data on the left nav of the Logs UI, click Data partitions. Search data partitions The default partition for all Logs accounts is Log. Any log that is not affected by a partition rule will be stored in the Log partition by default. You can query multiple partitions simultaneously. For best performance, select the smallest number of partitions possible. To search data partitions: From Views and Attributes on the left nav of the Logs UI, click Select partitions. Click one or more partitions you want to query, or search for a partition name. Click Query logs to search your selected partitions. Manage data partitions programatically with NerdGraph If you want to manage your data partitions programatically, you can use NerdGraph, our graphQL API, to do so. This tutorial shows how to query, create, and delete data partitions using our API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.79697,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Manage</em> data partitions programatically with NerdGraph",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Data partitions are a way to group or organize <em>log</em> data for faster and more efficient querying. When a query targets a single partition, New Relic <em>Logs</em>: Scans less unrelated data. Returns results faster. Accounts can have multiple partitions, and multiple partitions can be queried at the same time"
      },
      "id": "6087e311e7b9d2f90ba5c6a4"
    },
    {
      "sections": [
        "Use TCP endpoint to forward logs to New Relic",
        "Compatibility and requirements",
        "Important",
        "Configure rsyslog",
        "Legacy config file for rsyslog 7 or earlier",
        "Configure syslog-ng",
        "Tip"
      ],
      "title": "Use TCP endpoint to forward logs to New Relic",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Log API"
      ],
      "external_id": "3f572fe998dd7f72516a7b654295b779ff290176",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/log-api/use-tcp-endpoint-forward-logs-new-relic/",
      "published_at": "2021-07-02T14:33:44Z",
      "updated_at": "2021-06-25T22:58:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer a wide range of solutions to get your log data into New Relic. But in other situations where you don't have log forwarders (such as CDNs, hardware devices, or managed services), you can use syslog protocols via a TCP endpoint. You can forward your logs to New Relic using syslog clients such as rsyslog and syslog-ng. Compatibility and requirements To forward logs to New Relic using a syslog client, you need: A valid Insights API Insert key Some minor changes to the syslog client's configuration, as explained in this document Important Currently, our syslog endpoint only supports accounts in our US data center. Configure rsyslog To forward logs to New Relic with rsyslog: Install packages required to allow rsyslog to send logs using TLS encryption: sudo yum install rsyslog-gnutls ca-certificates Copy Optional: Configure rsyslog to tail log files and forward their contents to New Relic. Add the following to the /etc/rsyslog.conf file in order to enable its text file input module: module(load=\"imfile\" PollingInterval=\"10\" statefile.directory=\"/var/spool/rsyslog\" ) Copy In the /etc/rsyslog.d/ directory, create a text file named newrelic.conf. Explicitly include the newly created newrelic.conf to the /etc/rsyslog.d/ file: include(file=\"/etc/rsyslog.conf.d/newrelic.conf\") Copy Add the following to newrelic.conf, replacing YOUR_INSERT_KEY with your New Relic Insights API Insert key: ## Specify each of the files to be tailed in case step 1 is done input(type=\"imfile\" ruleset=\"infiles\" Tag=\"<YOUR_FILE_TAG>\" File=\"<PATH_TO_FILE>\" StateFile=\"<UNIQUE_STATEFILE_NAME >\") ## Template expected by the New Relic Syslog endpoint template(name=\"newrelic-rfc5424\" type=\"string\" string=\"<YOUR_INSERT_KEY> <%pri%>%protocol-version% %timestamp:::date-rfc3339% %hostname% %app-name% %procid% %msgid% %structured-data% %msg%\\n\" ) ## Configure TLS and log forwarding global(DefaultNetstreamDriver=\"gtls\" DefaultNetstreamDriverCAFile=\"/etc/ssl/certs/ca-certificates.crt\" ) action(type=\"omfwd\" Target=\"newrelic.syslog.nr-data.net\" Port=\"6514\" Protocol=\"tcp\" Template=\"newrelic-rfc5424\" ResendLastMSGOnReconnect=\"on\" StreamDriver=\"gtls\" StreamDriverAuthMode=\"x509/name\" StreamDriverPermittedPeers=\"*.syslog.nr-data.net\" StreamDriverMode=\"1\" ) Copy Restart the rsyslog service by running: sudo systemctl restart rsyslog Copy Check your New Relic account for logs. Legacy config file for rsyslog 7 or earlier If you are using rsyslog version 7 or below, the configuration files need to be adapted to the obsolete legacy format. This format is only kept for retro compatibility purposes. We strongly recommend to avoid using it, as stated in the rsyslog documentation. Install packages required to allow rsyslog to send logs using TLS encryption: sudo yum install rsyslog-gnutls ca-certificates Copy Optional: Configure rsyslog to tail log files and forward their contents to New Relic. Add the following to the /etc/rsyslog.conf file in order to enable its text file input module: $ModLoad imfile $InputFilePollInterval 10 $PrivDropToGroup adm $WorkDirectory /var/spool/rsyslog Copy In the /etc/rsyslog.d/ directory, create a text file named newrelic.conf. Explicitly include the newly created newrelic.conf to the /etc/rsyslog.d/ file: $IncludeConfig /etc/rsyslog.conf.d/newrelic.conf Copy Add the following to newrelic.conf, replacing YOUR_INSERT_KEY with your New Relic Insights API Insert key: ## Template expected by the New Relic Syslog endpoint $template NRLogFormat,\"YOUR_INSERT_KEY <%pri%>%protocol-version% %timestamp:::date-rfc3339% %hostname% %app-name% %procid% %msgid% %structured-data% %msg%\\n\" ## Specify each of the files to be tailed in case step 1 is done $InputFileName /path/to/file $InputFileTag <YOUR_FILE_TAG> $InputFileStateFile <UNIQUE_STATEFILE_NAME> $InputFileSeverity info $InputRunFileMonitor ## Configure TLS and log forwarding $DefaultNetstreamDriverCAFile /etc/ssl/certs/ca-certificates.crt $ActionSendStreamDriver gtls $ActionSendStreamDriverMode 1 $ActionSendStreamDriverAuthMode x509/name $ActionSendStreamDriverPermittedPeer *.syslog.nr-data.net *.* @@newrelic.syslog.nr-data.net:6514;NRLogFormat Copy Restart the rsyslog service by running: sudo systemctl restart rsyslog Copy Check your New Relic account for logs. Configure syslog-ng To forward logs to New Relic with syslog-ng: Install ca-certificates required to allow syslog-ng to send logs using TLS encryption: sudo yum install ca-certificates Copy Open the syslog-ng configuration file (/etc/syslog-ng/syslog-ng.conf) in a text editor. Define the sources to be monitored by adding: source s_src { internal(); }; Copy Optional: Configure syslog-ng to tail files by adding the following to the Sources configuration block: source s_files { file(\"<PATH_TO_FILE>\"); }; Copy Define the New Relic syslog format and add your New Relic Insights API Insert key: template NRFormat { template(\"YOUR_INSERT_KEY ${PRI}>1 ${ISODATE} ${HOST:--} ${PROGRAM:--} ${PID:--} ${MSGID:--} ${SDATA:--} $MSG\\n\"); template_escape(no); }; Copy Add the New Relic Syslog endpoint: destination d_newrelic { network(\"newrelic.syslog.nr-data.net\" port(6514) transport(\"tls\") tls(peer-verify(no)) template(NRFormat) ); }; Copy Add the following output to the log path configuration block: log { source(s_src); source(s_files); ## in case step 4 is implemented. destination(d_newrelic); }; Copy Restart syslog-ng by running: sudo service syslog-ng restart Copy Check your New Relic account for logs. Tip If you are running syslog-ng from a Docker container and experience issues, check balait/syslog image documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.1667,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use TCP endpoint to forward <em>logs</em> to New Relic",
        "sections": "Use TCP endpoint to forward <em>logs</em> to New Relic",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "We offer a wide range of solutions to get your <em>log</em> data into New Relic. But in other situations where you don&#x27;t have <em>log</em> forwarders (such as CDNs, hardware devices, or managed services), you can use syslog protocols via a TCP endpoint. You can forward your <em>logs</em> to New Relic using syslog clients"
      },
      "id": "603e7d6764441f1a774e88a0"
    }
  ],
  "/docs/mobile-apps/new-relic-mobile-apps/android-app/android-app-ui": [
    {
      "sections": [
        "Introduction to New Relic Android app",
        "Requirements",
        "Install New Relic's mobile app",
        "View New Relic data",
        "New Relic product details",
        "New Relic Synthetics data",
        "Alerts",
        "Mobile app monitoring",
        "Details on setting time range",
        "Data privacy"
      ],
      "title": "Introduction to New Relic Android app",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic Mobile apps",
        "Android app"
      ],
      "external_id": "ff8415c00363a49eaa062f4b0b13c795b4717ea5",
      "image": "https://docs.newrelic.com/static/ea914fce17844b32fdabefd60efc457e/e5166/navigation_nexus.jpg",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/android-app/introduction-new-relic-android-app/",
      "published_at": "2021-07-02T17:28:39Z",
      "updated_at": "2021-03-13T01:06:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The user interface for New Relic's Android app provides functionality similar to New Relic's standard user interface, with customized details for mobile users. Requirements Requirements include: Android 4.0 (Ice Cream Sandwich) or higher Screen size of 7 inches or less Install New Relic's mobile app You can install the New Relic Android app from the Google Play Store or learn more from the New Relic website. Follow standard procedures to install any Android app, then sign in with your New Relic user name (account email) and password if applicable. Depending on your New Relic account, additional installation or user authentication steps may be required. View New Relic data To view details of your apps monitored by New Relic, select a product from the app's main menu. See below for details on how to use specific features of the app: New Relic product details The New Relic Android app includes data about these features: New Relic APM metrics, both real-time and historical data, including health maps. Select the transaction icon to see detailed transaction metrics, or an Overview chart to view summary charts of your top five transactions. Select the icon to filter by labels and categories. New Relic Browser overview metrics, including average page load time, Browser Apdex, average throughput, and more. New Relic Infrastructure utilization. New Relic Plugins, including a list of their components or instances, and their charts and current values from the plugin's Summary. New Relic Mobile, including crash reports, network errors, API calls, and active user count. Event notifications, including mobile alerts wherever you are, plus deployment notifications and notes. New Relic's Android app does not have the full feature set of the New Relic web interface. For more detailed analysis, sign in to your New Relic account with a web browser. New Relic Synthetics data You can use the Android app to view your New Relic Synthetics data, including charts of your monitor's availability, load times, and load sizes. To view more detailed charts, select the caret icon. You can mute or disable your monitor, and view details of any recent errors. For scripted monitors, you can view and search the script log. Alerts When you log in to your New Relic account from the Android app, your device is automatically associated with your user channel. Then, you can add your user channel to your target policy to receive alerts. For Android alerts, notifications appear on your lock screen. To view them, tap the alert event. You can select any alert to view error details or acknowledge the alert. New Relic also sends a push notification when a colleague acknowledges an open event. Then, New Relic sends a final, closing notification when all Critical events end. Mobile app monitoring If you have a mobile application and have installed New Relic Mobile, you can monitor its performance directly from your Android device. New Relic Mobile monitoring includes network errors, API calls, and number of active users. You can also view detailed individual crash reports for a deeper understanding of a particular crash incident. Details on setting time range When viewing an application or host, you can change the visible time frame with the time picker. To move back and forth across the timeline, scrub the New Relic charts. To change the duration of the visible time slice, select the clock icon. To specify an end time other than now, slide the toggle from Ending Now to Custom Date. To save your changes and refresh the chart data, select the clock icon again. Data privacy To make troubleshooting easier, New Relic's mobile apps only record the following information about you: User's email address associated with your New Relic account, including first and last name (for authentication purposes only) IP address Device ID For more information, see our Mobile data privacy and security documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.8068,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>New</em> <em>Relic</em> <em>Android</em> <em>app</em>",
        "sections": "Install <em>New</em> <em>Relic&#x27;s</em> <em>mobile</em> <em>app</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>apps</em>",
        "body": "The user interface for <em>New</em> <em>Relic</em>&#x27;s <em>Android</em> <em>app</em> provides functionality similar to <em>New</em> <em>Relic</em>&#x27;s standard user interface, with customized details for <em>mobile</em> users. Requirements Requirements include: <em>Android</em> 4.0 (Ice Cream Sandwich) or higher Screen size of 7 inches or less Install <em>New</em> <em>Relic</em>&#x27;s <em>mobile</em>"
      },
      "id": "604415e0196a67ff23960f46"
    },
    {
      "sections": [
        "Mobile app authentication for New Relic partners",
        "Important",
        "Confirm your email address",
        "Troubleshoot email problems"
      ],
      "title": "Mobile app authentication for New Relic partners",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic Mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "de6bdd35891dbbfea0ae914251a9d5c4487594a9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-apps/mobile-app-features/authentication-partner-saml-sso-accounts/",
      "published_at": "2021-07-02T14:51:27Z",
      "updated_at": "2021-03-13T03:57:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This resource is for New Relic partners. For authentication of users in regular New Relic accounts, see Authentication. Partner account users typically use SAML-SSO to sign in through your New Relic partner site. You may not have separate passwords or authentication information for your New Relic account. If you use an email address associated with a New Relic partner account when you first sign in to the New Relic mobile app, New Relic will send you a confirmation email for authentication. Android app users will also see a notification message. Important The authentication email expires 20 minutes after it is sent. Confirm your email address To authenticate using a SAML-SSO account provided through a New Relic partner: From the New Relic mobile app, type your email address associated with the partner account. Select I don't have a password. Retrieve the authentication email from your mobile device within 20 minutes. Select the Authenticate button (Android users) or email link (Android or iOS users) in the email to log in to New Relic. You will be redirected to the New Relic mobile app and logged in to your partner account. Troubleshoot email problems Here are some troubleshooting tips: If you cannot find the authentication message from New Relic in your mobile device's email in-box, check your Spam folder. If you miss the 20-minute deadline, sign in to the New Relic mobile app again, then select the link to resend the authentication email.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 149.59813,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>app</em> authentication for <em>New</em> <em>Relic</em> partners",
        "sections": "<em>Mobile</em> <em>app</em> authentication for <em>New</em> <em>Relic</em> partners",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>apps</em>",
        "body": " <em>New</em> <em>Relic</em> account. If you use an email address associated with a <em>New</em> <em>Relic</em> partner account when you first sign in to the <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em>, <em>New</em> <em>Relic</em> will send you a confirmation email for authentication. <em>Android</em> <em>app</em> users will also see a notification message. Important The authentication email"
      },
      "id": "604418de28ccbc28932c6071"
    },
    {
      "sections": [
        "Alerting with New Relic mobile apps",
        "Tip",
        "Requirements",
        "Turn notifications on or off",
        "View alert incident details",
        "Troubleshoot alert settings",
        "Check notification settings for your mobile device.",
        "Delete the Android or iOS device from your New Relic account.",
        "Uninstall the New Relic mobile app.",
        "Reinstall the New Relic mobile app."
      ],
      "title": "Alerting with New Relic mobile apps",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic Mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "d55850dc642cc8ade20310e1d4654db61af1e809",
      "image": "https://docs.newrelic.com/static/f942198cbd9a41b7355ef7f01fa6cc66/e5166/alerts-incident-detail-nexus.jpg",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/authentication-alerts/alerting-new-relic-mobile-apps/",
      "published_at": "2021-07-02T17:28:38Z",
      "updated_at": "2021-04-06T08:55:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Tip Owner or Admins Account administrators can set up configuration to receive push notifications on Android and iOS devices from New Relic Alerts. You can receive alerts from any policy by attaching a user channel to the policy. Requirements This feature is available only to users on the original user model, not to users on the New Relic One user model. As a workaround, you can use the email notification channel. Turn notifications on or off When you log in to your New Relic account from an Android or iOS app, your device is automatically associated with your user channel. Be sure to add the associated user channel to the alert policy. View alert incident details The notification automatically appears on your device's lock screen. To start the New Relic app: Android devices: Tap the notification from the notification drawer. OR iOS devices: Swipe the screen. From the New Relic app's Alerts menu, select any alert to view error details for the associated application. Optional: Select Acknowledge. Optional: To view additional details, select Overview, Violations, or Event log. The main menu's Alerts list shows alerts in the following order, sorted by time: Active incidents Resolved incidents from today Resolved incidents and events from the past week, organized by day Troubleshoot alert settings If alerts are not working on your mobile device: Verify that you meet the requirements. Verify that alerts are enabled. Check your mobile device's notification settings, to ensure New Relic is permitted to send alerts. If the notification settings for your mobile device are correct, but you still do not receive notifications, delete the device from your account, then uninstall and reinstall the New Relic application. Check notification settings for your mobile device. Follow the procedure for your mobile device. Device To check notification settings: Android From your Android device's Settings, select Sound and notification. Check the settings for sound volume. Optional: Enable Also vibrate for calls. Check the settings for Interruptions. Check the settings for Notification. Check the settings for App notifications: Select the New Relic app, then check the settings for Block and Priority. iOS Ensure Do Not Disturb is off: From the iOS Settings app, select Do Not Disturb, and check that the Manual switch is off. Ensure the New Relic app is allowed to send notifications: From the iOS Settings app, select Notifications, and locate the New Relic app from the app list. Ensure that the Allow Notifications switch is on. Ensure that the alert style is set to Banners or Alerts. Optional: To enable audio alerts, set Sounds to on. Delete the Android or iOS device from your New Relic account. To delete the mobile device from your New Relic account, use the public graphql api api.newrelic.com/graphiql in a web browser: Query current devices by selecting actor -> mobilePushNotification -> devices and selecting appVersion, deviceId, and deviceName. Run this query to get the list of devices. Mutate to remove a device by selecting mutation -> mobilePushNotificationRemoveDevice, and passing in the deviceId from the list above. Or you can remove the device from the in-app Settings option from the menu -> Settings Look under Push notification devices, and remove from there. On iOS, slide from right to left to Delete a device, on Android, tap Delete Continue with the steps to reinstall the New Relic app from your device. Uninstall the New Relic mobile app. Follow the procedure to uninstall the New Relic app from your device, then reinstall it. Device To uninstall the New Relic app: Android From your Android device's Settings, select Apps, then select the New Relic app. Select Uninstall. Continue with the steps to reinstall the New Relic app. iOS From your iOS home screen, tap and hold the New Relic icon until it shakes. To delete the app, select the X icon. Continue with the steps to reinstall the New Relic app. Reinstall the New Relic mobile app. To reinstall the New Relic mobile app: From your Android device, select Google Play Store. OR From your iOS device's home screen, select App Store. Search for New Relic. Download the app. When the download finishes, sign in to your New Relic mobile app with your New Relic account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 139.43506,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Alerting with <em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "sections": "Alerting with <em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>apps</em>",
        "body": " there. On iOS, slide from right to left to Delete a device, on <em>Android</em>, tap Delete Continue with the steps to reinstall the <em>New</em> <em>Relic</em> <em>app</em> from your device. Uninstall the <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em>. Follow the procedure to uninstall the <em>New</em> <em>Relic</em> <em>app</em> from your device, then reinstall it. Device To uninstall"
      },
      "id": "603e9efd64441f19a14e88ab"
    }
  ],
  "/docs/mobile-apps/new-relic-mobile-apps/android-app/introduction-new-relic-android-app": [
    {
      "sections": [
        "Android app UI",
        "Pages",
        "Time range",
        "New Relic Synthetics",
        "Alerts",
        "Mobile apps",
        "For more help"
      ],
      "title": "Android app UI",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic Mobile apps",
        "Android app"
      ],
      "external_id": "8918a5a2454491a91421c55e26501a0e3f64cd3a",
      "image": "https://docs.newrelic.com/static/fc97ade0bbdbdef58b89495a0d91b734/edd00/deployment-markers_nexus.jpg",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/android-app/android-app-ui/",
      "published_at": "2021-07-02T17:27:20Z",
      "updated_at": "2021-03-13T01:23:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The UI for the New Relic Android app provides functionality similar to the standard user interface, with customized details for mobile users. Pages To view details of your New Relic apps, hosts, Synthetics monitors, Alerts, plugins, and key transactions, select a product from the main menu. The New Relic Android app includes: New Relic APM metrics, both real-time and historical data, including health maps. And, select the transaction icon for detailed transaction metrics, or an Overview Charts to view summary charts of your top five transactions. New Relic Infrastructure utilization. New Relic Plugins, including a list of their components or instances, and their charts and current values from the plugin's Summary. New Relic Mobile, including crash reports, network errors, API calls, and active user count. Select the filter icon to filter by labels and categories. Event notifications, including mobile alerts wherever you are, plus deployment notifications and notes. Note: New Relic's Android app does not have the full feature set of the New Relic web interface. For more detailed analysis, sign in to your New Relic account with a web browser. Time range When viewing an application or host, you can change the visible time frame by using the time picker icon in the top right of the page (the 7D in the screenshot). This feature is similar to the standard New Relic time picker. Features include: Scrub the New Relic charts to move back and forth in the timeline. Select the time picker to choose a time range that ends now (from 30 minutes to 90 days ago). New Relic Synthetics You can use the Android app to view your New Relic Synthetics data, including charts of your monitor's availability, load times, and load sizes. Select the caret icon to view more detailed charts. You can mute or disable your monitor, and view details of any recent errors. For scripted monitors, you can view and search the script log. Alerts When you log in to your New Relic account from the Android app, your device is automatically associated with your user channel. Then, you can add your user channel to your target policy to receive alerts. For Android alerts, notifications appear on your lock screen and can be viewed by tapping the alert. You can select any alert to view error details or acknowledge the alert. New Relic also sends a push notification when a colleague acknowledges an open event. Then, New Relic sends a final, closing notification when all Critical events end. Mobile apps If you have a mobile application and have installed New Relic Mobile, you can monitor its performance directly from your Android device. New Relic Mobile monitoring includes network errors, API calls, and number of active users. You can also view detailed individual crash reports for a deeper understanding of a particular crash incident. For more help Additional documentation resources include: New Relic Android app (compatibility, requirements, installation) Android authentication (procedures to add or remove users, and for the users to authenticate with their Android device)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.80826,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Android</em> <em>app</em> UI",
        "sections": "<em>Mobile</em> <em>apps</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>apps</em>",
        "body": "The UI for the <em>New</em> <em>Relic</em> <em>Android</em> <em>app</em> provides functionality similar to the standard user interface, with customized details for <em>mobile</em> users. Pages To view details of your <em>New</em> <em>Relic</em> <em>apps</em>, hosts, Synthetics monitors, Alerts, plugins, and key transactions, select a product from the main menu. The <em>New</em>"
      },
      "id": "6044181d28ccbc9a522c60a5"
    },
    {
      "sections": [
        "Mobile app authentication for New Relic partners",
        "Important",
        "Confirm your email address",
        "Troubleshoot email problems"
      ],
      "title": "Mobile app authentication for New Relic partners",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic Mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "de6bdd35891dbbfea0ae914251a9d5c4487594a9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-apps/mobile-app-features/authentication-partner-saml-sso-accounts/",
      "published_at": "2021-07-02T14:51:27Z",
      "updated_at": "2021-03-13T03:57:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This resource is for New Relic partners. For authentication of users in regular New Relic accounts, see Authentication. Partner account users typically use SAML-SSO to sign in through your New Relic partner site. You may not have separate passwords or authentication information for your New Relic account. If you use an email address associated with a New Relic partner account when you first sign in to the New Relic mobile app, New Relic will send you a confirmation email for authentication. Android app users will also see a notification message. Important The authentication email expires 20 minutes after it is sent. Confirm your email address To authenticate using a SAML-SSO account provided through a New Relic partner: From the New Relic mobile app, type your email address associated with the partner account. Select I don't have a password. Retrieve the authentication email from your mobile device within 20 minutes. Select the Authenticate button (Android users) or email link (Android or iOS users) in the email to log in to New Relic. You will be redirected to the New Relic mobile app and logged in to your partner account. Troubleshoot email problems Here are some troubleshooting tips: If you cannot find the authentication message from New Relic in your mobile device's email in-box, check your Spam folder. If you miss the 20-minute deadline, sign in to the New Relic mobile app again, then select the link to resend the authentication email.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 149.59813,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>app</em> authentication for <em>New</em> <em>Relic</em> partners",
        "sections": "<em>Mobile</em> <em>app</em> authentication for <em>New</em> <em>Relic</em> partners",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>apps</em>",
        "body": " <em>New</em> <em>Relic</em> account. If you use an email address associated with a <em>New</em> <em>Relic</em> partner account when you first sign in to the <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em>, <em>New</em> <em>Relic</em> will send you a confirmation email for authentication. <em>Android</em> <em>app</em> users will also see a notification message. Important The authentication email"
      },
      "id": "604418de28ccbc28932c6071"
    },
    {
      "sections": [
        "Alerting with New Relic mobile apps",
        "Tip",
        "Requirements",
        "Turn notifications on or off",
        "View alert incident details",
        "Troubleshoot alert settings",
        "Check notification settings for your mobile device.",
        "Delete the Android or iOS device from your New Relic account.",
        "Uninstall the New Relic mobile app.",
        "Reinstall the New Relic mobile app."
      ],
      "title": "Alerting with New Relic mobile apps",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic Mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "d55850dc642cc8ade20310e1d4654db61af1e809",
      "image": "https://docs.newrelic.com/static/f942198cbd9a41b7355ef7f01fa6cc66/e5166/alerts-incident-detail-nexus.jpg",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/authentication-alerts/alerting-new-relic-mobile-apps/",
      "published_at": "2021-07-02T17:28:38Z",
      "updated_at": "2021-04-06T08:55:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Tip Owner or Admins Account administrators can set up configuration to receive push notifications on Android and iOS devices from New Relic Alerts. You can receive alerts from any policy by attaching a user channel to the policy. Requirements This feature is available only to users on the original user model, not to users on the New Relic One user model. As a workaround, you can use the email notification channel. Turn notifications on or off When you log in to your New Relic account from an Android or iOS app, your device is automatically associated with your user channel. Be sure to add the associated user channel to the alert policy. View alert incident details The notification automatically appears on your device's lock screen. To start the New Relic app: Android devices: Tap the notification from the notification drawer. OR iOS devices: Swipe the screen. From the New Relic app's Alerts menu, select any alert to view error details for the associated application. Optional: Select Acknowledge. Optional: To view additional details, select Overview, Violations, or Event log. The main menu's Alerts list shows alerts in the following order, sorted by time: Active incidents Resolved incidents from today Resolved incidents and events from the past week, organized by day Troubleshoot alert settings If alerts are not working on your mobile device: Verify that you meet the requirements. Verify that alerts are enabled. Check your mobile device's notification settings, to ensure New Relic is permitted to send alerts. If the notification settings for your mobile device are correct, but you still do not receive notifications, delete the device from your account, then uninstall and reinstall the New Relic application. Check notification settings for your mobile device. Follow the procedure for your mobile device. Device To check notification settings: Android From your Android device's Settings, select Sound and notification. Check the settings for sound volume. Optional: Enable Also vibrate for calls. Check the settings for Interruptions. Check the settings for Notification. Check the settings for App notifications: Select the New Relic app, then check the settings for Block and Priority. iOS Ensure Do Not Disturb is off: From the iOS Settings app, select Do Not Disturb, and check that the Manual switch is off. Ensure the New Relic app is allowed to send notifications: From the iOS Settings app, select Notifications, and locate the New Relic app from the app list. Ensure that the Allow Notifications switch is on. Ensure that the alert style is set to Banners or Alerts. Optional: To enable audio alerts, set Sounds to on. Delete the Android or iOS device from your New Relic account. To delete the mobile device from your New Relic account, use the public graphql api api.newrelic.com/graphiql in a web browser: Query current devices by selecting actor -> mobilePushNotification -> devices and selecting appVersion, deviceId, and deviceName. Run this query to get the list of devices. Mutate to remove a device by selecting mutation -> mobilePushNotificationRemoveDevice, and passing in the deviceId from the list above. Or you can remove the device from the in-app Settings option from the menu -> Settings Look under Push notification devices, and remove from there. On iOS, slide from right to left to Delete a device, on Android, tap Delete Continue with the steps to reinstall the New Relic app from your device. Uninstall the New Relic mobile app. Follow the procedure to uninstall the New Relic app from your device, then reinstall it. Device To uninstall the New Relic app: Android From your Android device's Settings, select Apps, then select the New Relic app. Select Uninstall. Continue with the steps to reinstall the New Relic app. iOS From your iOS home screen, tap and hold the New Relic icon until it shakes. To delete the app, select the X icon. Continue with the steps to reinstall the New Relic app. Reinstall the New Relic mobile app. To reinstall the New Relic mobile app: From your Android device, select Google Play Store. OR From your iOS device's home screen, select App Store. Search for New Relic. Download the app. When the download finishes, sign in to your New Relic mobile app with your New Relic account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 139.43506,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Alerting with <em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "sections": "Alerting with <em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>apps</em>",
        "body": " there. On iOS, slide from right to left to Delete a device, on <em>Android</em>, tap Delete Continue with the steps to reinstall the <em>New</em> <em>Relic</em> <em>app</em> from your device. Uninstall the <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em>. Follow the procedure to uninstall the <em>New</em> <em>Relic</em> <em>app</em> from your device, then reinstall it. Device To uninstall"
      },
      "id": "603e9efd64441f19a14e88ab"
    }
  ],
  "/docs/mobile-apps/new-relic-mobile-apps/authentication-alerts/alerting-new-relic-mobile-apps": [
    {
      "sections": [
        "User settings and authentication",
        "User authentication",
        "User settings",
        "Sign in with additional username",
        "Switch between accounts",
        "Remove or re-add a user name"
      ],
      "title": "User settings and authentication",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic Mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "0b40ac4c2e769279d25d0ebb2ea77cebda8d8ea7",
      "image": "https://docs.newrelic.com/static/88ff328efc4a127601923bc728fea229/8c557/device-ipad-switch-user.png",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/authentication-alerts/user-settings-authentication/",
      "published_at": "2021-07-02T14:11:49Z",
      "updated_at": "2021-05-16T06:27:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This explains how to authenticate your New Relic mobile app account, and how to add users to or remove them from your mobile device. User authentication Depending on your New Relic account, additional installation or authentication steps may be required when you install the New Relic mobile app. New Relic account Additional requirements New users If you do not already have a New Relic account: From your desktop web browser, create a New Relic account. Install your application with the appropriate New Relic agent. As part of new account setup, you will receive an email with a password reset link. The password reset link expires after 20 minutes for mobile apps. Existing New Relic users No additional requirements; your applications, hosts, installed plugins, and key transactions automatically appear after you sign in. Users with New Relic partner accounts Depending on the partner, you may need to complete a different authentication process. Azure Store users: Due to the deep integration between Azure Storefront and New Relic, Azure Storefront users cannot access their accounts on the New Relic Android or iOS apps. Users with SAML-SSO enabled accounts When you sign in to the New Relic mobile app, your session automatically redirects to your web browser. From there you can sign in to your New Relic SAML-SSO account. If you see any errors when using SAML-SSO accounts on your mobile device, verify that you are able to sign in to one.newrelic.com with a desktop web browser. If no, contact your administrator. If yes, get support at support.newrelic.com. User settings After you sign in, all New Relic accounts and applications associated with the user appear automatically. Sign in with additional username Follow the procedure for your mobile device. Mobile device To sign in to the app with an additional user name: Android To switch users: Log out from the Android device: Main menu > (selected username) > Logout > Confirm. Log in with a new account. iPhone From the app menu, select your account name, then select the Users menu. From the Users menu, select the plus icon. Sign in with the additional username. iPad To access the Users menu: Select the user icon or slide right. From the Users menu, select the plus icon. Sign in with the additional username. Switch between accounts To switch between accounts associated with your username: From the Users menu, select the user name. Select the account name. Remove or re-add a user name To remove a specific username from this device: From the Users menu, select Logout. To remove a user from this device, select the user's red minus icon. Select the user's Log out icon. To add a user again, sign in with that username again. Select the user icon or slide right to show the New Relic iPad app's Users menu.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.38791,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "User settings <em>and</em> <em>authentication</em>",
        "sections": "User settings <em>and</em> <em>authentication</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>apps</em>",
        "body": "This explains how to authenticate your <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em> account, and how to add users to or remove them from your <em>mobile</em> device. User <em>authentication</em> Depending on your <em>New</em> <em>Relic</em> account, additional installation or <em>authentication</em> steps may be required when you install the <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em>"
      },
      "id": "604415a728ccbc8fb52c6068"
    },
    {
      "sections": [
        "Troubleshoot SSO accounts using mobile devices",
        "No user name or password",
        "Errors after signing in",
        "Reauthentication problems"
      ],
      "title": "Troubleshoot SSO accounts using mobile devices",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic Mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "9ebb373182ce5fea83ba5a6baa03b2c7bccf0174",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/authentication-alerts/troubleshoot-sso-accounts-using-mobile-devices/",
      "published_at": "2021-07-02T14:12:40Z",
      "updated_at": "2021-05-16T06:23:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Typically when you sign in to the New Relic mobile app, your session redirects automatically to your web browser. From there you can sign in to your New Relic account. Here are troubleshooting tips if you have problems using the New Relic mobile app with your SAML-SSO enabled account. No user name or password You may not have a user name or password for New Relic because some SAML providers will overwrite your password, or because your administrator has not sent you this information. In these situations: From the mobile app's Log in, select the I don't have a password link. Use your mobile device to open your email account. From your email account, retrieve the New Relic authentication email within 20 minutes. Select the Authenticate button or the link below it in the email. Errors after signing in If you see any errors after successfully signing in to your SSO provider with your mobile device, verify that you are able to sign in to one.newrelic.com with a desktop web browser. If no, contact your administrator. If yes, get support at support.newrelic.com. Reauthentication problems If you are using reauthentication on a SAML-SSO account, you must log in to your default account. (All other accounts will be grayed out.) If you attempt to switch to a grayed-out account, an error message will appear, explaining this is currently not supported.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.38635,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot SSO accounts using <em>mobile</em> devices",
        "sections": "Troubleshoot SSO accounts using <em>mobile</em> devices",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>apps</em>",
        "body": "Typically when you sign in to the <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em>, your session redirects automatically to your web browser. From there you can sign in to your <em>New</em> <em>Relic</em> account. Here are troubleshooting tips if you have problems using the <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em> with your SAML-SSO enabled account. No user name"
      },
      "id": "604415e0196a67fc3f960f42"
    },
    {
      "sections": [
        "Mobile app authentication for New Relic partners",
        "Important",
        "Confirm your email address",
        "Troubleshoot email problems"
      ],
      "title": "Mobile app authentication for New Relic partners",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic Mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "de6bdd35891dbbfea0ae914251a9d5c4487594a9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-apps/mobile-app-features/authentication-partner-saml-sso-accounts/",
      "published_at": "2021-07-02T14:51:27Z",
      "updated_at": "2021-03-13T03:57:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This resource is for New Relic partners. For authentication of users in regular New Relic accounts, see Authentication. Partner account users typically use SAML-SSO to sign in through your New Relic partner site. You may not have separate passwords or authentication information for your New Relic account. If you use an email address associated with a New Relic partner account when you first sign in to the New Relic mobile app, New Relic will send you a confirmation email for authentication. Android app users will also see a notification message. Important The authentication email expires 20 minutes after it is sent. Confirm your email address To authenticate using a SAML-SSO account provided through a New Relic partner: From the New Relic mobile app, type your email address associated with the partner account. Select I don't have a password. Retrieve the authentication email from your mobile device within 20 minutes. Select the Authenticate button (Android users) or email link (Android or iOS users) in the email to log in to New Relic. You will be redirected to the New Relic mobile app and logged in to your partner account. Troubleshoot email problems Here are some troubleshooting tips: If you cannot find the authentication message from New Relic in your mobile device's email in-box, check your Spam folder. If you miss the 20-minute deadline, sign in to the New Relic mobile app again, then select the link to resend the authentication email.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 208.87828,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>app</em> <em>authentication</em> for <em>New</em> <em>Relic</em> partners",
        "sections": "<em>Mobile</em> <em>app</em> <em>authentication</em> for <em>New</em> <em>Relic</em> partners",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>apps</em>",
        "body": " <em>New</em> <em>Relic</em> account. If you use an email address associated with a <em>New</em> <em>Relic</em> partner account when you first sign in to the <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em>, <em>New</em> <em>Relic</em> will send you a confirmation email for <em>authentication</em>. Android <em>app</em> users will also see a notification message. Important The <em>authentication</em> email"
      },
      "id": "604418de28ccbc28932c6071"
    }
  ],
  "/docs/mobile-apps/new-relic-mobile-apps/authentication-alerts/troubleshoot-sso-accounts-using-mobile-devices": [
    {
      "sections": [
        "User settings and authentication",
        "User authentication",
        "User settings",
        "Sign in with additional username",
        "Switch between accounts",
        "Remove or re-add a user name"
      ],
      "title": "User settings and authentication",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic Mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "0b40ac4c2e769279d25d0ebb2ea77cebda8d8ea7",
      "image": "https://docs.newrelic.com/static/88ff328efc4a127601923bc728fea229/8c557/device-ipad-switch-user.png",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/authentication-alerts/user-settings-authentication/",
      "published_at": "2021-07-02T14:11:49Z",
      "updated_at": "2021-05-16T06:27:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This explains how to authenticate your New Relic mobile app account, and how to add users to or remove them from your mobile device. User authentication Depending on your New Relic account, additional installation or authentication steps may be required when you install the New Relic mobile app. New Relic account Additional requirements New users If you do not already have a New Relic account: From your desktop web browser, create a New Relic account. Install your application with the appropriate New Relic agent. As part of new account setup, you will receive an email with a password reset link. The password reset link expires after 20 minutes for mobile apps. Existing New Relic users No additional requirements; your applications, hosts, installed plugins, and key transactions automatically appear after you sign in. Users with New Relic partner accounts Depending on the partner, you may need to complete a different authentication process. Azure Store users: Due to the deep integration between Azure Storefront and New Relic, Azure Storefront users cannot access their accounts on the New Relic Android or iOS apps. Users with SAML-SSO enabled accounts When you sign in to the New Relic mobile app, your session automatically redirects to your web browser. From there you can sign in to your New Relic SAML-SSO account. If you see any errors when using SAML-SSO accounts on your mobile device, verify that you are able to sign in to one.newrelic.com with a desktop web browser. If no, contact your administrator. If yes, get support at support.newrelic.com. User settings After you sign in, all New Relic accounts and applications associated with the user appear automatically. Sign in with additional username Follow the procedure for your mobile device. Mobile device To sign in to the app with an additional user name: Android To switch users: Log out from the Android device: Main menu > (selected username) > Logout > Confirm. Log in with a new account. iPhone From the app menu, select your account name, then select the Users menu. From the Users menu, select the plus icon. Sign in with the additional username. iPad To access the Users menu: Select the user icon or slide right. From the Users menu, select the plus icon. Sign in with the additional username. Switch between accounts To switch between accounts associated with your username: From the Users menu, select the user name. Select the account name. Remove or re-add a user name To remove a specific username from this device: From the Users menu, select Logout. To remove a user from this device, select the user's red minus icon. Select the user's Log out icon. To add a user again, sign in with that username again. Select the user icon or slide right to show the New Relic iPad app's Users menu.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.38791,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "User settings <em>and</em> <em>authentication</em>",
        "sections": "User settings <em>and</em> <em>authentication</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>apps</em>",
        "body": "This explains how to authenticate your <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em> account, and how to add users to or remove them from your <em>mobile</em> device. User <em>authentication</em> Depending on your <em>New</em> <em>Relic</em> account, additional installation or <em>authentication</em> steps may be required when you install the <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em>"
      },
      "id": "604415a728ccbc8fb52c6068"
    },
    {
      "sections": [
        "Alerting with New Relic mobile apps",
        "Tip",
        "Requirements",
        "Turn notifications on or off",
        "View alert incident details",
        "Troubleshoot alert settings",
        "Check notification settings for your mobile device.",
        "Delete the Android or iOS device from your New Relic account.",
        "Uninstall the New Relic mobile app.",
        "Reinstall the New Relic mobile app."
      ],
      "title": "Alerting with New Relic mobile apps",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic Mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "d55850dc642cc8ade20310e1d4654db61af1e809",
      "image": "https://docs.newrelic.com/static/f942198cbd9a41b7355ef7f01fa6cc66/e5166/alerts-incident-detail-nexus.jpg",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/authentication-alerts/alerting-new-relic-mobile-apps/",
      "published_at": "2021-07-02T17:28:38Z",
      "updated_at": "2021-04-06T08:55:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Tip Owner or Admins Account administrators can set up configuration to receive push notifications on Android and iOS devices from New Relic Alerts. You can receive alerts from any policy by attaching a user channel to the policy. Requirements This feature is available only to users on the original user model, not to users on the New Relic One user model. As a workaround, you can use the email notification channel. Turn notifications on or off When you log in to your New Relic account from an Android or iOS app, your device is automatically associated with your user channel. Be sure to add the associated user channel to the alert policy. View alert incident details The notification automatically appears on your device's lock screen. To start the New Relic app: Android devices: Tap the notification from the notification drawer. OR iOS devices: Swipe the screen. From the New Relic app's Alerts menu, select any alert to view error details for the associated application. Optional: Select Acknowledge. Optional: To view additional details, select Overview, Violations, or Event log. The main menu's Alerts list shows alerts in the following order, sorted by time: Active incidents Resolved incidents from today Resolved incidents and events from the past week, organized by day Troubleshoot alert settings If alerts are not working on your mobile device: Verify that you meet the requirements. Verify that alerts are enabled. Check your mobile device's notification settings, to ensure New Relic is permitted to send alerts. If the notification settings for your mobile device are correct, but you still do not receive notifications, delete the device from your account, then uninstall and reinstall the New Relic application. Check notification settings for your mobile device. Follow the procedure for your mobile device. Device To check notification settings: Android From your Android device's Settings, select Sound and notification. Check the settings for sound volume. Optional: Enable Also vibrate for calls. Check the settings for Interruptions. Check the settings for Notification. Check the settings for App notifications: Select the New Relic app, then check the settings for Block and Priority. iOS Ensure Do Not Disturb is off: From the iOS Settings app, select Do Not Disturb, and check that the Manual switch is off. Ensure the New Relic app is allowed to send notifications: From the iOS Settings app, select Notifications, and locate the New Relic app from the app list. Ensure that the Allow Notifications switch is on. Ensure that the alert style is set to Banners or Alerts. Optional: To enable audio alerts, set Sounds to on. Delete the Android or iOS device from your New Relic account. To delete the mobile device from your New Relic account, use the public graphql api api.newrelic.com/graphiql in a web browser: Query current devices by selecting actor -> mobilePushNotification -> devices and selecting appVersion, deviceId, and deviceName. Run this query to get the list of devices. Mutate to remove a device by selecting mutation -> mobilePushNotificationRemoveDevice, and passing in the deviceId from the list above. Or you can remove the device from the in-app Settings option from the menu -> Settings Look under Push notification devices, and remove from there. On iOS, slide from right to left to Delete a device, on Android, tap Delete Continue with the steps to reinstall the New Relic app from your device. Uninstall the New Relic mobile app. Follow the procedure to uninstall the New Relic app from your device, then reinstall it. Device To uninstall the New Relic app: Android From your Android device's Settings, select Apps, then select the New Relic app. Select Uninstall. Continue with the steps to reinstall the New Relic app. iOS From your iOS home screen, tap and hold the New Relic icon until it shakes. To delete the app, select the X icon. Continue with the steps to reinstall the New Relic app. Reinstall the New Relic mobile app. To reinstall the New Relic mobile app: From your Android device, select Google Play Store. OR From your iOS device's home screen, select App Store. Search for New Relic. Download the app. When the download finishes, sign in to your New Relic mobile app with your New Relic account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.2141,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerting</em> with <em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "sections": "<em>Alerting</em> with <em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>apps</em>",
        "body": ": From the iOS Settings <em>app</em>, select Notifications, and locate the <em>New</em> <em>Relic</em> <em>app</em> from the <em>app</em> list. Ensure that the Allow Notifications switch is on. Ensure that the <em>alert</em> style is set to Banners or <em>Alerts</em>. Optional: To enable audio <em>alerts</em>, set Sounds to on. Delete the Android or iOS device from your"
      },
      "id": "603e9efd64441f19a14e88ab"
    },
    {
      "sections": [
        "Mobile app authentication for New Relic partners",
        "Important",
        "Confirm your email address",
        "Troubleshoot email problems"
      ],
      "title": "Mobile app authentication for New Relic partners",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic Mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "de6bdd35891dbbfea0ae914251a9d5c4487594a9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-apps/mobile-app-features/authentication-partner-saml-sso-accounts/",
      "published_at": "2021-07-02T14:51:27Z",
      "updated_at": "2021-03-13T03:57:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This resource is for New Relic partners. For authentication of users in regular New Relic accounts, see Authentication. Partner account users typically use SAML-SSO to sign in through your New Relic partner site. You may not have separate passwords or authentication information for your New Relic account. If you use an email address associated with a New Relic partner account when you first sign in to the New Relic mobile app, New Relic will send you a confirmation email for authentication. Android app users will also see a notification message. Important The authentication email expires 20 minutes after it is sent. Confirm your email address To authenticate using a SAML-SSO account provided through a New Relic partner: From the New Relic mobile app, type your email address associated with the partner account. Select I don't have a password. Retrieve the authentication email from your mobile device within 20 minutes. Select the Authenticate button (Android users) or email link (Android or iOS users) in the email to log in to New Relic. You will be redirected to the New Relic mobile app and logged in to your partner account. Troubleshoot email problems Here are some troubleshooting tips: If you cannot find the authentication message from New Relic in your mobile device's email in-box, check your Spam folder. If you miss the 20-minute deadline, sign in to the New Relic mobile app again, then select the link to resend the authentication email.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 208.87828,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>app</em> <em>authentication</em> for <em>New</em> <em>Relic</em> partners",
        "sections": "<em>Mobile</em> <em>app</em> <em>authentication</em> for <em>New</em> <em>Relic</em> partners",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>apps</em>",
        "body": " <em>New</em> <em>Relic</em> account. If you use an email address associated with a <em>New</em> <em>Relic</em> partner account when you first sign in to the <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em>, <em>New</em> <em>Relic</em> will send you a confirmation email for <em>authentication</em>. Android <em>app</em> users will also see a notification message. Important The <em>authentication</em> email"
      },
      "id": "604418de28ccbc28932c6071"
    }
  ],
  "/docs/mobile-apps/new-relic-mobile-apps/authentication-alerts/user-settings-authentication": [
    {
      "sections": [
        "Troubleshoot SSO accounts using mobile devices",
        "No user name or password",
        "Errors after signing in",
        "Reauthentication problems"
      ],
      "title": "Troubleshoot SSO accounts using mobile devices",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic Mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "9ebb373182ce5fea83ba5a6baa03b2c7bccf0174",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/authentication-alerts/troubleshoot-sso-accounts-using-mobile-devices/",
      "published_at": "2021-07-02T14:12:40Z",
      "updated_at": "2021-05-16T06:23:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Typically when you sign in to the New Relic mobile app, your session redirects automatically to your web browser. From there you can sign in to your New Relic account. Here are troubleshooting tips if you have problems using the New Relic mobile app with your SAML-SSO enabled account. No user name or password You may not have a user name or password for New Relic because some SAML providers will overwrite your password, or because your administrator has not sent you this information. In these situations: From the mobile app's Log in, select the I don't have a password link. Use your mobile device to open your email account. From your email account, retrieve the New Relic authentication email within 20 minutes. Select the Authenticate button or the link below it in the email. Errors after signing in If you see any errors after successfully signing in to your SSO provider with your mobile device, verify that you are able to sign in to one.newrelic.com with a desktop web browser. If no, contact your administrator. If yes, get support at support.newrelic.com. Reauthentication problems If you are using reauthentication on a SAML-SSO account, you must log in to your default account. (All other accounts will be grayed out.) If you attempt to switch to a grayed-out account, an error message will appear, explaining this is currently not supported.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.38635,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot SSO accounts using <em>mobile</em> devices",
        "sections": "Troubleshoot SSO accounts using <em>mobile</em> devices",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>apps</em>",
        "body": "Typically when you sign in to the <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em>, your session redirects automatically to your web browser. From there you can sign in to your <em>New</em> <em>Relic</em> account. Here are troubleshooting tips if you have problems using the <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em> with your SAML-SSO enabled account. No user name"
      },
      "id": "604415e0196a67fc3f960f42"
    },
    {
      "sections": [
        "Alerting with New Relic mobile apps",
        "Tip",
        "Requirements",
        "Turn notifications on or off",
        "View alert incident details",
        "Troubleshoot alert settings",
        "Check notification settings for your mobile device.",
        "Delete the Android or iOS device from your New Relic account.",
        "Uninstall the New Relic mobile app.",
        "Reinstall the New Relic mobile app."
      ],
      "title": "Alerting with New Relic mobile apps",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic Mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "d55850dc642cc8ade20310e1d4654db61af1e809",
      "image": "https://docs.newrelic.com/static/f942198cbd9a41b7355ef7f01fa6cc66/e5166/alerts-incident-detail-nexus.jpg",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/authentication-alerts/alerting-new-relic-mobile-apps/",
      "published_at": "2021-07-02T17:28:38Z",
      "updated_at": "2021-04-06T08:55:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Tip Owner or Admins Account administrators can set up configuration to receive push notifications on Android and iOS devices from New Relic Alerts. You can receive alerts from any policy by attaching a user channel to the policy. Requirements This feature is available only to users on the original user model, not to users on the New Relic One user model. As a workaround, you can use the email notification channel. Turn notifications on or off When you log in to your New Relic account from an Android or iOS app, your device is automatically associated with your user channel. Be sure to add the associated user channel to the alert policy. View alert incident details The notification automatically appears on your device's lock screen. To start the New Relic app: Android devices: Tap the notification from the notification drawer. OR iOS devices: Swipe the screen. From the New Relic app's Alerts menu, select any alert to view error details for the associated application. Optional: Select Acknowledge. Optional: To view additional details, select Overview, Violations, or Event log. The main menu's Alerts list shows alerts in the following order, sorted by time: Active incidents Resolved incidents from today Resolved incidents and events from the past week, organized by day Troubleshoot alert settings If alerts are not working on your mobile device: Verify that you meet the requirements. Verify that alerts are enabled. Check your mobile device's notification settings, to ensure New Relic is permitted to send alerts. If the notification settings for your mobile device are correct, but you still do not receive notifications, delete the device from your account, then uninstall and reinstall the New Relic application. Check notification settings for your mobile device. Follow the procedure for your mobile device. Device To check notification settings: Android From your Android device's Settings, select Sound and notification. Check the settings for sound volume. Optional: Enable Also vibrate for calls. Check the settings for Interruptions. Check the settings for Notification. Check the settings for App notifications: Select the New Relic app, then check the settings for Block and Priority. iOS Ensure Do Not Disturb is off: From the iOS Settings app, select Do Not Disturb, and check that the Manual switch is off. Ensure the New Relic app is allowed to send notifications: From the iOS Settings app, select Notifications, and locate the New Relic app from the app list. Ensure that the Allow Notifications switch is on. Ensure that the alert style is set to Banners or Alerts. Optional: To enable audio alerts, set Sounds to on. Delete the Android or iOS device from your New Relic account. To delete the mobile device from your New Relic account, use the public graphql api api.newrelic.com/graphiql in a web browser: Query current devices by selecting actor -> mobilePushNotification -> devices and selecting appVersion, deviceId, and deviceName. Run this query to get the list of devices. Mutate to remove a device by selecting mutation -> mobilePushNotificationRemoveDevice, and passing in the deviceId from the list above. Or you can remove the device from the in-app Settings option from the menu -> Settings Look under Push notification devices, and remove from there. On iOS, slide from right to left to Delete a device, on Android, tap Delete Continue with the steps to reinstall the New Relic app from your device. Uninstall the New Relic mobile app. Follow the procedure to uninstall the New Relic app from your device, then reinstall it. Device To uninstall the New Relic app: Android From your Android device's Settings, select Apps, then select the New Relic app. Select Uninstall. Continue with the steps to reinstall the New Relic app. iOS From your iOS home screen, tap and hold the New Relic icon until it shakes. To delete the app, select the X icon. Continue with the steps to reinstall the New Relic app. Reinstall the New Relic mobile app. To reinstall the New Relic mobile app: From your Android device, select Google Play Store. OR From your iOS device's home screen, select App Store. Search for New Relic. Download the app. When the download finishes, sign in to your New Relic mobile app with your New Relic account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.2141,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerting</em> with <em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "sections": "<em>Alerting</em> with <em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>apps</em>",
        "body": ": From the iOS Settings <em>app</em>, select Notifications, and locate the <em>New</em> <em>Relic</em> <em>app</em> from the <em>app</em> list. Ensure that the Allow Notifications switch is on. Ensure that the <em>alert</em> style is set to Banners or <em>Alerts</em>. Optional: To enable audio <em>alerts</em>, set Sounds to on. Delete the Android or iOS device from your"
      },
      "id": "603e9efd64441f19a14e88ab"
    },
    {
      "sections": [
        "Mobile app authentication for New Relic partners",
        "Important",
        "Confirm your email address",
        "Troubleshoot email problems"
      ],
      "title": "Mobile app authentication for New Relic partners",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic Mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "de6bdd35891dbbfea0ae914251a9d5c4487594a9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-apps/mobile-app-features/authentication-partner-saml-sso-accounts/",
      "published_at": "2021-07-02T14:51:27Z",
      "updated_at": "2021-03-13T03:57:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This resource is for New Relic partners. For authentication of users in regular New Relic accounts, see Authentication. Partner account users typically use SAML-SSO to sign in through your New Relic partner site. You may not have separate passwords or authentication information for your New Relic account. If you use an email address associated with a New Relic partner account when you first sign in to the New Relic mobile app, New Relic will send you a confirmation email for authentication. Android app users will also see a notification message. Important The authentication email expires 20 minutes after it is sent. Confirm your email address To authenticate using a SAML-SSO account provided through a New Relic partner: From the New Relic mobile app, type your email address associated with the partner account. Select I don't have a password. Retrieve the authentication email from your mobile device within 20 minutes. Select the Authenticate button (Android users) or email link (Android or iOS users) in the email to log in to New Relic. You will be redirected to the New Relic mobile app and logged in to your partner account. Troubleshoot email problems Here are some troubleshooting tips: If you cannot find the authentication message from New Relic in your mobile device's email in-box, check your Spam folder. If you miss the 20-minute deadline, sign in to the New Relic mobile app again, then select the link to resend the authentication email.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 208.87828,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>app</em> <em>authentication</em> for <em>New</em> <em>Relic</em> partners",
        "sections": "<em>Mobile</em> <em>app</em> <em>authentication</em> for <em>New</em> <em>Relic</em> partners",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>apps</em>",
        "body": " <em>New</em> <em>Relic</em> account. If you use an email address associated with a <em>New</em> <em>Relic</em> partner account when you first sign in to the <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em>, <em>New</em> <em>Relic</em> will send you a confirmation email for <em>authentication</em>. Android <em>app</em> users will also see a notification message. Important The <em>authentication</em> email"
      },
      "id": "604418de28ccbc28932c6071"
    }
  ],
  "/docs/mobile-apps/new-relic-mobile-apps/ios-app/install-new-relic-ios-mobile-app": [
    {
      "sections": [
        "Introduction to iOS mobile app",
        "Features",
        "Time range",
        "New Relic Synthetics",
        "Alerts",
        "Mobile monitoring",
        "Data privacy"
      ],
      "title": "Introduction to iOS mobile app",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic Mobile apps",
        "iOS app"
      ],
      "external_id": "371077582a50dfd2a1e7c57cfbbf9eeaf8013e1c",
      "image": "https://docs.newrelic.com/static/630c7a9a486540073ab96a2c9926e303/442cb/device-ios-synthetics-view-monitor.png",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/ios-app/introduction-ios-mobile-app/",
      "published_at": "2021-07-02T14:12:40Z",
      "updated_at": "2021-03-13T03:15:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The user interface for New Relic's iPhone and iPad app provides functionality similar to New Relic's standard user interface, with customized details for mobile users. The New Relic iOS apps show near real-time information about your apps, hosts, and more. Features New Relic's iOS app includes these New Relic products and features: New Relic's iOS app for iPhone and iPad includes these New Relic products and features: New Relic APM (iPhone and iPad). Includes real-time and historical data. Select the icon to see transaction details. Select Overview Charts to view summary charts of your top five transactions. New Relic Browser (iPhone and iPad). Provide overview dashboard, including average page load time, Browser Apdex, average throughput, and more. New Relic Infrastructure (iPhone only). New Relic Alerts (iPhone and iPad). Get alert and deployment notifications. New Relic Synthetics (iPhone only). New Relic Browser (iPhone and iPad). New Relic Mobile (iPhone and iPad). Includes crash reports, network errors, API calls, and active user count. New Relic Plugins (iPhone and iPad). New Relic's iOS app does not have all the features of the New Relic web application. For more detailed analysis, sign in to your New Relic account with a web browser. Time range When viewing an application or host, you can change the visible time frame by using the clock icon in the top right of the page. This feature is similar to the standard New Relic time picker. Features include: Scrub the New Relic charts to move back and forth across the timeline. Select the time picker to choose a time range that ends now (from 30 minutes to 90 days ago). For iPads: to specify an end time other than now, slide the toggle from Ending Now to Custom Date. New Relic Synthetics You can use the iOS app to view your New Relic Synthetics data, including charts of your monitor's availability, load times, and load sizes. Select the caret icon to view more detailed charts. You can mute or disable your monitor, and view details of any recent errors. For scripted monitors, you can view and search the script log. Alerts When you connect the iOS app to your New Relic account, your device is automatically associated with your user channel. Then, you can add your user channel to your target policy to receive alerts. For iOS alerts, notifications appear on your lock screen and can be viewed by swiping the alert. You can select any alert to view error details or acknowledge the alert. New Relic also sends a push notification when a colleague acknowledges an open event. Then, New Relic sends a final, closing notification when all Critical events end. Mobile monitoring If you have a mobile application and have installed New Relic Mobile, you can monitor its performance directly from your iPhone or iPad. New Relic Mobile monitoring includes network errors, API calls, and number of active users. You can also view detailed individual crash reports for a deeper understanding of a particular crash incident. Data privacy To make troubleshooting easier, New Relic's mobile apps only record the following information about you: User's email address associated with your New Relic account, including first and last name (for authentication purposes only) IP address Device ID For more information, see our Mobile data privacy and security documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.12268,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Introduction</em> to <em>iOS</em> <em>mobile</em> <em>app</em>",
        "sections": "<em>Introduction</em> to <em>iOS</em> <em>mobile</em> <em>app</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>apps</em>",
        "body": "The user interface for <em>New</em> <em>Relic</em>&#x27;s <em>i</em>Phone and <em>i</em>Pad <em>app</em> provides functionality similar to <em>New</em> <em>Relic</em>&#x27;s standard user interface, with customized details for <em>mobile</em> users. The <em>New</em> <em>Relic</em> <em>iOS</em> <em>apps</em> show near real-time information about your <em>apps</em>, hosts, and more. Features <em>New</em> <em>Relic</em>&#x27;s <em>iOS</em> <em>app</em> includes"
      },
      "id": "6044161628ccbc96b62c6092"
    },
    {
      "sections": [
        "Alerting with New Relic mobile apps",
        "Tip",
        "Requirements",
        "Turn notifications on or off",
        "View alert incident details",
        "Troubleshoot alert settings",
        "Check notification settings for your mobile device.",
        "Delete the Android or iOS device from your New Relic account.",
        "Uninstall the New Relic mobile app.",
        "Reinstall the New Relic mobile app."
      ],
      "title": "Alerting with New Relic mobile apps",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic Mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "d55850dc642cc8ade20310e1d4654db61af1e809",
      "image": "https://docs.newrelic.com/static/f942198cbd9a41b7355ef7f01fa6cc66/e5166/alerts-incident-detail-nexus.jpg",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/authentication-alerts/alerting-new-relic-mobile-apps/",
      "published_at": "2021-07-02T17:28:38Z",
      "updated_at": "2021-04-06T08:55:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Tip Owner or Admins Account administrators can set up configuration to receive push notifications on Android and iOS devices from New Relic Alerts. You can receive alerts from any policy by attaching a user channel to the policy. Requirements This feature is available only to users on the original user model, not to users on the New Relic One user model. As a workaround, you can use the email notification channel. Turn notifications on or off When you log in to your New Relic account from an Android or iOS app, your device is automatically associated with your user channel. Be sure to add the associated user channel to the alert policy. View alert incident details The notification automatically appears on your device's lock screen. To start the New Relic app: Android devices: Tap the notification from the notification drawer. OR iOS devices: Swipe the screen. From the New Relic app's Alerts menu, select any alert to view error details for the associated application. Optional: Select Acknowledge. Optional: To view additional details, select Overview, Violations, or Event log. The main menu's Alerts list shows alerts in the following order, sorted by time: Active incidents Resolved incidents from today Resolved incidents and events from the past week, organized by day Troubleshoot alert settings If alerts are not working on your mobile device: Verify that you meet the requirements. Verify that alerts are enabled. Check your mobile device's notification settings, to ensure New Relic is permitted to send alerts. If the notification settings for your mobile device are correct, but you still do not receive notifications, delete the device from your account, then uninstall and reinstall the New Relic application. Check notification settings for your mobile device. Follow the procedure for your mobile device. Device To check notification settings: Android From your Android device's Settings, select Sound and notification. Check the settings for sound volume. Optional: Enable Also vibrate for calls. Check the settings for Interruptions. Check the settings for Notification. Check the settings for App notifications: Select the New Relic app, then check the settings for Block and Priority. iOS Ensure Do Not Disturb is off: From the iOS Settings app, select Do Not Disturb, and check that the Manual switch is off. Ensure the New Relic app is allowed to send notifications: From the iOS Settings app, select Notifications, and locate the New Relic app from the app list. Ensure that the Allow Notifications switch is on. Ensure that the alert style is set to Banners or Alerts. Optional: To enable audio alerts, set Sounds to on. Delete the Android or iOS device from your New Relic account. To delete the mobile device from your New Relic account, use the public graphql api api.newrelic.com/graphiql in a web browser: Query current devices by selecting actor -> mobilePushNotification -> devices and selecting appVersion, deviceId, and deviceName. Run this query to get the list of devices. Mutate to remove a device by selecting mutation -> mobilePushNotificationRemoveDevice, and passing in the deviceId from the list above. Or you can remove the device from the in-app Settings option from the menu -> Settings Look under Push notification devices, and remove from there. On iOS, slide from right to left to Delete a device, on Android, tap Delete Continue with the steps to reinstall the New Relic app from your device. Uninstall the New Relic mobile app. Follow the procedure to uninstall the New Relic app from your device, then reinstall it. Device To uninstall the New Relic app: Android From your Android device's Settings, select Apps, then select the New Relic app. Select Uninstall. Continue with the steps to reinstall the New Relic app. iOS From your iOS home screen, tap and hold the New Relic icon until it shakes. To delete the app, select the X icon. Continue with the steps to reinstall the New Relic app. Reinstall the New Relic mobile app. To reinstall the New Relic mobile app: From your Android device, select Google Play Store. OR From your iOS device's home screen, select App Store. Search for New Relic. Download the app. When the download finishes, sign in to your New Relic mobile app with your New Relic account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.06883,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Alerting with <em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "sections": "Alerting with <em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>apps</em>",
        "body": " there. On <em>iOS</em>, slide from right to left to Delete a device, on Android, tap Delete Continue with the steps to reinstall the <em>New</em> <em>Relic</em> <em>app</em> from your device. Uninstall the <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em>. Follow the procedure to uninstall the <em>New</em> <em>Relic</em> <em>app</em> from your device, then reinstall it. Device To uninstall"
      },
      "id": "603e9efd64441f19a14e88ab"
    },
    {
      "sections": [
        "Mobile monitoring best practices guide",
        "1. Start collecting data",
        "How to do it",
        "Add your mobile app to New Relic",
        "Install and configure our mobile SDK",
        "2. Explore your data",
        "Analyze, resolve, and prevent crashes",
        "Monitor your key workflows",
        "Get actionable session data",
        "3. Take preventive steps",
        "Metric-based alerts",
        "Event-based alerts",
        "4. Dig deeper into crashes",
        "Crash analysis",
        "Breadcrumbs",
        "Custom attributes",
        "5. Focus on KPIs",
        "Track and query feature use",
        "Measure page load times",
        "Examine data about webpage interactions"
      ],
      "title": "Mobile monitoring best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Full-stack observability"
      ],
      "external_id": "32f5d3919c54c90173721a2cda556d8fd57744f1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/mobile-monitoring-best-practices-guide/",
      "published_at": "2021-07-02T20:13:14Z",
      "updated_at": "2021-07-02T20:13:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "By eliminating crashes and increasing speed across the stack, you can build better performance into every mobile app release. Here are some best practices to take full advantage of mobile monitoring with New Relic. 1. Start collecting data Start collecting data in production. You'll see immediate value by adding our mobile monitoring SDK to your app for its next release to the app store. We recommend installing the iOS or Android agent to your production release even if you're simply testing New Relic's capabilities. This will ensure you'll get an adequate amount of data to really understand all of our mobile monitoring capabilities and your end users' experience. How to do it Add your mobile app to New Relic First, add a new app in New Relic's user interface (full steps): Go to one.newrelic.com and click Mobile. From the list of monitored apps, select Add more. Select the relevant platform. Type a name for your mobile app, and select Continue. Use one app and the associated app token for the development releases of your iOS app, another app and its associated app token for the production releases of that iOS app, and another pair of app tokens for development and production releases of your Android app. You'll be able to compare data from across the four app tokens using our query builder. Install and configure our mobile SDK Next, install and configure the mobile agent: Download the latest version of New Relic's SDK for iOS or Android, and add it to your mobile app. (Full steps for iOS and Android) Configure your installation as needed. For example: Enable the feature flag to capture MobileRequest events to use our full network analysis capabilities for iOS or Android. Automate dSYM uploads for your production builds. To avoid surprises, follow the standard pattern of where you start our mobile agent. In addition, start our agent before you initiate any other SDKs. For more information, see our documentation for Android installation and configuration and for iOS installation and configuration. Deploy a new release of your application. 2. Explore your data Immediately be able to explore your data. As soon as New Relic starts reporting data, take the time to explore the wealth of information about your mobile apps. To get started, go to one.newrelic.com and select Mobile. How to do it Analyze, resolve, and prevent crashes Find the cause of crashes so you can fix them. Then, uncover trends behind crashes so you can prevent them: From the summary UI page for a monitored mobile app, click Crash analysis. Analyze crash data so you can see and fix the most impactful crashes. Follow the breadcrumbs in the crash event trail to fix crashes and resolve critical errors more easily: From your mobile app's Crash analysis page in the UI, select a Crash type. From the crash type's Summary page, select the Crash trail tab. For more information, see our blog post about crash analysis. Monitor your key workflows Create custom breadcrumbs to monitor key workflows (such as your app's login or checkout process), track user clicks, optimize timing, and identify crash locations for faster MTTR. Get actionable session data Borrow from our example queries to: See how much of your user base has upgraded to your latest app version. Track adoption over time. Get a count of new installs as compared to upgrades from an earlier version. See the distribution of usage across geographical locations, carriers, ASN owners (wi-fi providers), devices, connection types, and more. 3. Take preventive steps Use alert notifications to help uncover the causes behind crashes and errors. Once you are running our mobile monitoring capabilities in production and have explored some of the key features, you can use New Relic to uncover critical issues with your mobile application. In particular, focus on crashes and errors. Use metric-based alerts as a starting point to gain high-level visibility into problems. Then, as new services or functionalities are added, use New Relic’s more targeted, event-based (NRQL) alerts to make sure that the most critical issues are handled swiftly. Use these alerts to determine whether a crash is impacting a large number of users. If it is, the relevant people (for example, both the mobile app team’s on-call member and the owner of the related back-end service) will be alerted. Make sure that your team knows how to respond to changes in crash rate (crashes per sessions) and the percentage of users impacted by crashes of your mobile app. How to do it Metric-based alerts Leverage our metric-based alerts and New Relic Mobile UI. Ensure that key members of your mobile team have opted in to receive emails for new crashes. These emails will take you to the crash type in the Mobile UI page for your mobile app. Create an alert for your crash rate threshold that key members of your team can view in Slack or any other Alerts notification channel you choose. Your alert notification will include a link to our UI, where you can examine a chart with the exceeded threshold. From there, a link will take you to the relevant mobile monitoring page, where you can get additional details. Event-based alerts Combine the metric-based workflow with event-based alerts and dashboards specific to your mobile app and system. Create your NRQL alert that focuses on crashes of your most recently released production version. Create an additional NRQL alert that focuses on the percentage of users impacted by crashes in your latest app version (to check the overall impact on your user base). 4. Dig deeper into crashes Take your crash reporting to the next level. Now it’s time to tackle some of those harder-to-reproduce crashes by: Applying additional instrumentation to your application. Leveraging crash event trails, NRQL queries, and dashboards to visualize your data. How to do it Crash analysis Crashes are an inevitable part of running mobile applications at scale. We provide tools to help you understand your highest-impact crashes. Use the Crash analysis UI to see which crashes are occurring most often, the percentage of crash-free users, which files and methods are associated with perhaps 80 percent of your crashes, which crashes a particular user just experienced, and more. Go after high-impact crashes with crash analysis: Add custom attributes to categorize the highest-value customers, and then use them to segment crashes according to your most valuable audiences. Add breadcrumbs and custom events to produce a detailed trail of events leading up to every crash occurrence (over the last 90 days). Then, view this crash event trail in our mobile monitoring UI. Use our mobile monitoring's Versions trends page to make sure you’re improving the crash rate over subsequent releases and avoiding regressions. Breadcrumbs Use breadcrumbs and custom attributes to better reproduce and debug crashes. For example, use our recordBreadrumb API for Android or iOS to track mid-session changes in state that can help debug crashes, such as: Change of connection type Change of orientation CPU and memory state at key points in the app code Custom attributes Add custom attributes to existing events, so you can ask even more precise questions of your mobile app. Add dimensions such as: User ID: Use to react to specific user concerns and to better understand which customers and segments are most impacted. Store ID: Use to address problems with out-of-date devices, bad wi-fi, and so on. User segments: Use to better understand which customers and segments are most impacted; for example, logged in vs. non-logged in. Money in the cart at session end Origin or attribution of entry into the app Standardize custom attribute names across your mobile apps, and align with your website (if monitored by New Relic Browser), so that you can compare and contrast performance across end-user channels. New Relic Mobile tracks the last interaction of crashed and non-crashed sessions to provide visibility into what the user viewed before exiting your app (either intentionally or due to a crash). 5. Focus on KPIs Bring your key performance indicators to life. Create custom interactions and events to hone in on the most important signals, including user activity for the business-critical aspects of your app. Using these powerful APIs, you can add custom instrumentation to just about anything. The following are some example use cases. How to do it Track and query feature use Use custom events to track feature use. For example: Use custom events to track user flow between app and website. Use custom events or mobile breadcrumbs to optimize the performance of key user flows (log in, shopping cart, etc.). use custom events to provide faster, contextualized support experiences for your digital customers. Use the recordCustomEvent API. Then compare the use of different features using: SELECT count(*) FROM MyNewMobileEventType FACET name Copy Measure page load times Use custom events to measure page load time: Create an app-launch timer to measure the time that elapses between a user-tap to launch your app and the point in your app code where the first screen is available. Record the timer value in New Relic using something like the following: recordCustomEvent(<myMobileTimers>, <appLaunch>, {attributes}) Copy Define start and stop timers to measure spinner durations, and then record this time in New Relic using something like the following: recordCustomEvent(<myMobileTimers>, <spinnerOnScreenA>, {attributes}) Copy Track specific user actions or funnel steps in the app (like \"add to cart\"), and include the price as an attribute on that event. Measure flows through the application by viewing the related funnel steps with custom events in Insights. For example, create a timer to track the start and end times of a subflow or an entire flow across multiple funnel steps to understand how long it took users to get through the process. Examine data about webpage interactions Use custom interactions to see traces associated with the same webpages. Use the agent API to disable default interactions, and focus on custom interactions so that you can review the page loads that are most crucial to your primary funnel. Define the start and stop times of these custom interactions to trace activities associated with individual steps of that funnel (for example, a specific user action or a page load). Track the last interactions of crashed and non-crashed sessions so that you can see what the user viewed before exiting your app (either intentionally or from a crash). Example query for non-crashed sessions: SELECT count(*) FROM Mobile WHERE sessionCrashed is null FACET lastInteraction SINCE 90 days ago Copy Example query for crashed sessions: SELECT count(*) FROM Mobile WHERE sessionCrashed is true FACET lastInteraction SINCE 90 days ago Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.29904,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> monitoring best practices guide",
        "sections": "Add your <em>mobile</em> <em>app</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>New</em> <em>Relic</em> solutions",
        "body": " value by adding our <em>mobile</em> monitoring SDK to your <em>app</em> for its next release to the <em>app</em> store. We recommend installing the <em>iOS</em> or Android agent to your production release even if you&#x27;re simply testing <em>New</em> <em>Relic</em>&#x27;s capabilities. This will ensure you&#x27;ll get an adequate amount of data to really understand"
      },
      "id": "6044151e28ccbc19ab2c60d8"
    }
  ],
  "/docs/mobile-apps/new-relic-mobile-apps/ios-app/introduction-ios-mobile-app": [
    {
      "sections": [
        "Install the New Relic iOS mobile app",
        "Compatibility and requirements",
        "Installation"
      ],
      "title": "Install the New Relic iOS mobile app",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic Mobile apps",
        "iOS app"
      ],
      "external_id": "a33650792e7ba24040db9a65d8d7fbb25c341d18",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/ios-app/install-new-relic-ios-mobile-app/",
      "published_at": "2021-07-02T14:11:44Z",
      "updated_at": "2021-03-13T04:04:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This section provides information about compatibility and requirements, basic instructions on how to install and configure the New Relic iPhone and iPad apps, and links to more detailed information. Compatibility and requirements The New Relic iOS app allows you to view your New Relic applications, Infrastructure data, plugins you have installed from Plugin Central, key transactions, Synthetics monitors, and alerts from an Apple iPhone or iPad. Product requirements include: iOS 7 or higher iPhone users: iPhone 4S or higher iPad users: iPad 2 or higher You can also use an iPod touch, although resolution may be different. Installation You can install the New Relic app from the App Store or learn more from the New Relic website. Follow standard procedures to install any iOS app, and then sign in with your New Relic user name (account email) and password if applicable. Depending on your New Relic account, additional installation or authentication steps may be required. For more information, see User settings and authentication.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.15707,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>New</em> <em>Relic</em> <em>iOS</em> <em>mobile</em> <em>app</em>",
        "sections": "<em>Install</em> the <em>New</em> <em>Relic</em> <em>iOS</em> <em>mobile</em> <em>app</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>apps</em>",
        "body": "This section provides information about compatibility and requirements, basic instructions on how to install and configure the <em>New</em> <em>Relic</em> <em>i</em>Phone and <em>i</em>Pad <em>apps</em>, and links to more detailed information. Compatibility and requirements The <em>New</em> <em>Relic</em> <em>iOS</em> <em>app</em> allows you to view your <em>New</em> <em>Relic</em> applications"
      },
      "id": "60441616196a67b070960f2b"
    },
    {
      "sections": [
        "Alerting with New Relic mobile apps",
        "Tip",
        "Requirements",
        "Turn notifications on or off",
        "View alert incident details",
        "Troubleshoot alert settings",
        "Check notification settings for your mobile device.",
        "Delete the Android or iOS device from your New Relic account.",
        "Uninstall the New Relic mobile app.",
        "Reinstall the New Relic mobile app."
      ],
      "title": "Alerting with New Relic mobile apps",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic Mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "d55850dc642cc8ade20310e1d4654db61af1e809",
      "image": "https://docs.newrelic.com/static/f942198cbd9a41b7355ef7f01fa6cc66/e5166/alerts-incident-detail-nexus.jpg",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/authentication-alerts/alerting-new-relic-mobile-apps/",
      "published_at": "2021-07-02T17:28:38Z",
      "updated_at": "2021-04-06T08:55:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Tip Owner or Admins Account administrators can set up configuration to receive push notifications on Android and iOS devices from New Relic Alerts. You can receive alerts from any policy by attaching a user channel to the policy. Requirements This feature is available only to users on the original user model, not to users on the New Relic One user model. As a workaround, you can use the email notification channel. Turn notifications on or off When you log in to your New Relic account from an Android or iOS app, your device is automatically associated with your user channel. Be sure to add the associated user channel to the alert policy. View alert incident details The notification automatically appears on your device's lock screen. To start the New Relic app: Android devices: Tap the notification from the notification drawer. OR iOS devices: Swipe the screen. From the New Relic app's Alerts menu, select any alert to view error details for the associated application. Optional: Select Acknowledge. Optional: To view additional details, select Overview, Violations, or Event log. The main menu's Alerts list shows alerts in the following order, sorted by time: Active incidents Resolved incidents from today Resolved incidents and events from the past week, organized by day Troubleshoot alert settings If alerts are not working on your mobile device: Verify that you meet the requirements. Verify that alerts are enabled. Check your mobile device's notification settings, to ensure New Relic is permitted to send alerts. If the notification settings for your mobile device are correct, but you still do not receive notifications, delete the device from your account, then uninstall and reinstall the New Relic application. Check notification settings for your mobile device. Follow the procedure for your mobile device. Device To check notification settings: Android From your Android device's Settings, select Sound and notification. Check the settings for sound volume. Optional: Enable Also vibrate for calls. Check the settings for Interruptions. Check the settings for Notification. Check the settings for App notifications: Select the New Relic app, then check the settings for Block and Priority. iOS Ensure Do Not Disturb is off: From the iOS Settings app, select Do Not Disturb, and check that the Manual switch is off. Ensure the New Relic app is allowed to send notifications: From the iOS Settings app, select Notifications, and locate the New Relic app from the app list. Ensure that the Allow Notifications switch is on. Ensure that the alert style is set to Banners or Alerts. Optional: To enable audio alerts, set Sounds to on. Delete the Android or iOS device from your New Relic account. To delete the mobile device from your New Relic account, use the public graphql api api.newrelic.com/graphiql in a web browser: Query current devices by selecting actor -> mobilePushNotification -> devices and selecting appVersion, deviceId, and deviceName. Run this query to get the list of devices. Mutate to remove a device by selecting mutation -> mobilePushNotificationRemoveDevice, and passing in the deviceId from the list above. Or you can remove the device from the in-app Settings option from the menu -> Settings Look under Push notification devices, and remove from there. On iOS, slide from right to left to Delete a device, on Android, tap Delete Continue with the steps to reinstall the New Relic app from your device. Uninstall the New Relic mobile app. Follow the procedure to uninstall the New Relic app from your device, then reinstall it. Device To uninstall the New Relic app: Android From your Android device's Settings, select Apps, then select the New Relic app. Select Uninstall. Continue with the steps to reinstall the New Relic app. iOS From your iOS home screen, tap and hold the New Relic icon until it shakes. To delete the app, select the X icon. Continue with the steps to reinstall the New Relic app. Reinstall the New Relic mobile app. To reinstall the New Relic mobile app: From your Android device, select Google Play Store. OR From your iOS device's home screen, select App Store. Search for New Relic. Download the app. When the download finishes, sign in to your New Relic mobile app with your New Relic account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.06883,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Alerting with <em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "sections": "Alerting with <em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>apps</em>",
        "body": " there. On <em>iOS</em>, slide from right to left to Delete a device, on Android, tap Delete Continue with the steps to reinstall the <em>New</em> <em>Relic</em> <em>app</em> from your device. Uninstall the <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em>. Follow the procedure to uninstall the <em>New</em> <em>Relic</em> <em>app</em> from your device, then reinstall it. Device To uninstall"
      },
      "id": "603e9efd64441f19a14e88ab"
    },
    {
      "sections": [
        "Mobile monitoring best practices guide",
        "1. Start collecting data",
        "How to do it",
        "Add your mobile app to New Relic",
        "Install and configure our mobile SDK",
        "2. Explore your data",
        "Analyze, resolve, and prevent crashes",
        "Monitor your key workflows",
        "Get actionable session data",
        "3. Take preventive steps",
        "Metric-based alerts",
        "Event-based alerts",
        "4. Dig deeper into crashes",
        "Crash analysis",
        "Breadcrumbs",
        "Custom attributes",
        "5. Focus on KPIs",
        "Track and query feature use",
        "Measure page load times",
        "Examine data about webpage interactions"
      ],
      "title": "Mobile monitoring best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Full-stack observability"
      ],
      "external_id": "32f5d3919c54c90173721a2cda556d8fd57744f1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/mobile-monitoring-best-practices-guide/",
      "published_at": "2021-07-02T20:13:14Z",
      "updated_at": "2021-07-02T20:13:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "By eliminating crashes and increasing speed across the stack, you can build better performance into every mobile app release. Here are some best practices to take full advantage of mobile monitoring with New Relic. 1. Start collecting data Start collecting data in production. You'll see immediate value by adding our mobile monitoring SDK to your app for its next release to the app store. We recommend installing the iOS or Android agent to your production release even if you're simply testing New Relic's capabilities. This will ensure you'll get an adequate amount of data to really understand all of our mobile monitoring capabilities and your end users' experience. How to do it Add your mobile app to New Relic First, add a new app in New Relic's user interface (full steps): Go to one.newrelic.com and click Mobile. From the list of monitored apps, select Add more. Select the relevant platform. Type a name for your mobile app, and select Continue. Use one app and the associated app token for the development releases of your iOS app, another app and its associated app token for the production releases of that iOS app, and another pair of app tokens for development and production releases of your Android app. You'll be able to compare data from across the four app tokens using our query builder. Install and configure our mobile SDK Next, install and configure the mobile agent: Download the latest version of New Relic's SDK for iOS or Android, and add it to your mobile app. (Full steps for iOS and Android) Configure your installation as needed. For example: Enable the feature flag to capture MobileRequest events to use our full network analysis capabilities for iOS or Android. Automate dSYM uploads for your production builds. To avoid surprises, follow the standard pattern of where you start our mobile agent. In addition, start our agent before you initiate any other SDKs. For more information, see our documentation for Android installation and configuration and for iOS installation and configuration. Deploy a new release of your application. 2. Explore your data Immediately be able to explore your data. As soon as New Relic starts reporting data, take the time to explore the wealth of information about your mobile apps. To get started, go to one.newrelic.com and select Mobile. How to do it Analyze, resolve, and prevent crashes Find the cause of crashes so you can fix them. Then, uncover trends behind crashes so you can prevent them: From the summary UI page for a monitored mobile app, click Crash analysis. Analyze crash data so you can see and fix the most impactful crashes. Follow the breadcrumbs in the crash event trail to fix crashes and resolve critical errors more easily: From your mobile app's Crash analysis page in the UI, select a Crash type. From the crash type's Summary page, select the Crash trail tab. For more information, see our blog post about crash analysis. Monitor your key workflows Create custom breadcrumbs to monitor key workflows (such as your app's login or checkout process), track user clicks, optimize timing, and identify crash locations for faster MTTR. Get actionable session data Borrow from our example queries to: See how much of your user base has upgraded to your latest app version. Track adoption over time. Get a count of new installs as compared to upgrades from an earlier version. See the distribution of usage across geographical locations, carriers, ASN owners (wi-fi providers), devices, connection types, and more. 3. Take preventive steps Use alert notifications to help uncover the causes behind crashes and errors. Once you are running our mobile monitoring capabilities in production and have explored some of the key features, you can use New Relic to uncover critical issues with your mobile application. In particular, focus on crashes and errors. Use metric-based alerts as a starting point to gain high-level visibility into problems. Then, as new services or functionalities are added, use New Relic’s more targeted, event-based (NRQL) alerts to make sure that the most critical issues are handled swiftly. Use these alerts to determine whether a crash is impacting a large number of users. If it is, the relevant people (for example, both the mobile app team’s on-call member and the owner of the related back-end service) will be alerted. Make sure that your team knows how to respond to changes in crash rate (crashes per sessions) and the percentage of users impacted by crashes of your mobile app. How to do it Metric-based alerts Leverage our metric-based alerts and New Relic Mobile UI. Ensure that key members of your mobile team have opted in to receive emails for new crashes. These emails will take you to the crash type in the Mobile UI page for your mobile app. Create an alert for your crash rate threshold that key members of your team can view in Slack or any other Alerts notification channel you choose. Your alert notification will include a link to our UI, where you can examine a chart with the exceeded threshold. From there, a link will take you to the relevant mobile monitoring page, where you can get additional details. Event-based alerts Combine the metric-based workflow with event-based alerts and dashboards specific to your mobile app and system. Create your NRQL alert that focuses on crashes of your most recently released production version. Create an additional NRQL alert that focuses on the percentage of users impacted by crashes in your latest app version (to check the overall impact on your user base). 4. Dig deeper into crashes Take your crash reporting to the next level. Now it’s time to tackle some of those harder-to-reproduce crashes by: Applying additional instrumentation to your application. Leveraging crash event trails, NRQL queries, and dashboards to visualize your data. How to do it Crash analysis Crashes are an inevitable part of running mobile applications at scale. We provide tools to help you understand your highest-impact crashes. Use the Crash analysis UI to see which crashes are occurring most often, the percentage of crash-free users, which files and methods are associated with perhaps 80 percent of your crashes, which crashes a particular user just experienced, and more. Go after high-impact crashes with crash analysis: Add custom attributes to categorize the highest-value customers, and then use them to segment crashes according to your most valuable audiences. Add breadcrumbs and custom events to produce a detailed trail of events leading up to every crash occurrence (over the last 90 days). Then, view this crash event trail in our mobile monitoring UI. Use our mobile monitoring's Versions trends page to make sure you’re improving the crash rate over subsequent releases and avoiding regressions. Breadcrumbs Use breadcrumbs and custom attributes to better reproduce and debug crashes. For example, use our recordBreadrumb API for Android or iOS to track mid-session changes in state that can help debug crashes, such as: Change of connection type Change of orientation CPU and memory state at key points in the app code Custom attributes Add custom attributes to existing events, so you can ask even more precise questions of your mobile app. Add dimensions such as: User ID: Use to react to specific user concerns and to better understand which customers and segments are most impacted. Store ID: Use to address problems with out-of-date devices, bad wi-fi, and so on. User segments: Use to better understand which customers and segments are most impacted; for example, logged in vs. non-logged in. Money in the cart at session end Origin or attribution of entry into the app Standardize custom attribute names across your mobile apps, and align with your website (if monitored by New Relic Browser), so that you can compare and contrast performance across end-user channels. New Relic Mobile tracks the last interaction of crashed and non-crashed sessions to provide visibility into what the user viewed before exiting your app (either intentionally or due to a crash). 5. Focus on KPIs Bring your key performance indicators to life. Create custom interactions and events to hone in on the most important signals, including user activity for the business-critical aspects of your app. Using these powerful APIs, you can add custom instrumentation to just about anything. The following are some example use cases. How to do it Track and query feature use Use custom events to track feature use. For example: Use custom events to track user flow between app and website. Use custom events or mobile breadcrumbs to optimize the performance of key user flows (log in, shopping cart, etc.). use custom events to provide faster, contextualized support experiences for your digital customers. Use the recordCustomEvent API. Then compare the use of different features using: SELECT count(*) FROM MyNewMobileEventType FACET name Copy Measure page load times Use custom events to measure page load time: Create an app-launch timer to measure the time that elapses between a user-tap to launch your app and the point in your app code where the first screen is available. Record the timer value in New Relic using something like the following: recordCustomEvent(<myMobileTimers>, <appLaunch>, {attributes}) Copy Define start and stop timers to measure spinner durations, and then record this time in New Relic using something like the following: recordCustomEvent(<myMobileTimers>, <spinnerOnScreenA>, {attributes}) Copy Track specific user actions or funnel steps in the app (like \"add to cart\"), and include the price as an attribute on that event. Measure flows through the application by viewing the related funnel steps with custom events in Insights. For example, create a timer to track the start and end times of a subflow or an entire flow across multiple funnel steps to understand how long it took users to get through the process. Examine data about webpage interactions Use custom interactions to see traces associated with the same webpages. Use the agent API to disable default interactions, and focus on custom interactions so that you can review the page loads that are most crucial to your primary funnel. Define the start and stop times of these custom interactions to trace activities associated with individual steps of that funnel (for example, a specific user action or a page load). Track the last interactions of crashed and non-crashed sessions so that you can see what the user viewed before exiting your app (either intentionally or from a crash). Example query for non-crashed sessions: SELECT count(*) FROM Mobile WHERE sessionCrashed is null FACET lastInteraction SINCE 90 days ago Copy Example query for crashed sessions: SELECT count(*) FROM Mobile WHERE sessionCrashed is true FACET lastInteraction SINCE 90 days ago Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.29904,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> monitoring best practices guide",
        "sections": "Add your <em>mobile</em> <em>app</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>New</em> <em>Relic</em> solutions",
        "body": " value by adding our <em>mobile</em> monitoring SDK to your <em>app</em> for its next release to the <em>app</em> store. We recommend installing the <em>iOS</em> or Android agent to your production release even if you&#x27;re simply testing <em>New</em> <em>Relic</em>&#x27;s capabilities. This will ensure you&#x27;ll get an adequate amount of data to really understand"
      },
      "id": "6044151e28ccbc19ab2c60d8"
    }
  ],
  "/docs/mobile-apps/new-relic-mobile-apps/tvos-app/introduction-apple-tv-app": [
    {
      "sections": [
        "User settings and authentication",
        "User authentication",
        "User settings",
        "Sign in with additional username",
        "Switch between accounts",
        "Remove or re-add a user name"
      ],
      "title": "User settings and authentication",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic Mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "0b40ac4c2e769279d25d0ebb2ea77cebda8d8ea7",
      "image": "https://docs.newrelic.com/static/88ff328efc4a127601923bc728fea229/8c557/device-ipad-switch-user.png",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/authentication-alerts/user-settings-authentication/",
      "published_at": "2021-07-02T14:11:49Z",
      "updated_at": "2021-05-16T06:27:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This explains how to authenticate your New Relic mobile app account, and how to add users to or remove them from your mobile device. User authentication Depending on your New Relic account, additional installation or authentication steps may be required when you install the New Relic mobile app. New Relic account Additional requirements New users If you do not already have a New Relic account: From your desktop web browser, create a New Relic account. Install your application with the appropriate New Relic agent. As part of new account setup, you will receive an email with a password reset link. The password reset link expires after 20 minutes for mobile apps. Existing New Relic users No additional requirements; your applications, hosts, installed plugins, and key transactions automatically appear after you sign in. Users with New Relic partner accounts Depending on the partner, you may need to complete a different authentication process. Azure Store users: Due to the deep integration between Azure Storefront and New Relic, Azure Storefront users cannot access their accounts on the New Relic Android or iOS apps. Users with SAML-SSO enabled accounts When you sign in to the New Relic mobile app, your session automatically redirects to your web browser. From there you can sign in to your New Relic SAML-SSO account. If you see any errors when using SAML-SSO accounts on your mobile device, verify that you are able to sign in to one.newrelic.com with a desktop web browser. If no, contact your administrator. If yes, get support at support.newrelic.com. User settings After you sign in, all New Relic accounts and applications associated with the user appear automatically. Sign in with additional username Follow the procedure for your mobile device. Mobile device To sign in to the app with an additional user name: Android To switch users: Log out from the Android device: Main menu > (selected username) > Logout > Confirm. Log in with a new account. iPhone From the app menu, select your account name, then select the Users menu. From the Users menu, select the plus icon. Sign in with the additional username. iPad To access the Users menu: Select the user icon or slide right. From the Users menu, select the plus icon. Sign in with the additional username. Switch between accounts To switch between accounts associated with your username: From the Users menu, select the user name. Select the account name. Remove or re-add a user name To remove a specific username from this device: From the Users menu, select Logout. To remove a user from this device, select the user's red minus icon. Select the user's Log out icon. To add a user again, sign in with that username again. Select the user icon or slide right to show the New Relic iPad app's Users menu.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 139.7616,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>apps</em>",
        "body": "This explains how to authenticate your <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em> account, and how to add users to or remove them from your <em>mobile</em> device. User authentication Depending on your <em>New</em> <em>Relic</em> account, additional installation or authentication steps may be required when you install the <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em>"
      },
      "id": "604415a728ccbc8fb52c6068"
    },
    {
      "sections": [
        "Troubleshoot SSO accounts using mobile devices",
        "No user name or password",
        "Errors after signing in",
        "Reauthentication problems"
      ],
      "title": "Troubleshoot SSO accounts using mobile devices",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic Mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "9ebb373182ce5fea83ba5a6baa03b2c7bccf0174",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/authentication-alerts/troubleshoot-sso-accounts-using-mobile-devices/",
      "published_at": "2021-07-02T14:12:40Z",
      "updated_at": "2021-05-16T06:23:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Typically when you sign in to the New Relic mobile app, your session redirects automatically to your web browser. From there you can sign in to your New Relic account. Here are troubleshooting tips if you have problems using the New Relic mobile app with your SAML-SSO enabled account. No user name or password You may not have a user name or password for New Relic because some SAML providers will overwrite your password, or because your administrator has not sent you this information. In these situations: From the mobile app's Log in, select the I don't have a password link. Use your mobile device to open your email account. From your email account, retrieve the New Relic authentication email within 20 minutes. Select the Authenticate button or the link below it in the email. Errors after signing in If you see any errors after successfully signing in to your SSO provider with your mobile device, verify that you are able to sign in to one.newrelic.com with a desktop web browser. If no, contact your administrator. If yes, get support at support.newrelic.com. Reauthentication problems If you are using reauthentication on a SAML-SSO account, you must log in to your default account. (All other accounts will be grayed out.) If you attempt to switch to a grayed-out account, an error message will appear, explaining this is currently not supported.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 139.76064,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot SSO accounts using <em>mobile</em> devices",
        "sections": "Troubleshoot SSO accounts using <em>mobile</em> devices",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>apps</em>",
        "body": "Typically when you sign in to the <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em>, your session redirects automatically to your web browser. From there you can sign in to your <em>New</em> <em>Relic</em> account. Here are troubleshooting tips if you have problems using the <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em> with your SAML-SSO enabled account. No user name"
      },
      "id": "604415e0196a67fc3f960f42"
    },
    {
      "sections": [
        "Install the New Relic iOS mobile app",
        "Compatibility and requirements",
        "Installation"
      ],
      "title": "Install the New Relic iOS mobile app",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic Mobile apps",
        "iOS app"
      ],
      "external_id": "a33650792e7ba24040db9a65d8d7fbb25c341d18",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/ios-app/install-new-relic-ios-mobile-app/",
      "published_at": "2021-07-02T14:11:44Z",
      "updated_at": "2021-03-13T04:04:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This section provides information about compatibility and requirements, basic instructions on how to install and configure the New Relic iPhone and iPad apps, and links to more detailed information. Compatibility and requirements The New Relic iOS app allows you to view your New Relic applications, Infrastructure data, plugins you have installed from Plugin Central, key transactions, Synthetics monitors, and alerts from an Apple iPhone or iPad. Product requirements include: iOS 7 or higher iPhone users: iPhone 4S or higher iPad users: iPad 2 or higher You can also use an iPod touch, although resolution may be different. Installation You can install the New Relic app from the App Store or learn more from the New Relic website. Follow standard procedures to install any iOS app, and then sign in with your New Relic user name (account email) and password if applicable. Depending on your New Relic account, additional installation or authentication steps may be required. For more information, see User settings and authentication.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.3404,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install the <em>New</em> <em>Relic</em> iOS <em>mobile</em> <em>app</em>",
        "sections": "Install the <em>New</em> <em>Relic</em> iOS <em>mobile</em> <em>app</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>apps</em>",
        "body": "This section provides information about compatibility and requirements, basic instructions on how to install and configure the <em>New</em> <em>Relic</em> iPhone and iPad <em>apps</em>, and links to more detailed information. Compatibility and requirements The <em>New</em> <em>Relic</em> iOS <em>app</em> allows you to view your <em>New</em> <em>Relic</em> applications"
      },
      "id": "60441616196a67b070960f2b"
    }
  ],
  "/docs/mobile-crash-rest-api-v1": [
    {
      "sections": [
        "Working with the New Relic REST API (v1) (deprecated)",
        "Important"
      ],
      "title": "Working with the New Relic REST API (v1) (deprecated)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v1 deprecated",
        "New Relic REST API v1"
      ],
      "external_id": "9cb0f38eb95a8757624ddb63298ff9a32e1176e7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v1-deprecated/new-relic-rest-api-v1/working-new-relic-rest-api-v1-deprecated/",
      "published_at": "2021-07-02T08:44:29Z",
      "updated_at": "2021-03-13T02:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Currently New Relic supports two versions of the REST API. Version 1 is deprecated and has been replaced with the newer v2. No termination date has been announced. However, no further development or modifications are being made to v1. Important Start new projects by referring to Getting started with API v2 and the New Relic REST API v2 examples. Also, begin migrating your v1 scripts to their v2 equivalent. To use the REST API v1 in any way, your API key is required. Then, from the command line, you can use: curl -gH \"x-api-key:REPLACE_WITH_YOUR_API_KEY\" 'ENDPOINT_URL' Copy OR wget -qO- --header \"x-api-key:REPLACE_WITH_YOUR_API_KEY\" 'ENDPOINT_URL' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 377.20407,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Working with the New Relic <em>REST</em> <em>API</em> (<em>v1</em>) (deprecated)",
        "sections": "Working with the New Relic <em>REST</em> <em>API</em> (<em>v1</em>) (deprecated)",
        "tags": "<em>REST</em> <em>API</em> <em>v1</em> deprecated",
        "body": "Currently New Relic supports two versions of the <em>REST</em> <em>API</em>. Version <em>1</em> is deprecated and has been replaced with the newer <em>v</em>2. No termination date has been announced. However, no further development or modifications are being made to <em>v1</em>. Important Start new projects by referring to Getting started"
      },
      "id": "6043ff97e7b9d20358579a0d"
    },
    {
      "sections": [
        "Our EU and US region data centers",
        "Requirements",
        "Regions and availability",
        "Regions and account hierarchy",
        "Hierarchy example for partnership accounts",
        "Create an EU region account",
        "API endpoints for EU region accounts",
        "Access New Relic One",
        "Billing and pricing",
        "Operational access and processing",
        "Verify your account is based in EU region"
      ],
      "title": "Our EU and US region data centers",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Welcome to New Relic",
        "Get started"
      ],
      "external_id": "38baae8599707418dbb5d42e05001e202b1bd28c",
      "image": "https://docs.newrelic.com/static/45e4547efe0b69d68711fc9786383ab1/c1b63/Eu_account_hierarchy.png",
      "url": "https://docs.newrelic.com/docs/using-new-relic/welcome-new-relic/get-started/our-eu-us-region-data-centers/",
      "published_at": "2021-07-02T11:34:30Z",
      "updated_at": "2021-07-02T11:34:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's global data hosting structure consists of two regions: the European Union (EU) region and the United States (US) region. Selecting your preferred region during the account setup process allows you to specify the region where your performance monitoring data will be hosted. You can also create accounts in each region. Requirements Access to the New Relic EU region requires the latest agent version. For new customers: Install the most recent agent version. For existing customers: Update to the most recent agent version. Minimum agent version required: C SDK 1.0.0 or higher Go 2.0.0 or higher Java 4.0.0 or higher .NET 8.0.0 or higher Node.js 3.0.0 or higher PHP 8.0.0.204 or higher Python 3.0.0.89 or higher Ruby 5.0.0.342 or higher Regions and availability Your choice of data center is not limited by your geographic location. You can choose to create an account with data hosted in either the EU or US region, regardless of where you or your systems reside. You can also create accounts in each region. New Relic offers almost all the same active products, features, support offerings, and performance levels in the EU region as what is offered in the US region. Exceptions: The following are not supported with an EU region account: Infinite Tracing is not available. APM's weekly performance reports are not available. The Plugins product is unavailable and is not supported. Errors inbox is not available. Log patterns Deprecated products and features are not available. New Relic's Incident Intelligence service operates solely in the U.S. Whether you store your data in New Relic’s US region data center or New Relic’s EU region data center, by using New Relic Incident Intelligence, you consent that New Relic may move your data to, and process your data in, the US region. Regions and account hierarchy You can create accounts in each region. If your data is currently being hosted in the US region, you must create a new account to store data in the EU region. You cannot view EU data from a US account, or US data from an EU account. The data collected remains separate. The data cannot be aggregated or migrated between accounts. For organizations that have a parent/child account structure, you can only have one parent account. For more, see Manage apps or users with child accounts. For partnership accounts, no changes to the partnership owner account are required. However, data cannot be shared across regions, so a partnership requires a parent account for each region. Hierarchy example for partnership accounts With partnership accounts, a new parent account must be created for any data to be host in the EU region. This hierarchy illustrates how global accounts are structured with partnership owner accounts. Data is not aggregated beyond the parent account. Example hierarchy for partnership organizations. Because data cannot be shared across regions, a partnership will require a parent account for each region. Create an EU region account To create a New Relic account in the EU region: Go to the New Relic signup page. OR If you have a specific offer from a New Relic partner, follow that link directly. Follow the online steps to create your account. From the Select your region dropdown, select European Union. Agree to the Terms of Service. When you receive an email confirmation message, select the link to confirm your account and sign in to New Relic. Then install or update to the most recent agent version. API endpoints for EU region accounts If you have an EU region account, use the appropriate endpoints to access the following New Relic APIs: API EU endpoint Browser source maps API sourcemaps.service. eu .newrelic.com Copy Infrastructure Alert API infra-api. eu .newrelic.com Copy Dashboard API rpm. eu .newrelic.com/api/explore/dashboards/list Copy Insert API insights-collector. eu01 .nr-data.net Copy Insights Query API insights-api. eu .newrelic.com Copy Mobile apps rpm. eu .newrelic.com/mobile Copy NerdGraph GraphiQL API api. eu .newrelic.com/graphiql Copy Partner API The partner API is a global API with no regional data differences. Use this endpoint for both EU and US accounts: rpm.newrelic.com/api/v2/partners/ Copy REST API api. eu .newrelic.com Copy Synthetics API synthetics. eu .newrelic.com/synthetics/api Copy Trace API trace-api. eu .newrelic.com/trace/v1 Copy Metric API metric-api. eu .newrelic.com/metric/v1 Copy Log API log-api. eu .newrelic.com/log/v1 Copy Access New Relic One If your accounts report data to the EU data center, use the following link to go to New Relic One: one.eu.newrelic.com. Billing and pricing New Relic's account billing process and pricing options are the same for both the EU and US regions. Operational access and processing Customer Data is hosted in the region selected during account creation. Systems Operations Data is stored in the US region. All other information, including account information (such as license subscription information, billing, and internal monitoring) is hosted in the US region and replicated in the EU region. New Relic may access and process Customer Data in the United States and such other jurisdictions where New Relic has affiliates and subsidiaries, including as may be necessary to maintain, secure, or perform the services, to provide technical support, or as necessary to comply with law or a binding order of a government body. Customer Data from existing New Relic accounts cannot be transferred or shared across regions, and new data generated cannot be shared with existing accounts, even in partnership accounts. Verify your account is based in EU region Use either of these options to verify whether your account data is hosted in the EU region's data center: In APM, mouse over the application name to view the URL. If it begins with rpm.eu.newrelic.com/, it is an EU-based account. Check your New Relic license key. If it begins with EU, it is an EU-based account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 293.12024,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>API</em> endpoints for EU region accounts",
        "body": ". eu .newrelic.com Copy <em>Mobile</em> apps rpm. eu .newrelic.com&#x2F;<em>mobile</em> Copy NerdGraph GraphiQL <em>API</em> <em>api</em>. eu .newrelic.com&#x2F;graphiql Copy Partner <em>API</em> The partner <em>API</em> is a global <em>API</em> with no regional data differences. Use this endpoint for both EU and US accounts: rpm.newrelic.com&#x2F;<em>api</em>&#x2F;<em>v</em>2&#x2F;partners&#x2F; Copy <em>REST</em> <em>API</em>"
      },
      "id": "6044586c64441f844b378edd"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-07-02T01:22:28Z",
      "updated_at": "2021-06-20T22:24:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and errorBeacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Note: You only need to modify the beacon and errorBeacon properties in the NREUM.info object. These values will override the default values found in the NR loader script. Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 260.28625,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Mobile</em> agents",
        "body": "), replace the https:&#x2F;&#x2F;trace-<em>api</em>.newrelic.com&#x2F;trace&#x2F;<em>v1</em> endpoint with https:&#x2F;&#x2F;gov-trace-<em>api</em>.newrelic.com&#x2F;trace&#x2F;<em>v1</em>. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and <em>mobile</em> agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant."
      },
      "id": "603e945164441f64384e8872"
    }
  ],
  "/docs/mobile-monitoring/index": [
    {
      "sections": [
        "Find Build UUIDs for unsymbolicated crashes",
        "View the Build UUID",
        "Binary images example",
        "Find and resymbolicate the dSYM",
        "For more help"
      ],
      "title": "Find Build UUIDs for unsymbolicated crashes",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "e8b926653583d66810c0f68eb6b0111ab3bfc477",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/find-build-uuids-unsymbolicated-crashes/",
      "published_at": "2021-07-02T14:14:31Z",
      "updated_at": "2021-07-02T14:14:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If the dSYM is not uploaded to New Relic, mobile crash reports cannot be symbolicated. You can upload dSYMs manually or directly through the New Relic UI. However, every build of an application will create a new dSYM, and it can be difficult managing which dSYM is attributed to which app build. In this situation, you can use the Build UUID identifier to: Identify a unique build of an application. Find which dSYM can be used to symbolicate a crash. View the Build UUID An application may have more than one Build UUID, one attributed for each CPU architecture the application is built. The Build UUID is also stored within the associated dSYM and can be extracted to identify the dSYM. New Relic crash reports also contain the Build UUID of the crashing application. To view the Build UUID: Go to one.newrelic.com and click Mobile in the top nav. Then find your app and click Crashes > Crash Analysis. From the Crash list table, select any row. From the selected crash report's Crash Details page, look for the App Image Uuid on the attribute list. If the App Image Uuid is not on the selected crash report's attributes list: Export the crash details. Look for the Build UUID in the Binary images section of the exported crash report. Use the Build UUID extracted from the crash details to find the missing dSYM. Binary images example Here is an example of the Binary images section from an exported crash report. This section lists the Build UUID for every dynamically-linked library included in the application, as well as the Build UUID for the main application. In this example, the main application is New Relic. Its Build UUID is 117667e7b8d230cb8a908906c64e0227. This is the identifier you can use to find the associated dSYM. Binary Images: 0xb1000 - 0x30d000 New Relic armv7 < 117667e7b8d230cb8a908906c64e0227 > /var/containers/Bundle/Application/New Relic.app/New Relic 0x22290000 - 0x22292000 libSystem.B.dylib armv7 <39d6d6f7c2ac3de8bb29c40a1b66368a> /usr/lib/libSystem.B.dylib 0x22292000 - 0x222de000 libc++.1.dylib armv7 <017dba6c16b63f9ebecb9ddd0d0a4520> /usr/lib/libc++.1.dylib 0x222de000 - 0x222f9000 libc++abi.dylib armv7 <d32373f6c2153a509f6603750d213ffb> /usr/lib/libc++abi.dylib 0x222fc000 - 0x22667000 libobjc.A.dylib armv7 <94f6d325c1843f45b3a439b86fc9de15> /usr/lib/libobjc.A.dylib 0x22667000 - 0x2266c000 libcache.dylib armv7 <8009f99fb892331dbcb61cd740ff0f43> /usr/lib/system/libcache.dylib 0x2266c000 - 0x22676000 libcommonCrypto.dylib armv7 <f6db318471d732d39918ef36bde65cb7> /usr/lib/system/libcommonCrypto.dylib 0x22676000 - 0x2267c000 libcompiler_rt.dylib armv7 <cfa3ca12d6c2383abcaf3c8541e9b86c> /usr/lib/system/libcompiler_rt.dylib 0x2267c000 - 0x22683000 libcopyfile.dylib armv7 <d2b06020c3693c7b9d179434f8115ba0> /usr/lib/system/libcopyfile.dylib 0x22683000 - 0x226d3000 libcorecrypto.dylib armv7 <181437f8d9e53277ace439de8b3fd1ad> /usr/lib/system/libcorecrypto.dylib 0x226d3000 - 0x2271d000 libdispatch.dylib armv7 <bbb4bba2176039ab95a59d7a56f6eff8> /usr/lib/system/libdispatch.dylib Copy Find and resymbolicate the dSYM To find a dSYM's Build UUID of a dSYM: use dwarfdump with the following terminal command: dwarfdump --uuid <path-to-dSYM> Copy In the following example, the New Relic dSYM returns two Build UUIDs, one each for ARMv7 and ARM64. The ARMv7 Build UUID matches the Build UUID of the missing crash example: > dwarfdump --uuid ./New\\ Relic.app.dSYM/Contents/Resources/DWARF/New\\ Relic UUID: 117667E7-B8D2-30CB-8A90-8906C64E0227 (armv7) ./New Relic.app.dSYM/Contents/Resources/DWARF/New Relic UUID: B1A8C6EE-02B9-3C55-AEE7-308521873107 (arm64) ./New Relic.app.dSYM/Contents/Resources/DWARF/New Relic Copy To symbolicate the unsymbolicated crashes, follow the instructions to manually upload the dSYM. For more help Manual dSYM upload (how to manually upload dSYMs) Retrieve and upload dSYMs (how to locate dSYMs from past app releases)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 705.43445,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Mobile</em> <em>monitoring</em>",
        "body": "If the dSYM is not uploaded to New Relic, <em>mobile</em> crash reports cannot be symbolicated. You can upload dSYMs manually or directly through the New Relic UI. However, every build of an application will create a new dSYM, and it can be difficult managing which dSYM is attributed to which app build"
      },
      "id": "603e9fbae7b9d21cef2a07dd"
    },
    {
      "sections": [
        "HTTP errors: Network failure analysis",
        "Find and use the HTTP errors page",
        "Group, sort, and filter errors and failures",
        "HTTP error profiles",
        "View more details about a specific error",
        "View and share error data with query builder",
        "View legacy HTTP errors UI page",
        "View the Errors page",
        "Error trace details",
        "View error data in query builder",
        "Unknown errors or URL errors"
      ],
      "title": "HTTP errors: Network failure analysis",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "04631e122b061663c6fd261b605202654aadcf96",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/http-errors-network-failure-analysis/",
      "published_at": "2021-07-02T17:32:53Z",
      "updated_at": "2021-06-26T14:38:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring's HTTP errors page helps you to better understand HTTP errors and network failures associated with your mobile app, to connect errors to services that are causing issues, and to share actionable data with your team: Team member View the data on the HTTP errors page to... Manager See a list of errors and failures so you can coordinate mobile app teams with backend teams and share the data they need to fix issues. QA engineer Make sure that a new version of your app does not cause a spike in errors compared to a previous version. DevOps engineer See a list of domains and URLs associated with HTTP errors and network failures, so you can focus on the ones that are causing errors and filter out status codes that are too noisy for your alerts. Mobile developer Find out if there are frontend or backend problems affecting your mobile app (even without an error alert going off) so that you can address them in a new version. Support engineer View the errors and session attributes (geography, connection type, device, app version) associated with an error so that you can help customers with their issues. Find and use the HTTP errors page There are two ways to get to the HTTP errors page: Go to one.newrelic.com > Mobile > (select an app) > Network > Network errors. From a mobile app's Overview page in Mobile monitoring, select the HTTP errors/network failures chart title link. From the HTTP errors page, investigate HTTP request and network failures: Use any standard page functions to look for trends in Errors and failures charts. Target specific types of errors and failures by grouping, sorting, and filtering the data. Find anomalies in your request errors with HTTP error profiles. Select an error or failure to view details for it. You can also define NRQL alerts that are focused on error types for your critical services or query your app data. Group, sort, and filter errors and failures If you want to do this... Do this... Change how the page groups and sorts errors and network failures Make selections from the Group by and Sort by dropdowns. By default, the Network errors page is grouped by request domain and sorted by errors and failures. Filter for specific errors and network failures Select an error or failure from the Errors and failures list and/or select multiple filters from the Filter dropdown. See which filters you applied or remove filters The filters you select display next to the filter dropdown. To clear filters, select the X next to the filter you want to clear. Change the time window Select a new time period from the Time picker dropdown. View information for one specific app version Select the version that you want to see charts and lists for in the Versions dropdown. HTTP error profiles Error profiles provide visual details about significant differences in the frequency of different values for HTTP error events. For each attribute, the error profile includes: A pie chart showing how the error's attribute is distributed for values that deviate the most A table comparing the error attribute's distribution to that of other errors This helps you take more of the guesswork out of resolving your mobile application's HTTP errors. You can more easily determine if you safely ignore the error, or if you should attempt to resolve the error with a new deployment, code change, customer communication or other actions. View more details about a specific error To view details about an error or failure, select the Request URL link to be directed to the Error summary page. From the Error summary page, you can view the version information, request attributes, and Response body, as well as get a breakdown of error types for the request URL. View and share error data with query builder To explore the data behind any of the charts or lists on the HTTP errors/requests page: Select for any chart. Select View query and then View in Insights. This will open the query builder. From the query builder, you can add the error data to a dashboard and share it via a permalink. To dig deeper into the error data, query your data for the following events and attributes: MobileRequestError events and attributes MobileRequest events and attributes View legacy HTTP errors UI page Accounts that do not have an Enterprise-level subscription see a different HTTP Errors UI page: The Errors page includes details about HTTP errors (403, 404, 422, 500, 502, etc.) and network failures for your hosts; for example: Secure connection failed Timed out Cannot find host Not connected to Internet Cannot connect to host View the Errors page To view HTTP errors or network failures for your mobile app: Go to one.newrelic.com > Mobile > (select an app) > Network > Errors. To change the view to errors or failures, select the Sort by option. To hide low-usage hosts, select the Hide < 1% throughput option. To limit information to a specific version of your app, or to change the time period, select your choice from the Versions menu or the time picker below the menu bar. To view details for a specific host, HTTP status error, or network failure, select its name. Use any of our standard user interface functions to drill down into detailed information. Error trace details Mobile monitoring will capture the response details from HTTP requests that return a 400 or 500 level status code. In addition, error messages generated from Android apps will include a stack trace. To view details about an error trace on the Errors page, select its request URL link. From here you can: View the response body. Share the error details with others by email. File a ticket about it through a ticketing system integrated with New Relic. Delete or hide the error. The errors chart also appears on the selected mobile app's Overview page. If the chart shows errors, you can select its HTTP errors/network failures title or select anywhere on the Overview page's chart to go directly to this Errors page. View error data in query builder To dig deeper into your request data, use the query builder to query and chart the MobileRequest events and attributes. Unknown errors or URL errors The Mobile agents maintain a list of exception types. In some cases, custom exceptions thrown by applications fall outside of this list. When this happens, Unknown may appear in the Mobile Errors page. If you find Unknown in your list of errors and need assistance in researching which exception types are being missed, get support at support.newrelic.com.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 563.12274,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Mobile</em> <em>monitoring</em>",
        "body": "<em>Mobile</em> <em>monitoring</em>&#x27;s HTTP errors page helps you to better understand HTTP errors and network failures associated with your <em>mobile</em> app, to connect errors to services that are causing issues, and to share actionable data with your team: Team member View the data on the HTTP errors page to... Manager"
      },
      "id": "603e8eb428ccbcd174eba791"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-ios/installation/spm-installation/",
      "sections": [
        "Swift Package Manager installation",
        "Tip",
        "Install your iOS application",
        "Configure using Swift Package Manager",
        "Important",
        "Change the logging level (optional)"
      ],
      "published_at": "2021-07-02T14:54:35Z",
      "title": "Swift Package Manager installation",
      "updated_at": "2021-07-02T14:54:35Z",
      "type": "docs",
      "external_id": "d8164f0a7145388a8cf0739039a84db37609260c",
      "document_type": "page",
      "popularity": 1,
      "body": "These procedures apply to iOS apps using Swift Package Manager. For other types, see iOS installation and configuration. Tip To use mobile monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Install your iOS application As part of the installation process, New Relic automatically generates an application token. This is a 40-character hexadecimal string for authenticating each mobile app you monitor in New Relic. To install and configure your iOS application: Go to one.newrelic.com. If applicable: From the Mobile Apps list, select Add a new app. From the Get Started page, select iOS as the platform for mobile monitoring. Type a name for your mobile app, then select Continue. Continue with the steps to configure New Relic for mobile monitoring. Configure using Swift Package Manager Select File > Swift Packages > Add Package Dependency.... Add the Github URL of the Package file: https://github.com/newrelic/newrelic-ios-agent-spm Copy Tip If you receive an artifact of binary target 'NewRelic' failed extraction: The operation couldn’t be completed. (TSCBasic.StringError error 1.) error when extracting the package, please close Xcode, delete the Derrived Data folder, re-open Xcode, and try again. Select the NewRelic package product, select your target, and select Finish. In your AppDelegate.swift file, add this call as the first line of applicationDidFinishLaunchWithOptions, replacing APP_TOKEN with your application token: NewRelic.start(withApplicationToken:\"APP_TOKEN\") Copy Important To ensure proper instrumentation, you must call the agent on the first line of didFinishLaunchingWithOptions(), and run the agent on the main thread. Starting the call later, on a background thread, or asynchronously can cause unexpected or unstable behavior. Add a build script to your target's Build Phases. Ensure the new build script is the very last build script. Then paste the following, replacing APP_TOKEN with your application token: SCRIPT=`/usr/bin/find \"${SRCROOT}\" -name newrelic_postbuild.sh | head -n 1` /bin/sh \"${SCRIPT}\" \"APP_TOKEN\" Copy Clean and build your app, then run it in the simulator or other device. Change the logging level (optional) Six log levels are available for mobile apps monitoring: none error warning info verbose ALL To increase your logging level in the app, add this method call before calling NewRelic.start(withApplicationToken): NRLogger.setLogLevels(NRLogLevelALL.rawValue) Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 550.095,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": "These procedures apply to iOS apps using Swift Package Manager. For other types, see iOS installation and configuration. Tip To use <em>mobile</em> <em>monitoring</em> and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up"
      },
      "id": "60df28abe7b9d2c503a553a7"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/crashes/crash-analysis-group-filter-your-crashes": [
    {
      "sections": [
        "Find Build UUIDs for unsymbolicated crashes",
        "View the Build UUID",
        "Binary images example",
        "Find and resymbolicate the dSYM",
        "For more help"
      ],
      "title": "Find Build UUIDs for unsymbolicated crashes",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "e8b926653583d66810c0f68eb6b0111ab3bfc477",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/find-build-uuids-unsymbolicated-crashes/",
      "published_at": "2021-07-02T14:14:31Z",
      "updated_at": "2021-07-02T14:14:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If the dSYM is not uploaded to New Relic, mobile crash reports cannot be symbolicated. You can upload dSYMs manually or directly through the New Relic UI. However, every build of an application will create a new dSYM, and it can be difficult managing which dSYM is attributed to which app build. In this situation, you can use the Build UUID identifier to: Identify a unique build of an application. Find which dSYM can be used to symbolicate a crash. View the Build UUID An application may have more than one Build UUID, one attributed for each CPU architecture the application is built. The Build UUID is also stored within the associated dSYM and can be extracted to identify the dSYM. New Relic crash reports also contain the Build UUID of the crashing application. To view the Build UUID: Go to one.newrelic.com and click Mobile in the top nav. Then find your app and click Crashes > Crash Analysis. From the Crash list table, select any row. From the selected crash report's Crash Details page, look for the App Image Uuid on the attribute list. If the App Image Uuid is not on the selected crash report's attributes list: Export the crash details. Look for the Build UUID in the Binary images section of the exported crash report. Use the Build UUID extracted from the crash details to find the missing dSYM. Binary images example Here is an example of the Binary images section from an exported crash report. This section lists the Build UUID for every dynamically-linked library included in the application, as well as the Build UUID for the main application. In this example, the main application is New Relic. Its Build UUID is 117667e7b8d230cb8a908906c64e0227. This is the identifier you can use to find the associated dSYM. Binary Images: 0xb1000 - 0x30d000 New Relic armv7 < 117667e7b8d230cb8a908906c64e0227 > /var/containers/Bundle/Application/New Relic.app/New Relic 0x22290000 - 0x22292000 libSystem.B.dylib armv7 <39d6d6f7c2ac3de8bb29c40a1b66368a> /usr/lib/libSystem.B.dylib 0x22292000 - 0x222de000 libc++.1.dylib armv7 <017dba6c16b63f9ebecb9ddd0d0a4520> /usr/lib/libc++.1.dylib 0x222de000 - 0x222f9000 libc++abi.dylib armv7 <d32373f6c2153a509f6603750d213ffb> /usr/lib/libc++abi.dylib 0x222fc000 - 0x22667000 libobjc.A.dylib armv7 <94f6d325c1843f45b3a439b86fc9de15> /usr/lib/libobjc.A.dylib 0x22667000 - 0x2266c000 libcache.dylib armv7 <8009f99fb892331dbcb61cd740ff0f43> /usr/lib/system/libcache.dylib 0x2266c000 - 0x22676000 libcommonCrypto.dylib armv7 <f6db318471d732d39918ef36bde65cb7> /usr/lib/system/libcommonCrypto.dylib 0x22676000 - 0x2267c000 libcompiler_rt.dylib armv7 <cfa3ca12d6c2383abcaf3c8541e9b86c> /usr/lib/system/libcompiler_rt.dylib 0x2267c000 - 0x22683000 libcopyfile.dylib armv7 <d2b06020c3693c7b9d179434f8115ba0> /usr/lib/system/libcopyfile.dylib 0x22683000 - 0x226d3000 libcorecrypto.dylib armv7 <181437f8d9e53277ace439de8b3fd1ad> /usr/lib/system/libcorecrypto.dylib 0x226d3000 - 0x2271d000 libdispatch.dylib armv7 <bbb4bba2176039ab95a59d7a56f6eff8> /usr/lib/system/libdispatch.dylib Copy Find and resymbolicate the dSYM To find a dSYM's Build UUID of a dSYM: use dwarfdump with the following terminal command: dwarfdump --uuid <path-to-dSYM> Copy In the following example, the New Relic dSYM returns two Build UUIDs, one each for ARMv7 and ARM64. The ARMv7 Build UUID matches the Build UUID of the missing crash example: > dwarfdump --uuid ./New\\ Relic.app.dSYM/Contents/Resources/DWARF/New\\ Relic UUID: 117667E7-B8D2-30CB-8A90-8906C64E0227 (armv7) ./New Relic.app.dSYM/Contents/Resources/DWARF/New Relic UUID: B1A8C6EE-02B9-3C55-AEE7-308521873107 (arm64) ./New Relic.app.dSYM/Contents/Resources/DWARF/New Relic Copy To symbolicate the unsymbolicated crashes, follow the instructions to manually upload the dSYM. For more help Manual dSYM upload (how to manually upload dSYMs) Retrieve and upload dSYMs (how to locate dSYMs from past app releases)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 319.3728,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Find Build UUIDs for unsymbolicated <em>crashes</em>",
        "sections": "Find Build UUIDs for unsymbolicated <em>crashes</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "If the dSYM is not uploaded to New Relic, <em>mobile</em> <em>crash</em> reports cannot be symbolicated. You can upload dSYMs manually or directly through the New Relic <em>UI</em>. However, every build of an application will create a new dSYM, and it can be difficult managing which dSYM is attributed to which app build"
      },
      "id": "603e9fbae7b9d21cef2a07dd"
    },
    {
      "sections": [
        "Mobile monitoring best practices guide",
        "1. Start collecting data",
        "How to do it",
        "Add your mobile app to New Relic",
        "Install and configure our mobile SDK",
        "2. Explore your data",
        "Analyze, resolve, and prevent crashes",
        "Monitor your key workflows",
        "Get actionable session data",
        "3. Take preventive steps",
        "Metric-based alerts",
        "Event-based alerts",
        "4. Dig deeper into crashes",
        "Crash analysis",
        "Breadcrumbs",
        "Custom attributes",
        "5. Focus on KPIs",
        "Track and query feature use",
        "Measure page load times",
        "Examine data about webpage interactions"
      ],
      "title": "Mobile monitoring best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Full-stack observability"
      ],
      "external_id": "32f5d3919c54c90173721a2cda556d8fd57744f1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/mobile-monitoring-best-practices-guide/",
      "published_at": "2021-07-02T20:13:14Z",
      "updated_at": "2021-07-02T20:13:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "By eliminating crashes and increasing speed across the stack, you can build better performance into every mobile app release. Here are some best practices to take full advantage of mobile monitoring with New Relic. 1. Start collecting data Start collecting data in production. You'll see immediate value by adding our mobile monitoring SDK to your app for its next release to the app store. We recommend installing the iOS or Android agent to your production release even if you're simply testing New Relic's capabilities. This will ensure you'll get an adequate amount of data to really understand all of our mobile monitoring capabilities and your end users' experience. How to do it Add your mobile app to New Relic First, add a new app in New Relic's user interface (full steps): Go to one.newrelic.com and click Mobile. From the list of monitored apps, select Add more. Select the relevant platform. Type a name for your mobile app, and select Continue. Use one app and the associated app token for the development releases of your iOS app, another app and its associated app token for the production releases of that iOS app, and another pair of app tokens for development and production releases of your Android app. You'll be able to compare data from across the four app tokens using our query builder. Install and configure our mobile SDK Next, install and configure the mobile agent: Download the latest version of New Relic's SDK for iOS or Android, and add it to your mobile app. (Full steps for iOS and Android) Configure your installation as needed. For example: Enable the feature flag to capture MobileRequest events to use our full network analysis capabilities for iOS or Android. Automate dSYM uploads for your production builds. To avoid surprises, follow the standard pattern of where you start our mobile agent. In addition, start our agent before you initiate any other SDKs. For more information, see our documentation for Android installation and configuration and for iOS installation and configuration. Deploy a new release of your application. 2. Explore your data Immediately be able to explore your data. As soon as New Relic starts reporting data, take the time to explore the wealth of information about your mobile apps. To get started, go to one.newrelic.com and select Mobile. How to do it Analyze, resolve, and prevent crashes Find the cause of crashes so you can fix them. Then, uncover trends behind crashes so you can prevent them: From the summary UI page for a monitored mobile app, click Crash analysis. Analyze crash data so you can see and fix the most impactful crashes. Follow the breadcrumbs in the crash event trail to fix crashes and resolve critical errors more easily: From your mobile app's Crash analysis page in the UI, select a Crash type. From the crash type's Summary page, select the Crash trail tab. For more information, see our blog post about crash analysis. Monitor your key workflows Create custom breadcrumbs to monitor key workflows (such as your app's login or checkout process), track user clicks, optimize timing, and identify crash locations for faster MTTR. Get actionable session data Borrow from our example queries to: See how much of your user base has upgraded to your latest app version. Track adoption over time. Get a count of new installs as compared to upgrades from an earlier version. See the distribution of usage across geographical locations, carriers, ASN owners (wi-fi providers), devices, connection types, and more. 3. Take preventive steps Use alert notifications to help uncover the causes behind crashes and errors. Once you are running our mobile monitoring capabilities in production and have explored some of the key features, you can use New Relic to uncover critical issues with your mobile application. In particular, focus on crashes and errors. Use metric-based alerts as a starting point to gain high-level visibility into problems. Then, as new services or functionalities are added, use New Relic’s more targeted, event-based (NRQL) alerts to make sure that the most critical issues are handled swiftly. Use these alerts to determine whether a crash is impacting a large number of users. If it is, the relevant people (for example, both the mobile app team’s on-call member and the owner of the related back-end service) will be alerted. Make sure that your team knows how to respond to changes in crash rate (crashes per sessions) and the percentage of users impacted by crashes of your mobile app. How to do it Metric-based alerts Leverage our metric-based alerts and New Relic Mobile UI. Ensure that key members of your mobile team have opted in to receive emails for new crashes. These emails will take you to the crash type in the Mobile UI page for your mobile app. Create an alert for your crash rate threshold that key members of your team can view in Slack or any other Alerts notification channel you choose. Your alert notification will include a link to our UI, where you can examine a chart with the exceeded threshold. From there, a link will take you to the relevant mobile monitoring page, where you can get additional details. Event-based alerts Combine the metric-based workflow with event-based alerts and dashboards specific to your mobile app and system. Create your NRQL alert that focuses on crashes of your most recently released production version. Create an additional NRQL alert that focuses on the percentage of users impacted by crashes in your latest app version (to check the overall impact on your user base). 4. Dig deeper into crashes Take your crash reporting to the next level. Now it’s time to tackle some of those harder-to-reproduce crashes by: Applying additional instrumentation to your application. Leveraging crash event trails, NRQL queries, and dashboards to visualize your data. How to do it Crash analysis Crashes are an inevitable part of running mobile applications at scale. We provide tools to help you understand your highest-impact crashes. Use the Crash analysis UI to see which crashes are occurring most often, the percentage of crash-free users, which files and methods are associated with perhaps 80 percent of your crashes, which crashes a particular user just experienced, and more. Go after high-impact crashes with crash analysis: Add custom attributes to categorize the highest-value customers, and then use them to segment crashes according to your most valuable audiences. Add breadcrumbs and custom events to produce a detailed trail of events leading up to every crash occurrence (over the last 90 days). Then, view this crash event trail in our mobile monitoring UI. Use our mobile monitoring's Versions trends page to make sure you’re improving the crash rate over subsequent releases and avoiding regressions. Breadcrumbs Use breadcrumbs and custom attributes to better reproduce and debug crashes. For example, use our recordBreadrumb API for Android or iOS to track mid-session changes in state that can help debug crashes, such as: Change of connection type Change of orientation CPU and memory state at key points in the app code Custom attributes Add custom attributes to existing events, so you can ask even more precise questions of your mobile app. Add dimensions such as: User ID: Use to react to specific user concerns and to better understand which customers and segments are most impacted. Store ID: Use to address problems with out-of-date devices, bad wi-fi, and so on. User segments: Use to better understand which customers and segments are most impacted; for example, logged in vs. non-logged in. Money in the cart at session end Origin or attribution of entry into the app Standardize custom attribute names across your mobile apps, and align with your website (if monitored by New Relic Browser), so that you can compare and contrast performance across end-user channels. New Relic Mobile tracks the last interaction of crashed and non-crashed sessions to provide visibility into what the user viewed before exiting your app (either intentionally or due to a crash). 5. Focus on KPIs Bring your key performance indicators to life. Create custom interactions and events to hone in on the most important signals, including user activity for the business-critical aspects of your app. Using these powerful APIs, you can add custom instrumentation to just about anything. The following are some example use cases. How to do it Track and query feature use Use custom events to track feature use. For example: Use custom events to track user flow between app and website. Use custom events or mobile breadcrumbs to optimize the performance of key user flows (log in, shopping cart, etc.). use custom events to provide faster, contextualized support experiences for your digital customers. Use the recordCustomEvent API. Then compare the use of different features using: SELECT count(*) FROM MyNewMobileEventType FACET name Copy Measure page load times Use custom events to measure page load time: Create an app-launch timer to measure the time that elapses between a user-tap to launch your app and the point in your app code where the first screen is available. Record the timer value in New Relic using something like the following: recordCustomEvent(<myMobileTimers>, <appLaunch>, {attributes}) Copy Define start and stop timers to measure spinner durations, and then record this time in New Relic using something like the following: recordCustomEvent(<myMobileTimers>, <spinnerOnScreenA>, {attributes}) Copy Track specific user actions or funnel steps in the app (like \"add to cart\"), and include the price as an attribute on that event. Measure flows through the application by viewing the related funnel steps with custom events in Insights. For example, create a timer to track the start and end times of a subflow or an entire flow across multiple funnel steps to understand how long it took users to get through the process. Examine data about webpage interactions Use custom interactions to see traces associated with the same webpages. Use the agent API to disable default interactions, and focus on custom interactions so that you can review the page loads that are most crucial to your primary funnel. Define the start and stop times of these custom interactions to trace activities associated with individual steps of that funnel (for example, a specific user action or a page load). Track the last interactions of crashed and non-crashed sessions so that you can see what the user viewed before exiting your app (either intentionally or from a crash). Example query for non-crashed sessions: SELECT count(*) FROM Mobile WHERE sessionCrashed is null FACET lastInteraction SINCE 90 days ago Copy Example query for crashed sessions: SELECT count(*) FROM Mobile WHERE sessionCrashed is true FACET lastInteraction SINCE 90 days ago Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.61737,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>monitoring</em> best practices guide",
        "sections": "<em>Mobile</em> <em>monitoring</em> best practices guide",
        "body": " event trail in our <em>mobile</em> <em>monitoring</em> <em>UI</em>. Use our <em>mobile</em> <em>monitoring</em>&#x27;s Versions trends page to make sure you’re improving the <em>crash</em> rate over subsequent releases and avoiding regressions. Breadcrumbs Use breadcrumbs and custom attributes to better reproduce and debug <em>crashes</em>. For example, use our"
      },
      "id": "6044151e28ccbc19ab2c60d8"
    },
    {
      "sections": [
        "Introduction to Mobile handled exceptions",
        "Features",
        "Requirements",
        "Tip",
        "Handled exceptions API and event type"
      ],
      "title": "Introduction to Mobile handled exceptions",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "cfdf733d55bb89d157df675fa162b737bdad52c7",
      "image": "https://docs.newrelic.com/static/5891a9437b94b543d81ee04a70ebe876/8c557/mobile-handled-exceptions-ui.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/introduction-mobile-handled-exceptions/",
      "published_at": "2021-07-02T14:15:31Z",
      "updated_at": "2021-05-16T06:28:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Exceptions can contribute to invalid application states, resulting not only in application crashes but also in negative user reviews. This may lead to users deleting your app, which in turn may affect your organization's profitability. With New Relic Mobile's Handled exceptions user interface, mobile development managers and their developer teams can identify significant factors affecting poor mobile app experience, and use filterable data to find a resolution more quickly. Features Handling exceptions as they occur can help improve your mobile app users' experience, but it's not enough to catch exceptions. You also need to know how to prevent them. For example: How many different types of handled exceptions are occurring? A high occurrence rate may necessitate changes to the back-end systems. Why does the user's app usage result in a try/catch? What is the context for the exceptions? When can a test environment's responses to handled exceptions indicate additional, more serious problems? What would have caused a crash if the exception had not been caught in production? What else (in the code or back-end API) is still affecting the users' experience? By using handled exceptions with New Relic Mobile, you can identify and resolve these kinds of issues more quickly. one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: As you explore the wealth of data in the charts and table, use groups and filters to discover patterns that help you determine the root cause of mobile app exceptions. Handled exception features Comments Slice and dice your exception data. New Relic Mobile offers both an API and a user interface to explore the data most important to your business. Use the recordHandledException() method within a try{...} catch(){...} block to help understand how often your application is throwing exceptions, and under what conditions. Use groups and filters to analyze trends leading to the exception. For example, you can group by OS Build, then filter a specific appVersion. Understand a particular user's experience. Examine the percentage charts to see overall trends with users and sessions at a glance. Then, use custom attributes to focus on exceptions related to paid accounts than free accounts. Pinpoint when most exceptions occur. For example, group on Last Interaction to get an overall view of problems. To drill down further, use filters, such as: To examine exceptions caused by network problems, filter by carrier and then select wifi. To examine exceptions caused by app releases, filter by appVersion. Align issues with common characteristics. For example: Use groups and filters to determine whether handled exception trends appear in networks (ASN, carrier, location, etc.) or in devices (device model, manufacturer, operating system build, version, etc.). Explore recurring patterns in stack traces with the top five exception locations table. Query data and share your findings via New Relic Insights. Explore the event trail before and after a crash. With New Relic Mobile you get a more complete picture of events before and after crashes occur, so you can analyze and resolve problems from multiple angles: Use the handled exception's Occurrences page for expected exceptions. Use the Crash analysis UI and event trail for unanticipated exceptions. Requirements Tip Access to this feature depends on your subscription level and mobile data retention. Additional requirements include: Android: New Relic Mobile's Android agent version 5.15.0 or higher iOS: New Relic Mobile's iOS agent version 5.15.0 or higher Handled exceptions API and event type New Relic Mobile automatically includes default attributes that you can use to explore your handled exceptions data in New Relic Insights and get specific details: Use the recordHandledExceptions() method for the Android or iOS SDK API. Query the MobileHandledException event type in Insights. For more information, see the Insights examples for New Relic Mobile. You can also create your own custom attributes and events. Then, select attributes in Mobile's Handled exceptions page, and query or share them in Insights.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 178.9654,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Mobile</em> handled exceptions",
        "sections": "Introduction to <em>Mobile</em> handled exceptions",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " trail before and after a <em>crash</em>. With New Relic <em>Mobile</em> you get a more complete picture of events before and after <em>crashes</em> occur, so you can analyze and resolve problems from multiple angles: Use the handled exception&#x27;s Occurrences page for expected exceptions. Use the <em>Crash</em> analysis <em>UI</em> and event trail"
      },
      "id": "603e7e8228ccbc05f9eba770"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/crashes/find-build-uuids-unsymbolicated-crashes": [
    {
      "sections": [
        "Mobile monitoring best practices guide",
        "1. Start collecting data",
        "How to do it",
        "Add your mobile app to New Relic",
        "Install and configure our mobile SDK",
        "2. Explore your data",
        "Analyze, resolve, and prevent crashes",
        "Monitor your key workflows",
        "Get actionable session data",
        "3. Take preventive steps",
        "Metric-based alerts",
        "Event-based alerts",
        "4. Dig deeper into crashes",
        "Crash analysis",
        "Breadcrumbs",
        "Custom attributes",
        "5. Focus on KPIs",
        "Track and query feature use",
        "Measure page load times",
        "Examine data about webpage interactions"
      ],
      "title": "Mobile monitoring best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Full-stack observability"
      ],
      "external_id": "32f5d3919c54c90173721a2cda556d8fd57744f1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/mobile-monitoring-best-practices-guide/",
      "published_at": "2021-07-02T20:13:14Z",
      "updated_at": "2021-07-02T20:13:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "By eliminating crashes and increasing speed across the stack, you can build better performance into every mobile app release. Here are some best practices to take full advantage of mobile monitoring with New Relic. 1. Start collecting data Start collecting data in production. You'll see immediate value by adding our mobile monitoring SDK to your app for its next release to the app store. We recommend installing the iOS or Android agent to your production release even if you're simply testing New Relic's capabilities. This will ensure you'll get an adequate amount of data to really understand all of our mobile monitoring capabilities and your end users' experience. How to do it Add your mobile app to New Relic First, add a new app in New Relic's user interface (full steps): Go to one.newrelic.com and click Mobile. From the list of monitored apps, select Add more. Select the relevant platform. Type a name for your mobile app, and select Continue. Use one app and the associated app token for the development releases of your iOS app, another app and its associated app token for the production releases of that iOS app, and another pair of app tokens for development and production releases of your Android app. You'll be able to compare data from across the four app tokens using our query builder. Install and configure our mobile SDK Next, install and configure the mobile agent: Download the latest version of New Relic's SDK for iOS or Android, and add it to your mobile app. (Full steps for iOS and Android) Configure your installation as needed. For example: Enable the feature flag to capture MobileRequest events to use our full network analysis capabilities for iOS or Android. Automate dSYM uploads for your production builds. To avoid surprises, follow the standard pattern of where you start our mobile agent. In addition, start our agent before you initiate any other SDKs. For more information, see our documentation for Android installation and configuration and for iOS installation and configuration. Deploy a new release of your application. 2. Explore your data Immediately be able to explore your data. As soon as New Relic starts reporting data, take the time to explore the wealth of information about your mobile apps. To get started, go to one.newrelic.com and select Mobile. How to do it Analyze, resolve, and prevent crashes Find the cause of crashes so you can fix them. Then, uncover trends behind crashes so you can prevent them: From the summary UI page for a monitored mobile app, click Crash analysis. Analyze crash data so you can see and fix the most impactful crashes. Follow the breadcrumbs in the crash event trail to fix crashes and resolve critical errors more easily: From your mobile app's Crash analysis page in the UI, select a Crash type. From the crash type's Summary page, select the Crash trail tab. For more information, see our blog post about crash analysis. Monitor your key workflows Create custom breadcrumbs to monitor key workflows (such as your app's login or checkout process), track user clicks, optimize timing, and identify crash locations for faster MTTR. Get actionable session data Borrow from our example queries to: See how much of your user base has upgraded to your latest app version. Track adoption over time. Get a count of new installs as compared to upgrades from an earlier version. See the distribution of usage across geographical locations, carriers, ASN owners (wi-fi providers), devices, connection types, and more. 3. Take preventive steps Use alert notifications to help uncover the causes behind crashes and errors. Once you are running our mobile monitoring capabilities in production and have explored some of the key features, you can use New Relic to uncover critical issues with your mobile application. In particular, focus on crashes and errors. Use metric-based alerts as a starting point to gain high-level visibility into problems. Then, as new services or functionalities are added, use New Relic’s more targeted, event-based (NRQL) alerts to make sure that the most critical issues are handled swiftly. Use these alerts to determine whether a crash is impacting a large number of users. If it is, the relevant people (for example, both the mobile app team’s on-call member and the owner of the related back-end service) will be alerted. Make sure that your team knows how to respond to changes in crash rate (crashes per sessions) and the percentage of users impacted by crashes of your mobile app. How to do it Metric-based alerts Leverage our metric-based alerts and New Relic Mobile UI. Ensure that key members of your mobile team have opted in to receive emails for new crashes. These emails will take you to the crash type in the Mobile UI page for your mobile app. Create an alert for your crash rate threshold that key members of your team can view in Slack or any other Alerts notification channel you choose. Your alert notification will include a link to our UI, where you can examine a chart with the exceeded threshold. From there, a link will take you to the relevant mobile monitoring page, where you can get additional details. Event-based alerts Combine the metric-based workflow with event-based alerts and dashboards specific to your mobile app and system. Create your NRQL alert that focuses on crashes of your most recently released production version. Create an additional NRQL alert that focuses on the percentage of users impacted by crashes in your latest app version (to check the overall impact on your user base). 4. Dig deeper into crashes Take your crash reporting to the next level. Now it’s time to tackle some of those harder-to-reproduce crashes by: Applying additional instrumentation to your application. Leveraging crash event trails, NRQL queries, and dashboards to visualize your data. How to do it Crash analysis Crashes are an inevitable part of running mobile applications at scale. We provide tools to help you understand your highest-impact crashes. Use the Crash analysis UI to see which crashes are occurring most often, the percentage of crash-free users, which files and methods are associated with perhaps 80 percent of your crashes, which crashes a particular user just experienced, and more. Go after high-impact crashes with crash analysis: Add custom attributes to categorize the highest-value customers, and then use them to segment crashes according to your most valuable audiences. Add breadcrumbs and custom events to produce a detailed trail of events leading up to every crash occurrence (over the last 90 days). Then, view this crash event trail in our mobile monitoring UI. Use our mobile monitoring's Versions trends page to make sure you’re improving the crash rate over subsequent releases and avoiding regressions. Breadcrumbs Use breadcrumbs and custom attributes to better reproduce and debug crashes. For example, use our recordBreadrumb API for Android or iOS to track mid-session changes in state that can help debug crashes, such as: Change of connection type Change of orientation CPU and memory state at key points in the app code Custom attributes Add custom attributes to existing events, so you can ask even more precise questions of your mobile app. Add dimensions such as: User ID: Use to react to specific user concerns and to better understand which customers and segments are most impacted. Store ID: Use to address problems with out-of-date devices, bad wi-fi, and so on. User segments: Use to better understand which customers and segments are most impacted; for example, logged in vs. non-logged in. Money in the cart at session end Origin or attribution of entry into the app Standardize custom attribute names across your mobile apps, and align with your website (if monitored by New Relic Browser), so that you can compare and contrast performance across end-user channels. New Relic Mobile tracks the last interaction of crashed and non-crashed sessions to provide visibility into what the user viewed before exiting your app (either intentionally or due to a crash). 5. Focus on KPIs Bring your key performance indicators to life. Create custom interactions and events to hone in on the most important signals, including user activity for the business-critical aspects of your app. Using these powerful APIs, you can add custom instrumentation to just about anything. The following are some example use cases. How to do it Track and query feature use Use custom events to track feature use. For example: Use custom events to track user flow between app and website. Use custom events or mobile breadcrumbs to optimize the performance of key user flows (log in, shopping cart, etc.). use custom events to provide faster, contextualized support experiences for your digital customers. Use the recordCustomEvent API. Then compare the use of different features using: SELECT count(*) FROM MyNewMobileEventType FACET name Copy Measure page load times Use custom events to measure page load time: Create an app-launch timer to measure the time that elapses between a user-tap to launch your app and the point in your app code where the first screen is available. Record the timer value in New Relic using something like the following: recordCustomEvent(<myMobileTimers>, <appLaunch>, {attributes}) Copy Define start and stop timers to measure spinner durations, and then record this time in New Relic using something like the following: recordCustomEvent(<myMobileTimers>, <spinnerOnScreenA>, {attributes}) Copy Track specific user actions or funnel steps in the app (like \"add to cart\"), and include the price as an attribute on that event. Measure flows through the application by viewing the related funnel steps with custom events in Insights. For example, create a timer to track the start and end times of a subflow or an entire flow across multiple funnel steps to understand how long it took users to get through the process. Examine data about webpage interactions Use custom interactions to see traces associated with the same webpages. Use the agent API to disable default interactions, and focus on custom interactions so that you can review the page loads that are most crucial to your primary funnel. Define the start and stop times of these custom interactions to trace activities associated with individual steps of that funnel (for example, a specific user action or a page load). Track the last interactions of crashed and non-crashed sessions so that you can see what the user viewed before exiting your app (either intentionally or from a crash). Example query for non-crashed sessions: SELECT count(*) FROM Mobile WHERE sessionCrashed is null FACET lastInteraction SINCE 90 days ago Copy Example query for crashed sessions: SELECT count(*) FROM Mobile WHERE sessionCrashed is true FACET lastInteraction SINCE 90 days ago Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.61737,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>monitoring</em> best practices guide",
        "sections": "<em>Mobile</em> <em>monitoring</em> best practices guide",
        "body": " event trail in our <em>mobile</em> <em>monitoring</em> <em>UI</em>. Use our <em>mobile</em> <em>monitoring</em>&#x27;s Versions trends page to make sure you’re improving the <em>crash</em> rate over subsequent releases and avoiding regressions. Breadcrumbs Use breadcrumbs and custom attributes to better reproduce and debug <em>crashes</em>. For example, use our"
      },
      "id": "6044151e28ccbc19ab2c60d8"
    },
    {
      "sections": [
        "Introduction to Mobile handled exceptions",
        "Features",
        "Requirements",
        "Tip",
        "Handled exceptions API and event type"
      ],
      "title": "Introduction to Mobile handled exceptions",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "cfdf733d55bb89d157df675fa162b737bdad52c7",
      "image": "https://docs.newrelic.com/static/5891a9437b94b543d81ee04a70ebe876/8c557/mobile-handled-exceptions-ui.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/introduction-mobile-handled-exceptions/",
      "published_at": "2021-07-02T14:15:31Z",
      "updated_at": "2021-05-16T06:28:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Exceptions can contribute to invalid application states, resulting not only in application crashes but also in negative user reviews. This may lead to users deleting your app, which in turn may affect your organization's profitability. With New Relic Mobile's Handled exceptions user interface, mobile development managers and their developer teams can identify significant factors affecting poor mobile app experience, and use filterable data to find a resolution more quickly. Features Handling exceptions as they occur can help improve your mobile app users' experience, but it's not enough to catch exceptions. You also need to know how to prevent them. For example: How many different types of handled exceptions are occurring? A high occurrence rate may necessitate changes to the back-end systems. Why does the user's app usage result in a try/catch? What is the context for the exceptions? When can a test environment's responses to handled exceptions indicate additional, more serious problems? What would have caused a crash if the exception had not been caught in production? What else (in the code or back-end API) is still affecting the users' experience? By using handled exceptions with New Relic Mobile, you can identify and resolve these kinds of issues more quickly. one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: As you explore the wealth of data in the charts and table, use groups and filters to discover patterns that help you determine the root cause of mobile app exceptions. Handled exception features Comments Slice and dice your exception data. New Relic Mobile offers both an API and a user interface to explore the data most important to your business. Use the recordHandledException() method within a try{...} catch(){...} block to help understand how often your application is throwing exceptions, and under what conditions. Use groups and filters to analyze trends leading to the exception. For example, you can group by OS Build, then filter a specific appVersion. Understand a particular user's experience. Examine the percentage charts to see overall trends with users and sessions at a glance. Then, use custom attributes to focus on exceptions related to paid accounts than free accounts. Pinpoint when most exceptions occur. For example, group on Last Interaction to get an overall view of problems. To drill down further, use filters, such as: To examine exceptions caused by network problems, filter by carrier and then select wifi. To examine exceptions caused by app releases, filter by appVersion. Align issues with common characteristics. For example: Use groups and filters to determine whether handled exception trends appear in networks (ASN, carrier, location, etc.) or in devices (device model, manufacturer, operating system build, version, etc.). Explore recurring patterns in stack traces with the top five exception locations table. Query data and share your findings via New Relic Insights. Explore the event trail before and after a crash. With New Relic Mobile you get a more complete picture of events before and after crashes occur, so you can analyze and resolve problems from multiple angles: Use the handled exception's Occurrences page for expected exceptions. Use the Crash analysis UI and event trail for unanticipated exceptions. Requirements Tip Access to this feature depends on your subscription level and mobile data retention. Additional requirements include: Android: New Relic Mobile's Android agent version 5.15.0 or higher iOS: New Relic Mobile's iOS agent version 5.15.0 or higher Handled exceptions API and event type New Relic Mobile automatically includes default attributes that you can use to explore your handled exceptions data in New Relic Insights and get specific details: Use the recordHandledExceptions() method for the Android or iOS SDK API. Query the MobileHandledException event type in Insights. For more information, see the Insights examples for New Relic Mobile. You can also create your own custom attributes and events. Then, select attributes in Mobile's Handled exceptions page, and query or share them in Insights.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 178.9654,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Mobile</em> handled exceptions",
        "sections": "Introduction to <em>Mobile</em> handled exceptions",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " trail before and after a <em>crash</em>. With New Relic <em>Mobile</em> you get a more complete picture of events before and after <em>crashes</em> occur, so you can analyze and resolve problems from multiple angles: Use the handled exception&#x27;s Occurrences page for expected exceptions. Use the <em>Crash</em> analysis <em>UI</em> and event trail"
      },
      "id": "603e7e8228ccbc05f9eba770"
    },
    {
      "sections": [
        "Mobile crash event trail",
        "Tip",
        "View events before mobile app crashes",
        "Use the event trail",
        "Difference between event trail and interaction trail"
      ],
      "title": "Mobile crash event trail",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "58795d499c8db6d8cc95bd6d2c645e970ea10d83",
      "image": "https://docs.newrelic.com/static/3731efca2d88ed92cc150d5f6c06830a/0d6fe/New-Relic-Mobile-crash-event-trail.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/mobile-crash-event-trail/",
      "published_at": "2021-07-02T14:15:31Z",
      "updated_at": "2021-05-16T06:28:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Mobile crash event trail shows you the events leading up to a crash of a mobile app, based on your subscription level's data retention policy. These can be events New Relic monitors by default, or custom events you created in New Relic Insights. This document explains what the crash event trail is and how to use it. Tip Access to this feature depends on your subscription level. View events before mobile app crashes When a mobile app crashes and you don't know why, you can study what happened right before the crash. New Relic Mobile's crash event trail shows you these events so that you can follow the \"breadcrumbs\" leading up to the crash and diagnose the cause of the failure. one.newrelic.com > Mobile > (select a mobile app) > Crash analysis > (selected crash type) > Event trail: The crash event trail shows the activity leading up to a mobile app crash. The crash event trail shows all New Relic Mobile event types leading up to a crash. You can use New Relic Mobile's iOS SDK or Android SDK to create custom MobileBreadcrumb events that track whatever app activity you think would help you diagnose a crash. You can also use MobileHandledException events in the crash event trail to aid in debugging. Use the iOS and Android recordHandledException APIs for iOS or Android to annotate where exceptions are handled in your application. These events will automatically appear in the crash event trail. For more about annotating crash event trails with custom data, see Add custom data to New Relic Mobile. Use the event trail To use the New Relic Mobile crash event trail: Go to one.newrelic.com > Mobile > (select a mobile app) > Crash analysis. On the lower right side of the Crash analysis page, select a crash type. On the Crash details page, beside the stack trace, select Event trail. Study the events leading up to a crash type for clues to the reasons for the crash. To expand details about an event's attributes, select it. To view the event trail results in New Relic Insights, select Open session in Insights. To scroll through occurrences of the same crash type, use the event trail's left and right arrows. For optimal use of New Relic's crash analysis tools, use: New Relic Mobile's Android SDK API or iOS SDK API to create custom MobileBreadcrumb or MobileHandledException events Enable MobileRequest events New Relic Mobile's Crash analysis page New Relic Mobile's Interaction trail New Relic Insights queries of your crash event data New Relic Insights dashboards Difference between event trail and interaction trail The crash event trail is different from the interaction trail. The crash event trail shows all New Relic Mobile event types leading up to a crash, whereas the interaction trail only shows interaction event types (Mobile events with the category interaction). The interaction trail has additional features, including stack traces and links to the associated interaction charts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 178.9654,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>crash</em> event trail",
        "sections": "View events before <em>mobile</em> app <em>crashes</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " event trail is and how to use it. Tip Access to this feature depends on your subscription level. View events before <em>mobile</em> app <em>crashes</em> When a <em>mobile</em> app <em>crashes</em> and you don&#x27;t know why, you can study what happened right before the <em>crash</em>. New Relic <em>Mobile</em>&#x27;s <em>crash</em> event trail shows you these events so"
      },
      "id": "604503b1e7b9d201e75799bb"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/crashes/handled-exceptions-analyze-trends-prevent-crashes": [
    {
      "sections": [
        "Find Build UUIDs for unsymbolicated crashes",
        "View the Build UUID",
        "Binary images example",
        "Find and resymbolicate the dSYM",
        "For more help"
      ],
      "title": "Find Build UUIDs for unsymbolicated crashes",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "e8b926653583d66810c0f68eb6b0111ab3bfc477",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/find-build-uuids-unsymbolicated-crashes/",
      "published_at": "2021-07-02T14:14:31Z",
      "updated_at": "2021-07-02T14:14:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If the dSYM is not uploaded to New Relic, mobile crash reports cannot be symbolicated. You can upload dSYMs manually or directly through the New Relic UI. However, every build of an application will create a new dSYM, and it can be difficult managing which dSYM is attributed to which app build. In this situation, you can use the Build UUID identifier to: Identify a unique build of an application. Find which dSYM can be used to symbolicate a crash. View the Build UUID An application may have more than one Build UUID, one attributed for each CPU architecture the application is built. The Build UUID is also stored within the associated dSYM and can be extracted to identify the dSYM. New Relic crash reports also contain the Build UUID of the crashing application. To view the Build UUID: Go to one.newrelic.com and click Mobile in the top nav. Then find your app and click Crashes > Crash Analysis. From the Crash list table, select any row. From the selected crash report's Crash Details page, look for the App Image Uuid on the attribute list. If the App Image Uuid is not on the selected crash report's attributes list: Export the crash details. Look for the Build UUID in the Binary images section of the exported crash report. Use the Build UUID extracted from the crash details to find the missing dSYM. Binary images example Here is an example of the Binary images section from an exported crash report. This section lists the Build UUID for every dynamically-linked library included in the application, as well as the Build UUID for the main application. In this example, the main application is New Relic. Its Build UUID is 117667e7b8d230cb8a908906c64e0227. This is the identifier you can use to find the associated dSYM. Binary Images: 0xb1000 - 0x30d000 New Relic armv7 < 117667e7b8d230cb8a908906c64e0227 > /var/containers/Bundle/Application/New Relic.app/New Relic 0x22290000 - 0x22292000 libSystem.B.dylib armv7 <39d6d6f7c2ac3de8bb29c40a1b66368a> /usr/lib/libSystem.B.dylib 0x22292000 - 0x222de000 libc++.1.dylib armv7 <017dba6c16b63f9ebecb9ddd0d0a4520> /usr/lib/libc++.1.dylib 0x222de000 - 0x222f9000 libc++abi.dylib armv7 <d32373f6c2153a509f6603750d213ffb> /usr/lib/libc++abi.dylib 0x222fc000 - 0x22667000 libobjc.A.dylib armv7 <94f6d325c1843f45b3a439b86fc9de15> /usr/lib/libobjc.A.dylib 0x22667000 - 0x2266c000 libcache.dylib armv7 <8009f99fb892331dbcb61cd740ff0f43> /usr/lib/system/libcache.dylib 0x2266c000 - 0x22676000 libcommonCrypto.dylib armv7 <f6db318471d732d39918ef36bde65cb7> /usr/lib/system/libcommonCrypto.dylib 0x22676000 - 0x2267c000 libcompiler_rt.dylib armv7 <cfa3ca12d6c2383abcaf3c8541e9b86c> /usr/lib/system/libcompiler_rt.dylib 0x2267c000 - 0x22683000 libcopyfile.dylib armv7 <d2b06020c3693c7b9d179434f8115ba0> /usr/lib/system/libcopyfile.dylib 0x22683000 - 0x226d3000 libcorecrypto.dylib armv7 <181437f8d9e53277ace439de8b3fd1ad> /usr/lib/system/libcorecrypto.dylib 0x226d3000 - 0x2271d000 libdispatch.dylib armv7 <bbb4bba2176039ab95a59d7a56f6eff8> /usr/lib/system/libdispatch.dylib Copy Find and resymbolicate the dSYM To find a dSYM's Build UUID of a dSYM: use dwarfdump with the following terminal command: dwarfdump --uuid <path-to-dSYM> Copy In the following example, the New Relic dSYM returns two Build UUIDs, one each for ARMv7 and ARM64. The ARMv7 Build UUID matches the Build UUID of the missing crash example: > dwarfdump --uuid ./New\\ Relic.app.dSYM/Contents/Resources/DWARF/New\\ Relic UUID: 117667E7-B8D2-30CB-8A90-8906C64E0227 (armv7) ./New Relic.app.dSYM/Contents/Resources/DWARF/New Relic UUID: B1A8C6EE-02B9-3C55-AEE7-308521873107 (arm64) ./New Relic.app.dSYM/Contents/Resources/DWARF/New Relic Copy To symbolicate the unsymbolicated crashes, follow the instructions to manually upload the dSYM. For more help Manual dSYM upload (how to manually upload dSYMs) Retrieve and upload dSYMs (how to locate dSYMs from past app releases)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 319.3726,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Find Build UUIDs for unsymbolicated <em>crashes</em>",
        "sections": "Find Build UUIDs for unsymbolicated <em>crashes</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "If the dSYM is not uploaded to New Relic, <em>mobile</em> <em>crash</em> reports cannot be symbolicated. You can upload dSYMs manually or directly through the New Relic <em>UI</em>. However, every build of an application will create a new dSYM, and it can be difficult managing which dSYM is attributed to which app build"
      },
      "id": "603e9fbae7b9d21cef2a07dd"
    },
    {
      "sections": [
        "Mobile monitoring best practices guide",
        "1. Start collecting data",
        "How to do it",
        "Add your mobile app to New Relic",
        "Install and configure our mobile SDK",
        "2. Explore your data",
        "Analyze, resolve, and prevent crashes",
        "Monitor your key workflows",
        "Get actionable session data",
        "3. Take preventive steps",
        "Metric-based alerts",
        "Event-based alerts",
        "4. Dig deeper into crashes",
        "Crash analysis",
        "Breadcrumbs",
        "Custom attributes",
        "5. Focus on KPIs",
        "Track and query feature use",
        "Measure page load times",
        "Examine data about webpage interactions"
      ],
      "title": "Mobile monitoring best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Full-stack observability"
      ],
      "external_id": "32f5d3919c54c90173721a2cda556d8fd57744f1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/mobile-monitoring-best-practices-guide/",
      "published_at": "2021-07-02T20:13:14Z",
      "updated_at": "2021-07-02T20:13:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "By eliminating crashes and increasing speed across the stack, you can build better performance into every mobile app release. Here are some best practices to take full advantage of mobile monitoring with New Relic. 1. Start collecting data Start collecting data in production. You'll see immediate value by adding our mobile monitoring SDK to your app for its next release to the app store. We recommend installing the iOS or Android agent to your production release even if you're simply testing New Relic's capabilities. This will ensure you'll get an adequate amount of data to really understand all of our mobile monitoring capabilities and your end users' experience. How to do it Add your mobile app to New Relic First, add a new app in New Relic's user interface (full steps): Go to one.newrelic.com and click Mobile. From the list of monitored apps, select Add more. Select the relevant platform. Type a name for your mobile app, and select Continue. Use one app and the associated app token for the development releases of your iOS app, another app and its associated app token for the production releases of that iOS app, and another pair of app tokens for development and production releases of your Android app. You'll be able to compare data from across the four app tokens using our query builder. Install and configure our mobile SDK Next, install and configure the mobile agent: Download the latest version of New Relic's SDK for iOS or Android, and add it to your mobile app. (Full steps for iOS and Android) Configure your installation as needed. For example: Enable the feature flag to capture MobileRequest events to use our full network analysis capabilities for iOS or Android. Automate dSYM uploads for your production builds. To avoid surprises, follow the standard pattern of where you start our mobile agent. In addition, start our agent before you initiate any other SDKs. For more information, see our documentation for Android installation and configuration and for iOS installation and configuration. Deploy a new release of your application. 2. Explore your data Immediately be able to explore your data. As soon as New Relic starts reporting data, take the time to explore the wealth of information about your mobile apps. To get started, go to one.newrelic.com and select Mobile. How to do it Analyze, resolve, and prevent crashes Find the cause of crashes so you can fix them. Then, uncover trends behind crashes so you can prevent them: From the summary UI page for a monitored mobile app, click Crash analysis. Analyze crash data so you can see and fix the most impactful crashes. Follow the breadcrumbs in the crash event trail to fix crashes and resolve critical errors more easily: From your mobile app's Crash analysis page in the UI, select a Crash type. From the crash type's Summary page, select the Crash trail tab. For more information, see our blog post about crash analysis. Monitor your key workflows Create custom breadcrumbs to monitor key workflows (such as your app's login or checkout process), track user clicks, optimize timing, and identify crash locations for faster MTTR. Get actionable session data Borrow from our example queries to: See how much of your user base has upgraded to your latest app version. Track adoption over time. Get a count of new installs as compared to upgrades from an earlier version. See the distribution of usage across geographical locations, carriers, ASN owners (wi-fi providers), devices, connection types, and more. 3. Take preventive steps Use alert notifications to help uncover the causes behind crashes and errors. Once you are running our mobile monitoring capabilities in production and have explored some of the key features, you can use New Relic to uncover critical issues with your mobile application. In particular, focus on crashes and errors. Use metric-based alerts as a starting point to gain high-level visibility into problems. Then, as new services or functionalities are added, use New Relic’s more targeted, event-based (NRQL) alerts to make sure that the most critical issues are handled swiftly. Use these alerts to determine whether a crash is impacting a large number of users. If it is, the relevant people (for example, both the mobile app team’s on-call member and the owner of the related back-end service) will be alerted. Make sure that your team knows how to respond to changes in crash rate (crashes per sessions) and the percentage of users impacted by crashes of your mobile app. How to do it Metric-based alerts Leverage our metric-based alerts and New Relic Mobile UI. Ensure that key members of your mobile team have opted in to receive emails for new crashes. These emails will take you to the crash type in the Mobile UI page for your mobile app. Create an alert for your crash rate threshold that key members of your team can view in Slack or any other Alerts notification channel you choose. Your alert notification will include a link to our UI, where you can examine a chart with the exceeded threshold. From there, a link will take you to the relevant mobile monitoring page, where you can get additional details. Event-based alerts Combine the metric-based workflow with event-based alerts and dashboards specific to your mobile app and system. Create your NRQL alert that focuses on crashes of your most recently released production version. Create an additional NRQL alert that focuses on the percentage of users impacted by crashes in your latest app version (to check the overall impact on your user base). 4. Dig deeper into crashes Take your crash reporting to the next level. Now it’s time to tackle some of those harder-to-reproduce crashes by: Applying additional instrumentation to your application. Leveraging crash event trails, NRQL queries, and dashboards to visualize your data. How to do it Crash analysis Crashes are an inevitable part of running mobile applications at scale. We provide tools to help you understand your highest-impact crashes. Use the Crash analysis UI to see which crashes are occurring most often, the percentage of crash-free users, which files and methods are associated with perhaps 80 percent of your crashes, which crashes a particular user just experienced, and more. Go after high-impact crashes with crash analysis: Add custom attributes to categorize the highest-value customers, and then use them to segment crashes according to your most valuable audiences. Add breadcrumbs and custom events to produce a detailed trail of events leading up to every crash occurrence (over the last 90 days). Then, view this crash event trail in our mobile monitoring UI. Use our mobile monitoring's Versions trends page to make sure you’re improving the crash rate over subsequent releases and avoiding regressions. Breadcrumbs Use breadcrumbs and custom attributes to better reproduce and debug crashes. For example, use our recordBreadrumb API for Android or iOS to track mid-session changes in state that can help debug crashes, such as: Change of connection type Change of orientation CPU and memory state at key points in the app code Custom attributes Add custom attributes to existing events, so you can ask even more precise questions of your mobile app. Add dimensions such as: User ID: Use to react to specific user concerns and to better understand which customers and segments are most impacted. Store ID: Use to address problems with out-of-date devices, bad wi-fi, and so on. User segments: Use to better understand which customers and segments are most impacted; for example, logged in vs. non-logged in. Money in the cart at session end Origin or attribution of entry into the app Standardize custom attribute names across your mobile apps, and align with your website (if monitored by New Relic Browser), so that you can compare and contrast performance across end-user channels. New Relic Mobile tracks the last interaction of crashed and non-crashed sessions to provide visibility into what the user viewed before exiting your app (either intentionally or due to a crash). 5. Focus on KPIs Bring your key performance indicators to life. Create custom interactions and events to hone in on the most important signals, including user activity for the business-critical aspects of your app. Using these powerful APIs, you can add custom instrumentation to just about anything. The following are some example use cases. How to do it Track and query feature use Use custom events to track feature use. For example: Use custom events to track user flow between app and website. Use custom events or mobile breadcrumbs to optimize the performance of key user flows (log in, shopping cart, etc.). use custom events to provide faster, contextualized support experiences for your digital customers. Use the recordCustomEvent API. Then compare the use of different features using: SELECT count(*) FROM MyNewMobileEventType FACET name Copy Measure page load times Use custom events to measure page load time: Create an app-launch timer to measure the time that elapses between a user-tap to launch your app and the point in your app code where the first screen is available. Record the timer value in New Relic using something like the following: recordCustomEvent(<myMobileTimers>, <appLaunch>, {attributes}) Copy Define start and stop timers to measure spinner durations, and then record this time in New Relic using something like the following: recordCustomEvent(<myMobileTimers>, <spinnerOnScreenA>, {attributes}) Copy Track specific user actions or funnel steps in the app (like \"add to cart\"), and include the price as an attribute on that event. Measure flows through the application by viewing the related funnel steps with custom events in Insights. For example, create a timer to track the start and end times of a subflow or an entire flow across multiple funnel steps to understand how long it took users to get through the process. Examine data about webpage interactions Use custom interactions to see traces associated with the same webpages. Use the agent API to disable default interactions, and focus on custom interactions so that you can review the page loads that are most crucial to your primary funnel. Define the start and stop times of these custom interactions to trace activities associated with individual steps of that funnel (for example, a specific user action or a page load). Track the last interactions of crashed and non-crashed sessions so that you can see what the user viewed before exiting your app (either intentionally or from a crash). Example query for non-crashed sessions: SELECT count(*) FROM Mobile WHERE sessionCrashed is null FACET lastInteraction SINCE 90 days ago Copy Example query for crashed sessions: SELECT count(*) FROM Mobile WHERE sessionCrashed is true FACET lastInteraction SINCE 90 days ago Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.61723,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>monitoring</em> best practices guide",
        "sections": "<em>Mobile</em> <em>monitoring</em> best practices guide",
        "body": " event trail in our <em>mobile</em> <em>monitoring</em> <em>UI</em>. Use our <em>mobile</em> <em>monitoring</em>&#x27;s Versions trends page to make sure you’re improving the <em>crash</em> rate over subsequent releases and avoiding regressions. Breadcrumbs Use breadcrumbs and custom attributes to better reproduce and debug <em>crashes</em>. For example, use our"
      },
      "id": "6044151e28ccbc19ab2c60d8"
    },
    {
      "sections": [
        "Introduction to Mobile handled exceptions",
        "Features",
        "Requirements",
        "Tip",
        "Handled exceptions API and event type"
      ],
      "title": "Introduction to Mobile handled exceptions",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "cfdf733d55bb89d157df675fa162b737bdad52c7",
      "image": "https://docs.newrelic.com/static/5891a9437b94b543d81ee04a70ebe876/8c557/mobile-handled-exceptions-ui.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/introduction-mobile-handled-exceptions/",
      "published_at": "2021-07-02T14:15:31Z",
      "updated_at": "2021-05-16T06:28:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Exceptions can contribute to invalid application states, resulting not only in application crashes but also in negative user reviews. This may lead to users deleting your app, which in turn may affect your organization's profitability. With New Relic Mobile's Handled exceptions user interface, mobile development managers and their developer teams can identify significant factors affecting poor mobile app experience, and use filterable data to find a resolution more quickly. Features Handling exceptions as they occur can help improve your mobile app users' experience, but it's not enough to catch exceptions. You also need to know how to prevent them. For example: How many different types of handled exceptions are occurring? A high occurrence rate may necessitate changes to the back-end systems. Why does the user's app usage result in a try/catch? What is the context for the exceptions? When can a test environment's responses to handled exceptions indicate additional, more serious problems? What would have caused a crash if the exception had not been caught in production? What else (in the code or back-end API) is still affecting the users' experience? By using handled exceptions with New Relic Mobile, you can identify and resolve these kinds of issues more quickly. one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: As you explore the wealth of data in the charts and table, use groups and filters to discover patterns that help you determine the root cause of mobile app exceptions. Handled exception features Comments Slice and dice your exception data. New Relic Mobile offers both an API and a user interface to explore the data most important to your business. Use the recordHandledException() method within a try{...} catch(){...} block to help understand how often your application is throwing exceptions, and under what conditions. Use groups and filters to analyze trends leading to the exception. For example, you can group by OS Build, then filter a specific appVersion. Understand a particular user's experience. Examine the percentage charts to see overall trends with users and sessions at a glance. Then, use custom attributes to focus on exceptions related to paid accounts than free accounts. Pinpoint when most exceptions occur. For example, group on Last Interaction to get an overall view of problems. To drill down further, use filters, such as: To examine exceptions caused by network problems, filter by carrier and then select wifi. To examine exceptions caused by app releases, filter by appVersion. Align issues with common characteristics. For example: Use groups and filters to determine whether handled exception trends appear in networks (ASN, carrier, location, etc.) or in devices (device model, manufacturer, operating system build, version, etc.). Explore recurring patterns in stack traces with the top five exception locations table. Query data and share your findings via New Relic Insights. Explore the event trail before and after a crash. With New Relic Mobile you get a more complete picture of events before and after crashes occur, so you can analyze and resolve problems from multiple angles: Use the handled exception's Occurrences page for expected exceptions. Use the Crash analysis UI and event trail for unanticipated exceptions. Requirements Tip Access to this feature depends on your subscription level and mobile data retention. Additional requirements include: Android: New Relic Mobile's Android agent version 5.15.0 or higher iOS: New Relic Mobile's iOS agent version 5.15.0 or higher Handled exceptions API and event type New Relic Mobile automatically includes default attributes that you can use to explore your handled exceptions data in New Relic Insights and get specific details: Use the recordHandledExceptions() method for the Android or iOS SDK API. Query the MobileHandledException event type in Insights. For more information, see the Insights examples for New Relic Mobile. You can also create your own custom attributes and events. Then, select attributes in Mobile's Handled exceptions page, and query or share them in Insights.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 178.96538,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Mobile</em> handled exceptions",
        "sections": "Introduction to <em>Mobile</em> handled exceptions",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " trail before and after a <em>crash</em>. With New Relic <em>Mobile</em> you get a more complete picture of events before and after <em>crashes</em> occur, so you can analyze and resolve problems from multiple angles: Use the handled exception&#x27;s Occurrences page for expected exceptions. Use the <em>Crash</em> analysis <em>UI</em> and event trail"
      },
      "id": "603e7e8228ccbc05f9eba770"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/crashes/handled-exceptions-occurrences": [
    {
      "sections": [
        "Find Build UUIDs for unsymbolicated crashes",
        "View the Build UUID",
        "Binary images example",
        "Find and resymbolicate the dSYM",
        "For more help"
      ],
      "title": "Find Build UUIDs for unsymbolicated crashes",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "e8b926653583d66810c0f68eb6b0111ab3bfc477",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/find-build-uuids-unsymbolicated-crashes/",
      "published_at": "2021-07-02T14:14:31Z",
      "updated_at": "2021-07-02T14:14:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If the dSYM is not uploaded to New Relic, mobile crash reports cannot be symbolicated. You can upload dSYMs manually or directly through the New Relic UI. However, every build of an application will create a new dSYM, and it can be difficult managing which dSYM is attributed to which app build. In this situation, you can use the Build UUID identifier to: Identify a unique build of an application. Find which dSYM can be used to symbolicate a crash. View the Build UUID An application may have more than one Build UUID, one attributed for each CPU architecture the application is built. The Build UUID is also stored within the associated dSYM and can be extracted to identify the dSYM. New Relic crash reports also contain the Build UUID of the crashing application. To view the Build UUID: Go to one.newrelic.com and click Mobile in the top nav. Then find your app and click Crashes > Crash Analysis. From the Crash list table, select any row. From the selected crash report's Crash Details page, look for the App Image Uuid on the attribute list. If the App Image Uuid is not on the selected crash report's attributes list: Export the crash details. Look for the Build UUID in the Binary images section of the exported crash report. Use the Build UUID extracted from the crash details to find the missing dSYM. Binary images example Here is an example of the Binary images section from an exported crash report. This section lists the Build UUID for every dynamically-linked library included in the application, as well as the Build UUID for the main application. In this example, the main application is New Relic. Its Build UUID is 117667e7b8d230cb8a908906c64e0227. This is the identifier you can use to find the associated dSYM. Binary Images: 0xb1000 - 0x30d000 New Relic armv7 < 117667e7b8d230cb8a908906c64e0227 > /var/containers/Bundle/Application/New Relic.app/New Relic 0x22290000 - 0x22292000 libSystem.B.dylib armv7 <39d6d6f7c2ac3de8bb29c40a1b66368a> /usr/lib/libSystem.B.dylib 0x22292000 - 0x222de000 libc++.1.dylib armv7 <017dba6c16b63f9ebecb9ddd0d0a4520> /usr/lib/libc++.1.dylib 0x222de000 - 0x222f9000 libc++abi.dylib armv7 <d32373f6c2153a509f6603750d213ffb> /usr/lib/libc++abi.dylib 0x222fc000 - 0x22667000 libobjc.A.dylib armv7 <94f6d325c1843f45b3a439b86fc9de15> /usr/lib/libobjc.A.dylib 0x22667000 - 0x2266c000 libcache.dylib armv7 <8009f99fb892331dbcb61cd740ff0f43> /usr/lib/system/libcache.dylib 0x2266c000 - 0x22676000 libcommonCrypto.dylib armv7 <f6db318471d732d39918ef36bde65cb7> /usr/lib/system/libcommonCrypto.dylib 0x22676000 - 0x2267c000 libcompiler_rt.dylib armv7 <cfa3ca12d6c2383abcaf3c8541e9b86c> /usr/lib/system/libcompiler_rt.dylib 0x2267c000 - 0x22683000 libcopyfile.dylib armv7 <d2b06020c3693c7b9d179434f8115ba0> /usr/lib/system/libcopyfile.dylib 0x22683000 - 0x226d3000 libcorecrypto.dylib armv7 <181437f8d9e53277ace439de8b3fd1ad> /usr/lib/system/libcorecrypto.dylib 0x226d3000 - 0x2271d000 libdispatch.dylib armv7 <bbb4bba2176039ab95a59d7a56f6eff8> /usr/lib/system/libdispatch.dylib Copy Find and resymbolicate the dSYM To find a dSYM's Build UUID of a dSYM: use dwarfdump with the following terminal command: dwarfdump --uuid <path-to-dSYM> Copy In the following example, the New Relic dSYM returns two Build UUIDs, one each for ARMv7 and ARM64. The ARMv7 Build UUID matches the Build UUID of the missing crash example: > dwarfdump --uuid ./New\\ Relic.app.dSYM/Contents/Resources/DWARF/New\\ Relic UUID: 117667E7-B8D2-30CB-8A90-8906C64E0227 (armv7) ./New Relic.app.dSYM/Contents/Resources/DWARF/New Relic UUID: B1A8C6EE-02B9-3C55-AEE7-308521873107 (arm64) ./New Relic.app.dSYM/Contents/Resources/DWARF/New Relic Copy To symbolicate the unsymbolicated crashes, follow the instructions to manually upload the dSYM. For more help Manual dSYM upload (how to manually upload dSYMs) Retrieve and upload dSYMs (how to locate dSYMs from past app releases)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 319.3726,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Find Build UUIDs for unsymbolicated <em>crashes</em>",
        "sections": "Find Build UUIDs for unsymbolicated <em>crashes</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "If the dSYM is not uploaded to New Relic, <em>mobile</em> <em>crash</em> reports cannot be symbolicated. You can upload dSYMs manually or directly through the New Relic <em>UI</em>. However, every build of an application will create a new dSYM, and it can be difficult managing which dSYM is attributed to which app build"
      },
      "id": "603e9fbae7b9d21cef2a07dd"
    },
    {
      "sections": [
        "Mobile monitoring best practices guide",
        "1. Start collecting data",
        "How to do it",
        "Add your mobile app to New Relic",
        "Install and configure our mobile SDK",
        "2. Explore your data",
        "Analyze, resolve, and prevent crashes",
        "Monitor your key workflows",
        "Get actionable session data",
        "3. Take preventive steps",
        "Metric-based alerts",
        "Event-based alerts",
        "4. Dig deeper into crashes",
        "Crash analysis",
        "Breadcrumbs",
        "Custom attributes",
        "5. Focus on KPIs",
        "Track and query feature use",
        "Measure page load times",
        "Examine data about webpage interactions"
      ],
      "title": "Mobile monitoring best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Full-stack observability"
      ],
      "external_id": "32f5d3919c54c90173721a2cda556d8fd57744f1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/mobile-monitoring-best-practices-guide/",
      "published_at": "2021-07-02T20:13:14Z",
      "updated_at": "2021-07-02T20:13:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "By eliminating crashes and increasing speed across the stack, you can build better performance into every mobile app release. Here are some best practices to take full advantage of mobile monitoring with New Relic. 1. Start collecting data Start collecting data in production. You'll see immediate value by adding our mobile monitoring SDK to your app for its next release to the app store. We recommend installing the iOS or Android agent to your production release even if you're simply testing New Relic's capabilities. This will ensure you'll get an adequate amount of data to really understand all of our mobile monitoring capabilities and your end users' experience. How to do it Add your mobile app to New Relic First, add a new app in New Relic's user interface (full steps): Go to one.newrelic.com and click Mobile. From the list of monitored apps, select Add more. Select the relevant platform. Type a name for your mobile app, and select Continue. Use one app and the associated app token for the development releases of your iOS app, another app and its associated app token for the production releases of that iOS app, and another pair of app tokens for development and production releases of your Android app. You'll be able to compare data from across the four app tokens using our query builder. Install and configure our mobile SDK Next, install and configure the mobile agent: Download the latest version of New Relic's SDK for iOS or Android, and add it to your mobile app. (Full steps for iOS and Android) Configure your installation as needed. For example: Enable the feature flag to capture MobileRequest events to use our full network analysis capabilities for iOS or Android. Automate dSYM uploads for your production builds. To avoid surprises, follow the standard pattern of where you start our mobile agent. In addition, start our agent before you initiate any other SDKs. For more information, see our documentation for Android installation and configuration and for iOS installation and configuration. Deploy a new release of your application. 2. Explore your data Immediately be able to explore your data. As soon as New Relic starts reporting data, take the time to explore the wealth of information about your mobile apps. To get started, go to one.newrelic.com and select Mobile. How to do it Analyze, resolve, and prevent crashes Find the cause of crashes so you can fix them. Then, uncover trends behind crashes so you can prevent them: From the summary UI page for a monitored mobile app, click Crash analysis. Analyze crash data so you can see and fix the most impactful crashes. Follow the breadcrumbs in the crash event trail to fix crashes and resolve critical errors more easily: From your mobile app's Crash analysis page in the UI, select a Crash type. From the crash type's Summary page, select the Crash trail tab. For more information, see our blog post about crash analysis. Monitor your key workflows Create custom breadcrumbs to monitor key workflows (such as your app's login or checkout process), track user clicks, optimize timing, and identify crash locations for faster MTTR. Get actionable session data Borrow from our example queries to: See how much of your user base has upgraded to your latest app version. Track adoption over time. Get a count of new installs as compared to upgrades from an earlier version. See the distribution of usage across geographical locations, carriers, ASN owners (wi-fi providers), devices, connection types, and more. 3. Take preventive steps Use alert notifications to help uncover the causes behind crashes and errors. Once you are running our mobile monitoring capabilities in production and have explored some of the key features, you can use New Relic to uncover critical issues with your mobile application. In particular, focus on crashes and errors. Use metric-based alerts as a starting point to gain high-level visibility into problems. Then, as new services or functionalities are added, use New Relic’s more targeted, event-based (NRQL) alerts to make sure that the most critical issues are handled swiftly. Use these alerts to determine whether a crash is impacting a large number of users. If it is, the relevant people (for example, both the mobile app team’s on-call member and the owner of the related back-end service) will be alerted. Make sure that your team knows how to respond to changes in crash rate (crashes per sessions) and the percentage of users impacted by crashes of your mobile app. How to do it Metric-based alerts Leverage our metric-based alerts and New Relic Mobile UI. Ensure that key members of your mobile team have opted in to receive emails for new crashes. These emails will take you to the crash type in the Mobile UI page for your mobile app. Create an alert for your crash rate threshold that key members of your team can view in Slack or any other Alerts notification channel you choose. Your alert notification will include a link to our UI, where you can examine a chart with the exceeded threshold. From there, a link will take you to the relevant mobile monitoring page, where you can get additional details. Event-based alerts Combine the metric-based workflow with event-based alerts and dashboards specific to your mobile app and system. Create your NRQL alert that focuses on crashes of your most recently released production version. Create an additional NRQL alert that focuses on the percentage of users impacted by crashes in your latest app version (to check the overall impact on your user base). 4. Dig deeper into crashes Take your crash reporting to the next level. Now it’s time to tackle some of those harder-to-reproduce crashes by: Applying additional instrumentation to your application. Leveraging crash event trails, NRQL queries, and dashboards to visualize your data. How to do it Crash analysis Crashes are an inevitable part of running mobile applications at scale. We provide tools to help you understand your highest-impact crashes. Use the Crash analysis UI to see which crashes are occurring most often, the percentage of crash-free users, which files and methods are associated with perhaps 80 percent of your crashes, which crashes a particular user just experienced, and more. Go after high-impact crashes with crash analysis: Add custom attributes to categorize the highest-value customers, and then use them to segment crashes according to your most valuable audiences. Add breadcrumbs and custom events to produce a detailed trail of events leading up to every crash occurrence (over the last 90 days). Then, view this crash event trail in our mobile monitoring UI. Use our mobile monitoring's Versions trends page to make sure you’re improving the crash rate over subsequent releases and avoiding regressions. Breadcrumbs Use breadcrumbs and custom attributes to better reproduce and debug crashes. For example, use our recordBreadrumb API for Android or iOS to track mid-session changes in state that can help debug crashes, such as: Change of connection type Change of orientation CPU and memory state at key points in the app code Custom attributes Add custom attributes to existing events, so you can ask even more precise questions of your mobile app. Add dimensions such as: User ID: Use to react to specific user concerns and to better understand which customers and segments are most impacted. Store ID: Use to address problems with out-of-date devices, bad wi-fi, and so on. User segments: Use to better understand which customers and segments are most impacted; for example, logged in vs. non-logged in. Money in the cart at session end Origin or attribution of entry into the app Standardize custom attribute names across your mobile apps, and align with your website (if monitored by New Relic Browser), so that you can compare and contrast performance across end-user channels. New Relic Mobile tracks the last interaction of crashed and non-crashed sessions to provide visibility into what the user viewed before exiting your app (either intentionally or due to a crash). 5. Focus on KPIs Bring your key performance indicators to life. Create custom interactions and events to hone in on the most important signals, including user activity for the business-critical aspects of your app. Using these powerful APIs, you can add custom instrumentation to just about anything. The following are some example use cases. How to do it Track and query feature use Use custom events to track feature use. For example: Use custom events to track user flow between app and website. Use custom events or mobile breadcrumbs to optimize the performance of key user flows (log in, shopping cart, etc.). use custom events to provide faster, contextualized support experiences for your digital customers. Use the recordCustomEvent API. Then compare the use of different features using: SELECT count(*) FROM MyNewMobileEventType FACET name Copy Measure page load times Use custom events to measure page load time: Create an app-launch timer to measure the time that elapses between a user-tap to launch your app and the point in your app code where the first screen is available. Record the timer value in New Relic using something like the following: recordCustomEvent(<myMobileTimers>, <appLaunch>, {attributes}) Copy Define start and stop timers to measure spinner durations, and then record this time in New Relic using something like the following: recordCustomEvent(<myMobileTimers>, <spinnerOnScreenA>, {attributes}) Copy Track specific user actions or funnel steps in the app (like \"add to cart\"), and include the price as an attribute on that event. Measure flows through the application by viewing the related funnel steps with custom events in Insights. For example, create a timer to track the start and end times of a subflow or an entire flow across multiple funnel steps to understand how long it took users to get through the process. Examine data about webpage interactions Use custom interactions to see traces associated with the same webpages. Use the agent API to disable default interactions, and focus on custom interactions so that you can review the page loads that are most crucial to your primary funnel. Define the start and stop times of these custom interactions to trace activities associated with individual steps of that funnel (for example, a specific user action or a page load). Track the last interactions of crashed and non-crashed sessions so that you can see what the user viewed before exiting your app (either intentionally or from a crash). Example query for non-crashed sessions: SELECT count(*) FROM Mobile WHERE sessionCrashed is null FACET lastInteraction SINCE 90 days ago Copy Example query for crashed sessions: SELECT count(*) FROM Mobile WHERE sessionCrashed is true FACET lastInteraction SINCE 90 days ago Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.61723,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>monitoring</em> best practices guide",
        "sections": "<em>Mobile</em> <em>monitoring</em> best practices guide",
        "body": " event trail in our <em>mobile</em> <em>monitoring</em> <em>UI</em>. Use our <em>mobile</em> <em>monitoring</em>&#x27;s Versions trends page to make sure you’re improving the <em>crash</em> rate over subsequent releases and avoiding regressions. Breadcrumbs Use breadcrumbs and custom attributes to better reproduce and debug <em>crashes</em>. For example, use our"
      },
      "id": "6044151e28ccbc19ab2c60d8"
    },
    {
      "sections": [
        "Introduction to Mobile handled exceptions",
        "Features",
        "Requirements",
        "Tip",
        "Handled exceptions API and event type"
      ],
      "title": "Introduction to Mobile handled exceptions",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "cfdf733d55bb89d157df675fa162b737bdad52c7",
      "image": "https://docs.newrelic.com/static/5891a9437b94b543d81ee04a70ebe876/8c557/mobile-handled-exceptions-ui.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/introduction-mobile-handled-exceptions/",
      "published_at": "2021-07-02T14:15:31Z",
      "updated_at": "2021-05-16T06:28:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Exceptions can contribute to invalid application states, resulting not only in application crashes but also in negative user reviews. This may lead to users deleting your app, which in turn may affect your organization's profitability. With New Relic Mobile's Handled exceptions user interface, mobile development managers and their developer teams can identify significant factors affecting poor mobile app experience, and use filterable data to find a resolution more quickly. Features Handling exceptions as they occur can help improve your mobile app users' experience, but it's not enough to catch exceptions. You also need to know how to prevent them. For example: How many different types of handled exceptions are occurring? A high occurrence rate may necessitate changes to the back-end systems. Why does the user's app usage result in a try/catch? What is the context for the exceptions? When can a test environment's responses to handled exceptions indicate additional, more serious problems? What would have caused a crash if the exception had not been caught in production? What else (in the code or back-end API) is still affecting the users' experience? By using handled exceptions with New Relic Mobile, you can identify and resolve these kinds of issues more quickly. one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: As you explore the wealth of data in the charts and table, use groups and filters to discover patterns that help you determine the root cause of mobile app exceptions. Handled exception features Comments Slice and dice your exception data. New Relic Mobile offers both an API and a user interface to explore the data most important to your business. Use the recordHandledException() method within a try{...} catch(){...} block to help understand how often your application is throwing exceptions, and under what conditions. Use groups and filters to analyze trends leading to the exception. For example, you can group by OS Build, then filter a specific appVersion. Understand a particular user's experience. Examine the percentage charts to see overall trends with users and sessions at a glance. Then, use custom attributes to focus on exceptions related to paid accounts than free accounts. Pinpoint when most exceptions occur. For example, group on Last Interaction to get an overall view of problems. To drill down further, use filters, such as: To examine exceptions caused by network problems, filter by carrier and then select wifi. To examine exceptions caused by app releases, filter by appVersion. Align issues with common characteristics. For example: Use groups and filters to determine whether handled exception trends appear in networks (ASN, carrier, location, etc.) or in devices (device model, manufacturer, operating system build, version, etc.). Explore recurring patterns in stack traces with the top five exception locations table. Query data and share your findings via New Relic Insights. Explore the event trail before and after a crash. With New Relic Mobile you get a more complete picture of events before and after crashes occur, so you can analyze and resolve problems from multiple angles: Use the handled exception's Occurrences page for expected exceptions. Use the Crash analysis UI and event trail for unanticipated exceptions. Requirements Tip Access to this feature depends on your subscription level and mobile data retention. Additional requirements include: Android: New Relic Mobile's Android agent version 5.15.0 or higher iOS: New Relic Mobile's iOS agent version 5.15.0 or higher Handled exceptions API and event type New Relic Mobile automatically includes default attributes that you can use to explore your handled exceptions data in New Relic Insights and get specific details: Use the recordHandledExceptions() method for the Android or iOS SDK API. Query the MobileHandledException event type in Insights. For more information, see the Insights examples for New Relic Mobile. You can also create your own custom attributes and events. Then, select attributes in Mobile's Handled exceptions page, and query or share them in Insights.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 178.96538,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Mobile</em> handled exceptions",
        "sections": "Introduction to <em>Mobile</em> handled exceptions",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " trail before and after a <em>crash</em>. With New Relic <em>Mobile</em> you get a more complete picture of events before and after <em>crashes</em> occur, so you can analyze and resolve problems from multiple angles: Use the handled exception&#x27;s Occurrences page for expected exceptions. Use the <em>Crash</em> analysis <em>UI</em> and event trail"
      },
      "id": "603e7e8228ccbc05f9eba770"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/crashes/introduction-mobile-handled-exceptions": [
    {
      "sections": [
        "Find Build UUIDs for unsymbolicated crashes",
        "View the Build UUID",
        "Binary images example",
        "Find and resymbolicate the dSYM",
        "For more help"
      ],
      "title": "Find Build UUIDs for unsymbolicated crashes",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "e8b926653583d66810c0f68eb6b0111ab3bfc477",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/find-build-uuids-unsymbolicated-crashes/",
      "published_at": "2021-07-02T14:14:31Z",
      "updated_at": "2021-07-02T14:14:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If the dSYM is not uploaded to New Relic, mobile crash reports cannot be symbolicated. You can upload dSYMs manually or directly through the New Relic UI. However, every build of an application will create a new dSYM, and it can be difficult managing which dSYM is attributed to which app build. In this situation, you can use the Build UUID identifier to: Identify a unique build of an application. Find which dSYM can be used to symbolicate a crash. View the Build UUID An application may have more than one Build UUID, one attributed for each CPU architecture the application is built. The Build UUID is also stored within the associated dSYM and can be extracted to identify the dSYM. New Relic crash reports also contain the Build UUID of the crashing application. To view the Build UUID: Go to one.newrelic.com and click Mobile in the top nav. Then find your app and click Crashes > Crash Analysis. From the Crash list table, select any row. From the selected crash report's Crash Details page, look for the App Image Uuid on the attribute list. If the App Image Uuid is not on the selected crash report's attributes list: Export the crash details. Look for the Build UUID in the Binary images section of the exported crash report. Use the Build UUID extracted from the crash details to find the missing dSYM. Binary images example Here is an example of the Binary images section from an exported crash report. This section lists the Build UUID for every dynamically-linked library included in the application, as well as the Build UUID for the main application. In this example, the main application is New Relic. Its Build UUID is 117667e7b8d230cb8a908906c64e0227. This is the identifier you can use to find the associated dSYM. Binary Images: 0xb1000 - 0x30d000 New Relic armv7 < 117667e7b8d230cb8a908906c64e0227 > /var/containers/Bundle/Application/New Relic.app/New Relic 0x22290000 - 0x22292000 libSystem.B.dylib armv7 <39d6d6f7c2ac3de8bb29c40a1b66368a> /usr/lib/libSystem.B.dylib 0x22292000 - 0x222de000 libc++.1.dylib armv7 <017dba6c16b63f9ebecb9ddd0d0a4520> /usr/lib/libc++.1.dylib 0x222de000 - 0x222f9000 libc++abi.dylib armv7 <d32373f6c2153a509f6603750d213ffb> /usr/lib/libc++abi.dylib 0x222fc000 - 0x22667000 libobjc.A.dylib armv7 <94f6d325c1843f45b3a439b86fc9de15> /usr/lib/libobjc.A.dylib 0x22667000 - 0x2266c000 libcache.dylib armv7 <8009f99fb892331dbcb61cd740ff0f43> /usr/lib/system/libcache.dylib 0x2266c000 - 0x22676000 libcommonCrypto.dylib armv7 <f6db318471d732d39918ef36bde65cb7> /usr/lib/system/libcommonCrypto.dylib 0x22676000 - 0x2267c000 libcompiler_rt.dylib armv7 <cfa3ca12d6c2383abcaf3c8541e9b86c> /usr/lib/system/libcompiler_rt.dylib 0x2267c000 - 0x22683000 libcopyfile.dylib armv7 <d2b06020c3693c7b9d179434f8115ba0> /usr/lib/system/libcopyfile.dylib 0x22683000 - 0x226d3000 libcorecrypto.dylib armv7 <181437f8d9e53277ace439de8b3fd1ad> /usr/lib/system/libcorecrypto.dylib 0x226d3000 - 0x2271d000 libdispatch.dylib armv7 <bbb4bba2176039ab95a59d7a56f6eff8> /usr/lib/system/libdispatch.dylib Copy Find and resymbolicate the dSYM To find a dSYM's Build UUID of a dSYM: use dwarfdump with the following terminal command: dwarfdump --uuid <path-to-dSYM> Copy In the following example, the New Relic dSYM returns two Build UUIDs, one each for ARMv7 and ARM64. The ARMv7 Build UUID matches the Build UUID of the missing crash example: > dwarfdump --uuid ./New\\ Relic.app.dSYM/Contents/Resources/DWARF/New\\ Relic UUID: 117667E7-B8D2-30CB-8A90-8906C64E0227 (armv7) ./New Relic.app.dSYM/Contents/Resources/DWARF/New Relic UUID: B1A8C6EE-02B9-3C55-AEE7-308521873107 (arm64) ./New Relic.app.dSYM/Contents/Resources/DWARF/New Relic Copy To symbolicate the unsymbolicated crashes, follow the instructions to manually upload the dSYM. For more help Manual dSYM upload (how to manually upload dSYMs) Retrieve and upload dSYMs (how to locate dSYMs from past app releases)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 319.37238,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Find Build UUIDs for unsymbolicated <em>crashes</em>",
        "sections": "Find Build UUIDs for unsymbolicated <em>crashes</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "If the dSYM is not uploaded to New Relic, <em>mobile</em> <em>crash</em> reports cannot be symbolicated. You can upload dSYMs manually or directly through the New Relic <em>UI</em>. However, every build of an application will create a new dSYM, and it can be difficult managing which dSYM is attributed to which app build"
      },
      "id": "603e9fbae7b9d21cef2a07dd"
    },
    {
      "sections": [
        "Mobile monitoring best practices guide",
        "1. Start collecting data",
        "How to do it",
        "Add your mobile app to New Relic",
        "Install and configure our mobile SDK",
        "2. Explore your data",
        "Analyze, resolve, and prevent crashes",
        "Monitor your key workflows",
        "Get actionable session data",
        "3. Take preventive steps",
        "Metric-based alerts",
        "Event-based alerts",
        "4. Dig deeper into crashes",
        "Crash analysis",
        "Breadcrumbs",
        "Custom attributes",
        "5. Focus on KPIs",
        "Track and query feature use",
        "Measure page load times",
        "Examine data about webpage interactions"
      ],
      "title": "Mobile monitoring best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Full-stack observability"
      ],
      "external_id": "32f5d3919c54c90173721a2cda556d8fd57744f1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/mobile-monitoring-best-practices-guide/",
      "published_at": "2021-07-02T20:13:14Z",
      "updated_at": "2021-07-02T20:13:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "By eliminating crashes and increasing speed across the stack, you can build better performance into every mobile app release. Here are some best practices to take full advantage of mobile monitoring with New Relic. 1. Start collecting data Start collecting data in production. You'll see immediate value by adding our mobile monitoring SDK to your app for its next release to the app store. We recommend installing the iOS or Android agent to your production release even if you're simply testing New Relic's capabilities. This will ensure you'll get an adequate amount of data to really understand all of our mobile monitoring capabilities and your end users' experience. How to do it Add your mobile app to New Relic First, add a new app in New Relic's user interface (full steps): Go to one.newrelic.com and click Mobile. From the list of monitored apps, select Add more. Select the relevant platform. Type a name for your mobile app, and select Continue. Use one app and the associated app token for the development releases of your iOS app, another app and its associated app token for the production releases of that iOS app, and another pair of app tokens for development and production releases of your Android app. You'll be able to compare data from across the four app tokens using our query builder. Install and configure our mobile SDK Next, install and configure the mobile agent: Download the latest version of New Relic's SDK for iOS or Android, and add it to your mobile app. (Full steps for iOS and Android) Configure your installation as needed. For example: Enable the feature flag to capture MobileRequest events to use our full network analysis capabilities for iOS or Android. Automate dSYM uploads for your production builds. To avoid surprises, follow the standard pattern of where you start our mobile agent. In addition, start our agent before you initiate any other SDKs. For more information, see our documentation for Android installation and configuration and for iOS installation and configuration. Deploy a new release of your application. 2. Explore your data Immediately be able to explore your data. As soon as New Relic starts reporting data, take the time to explore the wealth of information about your mobile apps. To get started, go to one.newrelic.com and select Mobile. How to do it Analyze, resolve, and prevent crashes Find the cause of crashes so you can fix them. Then, uncover trends behind crashes so you can prevent them: From the summary UI page for a monitored mobile app, click Crash analysis. Analyze crash data so you can see and fix the most impactful crashes. Follow the breadcrumbs in the crash event trail to fix crashes and resolve critical errors more easily: From your mobile app's Crash analysis page in the UI, select a Crash type. From the crash type's Summary page, select the Crash trail tab. For more information, see our blog post about crash analysis. Monitor your key workflows Create custom breadcrumbs to monitor key workflows (such as your app's login or checkout process), track user clicks, optimize timing, and identify crash locations for faster MTTR. Get actionable session data Borrow from our example queries to: See how much of your user base has upgraded to your latest app version. Track adoption over time. Get a count of new installs as compared to upgrades from an earlier version. See the distribution of usage across geographical locations, carriers, ASN owners (wi-fi providers), devices, connection types, and more. 3. Take preventive steps Use alert notifications to help uncover the causes behind crashes and errors. Once you are running our mobile monitoring capabilities in production and have explored some of the key features, you can use New Relic to uncover critical issues with your mobile application. In particular, focus on crashes and errors. Use metric-based alerts as a starting point to gain high-level visibility into problems. Then, as new services or functionalities are added, use New Relic’s more targeted, event-based (NRQL) alerts to make sure that the most critical issues are handled swiftly. Use these alerts to determine whether a crash is impacting a large number of users. If it is, the relevant people (for example, both the mobile app team’s on-call member and the owner of the related back-end service) will be alerted. Make sure that your team knows how to respond to changes in crash rate (crashes per sessions) and the percentage of users impacted by crashes of your mobile app. How to do it Metric-based alerts Leverage our metric-based alerts and New Relic Mobile UI. Ensure that key members of your mobile team have opted in to receive emails for new crashes. These emails will take you to the crash type in the Mobile UI page for your mobile app. Create an alert for your crash rate threshold that key members of your team can view in Slack or any other Alerts notification channel you choose. Your alert notification will include a link to our UI, where you can examine a chart with the exceeded threshold. From there, a link will take you to the relevant mobile monitoring page, where you can get additional details. Event-based alerts Combine the metric-based workflow with event-based alerts and dashboards specific to your mobile app and system. Create your NRQL alert that focuses on crashes of your most recently released production version. Create an additional NRQL alert that focuses on the percentage of users impacted by crashes in your latest app version (to check the overall impact on your user base). 4. Dig deeper into crashes Take your crash reporting to the next level. Now it’s time to tackle some of those harder-to-reproduce crashes by: Applying additional instrumentation to your application. Leveraging crash event trails, NRQL queries, and dashboards to visualize your data. How to do it Crash analysis Crashes are an inevitable part of running mobile applications at scale. We provide tools to help you understand your highest-impact crashes. Use the Crash analysis UI to see which crashes are occurring most often, the percentage of crash-free users, which files and methods are associated with perhaps 80 percent of your crashes, which crashes a particular user just experienced, and more. Go after high-impact crashes with crash analysis: Add custom attributes to categorize the highest-value customers, and then use them to segment crashes according to your most valuable audiences. Add breadcrumbs and custom events to produce a detailed trail of events leading up to every crash occurrence (over the last 90 days). Then, view this crash event trail in our mobile monitoring UI. Use our mobile monitoring's Versions trends page to make sure you’re improving the crash rate over subsequent releases and avoiding regressions. Breadcrumbs Use breadcrumbs and custom attributes to better reproduce and debug crashes. For example, use our recordBreadrumb API for Android or iOS to track mid-session changes in state that can help debug crashes, such as: Change of connection type Change of orientation CPU and memory state at key points in the app code Custom attributes Add custom attributes to existing events, so you can ask even more precise questions of your mobile app. Add dimensions such as: User ID: Use to react to specific user concerns and to better understand which customers and segments are most impacted. Store ID: Use to address problems with out-of-date devices, bad wi-fi, and so on. User segments: Use to better understand which customers and segments are most impacted; for example, logged in vs. non-logged in. Money in the cart at session end Origin or attribution of entry into the app Standardize custom attribute names across your mobile apps, and align with your website (if monitored by New Relic Browser), so that you can compare and contrast performance across end-user channels. New Relic Mobile tracks the last interaction of crashed and non-crashed sessions to provide visibility into what the user viewed before exiting your app (either intentionally or due to a crash). 5. Focus on KPIs Bring your key performance indicators to life. Create custom interactions and events to hone in on the most important signals, including user activity for the business-critical aspects of your app. Using these powerful APIs, you can add custom instrumentation to just about anything. The following are some example use cases. How to do it Track and query feature use Use custom events to track feature use. For example: Use custom events to track user flow between app and website. Use custom events or mobile breadcrumbs to optimize the performance of key user flows (log in, shopping cart, etc.). use custom events to provide faster, contextualized support experiences for your digital customers. Use the recordCustomEvent API. Then compare the use of different features using: SELECT count(*) FROM MyNewMobileEventType FACET name Copy Measure page load times Use custom events to measure page load time: Create an app-launch timer to measure the time that elapses between a user-tap to launch your app and the point in your app code where the first screen is available. Record the timer value in New Relic using something like the following: recordCustomEvent(<myMobileTimers>, <appLaunch>, {attributes}) Copy Define start and stop timers to measure spinner durations, and then record this time in New Relic using something like the following: recordCustomEvent(<myMobileTimers>, <spinnerOnScreenA>, {attributes}) Copy Track specific user actions or funnel steps in the app (like \"add to cart\"), and include the price as an attribute on that event. Measure flows through the application by viewing the related funnel steps with custom events in Insights. For example, create a timer to track the start and end times of a subflow or an entire flow across multiple funnel steps to understand how long it took users to get through the process. Examine data about webpage interactions Use custom interactions to see traces associated with the same webpages. Use the agent API to disable default interactions, and focus on custom interactions so that you can review the page loads that are most crucial to your primary funnel. Define the start and stop times of these custom interactions to trace activities associated with individual steps of that funnel (for example, a specific user action or a page load). Track the last interactions of crashed and non-crashed sessions so that you can see what the user viewed before exiting your app (either intentionally or from a crash). Example query for non-crashed sessions: SELECT count(*) FROM Mobile WHERE sessionCrashed is null FACET lastInteraction SINCE 90 days ago Copy Example query for crashed sessions: SELECT count(*) FROM Mobile WHERE sessionCrashed is true FACET lastInteraction SINCE 90 days ago Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.6171,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>monitoring</em> best practices guide",
        "sections": "<em>Mobile</em> <em>monitoring</em> best practices guide",
        "body": " event trail in our <em>mobile</em> <em>monitoring</em> <em>UI</em>. Use our <em>mobile</em> <em>monitoring</em>&#x27;s Versions trends page to make sure you’re improving the <em>crash</em> rate over subsequent releases and avoiding regressions. Breadcrumbs Use breadcrumbs and custom attributes to better reproduce and debug <em>crashes</em>. For example, use our"
      },
      "id": "6044151e28ccbc19ab2c60d8"
    },
    {
      "sections": [
        "Mobile crash event trail",
        "Tip",
        "View events before mobile app crashes",
        "Use the event trail",
        "Difference between event trail and interaction trail"
      ],
      "title": "Mobile crash event trail",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "58795d499c8db6d8cc95bd6d2c645e970ea10d83",
      "image": "https://docs.newrelic.com/static/3731efca2d88ed92cc150d5f6c06830a/0d6fe/New-Relic-Mobile-crash-event-trail.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/mobile-crash-event-trail/",
      "published_at": "2021-07-02T14:15:31Z",
      "updated_at": "2021-05-16T06:28:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Mobile crash event trail shows you the events leading up to a crash of a mobile app, based on your subscription level's data retention policy. These can be events New Relic monitors by default, or custom events you created in New Relic Insights. This document explains what the crash event trail is and how to use it. Tip Access to this feature depends on your subscription level. View events before mobile app crashes When a mobile app crashes and you don't know why, you can study what happened right before the crash. New Relic Mobile's crash event trail shows you these events so that you can follow the \"breadcrumbs\" leading up to the crash and diagnose the cause of the failure. one.newrelic.com > Mobile > (select a mobile app) > Crash analysis > (selected crash type) > Event trail: The crash event trail shows the activity leading up to a mobile app crash. The crash event trail shows all New Relic Mobile event types leading up to a crash. You can use New Relic Mobile's iOS SDK or Android SDK to create custom MobileBreadcrumb events that track whatever app activity you think would help you diagnose a crash. You can also use MobileHandledException events in the crash event trail to aid in debugging. Use the iOS and Android recordHandledException APIs for iOS or Android to annotate where exceptions are handled in your application. These events will automatically appear in the crash event trail. For more about annotating crash event trails with custom data, see Add custom data to New Relic Mobile. Use the event trail To use the New Relic Mobile crash event trail: Go to one.newrelic.com > Mobile > (select a mobile app) > Crash analysis. On the lower right side of the Crash analysis page, select a crash type. On the Crash details page, beside the stack trace, select Event trail. Study the events leading up to a crash type for clues to the reasons for the crash. To expand details about an event's attributes, select it. To view the event trail results in New Relic Insights, select Open session in Insights. To scroll through occurrences of the same crash type, use the event trail's left and right arrows. For optimal use of New Relic's crash analysis tools, use: New Relic Mobile's Android SDK API or iOS SDK API to create custom MobileBreadcrumb or MobileHandledException events Enable MobileRequest events New Relic Mobile's Crash analysis page New Relic Mobile's Interaction trail New Relic Insights queries of your crash event data New Relic Insights dashboards Difference between event trail and interaction trail The crash event trail is different from the interaction trail. The crash event trail shows all New Relic Mobile event types leading up to a crash, whereas the interaction trail only shows interaction event types (Mobile events with the category interaction). The interaction trail has additional features, including stack traces and links to the associated interaction charts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 178.96538,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>crash</em> event trail",
        "sections": "View events before <em>mobile</em> app <em>crashes</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " event trail is and how to use it. Tip Access to this feature depends on your subscription level. View events before <em>mobile</em> app <em>crashes</em> When a <em>mobile</em> app <em>crashes</em> and you don&#x27;t know why, you can study what happened right before the <em>crash</em>. New Relic <em>Mobile</em>&#x27;s <em>crash</em> event trail shows you these events so"
      },
      "id": "604503b1e7b9d201e75799bb"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/crashes/investigate-mobile-app-crash-report": [
    {
      "sections": [
        "Find Build UUIDs for unsymbolicated crashes",
        "View the Build UUID",
        "Binary images example",
        "Find and resymbolicate the dSYM",
        "For more help"
      ],
      "title": "Find Build UUIDs for unsymbolicated crashes",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "e8b926653583d66810c0f68eb6b0111ab3bfc477",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/find-build-uuids-unsymbolicated-crashes/",
      "published_at": "2021-07-02T14:14:31Z",
      "updated_at": "2021-07-02T14:14:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If the dSYM is not uploaded to New Relic, mobile crash reports cannot be symbolicated. You can upload dSYMs manually or directly through the New Relic UI. However, every build of an application will create a new dSYM, and it can be difficult managing which dSYM is attributed to which app build. In this situation, you can use the Build UUID identifier to: Identify a unique build of an application. Find which dSYM can be used to symbolicate a crash. View the Build UUID An application may have more than one Build UUID, one attributed for each CPU architecture the application is built. The Build UUID is also stored within the associated dSYM and can be extracted to identify the dSYM. New Relic crash reports also contain the Build UUID of the crashing application. To view the Build UUID: Go to one.newrelic.com and click Mobile in the top nav. Then find your app and click Crashes > Crash Analysis. From the Crash list table, select any row. From the selected crash report's Crash Details page, look for the App Image Uuid on the attribute list. If the App Image Uuid is not on the selected crash report's attributes list: Export the crash details. Look for the Build UUID in the Binary images section of the exported crash report. Use the Build UUID extracted from the crash details to find the missing dSYM. Binary images example Here is an example of the Binary images section from an exported crash report. This section lists the Build UUID for every dynamically-linked library included in the application, as well as the Build UUID for the main application. In this example, the main application is New Relic. Its Build UUID is 117667e7b8d230cb8a908906c64e0227. This is the identifier you can use to find the associated dSYM. Binary Images: 0xb1000 - 0x30d000 New Relic armv7 < 117667e7b8d230cb8a908906c64e0227 > /var/containers/Bundle/Application/New Relic.app/New Relic 0x22290000 - 0x22292000 libSystem.B.dylib armv7 <39d6d6f7c2ac3de8bb29c40a1b66368a> /usr/lib/libSystem.B.dylib 0x22292000 - 0x222de000 libc++.1.dylib armv7 <017dba6c16b63f9ebecb9ddd0d0a4520> /usr/lib/libc++.1.dylib 0x222de000 - 0x222f9000 libc++abi.dylib armv7 <d32373f6c2153a509f6603750d213ffb> /usr/lib/libc++abi.dylib 0x222fc000 - 0x22667000 libobjc.A.dylib armv7 <94f6d325c1843f45b3a439b86fc9de15> /usr/lib/libobjc.A.dylib 0x22667000 - 0x2266c000 libcache.dylib armv7 <8009f99fb892331dbcb61cd740ff0f43> /usr/lib/system/libcache.dylib 0x2266c000 - 0x22676000 libcommonCrypto.dylib armv7 <f6db318471d732d39918ef36bde65cb7> /usr/lib/system/libcommonCrypto.dylib 0x22676000 - 0x2267c000 libcompiler_rt.dylib armv7 <cfa3ca12d6c2383abcaf3c8541e9b86c> /usr/lib/system/libcompiler_rt.dylib 0x2267c000 - 0x22683000 libcopyfile.dylib armv7 <d2b06020c3693c7b9d179434f8115ba0> /usr/lib/system/libcopyfile.dylib 0x22683000 - 0x226d3000 libcorecrypto.dylib armv7 <181437f8d9e53277ace439de8b3fd1ad> /usr/lib/system/libcorecrypto.dylib 0x226d3000 - 0x2271d000 libdispatch.dylib armv7 <bbb4bba2176039ab95a59d7a56f6eff8> /usr/lib/system/libdispatch.dylib Copy Find and resymbolicate the dSYM To find a dSYM's Build UUID of a dSYM: use dwarfdump with the following terminal command: dwarfdump --uuid <path-to-dSYM> Copy In the following example, the New Relic dSYM returns two Build UUIDs, one each for ARMv7 and ARM64. The ARMv7 Build UUID matches the Build UUID of the missing crash example: > dwarfdump --uuid ./New\\ Relic.app.dSYM/Contents/Resources/DWARF/New\\ Relic UUID: 117667E7-B8D2-30CB-8A90-8906C64E0227 (armv7) ./New Relic.app.dSYM/Contents/Resources/DWARF/New Relic UUID: B1A8C6EE-02B9-3C55-AEE7-308521873107 (arm64) ./New Relic.app.dSYM/Contents/Resources/DWARF/New Relic Copy To symbolicate the unsymbolicated crashes, follow the instructions to manually upload the dSYM. For more help Manual dSYM upload (how to manually upload dSYMs) Retrieve and upload dSYMs (how to locate dSYMs from past app releases)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 319.37238,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Find Build UUIDs for unsymbolicated <em>crashes</em>",
        "sections": "Find Build UUIDs for unsymbolicated <em>crashes</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "If the dSYM is not uploaded to New Relic, <em>mobile</em> <em>crash</em> reports cannot be symbolicated. You can upload dSYMs manually or directly through the New Relic <em>UI</em>. However, every build of an application will create a new dSYM, and it can be difficult managing which dSYM is attributed to which app build"
      },
      "id": "603e9fbae7b9d21cef2a07dd"
    },
    {
      "sections": [
        "Mobile monitoring best practices guide",
        "1. Start collecting data",
        "How to do it",
        "Add your mobile app to New Relic",
        "Install and configure our mobile SDK",
        "2. Explore your data",
        "Analyze, resolve, and prevent crashes",
        "Monitor your key workflows",
        "Get actionable session data",
        "3. Take preventive steps",
        "Metric-based alerts",
        "Event-based alerts",
        "4. Dig deeper into crashes",
        "Crash analysis",
        "Breadcrumbs",
        "Custom attributes",
        "5. Focus on KPIs",
        "Track and query feature use",
        "Measure page load times",
        "Examine data about webpage interactions"
      ],
      "title": "Mobile monitoring best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Full-stack observability"
      ],
      "external_id": "32f5d3919c54c90173721a2cda556d8fd57744f1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/mobile-monitoring-best-practices-guide/",
      "published_at": "2021-07-02T20:13:14Z",
      "updated_at": "2021-07-02T20:13:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "By eliminating crashes and increasing speed across the stack, you can build better performance into every mobile app release. Here are some best practices to take full advantage of mobile monitoring with New Relic. 1. Start collecting data Start collecting data in production. You'll see immediate value by adding our mobile monitoring SDK to your app for its next release to the app store. We recommend installing the iOS or Android agent to your production release even if you're simply testing New Relic's capabilities. This will ensure you'll get an adequate amount of data to really understand all of our mobile monitoring capabilities and your end users' experience. How to do it Add your mobile app to New Relic First, add a new app in New Relic's user interface (full steps): Go to one.newrelic.com and click Mobile. From the list of monitored apps, select Add more. Select the relevant platform. Type a name for your mobile app, and select Continue. Use one app and the associated app token for the development releases of your iOS app, another app and its associated app token for the production releases of that iOS app, and another pair of app tokens for development and production releases of your Android app. You'll be able to compare data from across the four app tokens using our query builder. Install and configure our mobile SDK Next, install and configure the mobile agent: Download the latest version of New Relic's SDK for iOS or Android, and add it to your mobile app. (Full steps for iOS and Android) Configure your installation as needed. For example: Enable the feature flag to capture MobileRequest events to use our full network analysis capabilities for iOS or Android. Automate dSYM uploads for your production builds. To avoid surprises, follow the standard pattern of where you start our mobile agent. In addition, start our agent before you initiate any other SDKs. For more information, see our documentation for Android installation and configuration and for iOS installation and configuration. Deploy a new release of your application. 2. Explore your data Immediately be able to explore your data. As soon as New Relic starts reporting data, take the time to explore the wealth of information about your mobile apps. To get started, go to one.newrelic.com and select Mobile. How to do it Analyze, resolve, and prevent crashes Find the cause of crashes so you can fix them. Then, uncover trends behind crashes so you can prevent them: From the summary UI page for a monitored mobile app, click Crash analysis. Analyze crash data so you can see and fix the most impactful crashes. Follow the breadcrumbs in the crash event trail to fix crashes and resolve critical errors more easily: From your mobile app's Crash analysis page in the UI, select a Crash type. From the crash type's Summary page, select the Crash trail tab. For more information, see our blog post about crash analysis. Monitor your key workflows Create custom breadcrumbs to monitor key workflows (such as your app's login or checkout process), track user clicks, optimize timing, and identify crash locations for faster MTTR. Get actionable session data Borrow from our example queries to: See how much of your user base has upgraded to your latest app version. Track adoption over time. Get a count of new installs as compared to upgrades from an earlier version. See the distribution of usage across geographical locations, carriers, ASN owners (wi-fi providers), devices, connection types, and more. 3. Take preventive steps Use alert notifications to help uncover the causes behind crashes and errors. Once you are running our mobile monitoring capabilities in production and have explored some of the key features, you can use New Relic to uncover critical issues with your mobile application. In particular, focus on crashes and errors. Use metric-based alerts as a starting point to gain high-level visibility into problems. Then, as new services or functionalities are added, use New Relic’s more targeted, event-based (NRQL) alerts to make sure that the most critical issues are handled swiftly. Use these alerts to determine whether a crash is impacting a large number of users. If it is, the relevant people (for example, both the mobile app team’s on-call member and the owner of the related back-end service) will be alerted. Make sure that your team knows how to respond to changes in crash rate (crashes per sessions) and the percentage of users impacted by crashes of your mobile app. How to do it Metric-based alerts Leverage our metric-based alerts and New Relic Mobile UI. Ensure that key members of your mobile team have opted in to receive emails for new crashes. These emails will take you to the crash type in the Mobile UI page for your mobile app. Create an alert for your crash rate threshold that key members of your team can view in Slack or any other Alerts notification channel you choose. Your alert notification will include a link to our UI, where you can examine a chart with the exceeded threshold. From there, a link will take you to the relevant mobile monitoring page, where you can get additional details. Event-based alerts Combine the metric-based workflow with event-based alerts and dashboards specific to your mobile app and system. Create your NRQL alert that focuses on crashes of your most recently released production version. Create an additional NRQL alert that focuses on the percentage of users impacted by crashes in your latest app version (to check the overall impact on your user base). 4. Dig deeper into crashes Take your crash reporting to the next level. Now it’s time to tackle some of those harder-to-reproduce crashes by: Applying additional instrumentation to your application. Leveraging crash event trails, NRQL queries, and dashboards to visualize your data. How to do it Crash analysis Crashes are an inevitable part of running mobile applications at scale. We provide tools to help you understand your highest-impact crashes. Use the Crash analysis UI to see which crashes are occurring most often, the percentage of crash-free users, which files and methods are associated with perhaps 80 percent of your crashes, which crashes a particular user just experienced, and more. Go after high-impact crashes with crash analysis: Add custom attributes to categorize the highest-value customers, and then use them to segment crashes according to your most valuable audiences. Add breadcrumbs and custom events to produce a detailed trail of events leading up to every crash occurrence (over the last 90 days). Then, view this crash event trail in our mobile monitoring UI. Use our mobile monitoring's Versions trends page to make sure you’re improving the crash rate over subsequent releases and avoiding regressions. Breadcrumbs Use breadcrumbs and custom attributes to better reproduce and debug crashes. For example, use our recordBreadrumb API for Android or iOS to track mid-session changes in state that can help debug crashes, such as: Change of connection type Change of orientation CPU and memory state at key points in the app code Custom attributes Add custom attributes to existing events, so you can ask even more precise questions of your mobile app. Add dimensions such as: User ID: Use to react to specific user concerns and to better understand which customers and segments are most impacted. Store ID: Use to address problems with out-of-date devices, bad wi-fi, and so on. User segments: Use to better understand which customers and segments are most impacted; for example, logged in vs. non-logged in. Money in the cart at session end Origin or attribution of entry into the app Standardize custom attribute names across your mobile apps, and align with your website (if monitored by New Relic Browser), so that you can compare and contrast performance across end-user channels. New Relic Mobile tracks the last interaction of crashed and non-crashed sessions to provide visibility into what the user viewed before exiting your app (either intentionally or due to a crash). 5. Focus on KPIs Bring your key performance indicators to life. Create custom interactions and events to hone in on the most important signals, including user activity for the business-critical aspects of your app. Using these powerful APIs, you can add custom instrumentation to just about anything. The following are some example use cases. How to do it Track and query feature use Use custom events to track feature use. For example: Use custom events to track user flow between app and website. Use custom events or mobile breadcrumbs to optimize the performance of key user flows (log in, shopping cart, etc.). use custom events to provide faster, contextualized support experiences for your digital customers. Use the recordCustomEvent API. Then compare the use of different features using: SELECT count(*) FROM MyNewMobileEventType FACET name Copy Measure page load times Use custom events to measure page load time: Create an app-launch timer to measure the time that elapses between a user-tap to launch your app and the point in your app code where the first screen is available. Record the timer value in New Relic using something like the following: recordCustomEvent(<myMobileTimers>, <appLaunch>, {attributes}) Copy Define start and stop timers to measure spinner durations, and then record this time in New Relic using something like the following: recordCustomEvent(<myMobileTimers>, <spinnerOnScreenA>, {attributes}) Copy Track specific user actions or funnel steps in the app (like \"add to cart\"), and include the price as an attribute on that event. Measure flows through the application by viewing the related funnel steps with custom events in Insights. For example, create a timer to track the start and end times of a subflow or an entire flow across multiple funnel steps to understand how long it took users to get through the process. Examine data about webpage interactions Use custom interactions to see traces associated with the same webpages. Use the agent API to disable default interactions, and focus on custom interactions so that you can review the page loads that are most crucial to your primary funnel. Define the start and stop times of these custom interactions to trace activities associated with individual steps of that funnel (for example, a specific user action or a page load). Track the last interactions of crashed and non-crashed sessions so that you can see what the user viewed before exiting your app (either intentionally or from a crash). Example query for non-crashed sessions: SELECT count(*) FROM Mobile WHERE sessionCrashed is null FACET lastInteraction SINCE 90 days ago Copy Example query for crashed sessions: SELECT count(*) FROM Mobile WHERE sessionCrashed is true FACET lastInteraction SINCE 90 days ago Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.6171,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>monitoring</em> best practices guide",
        "sections": "<em>Mobile</em> <em>monitoring</em> best practices guide",
        "body": " event trail in our <em>mobile</em> <em>monitoring</em> <em>UI</em>. Use our <em>mobile</em> <em>monitoring</em>&#x27;s Versions trends page to make sure you’re improving the <em>crash</em> rate over subsequent releases and avoiding regressions. Breadcrumbs Use breadcrumbs and custom attributes to better reproduce and debug <em>crashes</em>. For example, use our"
      },
      "id": "6044151e28ccbc19ab2c60d8"
    },
    {
      "sections": [
        "Introduction to Mobile handled exceptions",
        "Features",
        "Requirements",
        "Tip",
        "Handled exceptions API and event type"
      ],
      "title": "Introduction to Mobile handled exceptions",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "cfdf733d55bb89d157df675fa162b737bdad52c7",
      "image": "https://docs.newrelic.com/static/5891a9437b94b543d81ee04a70ebe876/8c557/mobile-handled-exceptions-ui.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/introduction-mobile-handled-exceptions/",
      "published_at": "2021-07-02T14:15:31Z",
      "updated_at": "2021-05-16T06:28:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Exceptions can contribute to invalid application states, resulting not only in application crashes but also in negative user reviews. This may lead to users deleting your app, which in turn may affect your organization's profitability. With New Relic Mobile's Handled exceptions user interface, mobile development managers and their developer teams can identify significant factors affecting poor mobile app experience, and use filterable data to find a resolution more quickly. Features Handling exceptions as they occur can help improve your mobile app users' experience, but it's not enough to catch exceptions. You also need to know how to prevent them. For example: How many different types of handled exceptions are occurring? A high occurrence rate may necessitate changes to the back-end systems. Why does the user's app usage result in a try/catch? What is the context for the exceptions? When can a test environment's responses to handled exceptions indicate additional, more serious problems? What would have caused a crash if the exception had not been caught in production? What else (in the code or back-end API) is still affecting the users' experience? By using handled exceptions with New Relic Mobile, you can identify and resolve these kinds of issues more quickly. one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: As you explore the wealth of data in the charts and table, use groups and filters to discover patterns that help you determine the root cause of mobile app exceptions. Handled exception features Comments Slice and dice your exception data. New Relic Mobile offers both an API and a user interface to explore the data most important to your business. Use the recordHandledException() method within a try{...} catch(){...} block to help understand how often your application is throwing exceptions, and under what conditions. Use groups and filters to analyze trends leading to the exception. For example, you can group by OS Build, then filter a specific appVersion. Understand a particular user's experience. Examine the percentage charts to see overall trends with users and sessions at a glance. Then, use custom attributes to focus on exceptions related to paid accounts than free accounts. Pinpoint when most exceptions occur. For example, group on Last Interaction to get an overall view of problems. To drill down further, use filters, such as: To examine exceptions caused by network problems, filter by carrier and then select wifi. To examine exceptions caused by app releases, filter by appVersion. Align issues with common characteristics. For example: Use groups and filters to determine whether handled exception trends appear in networks (ASN, carrier, location, etc.) or in devices (device model, manufacturer, operating system build, version, etc.). Explore recurring patterns in stack traces with the top five exception locations table. Query data and share your findings via New Relic Insights. Explore the event trail before and after a crash. With New Relic Mobile you get a more complete picture of events before and after crashes occur, so you can analyze and resolve problems from multiple angles: Use the handled exception's Occurrences page for expected exceptions. Use the Crash analysis UI and event trail for unanticipated exceptions. Requirements Tip Access to this feature depends on your subscription level and mobile data retention. Additional requirements include: Android: New Relic Mobile's Android agent version 5.15.0 or higher iOS: New Relic Mobile's iOS agent version 5.15.0 or higher Handled exceptions API and event type New Relic Mobile automatically includes default attributes that you can use to explore your handled exceptions data in New Relic Insights and get specific details: Use the recordHandledExceptions() method for the Android or iOS SDK API. Query the MobileHandledException event type in Insights. For more information, see the Insights examples for New Relic Mobile. You can also create your own custom attributes and events. Then, select attributes in Mobile's Handled exceptions page, and query or share them in Insights.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 178.96538,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Mobile</em> handled exceptions",
        "sections": "Introduction to <em>Mobile</em> handled exceptions",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " trail before and after a <em>crash</em>. With New Relic <em>Mobile</em> you get a more complete picture of events before and after <em>crashes</em> occur, so you can analyze and resolve problems from multiple angles: Use the handled exception&#x27;s Occurrences page for expected exceptions. Use the <em>Crash</em> analysis <em>UI</em> and event trail"
      },
      "id": "603e7e8228ccbc05f9eba770"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/crashes/mobile-crash-event-trail": [
    {
      "sections": [
        "Find Build UUIDs for unsymbolicated crashes",
        "View the Build UUID",
        "Binary images example",
        "Find and resymbolicate the dSYM",
        "For more help"
      ],
      "title": "Find Build UUIDs for unsymbolicated crashes",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "e8b926653583d66810c0f68eb6b0111ab3bfc477",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/find-build-uuids-unsymbolicated-crashes/",
      "published_at": "2021-07-02T14:14:31Z",
      "updated_at": "2021-07-02T14:14:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If the dSYM is not uploaded to New Relic, mobile crash reports cannot be symbolicated. You can upload dSYMs manually or directly through the New Relic UI. However, every build of an application will create a new dSYM, and it can be difficult managing which dSYM is attributed to which app build. In this situation, you can use the Build UUID identifier to: Identify a unique build of an application. Find which dSYM can be used to symbolicate a crash. View the Build UUID An application may have more than one Build UUID, one attributed for each CPU architecture the application is built. The Build UUID is also stored within the associated dSYM and can be extracted to identify the dSYM. New Relic crash reports also contain the Build UUID of the crashing application. To view the Build UUID: Go to one.newrelic.com and click Mobile in the top nav. Then find your app and click Crashes > Crash Analysis. From the Crash list table, select any row. From the selected crash report's Crash Details page, look for the App Image Uuid on the attribute list. If the App Image Uuid is not on the selected crash report's attributes list: Export the crash details. Look for the Build UUID in the Binary images section of the exported crash report. Use the Build UUID extracted from the crash details to find the missing dSYM. Binary images example Here is an example of the Binary images section from an exported crash report. This section lists the Build UUID for every dynamically-linked library included in the application, as well as the Build UUID for the main application. In this example, the main application is New Relic. Its Build UUID is 117667e7b8d230cb8a908906c64e0227. This is the identifier you can use to find the associated dSYM. Binary Images: 0xb1000 - 0x30d000 New Relic armv7 < 117667e7b8d230cb8a908906c64e0227 > /var/containers/Bundle/Application/New Relic.app/New Relic 0x22290000 - 0x22292000 libSystem.B.dylib armv7 <39d6d6f7c2ac3de8bb29c40a1b66368a> /usr/lib/libSystem.B.dylib 0x22292000 - 0x222de000 libc++.1.dylib armv7 <017dba6c16b63f9ebecb9ddd0d0a4520> /usr/lib/libc++.1.dylib 0x222de000 - 0x222f9000 libc++abi.dylib armv7 <d32373f6c2153a509f6603750d213ffb> /usr/lib/libc++abi.dylib 0x222fc000 - 0x22667000 libobjc.A.dylib armv7 <94f6d325c1843f45b3a439b86fc9de15> /usr/lib/libobjc.A.dylib 0x22667000 - 0x2266c000 libcache.dylib armv7 <8009f99fb892331dbcb61cd740ff0f43> /usr/lib/system/libcache.dylib 0x2266c000 - 0x22676000 libcommonCrypto.dylib armv7 <f6db318471d732d39918ef36bde65cb7> /usr/lib/system/libcommonCrypto.dylib 0x22676000 - 0x2267c000 libcompiler_rt.dylib armv7 <cfa3ca12d6c2383abcaf3c8541e9b86c> /usr/lib/system/libcompiler_rt.dylib 0x2267c000 - 0x22683000 libcopyfile.dylib armv7 <d2b06020c3693c7b9d179434f8115ba0> /usr/lib/system/libcopyfile.dylib 0x22683000 - 0x226d3000 libcorecrypto.dylib armv7 <181437f8d9e53277ace439de8b3fd1ad> /usr/lib/system/libcorecrypto.dylib 0x226d3000 - 0x2271d000 libdispatch.dylib armv7 <bbb4bba2176039ab95a59d7a56f6eff8> /usr/lib/system/libdispatch.dylib Copy Find and resymbolicate the dSYM To find a dSYM's Build UUID of a dSYM: use dwarfdump with the following terminal command: dwarfdump --uuid <path-to-dSYM> Copy In the following example, the New Relic dSYM returns two Build UUIDs, one each for ARMv7 and ARM64. The ARMv7 Build UUID matches the Build UUID of the missing crash example: > dwarfdump --uuid ./New\\ Relic.app.dSYM/Contents/Resources/DWARF/New\\ Relic UUID: 117667E7-B8D2-30CB-8A90-8906C64E0227 (armv7) ./New Relic.app.dSYM/Contents/Resources/DWARF/New Relic UUID: B1A8C6EE-02B9-3C55-AEE7-308521873107 (arm64) ./New Relic.app.dSYM/Contents/Resources/DWARF/New Relic Copy To symbolicate the unsymbolicated crashes, follow the instructions to manually upload the dSYM. For more help Manual dSYM upload (how to manually upload dSYMs) Retrieve and upload dSYMs (how to locate dSYMs from past app releases)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 319.3722,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Find Build UUIDs for unsymbolicated <em>crashes</em>",
        "sections": "Find Build UUIDs for unsymbolicated <em>crashes</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "If the dSYM is not uploaded to New Relic, <em>mobile</em> <em>crash</em> reports cannot be symbolicated. You can upload dSYMs manually or directly through the New Relic <em>UI</em>. However, every build of an application will create a new dSYM, and it can be difficult managing which dSYM is attributed to which app build"
      },
      "id": "603e9fbae7b9d21cef2a07dd"
    },
    {
      "sections": [
        "Mobile monitoring best practices guide",
        "1. Start collecting data",
        "How to do it",
        "Add your mobile app to New Relic",
        "Install and configure our mobile SDK",
        "2. Explore your data",
        "Analyze, resolve, and prevent crashes",
        "Monitor your key workflows",
        "Get actionable session data",
        "3. Take preventive steps",
        "Metric-based alerts",
        "Event-based alerts",
        "4. Dig deeper into crashes",
        "Crash analysis",
        "Breadcrumbs",
        "Custom attributes",
        "5. Focus on KPIs",
        "Track and query feature use",
        "Measure page load times",
        "Examine data about webpage interactions"
      ],
      "title": "Mobile monitoring best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Full-stack observability"
      ],
      "external_id": "32f5d3919c54c90173721a2cda556d8fd57744f1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/mobile-monitoring-best-practices-guide/",
      "published_at": "2021-07-02T20:13:14Z",
      "updated_at": "2021-07-02T20:13:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "By eliminating crashes and increasing speed across the stack, you can build better performance into every mobile app release. Here are some best practices to take full advantage of mobile monitoring with New Relic. 1. Start collecting data Start collecting data in production. You'll see immediate value by adding our mobile monitoring SDK to your app for its next release to the app store. We recommend installing the iOS or Android agent to your production release even if you're simply testing New Relic's capabilities. This will ensure you'll get an adequate amount of data to really understand all of our mobile monitoring capabilities and your end users' experience. How to do it Add your mobile app to New Relic First, add a new app in New Relic's user interface (full steps): Go to one.newrelic.com and click Mobile. From the list of monitored apps, select Add more. Select the relevant platform. Type a name for your mobile app, and select Continue. Use one app and the associated app token for the development releases of your iOS app, another app and its associated app token for the production releases of that iOS app, and another pair of app tokens for development and production releases of your Android app. You'll be able to compare data from across the four app tokens using our query builder. Install and configure our mobile SDK Next, install and configure the mobile agent: Download the latest version of New Relic's SDK for iOS or Android, and add it to your mobile app. (Full steps for iOS and Android) Configure your installation as needed. For example: Enable the feature flag to capture MobileRequest events to use our full network analysis capabilities for iOS or Android. Automate dSYM uploads for your production builds. To avoid surprises, follow the standard pattern of where you start our mobile agent. In addition, start our agent before you initiate any other SDKs. For more information, see our documentation for Android installation and configuration and for iOS installation and configuration. Deploy a new release of your application. 2. Explore your data Immediately be able to explore your data. As soon as New Relic starts reporting data, take the time to explore the wealth of information about your mobile apps. To get started, go to one.newrelic.com and select Mobile. How to do it Analyze, resolve, and prevent crashes Find the cause of crashes so you can fix them. Then, uncover trends behind crashes so you can prevent them: From the summary UI page for a monitored mobile app, click Crash analysis. Analyze crash data so you can see and fix the most impactful crashes. Follow the breadcrumbs in the crash event trail to fix crashes and resolve critical errors more easily: From your mobile app's Crash analysis page in the UI, select a Crash type. From the crash type's Summary page, select the Crash trail tab. For more information, see our blog post about crash analysis. Monitor your key workflows Create custom breadcrumbs to monitor key workflows (such as your app's login or checkout process), track user clicks, optimize timing, and identify crash locations for faster MTTR. Get actionable session data Borrow from our example queries to: See how much of your user base has upgraded to your latest app version. Track adoption over time. Get a count of new installs as compared to upgrades from an earlier version. See the distribution of usage across geographical locations, carriers, ASN owners (wi-fi providers), devices, connection types, and more. 3. Take preventive steps Use alert notifications to help uncover the causes behind crashes and errors. Once you are running our mobile monitoring capabilities in production and have explored some of the key features, you can use New Relic to uncover critical issues with your mobile application. In particular, focus on crashes and errors. Use metric-based alerts as a starting point to gain high-level visibility into problems. Then, as new services or functionalities are added, use New Relic’s more targeted, event-based (NRQL) alerts to make sure that the most critical issues are handled swiftly. Use these alerts to determine whether a crash is impacting a large number of users. If it is, the relevant people (for example, both the mobile app team’s on-call member and the owner of the related back-end service) will be alerted. Make sure that your team knows how to respond to changes in crash rate (crashes per sessions) and the percentage of users impacted by crashes of your mobile app. How to do it Metric-based alerts Leverage our metric-based alerts and New Relic Mobile UI. Ensure that key members of your mobile team have opted in to receive emails for new crashes. These emails will take you to the crash type in the Mobile UI page for your mobile app. Create an alert for your crash rate threshold that key members of your team can view in Slack or any other Alerts notification channel you choose. Your alert notification will include a link to our UI, where you can examine a chart with the exceeded threshold. From there, a link will take you to the relevant mobile monitoring page, where you can get additional details. Event-based alerts Combine the metric-based workflow with event-based alerts and dashboards specific to your mobile app and system. Create your NRQL alert that focuses on crashes of your most recently released production version. Create an additional NRQL alert that focuses on the percentage of users impacted by crashes in your latest app version (to check the overall impact on your user base). 4. Dig deeper into crashes Take your crash reporting to the next level. Now it’s time to tackle some of those harder-to-reproduce crashes by: Applying additional instrumentation to your application. Leveraging crash event trails, NRQL queries, and dashboards to visualize your data. How to do it Crash analysis Crashes are an inevitable part of running mobile applications at scale. We provide tools to help you understand your highest-impact crashes. Use the Crash analysis UI to see which crashes are occurring most often, the percentage of crash-free users, which files and methods are associated with perhaps 80 percent of your crashes, which crashes a particular user just experienced, and more. Go after high-impact crashes with crash analysis: Add custom attributes to categorize the highest-value customers, and then use them to segment crashes according to your most valuable audiences. Add breadcrumbs and custom events to produce a detailed trail of events leading up to every crash occurrence (over the last 90 days). Then, view this crash event trail in our mobile monitoring UI. Use our mobile monitoring's Versions trends page to make sure you’re improving the crash rate over subsequent releases and avoiding regressions. Breadcrumbs Use breadcrumbs and custom attributes to better reproduce and debug crashes. For example, use our recordBreadrumb API for Android or iOS to track mid-session changes in state that can help debug crashes, such as: Change of connection type Change of orientation CPU and memory state at key points in the app code Custom attributes Add custom attributes to existing events, so you can ask even more precise questions of your mobile app. Add dimensions such as: User ID: Use to react to specific user concerns and to better understand which customers and segments are most impacted. Store ID: Use to address problems with out-of-date devices, bad wi-fi, and so on. User segments: Use to better understand which customers and segments are most impacted; for example, logged in vs. non-logged in. Money in the cart at session end Origin or attribution of entry into the app Standardize custom attribute names across your mobile apps, and align with your website (if monitored by New Relic Browser), so that you can compare and contrast performance across end-user channels. New Relic Mobile tracks the last interaction of crashed and non-crashed sessions to provide visibility into what the user viewed before exiting your app (either intentionally or due to a crash). 5. Focus on KPIs Bring your key performance indicators to life. Create custom interactions and events to hone in on the most important signals, including user activity for the business-critical aspects of your app. Using these powerful APIs, you can add custom instrumentation to just about anything. The following are some example use cases. How to do it Track and query feature use Use custom events to track feature use. For example: Use custom events to track user flow between app and website. Use custom events or mobile breadcrumbs to optimize the performance of key user flows (log in, shopping cart, etc.). use custom events to provide faster, contextualized support experiences for your digital customers. Use the recordCustomEvent API. Then compare the use of different features using: SELECT count(*) FROM MyNewMobileEventType FACET name Copy Measure page load times Use custom events to measure page load time: Create an app-launch timer to measure the time that elapses between a user-tap to launch your app and the point in your app code where the first screen is available. Record the timer value in New Relic using something like the following: recordCustomEvent(<myMobileTimers>, <appLaunch>, {attributes}) Copy Define start and stop timers to measure spinner durations, and then record this time in New Relic using something like the following: recordCustomEvent(<myMobileTimers>, <spinnerOnScreenA>, {attributes}) Copy Track specific user actions or funnel steps in the app (like \"add to cart\"), and include the price as an attribute on that event. Measure flows through the application by viewing the related funnel steps with custom events in Insights. For example, create a timer to track the start and end times of a subflow or an entire flow across multiple funnel steps to understand how long it took users to get through the process. Examine data about webpage interactions Use custom interactions to see traces associated with the same webpages. Use the agent API to disable default interactions, and focus on custom interactions so that you can review the page loads that are most crucial to your primary funnel. Define the start and stop times of these custom interactions to trace activities associated with individual steps of that funnel (for example, a specific user action or a page load). Track the last interactions of crashed and non-crashed sessions so that you can see what the user viewed before exiting your app (either intentionally or from a crash). Example query for non-crashed sessions: SELECT count(*) FROM Mobile WHERE sessionCrashed is null FACET lastInteraction SINCE 90 days ago Copy Example query for crashed sessions: SELECT count(*) FROM Mobile WHERE sessionCrashed is true FACET lastInteraction SINCE 90 days ago Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.61697,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>monitoring</em> best practices guide",
        "sections": "<em>Mobile</em> <em>monitoring</em> best practices guide",
        "body": " event trail in our <em>mobile</em> <em>monitoring</em> <em>UI</em>. Use our <em>mobile</em> <em>monitoring</em>&#x27;s Versions trends page to make sure you’re improving the <em>crash</em> rate over subsequent releases and avoiding regressions. Breadcrumbs Use breadcrumbs and custom attributes to better reproduce and debug <em>crashes</em>. For example, use our"
      },
      "id": "6044151e28ccbc19ab2c60d8"
    },
    {
      "sections": [
        "Introduction to Mobile handled exceptions",
        "Features",
        "Requirements",
        "Tip",
        "Handled exceptions API and event type"
      ],
      "title": "Introduction to Mobile handled exceptions",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "cfdf733d55bb89d157df675fa162b737bdad52c7",
      "image": "https://docs.newrelic.com/static/5891a9437b94b543d81ee04a70ebe876/8c557/mobile-handled-exceptions-ui.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/introduction-mobile-handled-exceptions/",
      "published_at": "2021-07-02T14:15:31Z",
      "updated_at": "2021-05-16T06:28:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Exceptions can contribute to invalid application states, resulting not only in application crashes but also in negative user reviews. This may lead to users deleting your app, which in turn may affect your organization's profitability. With New Relic Mobile's Handled exceptions user interface, mobile development managers and their developer teams can identify significant factors affecting poor mobile app experience, and use filterable data to find a resolution more quickly. Features Handling exceptions as they occur can help improve your mobile app users' experience, but it's not enough to catch exceptions. You also need to know how to prevent them. For example: How many different types of handled exceptions are occurring? A high occurrence rate may necessitate changes to the back-end systems. Why does the user's app usage result in a try/catch? What is the context for the exceptions? When can a test environment's responses to handled exceptions indicate additional, more serious problems? What would have caused a crash if the exception had not been caught in production? What else (in the code or back-end API) is still affecting the users' experience? By using handled exceptions with New Relic Mobile, you can identify and resolve these kinds of issues more quickly. one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: As you explore the wealth of data in the charts and table, use groups and filters to discover patterns that help you determine the root cause of mobile app exceptions. Handled exception features Comments Slice and dice your exception data. New Relic Mobile offers both an API and a user interface to explore the data most important to your business. Use the recordHandledException() method within a try{...} catch(){...} block to help understand how often your application is throwing exceptions, and under what conditions. Use groups and filters to analyze trends leading to the exception. For example, you can group by OS Build, then filter a specific appVersion. Understand a particular user's experience. Examine the percentage charts to see overall trends with users and sessions at a glance. Then, use custom attributes to focus on exceptions related to paid accounts than free accounts. Pinpoint when most exceptions occur. For example, group on Last Interaction to get an overall view of problems. To drill down further, use filters, such as: To examine exceptions caused by network problems, filter by carrier and then select wifi. To examine exceptions caused by app releases, filter by appVersion. Align issues with common characteristics. For example: Use groups and filters to determine whether handled exception trends appear in networks (ASN, carrier, location, etc.) or in devices (device model, manufacturer, operating system build, version, etc.). Explore recurring patterns in stack traces with the top five exception locations table. Query data and share your findings via New Relic Insights. Explore the event trail before and after a crash. With New Relic Mobile you get a more complete picture of events before and after crashes occur, so you can analyze and resolve problems from multiple angles: Use the handled exception's Occurrences page for expected exceptions. Use the Crash analysis UI and event trail for unanticipated exceptions. Requirements Tip Access to this feature depends on your subscription level and mobile data retention. Additional requirements include: Android: New Relic Mobile's Android agent version 5.15.0 or higher iOS: New Relic Mobile's iOS agent version 5.15.0 or higher Handled exceptions API and event type New Relic Mobile automatically includes default attributes that you can use to explore your handled exceptions data in New Relic Insights and get specific details: Use the recordHandledExceptions() method for the Android or iOS SDK API. Query the MobileHandledException event type in Insights. For more information, see the Insights examples for New Relic Mobile. You can also create your own custom attributes and events. Then, select attributes in Mobile's Handled exceptions page, and query or share them in Insights.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 178.96538,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Mobile</em> handled exceptions",
        "sections": "Introduction to <em>Mobile</em> handled exceptions",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " trail before and after a <em>crash</em>. With New Relic <em>Mobile</em> you get a more complete picture of events before and after <em>crashes</em> occur, so you can analyze and resolve problems from multiple angles: Use the handled exception&#x27;s Occurrences page for expected exceptions. Use the <em>Crash</em> analysis <em>UI</em> and event trail"
      },
      "id": "603e7e8228ccbc05f9eba770"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/alerts-page-mobile-apps": [
    {
      "sections": [
        "Find Build UUIDs for unsymbolicated crashes",
        "View the Build UUID",
        "Binary images example",
        "Find and resymbolicate the dSYM",
        "For more help"
      ],
      "title": "Find Build UUIDs for unsymbolicated crashes",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "e8b926653583d66810c0f68eb6b0111ab3bfc477",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/find-build-uuids-unsymbolicated-crashes/",
      "published_at": "2021-07-02T14:14:31Z",
      "updated_at": "2021-07-02T14:14:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If the dSYM is not uploaded to New Relic, mobile crash reports cannot be symbolicated. You can upload dSYMs manually or directly through the New Relic UI. However, every build of an application will create a new dSYM, and it can be difficult managing which dSYM is attributed to which app build. In this situation, you can use the Build UUID identifier to: Identify a unique build of an application. Find which dSYM can be used to symbolicate a crash. View the Build UUID An application may have more than one Build UUID, one attributed for each CPU architecture the application is built. The Build UUID is also stored within the associated dSYM and can be extracted to identify the dSYM. New Relic crash reports also contain the Build UUID of the crashing application. To view the Build UUID: Go to one.newrelic.com and click Mobile in the top nav. Then find your app and click Crashes > Crash Analysis. From the Crash list table, select any row. From the selected crash report's Crash Details page, look for the App Image Uuid on the attribute list. If the App Image Uuid is not on the selected crash report's attributes list: Export the crash details. Look for the Build UUID in the Binary images section of the exported crash report. Use the Build UUID extracted from the crash details to find the missing dSYM. Binary images example Here is an example of the Binary images section from an exported crash report. This section lists the Build UUID for every dynamically-linked library included in the application, as well as the Build UUID for the main application. In this example, the main application is New Relic. Its Build UUID is 117667e7b8d230cb8a908906c64e0227. This is the identifier you can use to find the associated dSYM. Binary Images: 0xb1000 - 0x30d000 New Relic armv7 < 117667e7b8d230cb8a908906c64e0227 > /var/containers/Bundle/Application/New Relic.app/New Relic 0x22290000 - 0x22292000 libSystem.B.dylib armv7 <39d6d6f7c2ac3de8bb29c40a1b66368a> /usr/lib/libSystem.B.dylib 0x22292000 - 0x222de000 libc++.1.dylib armv7 <017dba6c16b63f9ebecb9ddd0d0a4520> /usr/lib/libc++.1.dylib 0x222de000 - 0x222f9000 libc++abi.dylib armv7 <d32373f6c2153a509f6603750d213ffb> /usr/lib/libc++abi.dylib 0x222fc000 - 0x22667000 libobjc.A.dylib armv7 <94f6d325c1843f45b3a439b86fc9de15> /usr/lib/libobjc.A.dylib 0x22667000 - 0x2266c000 libcache.dylib armv7 <8009f99fb892331dbcb61cd740ff0f43> /usr/lib/system/libcache.dylib 0x2266c000 - 0x22676000 libcommonCrypto.dylib armv7 <f6db318471d732d39918ef36bde65cb7> /usr/lib/system/libcommonCrypto.dylib 0x22676000 - 0x2267c000 libcompiler_rt.dylib armv7 <cfa3ca12d6c2383abcaf3c8541e9b86c> /usr/lib/system/libcompiler_rt.dylib 0x2267c000 - 0x22683000 libcopyfile.dylib armv7 <d2b06020c3693c7b9d179434f8115ba0> /usr/lib/system/libcopyfile.dylib 0x22683000 - 0x226d3000 libcorecrypto.dylib armv7 <181437f8d9e53277ace439de8b3fd1ad> /usr/lib/system/libcorecrypto.dylib 0x226d3000 - 0x2271d000 libdispatch.dylib armv7 <bbb4bba2176039ab95a59d7a56f6eff8> /usr/lib/system/libdispatch.dylib Copy Find and resymbolicate the dSYM To find a dSYM's Build UUID of a dSYM: use dwarfdump with the following terminal command: dwarfdump --uuid <path-to-dSYM> Copy In the following example, the New Relic dSYM returns two Build UUIDs, one each for ARMv7 and ARM64. The ARMv7 Build UUID matches the Build UUID of the missing crash example: > dwarfdump --uuid ./New\\ Relic.app.dSYM/Contents/Resources/DWARF/New\\ Relic UUID: 117667E7-B8D2-30CB-8A90-8906C64E0227 (armv7) ./New Relic.app.dSYM/Contents/Resources/DWARF/New Relic UUID: B1A8C6EE-02B9-3C55-AEE7-308521873107 (arm64) ./New Relic.app.dSYM/Contents/Resources/DWARF/New Relic Copy To symbolicate the unsymbolicated crashes, follow the instructions to manually upload the dSYM. For more help Manual dSYM upload (how to manually upload dSYMs) Retrieve and upload dSYMs (how to locate dSYMs from past app releases)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 222.32843,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "If the dSYM is not uploaded to New Relic, <em>mobile</em> crash reports cannot be symbolicated. You can upload dSYMs manually or directly through the New Relic <em>UI</em>. However, every build of an application will create a new dSYM, and it can be difficult managing which dSYM is attributed to which <em>app</em> build"
      },
      "id": "603e9fbae7b9d21cef2a07dd"
    },
    {
      "sections": [
        "Devices page",
        "Viewing the Devices page",
        "Viewing drill-down details",
        "For more help"
      ],
      "title": "Devices page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile App pages"
      ],
      "external_id": "b8bf0965c688601c352eda9c33b952a5a9e7ddae",
      "image": "https://docs.newrelic.com/static/9ecb707eee4236b41488d12707399210/c1b63/screen-mobile-devices_0.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/devices-page/",
      "published_at": "2021-07-02T15:29:30Z",
      "updated_at": "2021-05-16T06:31:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Devices page for New Relic Mobile provides performance details about the top devices using your mobile application, such as iPad, iPhone, iPod Touch, Android Tablet, etc. Charts compare the devices by: Interaction time HTTP request time Error rates and network failures Active user sessions From here you can drill down into details by a specific model (for example, iPhone 6, 6S, 7). Viewing the Devices page one.newrelic.com > Mobile > (select an app) > App > Devices: Use this page to view, sort, or drill down into detailed information about the top five types of devices using your mobile app, including interaction and HTTP request times, error rates, and active users. To view performance details about your users' mobile devices: Go to one.newrelic.com > Mobile > (select an app) > App > Devices. To select the mobile app versions or change the time period, use the Versions menu and time picker below the New Relic menu bar. Optional: Select the Sort by and Hide < 1% throughput options. To limit details to a specific device type (for example, iPad), select its name. Viewing drill-down details To drill down into detailed information, use any of New Relic's standard user interface functions and page functions to drill down into detailed information. In addition: To view a list of specific devices or models (for example, iPad mini, iPad Air, etc.), select the type (for example, iPad). To view details for a specific device or model, select its name from the expanded list. To view trace details a slow transaction (if available), select its link. For more information, see Interactions page. To return to the main Devices page, select the Close (X) button. one.newrelic.com > Mobile > (select an app) > App > Devices > (select a device): This page provides drill-down details for the selected device, including http response time, network failures, active sessions, and slowest transaction traces (if available). For more help Additional documentation resources include: Errors page for mobile apps (detailed charts and information about errors with mobile apps) Versions analysis (seven-day report with a color-coded chart for mobile app usage, plus a table that summarizes mobile versions, date created, and averages) Monthly uniques report (bar charts showing the number of devices running your mobile app over the past 12 months)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 200.07541,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Devices <em>page</em>",
        "sections": "Devices <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " here you can drill down into details by a specific model (for example, iPhone 6, 6S, 7). Viewing the Devices <em>page</em> one.newrelic.com &gt; <em>Mobile</em> &gt; (select an <em>app</em>) &gt; <em>App</em> &gt; Devices: Use this <em>page</em> to view, sort, or drill down into detailed information about the top five types of devices using your <em>mobile</em>"
      },
      "id": "60450de0196a67fe2c960f64"
    },
    {
      "sections": [
        "Mobile apps index",
        "View your list of mobile apps",
        "Standard menu functions"
      ],
      "title": "Mobile apps index",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile App pages"
      ],
      "external_id": "38ff00ca55b0ca25a0ad534b57e02b01f4040c97",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/mobile-apps-index/",
      "published_at": "2021-07-02T13:10:32Z",
      "updated_at": "2021-04-16T21:34:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's mobile monitoring UI includes a mobile app index that shows a list of your monitored apps and important summary information about them. View your list of mobile apps To see the mobile apps index, go to one.newrelic.com and click Mobile. The index of available mobile apps includes a colored health status indicating: Green = Normal Yellow = Warning Red = Critical Gray = Not reporting data Standard menu functions To view details for a specific app, select it from the index. Here are some other functions available from the index: If you want to... Do this... View the app's status Mouse over the mobile app's colored health status indicator. If the health status indicator is gray and no data is being reported, you likely need to finish installing mobile monitoring. Monitor another app Select Add more. See the app's metadata To see the app's metadata, including its app ID, entity GUID, and more, click the icon next to the application name. For more about UI functions, see Basic UI functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.09676,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>apps</em> index",
        "sections": "<em>Mobile</em> <em>apps</em> index",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " Mouse over the <em>mobile</em> <em>app</em>&#x27;s colored health status indicator. If the health status indicator is gray and no data is being reported, you likely need to finish installing <em>mobile</em> <em>monitoring</em>. <em>Monitor</em> another <em>app</em> Select Add more. See the <em>app</em>&#x27;s metadata To see the <em>app</em>&#x27;s metadata, including its <em>app</em> ID, entity GUID, and more, click the icon next to the application name. For more about <em>UI</em> functions, see Basic <em>UI</em> functions."
      },
      "id": "604537fc64441f7903378f35"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/devices-page": [
    {
      "sections": [
        "Find Build UUIDs for unsymbolicated crashes",
        "View the Build UUID",
        "Binary images example",
        "Find and resymbolicate the dSYM",
        "For more help"
      ],
      "title": "Find Build UUIDs for unsymbolicated crashes",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "e8b926653583d66810c0f68eb6b0111ab3bfc477",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/find-build-uuids-unsymbolicated-crashes/",
      "published_at": "2021-07-02T14:14:31Z",
      "updated_at": "2021-07-02T14:14:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If the dSYM is not uploaded to New Relic, mobile crash reports cannot be symbolicated. You can upload dSYMs manually or directly through the New Relic UI. However, every build of an application will create a new dSYM, and it can be difficult managing which dSYM is attributed to which app build. In this situation, you can use the Build UUID identifier to: Identify a unique build of an application. Find which dSYM can be used to symbolicate a crash. View the Build UUID An application may have more than one Build UUID, one attributed for each CPU architecture the application is built. The Build UUID is also stored within the associated dSYM and can be extracted to identify the dSYM. New Relic crash reports also contain the Build UUID of the crashing application. To view the Build UUID: Go to one.newrelic.com and click Mobile in the top nav. Then find your app and click Crashes > Crash Analysis. From the Crash list table, select any row. From the selected crash report's Crash Details page, look for the App Image Uuid on the attribute list. If the App Image Uuid is not on the selected crash report's attributes list: Export the crash details. Look for the Build UUID in the Binary images section of the exported crash report. Use the Build UUID extracted from the crash details to find the missing dSYM. Binary images example Here is an example of the Binary images section from an exported crash report. This section lists the Build UUID for every dynamically-linked library included in the application, as well as the Build UUID for the main application. In this example, the main application is New Relic. Its Build UUID is 117667e7b8d230cb8a908906c64e0227. This is the identifier you can use to find the associated dSYM. Binary Images: 0xb1000 - 0x30d000 New Relic armv7 < 117667e7b8d230cb8a908906c64e0227 > /var/containers/Bundle/Application/New Relic.app/New Relic 0x22290000 - 0x22292000 libSystem.B.dylib armv7 <39d6d6f7c2ac3de8bb29c40a1b66368a> /usr/lib/libSystem.B.dylib 0x22292000 - 0x222de000 libc++.1.dylib armv7 <017dba6c16b63f9ebecb9ddd0d0a4520> /usr/lib/libc++.1.dylib 0x222de000 - 0x222f9000 libc++abi.dylib armv7 <d32373f6c2153a509f6603750d213ffb> /usr/lib/libc++abi.dylib 0x222fc000 - 0x22667000 libobjc.A.dylib armv7 <94f6d325c1843f45b3a439b86fc9de15> /usr/lib/libobjc.A.dylib 0x22667000 - 0x2266c000 libcache.dylib armv7 <8009f99fb892331dbcb61cd740ff0f43> /usr/lib/system/libcache.dylib 0x2266c000 - 0x22676000 libcommonCrypto.dylib armv7 <f6db318471d732d39918ef36bde65cb7> /usr/lib/system/libcommonCrypto.dylib 0x22676000 - 0x2267c000 libcompiler_rt.dylib armv7 <cfa3ca12d6c2383abcaf3c8541e9b86c> /usr/lib/system/libcompiler_rt.dylib 0x2267c000 - 0x22683000 libcopyfile.dylib armv7 <d2b06020c3693c7b9d179434f8115ba0> /usr/lib/system/libcopyfile.dylib 0x22683000 - 0x226d3000 libcorecrypto.dylib armv7 <181437f8d9e53277ace439de8b3fd1ad> /usr/lib/system/libcorecrypto.dylib 0x226d3000 - 0x2271d000 libdispatch.dylib armv7 <bbb4bba2176039ab95a59d7a56f6eff8> /usr/lib/system/libdispatch.dylib Copy Find and resymbolicate the dSYM To find a dSYM's Build UUID of a dSYM: use dwarfdump with the following terminal command: dwarfdump --uuid <path-to-dSYM> Copy In the following example, the New Relic dSYM returns two Build UUIDs, one each for ARMv7 and ARM64. The ARMv7 Build UUID matches the Build UUID of the missing crash example: > dwarfdump --uuid ./New\\ Relic.app.dSYM/Contents/Resources/DWARF/New\\ Relic UUID: 117667E7-B8D2-30CB-8A90-8906C64E0227 (armv7) ./New Relic.app.dSYM/Contents/Resources/DWARF/New Relic UUID: B1A8C6EE-02B9-3C55-AEE7-308521873107 (arm64) ./New Relic.app.dSYM/Contents/Resources/DWARF/New Relic Copy To symbolicate the unsymbolicated crashes, follow the instructions to manually upload the dSYM. For more help Manual dSYM upload (how to manually upload dSYMs) Retrieve and upload dSYMs (how to locate dSYMs from past app releases)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 222.32831,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "If the dSYM is not uploaded to New Relic, <em>mobile</em> crash reports cannot be symbolicated. You can upload dSYMs manually or directly through the New Relic <em>UI</em>. However, every build of an application will create a new dSYM, and it can be difficult managing which dSYM is attributed to which <em>app</em> build"
      },
      "id": "603e9fbae7b9d21cef2a07dd"
    },
    {
      "sections": [
        "Mobile apps index",
        "View your list of mobile apps",
        "Standard menu functions"
      ],
      "title": "Mobile apps index",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile App pages"
      ],
      "external_id": "38ff00ca55b0ca25a0ad534b57e02b01f4040c97",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/mobile-apps-index/",
      "published_at": "2021-07-02T13:10:32Z",
      "updated_at": "2021-04-16T21:34:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's mobile monitoring UI includes a mobile app index that shows a list of your monitored apps and important summary information about them. View your list of mobile apps To see the mobile apps index, go to one.newrelic.com and click Mobile. The index of available mobile apps includes a colored health status indicating: Green = Normal Yellow = Warning Red = Critical Gray = Not reporting data Standard menu functions To view details for a specific app, select it from the index. Here are some other functions available from the index: If you want to... Do this... View the app's status Mouse over the mobile app's colored health status indicator. If the health status indicator is gray and no data is being reported, you likely need to finish installing mobile monitoring. Monitor another app Select Add more. See the app's metadata To see the app's metadata, including its app ID, entity GUID, and more, click the icon next to the application name. For more about UI functions, see Basic UI functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.09676,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>apps</em> index",
        "sections": "<em>Mobile</em> <em>apps</em> index",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " Mouse over the <em>mobile</em> <em>app</em>&#x27;s colored health status indicator. If the health status indicator is gray and no data is being reported, you likely need to finish installing <em>mobile</em> <em>monitoring</em>. <em>Monitor</em> another <em>app</em> Select Add more. See the <em>app</em>&#x27;s metadata To see the <em>app</em>&#x27;s metadata, including its <em>app</em> ID, entity GUID, and more, click the icon next to the application name. For more about <em>UI</em> functions, see Basic <em>UI</em> functions."
      },
      "id": "604537fc64441f7903378f35"
    },
    {
      "sections": [
        "OS versions page",
        "Viewing the OS versions page",
        "Viewing drill-down details",
        "For more help"
      ],
      "title": "OS versions page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile App pages"
      ],
      "external_id": "370b6f1584d001a17f414066097692b9189e1a50",
      "image": "https://docs.newrelic.com/static/8d84abf966c2f4b75ca298b362995c0e/c1b63/os-version-pic_0.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/os-versions-page/",
      "published_at": "2021-07-02T13:42:10Z",
      "updated_at": "2021-03-16T09:36:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The OS versions page for Mobile monitoring provides performance details about the top operating system versions hosting your mobile application, such as iOS and Android. Charts compare the OS versions by: HTTP request time Network failures Requests per minute Active devices From here you can drill down into details by a major or minor OS version (for example, iOS 8, iOS 7.1.1, Android 4.2.2). Viewing the OS versions page one.newrelic.com > Mobile > (select an app) > App > OS versions: Use this page to view, sort, or drill down into detailed information about the top five types of operation system versions using your mobile app. To view performance details about the operating system versions for your mobile app users: Go to one.newrelic.com > Mobile > (select an app) > App > OS versions. To select the mobile app versions or time period, use the Versions menu and time picker below the UI menu bar. Optional: Select the Sort by and Hide < 1% throughput options. To expand or collapse the list of operating systems to include versions, select the operating system's name (for example, iOS 7). Viewing drill-down details To drill down into detailed information, use any of our standard user interface functions and page functions to drill down into detailed information. In addition: To view details for the minor and point releases of a major OS version (including interaction time, HTTP request times, network failures, active devices, and slowest traces or all subversions), select a major OS version from the list. To view details for a specific OS version, select its name from the expanded OS list. To view trace details a slow transaction (if available), select its link. For more information, see Interactions page. To return to the main OS versions page, select the Close (X) button. For more help Additional documentation resources include: Errors page for mobile apps (detailed charts and information about errors with mobile apps) Versions report (seven-day report with a color-coded chart for mobile app usage, plus a table that summarizes mobile versions, date created, and averages)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.40028,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "OS versions <em>page</em>",
        "sections": "OS versions <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The OS versions <em>page</em> for <em>Mobile</em> <em>monitoring</em> provides performance details about the top operating system versions hosting your <em>mobile</em> application, such as iOS and Android. Charts compare the OS versions by: HTTP request time Network failures Requests per minute Active devices From here you can drill"
      },
      "id": "603eaee9e7b9d260112a0809"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/interactions-page": [
    {
      "sections": [
        "Find Build UUIDs for unsymbolicated crashes",
        "View the Build UUID",
        "Binary images example",
        "Find and resymbolicate the dSYM",
        "For more help"
      ],
      "title": "Find Build UUIDs for unsymbolicated crashes",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "e8b926653583d66810c0f68eb6b0111ab3bfc477",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/find-build-uuids-unsymbolicated-crashes/",
      "published_at": "2021-07-02T14:14:31Z",
      "updated_at": "2021-07-02T14:14:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If the dSYM is not uploaded to New Relic, mobile crash reports cannot be symbolicated. You can upload dSYMs manually or directly through the New Relic UI. However, every build of an application will create a new dSYM, and it can be difficult managing which dSYM is attributed to which app build. In this situation, you can use the Build UUID identifier to: Identify a unique build of an application. Find which dSYM can be used to symbolicate a crash. View the Build UUID An application may have more than one Build UUID, one attributed for each CPU architecture the application is built. The Build UUID is also stored within the associated dSYM and can be extracted to identify the dSYM. New Relic crash reports also contain the Build UUID of the crashing application. To view the Build UUID: Go to one.newrelic.com and click Mobile in the top nav. Then find your app and click Crashes > Crash Analysis. From the Crash list table, select any row. From the selected crash report's Crash Details page, look for the App Image Uuid on the attribute list. If the App Image Uuid is not on the selected crash report's attributes list: Export the crash details. Look for the Build UUID in the Binary images section of the exported crash report. Use the Build UUID extracted from the crash details to find the missing dSYM. Binary images example Here is an example of the Binary images section from an exported crash report. This section lists the Build UUID for every dynamically-linked library included in the application, as well as the Build UUID for the main application. In this example, the main application is New Relic. Its Build UUID is 117667e7b8d230cb8a908906c64e0227. This is the identifier you can use to find the associated dSYM. Binary Images: 0xb1000 - 0x30d000 New Relic armv7 < 117667e7b8d230cb8a908906c64e0227 > /var/containers/Bundle/Application/New Relic.app/New Relic 0x22290000 - 0x22292000 libSystem.B.dylib armv7 <39d6d6f7c2ac3de8bb29c40a1b66368a> /usr/lib/libSystem.B.dylib 0x22292000 - 0x222de000 libc++.1.dylib armv7 <017dba6c16b63f9ebecb9ddd0d0a4520> /usr/lib/libc++.1.dylib 0x222de000 - 0x222f9000 libc++abi.dylib armv7 <d32373f6c2153a509f6603750d213ffb> /usr/lib/libc++abi.dylib 0x222fc000 - 0x22667000 libobjc.A.dylib armv7 <94f6d325c1843f45b3a439b86fc9de15> /usr/lib/libobjc.A.dylib 0x22667000 - 0x2266c000 libcache.dylib armv7 <8009f99fb892331dbcb61cd740ff0f43> /usr/lib/system/libcache.dylib 0x2266c000 - 0x22676000 libcommonCrypto.dylib armv7 <f6db318471d732d39918ef36bde65cb7> /usr/lib/system/libcommonCrypto.dylib 0x22676000 - 0x2267c000 libcompiler_rt.dylib armv7 <cfa3ca12d6c2383abcaf3c8541e9b86c> /usr/lib/system/libcompiler_rt.dylib 0x2267c000 - 0x22683000 libcopyfile.dylib armv7 <d2b06020c3693c7b9d179434f8115ba0> /usr/lib/system/libcopyfile.dylib 0x22683000 - 0x226d3000 libcorecrypto.dylib armv7 <181437f8d9e53277ace439de8b3fd1ad> /usr/lib/system/libcorecrypto.dylib 0x226d3000 - 0x2271d000 libdispatch.dylib armv7 <bbb4bba2176039ab95a59d7a56f6eff8> /usr/lib/system/libdispatch.dylib Copy Find and resymbolicate the dSYM To find a dSYM's Build UUID of a dSYM: use dwarfdump with the following terminal command: dwarfdump --uuid <path-to-dSYM> Copy In the following example, the New Relic dSYM returns two Build UUIDs, one each for ARMv7 and ARM64. The ARMv7 Build UUID matches the Build UUID of the missing crash example: > dwarfdump --uuid ./New\\ Relic.app.dSYM/Contents/Resources/DWARF/New\\ Relic UUID: 117667E7-B8D2-30CB-8A90-8906C64E0227 (armv7) ./New Relic.app.dSYM/Contents/Resources/DWARF/New Relic UUID: B1A8C6EE-02B9-3C55-AEE7-308521873107 (arm64) ./New Relic.app.dSYM/Contents/Resources/DWARF/New Relic Copy To symbolicate the unsymbolicated crashes, follow the instructions to manually upload the dSYM. For more help Manual dSYM upload (how to manually upload dSYMs) Retrieve and upload dSYMs (how to locate dSYMs from past app releases)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 222.32831,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "If the dSYM is not uploaded to New Relic, <em>mobile</em> crash reports cannot be symbolicated. You can upload dSYMs manually or directly through the New Relic <em>UI</em>. However, every build of an application will create a new dSYM, and it can be difficult managing which dSYM is attributed to which <em>app</em> build"
      },
      "id": "603e9fbae7b9d21cef2a07dd"
    },
    {
      "sections": [
        "Devices page",
        "Viewing the Devices page",
        "Viewing drill-down details",
        "For more help"
      ],
      "title": "Devices page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile App pages"
      ],
      "external_id": "b8bf0965c688601c352eda9c33b952a5a9e7ddae",
      "image": "https://docs.newrelic.com/static/9ecb707eee4236b41488d12707399210/c1b63/screen-mobile-devices_0.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/devices-page/",
      "published_at": "2021-07-02T15:29:30Z",
      "updated_at": "2021-05-16T06:31:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Devices page for New Relic Mobile provides performance details about the top devices using your mobile application, such as iPad, iPhone, iPod Touch, Android Tablet, etc. Charts compare the devices by: Interaction time HTTP request time Error rates and network failures Active user sessions From here you can drill down into details by a specific model (for example, iPhone 6, 6S, 7). Viewing the Devices page one.newrelic.com > Mobile > (select an app) > App > Devices: Use this page to view, sort, or drill down into detailed information about the top five types of devices using your mobile app, including interaction and HTTP request times, error rates, and active users. To view performance details about your users' mobile devices: Go to one.newrelic.com > Mobile > (select an app) > App > Devices. To select the mobile app versions or change the time period, use the Versions menu and time picker below the New Relic menu bar. Optional: Select the Sort by and Hide < 1% throughput options. To limit details to a specific device type (for example, iPad), select its name. Viewing drill-down details To drill down into detailed information, use any of New Relic's standard user interface functions and page functions to drill down into detailed information. In addition: To view a list of specific devices or models (for example, iPad mini, iPad Air, etc.), select the type (for example, iPad). To view details for a specific device or model, select its name from the expanded list. To view trace details a slow transaction (if available), select its link. For more information, see Interactions page. To return to the main Devices page, select the Close (X) button. one.newrelic.com > Mobile > (select an app) > App > Devices > (select a device): This page provides drill-down details for the selected device, including http response time, network failures, active sessions, and slowest transaction traces (if available). For more help Additional documentation resources include: Errors page for mobile apps (detailed charts and information about errors with mobile apps) Versions analysis (seven-day report with a color-coded chart for mobile app usage, plus a table that summarizes mobile versions, date created, and averages) Monthly uniques report (bar charts showing the number of devices running your mobile app over the past 12 months)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 200.07541,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Devices <em>page</em>",
        "sections": "Devices <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " here you can drill down into details by a specific model (for example, iPhone 6, 6S, 7). Viewing the Devices <em>page</em> one.newrelic.com &gt; <em>Mobile</em> &gt; (select an <em>app</em>) &gt; <em>App</em> &gt; Devices: Use this <em>page</em> to view, sort, or drill down into detailed information about the top five types of devices using your <em>mobile</em>"
      },
      "id": "60450de0196a67fe2c960f64"
    },
    {
      "sections": [
        "Mobile apps index",
        "View your list of mobile apps",
        "Standard menu functions"
      ],
      "title": "Mobile apps index",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile App pages"
      ],
      "external_id": "38ff00ca55b0ca25a0ad534b57e02b01f4040c97",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/mobile-apps-index/",
      "published_at": "2021-07-02T13:10:32Z",
      "updated_at": "2021-04-16T21:34:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's mobile monitoring UI includes a mobile app index that shows a list of your monitored apps and important summary information about them. View your list of mobile apps To see the mobile apps index, go to one.newrelic.com and click Mobile. The index of available mobile apps includes a colored health status indicating: Green = Normal Yellow = Warning Red = Critical Gray = Not reporting data Standard menu functions To view details for a specific app, select it from the index. Here are some other functions available from the index: If you want to... Do this... View the app's status Mouse over the mobile app's colored health status indicator. If the health status indicator is gray and no data is being reported, you likely need to finish installing mobile monitoring. Monitor another app Select Add more. See the app's metadata To see the app's metadata, including its app ID, entity GUID, and more, click the icon next to the application name. For more about UI functions, see Basic UI functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.09676,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>apps</em> index",
        "sections": "<em>Mobile</em> <em>apps</em> index",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " Mouse over the <em>mobile</em> <em>app</em>&#x27;s colored health status indicator. If the health status indicator is gray and no data is being reported, you likely need to finish installing <em>mobile</em> <em>monitoring</em>. <em>Monitor</em> another <em>app</em> Select Add more. See the <em>app</em>&#x27;s metadata To see the <em>app</em>&#x27;s metadata, including its <em>app</em> ID, entity GUID, and more, click the icon next to the application name. For more about <em>UI</em> functions, see Basic <em>UI</em> functions."
      },
      "id": "604537fc64441f7903378f35"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/mobile-apps-index": [
    {
      "sections": [
        "Find Build UUIDs for unsymbolicated crashes",
        "View the Build UUID",
        "Binary images example",
        "Find and resymbolicate the dSYM",
        "For more help"
      ],
      "title": "Find Build UUIDs for unsymbolicated crashes",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "e8b926653583d66810c0f68eb6b0111ab3bfc477",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/find-build-uuids-unsymbolicated-crashes/",
      "published_at": "2021-07-02T14:14:31Z",
      "updated_at": "2021-07-02T14:14:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If the dSYM is not uploaded to New Relic, mobile crash reports cannot be symbolicated. You can upload dSYMs manually or directly through the New Relic UI. However, every build of an application will create a new dSYM, and it can be difficult managing which dSYM is attributed to which app build. In this situation, you can use the Build UUID identifier to: Identify a unique build of an application. Find which dSYM can be used to symbolicate a crash. View the Build UUID An application may have more than one Build UUID, one attributed for each CPU architecture the application is built. The Build UUID is also stored within the associated dSYM and can be extracted to identify the dSYM. New Relic crash reports also contain the Build UUID of the crashing application. To view the Build UUID: Go to one.newrelic.com and click Mobile in the top nav. Then find your app and click Crashes > Crash Analysis. From the Crash list table, select any row. From the selected crash report's Crash Details page, look for the App Image Uuid on the attribute list. If the App Image Uuid is not on the selected crash report's attributes list: Export the crash details. Look for the Build UUID in the Binary images section of the exported crash report. Use the Build UUID extracted from the crash details to find the missing dSYM. Binary images example Here is an example of the Binary images section from an exported crash report. This section lists the Build UUID for every dynamically-linked library included in the application, as well as the Build UUID for the main application. In this example, the main application is New Relic. Its Build UUID is 117667e7b8d230cb8a908906c64e0227. This is the identifier you can use to find the associated dSYM. Binary Images: 0xb1000 - 0x30d000 New Relic armv7 < 117667e7b8d230cb8a908906c64e0227 > /var/containers/Bundle/Application/New Relic.app/New Relic 0x22290000 - 0x22292000 libSystem.B.dylib armv7 <39d6d6f7c2ac3de8bb29c40a1b66368a> /usr/lib/libSystem.B.dylib 0x22292000 - 0x222de000 libc++.1.dylib armv7 <017dba6c16b63f9ebecb9ddd0d0a4520> /usr/lib/libc++.1.dylib 0x222de000 - 0x222f9000 libc++abi.dylib armv7 <d32373f6c2153a509f6603750d213ffb> /usr/lib/libc++abi.dylib 0x222fc000 - 0x22667000 libobjc.A.dylib armv7 <94f6d325c1843f45b3a439b86fc9de15> /usr/lib/libobjc.A.dylib 0x22667000 - 0x2266c000 libcache.dylib armv7 <8009f99fb892331dbcb61cd740ff0f43> /usr/lib/system/libcache.dylib 0x2266c000 - 0x22676000 libcommonCrypto.dylib armv7 <f6db318471d732d39918ef36bde65cb7> /usr/lib/system/libcommonCrypto.dylib 0x22676000 - 0x2267c000 libcompiler_rt.dylib armv7 <cfa3ca12d6c2383abcaf3c8541e9b86c> /usr/lib/system/libcompiler_rt.dylib 0x2267c000 - 0x22683000 libcopyfile.dylib armv7 <d2b06020c3693c7b9d179434f8115ba0> /usr/lib/system/libcopyfile.dylib 0x22683000 - 0x226d3000 libcorecrypto.dylib armv7 <181437f8d9e53277ace439de8b3fd1ad> /usr/lib/system/libcorecrypto.dylib 0x226d3000 - 0x2271d000 libdispatch.dylib armv7 <bbb4bba2176039ab95a59d7a56f6eff8> /usr/lib/system/libdispatch.dylib Copy Find and resymbolicate the dSYM To find a dSYM's Build UUID of a dSYM: use dwarfdump with the following terminal command: dwarfdump --uuid <path-to-dSYM> Copy In the following example, the New Relic dSYM returns two Build UUIDs, one each for ARMv7 and ARM64. The ARMv7 Build UUID matches the Build UUID of the missing crash example: > dwarfdump --uuid ./New\\ Relic.app.dSYM/Contents/Resources/DWARF/New\\ Relic UUID: 117667E7-B8D2-30CB-8A90-8906C64E0227 (armv7) ./New Relic.app.dSYM/Contents/Resources/DWARF/New Relic UUID: B1A8C6EE-02B9-3C55-AEE7-308521873107 (arm64) ./New Relic.app.dSYM/Contents/Resources/DWARF/New Relic Copy To symbolicate the unsymbolicated crashes, follow the instructions to manually upload the dSYM. For more help Manual dSYM upload (how to manually upload dSYMs) Retrieve and upload dSYMs (how to locate dSYMs from past app releases)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 222.32816,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "If the dSYM is not uploaded to New Relic, <em>mobile</em> crash reports cannot be symbolicated. You can upload dSYMs manually or directly through the New Relic <em>UI</em>. However, every build of an application will create a new dSYM, and it can be difficult managing which dSYM is attributed to which <em>app</em> build"
      },
      "id": "603e9fbae7b9d21cef2a07dd"
    },
    {
      "sections": [
        "Devices page",
        "Viewing the Devices page",
        "Viewing drill-down details",
        "For more help"
      ],
      "title": "Devices page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile App pages"
      ],
      "external_id": "b8bf0965c688601c352eda9c33b952a5a9e7ddae",
      "image": "https://docs.newrelic.com/static/9ecb707eee4236b41488d12707399210/c1b63/screen-mobile-devices_0.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/devices-page/",
      "published_at": "2021-07-02T15:29:30Z",
      "updated_at": "2021-05-16T06:31:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Devices page for New Relic Mobile provides performance details about the top devices using your mobile application, such as iPad, iPhone, iPod Touch, Android Tablet, etc. Charts compare the devices by: Interaction time HTTP request time Error rates and network failures Active user sessions From here you can drill down into details by a specific model (for example, iPhone 6, 6S, 7). Viewing the Devices page one.newrelic.com > Mobile > (select an app) > App > Devices: Use this page to view, sort, or drill down into detailed information about the top five types of devices using your mobile app, including interaction and HTTP request times, error rates, and active users. To view performance details about your users' mobile devices: Go to one.newrelic.com > Mobile > (select an app) > App > Devices. To select the mobile app versions or change the time period, use the Versions menu and time picker below the New Relic menu bar. Optional: Select the Sort by and Hide < 1% throughput options. To limit details to a specific device type (for example, iPad), select its name. Viewing drill-down details To drill down into detailed information, use any of New Relic's standard user interface functions and page functions to drill down into detailed information. In addition: To view a list of specific devices or models (for example, iPad mini, iPad Air, etc.), select the type (for example, iPad). To view details for a specific device or model, select its name from the expanded list. To view trace details a slow transaction (if available), select its link. For more information, see Interactions page. To return to the main Devices page, select the Close (X) button. one.newrelic.com > Mobile > (select an app) > App > Devices > (select a device): This page provides drill-down details for the selected device, including http response time, network failures, active sessions, and slowest transaction traces (if available). For more help Additional documentation resources include: Errors page for mobile apps (detailed charts and information about errors with mobile apps) Versions analysis (seven-day report with a color-coded chart for mobile app usage, plus a table that summarizes mobile versions, date created, and averages) Monthly uniques report (bar charts showing the number of devices running your mobile app over the past 12 months)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 200.07541,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Devices <em>page</em>",
        "sections": "Devices <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " here you can drill down into details by a specific model (for example, iPhone 6, 6S, 7). Viewing the Devices <em>page</em> one.newrelic.com &gt; <em>Mobile</em> &gt; (select an <em>app</em>) &gt; <em>App</em> &gt; Devices: Use this <em>page</em> to view, sort, or drill down into detailed information about the top five types of devices using your <em>mobile</em>"
      },
      "id": "60450de0196a67fe2c960f64"
    },
    {
      "sections": [
        "OS versions page",
        "Viewing the OS versions page",
        "Viewing drill-down details",
        "For more help"
      ],
      "title": "OS versions page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile App pages"
      ],
      "external_id": "370b6f1584d001a17f414066097692b9189e1a50",
      "image": "https://docs.newrelic.com/static/8d84abf966c2f4b75ca298b362995c0e/c1b63/os-version-pic_0.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/os-versions-page/",
      "published_at": "2021-07-02T13:42:10Z",
      "updated_at": "2021-03-16T09:36:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The OS versions page for Mobile monitoring provides performance details about the top operating system versions hosting your mobile application, such as iOS and Android. Charts compare the OS versions by: HTTP request time Network failures Requests per minute Active devices From here you can drill down into details by a major or minor OS version (for example, iOS 8, iOS 7.1.1, Android 4.2.2). Viewing the OS versions page one.newrelic.com > Mobile > (select an app) > App > OS versions: Use this page to view, sort, or drill down into detailed information about the top five types of operation system versions using your mobile app. To view performance details about the operating system versions for your mobile app users: Go to one.newrelic.com > Mobile > (select an app) > App > OS versions. To select the mobile app versions or time period, use the Versions menu and time picker below the UI menu bar. Optional: Select the Sort by and Hide < 1% throughput options. To expand or collapse the list of operating systems to include versions, select the operating system's name (for example, iOS 7). Viewing drill-down details To drill down into detailed information, use any of our standard user interface functions and page functions to drill down into detailed information. In addition: To view details for the minor and point releases of a major OS version (including interaction time, HTTP request times, network failures, active devices, and slowest traces or all subversions), select a major OS version from the list. To view details for a specific OS version, select its name from the expanded OS list. To view trace details a slow transaction (if available), select its link. For more information, see Interactions page. To return to the main OS versions page, select the Close (X) button. For more help Additional documentation resources include: Errors page for mobile apps (detailed charts and information about errors with mobile apps) Versions report (seven-day report with a color-coded chart for mobile app usage, plus a table that summarizes mobile versions, date created, and averages)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.40027,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "OS versions <em>page</em>",
        "sections": "OS versions <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The OS versions <em>page</em> for <em>Mobile</em> <em>monitoring</em> provides performance details about the top operating system versions hosting your <em>mobile</em> application, such as iOS and Android. Charts compare the OS versions by: HTTP request time Network failures Requests per minute Active devices From here you can drill"
      },
      "id": "603eaee9e7b9d260112a0809"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/mobile-apps-overview-page": [
    {
      "sections": [
        "Find Build UUIDs for unsymbolicated crashes",
        "View the Build UUID",
        "Binary images example",
        "Find and resymbolicate the dSYM",
        "For more help"
      ],
      "title": "Find Build UUIDs for unsymbolicated crashes",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "e8b926653583d66810c0f68eb6b0111ab3bfc477",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/find-build-uuids-unsymbolicated-crashes/",
      "published_at": "2021-07-02T14:14:31Z",
      "updated_at": "2021-07-02T14:14:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If the dSYM is not uploaded to New Relic, mobile crash reports cannot be symbolicated. You can upload dSYMs manually or directly through the New Relic UI. However, every build of an application will create a new dSYM, and it can be difficult managing which dSYM is attributed to which app build. In this situation, you can use the Build UUID identifier to: Identify a unique build of an application. Find which dSYM can be used to symbolicate a crash. View the Build UUID An application may have more than one Build UUID, one attributed for each CPU architecture the application is built. The Build UUID is also stored within the associated dSYM and can be extracted to identify the dSYM. New Relic crash reports also contain the Build UUID of the crashing application. To view the Build UUID: Go to one.newrelic.com and click Mobile in the top nav. Then find your app and click Crashes > Crash Analysis. From the Crash list table, select any row. From the selected crash report's Crash Details page, look for the App Image Uuid on the attribute list. If the App Image Uuid is not on the selected crash report's attributes list: Export the crash details. Look for the Build UUID in the Binary images section of the exported crash report. Use the Build UUID extracted from the crash details to find the missing dSYM. Binary images example Here is an example of the Binary images section from an exported crash report. This section lists the Build UUID for every dynamically-linked library included in the application, as well as the Build UUID for the main application. In this example, the main application is New Relic. Its Build UUID is 117667e7b8d230cb8a908906c64e0227. This is the identifier you can use to find the associated dSYM. Binary Images: 0xb1000 - 0x30d000 New Relic armv7 < 117667e7b8d230cb8a908906c64e0227 > /var/containers/Bundle/Application/New Relic.app/New Relic 0x22290000 - 0x22292000 libSystem.B.dylib armv7 <39d6d6f7c2ac3de8bb29c40a1b66368a> /usr/lib/libSystem.B.dylib 0x22292000 - 0x222de000 libc++.1.dylib armv7 <017dba6c16b63f9ebecb9ddd0d0a4520> /usr/lib/libc++.1.dylib 0x222de000 - 0x222f9000 libc++abi.dylib armv7 <d32373f6c2153a509f6603750d213ffb> /usr/lib/libc++abi.dylib 0x222fc000 - 0x22667000 libobjc.A.dylib armv7 <94f6d325c1843f45b3a439b86fc9de15> /usr/lib/libobjc.A.dylib 0x22667000 - 0x2266c000 libcache.dylib armv7 <8009f99fb892331dbcb61cd740ff0f43> /usr/lib/system/libcache.dylib 0x2266c000 - 0x22676000 libcommonCrypto.dylib armv7 <f6db318471d732d39918ef36bde65cb7> /usr/lib/system/libcommonCrypto.dylib 0x22676000 - 0x2267c000 libcompiler_rt.dylib armv7 <cfa3ca12d6c2383abcaf3c8541e9b86c> /usr/lib/system/libcompiler_rt.dylib 0x2267c000 - 0x22683000 libcopyfile.dylib armv7 <d2b06020c3693c7b9d179434f8115ba0> /usr/lib/system/libcopyfile.dylib 0x22683000 - 0x226d3000 libcorecrypto.dylib armv7 <181437f8d9e53277ace439de8b3fd1ad> /usr/lib/system/libcorecrypto.dylib 0x226d3000 - 0x2271d000 libdispatch.dylib armv7 <bbb4bba2176039ab95a59d7a56f6eff8> /usr/lib/system/libdispatch.dylib Copy Find and resymbolicate the dSYM To find a dSYM's Build UUID of a dSYM: use dwarfdump with the following terminal command: dwarfdump --uuid <path-to-dSYM> Copy In the following example, the New Relic dSYM returns two Build UUIDs, one each for ARMv7 and ARM64. The ARMv7 Build UUID matches the Build UUID of the missing crash example: > dwarfdump --uuid ./New\\ Relic.app.dSYM/Contents/Resources/DWARF/New\\ Relic UUID: 117667E7-B8D2-30CB-8A90-8906C64E0227 (armv7) ./New Relic.app.dSYM/Contents/Resources/DWARF/New Relic UUID: B1A8C6EE-02B9-3C55-AEE7-308521873107 (arm64) ./New Relic.app.dSYM/Contents/Resources/DWARF/New Relic Copy To symbolicate the unsymbolicated crashes, follow the instructions to manually upload the dSYM. For more help Manual dSYM upload (how to manually upload dSYMs) Retrieve and upload dSYMs (how to locate dSYMs from past app releases)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 222.32816,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "If the dSYM is not uploaded to New Relic, <em>mobile</em> crash reports cannot be symbolicated. You can upload dSYMs manually or directly through the New Relic <em>UI</em>. However, every build of an application will create a new dSYM, and it can be difficult managing which dSYM is attributed to which <em>app</em> build"
      },
      "id": "603e9fbae7b9d21cef2a07dd"
    },
    {
      "sections": [
        "Devices page",
        "Viewing the Devices page",
        "Viewing drill-down details",
        "For more help"
      ],
      "title": "Devices page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile App pages"
      ],
      "external_id": "b8bf0965c688601c352eda9c33b952a5a9e7ddae",
      "image": "https://docs.newrelic.com/static/9ecb707eee4236b41488d12707399210/c1b63/screen-mobile-devices_0.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/devices-page/",
      "published_at": "2021-07-02T15:29:30Z",
      "updated_at": "2021-05-16T06:31:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Devices page for New Relic Mobile provides performance details about the top devices using your mobile application, such as iPad, iPhone, iPod Touch, Android Tablet, etc. Charts compare the devices by: Interaction time HTTP request time Error rates and network failures Active user sessions From here you can drill down into details by a specific model (for example, iPhone 6, 6S, 7). Viewing the Devices page one.newrelic.com > Mobile > (select an app) > App > Devices: Use this page to view, sort, or drill down into detailed information about the top five types of devices using your mobile app, including interaction and HTTP request times, error rates, and active users. To view performance details about your users' mobile devices: Go to one.newrelic.com > Mobile > (select an app) > App > Devices. To select the mobile app versions or change the time period, use the Versions menu and time picker below the New Relic menu bar. Optional: Select the Sort by and Hide < 1% throughput options. To limit details to a specific device type (for example, iPad), select its name. Viewing drill-down details To drill down into detailed information, use any of New Relic's standard user interface functions and page functions to drill down into detailed information. In addition: To view a list of specific devices or models (for example, iPad mini, iPad Air, etc.), select the type (for example, iPad). To view details for a specific device or model, select its name from the expanded list. To view trace details a slow transaction (if available), select its link. For more information, see Interactions page. To return to the main Devices page, select the Close (X) button. one.newrelic.com > Mobile > (select an app) > App > Devices > (select a device): This page provides drill-down details for the selected device, including http response time, network failures, active sessions, and slowest transaction traces (if available). For more help Additional documentation resources include: Errors page for mobile apps (detailed charts and information about errors with mobile apps) Versions analysis (seven-day report with a color-coded chart for mobile app usage, plus a table that summarizes mobile versions, date created, and averages) Monthly uniques report (bar charts showing the number of devices running your mobile app over the past 12 months)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 200.07541,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Devices <em>page</em>",
        "sections": "Devices <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " here you can drill down into details by a specific model (for example, iPhone 6, 6S, 7). Viewing the Devices <em>page</em> one.newrelic.com &gt; <em>Mobile</em> &gt; (select an <em>app</em>) &gt; <em>App</em> &gt; Devices: Use this <em>page</em> to view, sort, or drill down into detailed information about the top five types of devices using your <em>mobile</em>"
      },
      "id": "60450de0196a67fe2c960f64"
    },
    {
      "sections": [
        "Mobile apps index",
        "View your list of mobile apps",
        "Standard menu functions"
      ],
      "title": "Mobile apps index",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile App pages"
      ],
      "external_id": "38ff00ca55b0ca25a0ad534b57e02b01f4040c97",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/mobile-apps-index/",
      "published_at": "2021-07-02T13:10:32Z",
      "updated_at": "2021-04-16T21:34:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's mobile monitoring UI includes a mobile app index that shows a list of your monitored apps and important summary information about them. View your list of mobile apps To see the mobile apps index, go to one.newrelic.com and click Mobile. The index of available mobile apps includes a colored health status indicating: Green = Normal Yellow = Warning Red = Critical Gray = Not reporting data Standard menu functions To view details for a specific app, select it from the index. Here are some other functions available from the index: If you want to... Do this... View the app's status Mouse over the mobile app's colored health status indicator. If the health status indicator is gray and no data is being reported, you likely need to finish installing mobile monitoring. Monitor another app Select Add more. See the app's metadata To see the app's metadata, including its app ID, entity GUID, and more, click the icon next to the application name. For more about UI functions, see Basic UI functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.09676,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>apps</em> index",
        "sections": "<em>Mobile</em> <em>apps</em> index",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " Mouse over the <em>mobile</em> <em>app</em>&#x27;s colored health status indicator. If the health status indicator is gray and no data is being reported, you likely need to finish installing <em>mobile</em> <em>monitoring</em>. <em>Monitor</em> another <em>app</em> Select Add more. See the <em>app</em>&#x27;s metadata To see the <em>app</em>&#x27;s metadata, including its <em>app</em> ID, entity GUID, and more, click the icon next to the application name. For more about <em>UI</em> functions, see Basic <em>UI</em> functions."
      },
      "id": "604537fc64441f7903378f35"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/mobile-monitoring-email-notifications": [
    {
      "sections": [
        "Find Build UUIDs for unsymbolicated crashes",
        "View the Build UUID",
        "Binary images example",
        "Find and resymbolicate the dSYM",
        "For more help"
      ],
      "title": "Find Build UUIDs for unsymbolicated crashes",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "e8b926653583d66810c0f68eb6b0111ab3bfc477",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/find-build-uuids-unsymbolicated-crashes/",
      "published_at": "2021-07-02T14:14:31Z",
      "updated_at": "2021-07-02T14:14:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If the dSYM is not uploaded to New Relic, mobile crash reports cannot be symbolicated. You can upload dSYMs manually or directly through the New Relic UI. However, every build of an application will create a new dSYM, and it can be difficult managing which dSYM is attributed to which app build. In this situation, you can use the Build UUID identifier to: Identify a unique build of an application. Find which dSYM can be used to symbolicate a crash. View the Build UUID An application may have more than one Build UUID, one attributed for each CPU architecture the application is built. The Build UUID is also stored within the associated dSYM and can be extracted to identify the dSYM. New Relic crash reports also contain the Build UUID of the crashing application. To view the Build UUID: Go to one.newrelic.com and click Mobile in the top nav. Then find your app and click Crashes > Crash Analysis. From the Crash list table, select any row. From the selected crash report's Crash Details page, look for the App Image Uuid on the attribute list. If the App Image Uuid is not on the selected crash report's attributes list: Export the crash details. Look for the Build UUID in the Binary images section of the exported crash report. Use the Build UUID extracted from the crash details to find the missing dSYM. Binary images example Here is an example of the Binary images section from an exported crash report. This section lists the Build UUID for every dynamically-linked library included in the application, as well as the Build UUID for the main application. In this example, the main application is New Relic. Its Build UUID is 117667e7b8d230cb8a908906c64e0227. This is the identifier you can use to find the associated dSYM. Binary Images: 0xb1000 - 0x30d000 New Relic armv7 < 117667e7b8d230cb8a908906c64e0227 > /var/containers/Bundle/Application/New Relic.app/New Relic 0x22290000 - 0x22292000 libSystem.B.dylib armv7 <39d6d6f7c2ac3de8bb29c40a1b66368a> /usr/lib/libSystem.B.dylib 0x22292000 - 0x222de000 libc++.1.dylib armv7 <017dba6c16b63f9ebecb9ddd0d0a4520> /usr/lib/libc++.1.dylib 0x222de000 - 0x222f9000 libc++abi.dylib armv7 <d32373f6c2153a509f6603750d213ffb> /usr/lib/libc++abi.dylib 0x222fc000 - 0x22667000 libobjc.A.dylib armv7 <94f6d325c1843f45b3a439b86fc9de15> /usr/lib/libobjc.A.dylib 0x22667000 - 0x2266c000 libcache.dylib armv7 <8009f99fb892331dbcb61cd740ff0f43> /usr/lib/system/libcache.dylib 0x2266c000 - 0x22676000 libcommonCrypto.dylib armv7 <f6db318471d732d39918ef36bde65cb7> /usr/lib/system/libcommonCrypto.dylib 0x22676000 - 0x2267c000 libcompiler_rt.dylib armv7 <cfa3ca12d6c2383abcaf3c8541e9b86c> /usr/lib/system/libcompiler_rt.dylib 0x2267c000 - 0x22683000 libcopyfile.dylib armv7 <d2b06020c3693c7b9d179434f8115ba0> /usr/lib/system/libcopyfile.dylib 0x22683000 - 0x226d3000 libcorecrypto.dylib armv7 <181437f8d9e53277ace439de8b3fd1ad> /usr/lib/system/libcorecrypto.dylib 0x226d3000 - 0x2271d000 libdispatch.dylib armv7 <bbb4bba2176039ab95a59d7a56f6eff8> /usr/lib/system/libdispatch.dylib Copy Find and resymbolicate the dSYM To find a dSYM's Build UUID of a dSYM: use dwarfdump with the following terminal command: dwarfdump --uuid <path-to-dSYM> Copy In the following example, the New Relic dSYM returns two Build UUIDs, one each for ARMv7 and ARM64. The ARMv7 Build UUID matches the Build UUID of the missing crash example: > dwarfdump --uuid ./New\\ Relic.app.dSYM/Contents/Resources/DWARF/New\\ Relic UUID: 117667E7-B8D2-30CB-8A90-8906C64E0227 (armv7) ./New Relic.app.dSYM/Contents/Resources/DWARF/New Relic UUID: B1A8C6EE-02B9-3C55-AEE7-308521873107 (arm64) ./New Relic.app.dSYM/Contents/Resources/DWARF/New Relic Copy To symbolicate the unsymbolicated crashes, follow the instructions to manually upload the dSYM. For more help Manual dSYM upload (how to manually upload dSYMs) Retrieve and upload dSYMs (how to locate dSYMs from past app releases)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 222.32816,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "If the dSYM is not uploaded to New Relic, <em>mobile</em> crash reports cannot be symbolicated. You can upload dSYMs manually or directly through the New Relic <em>UI</em>. However, every build of an application will create a new dSYM, and it can be difficult managing which dSYM is attributed to which <em>app</em> build"
      },
      "id": "603e9fbae7b9d21cef2a07dd"
    },
    {
      "sections": [
        "Devices page",
        "Viewing the Devices page",
        "Viewing drill-down details",
        "For more help"
      ],
      "title": "Devices page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile App pages"
      ],
      "external_id": "b8bf0965c688601c352eda9c33b952a5a9e7ddae",
      "image": "https://docs.newrelic.com/static/9ecb707eee4236b41488d12707399210/c1b63/screen-mobile-devices_0.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/devices-page/",
      "published_at": "2021-07-02T15:29:30Z",
      "updated_at": "2021-05-16T06:31:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Devices page for New Relic Mobile provides performance details about the top devices using your mobile application, such as iPad, iPhone, iPod Touch, Android Tablet, etc. Charts compare the devices by: Interaction time HTTP request time Error rates and network failures Active user sessions From here you can drill down into details by a specific model (for example, iPhone 6, 6S, 7). Viewing the Devices page one.newrelic.com > Mobile > (select an app) > App > Devices: Use this page to view, sort, or drill down into detailed information about the top five types of devices using your mobile app, including interaction and HTTP request times, error rates, and active users. To view performance details about your users' mobile devices: Go to one.newrelic.com > Mobile > (select an app) > App > Devices. To select the mobile app versions or change the time period, use the Versions menu and time picker below the New Relic menu bar. Optional: Select the Sort by and Hide < 1% throughput options. To limit details to a specific device type (for example, iPad), select its name. Viewing drill-down details To drill down into detailed information, use any of New Relic's standard user interface functions and page functions to drill down into detailed information. In addition: To view a list of specific devices or models (for example, iPad mini, iPad Air, etc.), select the type (for example, iPad). To view details for a specific device or model, select its name from the expanded list. To view trace details a slow transaction (if available), select its link. For more information, see Interactions page. To return to the main Devices page, select the Close (X) button. one.newrelic.com > Mobile > (select an app) > App > Devices > (select a device): This page provides drill-down details for the selected device, including http response time, network failures, active sessions, and slowest transaction traces (if available). For more help Additional documentation resources include: Errors page for mobile apps (detailed charts and information about errors with mobile apps) Versions analysis (seven-day report with a color-coded chart for mobile app usage, plus a table that summarizes mobile versions, date created, and averages) Monthly uniques report (bar charts showing the number of devices running your mobile app over the past 12 months)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 200.07541,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Devices <em>page</em>",
        "sections": "Devices <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " here you can drill down into details by a specific model (for example, iPhone 6, 6S, 7). Viewing the Devices <em>page</em> one.newrelic.com &gt; <em>Mobile</em> &gt; (select an <em>app</em>) &gt; <em>App</em> &gt; Devices: Use this <em>page</em> to view, sort, or drill down into detailed information about the top five types of devices using your <em>mobile</em>"
      },
      "id": "60450de0196a67fe2c960f64"
    },
    {
      "sections": [
        "Mobile apps index",
        "View your list of mobile apps",
        "Standard menu functions"
      ],
      "title": "Mobile apps index",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile App pages"
      ],
      "external_id": "38ff00ca55b0ca25a0ad534b57e02b01f4040c97",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/mobile-apps-index/",
      "published_at": "2021-07-02T13:10:32Z",
      "updated_at": "2021-04-16T21:34:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's mobile monitoring UI includes a mobile app index that shows a list of your monitored apps and important summary information about them. View your list of mobile apps To see the mobile apps index, go to one.newrelic.com and click Mobile. The index of available mobile apps includes a colored health status indicating: Green = Normal Yellow = Warning Red = Critical Gray = Not reporting data Standard menu functions To view details for a specific app, select it from the index. Here are some other functions available from the index: If you want to... Do this... View the app's status Mouse over the mobile app's colored health status indicator. If the health status indicator is gray and no data is being reported, you likely need to finish installing mobile monitoring. Monitor another app Select Add more. See the app's metadata To see the app's metadata, including its app ID, entity GUID, and more, click the icon next to the application name. For more about UI functions, see Basic UI functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.09676,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>apps</em> index",
        "sections": "<em>Mobile</em> <em>apps</em> index",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " Mouse over the <em>mobile</em> <em>app</em>&#x27;s colored health status indicator. If the health status indicator is gray and no data is being reported, you likely need to finish installing <em>mobile</em> <em>monitoring</em>. <em>Monitor</em> another <em>app</em> Select Add more. See the <em>app</em>&#x27;s metadata To see the <em>app</em>&#x27;s metadata, including its <em>app</em> ID, entity GUID, and more, click the icon next to the application name. For more about <em>UI</em> functions, see Basic <em>UI</em> functions."
      },
      "id": "604537fc64441f7903378f35"
    }
  ]
}